{"docstore/metadata": {"5fdca76f-20a7-47a4-a83c-cacec63c90c4": {"doc_hash": "9b6698a867e674f2b69ee9764df7358552bf8919a0423a321d93b05d1896ca32"}, "37bd2236-911c-4b08-accb-ef6b1f9ef905": {"doc_hash": "f3fa714c7d449c16e53e54bf2a374e0ad3db788947511c5a08aeae7908beea16"}, "4581035e-2990-4f4f-8e1b-bed06d5448a4": {"doc_hash": "596de1ed0172cbdf8f7edeaea89873fb68db419951b92dc7197846c9d69d4e9a"}, "528fe30f-3a13-43f7-ae0a-37ce8b0208f2": {"doc_hash": "76cb5f3844f4bb06f370154b95343d5e821850b6e8ee96c59c7af9306c64135e"}, "945ad618-6119-4107-b8a8-eb0c64d57def": {"doc_hash": "4b11070ee654def9709516d9ceef7e63aa32c71555c80696425475bec097fcff"}, "51187fbd-9b8e-4d41-9669-16a9a0faf3b4": {"doc_hash": "411b12ff5a76205c7b3d78b91a15a367e674daaaa7bc5d49174faefd1b61fe29"}, "f1ca778a-d93c-4b59-87fd-60dc4780496e": {"doc_hash": "147ebd9485543ed71c303a752b8374ca71e5db05199ae3f316778f5e8f418fe9"}, "7e574ab9-43e5-45ad-a9e2-e9fac0a090a7": {"doc_hash": "1a5fb4f5439f3c40f63d259b4b3680e1eb39baef79be234273c68d67bd71edd9"}, "7c4ed315-37b0-4452-b3da-091b549063fb": {"doc_hash": "354ed88adde329e537d8c06fe17fd25735d1ac42772a6191b707b8c9ac8f82bc"}, "1af86495-ba94-43e3-a53d-a3c335a88549": {"doc_hash": "6872f00452a6dcf805b2a5e309c8614be9009352bf584f3c223e84cf3a7838b2"}, "d5d95e2e-dcd7-4a57-9b8f-b7788b78f38f": {"doc_hash": "8f764b5d040840845986097f3f988d727121f50c8c84db4bdbe1b78e2f52d38b"}, "fb498b95-d043-4828-a02e-fc28bc68f1c8": {"doc_hash": "1fe81b3d846a55c6a59e6817e5cdfcf0454392d09c2f19bef7c519e8c0fbfc04"}, "1a0973d8-6604-4b72-884a-a74900f2ebc7": {"doc_hash": "1624d90012ce0ac05e2de61e7e9a5a294a36d10ddac6a5458e6ee5ec4a16517c"}, "f031ae10-742d-432d-8c64-1d4bbe5cd2a1": {"doc_hash": "a21f8e9aa74069aca33e4624434845dccbaeb5afbd0c39cb59925aadd7916fb3"}, "c5398ab6-27d0-4a7e-90f6-05e13ff61eb5": {"doc_hash": "8bacec2414108ac22d0c8c3a7fcb732c29c363f8d2c574f55aac7bb8b336ed53"}, "900f478e-6fa4-45c1-9445-3074b7be99d1": {"doc_hash": "060f4bdc937826f86e53f781ef4c3aef29e0725099b501e8def68d5f7ba25349"}, "393cf43a-19a2-4f56-be4c-de5b02a7dfcd": {"doc_hash": "f9dc661ae53127319011f3be3ce0071571a0a5b0cd6adf1f41d5d2e6e8ad628e"}, "e5c4b133-9c70-4d9c-9b70-2cd34f1351da": {"doc_hash": "304ade60b8640d74aea7cebab2912de8c841b6f063d39cd3aa92c7d8ddc952d3"}, "9c9bcb9c-b165-403b-9a6c-cce1f55c0344": {"doc_hash": "d07334ae8251998ddcc1a594949ef622e85212a858025f42f383580bc7ef4d91"}, "2a2f9d8a-6f41-4108-a42b-2abc2edd97fa": {"doc_hash": "04dc0c007695fcb71fe7d93fb83d8832600f80d39874d0a5fed72fd5b953642e"}, "0f074703-15d1-49eb-a09a-4b83501ec8eb": {"doc_hash": "30852db2347aa68cb9f6ba775ccca8ac27b6340518432c88b6ad7dc18449c28f"}, "aa63d5c7-26f2-4f55-bda3-889481b364b1": {"doc_hash": "d13b9e137fd85b86da0d202de095f31a880d72ed77b8c98993b31d04b722cd28"}, "58257a48-1f67-4ef9-803b-d0a0a42965dd": {"doc_hash": "dc09c2e673e4273b5a0737f7c649aab7cc85b896b0d1b396cefd014ca2c60c89"}, "3da8e6a1-b3f8-4ce8-8e0e-28e9d30c0584": {"doc_hash": "0f1db01926f91a91e320f88863144b1ab44a4f4252431389d0febfba23a7e7a0"}, "1d891d19-535a-491d-88af-c97e09918a08": {"doc_hash": "54d17a83a6484fe4101957efffd0a93c4d75aa9eeb7f1722b5b564994e3ed891"}, "6383d9f7-06ca-4bcd-9b68-cbdd7bad5246": {"doc_hash": "50c2e787b7780a71fa48b4841c7d20435b3c9c3972f66ebea2a538e057955147"}, "c92a4b9b-c90f-442a-abc2-08d24c71dfc3": {"doc_hash": "46407b4af0cbd72c2d43b965eda4e6c2b5f58ce449aca27ceb095f668bcf55f9"}, "78822a72-71de-4dd3-9578-85bf49788e2a": {"doc_hash": "bfb83739f341261442083deecc0288113e950c467eddb5b252537d2fe78c3adf"}, "0dee402c-c817-463e-b8fa-f6b7cbad1043": {"doc_hash": "a28f17cfbaa5ba31cb5d1664e8c2e80aa1b12b32f1823a19f2e2d5791b1a810c"}, "7975aeb9-739a-4b9f-bbec-935319f8dfe4": {"doc_hash": "8a05486a499ec19c07c1f310462dab19dae05943989e0863d663d9f8fdc49bc3"}, "898d5649-af24-4cca-ae17-14baef9276de": {"doc_hash": "02968a4e9e8d113134b4c89169a3ee0d5d6cebc5e38eb055e65ec4216e4ad270"}, "bd3daff7-c0cc-4307-8436-3dc37ba83bb0": {"doc_hash": "8ec13adcc1b0179d24ee0a75b6f8c47daf622ac799e44cc44384da7b5ad8307b"}, "bb5a1511-c471-4b43-b69c-20b75f118834": {"doc_hash": "7d8bd78ce4e3be5f31b2ce83f11670da722ca2a0656f76b4bd42e122f449d080"}, "5a164584-56dd-4f2a-94f6-1483b152531e": {"doc_hash": "a76107b2ff598d2f5330ce5731bb1d377bbc5a43167895360fff64cfda2ae3a9"}, "258050e8-6120-4bd8-b50e-e511ee3e45a4": {"doc_hash": "2c2c78811bac78f635abeaaf6375ad6652ff5ffcd7044bc6a68289c9c3472239"}, "951a9037-87ff-4907-a530-7ab50820a30b": {"doc_hash": "11fa25be5afe132c3847cbdd43bb59a8c7f8194b81f93d3e6a0cc58ee4b56135"}, "5fe168bb-a705-4b4f-90ae-21a686faa2f1": {"doc_hash": "cfb637799ed7a05924ef8dfc2752e91e9035e52875f395c36a7af1ca1f8865f3"}, "82878ad2-8b3d-4f4f-a6e7-6f853e8bb04d": {"doc_hash": "16a4b52974a8aae072e5a00a85932fdb91c045fe3ab2f50c91c1cbc6d622c507"}, "d6825006-09ab-411a-b494-8862d6b5df86": {"doc_hash": "18e5b7a24db0002f6d2af80a6c20d8c03626dd5620e40b8907ea14892f1e8fd7"}, "62219533-1281-4650-93f9-ad363b4cfcc3": {"doc_hash": "8b1625d24241226377b57ed5bce3bd78fa9eecf37154affe2405e1b572f7bf2d"}, "afd0415f-2a85-4e3d-a0c3-c435d3e384e6": {"doc_hash": "f9ad7c24dbe3e750ad05b1dff54bee9852e765f6d6872ee53f88b0737bb65d91"}, "e51f519b-f653-4b41-99f8-53299da256e3": {"doc_hash": "2c17a6fcf80adc71e4e9cacb8bcc9343e4d0ddb86603584485938556a94a35ca"}, "ae4876e2-4d48-418d-9fcf-802119b6a019": {"doc_hash": "2d149f0163c757c304fdd10ca042d15c037cf97302ea4fb5569bf205fe4d9f6c"}, "6dc09ded-00e8-45ed-b90f-15bffa78c3c5": {"doc_hash": "4a83cdd9c3f203dc40f6514409639deb3f336fa96fac153485ced1c68d0e7525"}, "90d7236b-c218-4670-8ea5-7c24a954ef5b": {"doc_hash": "d246dd59cc0bf0ab41635881748555f81bacfebcbfe3fe881218fb069f357bb8"}, "d4c3880d-3f3e-420a-83bf-cd904882846e": {"doc_hash": "73246896e9b193bc29eb823518af64d3be14c9e162671b21ec5baa885514449d"}, "6f846041-1670-4913-b300-358a77d8fb8b": {"doc_hash": "49746c3d0623143cfc6150de7e96b7522754dd982fa560e72b5a40d220e4d821"}, "f56508a0-c32e-4f19-b1fa-80a3ceb450d7": {"doc_hash": "cee888219b43cfd38fd3d1f7138de5117119c09e78f3236bf26f2288362784f9"}, "e78f13a9-05b3-44d4-bf44-ca15c435a03d": {"doc_hash": "61055f115a1383893ae4a1080ff540a4ad99343519e38fc1742bb8465269b2f6"}, "767d2f30-b24b-4503-86fd-a5f3ac532c3b": {"doc_hash": "dd46a0fbb4aa6d3b5866e92812abcb6f3bde33a648e1aa690d962280d3c961c0"}, "9d51f697-8ec6-4e8d-8cda-ee852483ad15": {"doc_hash": "6501b20041ea63312dd968869bb6f2ac817a23068f9403235174ef717471eb6e"}, "87ef98f8-3a25-42ba-8cc2-7268a2c8cafa": {"doc_hash": "475d800e30f3a1634e0c5f83ca544087131dc497d54f3c3d9f649202cf0b8c8e"}, "e5f4e55f-921a-4f3d-ad5d-ea891eabbce9": {"doc_hash": "a4d5cb4e92a8eb802a0142c208f336bfaf7ae9e4e0d1b77172be654c11d40766"}, "dd607c41-f9f2-41a9-8d65-5944e639858a": {"doc_hash": "f0979f63265fc1cc609b8163c0314c26784cf9f928967901f918286b353175ae"}, "883ce6b3-73f9-49ff-a697-215c6bf883cb": {"doc_hash": "e189f32ebcbfee8c403251cbe4ab5e0b0c6c03289d882d8edd7e01710ffa18a1"}, "784ae904-6fd9-4e1b-9d8e-41919cc443ec": {"doc_hash": "628030eaa70f44f0cf2372a444f60aafeb1749cf8bdc1c1895bc889624606788"}, "08781c35-368d-4fce-af89-8ceb7eb5d90c": {"doc_hash": "85fb44f6c48da9a67e8f59dd9ceac6cc5d1fb06f054ceb7e8bf78c05812e10ef"}, "f57ad530-a18f-40e4-a40f-02d8ddb8adb5": {"doc_hash": "5aa2395064790cbd9e76d672ad6d06c263dd18d2c6d0ac778e8870d0de8935a8"}, "4948a8bd-9e2e-4f80-80d1-db57c3ea4466": {"doc_hash": "9d164b6ed2e36b05f9afd4259924d88a2e789dfb723f3de252c3f3d40830a7cd"}, "8cc96437-fa97-48f9-a074-c25edd207890": {"doc_hash": "c23d5e28628a9ac83b70d680899691748790ea66aba12d03b3052cfd32f1506a"}, "57b1cdc2-be4c-499b-9aa9-f9ebf79af525": {"doc_hash": "eb246b0754bf5acef5c9459824de8acd2436319b4da27006b71885598c4e4a57"}, "823e160d-7330-4c5e-b33d-227d6d54427a": {"doc_hash": "6652cc7902020c686d69973e0861f599a4cd2d5839d056cf708a67333aa0dd60"}, "13687b7f-e02f-4d0f-aea6-47326c102e6e": {"doc_hash": "6e93fcbef0f522a8957f2b4f58de7ebe4403b5f3221c9580703d4e8e8b6fc9c0"}, "374a13fd-f67b-4275-877f-a5a560e808b9": {"doc_hash": "eec2742d483fa0830f0a04429f68c3f05541c2f45df2761aefa0d42ad4efb837"}, "55469b63-dc24-4ecd-bd44-0e357586bf53": {"doc_hash": "55825d13c19a7e616cd3a082e95af9fe2ce54c4d167c59b5c5aa4b3284735b9f"}, "f12e966a-9701-4a0f-b787-b9c856297b8c": {"doc_hash": "1dc3a08feffdf4be5c132e5d02ae9a050ce35c6a741168e03a33dd2742ace299"}, "7836b5b7-597a-473f-a7dd-022ab96bf35f": {"doc_hash": "643494e7b09a65886ce71cc722f080c26a6b1dc499c0d58ab58f38ab28eb4daa"}, "eb13f5d3-1fab-4a9b-945b-0373a3455e48": {"doc_hash": "2669033c0657cd3424e7bd5738b958a7dff541646c63bd93998aac2bc673e1c7"}, "af6ea6d1-6b5d-4878-82bf-c90e8c1b32be": {"doc_hash": "4eb520e071c021bb3c23b29e8986fb50b20b9b11fd8e0402ee94390285c436c2"}, "e9cef8fd-5e32-453f-9d0b-a4863bb5737c": {"doc_hash": "0e5b25a6cf5ded08b06a611420b11c186e6ce99d6023490870a50a144d6efcff"}, "5dde6ed3-02ec-4256-8a46-e5d3fdedc978": {"doc_hash": "b16ab54c519662032ffa1f249ddf231757cc279c8b91d9ba81fed51b9904d201"}, "fb9bfa1f-b567-40ad-a89b-02a8ab70b023": {"doc_hash": "d7ebea6ebc5544e1c776d0c8aefb6df759f0f1d43c698e780b46faba1b5af116"}, "fe829457-6dc6-47ba-8620-0784d9c685f3": {"doc_hash": "bcaf9b0b3164f9fb5752d1c720086d5e44d8f79d3a5cc51a40bff52fab1e4c39"}, "7399d33a-97ee-4188-a725-6684bc671b7a": {"doc_hash": "62eb75607224f63fb15f105230913d8624c1c12b3cc5fb1934296475a8d2e0fb"}, "f4c46dc6-91ad-4562-969d-3ceab4817eb5": {"doc_hash": "0a4cb3002e91f948afe5eb2a304b9be96466f5bfbfded9812a7f529eac04db53"}, "0038fcb3-eae5-4c1e-9b43-d8128598e6da": {"doc_hash": "1eb1549cdd809b34cb826b74cbeea842c268047ea8c449317788c4c41d511e91"}, "baea3c86-272a-480f-8f90-fe50cd8d977d": {"doc_hash": "b48ffede3ad583a1f51d65b95df2a916603d611b1b803aba77f155e51dbbf0b1"}, "0df5351b-918e-4775-a471-6ffcd4182ebf": {"doc_hash": "170db5810bd00487a7c7d94f67d9daa3d55609fe21530bfa3b2f73cae3f13988"}, "d9195d25-0b41-40f2-b155-8c86540fee66": {"doc_hash": "26c1b1f44ed8d58e6a5834342839fb3be522ca21111ba76101bfd6969dcbf337"}, "1134c719-c299-48d7-bd1d-17dae46639a4": {"doc_hash": "7fb6dffe26ab066e4c908785dfcc006dfbdd92e63671c5d00898833a616d9819"}, "fff2b8b2-ae55-4a9a-bfa6-a21ee2f77ebc": {"doc_hash": "ef3628aca5267f4d4a12662913a466f591b18bafe1071fa8dddabe2af4a1a22e"}, "3f8555fc-1beb-45b2-ac52-ff6aa57d8928": {"doc_hash": "b5382f8bc3eab0810dc61955e3f1d9cd28f279cc49f5f64b5c52b3a7d636f6d7"}, "b41ee02e-c3c0-4b46-b4f8-9d834b8195bf": {"doc_hash": "222ceadf14ffa5abab05a8a10337d40f6be83303a3632a7fa1fd3e569e079f1d"}, "003f90ab-0657-4e5e-9672-253174157aca": {"doc_hash": "5b54377a04a7f3a8f86f98a81d282b233219f5721fdd3511fc2b1009628fec76"}, "175501a3-51f3-4057-a506-3e7e3f9e5d28": {"doc_hash": "5e75cf11286ec89eb63756cb9c777f1e54495f55a83c50cad7053571829648de"}, "1a36bbb8-7a17-427a-9076-deb36cd9e4dc": {"doc_hash": "4989e304bf60005657e3cab786bc04837b7c2bcf3fcca4e6c7754c098b64c143"}, "66946692-6537-44f6-a66f-a4dda36ccc67": {"doc_hash": "de7a2a47d0262fe73758828e81cf761dda810e7ca7cabfb424ec87b7c65598a1"}, "b4ccbf3f-1ce6-422c-ab7d-9399e77fe42f": {"doc_hash": "0ac238fbb4cfb2644f8ec31326952f9e2f16a8b7f4f8a06792280dc20ecfae04"}, "bac4a870-a4a4-478f-b20e-37d650d60e51": {"doc_hash": "6a5aae6cb1e3484b6c0ef324af0b7c28e7356bcb1b8389a44c7e5424128bdc85"}, "6701fa1e-4cc0-4b8e-bcb6-98be9ac5b253": {"doc_hash": "dd56b662ca8e08609b62786cf7a6eb61deab511dd4a13d5000e80b8c8ba0c864"}, "30018590-5c66-444c-bf2c-6021d644b552": {"doc_hash": "3341ffd45fabafbc5d4ddf4f0fc3d0cd9aaf783aaaa16eae7a4f91341343860a"}, "e29e5397-96c3-4792-a3e1-7eff15a93804": {"doc_hash": "3ea2f840fc88ea564bb24eec4287446224e99da0a78fe8eb7b3c8221c53b033b"}, "d8f05422-4f16-49a2-a2ad-a12023c5a8af": {"doc_hash": "ed0ce1aa5665d30f96f2175262d7c0c83e28a4aaf4fad7c986f1b3c27ae826d1"}, "3adff088-506d-431f-bff0-2a2f0a68a45c": {"doc_hash": "13fb5b7edf068ece4c5411927bc613bf8bedadb219f9729e47d8484ef73082af"}, "b250db54-beeb-40cb-b33f-888e2eebf77e": {"doc_hash": "d9043183f9722672f2f522e44dd34643b687b443367b0c4502fbcc8a4474ce7b"}, "0676ccc1-8cf9-4bf9-b5e9-420c91fed017": {"doc_hash": "802656b807ec2c2b5a8b7cdcbbaa7592cf9cb54848402f9e5efd12866f83ddb6"}, "394fdc66-c328-4cd3-ba47-d7587b00dd1e": {"doc_hash": "32458996d0ee53975191576f90a3a19a9570767f4bd4cb10f7aa1113bed82211"}, "83f1d845-a91a-4c18-a050-c27824c477f8": {"doc_hash": "3488d5c1f36ce50afaff77acd259ed37f7812862809c460d9c5d78a02da72bd2"}, "0216e669-c49f-438f-a72d-4ffc37935518": {"doc_hash": "2e2290ced1a26d443c20792754d093c6eafb16e1fbeffa274b4abaf7cb3b7a7c"}, "a3f328e3-a3ad-49dc-927c-f3bba8778f32": {"doc_hash": "ec7dca2fb892356164fb32ab27975ed943eea08cb72fa300576ee77517432ed4"}, "05ee2cdb-b0c7-4a89-bbe3-b681745d5ba3": {"doc_hash": "bde8652c52ccbc050cb9cfc8f0500a33c2e2adb85d3679d2dc95e3d14daa1c45"}, "b7514aee-8ae2-42fb-876c-2476281c1d2e": {"doc_hash": "1ef3732d8a40c43242c96afb1b68ac72fce6438bd2ab93b22a74634a207b51d9"}, "8c3480f6-714c-4fda-bd6f-0d4625a39233": {"doc_hash": "1e34d1badd69119db8309baa28f5558f3cffed4c1c7807c698f2249b7b50b8fe"}, "7294a5b5-ce6d-405e-bc37-029cdffe4483": {"doc_hash": "48658d708dc1f8099e5c1fbb8ca97176c6f368d25e05fca05a0706877c7dddfd"}, "e625afda-7a21-4300-9f49-9ce43e09b0c9": {"doc_hash": "babcf104df2b00d471da641a5e0b31ecebac1d8f668b51ddb284d36eb471fcd7"}, "2b4177df-5136-47c1-a9d1-802fb5db7586": {"doc_hash": "8ae801a324b92d54e1f1c224f3a35cb265931ce99a1b0945f7046ae64b9a971e"}, "baca0481-1f9f-4e6a-8ae3-aab998cdc2d6": {"doc_hash": "6cd403cf173937a65ee33c88d590c5d90b060582c91676b3d2dd28901534a059"}, "c862e8c6-0ac1-42ec-a7f0-d8e249bfe0ee": {"doc_hash": "82a1660f7119f511a23604ac57a3753155dcb9c8e655c23d531fa68e321d106b"}, "f88acf6b-1ee2-4bd7-8acc-e3617274792e": {"doc_hash": "975d3db250c3203ae581f0688737d5deb34cab8a189eb76dfeff6fdc1dbe10aa"}, "1b2b1f92-464f-4c7c-9d24-1c16fa34e359": {"doc_hash": "453e76896d8c05f86c36728dde2ad836654da3b07408283dd17780d5483afca9"}, "75c77758-5db0-4f99-be80-f4f6545c78f2": {"doc_hash": "ac5e1a91a184fe08e7d716a39f80a4564496afa2f04687b70a27821bb8ed9d5a"}, "0cb0f0ca-c0d0-4d8a-8158-071ed394dcec": {"doc_hash": "294a231ed821ff60b27895684ece710adf27e3fc30857bbfe8e8e2fc86d9e1ae"}, "e6c04656-69e4-4498-a122-f28d359bde54": {"doc_hash": "a9c3e135565d34c17c1d60a93b3eac9a85da9eaf78d00c1532f85fc9a25d2201"}, "da036ab2-5737-44c9-a823-dcda4355dcdb": {"doc_hash": "a59c684f4e0e72ffdbf0a15d90c281ff1ca29bccf091b445b97b684e221dbd6a"}, "0a66faa1-9327-4ebc-bd93-9a59d806cc87": {"doc_hash": "ffc28fa6fce4f6c3e3add3d792f2884339939689ba0b53da839153f651fc1059"}, "c7f361dc-6053-4813-a191-0b47bcfe60b2": {"doc_hash": "678e573981ee6d321a6bdad1e93b83fcdde04db797384c4814ee9679208b807a"}, "a4d23552-d941-4a19-8aa5-4de839c229cd": {"doc_hash": "d23c1d899a49216b4b5609c1da4bfd9b4cab27417b9aed39e3ccbf1c2ca82ab6"}, "e9820dda-d073-4cbf-af12-5692d93985f2": {"doc_hash": "d93853d0471463c5e380635b58bdfc6e94214fb4f4e821281a710547837d4787"}, "312b811b-a96c-4a63-bb2f-4ca0aab9eef6": {"doc_hash": "71dda7feea6c10fc7893ac630b60866ff44cfc07c635317bba36c3032876291d"}, "912055bf-dcd8-4f39-a9e2-eef36278b269": {"doc_hash": "5377cba7711627c46e1e90c90d7ad64c063ef0dfc71758a23b8b2e1898e938f4"}, "ed655cc9-84ac-4d60-900a-ac2543bc0aa8": {"doc_hash": "f85e3f963d32863539cacd49a6c193f964113779fe0a4496a3484e7719848214"}, "b7876235-9acd-41a8-950c-7983282c0f9d": {"doc_hash": "7e78f8fc5f7a81b071e276d6cc21bbd3b9acb9e98d1dcbd8d5ac1893e43014f2"}, "9d2fe1b7-26ab-4fc2-a838-345cc68f746f": {"doc_hash": "563e0e8eabd611821da19522b0b41686301890aef0e9e660f8b2ea2786e30b66"}, "67004150-8359-4a5f-bc63-b144d75a98e5": {"doc_hash": "89bce5303d31cea4eb9b18c490e0917b66daeec84b6d7e9527c88b6b6207d22e"}, "c2e26826-75bc-4c4e-826c-23a822e09554": {"doc_hash": "f5f632ad17bcfb8120521dab4c3e4a8b42a441ce0e6c97d44f40c640b4c17e32"}, "a59760aa-1bed-4458-a457-a1f3d52dd50f": {"doc_hash": "7b3e20d2e9236f7c658eecd43aea00ec5c1cd40bba938408b9efd557a8b542e1"}, "df1b5363-2cf9-4c33-bcdf-7ca7792ccbd3": {"doc_hash": "0a109f3db698be30daad6a56cc66f40d04c43e86a94983624cf66ffebc032fe5"}, "22fa3d72-9f23-492d-b7cc-f873051bda69": {"doc_hash": "3e77ad548e7ed5251288e0121e7dbf2208974efead76da15f5dd54281ecb2263"}, "3b88facf-a83a-4191-892b-950147b58eaf": {"doc_hash": "b5a7220ea7594fdf4db9df6cf71a3b5d6ce7f0fb144d4b23d2ecafe40045636f"}, "d0b81fb1-2dd8-4e89-aea8-c56aef7a99e0": {"doc_hash": "49512820c1d58bb3d04fb606dced93e2b42c98eddcf275c047ba39da0bfb02f5"}, "9332b2b1-965a-498a-8a52-66b04793ecad": {"doc_hash": "69384f544138c35f9165f224f85f698998ff24c4b7e2540fbf0f8d26675646fc"}, "a9f2fba3-8782-4448-8c1f-7aa1651152b0": {"doc_hash": "176ae8f215dcd7c312d25a331c48409c98920f4226d1ce5a400013bf542de75f"}, "1cb06d55-a4fd-496a-bb58-0f87d2ed8aad": {"doc_hash": "5de60cb0041c968055ff35848fdb3de9b8ebe5aa47d71f3cd1850aee6581c593"}, "5988199f-801a-4965-9cf6-6fb0a092f582": {"doc_hash": "11d81b8423e8ea1cf941d499509f1e23647f64067d254e7e3363883ddc196432"}, "cf47a9ad-a0f5-481e-8530-b0094df08148": {"doc_hash": "1372ae6e2cebfb46173270d767efd430405eaf87dcea97d6bc588a7a659af84e"}, "74579c95-b9e9-4f2a-a976-af9cd3e7ccfd": {"doc_hash": "83b42b67e981feb38ecb295c188aa50f32706568db74305ddaddc4db9abc3663"}, "a0d2cb06-36e3-4c85-ae7c-bae29f3d73de": {"doc_hash": "dbe85772ed878c62bcc4d0b2ae8c56acde20279b9200202f6ee3fe1c39117222"}, "5c845ae8-265e-4d36-bc0c-995a8653fef9": {"doc_hash": "1cf50ecdbe06d1a93726aee8a631af6c73fadcfdb6e16f17eb0ce622c5ece2c1"}, "a313f9b2-6bc9-4e46-b218-e646e9357f56": {"doc_hash": "a44a077fccbfaf0edbec937d45302dc9a0f7746102ce4e0430acf41980149ca1"}, "a22cdac0-7bd7-4822-b847-8a456dbab849": {"doc_hash": "016eca50716f24f8064efbd4de6169314d074ac5f8e5f4442ead343bc46bd57b"}, "73b28b77-810f-4f14-be49-b87e119cae14": {"doc_hash": "dc0ab1dcd27fe5831a02be85dba3ec636b4fc0657246429dc73942bf86fbe695"}, "5d5d4530-9f45-4334-8888-d5f020a9cd94": {"doc_hash": "3aa90b7a1bdcf5b4b4edc88dd2a8d4e79901470bab52a80ab81c3aecb4c4008c"}, "c690a244-8d72-4327-8a25-993256b7619a": {"doc_hash": "40c9f7177fa51aaba766c287d09b909126ece68dab62d8054a034e6c920da625"}, "94113faf-0897-45a1-9f32-6654bcb8d06b": {"doc_hash": "fe62c2f31545c055acf69d84805c7f665d69bd06976fbb3158f8daa843e50f72"}, "30599ab0-8819-4189-8395-9cc4ea87d9a8": {"doc_hash": "02c9621ab025bf88991717e668d78932aa6843159062ec08cf3d0bbd3ef478f7"}, "682a680d-048a-48d4-8778-cae71b780d30": {"doc_hash": "59be0514af2748ff628db2c5c74afa8fa19139e6d40a95e8484c987bac074eec"}, "a57f860f-4df0-42be-aa93-56ac770f3125": {"doc_hash": "573c13c5d1bdbc52224181f34ea587617e94c0043309650be1fb12beeefa57cf"}, "7bd8bf7d-d01f-466c-9b04-8f3f3709303d": {"doc_hash": "57ab3814e9dd16279a35158d5d6515b6008addf465d89ea2f61ece6c89f9a5b9"}, "6723783b-dd5f-40e7-a1dd-c814f6a2a398": {"doc_hash": "fef81ad6db5095f0baa04b7aa14ba24cb97e773c1d340738dd1d0679178d5641"}, "a072a5c8-8fc4-4f72-8437-42bfe7b23c5c": {"doc_hash": "3d8538e2bdd4469dbf032de24cedbbad4b31ad43c298678aa450901c48e76a9e"}, "d42276af-a365-477d-9e7b-4afa9d4b0b92": {"doc_hash": "620a8844f47953365a4cd3a958fb41ad82c590c5c62a962d8b88f005c1451f7c"}, "db0a5c3b-2258-460a-8f11-1dcbf09be334": {"doc_hash": "70fca6d119bfd093e0dd29183d782f1c09012b93de20f3479fd39a1dcbc1cde2"}, "2a34c7ad-8c01-4530-8524-717ddfdb4ff6": {"doc_hash": "c3e25d1e03ce3726ae8f7ceee35a102e15b005a8c90916ef60a0e038ecd76c44"}, "424bcb02-6067-4319-9d41-d35dee0572b4": {"doc_hash": "2082409f09035879b76bab95c18241f42f046ef2917df005f286ac1467c348ca"}, "41e08e14-04fa-461f-a2d3-c93fb1c8e7aa": {"doc_hash": "0317c3dd3eb1001a243e6d79f020c8586279fe4375a22c88178db252e674040c"}, "70ebc787-36ab-44cb-a12b-08a8479d9cee": {"doc_hash": "40a4facd9686811f607cbe44da52dad7b610cf0655fd2c3de5f05d896842dab2"}, "afea690d-c86d-4d12-9fd7-7e826fe9a3cd": {"doc_hash": "378efbb9fe9c8f8ffa2865164021e4e566d18588810d32cf4179491c43c254a4"}, "b7402726-19c8-492b-8bb3-a4eb0284c15c": {"doc_hash": "cd712adf26b4b6a4f1f9b691c62eb38d26b783b7fc2e044ac434dc30e9aac46a"}, "e85ff66d-99c4-4ab6-9fc0-397a00b31732": {"doc_hash": "b224468a6e6f5bd03c75b8bc8f005e6d333029af32b89e0e37ac4542b26432db"}, "8fad8fc3-5240-465d-98f8-d4e100ee4270": {"doc_hash": "3ba8ed58aa647a6db0a0f35b4ff7ac48318279ff321b0e6fa7a55c11c5ef4d6b"}, "ab8c3f47-5857-4522-812c-34df58b4d887": {"doc_hash": "04eccda608abe68533f16d07bcdaa0d9d9491c2ac01e084cf1035e9b4ae2910b"}, "a9789f59-036d-41c4-af35-da4bfc5442b5": {"doc_hash": "e8fedce318fbbee10e90f57a107f6c8704b13ae29ae4e0365419b29b8dde1bfd"}, "758120e0-e770-4d85-9ca0-689fa290cc8a": {"doc_hash": "01e0d7834fff371694eb51445a79bf96c009cf2fe5e14e7e454a8556b8f8219e"}, "c6e39892-c10e-406b-a21b-f94f1fd3a3c5": {"doc_hash": "912bc00bad16f21d73484a962d5e654d8a71033b087d68ac2b310ae5c875f74f"}, "e260a97c-200f-4e72-93b1-095e73040549": {"doc_hash": "138fcdf927f0fe28d2e38f457a580927c3e4b51e603d04e64742ac0cd1de46e4"}, "6d227109-1db4-4367-b41c-c43b1445c4d4": {"doc_hash": "81131beecc063cd37ad3d1a5ac1eafd8670ef14dba25caef526affcb3a073161"}, "7834d182-330a-4155-97d4-cc718d1d7eae": {"doc_hash": "7101743d16dab3b7f850e2e7f1f94c337a3ee41afdcf4ae5d778cb79d764519f"}, "3cf18bb8-514b-4544-80ab-abdfcf8d4c22": {"doc_hash": "354dbc2ffb74217a626a5983c3b019554c971a5c21e693929ba7fc8280d248f5"}, "0098d255-3cc0-4b7f-b60c-2f02e695193c": {"doc_hash": "0494b2157c913645b85ad6d4e2d10b555e136ff1f54ca2e18d4ee447f1140167"}, "70d92ff9-0889-49e3-96b5-9da267cb08bb": {"doc_hash": "47d2929526d44ffed5584c014ca9aa93f5e8ce66e6f3b6dc7cf439164e66d9ee"}, "541cc6cc-d795-4ee2-bff1-676ce67a141d": {"doc_hash": "eeeabe0092db2025f6c8dc60a821c59fdc823826b5efd2f65d224966e2d2a852"}, "9a78bb25-f818-47c1-aeed-738ed7d256f6": {"doc_hash": "e98b2d4cf4f892fe931e923986085e83b3c84e3a7c7f2c61be655792724e79b5"}, "2e4a2ce9-c0bc-4828-bf80-cd380c74176e": {"doc_hash": "768073762265290d5a6c191f0fb72879f1abfbf44e65ddf941a1dab75914efbe"}, "2ff9161d-1468-4a17-aa2a-946f3be5f5e7": {"doc_hash": "4b5fd59aa12d43a197e6aef1216c62d6bbb248d68079b70003626aacb88e034f"}, "80079f2f-6154-4b32-8825-57ca75e9afde": {"doc_hash": "f477f6014ec6c2cdf75f0f1c5c047791c022c0038b863ea1f8abf6170b8cf135"}, "496d8c72-6361-4d6b-b821-5a893a485128": {"doc_hash": "af42fcbdfc8a1d7cdee2c50e221973299685bc9a19d659a7a42f20b7d642ecbb"}, "6d9d513a-b2dd-4a2f-94de-3c8fc13fc6ee": {"doc_hash": "1916e79d1c06c5fd6a3c55244d794257b0c51c5fdd218c248aae0bc9227d8d7c"}, "0893545c-063f-43d2-9b81-c551f4c97047": {"doc_hash": "d5e2508af8ffbacbff1dab341719c0689859c18a4661245f590adb57a7ef7c59"}, "3448093c-6327-4996-99d6-102b01aa28c1": {"doc_hash": "dbbe72664d669df6d6e99ebc2591bf53ba45caf86439ecbd2b44206140d6a24a"}, "476e328e-dca9-4eae-92a6-624af44f730b": {"doc_hash": "0adf95b53af2e22f5e5656aa94ff285816f7d696d6a9d6c8a43e80d1df0e9fe3"}, "541192f5-0388-428e-926d-c25ee09034a0": {"doc_hash": "e227e5ef28e210110d98652038e9ec6a5e8d232d25add2c562376f64d2cfeef8"}, "be45e8f7-287f-4624-8693-1b8eb6dfe9ec": {"doc_hash": "e1b6113115b24bd2445045bfddf3ea4e6175b44a531d82a50cb42323b6965fbb"}, "562ccd3b-795d-4cab-9f30-efae14def32f": {"doc_hash": "9f5bf2d9281dd1ffcb0e258437120097fff70ef202808c5f2dd3f76632cfc33a"}, "2a7cddfa-560e-45e9-bd12-c2aa0a9e37e5": {"doc_hash": "50259f4e960197bbef6480fa2253606bd93ddd29b81c02ce806220713c8b44dd"}, "4e4e7696-72a8-4b35-9358-1343f0b1c2ed": {"doc_hash": "00b6c7ecaaf0fef1a9b5c981cc7a95ba1b67172477c534992014462a5f080a35"}, "6c8a07cc-b73a-44fd-ad91-3e9acff195d6": {"doc_hash": "7e7190c0d147c5fb2579fffe81c4286a9770d6e34c659246778cb7a6330b9eca"}, "c305562a-a177-4a64-b091-b9893b12e7c7": {"doc_hash": "6009368b31f5972c15433074fbd1c4fc52a0b7f31c51b523ea350a4ae4009e11"}, "25c1ae24-c5c9-4cc5-a99a-bbe2c6ad066a": {"doc_hash": "19748e5d87e44a253141be39bce2d1eaedcfa5d19b7d575ead1110ff28ab8144"}, "cfaec396-f598-4dfb-ad0b-4360dc65c4e7": {"doc_hash": "2c8ffa393a41cb19ae8682cdc086ce53f2d2b40d0a1757568f3b816b595caa12"}, "1212efff-8b75-4576-8b17-c0c60d3aba8a": {"doc_hash": "cb50ca971d8c789fec7205fa38437ad6664d889ae9a21820381828d1e474471f"}, "1c0a0333-4b6f-4ecd-9494-ec5e1c3a9a9f": {"doc_hash": "12439c172a860b545251537ebd39d13df14b10c124519e25e50f4bca6a11fe0c"}, "5a167dfc-8da4-4ab5-8550-9d9c54823aa7": {"doc_hash": "6373066f1bd245e69fb95da0a34ac9ac819989852878938af75f5ab2a325e3cb"}, "7d25e0f9-7a4d-49aa-aca7-a857821a0e34": {"doc_hash": "139374664208f1c1b130013d874bd38d7add99c146d5ec0474b57dae0b01748b"}, "415d9c3a-5d44-41ca-bb6d-04ff70f83c4c": {"doc_hash": "38d12cb7751919122e0b38f572336fa7dd3866e9025fd0261339f50cf59b7384"}, "82007428-c9bb-4f94-b8a7-282102e19199": {"doc_hash": "55cb0819b1a1103de094b463f69950cdcfdebef2686dc016900353ab0ca309b7"}, "70c808f9-c25b-4c0b-9474-3ba19375040c": {"doc_hash": "ecff028c0048759d26e2e9feab7ed95ded39feb87ad6ce19fcec6a14619cf010"}, "89453cfd-9157-4090-9f74-91ee81e132e4": {"doc_hash": "8c9134cfc64cd538b4177325549117548fbdb418b1d0e48490249e0778989b18"}, "6a6175a6-ef3b-4fc7-a0ed-d1f549557493": {"doc_hash": "97ade81f28ac0a2f6a33b00df8e586cced3a01c21ca8b870411036c7d6188f90"}, "47c1b622-256f-46df-ba92-7129b00109b6": {"doc_hash": "69ed32b601b4d1a1e023cd4d8a54056784300ff1795ad521f0d5ae9cdc4ad1e2"}, "0ec9b492-9ff8-483a-8ff4-94e2785bcf85": {"doc_hash": "2d40d48c088bb3f3b37c219e13b96cd1cf3f7d4af5863dc089914620a6055381"}, "22283e06-18b7-4678-886d-d07291bff80b": {"doc_hash": "d8795b1cbca9d06580c8197ff278e34f82ec1ef749d44e52a3aaf3beed2f14f7"}, "18ef4fdb-1970-481d-8d55-74f75accde8c": {"doc_hash": "710cc4e69b9caf3164375f50b517e61a51d6708e3ad031bdbb885ee7cb8908f7"}, "f7e7b774-111b-452a-a812-0e820b3fd651": {"doc_hash": "9908c0cb573cc2152b68ae0d732d521d6355f8c540ebb237aa1bf2596e8fc715"}, "fd4e72a8-a1e2-4a3e-a821-b896a92a3fbb": {"doc_hash": "31a1ad10b5e67a5520326cca9be51b2f8842dcb9d9d15fa2d3e32688f1f0344e"}, "bdfe6449-eae2-4f07-ac55-4bbb34ad4224": {"doc_hash": "37a923cef562a21ba0b414eee908e26efa48196d9ebad1214c18332892f36269"}, "701f12d9-8cfd-4dd5-81e4-4f94e93a3c6d": {"doc_hash": "777c8d6bbf74cfb79339ee2e96551645beb64843e2ac0c9c94545ad047f428f2"}, "54c76691-f270-41f7-8d50-b8367fb52902": {"doc_hash": "8acab53b15d76a1b433897faf0eaa44388e212d310a3448d2f9f6eb270e2bc20"}, "f88163e5-65fb-40ce-90ed-fb2ea2cbc5fb": {"doc_hash": "465ffbd0b248330c1ace16e8c3648010f3032207a38dd0486336a1ec5443573a"}, "bc68ceb6-55c2-4100-b8eb-1b06b3ced4f5": {"doc_hash": "0079b55403842ae74888f3fb94e635b47ed431a84212151fe129815dd97f6af0"}, "60690e63-973a-4d9b-80ab-3658fa56eabc": {"doc_hash": "f0c2f70d39f9705bae971548807b5546a3ce2870b85b3000347bc12715590ddf"}, "7c92a40b-749f-4220-aa2a-456cbcc16922": {"doc_hash": "4e4a49cf81d31da5e9ced8feb3e980cf4006dba3dbdbe7c8173649e08d7d9f50"}, "0f96876f-ba61-4a33-a309-06399c8eee17": {"doc_hash": "1d8fe19acb2b4b2189b2107d7ec33f81857df77fe26dfec10879fd8858e526b2"}, "66dd6657-7c1e-4ed7-9c1f-1ea7e2c6e4c0": {"doc_hash": "ef02dbdc2b16d03ff6b9223055930857c3f05f82a2b805348be1ff8353e61a83"}, "029f66e3-9a64-4565-8628-06604c6c38c5": {"doc_hash": "95ebff3f5eb6b7aadbcc35623b86ede01d7bda8061a0cd10549154eeb41261b8"}, "7bf45709-be08-423a-8210-c807bc32be2f": {"doc_hash": "0bf42427bd7cd8693f16704d9d7b0465a444802ebf9eec20ff0a58bfc9e9f29a"}, "0a19c473-2bb9-4bb7-b819-42880281c30a": {"doc_hash": "acacdfb0d88f70809518aeefdaf4bcf5862a5ceca9eac3930c119c2e1bd68a6a"}, "46f24e46-b7b7-472e-99d9-ebb7ed92c898": {"doc_hash": "550fea750737558d7cf194eca9273212dd4b80dd992ca321098e6052b531fc92"}, "a8bd8d56-4e6a-48dc-98ef-4e8a0175a2d1": {"doc_hash": "e2ae89cf7afd52a7b48dd16d63a9b6cfe93b409fd8f656da7c9a05e37df69e8b"}, "48283385-c28d-4960-8952-e984b2ad89dd": {"doc_hash": "8d4169a1a80d1d2681beff1627cec36968a37e37a7223f4de6e4d1633e3718bd"}, "93f20904-079c-402b-9784-c1c2d041feaa": {"doc_hash": "239fc46289a0ae372db43095e141c0f19165af0f784ac034d6b89c8bd86a376d"}, "093d3b27-11ab-45d7-831a-f68b76e944f5": {"doc_hash": "44d0e53855841383e6fa549a1172a00bf85cba3981f532d7bc8f08f7664d5b9e"}, "8217fdb0-8046-41a6-9d53-0364989c7076": {"doc_hash": "f198dfe03791f796d02705402ff8aee3f88fb160e7f56fcb6302885e396ad7ae"}, "97046f3a-f31b-41aa-9144-102757848f19": {"doc_hash": "b7adb80859fa8d569c9b4921b880797260a4b2bd91e6760607dfb3abb9aa4a0d"}, "a2bb940d-dbd3-439b-a08e-8652dbe38ffd": {"doc_hash": "8566c0ab0572b6de2262aec39bb09d370397833fd3dcb21eddc516230f12a209"}, "19b5bf85-6e1b-49f5-83d6-3ffadbae0ad1": {"doc_hash": "635110caee72e7f32716d28fa76afcc7cf1b91cb4233262ea0e9ab7f8f8702fb"}, "57854cd6-c4b9-468c-9d6a-c6413646bfb2": {"doc_hash": "3e9fe489fccabe8e61d714a9b5a402cb9132076dd66c09a0832061b6fbe3bdce"}, "2923f0c6-861d-4ce7-b0d5-d0e9218546fc": {"doc_hash": "0808a505f81dd5850acd8dba5cf7bbd7d65a0c9d13be2deeee36128c6e0e8eb7"}, "abc72242-8a0e-44b1-9a57-07336ce970c0": {"doc_hash": "83698abf172585eea9463185c42c28765c5c1fe2165d12c8836818dd8ecb4cce"}, "95990c9d-b7f3-4f76-b347-9db57205d2b2": {"doc_hash": "17e98ae240990a2ffd95b5dafedb4a2bfe76510b831ff80f0cab1e63ce135819"}, "5bc1c6f9-3622-436d-9fce-b879a860f4a4": {"doc_hash": "5d989181d2168ef71dd5de0d11cf01ed03c180d88770f688626fcbcf3274867a"}, "f4ef81c2-9b05-4f10-8e89-77e6c59ad74e": {"doc_hash": "2ea728f4dde3fa1a57f4b2fb6fd1c1c88466fdd05026ba18ca091bfd363c614b"}, "38b2bc5f-6107-48c5-9abf-3e207d112c19": {"doc_hash": "e88de3ff5e32dbfb3ff8b39c98096808b0b479ae27e5001a3513f0642e28c1e0"}, "79749186-56a1-458e-8206-56eceece27a6": {"doc_hash": "8bcb9278e61e24651bf2cffc37984bd87741ec7de50006e5fcbdc428964eba30"}, "20e23f9c-25a1-43cd-944d-5f2cd5d2c9dd": {"doc_hash": "d990e7515731a10d5457235993c90390fd1f77e98e7fa4b2348ff44d1af5c0bc"}, "6af50f47-0e94-4fa8-a380-1f85f00a7cec": {"doc_hash": "648f9c3a3ab964536e088a5ec8a76c0dfc48e10ed9175100c4f3498fbcd4953e"}, "566e6c97-202b-429f-b6b9-74da4ea70483": {"doc_hash": "a6238d86db7969a328ebdccd2181fbb688f34281dfc42c6db570447d015814d6"}, "9cc31a30-f666-4eed-8745-b1314b348632": {"doc_hash": "6a81893796962efec39b2dbced485ba1d4554648364bd3f3597867aa458e6727"}, "209b3d4a-23ec-4e3c-9f22-67450e00dd5d": {"doc_hash": "06f081827f72489e155d445c8ac695725f47a1ff7eb13433ac6bf38af6bf4a10"}, "69cfc77f-e887-4033-85ac-83a15e173791": {"doc_hash": "d2d5b8975a115a5a61dd1ebe6573d184e2548212e5ff470dc4b4044182ad2dbb"}, "e308e76c-a428-45d6-8367-b5cfd8ff0c96": {"doc_hash": "af201021ed9dd37019ba3a4c1bf2ddf31d1e1a6b37da637f7f2dfad7fdc3d2f4"}, "5691ceb5-2e3b-44d9-a5bf-6cdd8d6a6730": {"doc_hash": "f253176cf3d6f90e121de32f09e58c738224fdc39a15b675ddb53d58a0c74860"}, "c60ced93-4d86-485f-8dad-5bb39e79b1b7": {"doc_hash": "c3e8f02f640d9989262c38520896a9b6c224c1e12d6ebc623ce2546b075ac001"}, "0d46923b-91aa-4910-9546-bba412e3be4b": {"doc_hash": "3f1eab121acd98f934d57b17df6277c874d64f6b549d9dddf62238f8461bf7e6"}, "0ad9a354-f821-40f0-9eb3-da2381e3aaf1": {"doc_hash": "495a0b20d62ac2ef650afac88d85ef21882614a0f1e6558f00368ba64508feb8"}, "d89866f8-a218-484b-a7c8-7cd464db4727": {"doc_hash": "da484f3f3e2d3b9ca6024c06766015146289dd1b8288ac9d83c9062f7a98524a"}, "c99a48cd-4f68-42b4-b37b-602cdad9f878": {"doc_hash": "abb6ad1bc99831390e0b2d0845771a27c6968ae29297138f6d6a17851ccaa1cf"}, "d984b954-3e42-48aa-85be-b89a079c9950": {"doc_hash": "d3e53532c466f36500327706286fbf47a7e72ac59fb2f37921fac7889f4e21fc"}, "126a91e8-d4ea-4828-b7e4-7e19ee30a263": {"doc_hash": "c30af52c661440d739ee5f8c8591839e447d580c97d547c8c5aff34cdaf206af"}, "38ae37e7-0a78-495c-944f-b8ce44169678": {"doc_hash": "d53291c5c4a2c01852c2aad383acceaff29d855b579d16f80fc939988e4a7ef5"}, "299a5c5e-8ddf-40d3-a5b5-008163fa92c8": {"doc_hash": "ffd3ff6981acde88bf4c487bbde88747856dd16c3a1e9771c7761d0558d7c33a"}, "6d46c645-fdaa-4da6-9841-897de9859677": {"doc_hash": "0273c7b6abd2daa2d1e93207b5b040f6c5d03bfc8a11fb303678c61e1521e523"}, "73345b68-6741-4278-8537-c7920f963797": {"doc_hash": "ab30e2dee0a22ed1e859f06dabd001de73e5e0419c08ce346e4708a6630c4036"}, "c3423cc3-a14a-4281-9220-c4efa6a9a751": {"doc_hash": "2aa9ebdf7ba035718b226569430eaa964b0be245cceebc45608133292d5e1bbf"}, "e0da86f9-d39d-4b5c-9183-73170d372ff6": {"doc_hash": "427cc54a7cbe87adade5355f18a00fabca454618d64dd81fa0ea73676e6f097c"}, "6bbe1c81-d960-4a06-86bc-bb5049d1a4b9": {"doc_hash": "d36cb5cd2411c429f9bdbe1dc4f966f4176223c7dd5cc9d90a95a7468b4c5209"}, "72e4c9a5-fae7-4bae-8713-9493c1351f48": {"doc_hash": "34545c8918a72271ed2076b3671708d59a034811d4a2ad9c2662732ca40c60ba"}, "545d9a93-adf3-442e-8290-eab87eff28bd": {"doc_hash": "5978969a7ef2c9f1041fbad9499ec2207437553f8fd603753d961f520b007424"}, "5d5cd856-6cb5-4895-aed2-f45453fc5a6f": {"doc_hash": "becbfba897e9bde7658bef509e6471dfddc94be0d9883f12b46e52d2376d64e5"}, "cd5a65d1-ae7b-4b5b-9516-95f8edeac4e4": {"doc_hash": "a7aed0d87214d70b85345f8035d993af6e8dfb24e6ad7fa6af107b8e7dd5f294"}, "7f713e36-c731-497c-a4df-399052e5a916": {"doc_hash": "bf3a48ea73de86a3024e0e5117f868327fb50ca6b63a3b78463fdf73d3381a40"}, "b8d7710e-0499-4372-9806-39b78584a36f": {"doc_hash": "3bce52b13d706bbb8f2015a958e5bc680070f6e61a03da366cc66a9d30574acf"}, "8b8670c3-8a78-4629-811c-2da6f95a09b7": {"doc_hash": "5f4537920cfb33190e204eaa3524a39d9b5fc9bf3399e78ad9a7f28d2932b973"}, "5d3d18de-8f40-48ce-b6a5-cdddc3e676c7": {"doc_hash": "eab24a04e734c1243c186819f029fae6c5a2ff11b3d1cfee1dc5c953e38c82fd"}, "0d97bbcc-292f-4730-865c-eb8ab986d5f9": {"doc_hash": "5b97f552a5ebc28b9be5c88e0bb8cc06a41f8dcb97a590dddeff560615fd9f4d"}, "c4a06991-1558-4572-9922-3598d3d4c6cb": {"doc_hash": "9510688b0b8edf08f7d255c58f72cc688114d2510fee8d4aa0e1467130270168"}, "827b5ff6-f395-49d5-9292-75f5f93517f1": {"doc_hash": "04dc41319935bbfb283f255950fad5cd2791ae0d76e2f20de4e1aa929a7d4940"}, "59f776ba-1f3b-499f-9681-4d1d7f2c6b77": {"doc_hash": "8c9a00379ce4ca1e5e86ea633da645a3316781d861bfe1c7f2c635062d750c50"}, "c3e0600d-38a2-4c7d-a118-e62221d603c8": {"doc_hash": "8ceb7a9a1e3de799e8370987f16ab43098facf6b89047695430ce8ad9f527685"}, "1e576e40-ff8e-439e-a7eb-53a8932d4f64": {"doc_hash": "70d61ea24ff130d565bd0892373847d1008518fcb01d3abaad30886940310ab4"}, "9672ebcb-dfe8-486c-af7a-3a0ff4c5a94f": {"doc_hash": "49e83a8223a55491283fd19140d2a5134c2eed2b77127572745106187749ae55"}, "ecaa4fae-b4d9-4cc0-8621-3b650661a078": {"doc_hash": "21f9a7a306562fdf29d819e539f0d07d1ec115a9a71224d9b68157cc1d2fe6f9"}, "aaf28708-06d6-4be0-b118-e2156134aa9e": {"doc_hash": "626037e933bab7fa0597be49c6b14967b8907fecb8292e28d7a2b31e2a0afdff"}, "b0ce2b34-3d08-4b41-ba76-6b5161df15b8": {"doc_hash": "0744b73633b187cd375791268b9e1dfe1efb9194abf9bbe7ab22170a3066cc57"}, "219762ca-7a5f-484a-90d3-1ca926f93e6b": {"doc_hash": "1e0ff10eccf962463cfcd2775681ab04106d141f84585d5f7e0a9a3371b73d64"}, "11b436fd-c937-472d-9d72-cf7e5cb98311": {"doc_hash": "b26d44b2b6f090becaa65958b56e3b2bf31ff45b4773cd7d0faa3ff886a63e43"}, "22480b80-5645-4fdb-875b-1cdbf1a7e6f8": {"doc_hash": "3890010a8dbfe83fd1ec8499cabbd41f4ac282c5e4cc7f1ed04cc261531366a8"}, "115b6a8d-ac5e-4d72-bdb2-1d3890429963": {"doc_hash": "5d6b7b36379da61c93ca06350e7def33cd044e3158281a9b72070108971d09d8"}, "f6870ec9-720c-437d-95db-1142d778d376": {"doc_hash": "029fc6084176d0dea953dd6206bc758ad22a17a75ffd49cfbb3c04aaf4e69241"}, "11516d1a-cd40-4b79-aed8-9e36a487984b": {"doc_hash": "a3236519020e6c5f4e89f97a8a05edfaef21751583dc04fcee1631b157c6dc4c"}, "5da56061-7054-4b2c-809a-a73c3297a218": {"doc_hash": "7b9d6e2b30de9297e6d37e1021ac29be95d610df1cbe8fbaa71dd0b91ebb4d2a"}, "76ba1bd9-2a17-4903-b90f-b17e28c7030c": {"doc_hash": "07c46d8c85ea769cacdc40394eb3237835a2581bbf700fe7341c75599445c242"}, "bd4074ed-1670-4ce5-8d2b-ec5452240c98": {"doc_hash": "7c41405027c0587c4bebf1d5036034654e89e00f7847ef357b77ec6c099ced59"}, "9612aa85-3bf6-4dda-abcb-7702e75b17cf": {"doc_hash": "6cce3eb53672bf7ba51c34cdec6740f954a2ad8ef067314d3c85c6d2ab11a461"}, "8cceb003-3862-4c3b-b211-1d4347328ed6": {"doc_hash": "2fbce9fe9da2e9a2e87160342401bf87fa6c0d87b6a8aebbd4c6efdc07df2f05"}, "20e90c1f-df2d-4b82-b2e4-2467fe9cfbaa": {"doc_hash": "6f45e831d668571d46d3bb50a46ebeb2f762e201498e9ed9199d3cb79cc08cfb"}, "b7b5769d-f51a-451a-a979-6a919ad90171": {"doc_hash": "1a197b90cdc3e65f874deb88333ebbb51237c39f4cdaa7900454db11a69ffe2b"}, "b4057fa5-dc97-4d60-acb2-14d4f86ac475": {"doc_hash": "08f0f3b7e619d97dc8c6ba0c70ff4fac7cedb2011441ea94348abfcd31f5ab59"}, "4da1ef5c-84cf-46ef-8fea-86d31d5ac5df": {"doc_hash": "aee34b6b8f372c36d355acca784d29a71c7b9a3b9352fe06caabde5912dba886"}, "5dbccfce-7e9a-4e60-8b9a-9bcf9b0ef73c": {"doc_hash": "8fb559f08fde56af317bd04c0bca462aeb639f96d6ab245fb029f2c8af33ecb2"}, "d2e55835-7d0c-4be8-8f00-5e765743ca8e": {"doc_hash": "6ff181394eb1c89ec34ee3ee7fd04c4ad59fb72fcdd37f9810a868f02febc806"}, "9c1d5bd4-f21a-4832-a1a0-67bcfda576bf": {"doc_hash": "63daa02d578c55a5a941e013a0805d7c244499b35b216ac7e2624fe5271cfd02"}, "c43bcf01-2bd1-4c22-9ebf-74f46ac0f91e": {"doc_hash": "e23e55a24ce74e962126e8f415508ffe25764f6aa4547897c65cc7e30675c7b1"}, "a944ee64-2904-4841-a43d-196e590f2792": {"doc_hash": "ed60d87bbda73cdb1781633b72d57c4c4699e142034cf338c22daf672b49903f"}, "248f0479-4a06-4e9a-972c-d0205e2df956": {"doc_hash": "3b83a7bd5fe8a140e22a109bdda6691487edccf7a3c3efe36058a4137fca15e6"}, "556f31d9-9cdd-40a8-bf87-da8068cd9695": {"doc_hash": "4215484413e0a0a2dd8eac302bc8bf63472a634cb3c9edfd09ddc86309681a92"}, "409f5922-38da-4c2f-a88b-98c877882b39": {"doc_hash": "37621a7f91b81a0bc8c9fbf1cf25524674d53a2cf886477e6ab370f19baa3d5d"}, "5932e59c-e582-4605-a425-ed388e650145": {"doc_hash": "06fb6e84d642fa2611aaacd4cef79675271cff84842a7225ee3d37706ddd4df7"}, "812c5ac3-184d-4bf2-817d-243b9493c6b9": {"doc_hash": "ac23bcb10437e7756ef131e80fa9d81e4b1d84af29bcdc82144f7b6b828622c8"}, "ff884cde-19af-46c7-8573-45ffe6430d74": {"doc_hash": "17dcd0ab1276283a55dfe311416712a335af2d735ecc21241fa03fc822956e08"}, "8b9f12dc-9d81-48b8-acf6-ce3168fb8498": {"doc_hash": "4d123f97da374af99c264d79af7e9a26226aa164dd55a66ea0b2b5103b0da839"}, "cf1a7251-aff1-499d-851c-bd2588abf6f2": {"doc_hash": "89029140ce33d25ce35a6a3dc9f61414fa34f8c1aa0c9c1270408cd05f5e8c95"}, "b379d463-bd9f-4646-bd6d-4b7f317fafea": {"doc_hash": "99383c96d03e3b42bf8e9fd432ca6d3005d4499afac33a5fb5449a2f254e45ee"}, "6b7c1e5f-5a5e-46ac-8cca-6b398ccbecb8": {"doc_hash": "c0280836676570f0b39cb5ce685d8d5ee7d539454dba33c81d81990312843f45"}, "129fd2b5-7303-4ef2-8e88-4023188b95f1": {"doc_hash": "8c2528640a3e7aa7a34998cd76effd3a5ff8aaf7bcdb87ed45256c41042572ec"}, "60578cc4-704c-4ca6-8f55-4bf201db7097": {"doc_hash": "6c63663d921be7d0fe995b035dcaa4973fc12cf6855a7057e699a03bbb2cb594"}, "e99503c1-6258-418f-b37c-33300194f0ff": {"doc_hash": "16a20afc4d270ee92380d3d77fb11094cb431fe1059e596f6acb519bdedbb775"}, "53759cbd-2dda-443a-850f-7bff5abcaa6b": {"doc_hash": "0eb24819bf0d6505a44cec386bc9ff4552df0fd4c716bd0f3dc575808fe5399f"}, "49e40527-d8ee-4e4e-9f4d-035ab994fbee": {"doc_hash": "c468848e1fbf3dc0a6d581583cb38a9084cace744d230a924a99c7acec17ca8e"}, "f96b1224-440e-43e3-86db-02b1b2094b19": {"doc_hash": "0bcf2ec9a451febb24e6ef132c04755fc74256b7645adfcdcfa3843c09d45db3"}, "b1a31f8f-4b84-46d5-b006-8f268500012d": {"doc_hash": "5a8ced200a8b0694d5608d34f10495e8498fabe7554f81e9e31122816d20232f"}, "a893787f-f92f-4e73-8329-9e632c9b992c": {"doc_hash": "9a054b34c9cbcd72d618672438e6f65ca565f34e9b4859e52f5f52848bddd1b4"}, "1471d869-01b7-4e61-b385-d176f1aeaaae": {"doc_hash": "285895afd5b033b94a2befb364505d1edc92f37fa65fb59d6ed7f959d10524c5"}, "dcf44d07-ee10-4727-8a40-887ea679802e": {"doc_hash": "fdfb9e58a8916d9cb35f1b886e924c41335b37e62b663bb762bb02648e6d2c39"}, "df9867de-8d7a-4f4c-991f-baa6e6371e16": {"doc_hash": "e7c6c3d25fa595e6ec5f6b67990b27a796daa4e0db32e1f3691d8c2b606534ab"}, "2b9784d4-7b3d-47cc-868e-78d8cc839596": {"doc_hash": "29df6bb31a7e1c73d8a6b43d31b30561d106e95ae7e1333d4da833286f0a093d"}, "f65596f9-f47e-4cf1-a8e2-f0a40e4ac25a": {"doc_hash": "53d155aa036b160627aeb2f2f4401939f083046fa2c4262a50e27f77797edef1"}, "ecd771e5-136b-436b-beaa-c3a8cb5ec32e": {"doc_hash": "3f932ceda974ccdd8d1fca305101f6182d9dfa44e9f9810c1babd786e18bd011"}, "1f199d48-f5be-43c1-95a9-2e5ff06e1c33": {"doc_hash": "1c2375d50a863919d92f3f6a8bc7d202295ab91b8cdfa8d7935d772019f2697d"}, "4014b4ef-b022-48df-87a8-99dc4457d400": {"doc_hash": "7c7203d17dee06709a9b96d4ee68714ff9ea477d78f1e833a5b3d1fdf759726d"}, "55453d2a-be54-4259-926b-e13d941f7f63": {"doc_hash": "2ff54d8e6909342bbcced7317706f617e4cce3af969eea00ac91811a420f274c"}, "5b261188-8ad8-41ab-b827-541dfaf2b0c8": {"doc_hash": "246c23a9b62d10ff6cb163f35a94c62ce5c8aa5c3b1ecfc4e5a2611eaeabc0f8"}, "ce2db4ea-900e-444f-9e10-a50d0c799362": {"doc_hash": "d26b839f1450e5f43c29fddbeec4803e114cbbddee93883c78c9b676def930b9"}, "fb1336ce-f866-4763-9845-80450b88bff2": {"doc_hash": "7180ca4b5f746e891e10e2e16e06d6a0849a7560102082296a61962f994001b7"}, "71fa8a5f-ce00-48c8-b413-b598a721c697": {"doc_hash": "695bf9486b9677bee166f013e008d62a78ac9fe29cc3973b22db55a006173fbf"}, "ebca192e-3d6c-4242-b273-79c7d148ae4a": {"doc_hash": "7e3361f12a2077b9a3743ba5630bdec65f16cb38bb63d5e3dcbbbe310628d48e"}, "06cd562f-d684-40b3-82dc-2b060aa5a408": {"doc_hash": "db4f7b175643c65fa615a9b8c24eb3ef841b3cc3dbb21cff2778966468def798"}, "a8e78090-d76e-4018-ad44-c6eabd808186": {"doc_hash": "da81998546eddfb7c65220b0814622b040e1f380984fa4cd6cd2e53c5712e238"}, "da92c9c6-cd83-4c94-bc2f-5357b56f70ea": {"doc_hash": "616eba615b9e6fd92fbcbefa85e5a07131bf7687b6bcc3338689e1650fd04e3e"}, "21fce722-6ee1-4f45-b562-4d63c2c7ea2b": {"doc_hash": "0cd84e90b0c77891f10917f899834d4106d1346901583745a57d2b67134d8f0e"}, "1977f293-ae63-43de-9303-a53039269190": {"doc_hash": "1f48cd3730214648baf24aa0a8930a31c64a846432cc8743aee98eabc37c74fd"}, "6f81abfc-cbc2-4a0a-a9d4-d0a924372457": {"doc_hash": "b76707769e21ed090c6388be9527c61757e5765893b0d2439a93e71b09d69019"}, "95dc9d08-7ec6-407d-82c9-a0de285dc48d": {"doc_hash": "f381870ccaeac5c199dd46f759bbb97334695264249ddc83e3cbac288fa399f4"}, "9c620293-22e4-46a0-b215-fa20fb929542": {"doc_hash": "a8d4d81f800d4240b0f320a7ac25a51453f617028af624d572da7aff2299e8ca"}, "b232ce0d-fc44-44cc-acb2-e4b51841f290": {"doc_hash": "45facab2ceaca36ab6347dbb1567836485d3ed7927db4bc0fe7c7c9403d566d4"}, "c6752815-236e-4a24-bf8a-b881af2b4106": {"doc_hash": "47436f5823daa52143376c06bdcac56c8c3c133c933e292719575f0a12e46ad0"}, "93077e6d-0807-4f30-8372-d631d59f1251": {"doc_hash": "c825bf8cd7ac42d582e580b7fb2db4e80900aa8a988a9d84a01efb399090566f"}, "c520cb25-2157-4332-b8d8-7764e565eb07": {"doc_hash": "ce3bd6e60f3d3e70955d944be638464d9af8447fe8388120d65929a4c866d0b7"}, "bb53949d-4ddb-4384-a1e6-eefbb628acf1": {"doc_hash": "a45a4fbbfefeff83563266d02cea2d7e56c4f951ae1d943abbdec595808c59f4"}, "cb3ab435-cd83-45af-bf99-b2b22de2638d": {"doc_hash": "fdda4895be2aeddb15c60f5c4c24dc138b20a633635d014b699f855d8838841c"}, "484996ef-8748-415e-a429-4cccfd7ee5bb": {"doc_hash": "342bba3de1047640ebd411bf0ca38575bf9b9a93aa6a57f71b83b02da448273d"}, "1f45241e-f900-447a-8f75-78b81115075b": {"doc_hash": "87b8fcd6ddbb10f8dbd359825bec7d6e72647dd0585ac9a810d3b254d671b27f"}, "1d31a4f9-34ad-4f47-814e-7a2020d31637": {"doc_hash": "614ea89403e99310b543ccf9676755e0de8719310ed99c7e02e1557a333feb06"}, "69ccd261-28dd-48b0-8fa6-66338bbfd9ae": {"doc_hash": "b119e434443f57a59879e293cd7eaef9eabc47246d26a570f33441da78317f3e"}, "8695c84e-c92f-414b-ae33-8981af4f2769": {"doc_hash": "ad20db7c2049148b57cd6b73e2ea5b9c2f43e46998a88af7cf3e19e2f7967f4d"}, "e98cd12f-077b-4574-9203-27a5c9d890b2": {"doc_hash": "7435d173c61a74e32daea39054a4c8aab70fd80ee7371e0a08fe314e8ddd66a1"}, "1cb74a30-b7ea-4fd2-92cf-c3642eaf6d4b": {"doc_hash": "f4c105d9bd3196745ab575e209f22e6d12d6f7f9804525ba571b830c17c8f81b"}, "dd98e63c-8594-496c-80c0-7420cbc7bdcf": {"doc_hash": "145bafda228c77b6a2b04681c5beffa1556b222f9182621c18509203d3312270"}, "8cda39b2-223a-4407-9371-cf8bca6abc30": {"doc_hash": "e8af63e92fa4c8259f748db331d06d4641ee729cf8fe2f654f204aa4f7bf4b45"}, "e0302406-d5a4-4f74-86a3-29f2dad630ca": {"doc_hash": "855995e8ff778357476142d3882476cb3078299d67b2f9c7bb6d681765cdf889"}, "1e3c7aad-3d88-4727-973d-da4a9336e256": {"doc_hash": "aa12f17397c45334a50c76e5c1d4d60b3e0b8b8f246116f4c56ddadb02d57293"}, "79bec56c-18ff-42f5-b02a-4bb31fc7d7b0": {"doc_hash": "538d08e7d646127696fc302db6b15411b1dfc639bc17015f9b6ea456cd90aab8"}, "8972270e-9951-4658-a166-da16910bf9f9": {"doc_hash": "9626e270d0e6c259c371b050655334a7c445888931f65b5fd7285b37151389fe"}, "6ab4a37c-63d6-465f-b705-125540012e29": {"doc_hash": "1ee8812a75e4c39b17b46ed4d262c36c2e552048d683cd9c558c16079accb9b1"}, "00ab1247-1fc9-412a-8864-f894db4cee60": {"doc_hash": "0825c9774d91f51f1bf15a8280608fa7cc99c7fb2016d76118d617a338bccc91"}, "f899621d-48f3-4348-8b03-cf8a57f88ac4": {"doc_hash": "949e29c3ad3b0064f74c3a02d5bda22738fb51074804be0bc99c51a226693b71"}, "39c53241-670b-470d-9663-1cc2e9a446a2": {"doc_hash": "6059a2ac629f6d3f4f53ddc9da1be946dddf91602bccdfb92449487694a03b1c"}, "9dda46c4-158b-40e2-a359-358aaf944998": {"doc_hash": "864c8ffed052954c0ac1b6e3e3930404df73371826a81e8cf3b1132000c22375"}, "1335ac7c-95c0-4974-9e7c-56f962ccd283": {"doc_hash": "fb639f112dc95d8c8e939d54cb597c72613eb3f5dc5116bc0b47d23f50da3476"}, "cd0815d8-60a3-4b90-9540-74c3aee760ce": {"doc_hash": "3bd92de63c3ae7b16b69fc392877665c3beb13a788bcfa9da40b7995603334dc"}, "0570143b-4e01-48a8-9ca0-2ed3792f94f8": {"doc_hash": "718fb2cb0bb029aec780d87c8c50558f6eb7e62f0fb91d381c4747019432a163"}, "65ca127f-71f3-4319-87b1-8da9e31bacc1": {"doc_hash": "b934f75098cbb824bf986457c5fd7df09f4272e572f53606e4c7bbc991d9b816"}, "ba5f5581-45e1-4e88-bb52-010cda0b51db": {"doc_hash": "b1ecb72afe29c6684d21c5f1f0fa2c20876ffe1e36ade57bc0679e1bb2e475e0"}, "ff2f6b08-6786-45ed-8ba5-5e785d8bd983": {"doc_hash": "93296df5cce3622ea37bdaf4fcfef2a27322ea3925748a8489c61538cb82f0e3"}, "dbab1c37-6730-4eb5-8908-996d74f384e9": {"doc_hash": "f1ed962a0cc798ad88bfd623955c30b0d2d7b5adba5ffc3bda1ebc71d5a55255"}, "92bc9c97-9de1-4eb2-9085-8eb0bc067dad": {"doc_hash": "e4964c00ccb3f48545d429dce64b2ce74f51ea6f4381539b8e528d6e33dd40cc"}, "128fd52d-8ca7-4947-ae3a-7338655ed629": {"doc_hash": "d2e8a1ec06f12934df3f5d264f1cab8cc16c0f00e8de33c766e35f0700cc9df4"}, "e592555c-7050-4b19-9575-673751940dea": {"doc_hash": "a35bfed1d558f4d885305dc8233d759835a85757586da68345574a63144866cf"}, "5d8b3960-4cfe-4603-b4bb-c8300dc4ade3": {"doc_hash": "33a3180d0be65cc52384acc0a25b9a74476edf3ed22ae83c5074390d45a9e2ab"}, "3596891d-49a8-4354-8885-be0a0c8488c4": {"doc_hash": "6fc284e1900717efccd5585a583340fd309c6c71a918299b18be94223ad973cb"}, "7d5ebe42-eb79-4105-86fa-a76c3891255b": {"doc_hash": "8bf66fa3e1678337a1721282aac400bef748acf0641c75f9c6d6ae7e297afe73"}, "aa1d26ec-6575-4993-98ed-8df0383ac560": {"doc_hash": "23a39aec5c0ded5ac9a3fb4724d9cfff48edaf719de7d62492610c47b0ce74ac"}, "2896f16f-0864-4db6-9995-81bc9f2ea82f": {"doc_hash": "b27d73d061e915ca015742751e47581941849d6824be9614b8d9c60835d49581"}, "5a95a7c1-a15d-483d-8d49-820908aac6d3": {"doc_hash": "10a385bb816aa8f98b3d729a524c25559bc84ff6efd063e9ca22735e7356012b"}, "89d037c9-f5f5-4781-b530-51581b342e26": {"doc_hash": "498a3a83f67effc63d2049cbe896ea356f9076c75c5c74f86cae37ea43eb5a6a"}, "1d2f0838-10cf-4ff5-9292-928cb222873c": {"doc_hash": "c43e4d225058ee50d0cf5c22247c25e3ea67c6b65daed7d0f2a5f1791d994b4b"}, "34aaffd4-86b3-4456-ab7b-9ae1d263e9c4": {"doc_hash": "bab3014c9ff09d5e3dece529fadd978aebdae08383dd89f120b62a3e821dcbd5"}, "63aa74c1-fd83-4623-94c0-ee61c1fe7075": {"doc_hash": "8d99c1cc579d28cd67ed85e3cca35b6b5920521896f5131a82b06a69a23e8c0a"}, "bdf2ef05-21a3-4ef3-8c3c-5e36294a17fb": {"doc_hash": "95ccda34c473611bbb35864c0d054a0e3f8bee4bf0a1f321766ad41d40d2178c"}, "8db403b9-e197-4bf0-ae12-853933f3ca27": {"doc_hash": "ad4a6e3518892ec6560db03e00eb12e1f2247226451d6c61d063879bc79c4a70"}, "79864a9f-fd5d-43ad-80e7-64cdc93b1eef": {"doc_hash": "488546ab28c9c59cb0b3062f8baa26e1883f3b620f4984dfdba51326fe0752fa"}, "3f403ce9-c6d8-45c2-969d-861f5ffc401d": {"doc_hash": "f66be99be64738b117fd782947bb81f7cb5a79e3397047550c59c4f8af1a16b5"}, "628e8be5-cc12-408d-b5b0-82f20cf163ae": {"doc_hash": "d41ab0f23f67dbc2c777f6e27b6d3e23c31e515ff25f5f6d4ccb6b48372e19af"}, "98dc066d-17be-4a7f-9348-6f5b3bef01ee": {"doc_hash": "abe5267613c7dfbd57fe4baad361e7c37820ae71f3747703f9b9926e1fd29433"}, "3e3440a0-c744-4119-8e95-8c75db02eda7": {"doc_hash": "edbb24b7918d55076757a4c8f66a3f2ea7e7e06daa3e51dd0315a26a6e3fc303"}, "b27cc8a9-c505-4146-9236-1eeaa2ceabe5": {"doc_hash": "00276ed67bc601dba0aa6d941a0b5372cb22f2fe8cbb11ca4950bf561ae6d81f"}, "c96ae6f2-43a6-47f3-ae9e-b623906602a2": {"doc_hash": "20a76649c905938a34e4162f171ba28b0a0e7b32e5bf7d62fe3109e31f4c6887"}, "6ef389a8-9402-40b7-bdb4-d9664371361f": {"doc_hash": "47666c94eba0fed707fe65998c72fb87ee05691b735a0d3c906ccfb17636b1e2"}, "a466cb63-55bb-4671-b966-83f6910e0579": {"doc_hash": "1d05fabb59f0f945ce867fd092364b59449c26ddf07c9ac331c50aafd7279dbe"}, "4044f40e-3f00-42aa-8151-cb01883c0f7d": {"doc_hash": "9dbcc49cf4069d402b4281bc311fc71039c1c381597022bc9bb0b005fc908a88"}, "2678f70b-631b-4b0b-ab93-4afb5d8c9c90": {"doc_hash": "8ba5698a030d1a14cb545fd9f09b33b888c64efa33f1aab443ad83dfbc53756f"}, "fa05fbab-4f5c-47a4-bf52-55e190234d96": {"doc_hash": "43839ba4c7fee5a1f17f3bb5f723713065348c14a51f2d2f014ab5d25bcceb4f"}, "1679f3a5-8a0d-4e37-b3af-ddb564d4ec43": {"doc_hash": "0e3239b304fa9720b7a6973f28ef802a846d4523230718cf58a278891cd81ce0"}, "dd8eaec3-d0d2-4bb6-8785-efbf48e0213f": {"doc_hash": "6ff96f76c90d4d0986c22b4ea1cab797b1eead26dde5990cb8a444fe9a4cbf02"}, "ccff84ae-75ed-4b64-9a9c-e95bf3be21e8": {"doc_hash": "ea16d7825a51ebf93d1555a82e282c1a44e71b07615ce23e6d688998d0aad75d"}, "0fb6b0db-2775-4c6e-9eb1-581434266f01": {"doc_hash": "55bbcce9a62a7994fdcc35881260c21170690497b70b0268e504266feaa1ea04"}, "9b1848fd-dff1-47b8-9b1c-71f02bbe2c6c": {"doc_hash": "e680350551b73ed7455445c6affcd4cd6e4525fc3ebe36d0426efe871de95b0b"}, "359864b1-ee8c-490c-9183-79b2b4b1d321": {"doc_hash": "c9d0f7bad396e36d17d0d7196162870a173a428097192169ac4acc98e1285716"}, "c84269f6-2282-44f7-ad07-5eaa60951235": {"doc_hash": "1ccca3ca148ec49976dce1e629adbd1f149e86b2ce01de3afbc00c8149fa9ad6"}, "34d2673a-8782-4373-b7c5-31a1ea164786": {"doc_hash": "f6a2731c13df87eb2626456fc1842a65e7d88b60239e9d2775aa11ea412830dc"}, "2f34f22b-77d3-44b1-9ac1-9a4496bce79e": {"doc_hash": "c35ab78a32ad362395226f80e2a234ca50b06e620f72721e725eb18de8673e53"}, "40658619-ddb6-4cdc-b27e-607ef48154a9": {"doc_hash": "36219b5dea6967d1ea8686e6a9d640671f8318f79e17dd9ded83b3a251cd8632"}, "e8d5e261-d39b-4f61-950e-dd7e29d16458": {"doc_hash": "63d38a1084cfbffc27e0a568934733171042f38fb2dd61feefe1ee6b0aef5c14"}, "6dedc4b1-6b39-4242-b676-cd93d754394b": {"doc_hash": "1852f4acbad5dc855944ffbd5dab0dfb1c6deb35f097ed891aaf013990b9612c"}, "e65c9712-f26b-4c89-8fcc-4e3ce2e91970": {"doc_hash": "4c27552c468e36986858ea93c1b0f3663c485321dc5f2994fd7e36ae4489a9ea"}, "edb88a85-760f-486c-bbb0-0f8c50b8b76e": {"doc_hash": "cf6cd2b55557cb1cda3808cecd2e7a1b325943ffd9a398af6e589ccf1ecc351c"}, "48867ffd-5ec6-4e2e-88ae-082f01349b86": {"doc_hash": "6886b5cf5d3ea3339576879c82d136272762d567e0c7efacee1b7bc8ff76ac62"}, "e027283d-e8e1-47f5-8a5a-8a87196fc7dd": {"doc_hash": "40361b1637847acae44cfbc583ae679e066ff59643a794a41da23da1b3fec6dd"}, "35366f03-fae4-410d-ac6e-69cec9a64594": {"doc_hash": "b86470644e0a47fbfb5d1e7393229d24954a3086d5cfa5e4faf7870774f06271"}, "b6f5e7fb-39af-4871-80ca-80e92e154510": {"doc_hash": "ed39c5c2c82a3a4236f164d2d14335ff9bcd3187f76b7c688051684b60ccb61d"}, "30b7fd33-547e-441e-8b3d-bd315c7d3c99": {"doc_hash": "1d1e038339a103b34868acfd34595e23bf85452140068af7dd1cd7c4dae6925a"}, "9ecfa0cf-c386-4a24-966a-ac55779dbae0": {"doc_hash": "2669f60c1db7399f9e270149e510cfe10f3f0d123c15e5ddd06ebceeba4b5bdb"}, "05976454-c5fb-4282-acbb-e2f5edb17ac2": {"doc_hash": "3ce8b3fa6bb737304467ef4c4344eadf8e8561d9f055d8fc86c717df41402c57"}, "d331462a-0d87-4e92-a441-c491be46c143": {"doc_hash": "bd96f86ef43a29f2286005648432d68b73d38ed2ef357c788df3aadaad91378b"}, "b5a2cb58-09fe-48df-8472-319a94e92dc6": {"doc_hash": "4584976b3eb43343f4d865b7e76a3f6d3ba38d87aceeed301114c4e0e073ff01"}, "661dff1c-7e03-4db3-8a44-2db282d96005": {"doc_hash": "63190a34fa5cf3f2eadfbb7906d6394979a51bc31289ca6d1ec3cb0ab9f90310"}, "122f857d-21fe-4280-88e2-e727f4e2edb9": {"doc_hash": "21f41eeec0a558f798de6f37633b0d28500c9f4d38ec6dff27decdf1db01e9b4"}, "856f14c0-8dd8-494e-bc4c-d5c1801075d1": {"doc_hash": "556b6b29ea388be15ae4aff9853d1cce1574b99ebb7e988edc991745ca470649"}, "02a96dc1-30e6-45ba-ac0c-5fab4b626d24": {"doc_hash": "5570ceec338c9cee81ccef577f59359727e599849fee32272b1dbc68395e58c9"}, "eaf48bec-50f9-4bc4-bb03-46c16cb96d80": {"doc_hash": "bbe2560d01af69ad9ca7ca72970a4c184575044cf3b38713994fd339d765dc98"}, "bc2e1947-153b-48bc-9992-94f9eb4e05ee": {"doc_hash": "90650a4776082153f471a7c9d6249b2ecba0c297ed8e155a688e35b5f1cfb420"}, "7ca3ee29-86e9-429f-90d6-f1cb956237c7": {"doc_hash": "b2b48b52fcbcaed55a196c7d31b068559c67b66005ae0e21fd617250e9e62815"}, "97f98343-e362-48d8-8958-7da7f44891b5": {"doc_hash": "386385e33e39935aa972c46ddc2c967c434cb5129630b331ae4fef0534dd704b"}, "dd0e7528-be46-4855-88b1-ae6e27ba61cb": {"doc_hash": "553897e6b5c423ae37fb4c1d4150db24fdd7715b627048e4da3c64fa6667c37c"}, "7c7c1a87-c4ed-4a3c-bb02-767537be295b": {"doc_hash": "48724eec05b856ea2b5f6497cd8a85dd3e2dff36acc7cfbd36a431a01a3459ed"}, "6002ad3a-8017-46a5-8a4d-9b75b984f644": {"doc_hash": "94f419a46b94e21ef26c1a767bdbe31604d99cea41e4a080de54d299aac48b3c"}, "810876c9-2d8c-4032-b8ed-f23538566ed3": {"doc_hash": "d3ae8e8b1a0023ccc7d7c3f59bc8f67bac56beb630be30fc0c16657377de3b39"}, "751cfadd-b091-4642-b85b-19771b1dceb0": {"doc_hash": "6665cc75424a0b5304eaa62d3ddf0a7085d1669a6a2a4bdbce2bde839f92cbfd"}, "3c56cde8-837d-41d3-a09e-b29ac70bc554": {"doc_hash": "bc5d800d9113635e938610d870b2a8d3a7c03a42e93aa3d8a06ae47262eb3256"}, "043e48d5-7717-415e-8efa-17c693efb4f4": {"doc_hash": "e82005e466017afa37642320a129401fe85afa299e2130393d56d50263c36896"}, "a743a739-8538-4ee8-915d-9126c42f7bc5": {"doc_hash": "510af7d6079b920e9b962287aa3ed4bb4a60f44a996294865d3cb365761de4d2"}, "48e1478e-5125-42d7-8dea-504b4d9617c1": {"doc_hash": "7e3b620950727ba6927ab456dbe7728e9e0794cdf2d5d52ce021922fffd70d0a"}, "0bdab582-438f-497a-ab1d-7739b6b32673": {"doc_hash": "e3f0ae584b70c3a48a771c71d55255547a61c80c3c577186c72ebbba45c17d97"}, "a055997a-a88a-4a07-9d8f-b23ac2aac43b": {"doc_hash": "30786c5c19fa1d882a0aeb9c3dda94f845440f366fa5373d9dafaf20c7340099"}, "d524523e-4fdd-41f8-a6b9-da3f4a98e262": {"doc_hash": "d185d5522bad9e16c68f06e061e0398748c7e12ec7486dc9ed3c2e39715372c3"}, "c0e00ba5-b9e2-464f-bdc2-cbbc10cd9f94": {"doc_hash": "ba8662e04150c98bfd441c777f4dfd1fce5095262c16cb49fe4b4036830490a9"}, "72db00b8-72b3-47fa-b009-3c890eafcd7b": {"doc_hash": "714c32eb835180504fbc7bbd2d431ebf22f4e4ef64aaec32708d4ee78a475503"}, "cf4f0c19-f13c-4981-9d73-7f1673648fed": {"doc_hash": "b7aa62db29a71686ee7c570507e013094830b7543b1418dfce427327b79b4270"}, "0c9ef5f1-76d5-4b5b-9c44-04dfad7900be": {"doc_hash": "a9a538472ee2028ccde5c35381f2f2dfb8274366b1dd728eb768bae17082ae08"}, "564e4b7d-ca49-4965-a6ed-f1cb2a73f0bb": {"doc_hash": "e01f4a4372a9dd8505121ec2b2064bfd8e1c306a1272f7941903d10475762a0f"}, "4dca43ae-fc6e-43d0-a1ba-9d09901f8e6c": {"doc_hash": "1913ed9a5293cc8ae161a56e5011a8df87163b9c8b5971a2f8e929493eea01ae"}, "9506cf0a-81c6-4a97-b0a0-0d331cf5e99c": {"doc_hash": "bae8e79bb0e8f6928c128592e1a3196855bc1cbd36a77fa86523e276f8362acf"}, "f5b5088b-ee0e-459b-908f-4591d6006bc8": {"doc_hash": "471699721784067a861cb30279e698db681f983d88c6c5bf0b6ec34f47dac1d5"}, "080b7fa0-7ba3-4d1e-b55c-fe0686d98c3c": {"doc_hash": "f491e6ed5501435d56c11368bc4280a4fe13142457db1fcd1db62057144bbb9d"}, "32dc3a15-4640-4999-a48f-233a54f5af8a": {"doc_hash": "7400ec5e788b807a150c8f8903fa0bff90d0aab5864c14a1747bd061caab9b4b"}, "7bb267d0-a37d-4ae3-be28-fc19a64e863a": {"doc_hash": "122db0f07dd08a2693774c5d74ea52a0b057ac9d0fa1cbc928570357ce9f74cb"}, "90f809ac-6aba-4d97-a234-4ac14a7b3050": {"doc_hash": "808a36ae3251ee12f3e3a03ef15b74568c32cb2d137e127b9d45a9515c5b76a0"}, "cc70efc9-955d-4de3-9945-d5d58bd0f88a": {"doc_hash": "422e5c46b3ee903636cf806b52e0233cc4f46a13f32fa54b529f4a28cc93483b"}, "238d8bf8-39d7-4443-b01f-1c30b4b2b337": {"doc_hash": "f123cc2e485a45de50eeeb4863c104efec3c30a05625ad34eb89fe168a11f4ee"}, "fca1b334-4168-4e1c-871e-05a03f6fde10": {"doc_hash": "c05b769a8be5f674ab4a3a95418a13ac4f6cf9d5b433835499ce764928b7ab82"}, "8023c1e7-359a-4944-a8d0-02ff3ac85e64": {"doc_hash": "cdde551094afc41334291528dcd6483c9ded206a900f69c93693366ee5ee4a74"}, "68206f21-e5d8-49f4-9c85-ebf80e9ee9f0": {"doc_hash": "436dc0501f2ef75f0300215ed953248da57a17b62e86b4d63f4af2187c67e6a6"}, "ad0e90be-2bc2-4677-832f-2832332d803d": {"doc_hash": "f6270c7193728378b7c6e42d80d1e755ead90f26fc7970d8da8a614b3aca7b01"}, "858cf3f8-74ce-4cc4-b668-1e29088919c5": {"doc_hash": "680ebe60477ed43b708b30d4b9a4b15404f9c87c9a28cfe3e7317e3c2379f340"}, "8697faa3-0f3f-4a71-a422-163528276b8a": {"doc_hash": "c59dc597ac64b1f3ce64db5ded795e9b7256c97cdbcabc3440a5da15dbc9542a"}, "3d240334-4a68-444d-b9b0-8b242ca320c5": {"doc_hash": "0c023e3cf8bcebeba22d122e20bc346938da5b0aa7fab3e26cb4a6f41c493e82"}, "a941df31-d957-4408-99b5-6ad596f237c4": {"doc_hash": "bd3c73abac6b3e5a7739c944eba701030cc37cff3da342637e0aba4ef22cbcca"}, "ca34bd3f-ab4f-4bf0-bf4e-1e2fea0a781f": {"doc_hash": "f8c4c893fb9602dd495dae8459fe2676487e9a4c7c96a3f7bc2be140f2da2d41"}, "10551ba4-3c49-4ce8-9da9-0ee352cbd253": {"doc_hash": "64728817059339b37a634852cb656d3f4c8636fdaac2d98857fec8e883301fb7"}, "66bf39ee-69a0-4349-afb7-63ee4caa4d8a": {"doc_hash": "f038042418b0d8a9db6a4cefcb28b46e4fec9d7fdb4759554eafad629734d649"}, "97542c3f-34cd-4146-baf2-7e9019132b43": {"doc_hash": "7e50b77395c7dfc6b1da3ecbd08485db11960e27e15255c8661d51c486867294"}, "2377bcac-830b-476b-8d20-d65d10d8b5c7": {"doc_hash": "3b86f873094f089a72dcb83cf8c21f995021402ae1a9eb961dc078478922f843"}, "c58c7445-a630-4fe8-9009-c54d4c79e4e7": {"doc_hash": "06c5642b750f9161ee8d15283dbbfb93c8f507caed466007217461c49f7e4356"}, "ebf1e265-7f83-47e5-83d4-c39e75e23760": {"doc_hash": "8c94b4f6ea8512f54ec0e47d029cec3776774fac59d027df7338f14f177cae77"}, "36732651-f996-4ba5-9291-73a9f6cdb2c4": {"doc_hash": "eea97ddfec0f2413005f4e239ade5c997602ffb0093546591a3f04823c78ce6b"}, "c82e75f9-e667-4a7c-9795-e807a11fca1e": {"doc_hash": "b26ada2af98b00e86c9a836356220a62c766ab0d7945f2f22f90fceab74bb671"}, "eb7b609f-43e2-48d7-8137-0392072ca742": {"doc_hash": "453c022d9627e1866c0a9ffd498de923f41d07ea7cb261f60622b89e9d615a10"}, "7183b0da-d584-4709-bce6-02084f4c671d": {"doc_hash": "09a952a3bcbfe1981807ce15ca50d798f0e9714113d39707c6487383dd5c8970"}, "a55d14c4-0f60-4835-87f0-3b857c93c4d7": {"doc_hash": "2348b21f16b1128b0ddbdd064c09e04ec07aac9051abbf832a2f683b0ca48bbd"}, "7d684626-1973-474c-86d4-c70655e50682": {"doc_hash": "08b5c7f46dc7e015635af984e9e59e3d59fec1d6bb5610f94c5e43c71a72afeb"}, "09f9b482-ee9a-4f8a-a692-c29f6860f6ea": {"doc_hash": "bc1f1e793dbdc4a441cc5f72721ae2c83ea6924a496c7d133ae9f08528b7c7ee"}, "1ce3221c-e06a-429a-b1c9-198aa09172f4": {"doc_hash": "db3479bfc981a174456fdfbdc2b763ba935ec080fd6235ed0514fce03c7dc58d"}, "8ee89fc9-d2a3-46e5-9aea-343e87c32a61": {"doc_hash": "8c405da86dcdc93951f63e1ac3b04bd5c23058fdac0b2b36cb49f9e1b953d171"}, "8574f445-4346-4101-aa46-7091eeecdef3": {"doc_hash": "4ee8a2d00799e6c3b2e1558d2f1213a1ebc3a70b2498390404cb302a20527f9d"}, "a97d9081-5fa9-4e18-85ce-995bba721433": {"doc_hash": "5d6f6b88a9bd15cb128ea928a38344e9b74e50d07fd6f0be5f7179479226ec32"}, "510e78ba-26e1-4d52-8ad2-5b1165042a4c": {"doc_hash": "4520fdfce888e4aeaefb4bae3cf0f5cecb5ebcd22f8d999fb7bc6ab1378f8b47"}, "2db66b8f-2001-42e1-9b7c-1ca86d068deb": {"doc_hash": "38b3acc61efff6521f4b1b4eb958cb7d5b6eaba6eda205192188dac3980f5114"}, "cba47a6d-4142-4f18-b167-8688f2c7150e": {"doc_hash": "15ae77b3a358e1adad719403dc1ecdc0542b85be1ab5b217703fdd1820a366b8"}, "cdecce45-df80-4933-ba1b-865bd23a1df6": {"doc_hash": "7ea2013b92cfda0ca0ff29a32a4210d02fe24d80f02402cf7179cdf4c5128325"}, "0989dec8-684d-44b6-afd5-0e0c42e9fa47": {"doc_hash": "386ab04d091c3edc81a1c1a2373050ae37cb372163b50daa1a347b71e00e69b6"}, "3d569f81-e4ca-4833-8e5a-3403aa3dbb6d": {"doc_hash": "cf938e3b505995bd5564607fb1bc419909cfbc0aeee02f53b7d71111990794c6"}, "d1dfdf4f-9c9a-473c-8729-55a1bedeb9f3": {"doc_hash": "2ae1e46f209baf4128b0525c86f4e61fb67655367d814f3f57ccb49edf0a27ef"}, "827f83ea-20ad-4cfc-9a81-bd4c4341fffa": {"doc_hash": "5bdd6e454ab88bff2f9b78f281b9e8c087d13adf3351c7a48ca721face75ea3e"}, "57304954-3365-4190-875b-006d0feb215f": {"doc_hash": "cdb8ae14dbeb2c5227bb0d7280c954da42bc6764c42dd63408d1e25df7aff88e"}, "2530d9ae-66e9-4cc9-a153-ba289adee82b": {"doc_hash": "f1b520009e0ed44258bb949f8a2bfe486938045ec26c9c829a824a92ab69cdc9"}, "9959f5e9-09e5-4f6f-b79c-d0ae76440c36": {"doc_hash": "8cc693a5ed446ada0f9dde08ac7280a4cff707741a5cdddda02c864738c1ef69"}, "4b543657-da74-442a-851c-82e9e4c62796": {"doc_hash": "badc807d197a856be5abc9c0a904d617495726affd3b8ed1e8f64bf118136281"}, "f3696eae-796a-4f7d-a45b-a42b13e7c359": {"doc_hash": "a5ef956b49aecb4238d64c9cf2f35bef4040a5f2c8e40773bf355d5777477244"}, "986effca-f321-4ba2-b241-c9e295095733": {"doc_hash": "69e601403b5952789bd9a2f297f2f7a185ecc7fa6de408377a19257d8f97a314"}, "98565fbf-1d50-4962-86cf-c24070d9603d": {"doc_hash": "86e556b8c7d761f1ac1f6761f589283759e876ad75ff5dd42e29218dcbf88a81"}, "b6e0ff96-78c9-4510-adc0-fc61f5f67c9d": {"doc_hash": "a1397a62b80cd37a28396490e1a81d357f986e32bd886b0eddea8e9583cb9500"}, "674b6b81-e0e4-425f-9e3d-96a66393346e": {"doc_hash": "0b837adeccb49907f2d783fba6533079da7cdb03c63bfd3613316b5ad902942e"}, "b9f0190d-9315-4b11-906d-2d4b2facfce5": {"doc_hash": "62dffd548be59846545e44dc0c50e43cd273293b71fef128afeeb77e22cb9349"}, "f1b671fe-efcb-4117-9cbf-edf3468c7aa6": {"doc_hash": "829f7cb6d2d0d870a2e3b4fa95c6e3f8fd099ab1cd47eec1e3fc996acafb72e7"}, "a3a08c5e-feb5-4356-a32f-039ad9eca9e6": {"doc_hash": "7302f0bd6f8f3396049b3de3df686788568ac12ddc627bb85f33fe241e354ab2"}, "04d9f638-42d9-4c6d-91d0-75b882f5b3b4": {"doc_hash": "261cfc037d4f4adf22a6cc668c327e78d4800735fb5f7439e0d32b7b465a1142"}, "0879b85c-b035-450d-a6c0-34bfdcdf88ec": {"doc_hash": "70e7579f26231779576c80de4b328df54d3d8988f667eccd9f4ad7ecee937747"}, "0d7ba882-30f8-46df-b9f3-837fe6f51f98": {"doc_hash": "96bdac8839eebd73559d9dd5649710e945474ffed6c8db2c1461a89f06ff4759"}, "37883d90-f45e-42da-921b-0a192b32ebe4": {"doc_hash": "23bdf2586ee4eddceebb9a832329348473576e71f3a61c7b11a01dac4de6bad5"}, "7b6d8745-bba5-495a-933a-283889eb94f9": {"doc_hash": "8636aa0018571df8a44422a36b3ea3ab688b1e4a02f334de8e6a14488a47fe02"}, "6e175c6b-34df-4d62-843e-36f12490c7f2": {"doc_hash": "1b6019707ac311670f39e9fdae35a6e7abbea4a933fe04f6789ba287b54cfe65"}, "70d497c6-959d-48d5-8451-005e0909a884": {"doc_hash": "3eff3ede25d4369ed066514472b0cbce677f7878f408c40a8fa7d785f4a86dce"}, "95bd534d-ab95-4d09-b149-da5057ed388c": {"doc_hash": "4ddc48cf2ba9cbe94528ae09101324b675e195beb850b80a9578d9f0e084bda7"}, "e50a8f7f-f8cf-4baa-9629-dad11ae8996d": {"doc_hash": "3df30e48bf76b1634ffc1c1a3291be77677df029ae0a302e437d44f5640bd11d"}, "54ffef70-b630-4f7c-af0f-92d4e5304291": {"doc_hash": "20d49b915cfa786a104be03eea0cc2305cffceb852d30a909667e65a77ab888a"}, "d522fbf7-626e-421e-80ae-b1cd7645422d": {"doc_hash": "3bc6fcd362a30ab24a6e3d7e6349a76790c81f4fbe51697a4f7d16cddf33c6dd"}, "7a228fe7-5cbc-49de-ab6e-aad6cdb1f97f": {"doc_hash": "b68899937be87f5c878b696b736a305da8fc126c4e42312d5c2add7d700fa9ef"}, "3ca1c954-2d8c-4e06-856b-f42d96d97a81": {"doc_hash": "567922197e1ec4275236bcf56ae81cba915abb5443b678c1343446cbea1914f9"}, "47934ca0-c3da-4769-bd70-1d4c6df2388e": {"doc_hash": "837de7c846948e40cea2bf3190cdda879a064bd8a9299066e4503ab9e372615d"}, "84a04cfd-1e14-4e5e-bdb9-0e74da05c032": {"doc_hash": "233501e397a1a27daa505330ee1dceccbf1cc81a6b77832ab17b2d93b64fe404"}, "c0da706e-cda8-42d0-ae0c-bb85030eb3bb": {"doc_hash": "79fd0831e919e3f55da4dd4e17a620f9b8972909025367be2dc8c5dc37426ff1"}, "4078330f-c85d-4ef9-ac4c-c66d3ce845c8": {"doc_hash": "370230dbc78245f79d93b7c6c14ea782e86a80b2976cd49550757a087365a266"}, "bfdfda61-6111-43b9-a35f-dc0b71b60778": {"doc_hash": "f5651639784d3c8848858e00b58c226d3987bc6079030b3d75dcfbd4bd668e80"}, "abd9322f-9a53-485a-adde-d19475fb0893": {"doc_hash": "a32c0ee3c23fcc9fc541ff5d25c16af5365ebe85af256eca8558e55f5ffebc43"}, "932a95a6-61b0-4e1d-933c-6af76fab904f": {"doc_hash": "f51edb373aad7dd4da8cc7d456af6d5960570b4925df0425430952fb215b703f"}, "4a4bede2-c2ca-49b0-9016-63b519ba93b4": {"doc_hash": "68dafb431ac5f61f1f9e2e1b62294416cd4333961a8a164b0949e1bc8d6eced0"}, "304aefc4-ebf0-443e-b501-a0750afc67a5": {"doc_hash": "2e4fffbb8ecf513749effa070e9450c0af0b230c84bf93e1b578e0d7e33d1a3b"}, "a34c95e5-ed3a-455c-9b6f-738ab3cee1b9": {"doc_hash": "9ce608ddbac01903f29872ef4c338faaf9237a729d3a7ebb8060ad96f28181b7"}, "3d57c494-6517-4132-85de-11d7c016c3ee": {"doc_hash": "0c6d0a2c72c29ec54e57271e2e731126ff7ed345cf86ac7dd072fac96a5ca386"}, "ce91a5ba-ee74-4db3-ae03-be4fa4670970": {"doc_hash": "93b94669ace487595422b4f245d1f0687c0d6364e56f5d9126722580cb1f5247"}, "00f6ce1f-02b4-4958-b207-215e73b12b99": {"doc_hash": "8b8c122f7c027ea28fb331d7ed1854cf459d018993c764d9033f572b82f253f3"}, "66307222-fac4-4f4e-b83c-7d5138a9d88b": {"doc_hash": "3913ad9e2984c6ac0507de2b2e3acb78498c8993d9eccace026abbf775bd2702"}, "e437cd0e-beaf-4f94-bed0-ba052e18b3a9": {"doc_hash": "d3091e2f40a7f0af2b1a1035b6064ec095b8ec980f591dae102f45b4253e8451"}, "fef3d819-161a-4522-9aa4-e816e0fc4407": {"doc_hash": "a563ad71b815e8af56811bbfc977aa222bdfc16b91f4f9cf183dac040b1dbe84"}, "9f114e9e-5c33-4a2d-8f6a-449708caa684": {"doc_hash": "a25ea82aa71b6b2b83e3d1c578d303ec1fdebf6830679b475beb39760ccba2c5"}, "f9e460ff-79f0-4056-84db-bd92a3346cf3": {"doc_hash": "93f50e74dd109c0f1cef442d4e06ce757512b641181c92ded579901e544fb582"}, "a2f8d9b1-8344-4af8-9ed5-767f6a6ed229": {"doc_hash": "dc9b5ef0d895771c9f7f7e8c90de8327cdcaed90ebcc069003fa18486a1c3040"}, "94db9a0f-dd4d-4feb-bf37-8af039620c54": {"doc_hash": "d9d0550d5e729d3225fb70053d2408865876251e48e4be4acb970d2b38400156"}, "e55ae45e-9943-4179-8d45-7aa57a303126": {"doc_hash": "7732786a6ccdf078de010fb6d050730107a41dd3a881ab013260d82b34cf6eca"}, "0b62ae51-4ec3-4a1c-994a-bdf2e413c230": {"doc_hash": "84b6dfe7242902f3003a75242f127c77745165278aa478aa4c41df893220aa25"}, "21378c85-52f7-4bef-933e-3f08476ff735": {"doc_hash": "410f8bcf994ca97afc78546bb814ce174c1e6bdeff423bdcdefd839f7e0c6fb9"}, "e4eddac3-4ce7-4bff-b394-e0ab0bf482d2": {"doc_hash": "af374620cc59aed12aa62128bcc526e5512fbefffdcd950223606c9eae4c68be"}, "c497851d-2f87-4323-81b4-859a87e8e5bc": {"doc_hash": "e06013b27ffb997166da1f5fe2bc631667825606b1860b4d61831f632a47b8dd"}, "2e2e8e5f-b8f6-4aed-b9d4-b83b91372d26": {"doc_hash": "04a7bed1754a41d86f1d4bfa2d2c1f70c8e8a6e10b69d5d9f3d0599acbd18d64"}, "0453f06c-1ac2-4dd6-8c90-8ecdaa5e0965": {"doc_hash": "5af3d2a62c620dc018c4f4e6f2a11e9d6c58df99b50d418ea7aa8bf2383aa169"}, "ff9b3115-4276-4746-893a-7f96949bb7bb": {"doc_hash": "912ac2aaec7373fbaadc94327841bf8e640d657282ac2330371b1e883147c275"}, "6fea1f64-a948-4bf2-ba5d-bac639c82b2d": {"doc_hash": "cbdef8df7da517d380fa806afa63a7c6155f53788f6dd840c33633d0940bc7fd"}, "d9a37cc1-262b-4343-9ec9-2fe1deb9b6c0": {"doc_hash": "fb16406b1551e7a06ec3c0b44848485d9b8d5da8de5bb8e181838fd93a597e7d"}, "7c4f17cc-3cf8-4b19-b680-6cf3e223d761": {"doc_hash": "11f55b3c44c1743fe3519f127b0b83f7d49e71287e3b56ad048dd01c7b9f5127"}, "2896608c-533e-4013-98ff-d5c0714d38fe": {"doc_hash": "8eda1c3864aa6dcded92a92e05003035d1f3ac5efdaa5db39859de1c5ce381e8"}, "2f80f4f9-02c2-4108-aa0f-ab4199a8ed13": {"doc_hash": "d826423c6a72e14dd7ca669f9964e2274c2f852343743b423c162ef81ddf5c69"}, "3c257d56-e09f-44c1-9a6e-404fdfc979cd": {"doc_hash": "5036f90e1c7b2db1ff13603110a9a8ae941830f004adf3e10526dd164cd8fc83"}, "88ce8775-ef34-40c5-a9d5-fb9bd7d0a233": {"doc_hash": "eeea7ee8e9709170dde67802b2d8a518ca2e2d4be6ed28ebfbdf3c9f279f8bef"}, "cad56b14-8d2d-4395-8cf2-c478de344d7d": {"doc_hash": "d74c44a963d607a874f41db3f7157cc9929cb28bd7c426d969ba9ffedd7357a5"}, "bbf6aea5-b4ed-40dc-a24d-2fcd4946d705": {"doc_hash": "ed52128835471c8f6eed68f281bdc18b019b52cb4a2316e36f63c3dc7fc8a51f"}, "41d7f66d-2bda-4c18-ae78-c7c7ba4d791d": {"doc_hash": "a3bbf254c09cf4ddf562acedb56b6a7cd373756a3e0878b7d2707258f1cc8f61"}, "24198e3d-49b8-4422-9bf1-00d8bed144f1": {"doc_hash": "161462bbfe18ea20c87cb5dcf1487af31d10f13376f2cd9ed748fdbaa655471c"}, "4c7e6271-02d0-4dc1-92fc-4a8b6d54ee14": {"doc_hash": "8fd849eb8697505eb99449e5cf3ed1d67a8628bd18d10bd45aa5dd90da4a1a0c"}, "8306308a-2e69-4087-980a-0e3680811f4b": {"doc_hash": "56ba0274661f68c56164ef093f06bfe5e11db478c9800c7310c57c08ba9f2350"}, "e7e4d45a-c6bc-44c6-80f3-5b8b13ea0926": {"doc_hash": "f4f8e53d95cd12cf69232622b84dbc6f2cf2488bc5dac91e2917173e0779e2f5"}, "96741912-1e72-48b1-abaf-3c6da4497147": {"doc_hash": "4d58c7de75ba1faf5bfac60594f9ee6ac7433d126776a0c5156f7269f4aa60f2"}, "662010ae-67f5-4901-8835-b55571bee389": {"doc_hash": "e04c7229cd168c941dc5d5a65e10bd7e06fcbf8bca47025763a98f29e2f48041"}, "a2c5b6b1-6b06-445b-87a7-b96b4bf5078a": {"doc_hash": "c3c509fadc304ec7edfa80231f7beaefb1f51773588997b0e395d85499494898"}, "4e7f917a-c35c-469c-b61d-9da8a05c792f": {"doc_hash": "e93933f743fbdbcecbd6a274f79db146fef7335cecb4eab96719681e6024bfc1"}, "4b473ee4-621a-4493-9594-d1d23d5069f8": {"doc_hash": "1410f0db96b0846067a80cb26028fce60860f880b8df133a4ff1cc1d3a0fd867"}, "566b6ddc-b99e-47eb-b2a8-e3606c8f3082": {"doc_hash": "4b02b20e2940671d6bc7571eb29e858ade3595dae92d60a5e1f39a38207883f5"}, "97445140-56a3-4e3f-a851-a2f5aa417a42": {"doc_hash": "2292a6cf8eb65b9b73bba9d309647a8b2c3da41eaced93201f7042e78e15a06b"}, "9e57d4a5-7a53-4139-8b4a-8b881a740fda": {"doc_hash": "6bd7fa9f75699bf180d64b1b8f31e5d015b116981f0d7bba2ad0a88c1fb3be09"}, "c5111d56-dec7-4b22-bae4-628aafbff881": {"doc_hash": "c4e9f9c5cb5763c21e7d517dff33d14024791e10c0198274e298fe5d4424e1af"}, "d723b96f-d88c-4ccd-99d4-5dc9c9352293": {"doc_hash": "78f72963d1f63f145cfd5297108be8c105d672e885a8a4e06b9f9632ccb4e938"}, "40e5f72e-ebc4-4f6b-98e7-28781c99989b": {"doc_hash": "74ffea1043dc43cc1766368a05e00381f6029eab5ca6db659f6c4aa3ea13ab8a"}, "1be5860d-eb4d-4edf-aa33-718c6dce73e5": {"doc_hash": "a92796e377cc1559134affc46c293d9b859c413200de2dbc4174170f898a5bd6"}, "f2245af4-a884-4aff-bfdd-2a53b12b712c": {"doc_hash": "2e8bb641ce8c06137cde7a7ff024e5616d78354e7eab256c03df4eaac9b67684"}, "a0ec949e-d3ae-4104-a959-f29f95ce29ee": {"doc_hash": "0e34c1f308019c62603ef98d7e4fea797ef7262aaa8d0a46296000b7b714d45d"}, "850f3fb1-9217-4604-a022-ffebd61cb105": {"doc_hash": "97b001cda3eae0e9323270b62670e8919d51c8b3352f20ce24ac9101ea91e554"}, "01f0894f-34cb-4a03-8caf-2dea0ab2eeb5": {"doc_hash": "9779a559e3161638fbeb13cacba849ef3c7845ef0cc66d4819632986333f3666"}, "c4168a08-c15d-4a39-9bf3-5709f4533adf": {"doc_hash": "b74952958a336544057a07647c7fe5a96a0ee397f927da11cfd48865b4a33009"}, "adc4d74d-abf5-4858-8979-fdbfeba0d78b": {"doc_hash": "4feed2209ac2653e98117e8956748249e693d9cd54f61d0ccf6159e013e7a1c5"}, "b59bd784-c77c-460e-9624-d005b276b338": {"doc_hash": "3cea645c777d70c39a9a81d158f7561ae027a8b3cd4061514340f41336a3c56b"}, "a3b81293-26f7-4fa6-b408-59a420c9c864": {"doc_hash": "6632fed2e86c494e910997cc821cfc53c22af54b235d18f44ec22632dbfd377b"}, "9e2c5494-0288-46e8-bd0a-00fbf6f284d4": {"doc_hash": "d61431e451ecf51ccc5dd403eb5d6eac97277ee797f97aed8084f2a95dde1a5f"}, "63ec6552-6b0f-4827-988f-6b8472fe3720": {"doc_hash": "78a1bcf146d42ea8ed5ea346d21dcc1f28c74141838b6f26e9d3bfedd308b5a8"}, "119cd445-7e55-4312-baea-15c06513b721": {"doc_hash": "4c7f69b0d855b27e011037b6fd3311d7900977a3fc1884263f59dbc9612bab0c"}, "65e9971a-8b07-4428-9175-6ddfc2538008": {"doc_hash": "5efe59e43eaca46344157f4910d2c47e76e897144efdf56968d99466c9dcf9dd"}, "91842ecb-62b1-458e-8fbd-6e5343ffa2fb": {"doc_hash": "9412fae63eac8637f2a22d70a4b975cfa3e4b1207fc4bf5640658e69da93c7b6"}, "9cc4102e-d43d-4a8c-8038-063c92303fb2": {"doc_hash": "44e3a83c36bf973b6b93eed5d7c08cc3b572f1f756b70b83be800e661ca6ada1"}, "3a2ff404-3f12-4ad8-a13c-33a82e2d98df": {"doc_hash": "a5e5366f1884d107530e046ad04b5a6454eb59ae026af10574c69bbeb3237233"}, "60b42a54-d6d4-4445-b73c-52d293d29cea": {"doc_hash": "fd63e80b2855ecf4046f407b2ea0dc437c7a4b7937ffe5befffdbf567f92ff72"}, "682844fb-1ff8-4860-bbe4-8e99554224f6": {"doc_hash": "174eb723c9ff5339a80c3a7f1246ba3fd9c5ee1e9cdac5736cfcce07e1fe0727"}, "a130d41f-4583-4225-8282-917e62b3ebd6": {"doc_hash": "192a37d1a76027e9a72e47a46f143bf320b62871124e9ac58279fcb1f6b5082a"}, "35bdc77c-a0f3-4967-bdea-81d89c02e2c2": {"doc_hash": "58f5e64267e035d17a669e679670cb800510e34fdbe26163edbe769d595df87e"}, "8294a9c7-773b-4ba4-bb0a-3e7e7077355e": {"doc_hash": "af9447e45b71ce6fe02a7e8cdb704d62625fe1aa7455cb49a28f263f96c9fb53"}, "448150f4-0a3a-4bd1-aacb-e2ed7bcfc1d2": {"doc_hash": "4b37a89b8b05b513ff5fd2a62589bb8a247adbc84f04b984a2f056918b2a4e55"}, "fab0b1aa-3e5c-4ac8-870b-7365313930fd": {"doc_hash": "a6582ffafc65c8be7a4fbc26ff83c39fa3037305d588d2199c79cda875fe8031"}, "5335b344-f338-42b4-b287-813dbe0bfcb8": {"doc_hash": "be76613bdf6c2812e793ed1ccfbbe6aba3753c446e978ad9ae8f1f9b30d0e9c7"}, "4dfd71e0-1d6a-4246-85b9-6009cc7d5540": {"doc_hash": "d34632145ab9e18a57a34cfa08cf07811d7db8e17e8601129fd3c134dd9309ab"}, "f1637a71-3a24-452c-8bd4-1301caf073e2": {"doc_hash": "925ec4af90dd6f9ea0f91ee44c48ae97d5077e7690ec92faafc8fd9c7c7e2451"}, "12170e4e-ccc1-4d59-9013-ddf2056c65ba": {"doc_hash": "4cb43b24a520dbbbc61058b6c526edfb0b72db200195a575d290eab3d279cf05"}, "16a9c0c3-2ba0-49b3-a336-de6af11c8861": {"doc_hash": "72adfdbe6ad8f19765855a8a2c7419800b961d618dae869e9122c1774bb89d64"}, "57a40e1c-4b5e-45f5-80a6-61f22b406681": {"doc_hash": "b16619b212894e4122b7c8cf16ecfe1139fb13c13ff17226d382d63810c33be1"}, "8f5575ca-13d6-40f4-9c6b-fae1e2b015a2": {"doc_hash": "372e27da0354ccfd32d9adb7e5dd78a44e4979ee22c1792a204e1f0446c90be3"}, "9c3e1e26-1196-4f0d-8d9d-e3d99ce967bf": {"doc_hash": "96940548d121543a0cb3ef0419766d3cd0f229be52711bbf9498b282187deb48"}, "3d33a658-16af-4fff-a309-fd969f50e14b": {"doc_hash": "ec9a134f93f3781fb017e9d0f9cbed97c7834c7a31144906c43e81d6b531ee99"}, "fffdcded-2c11-420d-b4b2-a26b3a36cf7a": {"doc_hash": "13ad55bfdc5b68ea7362a066cc22dc6477434ca9fc14306d5f6fc6e07413734e"}, "64a35d7b-682e-4695-a163-0070d5a1d853": {"doc_hash": "3fce808e1189a610f269f276fdb50b53d78009e100220cdc7514be0a29bb72a7"}, "2cc3dfec-0bb3-4bca-933c-a9753c1ece86": {"doc_hash": "8e4890bd4b5733cedcba97465a8c64b7ae2d4f1d71701b67fe975f0ba974be7f"}, "a0cba3bf-336e-407d-94ca-d9fbfc35e22c": {"doc_hash": "793639ab9584c3beb7184e9c7882e3152a16983dc8a5bab08a91548ea47c690d"}, "8a420f6f-a273-435f-8e46-c2bf54f73754": {"doc_hash": "37e9c4ad78f16137ac5fd910be41d8c4f9e0e83cde58b2f38f39cd1bb65a1893"}, "4b64f3f2-89f5-43e9-a2ec-458308e8c960": {"doc_hash": "39a893a75bb893b1774e9803c54a12552c94f436180cc6abf774d4e6482bedf5"}, "b4d4e508-30cb-492a-b3aa-8e5c56ed6e63": {"doc_hash": "f5be5e5f0094c868de54d5bab45f7a91e5614044b6d7b660ea1b7c8c49d15719"}, "8be020db-f71d-4fe9-96d2-dfbfc068f75d": {"doc_hash": "71ae732c7be8e31264beeb8c4ccc2316a0743f4c0b4a56e2d72e50fd6f099abb"}, "0372966c-3c2e-4fbd-8ffc-51e4d77748ce": {"doc_hash": "99d61130096014f57b3883d58f09a3700e318fff6102ef65971ca25320cc543e"}, "1402cb4c-8839-4ec4-af61-79b0b189958e": {"doc_hash": "e52641a5b071d5d585d1178177931031289bc66fbe642eb2edff747c0b961303"}, "4b3519c6-7117-4f27-ab96-b977d4d56577": {"doc_hash": "645c071c100a73db8bc2f97dff8f45071706fea3feb79898634184796a746db1"}, "55416b58-22b0-4740-9c4e-2fe239247b72": {"doc_hash": "b13a256ae91b4d305a5d8e1eff219beb52ebecb6899127030c32ceea5c7c0ff4"}, "c63bb663-8844-4694-9ec4-c1b1ceccf389": {"doc_hash": "9dd50268e136ca55002ec86e3037c140110a01cc874031aab4940852f6aff324"}, "b6be149a-2ebc-4488-af3e-b1a778c7e73f": {"doc_hash": "8dad14cdd1a6ce3561d28a603a98c2278d0ab70e97cbd44857df45897f830718"}, "81f78aeb-a0c5-4645-b4ff-7dcacb66c7e3": {"doc_hash": "b0d1022922962e62164469ebd48cf0a51798f04617cc1df98d5adf452b216271"}, "feadf6fd-deed-4b51-91d4-bea1cfb022ab": {"doc_hash": "7a55dd20c904bdc9ca072a2b5357a58fe4e973da8a65d280916615e0b9a21c20"}, "74bb21af-d11c-4317-bd73-991e49635380": {"doc_hash": "e5257407a0fb21e6a1c801fb5d55a1bb7d4014993b9692644232fd69b580ea2d"}, "bfc3105b-5fb4-43e5-accf-5ee5306aec02": {"doc_hash": "92bd21d6fa847376091cf8fd19fdde3853f315118dac937567c878c9735a0d3a"}, "d1cca5b0-d600-4deb-9914-b1d795bff567": {"doc_hash": "06ca548b40c628ec78e0b32aa2b6676a5a445f1e7472a420239d0f1d04a45952"}, "3e34d314-da92-4bf7-a431-99f6b6d2cc11": {"doc_hash": "a1c236183f4f1b131d67f199141a8f812a3bb4bfd8204de5e837975ef5c5b5ca"}, "f82de0e1-2638-4662-9ca0-75777eb908c0": {"doc_hash": "e1791ddd6330d467d874a75c1c96a1d7d6be32cb7984f2ae46aaba77de56ec4d"}, "7859985d-9838-4f20-be4d-627840497009": {"doc_hash": "8b29090e1bc7eb805feb5aebd5cb6cb3db15fd7de62358c826de15d7d597e23d"}, "2f25b6a5-bb15-437c-bd3f-4d1f062c98fd": {"doc_hash": "2b32328d97d5d8620749f0a8b165b696c4708e5a3506d486f50a22591b89b1f9"}, "75c2fe5f-8eaa-4585-b8df-0d0a1e9c0265": {"doc_hash": "2095792e3b0178bdd3f455f9fd0c306d360a8851cca00075159ca3b4e5d16514"}, "841eefaa-cf8a-4968-8622-3deaea4dfb65": {"doc_hash": "31e94956cd247b5e4735900d54b21ce0526dec89dc5af22886fa9718953d9bca"}, "7c8ac85a-7b57-4c46-b3db-6b3e3a4b51a1": {"doc_hash": "c53e0775139ee5a7381ddc9a82c0a19bc81d9d150dc9cc98f98f9b1729b94715"}, "7e4b2c4d-5771-4da9-826a-89616aab08b3": {"doc_hash": "17e53556a7018d22015821ab4b5960116ba0c6167edb8c6a38d032d3cb5ea225"}, "66033e4a-95da-454c-861a-4a4502e9a917": {"doc_hash": "816aed658ab179cc3739ad37a50f8f27b5be36f22fbe25d527a269797945db82"}, "f1b7603a-15cb-4251-80d5-0dda429c6cf2": {"doc_hash": "bc2aee9b8a7f66215753c4ecd9889283338bf2638e9fe4cb63f10c426d84fa75"}, "db65d9b8-d8b3-4f6d-9ef0-983b89fe8ec9": {"doc_hash": "39faa31f604ada5b21c8ff339cd1669698a74c66589cfe64ba873e19c130acef"}, "f94f7338-c363-454e-8577-99c407c812e0": {"doc_hash": "c9edab6085d43250c706644bfbcb236280bcac30f13c1414a14bd9091b924ca9"}, "3020e5ca-d14d-44ab-8e27-5b6a6b69898b": {"doc_hash": "b942a56efd18644a1450527ce3379c55fe3f95368b3219db50686d952b0a8853"}, "02898aee-e156-4779-ac23-ee57e6573ebb": {"doc_hash": "836413bd44f938c80f8d73d5857fa29be4cc05a555dfbad47b0c33cef0cad926"}, "aa190f9a-324e-4852-b59f-e18360b36ffb": {"doc_hash": "0600348e974b93c9e309ede8f7fa36dc645d96a351547835ece7fbe9e72f8976"}, "324c62d1-6350-4fbc-9a28-82bfef998ad1": {"doc_hash": "807bea0c3092ee42db9d542e103a405477fd9a766dd3ab3277e7527d8abb9d49"}, "ae658b46-ea3d-44c3-ad75-33a608ba6b23": {"doc_hash": "5f144011efb114633a7f01ee35a80b9a4d2abbe8853a25eeff7e63d3eb90836c"}, "f928bd9b-f860-4775-9d5b-75794aac06c4": {"doc_hash": "ab4ba9e3c16ea673f30f5a0e132d960f178203c32b2ee76d8423b751fce75f06"}, "375815e8-c01f-4812-81c4-03acbb11fd81": {"doc_hash": "ecbc715e8bb3cda42e8defb1e5ba109e550b2f7dda6de1d0dec9e1f7b0ac5402"}, "78d7588b-c5d6-4c2f-8be2-3a03941d386e": {"doc_hash": "340de30b5846013a826fde5042dd50a68162a77d17e0659d01b5565a28721ad8"}, "24a28517-c435-4a31-841f-1035c01f3d5f": {"doc_hash": "d63701597cab7a4dcb54d339c30c0ef3724deef36e51a44fe570cd5d23a411df"}, "f1ee7129-cc5a-41fa-ad7f-af7e253eeb71": {"doc_hash": "589db80d6fd3fdfcb8d9c85d85b4a34bd58f44776291f849426571f92dc2af46"}, "026e893b-acf4-46d0-9d9b-f87519604bb7": {"doc_hash": "7e102646f961513e220ed4d956ebbe7e9d27f8ac6b5aaa8a08d32e54df105819"}, "61b52c42-716f-4b5f-9eb7-c8ced71af64a": {"doc_hash": "f7b69c3800029c3d8f8ee08b98de64c784f443977d5e0ba452633f9d46d546a6"}, "8ea37156-d79d-4225-9625-3a81fd5a4c94": {"doc_hash": "91b81af42e43cb80dd82f4f37e75adc5608b86203ca7bfd8069dfa934bfe1b0f"}, "16324afe-0c23-44d3-85ab-e728f6c62477": {"doc_hash": "cab3ee766bc81c1ef66dabee2f22f0b7f57d021e0494a8c3af815f0c3fc43cd8"}, "30016a60-1c80-4d34-8d5e-b059775ed3e3": {"doc_hash": "91c1d9be0a952d0f9443c9da19005af289032109300d83fcf1ab5e8c21d4e831"}, "18fa325c-61bd-43c0-bba9-f201fa1cab48": {"doc_hash": "554436cbd85065d9a32fca016c1646b3163f1305730c81026bb9d9b9b360c03f"}, "9de094da-ed65-4ef8-b038-2c8e6227f5ea": {"doc_hash": "b674c444631df5e67b6523bef06ea4b33e0679c92a780623f60cd31cf8a9edfe"}, "85a900fa-c0fb-463e-b136-01eeaa9fc704": {"doc_hash": "958bd6cc8658f64d9b67e9a3c914a5df43984ec05825c7d7777da11b56019a19"}, "6751cdbf-0004-477d-9679-bac6d12033b9": {"doc_hash": "5122c9c4e010fb8a34f704464e4a1e5b5cdb7d41512501f37e5ea870c17304ee"}, "e4c1ab21-9457-49ae-be99-f373122fb8ed": {"doc_hash": "473b9277d3d3944a80991bb6110fdb506c9572499af621b02577216302d63c90"}, "ded34db0-7fa7-4b21-ac86-7e919d875e8c": {"doc_hash": "5d9f6383a56f9875a6db0ae2257d4fc33e9cc964efafb521a59f748cb892bc94"}, "35c33495-164b-4623-aa64-94e83f98f07c": {"doc_hash": "663a499f07107a5ef134fc1af20c90857ca6410b4e6675a5a868c6f6c690545b"}, "0ae03ccd-74ad-41f4-a57e-430c1e2eed0e": {"doc_hash": "0f067b17d07192ee42e1faf7430237baf046636eff803475684f24bd03f95b46"}, "c1fec69a-8603-4f84-8338-8dff1b8efd5b": {"doc_hash": "29f16a89e42dad009adf4416b4984c3f268c093f6325b629805a4da814beb912"}, "4f6a46ff-d6c9-4f3d-a7a0-9f2ac784b33f": {"doc_hash": "c447c6ac3c21f3a3be7cdf8e73a7ee32df55142369ac0c536dd599cd6e795f66"}, "cb47a884-0d9c-4ed8-a911-6c13c93571b7": {"doc_hash": "3abadb3ce16936b52b2d130e939cd618e73e136b35c66b3afb9e39f845650397"}, "8ba1e891-7fae-43a0-9502-a289620fe3a6": {"doc_hash": "51f6e82f7df6ab43b14187e079f385987f3a0856eec98debed63343a21f74efe"}, "26475304-2b2e-4154-8b48-8265a3b9cc4a": {"doc_hash": "fcb5abdee7d052696ef61dc6413dcc8aaeb379ed3a9596e246696a74194ca273"}, "edea2894-0041-4cdb-ac6f-fe13bbf3bc6e": {"doc_hash": "c525cc2e36b02f528a7833a183550e8a4a8dc9df821fb57388e437fdab9cf675"}, "05f95331-96c8-4463-bfdd-8a6183cafae4": {"doc_hash": "3d6bb73afeed471f2bae87b044d967e05c6fa14d2d9f9e74622b2d799ec443ad"}, "6e2a8857-450b-4bc0-8ebe-dab0351ed813": {"doc_hash": "6497a4b5501ffda2b87e82bc44e060d580cdf38db7a472328eb7ee81532a2e3f"}, "28eaf934-344a-44c7-b7dc-7dad5691c033": {"doc_hash": "aa57bba16872253cf74f1c7446f01a90595f37e57246b3ae3c594192ab4b72e9"}, "d2214610-4564-4fe7-8b83-685f3c75bfbf": {"doc_hash": "25fbd06cb67d0d4435b7289652ae97f1e07b997e7849d59903abb09fa1b36301"}, "a72a1047-66eb-405a-b0e2-2d1decb7d959": {"doc_hash": "10d23ba2031d6f9e39845f8c92d3ea660237233c021ebd113e706d9321184a4e"}, "d25b4cc7-632e-4584-bf88-2d207a6986c8": {"doc_hash": "abbbdcff4b3505bace31171c85b5fe55bb98513072c0a47e6e0520c7057b402c"}, "00880046-7cbd-432e-b95e-e793116e9d81": {"doc_hash": "3c38d6ff1ed0f797703b895d43da897cde2c78c4af746d1b14525cd6f3120d9f"}, "96a7d6f1-128c-4a09-b935-a1c99927c717": {"doc_hash": "3be8d7f7f24da08e6edf2990a315f137c01904f6bf547d1d35b250e854d760f2"}, "3b033c94-6f3b-4dbc-95bd-0b2feb8eaf27": {"doc_hash": "1305bcaf8a69bccefad5c37204709a34e225a2d02c596f6b0312a12e4222a36a"}, "e4f80229-f4d7-43f1-a4fc-a860d543f2e2": {"doc_hash": "63d7eb7b3f7f041f3d0a0b618e050a1bbd47e4d022168e0d4945515584c1a6ec"}, "e61fc082-0804-498b-9dad-f5768ad2d518": {"doc_hash": "8a220de35db85af0008618ee039277774e91c08048aeaba26269b655fa8ee33a"}, "6da5349d-8690-4b43-bd13-66adcbe75336": {"doc_hash": "af9e42d1a64ec3f2ba70786eb6724a33eba8be224dbecb811bf47902a09db81a"}, "927d4969-d577-49f4-b605-b6ba3b3a738f": {"doc_hash": "37efc25f078097426218e94a748b1afb2a23a780300ee9ce4ba8643fbacd46e1"}, "339c99a9-4348-48ee-a9c3-8483b58fd861": {"doc_hash": "83efb1d8c73c3f2c406ee30ee46de58f3a734611e78ee1fe9b71727278eb997e"}, "43781ed3-561a-494e-911a-81755c7fe564": {"doc_hash": "0e8f4a70846e70fb6952fc85de8243271abbdf2d10075f4d687ac2c05726144e"}, "f52ac61d-f89d-4889-90e3-b48e8897e78d": {"doc_hash": "490f8364c4a19aee8c717e505ff5f95b4802db6c50c64f7997a345c405ebf988"}, "af926539-87f4-4a2f-93a3-9a2938695dbb": {"doc_hash": "0fdb5fd44b721f0c70a62ce09e763cf25066b84558f96fcc311e7d2037acdc14"}, "7fba8177-f74a-4a47-b92c-0e34316dd5f2": {"doc_hash": "a0aa948e266fff2e3f3fd5a876f360a32ced543c3b4653221bfd3a9405fe6124"}, "81065987-5c95-4b2f-bae2-09a8f0c0b450": {"doc_hash": "933ea923fb8f4900c307bbc510066734f80cb7c52617a9152e5a6d83e00bedde"}, "8162c312-1a45-440d-9b4d-ab6f53d3fe3a": {"doc_hash": "e7db0b32ed8cf18840e678bf800fe2134ccad32b1eb7f42137c95eb501f58b88"}, "0f8ecf36-8108-47ab-b5bb-63d30725710c": {"doc_hash": "f53598148ef339a59341dca8a7e045d37c35448c97d3aa10e42560ded45960b8"}, "c728acca-bafd-4e75-aa12-538e0f4b6b4a": {"doc_hash": "fe9dac33ba79e7f7230a87f9e679d9c4e0a1e1092022ba0a5e430c1b70de6848"}, "61ec02b2-3b5d-44e8-940b-66c331737fd6": {"doc_hash": "1659470567558368d8b5ece37f5fe09bb865cbe8634f2a9c386688669706b626"}, "dec1c46e-99a7-4f01-827a-8815bbb6161b": {"doc_hash": "dadc54c7babfb9ef18178cab6e3e4194901d66efd3e360030c8c7747405ec1f2"}, "0dd26e67-4ee1-4277-bc36-73394f2daedd": {"doc_hash": "d7722ab71fba75cc87fd309442ef1696cf30fdeddc0b1f94e95c972e38932f89"}, "1d8c0a27-f8e3-41af-9bfa-ab8998d8a9d1": {"doc_hash": "8ae90b72a6c426378f727ed8affcdeee0a1a6a5581dda7b032ede884af4f8364"}, "1bb99108-663a-4e18-bac5-38a3cabc49d6": {"doc_hash": "e81f3bfb5fd73c068fb8802c44883895e344d97d3e6e486bebb332a1d5c8eaeb"}, "e59b878e-f355-48e6-91f5-0d915e8d511b": {"doc_hash": "98af94630d34675dd249bb37ed4274053e65044f1ae077fe752edbab80e6ffd0"}, "89cd2518-f708-4678-afe6-cd0ef19b0462": {"doc_hash": "9d49d862aafe93968183146011b981b1a8bb9f8e683894718417908808ab5b88"}, "41899c62-cda9-4b42-9b60-5247cd4b1991": {"doc_hash": "87808f78aa53b9a4568d548d1e1757bb33df9e8634089b5c79827462fc3d63cd"}, "3f240d93-fb2e-4eb0-a2a9-b0a3e43219a0": {"doc_hash": "b133c1872f5ef4e6cac21ba6cc8de76a4f15e1a69ddf93ce26eb755b0032467a"}, "0910a13c-7672-46b9-a4b9-1ca0e40ce112": {"doc_hash": "05f1673f426942c481aa176115ea5341e6804b22fe5d868ac621d4b181730acb"}, "0356d565-621a-4e5f-8568-babfd88426e2": {"doc_hash": "e9f0dd91e8616e8d25fe3a34ffeaaa588b139da6d088ada387f467a7237e3681"}, "1b0b6747-a405-4d9e-90d9-7a98cd6525f9": {"doc_hash": "25efc08d65dc2d97381e1992dc1f55295bc5330672359e0a203fc64a81ac5918"}, "aabb4c3d-fc0d-4bd9-b7a8-da002ca95d9c": {"doc_hash": "d19d6350ed69b7326d794b8f5a807982f193b2fc3a4d49511298fc184612d5a0"}}, "docstore/data": {"37bd2236-911c-4b08-accb-ef6b1f9ef905": {"__data__": {"text": "GLOBAL  \nEDITION\nComputer Networking\n A Top-Down Approach\n SEVENTH EDITION\nKurose \u2022 Ross\n\nDigital Resources for Students\nYour new textbook provides 12-month access to digital resources that may include VideoNotes, \ninteractive exercises, programming assignments, Wireshark labs, additional technical material, \nand more. Refer to the preface in the textbook for a detailed list of resources.\nFollow the instructions below to register for the Companion Website for Computer Networking: \nA Top-Down Approach , Seventh Edition.\n1. Go to www.pearsonglobaleditions.com/kurose\n2. Find the title of your textbook.\n3. Click Companion Website\n4.  Click Register and follow the on-screen instructions to create a login name and password.\nUse a coin to scratch of the coating and reveal your access code.\nDo not use a sharp knife or other sharp object as it may damage the code.\nUse the login name and password you created during registration to start using the  \ndigital resources that accompany your textbook.\nIMPORTANT:\nThis access code can only be used once. This subscription is valid for 12 months upon activation \nand is not transferrable. If the access code has already been revealed it may no longer be valid. \nFor technical support go to https://support.pearson.com/getsupport\nCOMPUTER \nNETWORKING\nA Top-Down Approach\nBoston Columbus Indianapolis New York San Francisco Hoboken\nAmsterdam Cape Town Dubai London Madrid Milan Munich Paris Montr\u00e9al Toronto\nDelhi Mexico City S\u00e3o Paulo Sydney Hong Kong Seoul Singapore Taipei TokyoSEVENTH EDITION\nGLOBAL EDITION\nJAMES F. K UROSE\nUniversity of Massachusetts, Amherst\nKEITH W. R OSS\nNYU and NYU Shanghai\nVice President, Editorial Director, ECS:   \nMarcia Horton\nAcquisitions Editor:  Matt Goldstein\nEditorial Assistant:  Kristy Alaura\nAcquisitions Editor, Global Editions:  Aditee Agarwal\nVice President of Marketing:  Christy Lesko\nDirector of Field Marketing:  Tim Galligan\nProduct Marketing Manager:  Bram Van Kempen\nField Marketing Manager:  Demetrius Hall\nMarketing Assistant:  Jon Bryant\nDirector of Product Management:  Erin Gregg\nTeam Lead, Program and Project Management:  \nScott Disanno\nProgram Manager:  Joanne Manning and Carole Snyder\nProject Manager:  Katrina Ostler, Ostler Editorial, Inc.Project Editor, Global Editions:  K.K. Neelakantan\nSenior Manufacturing Controller, Global \nEditions:  Kay Holman\nSenior Specialist, Program Planning and Support:  \nMaura Zaldivar-Garcia\nCover Designer:  Lumina Datamatics\nManager, Rights and Permissions:  Ben Ferrini\nProject Manager, Rights and Permissions:   \nJenny Hoffman, Aptara Corporation\nInventory Manager:  Ann Lam\nCover Image:  ISebyI/ Shutterstock.com\nMedia Project Manager:  Steve Wright\nMedia Production Manager, Global Editions:  \nVikram Kumar\nCredits and acknowledgments borrowed from other sources and reproduced, with  permission, in this textbook \nappear on appropriate page within text.\nPearson Education Limited\nEdinburgh Gate\nHarlow\nEssex CM20 2JE\nEngland\nand Associated Companies throughout the world\nVisit us on the World Wide Web at:\nwww.pearsonglobaleditions.com\n\u00a9 Pearson Education Limited 2017\nThe rights of James F. Kurose and Keith W. Ross to be identified as the authors of this work have been asserted by \nthem in accordance with the Copyright, Designs and Patents Act 1988.\nAuthorized adaptation from the United States edition, entitled Computer Networking: A Top-Down Approach, Seventh \nEdition, ISBN 978-0-13-359414-0, by James F. Kurose and Keith W. Ross published by Pearson Education \u00a9 2017.\nAll rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in \nany form or by any means, electronic,", "doc_id": "37bd2236-911c-4b08-accb-ef6b1f9ef905", "embedding": null, "doc_hash": "f3fa714c7d449c16e53e54bf2a374e0ad3db788947511c5a08aeae7908beea16", "extra_info": null, "node_info": {"start": 0, "end": 3680}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "3": "4581035e-2990-4f4f-8e1b-bed06d5448a4"}}, "__type__": "1"}, "4581035e-2990-4f4f-8e1b-bed06d5448a4": {"__data__": {"text": "CM20 2JE\nEngland\nand Associated Companies throughout the world\nVisit us on the World Wide Web at:\nwww.pearsonglobaleditions.com\n\u00a9 Pearson Education Limited 2017\nThe rights of James F. Kurose and Keith W. Ross to be identified as the authors of this work have been asserted by \nthem in accordance with the Copyright, Designs and Patents Act 1988.\nAuthorized adaptation from the United States edition, entitled Computer Networking: A Top-Down Approach, Seventh \nEdition, ISBN 978-0-13-359414-0, by James F. Kurose and Keith W. Ross published by Pearson Education \u00a9 2017.\nAll rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in \nany form or by any means, electronic, mechanical, photocopying, recording or otherwise, without either the prior \nwritten permission of the publisher or a license permitting restricted copying in the United Kingdom issued by the \nCopyright Licensing Agency Ltd, Saffron House, 6\u201310 Kirby Street, London EC1N 8TS.\nAll trademarks used herein are the property of their respective owners. The use of any trademark in this text does \nnot vest in the author or publisher any trademark ownership rights in such trademarks, nor does the use of such \ntrademarks imply any affiliation with or endorsement of this book by such owners.\nBritish Library Cataloguing-in-Publication Data\nA catalogue record for this book is available from the British Library\n10 9 8 7 6 5 4 3 2 1\nISBN 10: 1-292-15359-8\nISBN 13: 978-1-292-15359-9\nTypeset by Cenveo Publisher Services\nPrinted and bound in Malaysia.\n3About the Authors\nJim Kurose\nJim Kurose is a Distinguished University Professor of Computer Science at \nthe University of Massachusetts, Amherst. He is currently on leave from \nthe University of Massachusetts, serving as an Assistant Director at the US \nNational Science Foundation, where he leads the Directorate of Computer \nand Information Science and Engineering.\nDr. Kurose has received a number of recognitions for his educational activ -\nities including Outstanding Teacher Awards from the National Technological \nUniversity (eight times), the University of Massachusetts, and the Northeast \nAssociation of Graduate Schools. He received the IEEE Taylor Booth \nEducation Medal and was recognized for his leadership of Massachusetts\u2019 \nCommonwealth Information Technology Initiative. He has won several confer -\nence best paper awards and received the IEEE Infocom  Achievement Award \nand the ACM Sigcomm  Test of Time Award.\nDr. Kurose is a former Editor-in-Chief of IEEE Transactions on \nCommunications  and of IEEE/ACM Transactions on Networking . He has \nserved as Technical Program co-Chair for IEEE Infocom, ACM SIGCOMM, \nACM Internet Measurement Conference , and ACM SIGMETRICS . He is a \nFellow of the IEEE and the ACM. His research  interests include network proto -\ncols and architecture, network measurement, multimedia communication, and \nmodeling and performance  evaluation. He holds a PhD in Computer Science \nfrom Columbia University.\nKeith Ross\nKeith Ross is the Dean of Engineering and Computer Science at NYU \nShanghai and the Leonard J. Shustek Chair Professor in the Computer Science \nand Engineering Department at NYU. Previously he was at University of \nPennsylvania (13 years), Eurecom Institute (5 years) and Polytechnic University \n(10 years). He received a B.S.E.E from Tufts University, a M.S.E.E. from \nColumbia University, and a Ph.D. in Computer and Control Engineering from \nThe University of Michigan. Keith Ross is also the co-founder and original \nCEO of Wimba, which develops online multimedia applications for e-learning \nand was acquired by Blackboard in 2010.\nProfessor Ross\u2019s research interests are in privacy, social networks,  \npeer-to-peer networking, Internet measurement, content distribution networks, \nand stochastic modeling. He is an ACM Fellow, an IEEE Fellow, recipient ", "doc_id": "4581035e-2990-4f4f-8e1b-bed06d5448a4", "embedding": null, "doc_hash": "596de1ed0172cbdf8f7edeaea89873fb68db419951b92dc7197846c9d69d4e9a", "extra_info": null, "node_info": {"start": 3063, "end": 6957}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "37bd2236-911c-4b08-accb-ef6b1f9ef905", "3": "528fe30f-3a13-43f7-ae0a-37ce8b0208f2"}}, "__type__": "1"}, "528fe30f-3a13-43f7-ae0a-37ce8b0208f2": {"__data__": {"text": "Professor in the Computer Science \nand Engineering Department at NYU. Previously he was at University of \nPennsylvania (13 years), Eurecom Institute (5 years) and Polytechnic University \n(10 years). He received a B.S.E.E from Tufts University, a M.S.E.E. from \nColumbia University, and a Ph.D. in Computer and Control Engineering from \nThe University of Michigan. Keith Ross is also the co-founder and original \nCEO of Wimba, which develops online multimedia applications for e-learning \nand was acquired by Blackboard in 2010.\nProfessor Ross\u2019s research interests are in privacy, social networks,  \npeer-to-peer networking, Internet measurement, content distribution networks, \nand stochastic modeling. He is an ACM Fellow, an IEEE Fellow, recipient  \n4     ABOUT THE AUTHORS\nof the Infocom 2009 Best Paper Award, and recipient of 2011 and 2008 \nBest Paper Awards for Multimedia Communications (awarded by IEEE \nCommunications Society). He has served on numerous journal editorial boards \nand conference program committees, including IEEE/ACM Transactions on \nNetworking, ACM SIGCOMM, ACM CoNext, and ACM Internet Measurement \nConference . He also has served as an advisor to the Federal Trade Commission \non P2P file sharing.\nTo Julie and our three precious  \nones\u2014Chris, Charlie, and Nina  \nJFK\nA big THANKS to my professors, colleagues,  \nand students all over the world.\nKWR\nThis page intentionally left blank\nPreface\nWelcome to the seventh edition of Computer Networking: A Top-Down Approach.  \nSince the publication of the first edition 16 years ago, our book has been adopted \nfor use at many hundreds of colleges and universities, translated into 14 languages,  \nand used by over 100,000 students and practitioners worldwide. We\u2019ve heard from \nmany of these readers and have been overwhelmed by the  positive  response.\nWhat\u2019s New in the Seventh Edition?\nWe think one important reason for this success has been that our book continues to \noffer a fresh and timely approach to computer networking instruction. We\u2019ve made \nchanges in this seventh edition, but we\u2019ve also kept unchanged what we believe (and \nthe instructors and students who have used our book have confirmed) to be the most \nimportant aspects of this book: its top-down approach, its focus on the Internet and a \nmodern treatment of computer networking, its attention to both principles and prac -\ntice, and its accessible style and approach toward learning about computer network -\ning. Nevertheless, the seventh edition has been revised and updated substantially.\nLong-time readers of our book will notice that for the first time since this text \nwas published, we\u2019ve changed the organization of the chapters themselves. The net -\nwork layer, which had been previously covered in a single chapter, is now covered \nin Chapter 4 (which focuses on the so-called \u201cdata plane\u201d component of the net -\nwork layer) and Chapter 5 (which focuses on the network layer\u2019s \u201ccontrol plane\u201d). \nThis expanded coverage of the network layer reflects the swift rise in importance \nof software-defined networking (SDN), arguably the most important and exciting \nadvance in networking in decades. Although a relatively recent innovation, SDN \nhas been rapidly adopted in practice\u2014so much so that it\u2019s already hard to imagine \nan introduction to modern computer networking that doesn\u2019t cover SDN. The topic \nof network management, previously covered in Chapter 9, has now been folded into \nthe new Chapter 5. As always, we\u2019ve also updated many other sections of the text \nto reflect recent changes in the dynamic field of networking since the sixth edition. \nAs always, material that has been retired from the printed text can always be found \non this book\u2019s Companion Website. The most important updates are the following:\n\u2022\tChapter 1 has been updated to reflect the ever-growing reach and use of the \n Internet.\n\u2022\tChapter 2, which covers the application layer, has been significantly updated. \nWe\u2019ve removed the", "doc_id": "528fe30f-3a13-43f7-ae0a-37ce8b0208f2", "embedding": null, "doc_hash": "76cb5f3844f4bb06f370154b95343d5e821850b6e8ee96c59c7af9306c64135e", "extra_info": null, "node_info": {"start": 6932, "end": 10897}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "4581035e-2990-4f4f-8e1b-bed06d5448a4", "3": "945ad618-6119-4107-b8a8-eb0c64d57def"}}, "__type__": "1"}, "945ad618-6119-4107-b8a8-eb0c64d57def": {"__data__": {"text": "a relatively recent innovation, SDN \nhas been rapidly adopted in practice\u2014so much so that it\u2019s already hard to imagine \nan introduction to modern computer networking that doesn\u2019t cover SDN. The topic \nof network management, previously covered in Chapter 9, has now been folded into \nthe new Chapter 5. As always, we\u2019ve also updated many other sections of the text \nto reflect recent changes in the dynamic field of networking since the sixth edition. \nAs always, material that has been retired from the printed text can always be found \non this book\u2019s Companion Website. The most important updates are the following:\n\u2022\tChapter 1 has been updated to reflect the ever-growing reach and use of the \n Internet.\n\u2022\tChapter 2, which covers the application layer, has been significantly updated. \nWe\u2019ve removed the material on the FTP protocol and distributed hash tables to \n7\n8     PREFACE\nmake room for a new section on application-level video streaming and  content \ndistribution networks, together with Netflix and YouTube case studies. The \n socket programming sections have been updated from Python 2 to Python 3.\n\u2022\tChapter 3, which covers the transport layer, has been modestly updated. The \n material on asynchronous transport mode (ATM) networks has been replaced by \nmore modern material on the Internet\u2019s explicit congestion notification (ECN), \nwhich teaches the same principles.\n\u2022\tChapter 4 covers the \u201cdata plane\u201d component of the network layer\u2014the per-router  \nforwarding function that determine how a packet arriving on one of a router\u2019s \ninput links is forwarded to one of that router\u2019s output links. We updated the mate -\nrial on traditional Internet forwarding found in all previous editions, and added \nmaterial on packet scheduling. We\u2019ve also added a new section on generalized \nforwarding, as practiced in SDN. There are also numerous updates throughout the \nchapter. Material on multicast and broadcast communication has been removed to \nmake way for the new material.\n\u2022\tIn Chapter 5, we cover the control plane functions of the network layer\u2014the \n network-wide  logic that controls how a datagram is routed along an end-to-end \npath of routers from the source host to the destination host. As in previous  editions, \nwe cover routing algorithms, as well as routing protocols (with an updated treat -\nment of BGP) used in today\u2019s Internet. We\u2019ve added a significant new section \non the SDN control plane, where routing and other functions are implemented in \nso-called SDN controllers.\n\u2022\tChapter 6, which now covers the link layer, has an updated treatment of Ethernet, \nand of data center networking.\n\u2022\tChapter 7, which covers wireless and mobile networking, contains updated \n material on 802.11 (so-called \u201cWiFi) networks and cellular networks, including \n4G and LTE.\n\u2022\tChapter 8, which covers network security and was extensively updated in the \nsixth edition, has only modest updates in this seventh edition.\n\u2022\tChapter 9, on multimedia networking, is now slightly \u201cthinner\u201d than in the sixth edi -\ntion, as material on video streaming and content distribution networks has been \nmoved to Chapter 2, and material on packet scheduling has been incorporated \ninto Chapter 4.\n\u2022\tSignificant new material involving end-of-chapter problems has been added. As \nwith all previous editions, homework problems have been revised, added, and \nremoved.\nAs always, our aim in creating this new edition of our book is to continue to \nprovide a focused and modern treatment of computer networking, emphasizing both \nprinciples and practice.\nPREFACE      9\nAudience\nThis textbook is for a first course on computer networking. It can be used in both \ncomputer science and electrical engineering departments. In terms of programming \nlanguages, the book assumes only that the student has experience with C, C++, Java, \nor Python (and even then only in a few places). Although this book is more precise \nand analytical than many other introductory computer networking", "doc_id": "945ad618-6119-4107-b8a8-eb0c64d57def", "embedding": null, "doc_hash": "4b11070ee654def9709516d9ceef7e63aa32c71555c80696425475bec097fcff", "extra_info": null, "node_info": {"start": 10863, "end": 14831}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "528fe30f-3a13-43f7-ae0a-37ce8b0208f2", "3": "51187fbd-9b8e-4d41-9669-16a9a0faf3b4"}}, "__type__": "1"}, "51187fbd-9b8e-4d41-9669-16a9a0faf3b4": {"__data__": {"text": "been incorporated \ninto Chapter 4.\n\u2022\tSignificant new material involving end-of-chapter problems has been added. As \nwith all previous editions, homework problems have been revised, added, and \nremoved.\nAs always, our aim in creating this new edition of our book is to continue to \nprovide a focused and modern treatment of computer networking, emphasizing both \nprinciples and practice.\nPREFACE      9\nAudience\nThis textbook is for a first course on computer networking. It can be used in both \ncomputer science and electrical engineering departments. In terms of programming \nlanguages, the book assumes only that the student has experience with C, C++, Java, \nor Python (and even then only in a few places). Although this book is more precise \nand analytical than many other introductory computer networking texts, it rarely uses \nany mathematical concepts that are not taught in high school. We have made a delib -\nerate effort to avoid using any advanced calculus, probability, or stochastic process \nconcepts (although we\u2019ve included some homework problems for students with this \nadvanced background). The book is therefore appropriate for undergraduate courses \nand for first-year graduate courses. It should also be useful to practitioners in the \ntelecommunications industry.\nWhat Is Unique About This Textbook?\nThe subject of computer networking is enormously complex, involving many con -\ncepts, protocols, and technologies that are woven together in an intricate manner. \nTo cope with this scope and complexity, many computer networking texts are often \norganized around the \u201clayers\u201d of a network architecture. With a layered organization, \nstudents can see through the complexity of computer networking\u2014they learn about \nthe distinct concepts and protocols in one part of the architecture while seeing the \nbig picture of how all parts fit together. From a pedagogical perspective, our personal \nexperience has been that such a layered approach indeed works well. Nevertheless, \nwe have found that the traditional approach of teaching\u2014bottom up; that is, from the \nphysical layer towards the application layer\u2014is not the best approach for a modern \ncourse on computer networking.\nA Top-Down Approach\nOur book broke new ground 16 years ago by treating networking in a top-down \n manner\u2014that is, by beginning at the application layer and working its way down \ntoward the physical layer. The feedback we received from teachers and students alike \nhave confirmed that this top-down approach has many advantages and does indeed \nwork well pedagogically. First, it places emphasis on the application layer (a \u201chigh \ngrowth area\u201d in networking). Indeed, many of the recent revolutions in  computer \nnetworking\u2014including the Web, peer-to-peer file sharing, and media streaming\u2014\nhave taken place at the application layer. An early emphasis on application-layer \nissues differs from the approaches taken in most other texts, which have only a \nsmall amount of material on network applications, their requirements, application-\nlayer paradigms (e.g., client-server and peer-to-peer), and application programming \n10     PREFACE\n interfaces.  Second, our experience as instructors (and that of many instructors who \nhave used this text) has been that teaching networking applications near the begin -\nning of the course is a powerful motivational tool. Students are thrilled to learn about \nhow networking applications work\u2014applications such as e-mail and the Web, which \nmost students use on a daily basis. Once a student understands the applications, the \nstudent can then understand the network services needed to support these applica -\ntions. The student can then, in turn, examine the various ways in which such services \nmight be provided and implemented in the lower layers. Covering applications early \nthus provides motivation for the remainder of the text.\nThird, a top-down approach enables instructors to introduce network applica -\ntion development at an early stage. Students not only see how popular applica -\ntions and protocols work, but also learn how easy it is to create their own network \n applications and application-level", "doc_id": "51187fbd-9b8e-4d41-9669-16a9a0faf3b4", "embedding": null, "doc_hash": "411b12ff5a76205c7b3d78b91a15a367e674daaaa7bc5d49174faefd1b61fe29", "extra_info": null, "node_info": {"start": 14825, "end": 18972}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "945ad618-6119-4107-b8a8-eb0c64d57def", "3": "f1ca778a-d93c-4b59-87fd-60dc4780496e"}}, "__type__": "1"}, "f1ca778a-d93c-4b59-87fd-60dc4780496e": {"__data__": {"text": "powerful motivational tool. Students are thrilled to learn about \nhow networking applications work\u2014applications such as e-mail and the Web, which \nmost students use on a daily basis. Once a student understands the applications, the \nstudent can then understand the network services needed to support these applica -\ntions. The student can then, in turn, examine the various ways in which such services \nmight be provided and implemented in the lower layers. Covering applications early \nthus provides motivation for the remainder of the text.\nThird, a top-down approach enables instructors to introduce network applica -\ntion development at an early stage. Students not only see how popular applica -\ntions and protocols work, but also learn how easy it is to create their own network \n applications and application-level protocols. With the top-down approach, students \nget early  exposure to the notions of socket programming, service models, and \n protocols\u2014important concepts that resurface in all subsequent layers. By providing \nsocket programming examples in Python, we highlight the central ideas without \nconfusing students with complex code. Undergraduates in electrical engineering \nand computer science should not have difficulty following the Python code.\nAn Internet Focus\nAlthough we dropped the phrase \u201cFeaturing the Internet\u201d from the title of this book \nwith the fourth edition, this doesn\u2019t mean that we dropped our focus on the Internet. \nIndeed, nothing could be further from the case! Instead, since the Internet has become \nso pervasive, we felt that any networking textbook must have a significant focus on \nthe Internet, and thus this phrase was somewhat unnecessary. We continue to use the \nInternet\u2019s architecture and protocols as primary vehicles for studying fundamental \ncomputer networking concepts. Of course, we also include concepts and protocols \nfrom other network architectures. But the spotlight is clearly on the Internet, a fact \nreflected in our organizing the book around the Internet\u2019s five-layer architecture: the \napplication, transport, network, link, and physical layers.\nAnother benefit of spotlighting the Internet is that most computer science and \nelectrical engineering students are eager to learn about the Internet and its protocols. \nThey know that the Internet has been a revolutionary and disruptive technology and \ncan see that it is profoundly changing our world. Given the enormous relevance of \nthe Internet, students are naturally curious about what is \u201cunder the hood.\u201d Thus, it \nis easy for an instructor to get students excited about basic principles when using the \nInternet as the guiding focus.\nTeaching Networking Principles\nTwo of the unique features of the book\u2014its top-down approach and its focus on the \nInternet\u2014have appeared in the titles of our book. If we could have squeezed a third  \nPREFACE      11\nphrase into the subtitle, it would have contained the word principles.  The field of \nnetworking is now mature enough that a number of fundamentally important issues \ncan be identified. For example, in the transport layer, the fundamental issues include \nreliable communication over an unreliable network layer, connection establishment/ \nteardown and handshaking, congestion and flow control, and multiplexing. Three fun -\ndamentally important network-layer issues are determining \u201cgood\u201d paths between two \nrouters, interconnecting a large number of heterogeneous networks, and managing the \ncomplexity of a modern network. In the link layer, a fundamental problem is sharing a \nmultiple access channel. In network security, techniques for providing confidentiality, \nauthentication, and message integrity are all based on cryptographic fundamentals. \nThis text identifies fundamental networking issues and studies approaches towards \naddressing these issues. The student learning these principles will gain knowledge \nwith a long \u201cshelf life\u201d\u2014long after today\u2019s network standards and protocols have \nbecome obsolete, the principles they embody will remain important and relevant. We \nbelieve that the combination of using the Internet to get the student\u2019s foot in the door \nand then emphasizing fundamental issues and solution approaches will allow the stu -\ndent to quickly understand just", "doc_id": "f1ca778a-d93c-4b59-87fd-60dc4780496e", "embedding": null, "doc_hash": "147ebd9485543ed71c303a752b8374ca71e5db05199ae3f316778f5e8f418fe9", "extra_info": null, "node_info": {"start": 18961, "end": 23232}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "51187fbd-9b8e-4d41-9669-16a9a0faf3b4", "3": "7e574ab9-43e5-45ad-a9e2-e9fac0a090a7"}}, "__type__": "1"}, "7e574ab9-43e5-45ad-a9e2-e9fac0a090a7": {"__data__": {"text": "large number of heterogeneous networks, and managing the \ncomplexity of a modern network. In the link layer, a fundamental problem is sharing a \nmultiple access channel. In network security, techniques for providing confidentiality, \nauthentication, and message integrity are all based on cryptographic fundamentals. \nThis text identifies fundamental networking issues and studies approaches towards \naddressing these issues. The student learning these principles will gain knowledge \nwith a long \u201cshelf life\u201d\u2014long after today\u2019s network standards and protocols have \nbecome obsolete, the principles they embody will remain important and relevant. We \nbelieve that the combination of using the Internet to get the student\u2019s foot in the door \nand then emphasizing fundamental issues and solution approaches will allow the stu -\ndent to quickly understand just about any networking technology.\nThe Website\nEach new copy of this textbook includes twelve months of access to a Companion \n Website for all book readers at http://www.pearsonglobaleditions.com/kurose, which \nincludes:\n\u2022\tInteractive learning material.  The book\u2019s Companion Website contains \n VideoNotes\u2014video presentations of important topics throughout the book \ndone by the authors, as well as walkthroughs of solutions to problems similar to \nthose at the end of the chapter. We\u2019ve seeded the Web site with VideoNotes and \n online\u00a0problems for chapters 1 through 5 and will continue to actively add and \nupdate this material over time. As in earlier editions, the Web site contains the \ninteractive Java applets that animate many key networking concepts. The site also \nhas interactive quizzes that permit students to check their basic understanding of \nthe subject matter. Professors can integrate these interactive features into their \nlectures or use them as mini labs.\n\u2022\tAdditional technical material.  As we have added new material in each edition of \nour book, we\u2019ve had to remove coverage of some existing topics to keep the book \nat manageable length. For example, to make room for the new  material in this \n edition, we\u2019ve removed material on FTP, distributed hash tables, and  multicasting, \nMaterial that appeared in earlier editions of the text is still of  interest, and thus can \nbe found on the book\u2019s Web site.\n\u2022\tProgramming assignments.  The Web site also provides a number of detailed \nprogramming assignments, which include building a multithreaded Web  server, \n12     PREFACE\nbuilding an e-mail client with a GUI interface, programming the sender and \n receiver sides of a reliable data transport protocol, programming a distributed \nrouting algorithm, and more.\n\u2022\tWireshark labs.  One\u2019s understanding of network protocols can be greatly \n deepened by seeing them in action. The Web site provides numerous Wireshark \nassignments that enable students to actually observe the sequence of messages \nexchanged between two protocol entities. The Web site includes separate Wire -\nshark labs on HTTP, DNS, TCP, UDP, IP, ICMP, Ethernet, ARP, WiFi, SSL, and  \non tracing all protocols involved in satisfying a request to fetch a Web page. We\u2019ll \ncontinue to add new labs over time.\nIn addition to the Companion Website, the authors maintain a public Web site, \nhttp://gaia.cs.umass.edu/kurose_ross/interactive, containing interactive exercises \nthat create (and present solutions for) problems similar to selected end-of-chapter \nproblems. Since students can generate (and view solutions for) an unlimited number \nof similar problem instances, they can work until the material is truly mastered.\nPedagogical Features\nWe have each been teaching computer networking for more than 30 years. Together, \nwe bring more than 60 years of teaching experience to this text, during which time \nwe have taught many thousands of students. We have also been active researchers \nin computer networking during this time. (In fact, Jim and Keith first met each other \nas master\u2019s students in a computer networking course taught by Mischa Schwartz \nin 1979 at Columbia University.)", "doc_id": "7e574ab9-43e5-45ad-a9e2-e9fac0a090a7", "embedding": null, "doc_hash": "1a5fb4f5439f3c40f63d259b4b3680e1eb39baef79be234273c68d67bd71edd9", "extra_info": null, "node_info": {"start": 23194, "end": 27234}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "f1ca778a-d93c-4b59-87fd-60dc4780496e", "3": "7c4ed315-37b0-4452-b3da-091b549063fb"}}, "__type__": "1"}, "7c4ed315-37b0-4452-b3da-091b549063fb": {"__data__": {"text": "containing interactive exercises \nthat create (and present solutions for) problems similar to selected end-of-chapter \nproblems. Since students can generate (and view solutions for) an unlimited number \nof similar problem instances, they can work until the material is truly mastered.\nPedagogical Features\nWe have each been teaching computer networking for more than 30 years. Together, \nwe bring more than 60 years of teaching experience to this text, during which time \nwe have taught many thousands of students. We have also been active researchers \nin computer networking during this time. (In fact, Jim and Keith first met each other \nas master\u2019s students in a computer networking course taught by Mischa Schwartz \nin 1979 at Columbia University.) We think all this gives us a good perspective on \nwhere networking has been and where it is likely to go in the future. Nevertheless, \nwe have resisted temptations to bias the material in this book towards our own pet \nresearch projects. We figure you can visit our personal Web sites if you are interested \nin our research. Thus, this book is about modern computer networking\u2014it is about \ncontemporary protocols and technologies as well as the underlying principles behind \nthese protocols and technologies. We also believe that learning (and teaching!) about \nnetworking can be fun. A sense of humor, use of analogies, and real-world examples \nin this book will hopefully make this material more fun.\nSupplements for Instructors\nWe provide a complete supplements package to aid instructors in teaching this \ncourse. This material can be accessed from Pearson\u2019s Instructor Resource Center  \n(http://www.pearsonglobaleditions.com/kurose). Visit the Instructor Resource Cen -\nter for  information about accessing these instructor\u2019s supplements.\nPREFACE      13\n\u2022\tPowerPoint\u00ae slides.  We provide PowerPoint slides for all nine chapters. The \nslides have been completely updated with this seventh edition. The slides cover \neach chapter in detail. They use graphics and animations (rather than relying only \non monotonous text bullets) to make the slides interesting and visually appealing. \nWe provide the original PowerPoint slides so you can customize them to best suit \nyour own teaching needs. Some of these slides have been contributed by other \ninstructors who have taught from our book.\n\u2022\tHomework solutions.  We provide a solutions manual for the homework prob -\nlems in the text, programming assignments, and Wireshark labs. As noted \n earlier,\u00a0we\u2019ve introduced many new homework problems in the first six chapters \nof the book.\nChapter Dependencies\nThe first chapter of this text presents a self-contained overview of computer net -\nworking. Introducing many key concepts and terminology, this chapter sets the stage \nfor the rest of the book. All of the other chapters directly depend on this first chapter. \nAfter completing Chapter 1, we recommend instructors cover Chapters 2 through 6 \nin sequence, following our top-down philosophy. Each of these five chapters lever -\nages material from the preceding chapters. After completing the first six chapters, \nthe instructor has quite a bit of flexibility. There are no interdependencies among \nthe last three chapters, so they can be taught in any order. However, each of the last \nthree chapters depends on the material in the first six chapters. Many instructors first \nteach the first six chapters and then teach one of the last three chapters for \u201cdessert.\u201d\nOne Final Note: We\u2019d Love to Hear from You\nWe encourage students and instructors to e-mail us with any comments they might \nhave about our book. It\u2019s been wonderful for us to hear from so many instructors \nand students from around the world about our first five editions. We\u2019ve incorporated \nmany of these suggestions into later editions of the book. We also encourage instruc -\ntors to send us new homework problems (and solutions) that would complement the \ncurrent homework problems. We\u2019ll post these on the instructor-only portion of the \nWeb site. We also", "doc_id": "7c4ed315-37b0-4452-b3da-091b549063fb", "embedding": null, "doc_hash": "354ed88adde329e537d8c06fe17fd25735d1ac42772a6191b707b8c9ac8f82bc", "extra_info": null, "node_info": {"start": 27331, "end": 31365}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "7e574ab9-43e5-45ad-a9e2-e9fac0a090a7", "3": "1af86495-ba94-43e3-a53d-a3c335a88549"}}, "__type__": "1"}, "1af86495-ba94-43e3-a53d-a3c335a88549": {"__data__": {"text": "chapters depends on the material in the first six chapters. Many instructors first \nteach the first six chapters and then teach one of the last three chapters for \u201cdessert.\u201d\nOne Final Note: We\u2019d Love to Hear from You\nWe encourage students and instructors to e-mail us with any comments they might \nhave about our book. It\u2019s been wonderful for us to hear from so many instructors \nand students from around the world about our first five editions. We\u2019ve incorporated \nmany of these suggestions into later editions of the book. We also encourage instruc -\ntors to send us new homework problems (and solutions) that would complement the \ncurrent homework problems. We\u2019ll post these on the instructor-only portion of the \nWeb site. We also encourage instructors and students to create new Java applets that \nillustrate the concepts and protocols in this book. If you have an applet that you think \nwould be appropriate for this text, please submit it to us. If the applet (including nota -\ntion and terminology) is appropriate, we\u2019ll be happy to include it on the text\u2019s Web \nsite, with an appropriate reference to the applet\u2019s authors.\nSo, as the saying goes, \u201cKeep those cards and letters coming!\u201d Seriously, please \ndo continue to send us interesting URLs, point out typos, disagree with any of our \n14     PREFACE\nclaims, and tell us what works and what doesn\u2019t work. Tell us what you think should \nor shouldn\u2019t be included in the next edition. Send your e-mail to kurose@cs.umass  \n.edu and keithwross@nyu.edu.\nAcknowledgments\nSince we began writing this book in 1996, many people have given us invaluable \nhelp and have been influential in shaping our thoughts on how to best organize and \nteach a networking course. We want to say A BIG THANKS to everyone who has \nhelped us from the earliest first drafts of this book, up to this seventh edition. We are \nalso very thankful to the many hundreds of readers from around the world\u2014students, \nfaculty, practitioners\u2014who have sent us thoughts and comments on earlier editions \nof the book and suggestions for future editions of the book. Special thanks go out to:\nAl Aho (Columbia University)\nHisham Al-Mubaid (University of Houston-Clear Lake)\nPratima Akkunoor (Arizona State University)\nPaul Amer (University of Delaware)\nShamiul Azom (Arizona State University)\nLichun Bao (University of California at Irvine)\nPaul Barford (University of Wisconsin)\nBobby Bhattacharjee (University of Maryland)\nSteven Bellovin (Columbia University)\nPravin Bhagwat (Wibhu)\nSupratik Bhattacharyya (previously at Sprint)\nErnst Biersack (Eur\u00e9com Institute)\nShahid Bokhari (University of Engineering & Technology, Lahore)\nJean Bolot (Technicolor Research)\nDaniel Brushteyn (former University of Pennsylvania student)\nKen Calvert (University of Kentucky)\nEvandro Cantu (Federal University of Santa Catarina)\nJeff Case (SNMP Research International)\nJeff Chaltas (Sprint)\nVinton Cerf (Google)\nByung Kyu Choi (Michigan Technological University)\nBram Cohen (BitTorrent, Inc.)\nConstantine Coutras (Pace University)\nJohn Daigle (University of Mississippi)\nEdmundo A. de Souza e Silva (Federal University of Rio de Janeiro)\nPhilippe Decuetos (Eur\u00e9com Institute)\nChristophe Diot (Technicolor Research)\nPrithula Dhunghel (Akamai)\nPREFACE      15\nDeborah Estrin (University of California, Los Angeles)\nMichalis Faloutsos (University of California at Riverside)\nWu-chi Feng (Oregon Graduate Institute)\nSally Floyd (ICIR, University of California at Berkeley)\nPaul Francis (Max Planck Institute)\nDavid Fullager (Netflix)\nLixin Gao", "doc_id": "1af86495-ba94-43e3-a53d-a3c335a88549", "embedding": null, "doc_hash": "6872f00452a6dcf805b2a5e309c8614be9009352bf584f3c223e84cf3a7838b2", "extra_info": null, "node_info": {"start": 31392, "end": 34937}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "7c4ed315-37b0-4452-b3da-091b549063fb", "3": "d5d95e2e-dcd7-4a57-9b8f-b7788b78f38f"}}, "__type__": "1"}, "d5d95e2e-dcd7-4a57-9b8f-b7788b78f38f": {"__data__": {"text": "Kyu Choi (Michigan Technological University)\nBram Cohen (BitTorrent, Inc.)\nConstantine Coutras (Pace University)\nJohn Daigle (University of Mississippi)\nEdmundo A. de Souza e Silva (Federal University of Rio de Janeiro)\nPhilippe Decuetos (Eur\u00e9com Institute)\nChristophe Diot (Technicolor Research)\nPrithula Dhunghel (Akamai)\nPREFACE      15\nDeborah Estrin (University of California, Los Angeles)\nMichalis Faloutsos (University of California at Riverside)\nWu-chi Feng (Oregon Graduate Institute)\nSally Floyd (ICIR, University of California at Berkeley)\nPaul Francis (Max Planck Institute)\nDavid Fullager (Netflix)\nLixin Gao (University of Massachusetts)\nJJ Garcia-Luna-Aceves (University of California at Santa Cruz)\nMario Gerla (University of California at Los Angeles)\nDavid Goodman (NYU-Poly)\nYang Guo (Alcatel/Lucent Bell Labs)\nTim Griffin (Cambridge University)\nMax Hailperin (Gustavus Adolphus College)\nBruce Harvey (Florida A&M University, Florida State University)\nCarl Hauser (Washington State University)\nRachelle Heller (George Washington University)\nPhillipp Hoschka (INRIA/W3C)\nWen Hsin (Park University)\nAlbert Huang (former University of Pennsylvania student)\nCheng Huang (Microsoft Research)\nEsther A. Hughes (Virginia Commonwealth University)\nVan Jacobson (Xerox PARC)\nPinak Jain (former NYU-Poly student)\nJobin James (University of California at Riverside)\nSugih Jamin (University of Michigan)\nShivkumar Kalyanaraman (IBM Research, India)\nJussi Kangasharju (University of Helsinki)\nSneha Kasera (University of Utah)\nParviz Kermani (formerly of IBM Research)\nHyojin Kim (former University of Pennsylvania student)\nLeonard Kleinrock (University of California at Los Angeles)\nDavid Kotz (Dartmouth College)\nBeshan Kulapala (Arizona State University)\nRakesh Kumar (Bloomberg)\nMiguel A. Labrador (University of South Florida)\nSimon Lam (University of Texas)\nSteve Lai (Ohio State University)\nTom LaPorta (Penn State University)\nTim-Berners Lee (World Wide Web Consortium)\nArnaud Legout (INRIA)\nLee Leitner (Drexel University)\nBrian Levine (University of Massachusetts)\nChunchun Li (former NYU-Poly student)\n16     PREFACE\nYong Liu (NYU-Poly)\nWilliam Liang (former University of Pennsylvania student)\nWillis Marti (Texas A&M University)\nNick McKeown (Stanford University)\nJosh McKinzie (Park University)\nDeep Medhi (University of Missouri, Kansas City)\nBob Metcalfe (International Data Group)\nSue Moon (KAIST)\nJenni Moyer (Comcast)\nErich Nahum (IBM Research)\nChristos Papadopoulos (Colorado Sate University)\nCraig Partridge (BBN Technologies)\nRadia Perlman (Intel)\nJitendra Padhye (Microsoft Research)\nVern Paxson (University of California at Berkeley)\nKevin Phillips (Sprint)\nGeorge Polyzos (Athens University of Economics and Business)\nSriram Rajagopalan (Arizona State University)\nRamachandran Ramjee (Microsoft Research)\nKen Reek (Rochester Institute of Technology)\nMartin Reisslein (Arizona State University)\nJennifer Rexford (Princeton University)\nLeon Reznik (Rochester Institute of Technology)\nPablo Rodrigez (Telefonica)\nSumit Roy (University of Washington)\nDan Rubenstein (Columbia University)\nAvi Rubin (Johns Hopkins University)\nDouglas Salane (John Jay College)\nDespina Saparilla (Cisco Systems)\nJohn Schanz (Comcast)\nHenning Schulzrinne (Columbia University)\nMischa Schwartz (Columbia University)\nArdash Sethi (University of", "doc_id": "d5d95e2e-dcd7-4a57-9b8f-b7788b78f38f", "embedding": null, "doc_hash": "8f764b5d040840845986097f3f988d727121f50c8c84db4bdbe1b78e2f52d38b", "extra_info": null, "node_info": {"start": 35001, "end": 38349}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "1af86495-ba94-43e3-a53d-a3c335a88549", "3": "fb498b95-d043-4828-a02e-fc28bc68f1c8"}}, "__type__": "1"}, "fb498b95-d043-4828-a02e-fc28bc68f1c8": {"__data__": {"text": "Phillips (Sprint)\nGeorge Polyzos (Athens University of Economics and Business)\nSriram Rajagopalan (Arizona State University)\nRamachandran Ramjee (Microsoft Research)\nKen Reek (Rochester Institute of Technology)\nMartin Reisslein (Arizona State University)\nJennifer Rexford (Princeton University)\nLeon Reznik (Rochester Institute of Technology)\nPablo Rodrigez (Telefonica)\nSumit Roy (University of Washington)\nDan Rubenstein (Columbia University)\nAvi Rubin (Johns Hopkins University)\nDouglas Salane (John Jay College)\nDespina Saparilla (Cisco Systems)\nJohn Schanz (Comcast)\nHenning Schulzrinne (Columbia University)\nMischa Schwartz (Columbia University)\nArdash Sethi (University of Delaware)\nHarish Sethu (Drexel University)\nK. Sam Shanmugan (University of Kansas)\nPrashant Shenoy (University of Massachusetts)\nClay Shields (Georgetown University)\nSubin Shrestra (University of Pennsylvania)\nBojie Shu (former NYU-Poly student)\nMihail L. Sichitiu (NC State University)\nPeter Steenkiste (Carnegie Mellon University)\nTatsuya Suda (University of California at Irvine)\nKin Sun Tam (State University of New York at Albany)\nPREFACE      17\nDon Towsley (University of Massachusetts)\nDavid Turner (California State University, San Bernardino)\nNitin Vaidya (University of Illinois)\nMichele Weigle (Clemson University)\nDavid Wetherall (University of Washington)\nIra Winston (University of Pennsylvania)\nDi Wu (Sun Yat-sen University)\nShirley Wynn (NYU-Poly)\nRaj Yavatkar (Intel)\nYechiam Yemini (Columbia University)\nDian Yu (NYU Shanghai)\nMing Yu (State University of New York at Binghamton)\nEllen Zegura (Georgia Institute of Technology)\nHonggang Zhang (Suffolk University)\nHui Zhang (Carnegie Mellon University)\nLixia Zhang (University of California at Los Angeles)\nMeng Zhang (former NYU-Poly student)\nShuchun Zhang (former University of Pennsylvania student)\nXiaodong Zhang (Ohio State University)\nZhiLi Zhang (University of Minnesota)\nPhil Zimmermann (independent consultant)\nMike Zink (University of Massachusetts)\nCliff C. Zou (University of Central Florida)\nWe also want to thank the entire Pearson team\u2014in particular, Matt Goldstein and \nJoanne Manning\u2014who have done an absolutely outstanding job on this seventh \n edition (and who have put up with two very finicky authors who seem congenitally \n unable to meet deadlines!). Thanks also to our artists, Janet Theurer and Patrice \nRossi Calkin, for their work on the beautiful figures in this and earlier editions of \nour book, and to Katie Ostler and her team at Cenveo for their wonderful production \nwork on this edition. Finally, a most special thanks go to our previous two editors \nat  Addison-Wesley\u2014Michael Hirsch and Susan Hartman. This book would not be \nwhat it is (and may well not have been at all) without their graceful management, \nconstant encouragement, nearly infinite patience, good humor, and perseverance.\n18     PREFACE\nAcknowledgments for the Global Edition\nPearson would like to thank and acknowledge the following people for their \ncontributions to the Global Edition.\nContributors  \nMario De Francesco (Aalto University)\nReviewers\nArif Ahmed (National Institute of Technology Silchar)\nKaushik Goswami (St. Xavier\u2019s College Kolkata)\nMoumita Mitra Manna (Bangabasi College)\nChapter 1 Computer Networks and the Internet 29\n1.1 What Is the Internet? 30\n1.1.1 A Nuts-and-Bolts Description 30\n1.1.2 A Services Description 33\n1.1.3 What Is a Protocol? 35\n1.2 The Network Edge", "doc_id": "fb498b95-d043-4828-a02e-fc28bc68f1c8", "embedding": null, "doc_hash": "1fe81b3d846a55c6a59e6817e5cdfcf0454392d09c2f19bef7c519e8c0fbfc04", "extra_info": null, "node_info": {"start": 38286, "end": 41728}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "d5d95e2e-dcd7-4a57-9b8f-b7788b78f38f", "3": "1a0973d8-6604-4b72-884a-a74900f2ebc7"}}, "__type__": "1"}, "1a0973d8-6604-4b72-884a-a74900f2ebc7": {"__data__": {"text": "encouragement, nearly infinite patience, good humor, and perseverance.\n18     PREFACE\nAcknowledgments for the Global Edition\nPearson would like to thank and acknowledge the following people for their \ncontributions to the Global Edition.\nContributors  \nMario De Francesco (Aalto University)\nReviewers\nArif Ahmed (National Institute of Technology Silchar)\nKaushik Goswami (St. Xavier\u2019s College Kolkata)\nMoumita Mitra Manna (Bangabasi College)\nChapter 1 Computer Networks and the Internet 29\n1.1 What Is the Internet? 30\n1.1.1 A Nuts-and-Bolts Description 30\n1.1.2 A Services Description 33\n1.1.3 What Is a Protocol? 35\n1.2 The Network Edge 37\n1.2.1 Access Networks 40\n1.2.2 Physical Media 46\n1.3 The Network Core 49\n1.3.1 Packet Switching 51\n1.3.2 Circuit Switching 55\n1.3.3 A Network of Networks 59\n1.4 Delay, Loss, and Throughput in Packet-Switched Networks 63\n1.4.1 Overview of Delay in Packet-Switched Networks 63\n1.4.2 Queuing Delay and Packet Loss 67\n1.4.3 End-to-End Delay 69\n1.4.4 Throughput in Computer Networks 71\n1.5 Protocol Layers and Their Service Models 75\n1.5.1 Layered Architecture 75\n1.5.2 Encapsulation 81\n1.6 Networks Under Attack 83\n1.7 History of Computer Networking and the Internet 87\n1.7.1 The Development of Packet Switching: 1961\u20131972 87\n1.7.2 Proprietary Networks and Internetworking: 1972\u20131980 88\n1.7.3 A Proliferation of Networks: 1980\u20131990 90\n1.7.4 The Internet Explosion: The 1990s 91\n1.7.5 The New Millennium 92\n1.8 Summary 93\nHomework Problems and Questions 95\nWireshark Lab 105\nInterview: Leonard Kleinrock  107Table of Contents\n19\n20     TABLE OF CONTENTS\nChapter 2 Application Layer 111\n2.1 Principles of Network Applications 112\n2.1.1 Network Application Architectures 114\n2.1.2 Processes Communicating 116\n2.1.3 Transport Services Available to Applications 118\n2.1.4 Transport Services Provided by the Internet 121\n2.1.5 Application-Layer Protocols 124\n2.1.6 Network Applications Covered in This Book 125\n2.2 The Web and HTTP 126\n2.2.1 Overview of HTTP 126\n2.2.2 Non-Persistent and Persistent Connections 128\n2.2.3 HTTP Message Format 131\n2.2.4 User-Server Interaction: Cookies 136\n2.2.5 Web Caching 138\n2.3 Electronic Mail in the Internet 144\n2.3.1 SMTP 146\n2.3.2 Comparison with HTTP 149\n2.3.3 Mail Message Formats 149\n2.3.4 Mail Access Protocols 150\n2.4 DNS\u2014The Internet\u2019s Directory Service 154\n2.4.1 Services Provided by DNS 155\n2.4.2 Overview of How DNS Works 157\n2.4.3 DNS Records and Messages 163\n2.5 Peer-to-Peer Applications 168\n2.5.1 P2P File Distribution 168\n2.6 Video Streaming and Content Distribution Networks 175\n2.6.1 Internet Video 176\n2.6.2 HTTP Streaming and DASH 176\n2.6.3 Content Distribution Networks 177\n2.6.4 Case Studies: Netflix, YouTube, and Kankan 181\n2.7 Socket Programming: Creating Network Applications 185\n2.7.1 Socket Programming with UDP 187\n2.7.2 Socket Programming with TCP 192\n2.8 Summary 198\nHomework Problems and Questions 199\nSocket Programming Assignments 208\nWireshark Labs: HTTP, DNS 210\nInterview: Marc Andreessen 212\nTABLE OF CONTENTS      21\nChapter 3 Transport Layer 215\n3.1 Introduction and Transport-Layer Services 216\n3.1.1 Relationship Between Transport and Network Layers", "doc_id": "1a0973d8-6604-4b72-884a-a74900f2ebc7", "embedding": null, "doc_hash": "1624d90012ce0ac05e2de61e7e9a5a294a36d10ddac6a5458e6ee5ec4a16517c", "extra_info": null, "node_info": {"start": 41788, "end": 44949}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "fb498b95-d043-4828-a02e-fc28bc68f1c8", "3": "f031ae10-742d-432d-8c64-1d4bbe5cd2a1"}}, "__type__": "1"}, "f031ae10-742d-432d-8c64-1d4bbe5cd2a1": {"__data__": {"text": "P2P File Distribution 168\n2.6 Video Streaming and Content Distribution Networks 175\n2.6.1 Internet Video 176\n2.6.2 HTTP Streaming and DASH 176\n2.6.3 Content Distribution Networks 177\n2.6.4 Case Studies: Netflix, YouTube, and Kankan 181\n2.7 Socket Programming: Creating Network Applications 185\n2.7.1 Socket Programming with UDP 187\n2.7.2 Socket Programming with TCP 192\n2.8 Summary 198\nHomework Problems and Questions 199\nSocket Programming Assignments 208\nWireshark Labs: HTTP, DNS 210\nInterview: Marc Andreessen 212\nTABLE OF CONTENTS      21\nChapter 3 Transport Layer 215\n3.1 Introduction and Transport-Layer Services 216\n3.1.1 Relationship Between Transport and Network Layers 216\n3.1.2 Overview of the Transport Layer in the Internet 219\n3.2 Multiplexing and Demultiplexing 221\n3.3 Connectionless Transport: UDP 228\n3.3.1 UDP Segment Structure 232\n3.3.2 UDP Checksum 232\n3.4 Principles of Reliable Data Transfer 234\n3.4.1 Building a Reliable Data Transfer Protocol 236\n3.4.2 Pipelined Reliable Data Transfer Protocols 245\n3.4.3 Go-Back-N (GBN) 249\n3.4.4 Selective Repeat (SR) 254\n3.5 Connection-Oriented Transport: TCP 261\n3.5.1 The TCP Connection 261\n3.5.2 TCP Segment Structure 264\n3.5.3 Round-Trip Time Estimation and Timeout 269\n3.5.4 Reliable Data Transfer 272\n3.5.5 Flow Control 280\n3.5.6 TCP Connection Management 283\n3.6 Principles of Congestion Control 289\n3.6.1 The Causes and the Costs of Congestion 289\n3.6.2 Approaches to Congestion Control 296\n3.7 TCP Congestion Control 297\n3.7.1 Fairness 307\n3.7.2 Explicit Congestion Notification (ECN): Network-assisted  \nCongestion Control 310\n3.8 Summary 312\nHomework Problems and Questions 314\nProgramming Assignments 329\nWireshark Labs: Exploring TCP, UDP 330\nInterview: Van Jacobson 331\nChapter 4 The Network Layer: Data Plane 333\n4.1 Overview of Network Layer 334\n4.1.1 Forwarding and Routing: The Network Data and Control Planes 334\n4.1.2 Network Service Models 339\n4.2 What\u2019s Inside a Router? 341\n4.2.1 Input Port Processing and Destination-Based Forwarding 344\n4.2.2 Switching 347\n4.2.3 Output Port Processing 349\n22     TABLE OF CONTENTS\n4.2.4 Where Does Queuing Occur? 349\n4.2.5 Packet Scheduling 353\n4.3 The Internet Protocol (IP): IPv4, Addressing, IPv6, and More 357\n4.3.1 IPv4 Datagram Format 358\n4.3.2 IPv4 Datagram Fragmentation 360\n4.3.3 IPv4 Addressing 362\n4.3.4 Network Address Translation (NAT) 373\n4.3.5 IPv6 376\n4.4 Generalized Forwarding and SDN 382\n4.4.1 Match 384\n4.4.2 Action 386\n4.4.3 OpenFlow Examples of Match-plus-action in Action 386\n4.5 Summary 389\nHomework Problems and Questions 389\nWireshark Lab 398\nInterview: Vinton G. Cerf 399\nChapter 5 The Network Layer: Control Plane 401\n5.1 Introduction 402\n5.2 Routing Algorithms 404\n5.2.1 The Link-State (LS) Routing Algorithm 407\n5.2.2 The Distance-Vector (DV) Routing Algorithm 412\n5.3 Intra-AS Routing in the Internet: OSPF 419\n5.4 Routing Among the ISPs: BGP 423\n5.4.1 The Role of BGP 423\n5.4.2 Advertising BGP Route Information 424\n5.4.3 Determining the Best Routes 426\n5.4.4 IP-Anycast 430\n5.4.5 Routing Policy", "doc_id": "f031ae10-742d-432d-8c64-1d4bbe5cd2a1", "embedding": null, "doc_hash": "a21f8e9aa74069aca33e4624434845dccbaeb5afbd0c39cb59925aadd7916fb3", "extra_info": null, "node_info": {"start": 44912, "end": 47961}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "1a0973d8-6604-4b72-884a-a74900f2ebc7", "3": "c5398ab6-27d0-4a7e-90f6-05e13ff61eb5"}}, "__type__": "1"}, "c5398ab6-27d0-4a7e-90f6-05e13ff61eb5": {"__data__": {"text": "OpenFlow Examples of Match-plus-action in Action 386\n4.5 Summary 389\nHomework Problems and Questions 389\nWireshark Lab 398\nInterview: Vinton G. Cerf 399\nChapter 5 The Network Layer: Control Plane 401\n5.1 Introduction 402\n5.2 Routing Algorithms 404\n5.2.1 The Link-State (LS) Routing Algorithm 407\n5.2.2 The Distance-Vector (DV) Routing Algorithm 412\n5.3 Intra-AS Routing in the Internet: OSPF 419\n5.4 Routing Among the ISPs: BGP 423\n5.4.1 The Role of BGP 423\n5.4.2 Advertising BGP Route Information 424\n5.4.3 Determining the Best Routes 426\n5.4.4 IP-Anycast 430\n5.4.5 Routing Policy 431\n5.4.6 Putting the Pieces Together: Obtaining Internet Presence 434\n5.5 The SDN Control Plane 435\n5.5.1 The SDN Control Plane: SDN Controller and SDN Control  \nApplications 438\n5.5.2 OpenFlow Protocol 440\n5.5.3 Data and Control Plane Interaction: An Example 442\n5.5.4 SDN: Past and Future 443\n5.6 ICMP: The Internet Control Message Protocol 447\n5.7 Network Management and SNMP 449\n5.7.1 The Network Management Framework 450\n5.7.2 The Simple Network Management Protocol (SNMP) 452\n5.8 Summary 454\nTABLE OF CONTENTS      23\nHomework Problems and Questions 455\nSocket Programming Assignment 461\nProgramming Assignment 462\nWireshark Lab 463\nInterview: Jennifer Rexford 464\nChapter 6 The Link Layer and LANs 467\n6.1 Introduction to the Link Layer 468\n6.1.1 The Services Provided by the Link Layer 470\n6.1.2 Where Is the Link Layer Implemented? 471\n6.2 Error-Detection and -Correction Techniques 472\n6.2.1 Parity Checks 474\n6.2.2 Checksumming Methods 476\n6.2.3 Cyclic Redundancy Check (CRC) 477\n6.3 Multiple Access Links and Protocols 479\n6.3.1 Channel Partitioning Protocols 481\n6.3.2 Random Access Protocols 483\n6.3.3 Taking-Turns Protocols 492\n6.3.4 DOCSIS: The Link-Layer Protocol for Cable Internet Access 493\n6.4 Switched Local Area Networks 495\n6.4.1 Link-Layer Addressing and ARP 496\n6.4.2 Ethernet 502\n6.4.3 Link-Layer Switches 509\n6.4.4 Virtual Local Area Networks (VLANs) 515\n6.5 Link Virtualization: A Network as a Link Layer 519\n6.5.1 Multiprotocol Label Switching (MPLS) 520\n6.6 Data Center Networking 523\n6.7 Retrospective: A Day in the Life of a Web Page Request 528\n6.7.1 Getting Started: DHCP, UDP, IP, and Ethernet 528\n6.7.2 Still Getting Started: DNS and ARP 530\n6.7.3 Still Getting Started: Intra-Domain Routing to the DNS Server 531\n6.7.4 Web Client-Server Interaction: TCP and HTTP 532\n6.8 Summary 534\nHomework Problems and Questions 535\nWireshark Lab 543\nInterview: Simon S. Lam 544\nChapter 7 Wireless and Mobile Networks 547\n7.1 Introduction 548\n7.2 Wireless Links and Network Characteristics 553\n7.2.1 CDMA 556\n24     TABLE OF CONTENTS\n7.3 WiFi: 802.11 Wireless LANs 560\n7.3.1 The 802.11 Architecture 561\n7.3.2 The 802.11 MAC Protocol 565\n7.3.3 The IEEE 802.11 Frame 570\n7.3.4 Mobility in the Same IP Subnet 574\n7.3.5 Advanced Features in 802.11 575\n7.3.6 Personal Area Networks: Bluetooth and Zigbee 576\n7.4 Cellular Internet Access 579\n7.4.1 An Overview of Cellular Network Architecture 579\n7.4.2 3G Cellular Data Networks: Extending the Internet  \nto Cellular Subscribers", "doc_id": "c5398ab6-27d0-4a7e-90f6-05e13ff61eb5", "embedding": null, "doc_hash": "8bacec2414108ac22d0c8c3a7fcb732c29c363f8d2c574f55aac7bb8b336ed53", "extra_info": null, "node_info": {"start": 48050, "end": 51129}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "f031ae10-742d-432d-8c64-1d4bbe5cd2a1", "3": "900f478e-6fa4-45c1-9445-3074b7be99d1"}}, "__type__": "1"}, "900f478e-6fa4-45c1-9445-3074b7be99d1": {"__data__": {"text": "7 Wireless and Mobile Networks 547\n7.1 Introduction 548\n7.2 Wireless Links and Network Characteristics 553\n7.2.1 CDMA 556\n24     TABLE OF CONTENTS\n7.3 WiFi: 802.11 Wireless LANs 560\n7.3.1 The 802.11 Architecture 561\n7.3.2 The 802.11 MAC Protocol 565\n7.3.3 The IEEE 802.11 Frame 570\n7.3.4 Mobility in the Same IP Subnet 574\n7.3.5 Advanced Features in 802.11 575\n7.3.6 Personal Area Networks: Bluetooth and Zigbee 576\n7.4 Cellular Internet Access 579\n7.4.1 An Overview of Cellular Network Architecture 579\n7.4.2 3G Cellular Data Networks: Extending the Internet  \nto Cellular Subscribers 582\n7.4.3 On to 4G: LTE 585\n7.5 Mobility Management: Principles 588\n7.5.1 Addressing 590\n7.5.2 Routing to a Mobile Node 592\n7.6 Mobile IP 598\n7.7 Managing Mobility in Cellular Networks 602\n7.7.1 Routing Calls to a Mobile User 604\n7.7.2 Handoffs in GSM 605\n7.8 Wireless and Mobility: Impact on Higher-Layer Protocols 608\n7.9 Summary 610\nHomework Problems and Questions 611\nWireshark Lab 616\nInterview: Deborah Estrin 617\nChapter 8 Security in Computer Networks 621\n8.1 What Is Network Security? 622\n8.2 Principles of Cryptography 624\n8.2.1 Symmetric Key Cryptography 626\n8.2.2 Public Key Encryption 632\n8.3 Message Integrity and Digital Signatures 638\n8.3.1 Cryptographic Hash Functions 639\n8.3.2 Message Authentication Code 641\n8.3.3 Digital Signatures 642\n8.4 End-Point Authentication 649\n8.4.1 Authentication Protocol ap1.0  650\n8.4.2 Authentication Protocol ap2.0  650\n8.4.3 Authentication Protocol ap3.0  651\n8.4.4 Authentication Protocol ap3.1  651\n8.4.5 Authentication Protocol ap4.0  652\nTABLE OF CONTENTS      25\n8.5 Securing E-Mail 654\n8.5.1 Secure E-Mail 655\n8.5.2 PGP 658\n8.6 Securing TCP Connections: SSL 659\n8.6.1 The Big Picture 660\n8.6.2 A More Complete Picture 663\n8.7 Network-Layer Security: IPsec and Virtual Private Networks 665\n8.7.1 IPsec and Virtual Private Networks (VPNs) 666\n8.7.2 The AH and ESP Protocols 668\n8.7.3 Security Associations 668\n8.7.4 The IPsec Datagram 669\n8.7.5 IKE: Key Management in IPsec 673\n8.8 Securing Wireless LANs 674\n8.8.1 Wired Equivalent Privacy (WEP) 674\n8.8.2 IEEE 802.11i 676\n8.9 Operational Security: Firewalls and Intrusion Detection Systems 679\n8.9.1 Firewalls 679\n8.9.2 Intrusion Detection Systems 687\n8.10 Summary 690\nHomework Problems and Questions 692\nWireshark Lab 700\nIPsec Lab 700\nInterview: Steven M. Bellovin 701\nChapter 9 Multimedia Networking 703\n9.1 Multimedia Networking Applications 704\n9.1.1 Properties of Video 704\n9.1.2 Properties of Audio 705\n9.1.3 Types of Multimedia Network Applications 707\n9.2 Streaming Stored Video 709\n9.2.1 UDP Streaming 711\n9.2.2 HTTP Streaming 712\n9.3 Voice-over-IP 716\n9.3.1 Limitations of the Best-Effort IP Service 716\n9.3.2 Removing Jitter at the Receiver for Audio 719\n9.3.3 Recovering from Packet Loss 722\n9.3.4 Case Study: VoIP with Skype 725\n9.4 Protocols for Real-Time Conversational Applications 728\n9.4.1 RTP 728\n9.4.2 SIP", "doc_id": "900f478e-6fa4-45c1-9445-3074b7be99d1", "embedding": null, "doc_hash": "060f4bdc937826f86e53f781ef4c3aef29e0725099b501e8def68d5f7ba25349", "extra_info": null, "node_info": {"start": 51134, "end": 54054}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "c5398ab6-27d0-4a7e-90f6-05e13ff61eb5", "3": "393cf43a-19a2-4f56-be4c-de5b02a7dfcd"}}, "__type__": "1"}, "393cf43a-19a2-4f56-be4c-de5b02a7dfcd": {"__data__": {"text": "701\nChapter 9 Multimedia Networking 703\n9.1 Multimedia Networking Applications 704\n9.1.1 Properties of Video 704\n9.1.2 Properties of Audio 705\n9.1.3 Types of Multimedia Network Applications 707\n9.2 Streaming Stored Video 709\n9.2.1 UDP Streaming 711\n9.2.2 HTTP Streaming 712\n9.3 Voice-over-IP 716\n9.3.1 Limitations of the Best-Effort IP Service 716\n9.3.2 Removing Jitter at the Receiver for Audio 719\n9.3.3 Recovering from Packet Loss 722\n9.3.4 Case Study: VoIP with Skype 725\n9.4 Protocols for Real-Time Conversational Applications 728\n9.4.1 RTP 728\n9.4.2 SIP 731\n26     TABLE OF CONTENTS\n9.5 Network Support for Multimedia 737\n9.5.1 Dimensioning Best-Effort Networks 739\n9.5.2 Providing Multiple Classes of Service 740\n9.5.3 Diffserv 747\n9.5.4 Per-Connection Quality-of-Service (QoS) Guarantees:  \nResource Reservation and Call Admission 751\n9.6 Summary 754\nHomework Problems and Questions 755\nProgramming Assignment 763\nInterview: Henning Schulzrinne 765\n References 769\n Index 811\nCOMPUTER \nNETWORKING\nA Top-Down ApproachSEVENTH EDITION\nGLOBAL EDITION\n\nThis page intentionally left blank\n29Today\u2019s Internet is arguably the largest engineered system ever created by  mankind, \nwith hundreds of millions of connected computers, communication links, and  \nswitches; with billions of users who connect via laptops, tablets, and smartphones; \nand with an array of new Internet-connected \u201cthings\u201d including game consoles, sur -\nveillance systems, watches, eye glasses, thermostats, body scales, and cars. Given \nthat the Internet is so large and has so many diverse components and uses, is there \nany hope of understanding how it works? Are there guiding principles and struc -\nture that can provide a foundation for understanding such an amazingly large and \ncomplex system? And if so, is it possible that it actually could be both interesting \nand fun to learn about computer networks? Fortunately, the answer to all of these \nquestions is a resounding YES! Indeed, it\u2019s our aim in this book to provide you with \na modern introduction to the dynamic field of computer networking, giving you the \nprinciples and practical insights you\u2019ll need to understand not only today\u2019s networks, \nbut tomorrow\u2019s as well.\nThis first chapter presents a broad overview of computer networking and the \nInternet. Our goal here is to paint a broad picture and set the context for the rest \nof this book, to see the forest through the trees. We\u2019ll cover a lot of ground in this \nintroductory chapter and discuss a lot of the pieces of a computer network, without \nlosing sight of the big picture.\nWe\u2019ll structure our overview of computer networks in this chapter as follows. \nAfter introducing some basic terminology and concepts, we\u2019ll first examine the basic \nhardware and software components that make up a network. We\u2019ll begin at the net -\nwork\u2019s edge and look at the end systems and network applications running in the \nnetwork. We\u2019ll then explore the core of a computer network, examining the links 1CHAPTER\nComputer \nNetworks and \nthe Internet\n30     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\nand the switches that transport data, as well as the access networks and physical \nmedia that connect end systems to the network core. We\u2019ll learn that the Internet is \na network of networks, and we\u2019ll learn how these networks connect with each other.\nAfter having completed this overview of the edge and core of a computer net -\nwork, we\u2019ll take the broader and more abstract view in the second half of this chap -\nter. We\u2019ll examine delay, loss, and throughput of data in a computer network and \nprovide simple quantitative models for", "doc_id": "393cf43a-19a2-4f56-be4c-de5b02a7dfcd", "embedding": null, "doc_hash": "f9dc661ae53127319011f3be3ce0071571a0a5b0cd6adf1f41d5d2e6e8ad628e", "extra_info": null, "node_info": {"start": 54068, "end": 57693}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "900f478e-6fa4-45c1-9445-3074b7be99d1", "3": "e5c4b133-9c70-4d9c-9b70-2cd34f1351da"}}, "__type__": "1"}, "e5c4b133-9c70-4d9c-9b70-2cd34f1351da": {"__data__": {"text": "running in the \nnetwork. We\u2019ll then explore the core of a computer network, examining the links 1CHAPTER\nComputer \nNetworks and \nthe Internet\n30     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\nand the switches that transport data, as well as the access networks and physical \nmedia that connect end systems to the network core. We\u2019ll learn that the Internet is \na network of networks, and we\u2019ll learn how these networks connect with each other.\nAfter having completed this overview of the edge and core of a computer net -\nwork, we\u2019ll take the broader and more abstract view in the second half of this chap -\nter. We\u2019ll examine delay, loss, and throughput of data in a computer network and \nprovide simple quantitative models for end-to-end throughput and delay: models \nthat take into account transmission, propagation, and queuing delays. We\u2019ll then \nintroduce some of the key architectural principles in computer networking, namely, \nprotocol layering and service models. We\u2019ll also learn that computer networks are \nvulnerable to many different types of attacks; we\u2019ll survey some of these attacks and \nconsider how computer networks can be made more secure. Finally, we\u2019ll close this \nchapter with a brief history of computer networking.\n1.1 What Is the Internet?\nIn this book, we\u2019ll use the public Internet, a specific computer network, as our prin -\ncipal vehicle for discussing computer networks and their protocols. But what  is the \nInternet? There are a couple of ways to answer this question. First, we can describe \nthe nuts and bolts of the Internet, that is, the basic hardware and software components \nthat make up the Internet. Second, we can describe the Internet in terms of a network -\ning infrastructure that provides services to distributed applications. Let\u2019s begin with \nthe nuts-and-bolts description, using Figure 1.1 to illustrate our discussion.\n1.1.1 A Nuts-and-Bolts Description\nThe Internet is a computer network that interconnects billions of computing devices \nthroughout the world. Not too long ago, these computing devices were primarily \ntraditional desktop PCs, Linux workstations, and so-called servers that store and \ntransmit information such as Web pages and e-mail messages. Increasingly, how -\never, nontraditional Internet \u201cthings\u201d such as laptops, smartphones, tablets, TVs, \ngaming consoles, thermostats, home security systems, home appliances, watches, \neye glasses, cars, traffic control systems and more are being connected to the Inter -\nnet. Indeed, the term computer network  is beginning to sound a bit dated, given the \nmany nontraditional devices that are being hooked up to the Internet. In Internet \njargon, all of these devices are called hosts  or end systems . By some estimates, in \n2015 there were about 5 billion devices connected to the Internet, and the number  \nwill reach 25 billion by 2020 [Gartner 2014]. It is estimated that in 2015 there  \nwere over 3.2 billion Internet users worldwide, approximately 40% of the world \npopulation [ITU 2015].\n1.1  \u2022  WHAT IS THE INTERNET?      31\nFigure 1.1  \u2666 Some pieces of the InternetKey:\nHost\n(= end system)Server Mobile Router Link-layer\nswitc hMode mB ase\nstationSmartphone\nTablet Traf\ufb01c light Thermostat Fridg eF lat computer\nmonitorKeyboardNational or\nGlobal IS P\nMobile Network\nLocal or\nRegional ISP\nEnterprise Network\nCell phone\ntowerHome Networ k\n32     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\nEnd systems are connected together by a network of communication links  and \npacket switches . We\u2019ll see in Section 1.2 that there are many types of communica -\ntion links, which are made up of different types of physical media, including coaxial \ncable, copper wire, optical fiber, and radio spectrum. Different links can transmit \ndata at different rates, with the transmission rate  of a link measured in", "doc_id": "e5c4b133-9c70-4d9c-9b70-2cd34f1351da", "embedding": null, "doc_hash": "304ade60b8640d74aea7cebab2912de8c841b6f063d39cd3aa92c7d8ddc952d3", "extra_info": null, "node_info": {"start": 57570, "end": 61408}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "393cf43a-19a2-4f56-be4c-de5b02a7dfcd", "3": "9c9bcb9c-b165-403b-9a6c-cce1f55c0344"}}, "__type__": "1"}, "9c9bcb9c-b165-403b-9a6c-cce1f55c0344": {"__data__": {"text": "Router Link-layer\nswitc hMode mB ase\nstationSmartphone\nTablet Traf\ufb01c light Thermostat Fridg eF lat computer\nmonitorKeyboardNational or\nGlobal IS P\nMobile Network\nLocal or\nRegional ISP\nEnterprise Network\nCell phone\ntowerHome Networ k\n32     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\nEnd systems are connected together by a network of communication links  and \npacket switches . We\u2019ll see in Section 1.2 that there are many types of communica -\ntion links, which are made up of different types of physical media, including coaxial \ncable, copper wire, optical fiber, and radio spectrum. Different links can transmit \ndata at different rates, with the transmission rate  of a link measured in bits/second. \nWhen one end system has data to send to another end system, the sending end system \nsegments the data and adds header bytes to each segment. The resulting packages \nof information, known as packets  in the jargon of computer networks, are then sent \nthrough the network to the destination end system, where they are reassembled into \nthe original data.\nA packet switch takes a packet arriving on one of its incoming communication \nlinks and forwards that packet on one of its outgoing communication links. Packet \nswitches come in many shapes and flavors, but the two most prominent types in \ntoday\u2019s Internet are routers  and link-layer switches . Both types of switches forward \npackets toward their ultimate destinations. Link-layer switches are typically used in \naccess networks, while routers are typically used in the network core. The sequence \nof communication links and packet switches traversed by a packet from the sending \nend system to the receiving end system is known as a route  or path  through the \nnetwork. Cisco predicts annual global IP traffic will pass the zettabyte ( 1021 bytes) \nthreshold by the end of 2016, and will reach 2 zettabytes per year by 2019 [Cisco \nVNI 2015].\nPacket-switched networks (which transport packets) are in many ways similar \nto transportation networks of highways, roads, and intersections (which transport \nvehicles). Consider, for example, a factory that needs to move a large amount of \ncargo to some destination warehouse located thousands of kilometers away. At the \nfactory, the cargo is segmented and loaded into a fleet of trucks. Each of the trucks \nthen independently travels through the network of highways, roads, and intersections \nto the destination warehouse. At the destination warehouse, the cargo is unloaded \nand grouped with the rest of the cargo arriving from the same shipment. Thus, in \nmany ways, packets are analogous to trucks, communication links are analogous to \nhighways and roads, packet switches are analogous to intersections, and end systems \nare analogous to buildings. Just as a truck takes a path through the transportation \nnetwork, a packet takes a path through a computer network.\nEnd systems access the Internet through Internet Service Providers (ISPs) , \nincluding residential ISPs such as local cable or telephone companies; corporate \nISPs; university ISPs; ISPs that provide WiFi access in airports, hotels, coffee shops, \nand other public places; and cellular data ISPs, providing mobile access to our \nsmartphones and other devices. Each ISP is in itself a network of packet switches \nand communication links. ISPs provide a variety of types of network access to the \nend systems, including residential broadband access such as cable modem or DSL, \nhigh-speed local area network access, and mobile wireless access. ISPs also provide \n Internet access to content providers, connecting Web sites and video servers directly \nto the Internet. The Internet is all about connecting end systems to each other, so the \n1.1  \u2022  WHAT IS THE INTERNET?      33\nISPs that provide access to end systems must also be interconnected. These lower-\ntier ISPs are interconnected through national and international upper-tier ISPs such \nas Level 3 Communications, AT&T, Sprint, and", "doc_id": "9c9bcb9c-b165-403b-9a6c-cce1f55c0344", "embedding": null, "doc_hash": "d07334ae8251998ddcc1a594949ef622e85212a858025f42f383580bc7ef4d91", "extra_info": null, "node_info": {"start": 61425, "end": 65400}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "e5c4b133-9c70-4d9c-9b70-2cd34f1351da", "3": "2a2f9d8a-6f41-4108-a42b-2abc2edd97fa"}}, "__type__": "1"}, "2a2f9d8a-6f41-4108-a42b-2abc2edd97fa": {"__data__": {"text": "ISPs, providing mobile access to our \nsmartphones and other devices. Each ISP is in itself a network of packet switches \nand communication links. ISPs provide a variety of types of network access to the \nend systems, including residential broadband access such as cable modem or DSL, \nhigh-speed local area network access, and mobile wireless access. ISPs also provide \n Internet access to content providers, connecting Web sites and video servers directly \nto the Internet. The Internet is all about connecting end systems to each other, so the \n1.1  \u2022  WHAT IS THE INTERNET?      33\nISPs that provide access to end systems must also be interconnected. These lower-\ntier ISPs are interconnected through national and international upper-tier ISPs such \nas Level 3 Communications, AT&T, Sprint, and NTT. An upper-tier ISP consists of \nhigh-speed routers interconnected with high-speed fiber-optic links. Each ISP net -\nwork, whether upper-tier or lower-tier, is managed independently, runs the IP pro -\ntocol (see below), and conforms to certain naming and address conventions. We\u2019ll \nexamine ISPs and their interconnection more closely in Section 1.3.\nEnd systems, packet switches, and other pieces of the Internet run protocols  that \ncontrol the sending and receiving of information within the Internet. The Transmission  \nControl Protocol (TCP)  and the Internet Protocol (IP)  are two of the most impor -\ntant protocols in the Internet. The IP protocol specifies the format of the packets \nthat are sent and received among routers and end systems. The Internet\u2019s principal \nprotocols are collectively known as TCP/IP . We\u2019ll begin looking into protocols in \nthis introductory  chapter. But that\u2019s just a start\u2014much of this book is concerned with \ncomputer network protocols!\nGiven the importance of protocols to the Internet, it\u2019s important that everyone \nagree on what each and every protocol does, so that people can create systems and \nproducts that interoperate. This is where standards come into play. Internet  standards  \nare developed by the Internet Engineering Task Force (IETF) [IETF 2016]. The IETF \nstandards documents are called requests for comments (RFCs) . RFCs started out \nas general requests for comments (hence the name) to resolve network and protocol \ndesign problems that faced the precursor to the Internet [Allman 2011]. RFCs tend \nto be quite technical and detailed. They define protocols such as TCP, IP, HTTP (for \nthe Web), and SMTP (for e-mail). There are currently more than 7,000 RFCs. Other \nbodies also specify standards for network components, most notably for network \nlinks. The IEEE 802 LAN/MAN Standards Committee [IEEE 802 2016], for exam -\nple, specifies the Ethernet and wireless WiFi standards.\n1.1.2 A Services Description\nOur discussion above has identified many of the pieces that make up the Internet. \nBut we can also describe the Internet from an entirely different angle\u2014namely, as \nan infrastructure that provides services to applications . In addition to traditional \napplications such as e-mail and Web surfing, Internet applications include mobile \nsmartphone and tablet applications, including Internet messaging, mapping with \nreal-time road-traffic information, music streaming from the cloud, movie and tel -\nevision streaming, online social networks, video conferencing, multi-person games, \nand location-based recommendation systems. The applications are said to be distrib-\nuted applications , since they involve multiple end systems that exchange data with \neach other. Importantly, Internet applications run on end systems\u2014they do not run \nin the packet switches in the network core. Although packet switches facilitate the \nexchange of data among end systems, they are not concerned with the application \nthat is the source or sink of data.\n34     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\nLet\u2019s explore a little more what we mean by an infrastructure that provides \n", "doc_id": "2a2f9d8a-6f41-4108-a42b-2abc2edd97fa", "embedding": null, "doc_hash": "04dc0c007695fcb71fe7d93fb83d8832600f80d39874d0a5fed72fd5b953642e", "extra_info": null, "node_info": {"start": 65331, "end": 69277}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "9c9bcb9c-b165-403b-9a6c-cce1f55c0344", "3": "0f074703-15d1-49eb-a09a-4b83501ec8eb"}}, "__type__": "1"}, "0f074703-15d1-49eb-a09a-4b83501ec8eb": {"__data__": {"text": "road-traffic information, music streaming from the cloud, movie and tel -\nevision streaming, online social networks, video conferencing, multi-person games, \nand location-based recommendation systems. The applications are said to be distrib-\nuted applications , since they involve multiple end systems that exchange data with \neach other. Importantly, Internet applications run on end systems\u2014they do not run \nin the packet switches in the network core. Although packet switches facilitate the \nexchange of data among end systems, they are not concerned with the application \nthat is the source or sink of data.\n34     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\nLet\u2019s explore a little more what we mean by an infrastructure that provides \n services to applications. To this end, suppose you have an exciting new idea for a dis -\ntributed Internet application, one that may greatly benefit humanity or one that may \nsimply make you rich and famous. How might you go about transforming this idea \ninto an actual Internet application? Because applications run on end systems, you are \ngoing to need to write programs that run on the end systems. You might, for example, \nwrite your programs in Java, C, or Python. Now, because you are developing a dis -\ntributed Internet application, the programs running on the different end systems will \nneed to send data to each other. And here we get to a central issue\u2014one that leads \nto the alternative way of describing the Internet as a platform for applications. How \ndoes one program running on one end system instruct the Internet to deliver data to \nanother program running on another end system?\nEnd systems attached to the Internet provide a socket interface  that specifies \nhow a program running on one end system asks the Internet infrastructure to deliver \ndata to a specific destination program running on another end system. This Internet \nsocket interface is a set of rules that the sending program must follow so that the \nInternet can deliver the data to the destination program. We\u2019ll discuss the Internet \nsocket interface in detail in Chapter 2 . For now, let\u2019s draw upon a simple analogy, \none that we will frequently use in this book. Suppose Alice wants to send a letter to \nBob using the postal service. Alice, of course, can\u2019t just write the letter (the data) and \ndrop the letter out her window. Instead, the postal service requires that Alice put the \nletter in an envelope; write Bob\u2019s full name, address, and zip code in the center of the \nenvelope; seal the envelope; put a stamp in the upper-right-hand corner of the enve -\nlope; and finally, drop the envelope into an official postal service mailbox. Thus, the \npostal service has its own \u201cpostal service interface,\u201d or set of rules, that Alice must \nfollow to have the postal service deliver her letter to Bob. In a similar manner, the \nInternet has a socket interface that the program sending data must follow to have the \nInternet deliver the data to the program that will receive the data.\nThe postal service, of course, provides more than one service to its customers. It \nprovides express delivery, reception confirmation, ordinary use, and many more ser -\nvices. In a similar manner, the Internet provides multiple services to its applications. \nWhen you develop an Internet application, you too must choose one of the Internet\u2019s \nservices for your application. We\u2019ll describe the Internet\u2019s services in Chapter 2.\nWe have just given two descriptions of the Internet; one in terms of its hardware \nand software components, the other in terms of an infrastructure for providing ser -\nvices to distributed applications. But perhaps you are still confused as to what the \nInternet is. What are packet switching and TCP/IP? What are routers? What kinds of \ncommunication links are present in the Internet? What is a distributed application? \nHow can a thermostat or body scale be attached to the Internet? If you feel a bit over -\nwhelmed by all of this now, don\u2019t worry\u2014the purpose of this book is to introduce \nyou to both the nuts and bolts of the Internet and the principles that govern how", "doc_id": "0f074703-15d1-49eb-a09a-4b83501ec8eb", "embedding": null, "doc_hash": "30852db2347aa68cb9f6ba775ccca8ac27b6340518432c88b6ad7dc18449c28f", "extra_info": null, "node_info": {"start": 69311, "end": 73437}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "2a2f9d8a-6f41-4108-a42b-2abc2edd97fa", "3": "aa63d5c7-26f2-4f55-bda3-889481b364b1"}}, "__type__": "1"}, "aa63d5c7-26f2-4f55-bda3-889481b364b1": {"__data__": {"text": "one of the Internet\u2019s \nservices for your application. We\u2019ll describe the Internet\u2019s services in Chapter 2.\nWe have just given two descriptions of the Internet; one in terms of its hardware \nand software components, the other in terms of an infrastructure for providing ser -\nvices to distributed applications. But perhaps you are still confused as to what the \nInternet is. What are packet switching and TCP/IP? What are routers? What kinds of \ncommunication links are present in the Internet? What is a distributed application? \nHow can a thermostat or body scale be attached to the Internet? If you feel a bit over -\nwhelmed by all of this now, don\u2019t worry\u2014the purpose of this book is to introduce \nyou to both the nuts and bolts of the Internet and the principles that govern how and \nwhy it works. We\u2019ll explain these important terms and questions in the following \nsections and chapters.\n1.1  \u2022  WHAT IS THE INTERNET?      35\n1.1.3 What Is a Protocol?\nNow that we\u2019ve got a bit of a feel for what the Internet is, let\u2019s consider another \nimportant buzzword in computer networking: protocol . What is a protocol? What \ndoes a protocol do ?\nA Human Analogy\nIt is probably easiest to understand the notion of a computer network protocol by \nfirst considering some human analogies, since we humans execute protocols all of \nthe time. Consider what you do when you want to ask someone for the time of day. \nA typical exchange is shown in Figure 1.2. Human protocol (or good manners, at \nleast) dictates that one first offer a greeting (the first \u201cHi\u201d in Figure 1.2) to initiate \ncommunication with someone else. The typical response to a \u201cHi\u201d is a returned \u201cHi\u201d \nmessage. Implicitly, one then takes a cordial \u201cHi\u201d response as an indication that one \ncan proceed and ask for the time of day. A different response to the initial \u201cHi\u201d (such \nas \u201cDon\u2019t bother me!\u201d or \u201cI don\u2019t speak English,\u201d or some unprintable reply) might \nFigure 1.2  \u2666 A human protocol and a computer network protocolGET http://www.pearsonglobaleditions.com/\nkuroseTCP connection request\nTime TimeTCP connection reply\n<\ufb01le>Hi\nGot the time?\nTime TimeHi\n2:00\n36     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\nindicate an unwillingness or inability to communicate. In this case, the human proto -\ncol would be not to ask for the time of day. Sometimes one gets no response at all to \na question, in which case one typically gives up asking that person for the time. Note \nthat in our human protocol, there are specific messages we send, and specific actions \nwe take in response to the received reply messages or other events  (such as no reply \nwithin some given amount of time). Clearly, transmitted and received messages, and \nactions taken when these messages are sent or received or other events occur, play \na central role in a human protocol. If people run different protocols (for example, if \none person has manners but the other does not, or if one understands the concept of \ntime and the other does not) the protocols do not interoperate and no useful work can \nbe accomplished. The same is true in networking\u2014it takes two (or more) communi -\ncating entities running the same protocol in order to accomplish a task.\nLet\u2019s consider a second human analogy. Suppose you\u2019re in a college class (a \ncomputer networking class, for example!). The teacher is droning on about protocols \nand you\u2019re confused. The teacher stops to ask, \u201cAre there any questions?\u201d (a message \nthat is transmitted to, and received by, all students who are not sleeping). You raise \nyour hand (transmitting an implicit message to the teacher). Your teacher acknowl -\nedges you with a smile, saying \u201cYes . .", "doc_id": "aa63d5c7-26f2-4f55-bda3-889481b364b1", "embedding": null, "doc_hash": "d13b9e137fd85b86da0d202de095f31a880d72ed77b8c98993b31d04b722cd28", "extra_info": null, "node_info": {"start": 73422, "end": 77082}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "0f074703-15d1-49eb-a09a-4b83501ec8eb", "3": "58257a48-1f67-4ef9-803b-d0a0a42965dd"}}, "__type__": "1"}, "58257a48-1f67-4ef9-803b-d0a0a42965dd": {"__data__": {"text": "and the other does not) the protocols do not interoperate and no useful work can \nbe accomplished. The same is true in networking\u2014it takes two (or more) communi -\ncating entities running the same protocol in order to accomplish a task.\nLet\u2019s consider a second human analogy. Suppose you\u2019re in a college class (a \ncomputer networking class, for example!). The teacher is droning on about protocols \nand you\u2019re confused. The teacher stops to ask, \u201cAre there any questions?\u201d (a message \nthat is transmitted to, and received by, all students who are not sleeping). You raise \nyour hand (transmitting an implicit message to the teacher). Your teacher acknowl -\nedges you with a smile, saying \u201cYes . . .\u201d (a transmitted message encouraging you \nto ask your question\u2014teachers love to be asked questions), and you then ask your \nquestion (that is, transmit your message to your teacher). Your teacher hears your \nquestion (receives your question message) and answers (transmits a reply to you). \nOnce again, we see that the transmission and receipt of messages, and a set of con -\nventional actions taken when these messages are sent and received, are at the heart \nof this question-and-answer protocol.\nNetwork Protocols\nA network protocol is similar to a human protocol, except that the entities exchang -\ning messages and taking actions are hardware or software components of some \ndevice (for example, computer, smartphone, tablet, router, or other network-capable \ndevice). All activity in the Internet that involves two or more communicating remote \nentities is governed by a protocol. For example, hardware-implemented protocols in \ntwo physically connected computers control the flow of bits on the \u201cwire\u201d between \nthe two network interface cards; congestion-control protocols in end systems control \nthe rate at which packets are transmitted between sender and receiver; protocols in \nrouters determine a packet\u2019s path from source to destination. Protocols are running \neverywhere in the Internet, and consequently much of this book is about computer \nnetwork protocols.\nAs an example of a computer network protocol with which you are probably \nfamiliar, consider what happens when you make a request to a Web server, that \nis, when you type the URL of a Web page into your Web browser. The scenario \nis illustrated in the right half of Figure 1.2. First, your computer will send a con -\nnection request message to the Web server and wait for a reply. The Web server \n1.2  \u2022  THE NETWORK EDGE      37\nwill eventually receive your connection request message and return a connection \nreply message. Knowing that it is now OK to request the Web document, your \ncomputer then sends the name of the Web page it wants to fetch from that Web \nserver in a GET message. Finally, the Web server returns the Web page (file) to \nyour computer.\nGiven the human and networking examples above, the exchange of messages \nand the actions taken when these messages are sent and received are the key defining \nelements of a protocol:\nA protocol  defines the format and the order of messages exchanged between two \nor more communicating entities, as well as the actions taken on the transmission \nand/or receipt of a message or other event.\nThe Internet, and computer networks in general, make extensive use of pro -\ntocols. Different protocols are used to accomplish different communication tasks. \nAs you read through this book, you will learn that some protocols are simple and \nstraightforward, while others are complex and intellectually deep. Mastering the \nfield of computer networking is equivalent to understanding the what, why, and how \nof networking protocols.\n1.2 The Network Edge\nIn the previous section we presented a high-level overview of the Internet and net -\nworking protocols. We are now going to delve a bit more deeply into the components \nof a computer network (and the Internet, in particular). We begin in this section at \nthe edge of a network and look at the components with which we are most ", "doc_id": "58257a48-1f67-4ef9-803b-d0a0a42965dd", "embedding": null, "doc_hash": "dc09c2e673e4273b5a0737f7c649aab7cc85b896b0d1b396cefd014ca2c60c89", "extra_info": null, "node_info": {"start": 77152, "end": 81154}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "aa63d5c7-26f2-4f55-bda3-889481b364b1", "3": "3da8e6a1-b3f8-4ce8-8e0e-28e9d30c0584"}}, "__type__": "1"}, "3da8e6a1-b3f8-4ce8-8e0e-28e9d30c0584": {"__data__": {"text": "receipt of a message or other event.\nThe Internet, and computer networks in general, make extensive use of pro -\ntocols. Different protocols are used to accomplish different communication tasks. \nAs you read through this book, you will learn that some protocols are simple and \nstraightforward, while others are complex and intellectually deep. Mastering the \nfield of computer networking is equivalent to understanding the what, why, and how \nof networking protocols.\n1.2 The Network Edge\nIn the previous section we presented a high-level overview of the Internet and net -\nworking protocols. We are now going to delve a bit more deeply into the components \nof a computer network (and the Internet, in particular). We begin in this section at \nthe edge of a network and look at the components with which we are most  familiar\u2014\nnamely, the computers, smartphones and other devices that we use on a daily basis. \nIn the next section we\u2019ll move from the network edge to the network core and exam -\nine switching and routing in computer networks.\nRecall from the previous section that in computer networking jargon, the com -\nputers and other devices connected to the Internet are often referred to as end sys -\ntems. They are referred to as end systems because they sit at the edge of the Internet,  \nas shown in Figure 1.3. The Internet\u2019s end systems include desktop computers  \n(e.g., desktop PCs, Macs, and Linux boxes), servers (e.g., Web and e-mail servers),  \nand mobile devices (e.g., laptops, smartphones, and tablets). Furthermore, an \nincreasing number of non-traditional \u201cthings\u201d are being attached to the Internet as \nend  systems (see the Case History feature).\nEnd systems are also referred to as hosts  because they host (that is, run) appli -\ncation programs such as a Web browser program, a Web server program, an e-mail \nclient program, or an e-mail server program. Throughout this book we will use the \n38     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\nFigure 1.3  \u2666 End-system interactionNational or\nGlobal ISP\nMobile Network\nLocal or\nRegional ISP\nEnterprise NetworkHome Network\n1.2  \u2022  THE NETWORK EDGE      39\nterms hosts and end systems interchangeably; that is, host = end system . Hosts are \nsometimes further divided into two categories: clients  and servers . Informally, cli -\nents tend to be desktop and mobile PCs, smartphones, and so on, whereas serv -\ners tend to be more powerful machines that store and distribute Web pages, stream \nvideo, relay e-mail, and so on. Today, most of the servers from which we receive \nsearch results, e-mail, Web pages, and videos reside in large data centers . For exam -\nple, Google has 50-100 data centers, including about 15 large centers, each with \nmore than 100,000 servers.THE INTERNET OF THINGS\nCan you imagine a world in which just about everything is wirelessly connected to \nthe Internet? A world in which most people, cars, bicycles, eye glasses, watches, \ntoys, hospital equipment, home sensors, classrooms, video surveillance systems, \natmospheric sensors, store-shelf products, and pets are connected? This world of the \nInternet of Things (IoT) may actually be just around the corner.\nBy some estimates, as of 2015 there are already 5 billion things connected to \nthe Internet, and the number could reach 25 billion by 2020 [Gartner 2014]. These \nthings include our smartphones, which already follow us around in our homes, offices, \nand cars, reporting our geo-locations and usage data to our ISPs and Internet applica -\ntions. But in addition to our smartphones, a wide-variety of non-traditional \u201cthings\u201d are \nalready available as products. For example, there are Internet-connected wearables, \nincluding watches (from Apple and many others) and eye glasses. Internet-connected \nglasses can, for example, upload everything we see to the cloud, allowing us to", "doc_id": "3da8e6a1-b3f8-4ce8-8e0e-28e9d30c0584", "embedding": null, "doc_hash": "0f1db01926f91a91e320f88863144b1ab44a4f4252431389d0febfba23a7e7a0", "extra_info": null, "node_info": {"start": 81050, "end": 84899}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "58257a48-1f67-4ef9-803b-d0a0a42965dd", "3": "1d891d19-535a-491d-88af-c97e09918a08"}}, "__type__": "1"}, "1d891d19-535a-491d-88af-c97e09918a08": {"__data__": {"text": "products, and pets are connected? This world of the \nInternet of Things (IoT) may actually be just around the corner.\nBy some estimates, as of 2015 there are already 5 billion things connected to \nthe Internet, and the number could reach 25 billion by 2020 [Gartner 2014]. These \nthings include our smartphones, which already follow us around in our homes, offices, \nand cars, reporting our geo-locations and usage data to our ISPs and Internet applica -\ntions. But in addition to our smartphones, a wide-variety of non-traditional \u201cthings\u201d are \nalready available as products. For example, there are Internet-connected wearables, \nincluding watches (from Apple and many others) and eye glasses. Internet-connected \nglasses can, for example, upload everything we see to the cloud, allowing us to share \nour visual experiences with people around the world in real-time. There are Internet-\nconnected things already available for the smart home, including Internet-connected \nthermostats that can be controlled remotely from our smartphones, and Internet-\nconnected body scales, enabling us to graphically review the progress of our diets \nfrom our smartphones. There are Internet-connected toys, including dolls that  \nrecognize and interpret a child\u2019s speech and respond appropriately.\nThe IoT offers potentially revolutionary benefits to users. But at the same time there \nare also huge security and privacy risks. For example, attackers, via the Internet, \nmight be able to hack into IoT devices or into the servers collecting data from IoT \ndevices. For example, an attacker could hijack an Internet-connected doll and talk \ndirectly with a child; or an attacker could hack into a database that stores  personal \nhealth and activity information collected from wearable devices. These security \nand privacy concerns could undermine the consumer confidence necessary for the \n technologies to meet their full potential and may result in less widespread adoption \n[FTC 2015].CASE HISTORY\n\n40     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\n1.2.1 Access Networks\nHaving considered the applications and end systems at the \u201cedge of the network,\u201d \nlet\u2019s next consider the access network\u2014the network that physically connects an end \nsystem to the first router (also known as the \u201cedge router\u201d) on a path from the end \nsystem to any other distant end system. Figure 1.4 shows several types of access \nFigure 1.4  \u2666 Access networksNational or\nGlobal ISP\nMobile Network\nLocal or\nRegional ISP\nEnterprise NetworkHome Network\n1.2  \u2022  THE NETWORK EDGE      41\nnetworks with thick, shaded lines and the settings (home, enterprise, and wide-area \nmobile wireless) in which they are used.\nHome Access: DSL, Cable, FTTH, Dial-Up, and Satellite\nIn developed countries as of 2014, more than 78 percent of the households have Internet \naccess, with Korea, Netherlands, Finland, and Sweden leading the way with more than \n80 percent of households having Internet access, almost all via a high-speed broadband \nconnection [ITU 2015]. Given this widespread use of home access networks let\u2019s begin \nour overview of access networks by considering how homes connect to the Internet.\nToday, the two most prevalent types of broadband residential access are digital \nsubscriber line (DSL)  and cable. A residence typically obtains DSL Internet access \nfrom the same local telephone company (telco) that provides its wired local phone \naccess. Thus, when DSL is used, a customer\u2019s telco is also its ISP. As shown in \nFigure 1. 5, each customer\u2019s DSL modem uses the existing telephone line (twisted-\npair copper wire, which we\u2019ll discuss in Section 1.2.2) to exchange data with a digi -\ntal subscriber line access multiplexer (DSLAM) located in the telco\u2019s local central \noffice (CO). The home\u2019s DSL modem takes digital data and translates it to high- \nfrequency tones for transmission over telephone wires to the CO; the analog signals \nfrom many", "doc_id": "1d891d19-535a-491d-88af-c97e09918a08", "embedding": null, "doc_hash": "54d17a83a6484fe4101957efffd0a93c4d75aa9eeb7f1722b5b564994e3ed891", "extra_info": null, "node_info": {"start": 84914, "end": 88838}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "3da8e6a1-b3f8-4ce8-8e0e-28e9d30c0584", "3": "6383d9f7-06ca-4bcd-9b68-cbdd7bad5246"}}, "__type__": "1"}, "6383d9f7-06ca-4bcd-9b68-cbdd7bad5246": {"__data__": {"text": "line (DSL)  and cable. A residence typically obtains DSL Internet access \nfrom the same local telephone company (telco) that provides its wired local phone \naccess. Thus, when DSL is used, a customer\u2019s telco is also its ISP. As shown in \nFigure 1. 5, each customer\u2019s DSL modem uses the existing telephone line (twisted-\npair copper wire, which we\u2019ll discuss in Section 1.2.2) to exchange data with a digi -\ntal subscriber line access multiplexer (DSLAM) located in the telco\u2019s local central \noffice (CO). The home\u2019s DSL modem takes digital data and translates it to high- \nfrequency tones for transmission over telephone wires to the CO; the analog signals \nfrom many such houses are translated back into digital format at the DSLAM.\nThe residential telephone line carries both data and traditional telephone signals \nsimultaneously, which are encoded at different frequencies:\n\u2022 A high-speed downstream channel, in the 50 kHz to 1 MHz band\n\u2022 A medium-speed upstream channel, in the 4 kHz to 50 kHz band\n\u2022 An ordinary two-way telephone channel, in the 0 to 4 kHz band\nThis approach makes the single DSL link appear as if there were three separate links, so \nthat a telephone call and an Internet connection can share the DSL link at the same time. \nFigure 1.5  \u2666 DSL Internet accessHome PCHome\nphone\nDSL\nmodemInternet\nTelephone\nnetworkSplitterExisting phone line:\n0-4KHz phone; 4-50KHz\nupstream data; 50KHz\u2013\n1MHz downstream data\nCentral\nof\ufb01ceDSLAM\n42     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\n(We\u2019ll describe this technique of frequency-division multiplexing in Section 1.3.1.) \nOn the customer side, a splitter separates the data and telephone signals arriving to the \nhome and forwards the data signal to the DSL modem. On the telco side, in the CO, the \nDSLAM separates the data and phone signals and sends the data into the Internet. Hun -\ndreds or even thousands of households connect to a single DSLAM [Dischinger 2007].\nThe DSL standards define multiple transmission rates, including 12 Mbps down -\nstream and 1.8 Mbps upstream [ITU 1999], and 55 Mbps downstream and 15 Mbps \nupstream [ITU 2006]. Because the downstream and upstream rates are different, the \naccess is said to be asymmetric. The actual downstream and upstream transmission \nrates achieved may be less than the rates noted above, as the DSL provider may pur -\nposefully limit a residential rate when tiered service (different rates, available at dif -\nferent prices) are offered. The maximum rate is also limited by the distance between \nthe home and the CO, the gauge of the twisted-pair line and the degree of electrical \ninterference. Engineers have expressly designed DSL for short distances between the \nhome and the CO; generally, if the residence is not located within 5 to 10 miles of the \nCO, the residence must resort to an alternative form of Internet access.\nWhile DSL makes use of the telco\u2019s existing local telephone infrastructure, \ncable Internet access  makes use of the cable television company\u2019s existing cable \ntelevision infrastructure. A residence obtains cable Internet access from the same \ncompany that provides its cable television. As illustrated in Figure 1.6, fiber optics \nconnect the cable head end to neighborhood-level junctions, from which traditional \ncoaxial cable is then used to reach individual houses and apartments. Each neighbor -\nhood junction typically supports 500 to 5,000 homes. Because both fiber and coaxial \ncable are employed in this system, it is often referred to as hybrid fiber coax (HFC).\nFigure 1.6  \u2666 A hybrid fiber-coaxial access networkFiber\ncableCoaxial cable\nHundreds\nof homes\nCable head endHundreds\nof", "doc_id": "6383d9f7-06ca-4bcd-9b68-cbdd7bad5246", "embedding": null, "doc_hash": "50c2e787b7780a71fa48b4841c7d20435b3c9c3972f66ebea2a538e057955147", "extra_info": null, "node_info": {"start": 88953, "end": 92604}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "1d891d19-535a-491d-88af-c97e09918a08", "3": "c92a4b9b-c90f-442a-abc2-08d24c71dfc3"}}, "__type__": "1"}, "c92a4b9b-c90f-442a-abc2-08d24c71dfc3": {"__data__": {"text": "infrastructure, \ncable Internet access  makes use of the cable television company\u2019s existing cable \ntelevision infrastructure. A residence obtains cable Internet access from the same \ncompany that provides its cable television. As illustrated in Figure 1.6, fiber optics \nconnect the cable head end to neighborhood-level junctions, from which traditional \ncoaxial cable is then used to reach individual houses and apartments. Each neighbor -\nhood junction typically supports 500 to 5,000 homes. Because both fiber and coaxial \ncable are employed in this system, it is often referred to as hybrid fiber coax (HFC).\nFigure 1.6  \u2666 A hybrid fiber-coaxial access networkFiber\ncableCoaxial cable\nHundreds\nof homes\nCable head endHundreds\nof homesFiber\nnode\nFiber\nnodeInternet\nCMTS\n1.2  \u2022  THE NETWORK EDGE      43\nCable Internet access requires special modems, called cable modems. As with \na DSL modem, the cable modem is typically an external device and connects to \nthe home PC through an Ethernet port. (We will discuss Ethernet in great detail in \nChapter 6 .) At the cable head end, the cable modem termination system (CMTS) \nserves a similar function as the DSL network\u2019s DSLAM\u2014turning the analog signal \nsent from the cable modems in many downstream homes back into digital format. \nCable modems divide the HFC network into two channels, a downstream and an \nupstream channel. As with DSL, access is typically asymmetric, with the downstream  \nchannel typically allocated a higher transmission rate than the upstream channel. The \n DOCSIS 2.0 standard defines downstream rates up to 42.8 Mbps and upstream rates \nof up to 30.7 Mbps. As in the case of DSL networks, the maximum achievable rate \nmay not be realized due to lower contracted data rates or media impairments.\nOne important characteristic of cable Internet access is that it is a shared broad-\ncast medium. In particular, every packet sent by the head end travels downstream on \nevery link to every home and every packet sent by a home travels on the upstream \nchannel to the head end. For this reason, if several users are simultaneously down -\nloading a video file on the downstream channel, the actual rate at which each user \nreceives its video file will be significantly lower than the aggregate cable down -\nstream rate. On the other hand, if there are only a few active users and they are all \nWeb surfing, then each of the users may actually receive Web pages at the full cable \ndownstream rate, because the users will rarely request a Web page at exactly the \nsame time. Because the upstream channel is also shared, a distributed multiple access \nprotocol is needed to coordinate transmissions and avoid collisions. (We\u2019ll discuss \nthis collision issue in some detail in Chapter 6.)\nAlthough DSL and cable networks currently represent more than 85 percent \nof residential broadband access in the United States, an up-and-coming technol -\nogy that provides even higher speeds is fiber to the home (FTTH)  [FTTH Coun -\ncil 2016]. As the name suggests, the FTTH concept is simple\u2014provide an optical \nfiber path from the CO directly to the home. Many countries today\u2014including  \nthe UAE, South Korea, Hong Kong, Japan, Singapore, Taiwan, Lithuania, and  \nSweden\u2014now have household penetration rates exceeding 30% [FTTH Council 2016].\nThere are several competing technologies for optical distribution from the CO \nto the homes. The simplest optical distribution network is called direct fiber, with \none fiber leaving the CO for each home. More commonly, each fiber leaving the \ncentral office is actually shared by many homes; it is not until the fiber gets rela -\ntively close to the homes that it is split into individual customer-specific fibers. There \nare two competing optical-distribution network architectures that perform this split -\nting: active optical networks (AONs) and passive optical networks (PONs).", "doc_id": "c92a4b9b-c90f-442a-abc2-08d24c71dfc3", "embedding": null, "doc_hash": "46407b4af0cbd72c2d43b965eda4e6c2b5f58ce449aca27ceb095f668bcf55f9", "extra_info": null, "node_info": {"start": 92533, "end": 96417}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "6383d9f7-06ca-4bcd-9b68-cbdd7bad5246", "3": "78822a72-71de-4dd3-9578-85bf49788e2a"}}, "__type__": "1"}, "78822a72-71de-4dd3-9578-85bf49788e2a": {"__data__": {"text": "UAE, South Korea, Hong Kong, Japan, Singapore, Taiwan, Lithuania, and  \nSweden\u2014now have household penetration rates exceeding 30% [FTTH Council 2016].\nThere are several competing technologies for optical distribution from the CO \nto the homes. The simplest optical distribution network is called direct fiber, with \none fiber leaving the CO for each home. More commonly, each fiber leaving the \ncentral office is actually shared by many homes; it is not until the fiber gets rela -\ntively close to the homes that it is split into individual customer-specific fibers. There \nare two competing optical-distribution network architectures that perform this split -\nting: active optical networks (AONs) and passive optical networks (PONs). AON is \nessentially switched Ethernet, which is discussed in Chapter 6.\nHere, we briefly discuss PON, which is used in Verizon\u2019s FIOS service. \nFig ure 1.7 shows FTTH using the PON distribution architecture. Each home has \nan optical network terminator (ONT), which is connected by dedicated optical fiber \nto a neighborhood splitter. The splitter combines a number of homes (typically less  \n44     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\nthan 100) onto a single, shared optical fiber, which connects to an optical line \n terminator (OLT) in the telco\u2019s CO. The OLT, providing conversion between opti -\ncal and electrical signals, connects to the Internet via a telco router. In the home, \nusers connect a home router (typically a wireless router) to the ONT and access the \n Internet via this home router. In the PON architecture, all packets sent from OLT to \nthe splitter are replicated at the splitter (similar to a cable head end).\nFTTH can potentially provide Internet access rates in the gigabits per second \nrange. However, most FTTH ISPs provide different rate offerings, with the higher \nrates naturally costing more money. The average downstream speed of US FTTH \ncustomers was approximately 20 Mbps in 2011 (compared with 13 Mbps for cable \naccess networks and less than 5 Mbps for DSL) [FTTH Council 2011b].\nTwo other access network technologies are also used to provide Internet access \nto the home. In locations where DSL, cable, and FTTH are not available (e.g., in \nsome rural settings), a satellite link can be used to connect a residence to the Inter -\nnet at speeds of more than 1 Mbps; StarBand and HughesNet are two such satellite \naccess providers. Dial-up access over traditional phone lines is based on the same \nmodel as DSL\u2014a home modem connects over a phone line to a modem in the ISP. \nCompared with DSL and other broadband access networks, dial-up access is excru -\nciatingly slow at 56 kbps.\nAccess in the Enterprise (and the Home): Ethernet and WiFi\nOn corporate and university campuses, and increasingly in home settings, a local area \nnetwork (LAN) is used to connect an end system to the edge router. Although there \nare many types of LAN technologies, Ethernet is by far the most prevalent access \ntechnology in corporate, university, and home networks. As shown in Figure 1.8,  \nEthernet users use twisted-pair copper wire to connect to an Ethernet switch, a tech-\nnology discussed in detail in Chapter 6. The Ethernet switch, or a network of such Figure 1.7  \u2666 FTTH Internet accessInternet\nCentral of\ufb01ce\nOptical\nsplitterONT\nONT\nONTOLT\nOptical\n\ufb01bers\n1.2  \u2022  THE NETWORK EDGE      45\ninterconnected switches, is then in turn connected into the larger Internet. With Eth-\nernet access, users typically have 100 Mbps or 1 Gbps access to the Ethernet switch, \nwhereas servers may have 1 Gbps or even 10 Gbps access.\nIncreasingly, however, people are accessing the Internet wirelessly from lap -\ntops, smartphones, tablets, and other", "doc_id": "78822a72-71de-4dd3-9578-85bf49788e2a", "embedding": null, "doc_hash": "bfb83739f341261442083deecc0288113e950c467eddb5b252537d2fe78c3adf", "extra_info": null, "node_info": {"start": 96422, "end": 100135}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "c92a4b9b-c90f-442a-abc2-08d24c71dfc3", "3": "0dee402c-c817-463e-b8fa-f6b7cbad1043"}}, "__type__": "1"}, "0dee402c-c817-463e-b8fa-f6b7cbad1043": {"__data__": {"text": "in Figure 1.8,  \nEthernet users use twisted-pair copper wire to connect to an Ethernet switch, a tech-\nnology discussed in detail in Chapter 6. The Ethernet switch, or a network of such Figure 1.7  \u2666 FTTH Internet accessInternet\nCentral of\ufb01ce\nOptical\nsplitterONT\nONT\nONTOLT\nOptical\n\ufb01bers\n1.2  \u2022  THE NETWORK EDGE      45\ninterconnected switches, is then in turn connected into the larger Internet. With Eth-\nernet access, users typically have 100 Mbps or 1 Gbps access to the Ethernet switch, \nwhereas servers may have 1 Gbps or even 10 Gbps access.\nIncreasingly, however, people are accessing the Internet wirelessly from lap -\ntops, smartphones, tablets, and other \u201cthings\u201d (see earlier sidebar on \u201cInternet of \nThings\u201d). In a wireless LAN setting, wireless users transmit/receive packets to/from \nan access point that is connected into the enterprise\u2019s network (most likely using \nwired Ethernet), which in turn is connected to the wired Internet. A wireless LAN \nuser must typically be within a few tens of meters of the access point. Wireless LAN \naccess based on IEEE 802.11 technology, more colloquially known as WiFi, is now \njust about everywhere\u2014universities, business offices, cafes, airports, homes, and \neven in airplanes. In many cities, one can stand on a street corner and be within range \nof ten or twenty base stations (for a browseable global map of 802.11 base stations \nthat have been discovered and logged on a Web site by people who take great enjoy -\nment in doing such things, see [wigle.net 2016]). As discussed in detail in Chapter 7 , \n802.11 today provides a shared transmission rate of up to more than 100 Mbps.\nEven though Ethernet and WiFi access networks were initially deployed in enter -\nprise (corporate, university) settings, they have recently become relatively common \ncomponents of home networks. Many homes combine broadband residential access \n(that is, cable modems or DSL) with these inexpensive wireless LAN technologies \nto create powerful home networks [Edwards 2011]. Figure 1.9 shows a typical home \nnetwork. This home network consists of a roaming laptop as well as a wired PC; a base \nstation (the wireless access point), which communicates with the wireless PC and other \nwireless devices in the home; a cable modem, providing broadband access to the Inter -\nnet; and a router, which interconnects the base station and the stationary PC with the \ncable modem. This network allows household members to have broadband access to the \nInternet with one member roaming from the kitchen to the backyard to the bedrooms.Figure 1.8  \u2666 Ethernet Internet accessEthernet\nswitchInstitutional\nrouter100 Mbps\n100 Mbps\n100 Mbps\nServerTo Institution\u2019s\nISP\n46     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\nWide-Area Wireless Access: 3G and LTE\nIncreasingly, devices such as iPhones and Android devices are being used to mes -\nsage, share photos in social networks, watch movies, and stream music while on the \nrun. These devices employ the same wireless infrastructure used for cellular teleph -\nony to send/receive packets through a base station that is operated by the cellular \nnetwork provider. Unlike WiFi, a user need only be within a few tens of kilometers \n(as opposed to a few tens of meters) of the base station.\nTelecommunications companies have made enormous investments in so-called \nthird-generation (3G) wireless, which provides packet-switched wide-area wire -\nless Internet access at speeds in excess of 1 Mbps. But even higher-speed wide-area \naccess technologies\u2014a fourth-generation (4G) of wide-area wireless networks\u2014are \nalready being deployed. LTE (for \u201cLong-Term Evolution\u201d\u2014a candidate for Bad \nAcronym of the Year Award) has its roots in 3G technology, and can achieve", "doc_id": "0dee402c-c817-463e-b8fa-f6b7cbad1043", "embedding": null, "doc_hash": "a28f17cfbaa5ba31cb5d1664e8c2e80aa1b12b32f1823a19f2e2d5791b1a810c", "extra_info": null, "node_info": {"start": 100199, "end": 103937}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "78822a72-71de-4dd3-9578-85bf49788e2a", "3": "7975aeb9-739a-4b9f-bbec-935319f8dfe4"}}, "__type__": "1"}, "7975aeb9-739a-4b9f-bbec-935319f8dfe4": {"__data__": {"text": "cellular teleph -\nony to send/receive packets through a base station that is operated by the cellular \nnetwork provider. Unlike WiFi, a user need only be within a few tens of kilometers \n(as opposed to a few tens of meters) of the base station.\nTelecommunications companies have made enormous investments in so-called \nthird-generation (3G) wireless, which provides packet-switched wide-area wire -\nless Internet access at speeds in excess of 1 Mbps. But even higher-speed wide-area \naccess technologies\u2014a fourth-generation (4G) of wide-area wireless networks\u2014are \nalready being deployed. LTE (for \u201cLong-Term Evolution\u201d\u2014a candidate for Bad \nAcronym of the Year Award) has its roots in 3G technology, and can achieve rates in \nexcess of 10 Mbps. LTE downstream rates of many tens of Mbps have been reported \nin commercial deployments. We\u2019ll cover the basic principles of wireless networks \nand mobility, as well as WiFi, 3G, and LTE technologies (and more!) in Chapter 7.\n1.2.2 Physical Media\nIn the previous subsection, we gave an overview of some of the most important \nnetwork access technologies in the Internet. As we described these technologies, \nwe also indicated the physical media used. For example, we said that HFC uses a \ncombination of fiber cable and coaxial cable. We said that DSL and Ethernet use \ncopper wire. And we said that mobile access networks use the radio spectrum. In this \nsubsection we provide a brief overview of these and other transmission media that \nare commonly used in the Internet.\nIn order to define what is meant by a physical medium, let us reflect on the brief life \nof a bit. Consider a bit traveling from one end system, through a series of links and rout -\ners, to another end system. This poor bit gets kicked around and transmitted many, many Figure 1.9  \u2666 A typical home networkCable\nhead end\nHouseInternet\n1.2  \u2022  THE NETWORK EDGE      47\ntimes! The source end system first transmits the bit, and shortly thereafter the first router \nin the series receives the bit; the first router then transmits the bit, and shortly thereafter \nthe second router receives the bit; and so on. Thus our bit, when traveling from source \nto destination, passes through a series of transmitter-receiver pairs. For each transmitter-\nreceiver pair, the bit is sent by propagating electromagnetic waves or optical pulses \nacross a physical medium . The physical medium can take many shapes and forms and \ndoes not have to be of the same type for each transmitter-receiver pair along the path. \nExamples of physical media include twisted-pair copper wire, coaxial cable, multimode \nfiber-optic cable, terrestrial radio spectrum, and satellite radio spectrum. Physical media \nfall into two categories: guided media  and unguided media . With guided media, the \nwaves are guided along a solid medium, such as a fiber-optic cable, a twisted-pair cop -\nper wire, or a coaxial cable. With unguided media, the waves propagate in the atmos -\nphere and in outer space, such as in a wireless LAN or a digital satellite channel.\nBut before we get into the characteristics of the various media types, let us say a \nfew words about their costs. The actual cost of the physical link (copper wire, fiber-optic \ncable, and so on) is often relatively minor compared with other networking costs. In par -\nticular, the labor cost associated with the installation of the physical link can be orders \nof magnitude higher than the cost of the material. For this reason, many builders install \ntwisted pair, optical fiber, and coaxial cable in every room in a building. Even if only one \nmedium is initially used, there is a good chance that another medium could be used in \nthe near future, and so money is saved by not having to lay additional wires in the future.\nTwisted-Pair Copper Wire\nThe least expensive and most commonly used guided transmission medium is", "doc_id": "7975aeb9-739a-4b9f-bbec-935319f8dfe4", "embedding": null, "doc_hash": "8a05486a499ec19c07c1f310462dab19dae05943989e0863d663d9f8fdc49bc3", "extra_info": null, "node_info": {"start": 103890, "end": 107757}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "0dee402c-c817-463e-b8fa-f6b7cbad1043", "3": "898d5649-af24-4cca-ae17-14baef9276de"}}, "__type__": "1"}, "898d5649-af24-4cca-ae17-14baef9276de": {"__data__": {"text": "into the characteristics of the various media types, let us say a \nfew words about their costs. The actual cost of the physical link (copper wire, fiber-optic \ncable, and so on) is often relatively minor compared with other networking costs. In par -\nticular, the labor cost associated with the installation of the physical link can be orders \nof magnitude higher than the cost of the material. For this reason, many builders install \ntwisted pair, optical fiber, and coaxial cable in every room in a building. Even if only one \nmedium is initially used, there is a good chance that another medium could be used in \nthe near future, and so money is saved by not having to lay additional wires in the future.\nTwisted-Pair Copper Wire\nThe least expensive and most commonly used guided transmission medium is twisted-\npair copper wire. For over a hundred years it has been used by telephone networks. \nIn fact, more than 99 percent of the wired connections from the telephone handset to \nthe local telephone switch use twisted-pair copper wire. Most of us have seen twisted \npair in our homes (or those of our parents or grandparents!) and work environments. \nTwisted pair consists of two insulated copper wires, each about 1 mm thick, arranged \nin a regular spiral pattern. The wires are twisted together to reduce the electrical inter -\nference from similar pairs close by. Typically, a number of pairs are bundled together \nin a cable by wrapping the pairs in a protective shield. A wire pair constitutes a single \ncommunication link. Unshielded twisted pair (UTP)  is commonly used for computer \nnetworks within a building, that is, for LANs. Data rates for LANs using twisted pair \ntoday range from 10 Mbps to 10 Gbps. The data rates that can be achieved depend on \nthe thickness of the wire and the distance between transmitter and receiver.\nWhen fiber-optic technology emerged in the 1980s, many people disparaged \ntwisted pair because of its relatively low bit rates. Some people even felt that fiber-\noptic technology would completely replace twisted pair. But twisted pair did not give \nup so easily. Modern twisted-pair technology, such as category 6a cable, can achieve \ndata rates of 10 Gbps for distances up to a hundred meters. In the end, twisted pair \nhas emerged as the dominant solution for high-speed LAN networking.\n48     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\nAs discussed earlier, twisted pair is also commonly used for residential Internet \naccess. We saw that dial-up modem technology enables access at rates of up to 56 \nkbps over twisted pair. We also saw that DSL (digital subscriber line) technology \nhas enabled residential users to access the Internet at tens of Mbps over twisted pair \n(when users live close to the ISP\u2019s central office).\nCoaxial Cable\nLike twisted pair, coaxial cable consists of two copper conductors, but the two con -\nductors are concentric rather than parallel. With this construction and special insula -\ntion and shielding, coaxial cable can achieve high data transmission rates. Coaxial \ncable is quite common in cable television systems. As we saw earlier, cable televi -\nsion systems have recently been coupled with cable modems to provide residential \nusers with Internet access at rates of tens of Mbps. In cable television and cable \nInternet access, the transmitter shifts the digital signal to a specific frequency band, \nand the resulting analog signal is sent from the transmitter to one or more receivers. \nCoaxial cable can be used as a guided shared medium . Specifically, a number of \nend systems can be connected directly to the cable, with each of the end systems \nreceiving whatever is sent by the other end systems.\nFiber Optics\nAn optical fiber is a thin, flexible medium that conducts pulses of light, with each \npulse representing a bit. A single optical fiber can support tremendous bit rates, up \nto tens or even hundreds of gigabits per second. They are immune", "doc_id": "898d5649-af24-4cca-ae17-14baef9276de", "embedding": null, "doc_hash": "02968a4e9e8d113134b4c89169a3ee0d5d6cebc5e38eb055e65ec4216e4ad270", "extra_info": null, "node_info": {"start": 107699, "end": 111650}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "7975aeb9-739a-4b9f-bbec-935319f8dfe4", "3": "bd3daff7-c0cc-4307-8436-3dc37ba83bb0"}}, "__type__": "1"}, "bd3daff7-c0cc-4307-8436-3dc37ba83bb0": {"__data__": {"text": "with cable modems to provide residential \nusers with Internet access at rates of tens of Mbps. In cable television and cable \nInternet access, the transmitter shifts the digital signal to a specific frequency band, \nand the resulting analog signal is sent from the transmitter to one or more receivers. \nCoaxial cable can be used as a guided shared medium . Specifically, a number of \nend systems can be connected directly to the cable, with each of the end systems \nreceiving whatever is sent by the other end systems.\nFiber Optics\nAn optical fiber is a thin, flexible medium that conducts pulses of light, with each \npulse representing a bit. A single optical fiber can support tremendous bit rates, up \nto tens or even hundreds of gigabits per second. They are immune to electromagnetic \ninterference, have very low signal attenuation up to 100 kilometers, and are very hard \nto tap. These characteristics have made fiber optics the preferred long-haul guided \ntransmission media, particularly for overseas links. Many of the long-distance tele -\nphone networks in the United States and elsewhere now use fiber optics exclusively. \nFiber optics is also prevalent in the backbone of the Internet. However, the high cost \nof optical devices\u2014such as transmitters, receivers, and switches\u2014has hindered their \ndeployment for short-haul transport, such as in a LAN or into the home in a residen -\ntial access network. The Optical Carrier (OC) standard link speeds range from 51.8 \nMbps to 39.8 Gbps; these specifications are often referred to as OC- n, where the link \nspeed equals n \u221e 51.8 Mbps. Standards in use today include OC-1, OC-3, OC-12, \nOC-24, OC-48, OC-96, OC-192, OC-768. [Mukherjee 2006, Ramaswami 2010]  \nprovide coverage of various aspects of optical networking.\nTerrestrial Radio Channels\nRadio channels carry signals in the electromagnetic spectrum. They are an attractive \nmedium because they require no physical wire to be installed, can penetrate walls, \nprovide connectivity to a mobile user, and can potentially carry a signal for long \n1.3  \u2022  THE NETWORK CORE      49\ndistances. The characteristics of a radio channel depend significantly on the propaga -\ntion environment and the distance over which a signal is to be carried. Environmental \nconsiderations determine path loss and shadow fading (which decrease the signal \nstrength as the signal travels over a distance and around/through obstructing objects), \nmultipath fading (due to signal reflection off of interfering objects), and interference \n(due to other transmissions and electromagnetic signals).\nTerrestrial radio channels can be broadly classified into three groups: those that \noperate over very short distance (e.g., with one or two meters); those that operate in \nlocal areas, typically spanning from ten to a few hundred meters; and those that oper -\nate in the wide area, spanning tens of kilometers. Personal devices such as wireless \nheadsets, keyboards, and medical devices operate over short distances; the wireless \nLAN technologies described in Section 1.2.1 use local-area radio channels; the cel -\nlular access technologies use wide-area radio channels. We\u2019ll discuss radio channels \nin detail in Chapter 7.\nSatellite Radio Channels\nA communication satellite links two or more Earth-based microwave transmitter/  \nreceivers, known as ground stations. The satellite receives transmissions on one fre -\nquency band, regenerates the signal using a repeater (discussed below), and transmits \nthe signal on another frequency. Two types of satellites are used in communications: \ngeostationary satellites  and low-earth orbiting (LEO) satellites  [Wiki Satellite 2016].\nGeostationary satellites permanently remain above the same spot on Earth. This \nstationary presence is achieved by placing the satellite in orbit at 36,000 kilometers \nabove Earth\u2019s surface. This huge distance from ground station through satellite back \nto", "doc_id": "bd3daff7-c0cc-4307-8436-3dc37ba83bb0", "embedding": null, "doc_hash": "8ec13adcc1b0179d24ee0a75b6f8c47daf622ac799e44cc44384da7b5ad8307b", "extra_info": null, "node_info": {"start": 111680, "end": 115601}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "898d5649-af24-4cca-ae17-14baef9276de", "3": "bb5a1511-c471-4b43-b69c-20b75f118834"}}, "__type__": "1"}, "bb5a1511-c471-4b43-b69c-20b75f118834": {"__data__": {"text": "We\u2019ll discuss radio channels \nin detail in Chapter 7.\nSatellite Radio Channels\nA communication satellite links two or more Earth-based microwave transmitter/  \nreceivers, known as ground stations. The satellite receives transmissions on one fre -\nquency band, regenerates the signal using a repeater (discussed below), and transmits \nthe signal on another frequency. Two types of satellites are used in communications: \ngeostationary satellites  and low-earth orbiting (LEO) satellites  [Wiki Satellite 2016].\nGeostationary satellites permanently remain above the same spot on Earth. This \nstationary presence is achieved by placing the satellite in orbit at 36,000 kilometers \nabove Earth\u2019s surface. This huge distance from ground station through satellite back \nto ground station introduces a substantial signal propagation delay of 280 millisec -\nonds. Nevertheless, satellite links, which can operate at speeds of hundreds of Mbps, \nare often used in areas without access to DSL or cable-based Internet access.\nLEO satellites are placed much closer to Earth and do not remain permanently \nabove one spot on Earth. They rotate around Earth (just as the Moon does) and may \ncommunicate with each other, as well as with ground stations. To provide continuous \ncoverage to an area, many satellites need to be placed in orbit. There are currently  \nmany low-altitude communication systems in development. LEO satellite  technology \nmay be used for Internet access sometime in the future.\n1.3 The Network Core\nHaving examined the Internet\u2019s edge, let us now delve more deeply inside the net -\nwork core\u2014the mesh of packet switches and links that interconnects the Internet\u2019s \nend systems. Figure 1.10 highlights the network core with thick, shaded lines.\n50     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\nFigure 1.10  \u2666 The network coreNational or\nGlobal ISP\nMobile Network\nLocal or\nRegional ISP\nEnterprise NetworkHome Network\n1.3  \u2022  THE NETWORK CORE      51\n1.3.1 Packet Switching\nIn a network application, end systems exchange messages  with each other. Mes -\nsages can contain anything the application designer wants. Messages may perform \na control function (for example, the \u201cHi\u201d messages in our handshaking example in \nFigure 1. 2) or can contain data, such as an e-mail message, a JPEG image, or an \nMP3 audio file. To send a message from a source end system to a destination end \nsystem, the source breaks long messages into smaller chunks of data known as pack-\nets. Between source and destination, each packet travels through communication \nlinks and packet switches  (for which there are two predominant types, routers  and \nlink-layer switches ). Packets are transmitted over each communication link at a rate \nequal to the full transmission rate of the link. So, if a source end system or a packet \nswitch is sending a packet of L bits over a link with transmission rate R bits/sec, then \nthe time to transmit the packet is L / R seconds.\nStore-and-Forward Transmission\nMost packet switches use store-and-forward transmission  at the inputs to the \nlinks. Store-and-forward transmission means that the packet switch must receive \nthe entire packet before it can begin to transmit the first bit of the packet onto the \noutbound link. To explore store-and-forward transmission in more detail, consider \na simple network consisting of two end systems connected by a single router, as \nshown in Figure 1.11. A router will typically have many incident links, since its \njob is to switch an incoming packet onto an outgoing link; in this simple example, \nthe router has the rather simple task of transferring a packet from one (input) link \nto the only other attached link. In this example, the source has three packets, each \nconsisting of L bits, to send to the destination. At the snapshot of time shown in \nFigure 1. 11, the source has transmitted some of packet 1, and the front of", "doc_id": "bb5a1511-c471-4b43-b69c-20b75f118834", "embedding": null, "doc_hash": "7d8bd78ce4e3be5f31b2ce83f11670da722ca2a0656f76b4bd42e122f449d080", "extra_info": null, "node_info": {"start": 115583, "end": 119484}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "bd3daff7-c0cc-4307-8436-3dc37ba83bb0", "3": "5a164584-56dd-4f2a-94f6-1483b152531e"}}, "__type__": "1"}, "5a164584-56dd-4f2a-94f6-1483b152531e": {"__data__": {"text": "transmission means that the packet switch must receive \nthe entire packet before it can begin to transmit the first bit of the packet onto the \noutbound link. To explore store-and-forward transmission in more detail, consider \na simple network consisting of two end systems connected by a single router, as \nshown in Figure 1.11. A router will typically have many incident links, since its \njob is to switch an incoming packet onto an outgoing link; in this simple example, \nthe router has the rather simple task of transferring a packet from one (input) link \nto the only other attached link. In this example, the source has three packets, each \nconsisting of L bits, to send to the destination. At the snapshot of time shown in \nFigure 1. 11, the source has transmitted some of packet 1, and the front of packet 1 \nhas already arrived at the router. Because the router employs store-and-forwarding, \nat this instant of time, the router cannot transmit the bits it has received; instead it \nmust first buffer (i.e., \u201cstore\u201d) the packet\u2019s bits. Only after the router has received \nall of the packet\u2019s bits can it begin to transmit (i.e., \u201cforward\u201d) the packet onto the \noutbound link. To gain some insight into store-and-forward transmission, let\u2019s now \ncalculate the amount of time that elapses from when the source begins to send the \npacket until the destination has received the entire packet. (Here we will ignore \npropagation delay\u2014the time it takes for the bits to travel across the wire at near \nthe speed of light\u2014which will be discussed in Section 1.4.) The source begins to \ntransmit at time 0; at time L/R seconds, the source has transmitted the entire packet, \nand the entire packet has been received and stored at the router (since there is no \npropagation delay). At time L/R seconds, since the router has just received the entire \npacket, it can begin to transmit the packet onto the outbound link towards the des -\ntination; at time 2 L/R, the router has transmitted the entire packet, and the entire \npacket has been received by the destination. Thus, the total delay is 2 L/R. If the \n52     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\nswitch instead forwarded bits as soon as they arrive (without first receiving the entire \npacket), then the total delay would be L/R since bits are not held up at the router. \nBut, as we will discuss in Section 1.4, routers need to receive, store, and process  the \nentire packet before forwarding.\nNow let\u2019s calculate the amount of time that elapses from when the source begins \nto send the first packet until the destination has received all three packets. As before, \nat time L/R, the router begins to forward the first packet. But also at time L/R the \nsource will begin to send the second packet, since it has just finished sending the \nentire first packet. Thus, at time 2 L/R, the destination has received the first packet \nand the router has received the second packet. Similarly, at time 3 L/R, the destina -\ntion has received the first two packets and the router has received the third packet. \nFinally, at time 4 L/R the destination has received all three packets!\nLet\u2019s now consider the general case of sending one packet from source to des -\ntination over a path consisting of N links each of rate R (thus, there are N-1 routers \nbetween source and destination). Applying the same logic as above, we see that the \nend-to-end delay is:\n dend@to@end=N L\nR ( 1.1)\nYou may now want to try to determine what the delay would be for P packets sent \nover a series of N links.\nQueuing Delays and Packet Loss\nEach packet switch has multiple links attached to it. For each attached link, the \npacket switch has an output buffer  (also called an output queue ), which stores \npackets that", "doc_id": "5a164584-56dd-4f2a-94f6-1483b152531e", "embedding": null, "doc_hash": "a76107b2ff598d2f5330ce5731bb1d377bbc5a43167895360fff64cfda2ae3a9", "extra_info": null, "node_info": {"start": 119478, "end": 123230}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "bb5a1511-c471-4b43-b69c-20b75f118834", "3": "258050e8-6120-4bd8-b50e-e511ee3e45a4"}}, "__type__": "1"}, "258050e8-6120-4bd8-b50e-e511ee3e45a4": {"__data__": {"text": "has received the third packet. \nFinally, at time 4 L/R the destination has received all three packets!\nLet\u2019s now consider the general case of sending one packet from source to des -\ntination over a path consisting of N links each of rate R (thus, there are N-1 routers \nbetween source and destination). Applying the same logic as above, we see that the \nend-to-end delay is:\n dend@to@end=N L\nR ( 1.1)\nYou may now want to try to determine what the delay would be for P packets sent \nover a series of N links.\nQueuing Delays and Packet Loss\nEach packet switch has multiple links attached to it. For each attached link, the \npacket switch has an output buffer  (also called an output queue ), which stores \npackets that the router is about to send into that link. The output buffers play a key \nrole in packet switching. If an arriving packet needs to be transmitted onto a link but \nfinds the link busy with the transmission of another packet, the arriving packet must \nwait in the output buffer. Thus, in addition to the store-and-forward delays, packets \nsuffer output buffer queuing delays . These delays are variable and depend on the \nlevel of congestion in the network. Since the amount of buffer space is finite, an Figure 1.11  \u2666 Store-and-forward packet switchingSourceR bps1 2\nDestination Front of packet 1\nstored in router,\nawaiting remaining\nbits before forwarding3\n1.3  \u2022  THE NETWORK CORE      53\narriving packet may find that the buffer is completely full with other packets waiting \nfor transmission. In this case, packet loss  will occur\u2014either the arriving packet or \none of the already-queued packets will be dropped.\nFigure 1.12 illustrates a simple packet-switched network. As in Figure 1.11, \npackets are represented by three-dimensional slabs. The width of a slab represents \nthe number of bits in the packet. In this figure, all packets have the same width and \nhence the same length. Suppose Hosts A and B are sending packets to Host E. Hosts \nA and B first send their packets along 100 Mbps Ethernet links to the first router. \nThe router then directs these packets to the 15 Mbps link. If, during a short interval \nof time, the arrival rate of packets to the router (when converted to bits per second) \nexceeds 15 Mbps, congestion will occur at the router as packets queue in the link\u2019s \noutput buffer before being transmitted onto the link. For example, if Host A and B \neach send a burst of five packets back-to-back at the same time, then most of these \npackets will spend some time waiting in the queue. The situation is, in fact, entirely \nanalogous to many common-day situations\u2014for example, when we wait in line for a \nbank teller or wait in front of a tollbooth. We\u2019ll examine this queuing delay in more \ndetail in Section 1.4.\nForwarding Tables and Routing Protocols\nEarlier, we said that a router takes a packet arriving on one of its attached communi -\ncation links and forwards that packet onto another one of its attached communication \nlinks. But how does the router determine which link it should forward the packet \nonto? Packet forwarding is actually done in different ways in different types of  \ncomputer networks. Here, we briefly describe how it is done in the Internet.Figure 1.12  \u2666 Packet switching100 Mbps Ethernet\nKey:\nPacketsA\nBC\nDE15 Mbps\nQueue of\npackets waiting\nfor output link\n54     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\nIn the Internet, every end system has an address called an IP address. When a \nsource end system wants to send a packet to a destination end system, the source \nincludes the destination\u2019s IP address in the packet\u2019s header. As with postal addresses, \nthis address has a hierarchical structure. When a packet", "doc_id": "258050e8-6120-4bd8-b50e-e511ee3e45a4", "embedding": null, "doc_hash": "2c2c78811bac78f635abeaaf6375ad6652ff5ffcd7044bc6a68289c9c3472239", "extra_info": null, "node_info": {"start": 123306, "end": 127004}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "5a164584-56dd-4f2a-94f6-1483b152531e", "3": "951a9037-87ff-4907-a530-7ab50820a30b"}}, "__type__": "1"}, "951a9037-87ff-4907-a530-7ab50820a30b": {"__data__": {"text": "the router determine which link it should forward the packet \nonto? Packet forwarding is actually done in different ways in different types of  \ncomputer networks. Here, we briefly describe how it is done in the Internet.Figure 1.12  \u2666 Packet switching100 Mbps Ethernet\nKey:\nPacketsA\nBC\nDE15 Mbps\nQueue of\npackets waiting\nfor output link\n54     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\nIn the Internet, every end system has an address called an IP address. When a \nsource end system wants to send a packet to a destination end system, the source \nincludes the destination\u2019s IP address in the packet\u2019s header. As with postal addresses, \nthis address has a hierarchical structure. When a packet arrives at a router in the net -\nwork, the router examines a portion of the packet\u2019s destination address and forwards \nthe packet to an adjacent router. More specifically, each router has a forwarding \ntable  that maps destination addresses (or portions of the destination addresses) to that \nrouter\u2019s outbound links. When a packet arrives at a router, the router examines the \naddress and searches its forwarding table, using this destination address, to find the \nappropriate outbound link. The router then directs the packet to this outbound link.\nThe end-to-end routing process is analogous to a car driver who does not use \nmaps but instead prefers to ask for directions. For example, suppose Joe is driving \nfrom Philadelphia to 156 Lakeside Drive in Orlando, Florida. Joe first drives to his \nneighborhood gas station and asks how to get to 156 Lakeside Drive in Orlando, \nFlorida. The gas station attendant extracts the Florida portion of the address and tells \nJoe that he needs to get onto the interstate highway I-95 South, which has an entrance \njust next to the gas station. He also tells Joe that once he enters Florida, he should ask \nsomeone else there. Joe then takes I-95 South until he gets to Jacksonville, Florida, \nat which point he asks another gas station attendant for directions. The attendant \nextracts the Orlando portion of the address and tells Joe that he should continue on \nI-95 to Daytona Beach and then ask someone else. In Daytona Beach, another gas \nstation attendant also extracts the Orlando portion of the address and tells Joe that \nhe should take I-4 directly to Orlando. Joe takes I-4 and gets off at the Orlando exit. \nJoe goes to another gas station attendant, and this time the attendant extracts the \nLakeside Drive portion of the address and tells Joe the road he must follow to get to \nLakeside Drive. Once Joe reaches Lakeside Drive, he asks a kid on a bicycle how to \nget to his destination. The kid extracts the 156 portion of the address and points to \nthe house. Joe finally reaches his ultimate destination. In the above analogy, the gas \nstation attendants and kids on bicycles are analogous to routers.\nWe just learned that a router uses a packet\u2019s destination address to index a for -\nwarding table and determine the appropriate outbound link. But this statement begs \nyet another question: How do forwarding tables get set? Are they configured by hand \nin each and every router, or does the Internet use a more automated procedure? This \nissue will be studied in depth in Chapter 5 . But to whet your appetite here, we\u2019ll note \nnow that the Internet has a number of special routing protocols  that are used to auto -\nmatically set the forwarding tables. A routing protocol may, for example, determine \nthe shortest path from each router to each destination and use the shortest path results \nto configure the forwarding tables in the routers.\nHow would you actually like to see the end-to-end route that packets take in \nthe Internet? We now invite you to get your hands dirty by interacting with the \nTrace-route program. Simply visit the site www.traceroute.org, choose a source in \na particular country, and trace the", "doc_id": "951a9037-87ff-4907-a530-7ab50820a30b", "embedding": null, "doc_hash": "11fa25be5afe132c3847cbdd43bb59a8c7f8194b81f93d3e6a0cc58ee4b56135", "extra_info": null, "node_info": {"start": 127007, "end": 130890}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "258050e8-6120-4bd8-b50e-e511ee3e45a4", "3": "5fe168bb-a705-4b4f-90ae-21a686faa2f1"}}, "__type__": "1"}, "5fe168bb-a705-4b4f-90ae-21a686faa2f1": {"__data__": {"text": "each and every router, or does the Internet use a more automated procedure? This \nissue will be studied in depth in Chapter 5 . But to whet your appetite here, we\u2019ll note \nnow that the Internet has a number of special routing protocols  that are used to auto -\nmatically set the forwarding tables. A routing protocol may, for example, determine \nthe shortest path from each router to each destination and use the shortest path results \nto configure the forwarding tables in the routers.\nHow would you actually like to see the end-to-end route that packets take in \nthe Internet? We now invite you to get your hands dirty by interacting with the \nTrace-route program. Simply visit the site www.traceroute.org, choose a source in \na particular country, and trace the route from that source to your computer. (For a \ndiscussion of Traceroute, see Section 1.4.)\n1.3  \u2022  THE NETWORK CORE      55\n1.3.2 Circuit Switching\nThere are two fundamental approaches to moving data through a network of links \nand switches: circuit switching  and packet switching . Having covered packet-\nswitched networks in the previous subsection, we now turn our attention to circuit-\nswitched networks.\nIn circuit-switched networks, the resources needed along a path (buffers, link \ntransmission rate) to provide for communication between the end systems are \nreserved  for the duration of the communication session between the end systems.  \nIn packet-switched networks, these resources are not reserved; a session\u2019s messages \nuse the resources on demand and, as a consequence, may have to wait (that is, queue) \nfor access to a communication link. As a simple analogy, consider two restaurants, \none that requires reservations and another that neither requires reservations nor \naccepts them. For the restaurant that requires reservations, we have to go through \nthe hassle of calling before we leave home. But when we arrive at the restaurant we \ncan, in principle, immediately be seated and order our meal. For the restaurant that \ndoes not require reservations, we don\u2019t need to bother to reserve a table. But when \nwe arrive at the restaurant, we may have to wait for a table before we can be seated.\nTraditional telephone networks are examples of circuit-switched networks. \n Consider what happens when one person wants to send information (voice or facsimile)  \nto another over a telephone network. Before the sender can send the information, \nthe network must establish a connection between the sender and the receiver. This \nis a bona fide  connection for which the switches on the path between the sender and \nreceiver maintain connection state for that connection. In the jargon of telephony, \nthis connection is called a circuit . When the network establishes the circuit, it also \nreserves a constant transmission rate in the network\u2019s links (representing a fraction \nof each link\u2019s transmission capacity) for the duration of the connection. Since a given \ntransmission rate has been reserved for this sender-to-receiver connection, the sender \ncan transfer the data to the receiver at the guaranteed  constant rate.\nFigure 1. 13 illustrates a circuit-switched network. In this network, the four \ncircuit switches are interconnected by four links. Each of these links has four cir -\ncuits, so that each link can support four simultaneous connections. The hosts (for \nexample, PCs and workstations) are each directly connected to one of the switches. \nWhen two hosts want to communicate, the network establishes a dedicated end-\nto-end connection  between the two hosts. Thus, in order for Host A to communi -\ncate with Host B, the network must first reserve one circuit on each of two links. \nIn this example, the dedicated end-to-end connection uses the second circuit in \nthe first link and the fourth circuit in the second link. Because each link has four \ncircuits, for each link used by the end-to-end connection, the connection gets one \nfourth of the link\u2019s total transmission capacity for the duration of the", "doc_id": "5fe168bb-a705-4b4f-90ae-21a686faa2f1", "embedding": null, "doc_hash": "cfb637799ed7a05924ef8dfc2752e91e9035e52875f395c36a7af1ca1f8865f3", "extra_info": null, "node_info": {"start": 130846, "end": 134850}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "951a9037-87ff-4907-a530-7ab50820a30b", "3": "82878ad2-8b3d-4f4f-a6e7-6f853e8bb04d"}}, "__type__": "1"}, "82878ad2-8b3d-4f4f-a6e7-6f853e8bb04d": {"__data__": {"text": "by four links. Each of these links has four cir -\ncuits, so that each link can support four simultaneous connections. The hosts (for \nexample, PCs and workstations) are each directly connected to one of the switches. \nWhen two hosts want to communicate, the network establishes a dedicated end-\nto-end connection  between the two hosts. Thus, in order for Host A to communi -\ncate with Host B, the network must first reserve one circuit on each of two links. \nIn this example, the dedicated end-to-end connection uses the second circuit in \nthe first link and the fourth circuit in the second link. Because each link has four \ncircuits, for each link used by the end-to-end connection, the connection gets one \nfourth of the link\u2019s total transmission capacity for the duration of the connection. \nThus, for example, if each link between adjacent switches has a transmission rate of  \n1 Mbps, then each end-to-end circuit-switch connection gets 250 kbps of dedicated \ntransmission rate.\n56     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\nFigure 1.13  \u2666   A simple circuit-switched network consisting of four switches \nand four links\nIn contrast, consider what happens when one host wants to send a packet to \nanother host over a packet-switched network, such as the Internet. As with circuit \nswitching, the packet is transmitted over a series of communication links. But dif -\nferent from circuit switching, the packet is sent into the network without reserving \nany link resources whatsoever. If one of the links is congested because other packets \nneed to be transmitted over the link at the same time, then the packet will have to \nwait in a buffer at the sending side of the transmission link and suffer a delay. The \nInternet makes its best effort to deliver packets in a timely manner, but it does not \nmake any guarantees.\nMultiplexing in Circuit-Switched Networks\nA circuit in a link is implemented with either frequency-division multiplexing \n(FDM)  or time-division multiplexing (TDM) . With FDM, the frequency spectrum \nof a link is divided up among the connections established across the link. Specifi -\ncally, the link dedicates a frequency band to each connection for the  duration of the \nconnection. In telephone networks, this frequency band typically has a width of 4 \nkHz (that is, 4,000 hertz or 4,000 cycles per second). The width of the band is called, \nnot surprisingly, the bandwidth . FM radio stations also use FDM to share the fre -\nquency spectrum between 88 MHz and 108 MHz, with each station being allocated \na specific frequency band.\nFor a TDM link, time is divided into frames of fixed duration, and each frame is \ndivided into a fixed number of time slots. When the network establishes a connection \nacross a link, the network dedicates one time slot in every frame to this connection. \nThese slots are dedicated for the sole use of that connection, with one time slot avail -\nable for use (in every frame) to transmit the connection\u2019s data.\n1.3  \u2022  THE NETWORK CORE      57\nFigure 1. 14 illustrates FDM and TDM for a specific network link supporting \nup to four circuits. For FDM, the frequency domain is segmented into four bands, \neach of bandwidth 4 kHz. For TDM, the time domain is segmented into frames, with \nfour time slots in each frame; each circuit is assigned the same dedicated slot in the \nrevolving TDM frames. For TDM, the transmission rate of a circuit is equal to the \nframe rate multiplied by the number of bits in a slot. For example, if the link trans -\nmits 8,000 frames per second and each slot consists of 8 bits, then the transmission \nrate of each circuit is 64 kbps.\nProponents of packet switching have always argued that circuit switching is waste -\nful because the dedicated circuits are idle during silent periods . For example, when one \nperson in a telephone call stops talking, the idle network resources (frequency bands or \ntime slots in the links along the", "doc_id": "82878ad2-8b3d-4f4f-a6e7-6f853e8bb04d", "embedding": null, "doc_hash": "16a4b52974a8aae072e5a00a85932fdb91c045fe3ab2f50c91c1cbc6d622c507", "extra_info": null, "node_info": {"start": 134834, "end": 138768}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "5fe168bb-a705-4b4f-90ae-21a686faa2f1", "3": "d6825006-09ab-411a-b494-8862d6b5df86"}}, "__type__": "1"}, "d6825006-09ab-411a-b494-8862d6b5df86": {"__data__": {"text": "into four bands, \neach of bandwidth 4 kHz. For TDM, the time domain is segmented into frames, with \nfour time slots in each frame; each circuit is assigned the same dedicated slot in the \nrevolving TDM frames. For TDM, the transmission rate of a circuit is equal to the \nframe rate multiplied by the number of bits in a slot. For example, if the link trans -\nmits 8,000 frames per second and each slot consists of 8 bits, then the transmission \nrate of each circuit is 64 kbps.\nProponents of packet switching have always argued that circuit switching is waste -\nful because the dedicated circuits are idle during silent periods . For example, when one \nperson in a telephone call stops talking, the idle network resources (frequency bands or \ntime slots in the links along the connection\u2019s route) cannot be used by other ongoing \nconnections. As another example of how these resources can be underutilized, consider \na radiologist who uses a circuit-switched network to remotely access a series of x-rays. \nThe radiologist sets up a connection, requests an image, contemplates the image, and \nthen requests a new image. Network resources are allocated to the connection but are \nnot used (i.e., are wasted) during the radiologist\u2019s contemplation periods. Proponents \nof packet switching also enjoy pointing out that establishing end-to-end circuits and \nreserving end-to-end transmission capacity is complicated and requires complex sign -\naling software to coordinate the operation of the switches along the end-to-end path.Figure 1.14  \u2666   With FDM, each circuit continuously gets a fraction of the \nbandwidth. With TDM, each circuit gets all of the bandwidth \nperiodically during brief intervals of time (that is, during slots)4KHz\nTDMFDM\nLink Frequency\n4KHz\nSlot\nKey:\nAll slots labeled \u201c2\u201d are dedicated\nto a speci\ufb01c sender-receiver pair.Frame1\n223 41 234 12 34 1234\nTime \n58     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\nBefore we finish our discussion of circuit switching, let\u2019s work through a numer -\nical example that should shed further insight on the topic. Let us consider how long \nit takes to send a file of 640,000 bits from Host A to Host B over a circuit-switched \nnetwork. Suppose that all links in the network use TDM with 24 slots and have a bit \nrate of 1.536 Mbps. Also suppose that it takes 500 msec to establish an end-to-end \ncircuit before Host A can begin to transmit the file. How long does it take to send \nthe file? Each circuit has a transmission rate of (1.536 Mbps)/24 = 64 kbps, so it \ntakes (640,000 bits)/(64 kbps) = 10 seconds to transmit the file. To this 10 seconds \nwe add the circuit establishment time, giving 10.5 seconds to send the file. Note \nthat the transmission time is independent of the number of links: The transmission \ntime would be 10 seconds if the end-to-end circuit passed through one link or a \nhundred links. (The actual end-to-end delay also includes a propagation delay; see \nSection 1.4.)\nPacket Switching Versus Circuit Switching\nHaving described circuit switching and packet switching, let us compare the two. \nCritics of packet switching have often argued that packet switching is not suita -\nble for real-time services (for example, telephone calls and video conference calls) \nbecause of its variable and unpredictable end-to-end delays (due primarily to vari -\nable and unpredictable queuing delays). Proponents of packet switching argue that \n(1) it offers better sharing of transmission capacity than circuit switching and (2) it \nis simpler, more efficient, and less costly to implement than circuit switching. An  \ninteresting discussion of packet switching versus circuit switching is [Molinero-  \nFernandez 2002]. Generally speaking, people who do not like to hassle with  restaurant \nreservations", "doc_id": "d6825006-09ab-411a-b494-8862d6b5df86", "embedding": null, "doc_hash": "18e5b7a24db0002f6d2af80a6c20d8c03626dd5620e40b8907ea14892f1e8fd7", "extra_info": null, "node_info": {"start": 138780, "end": 142562}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "82878ad2-8b3d-4f4f-a6e7-6f853e8bb04d", "3": "62219533-1281-4650-93f9-ad363b4cfcc3"}}, "__type__": "1"}, "62219533-1281-4650-93f9-ad363b4cfcc3": {"__data__": {"text": "described circuit switching and packet switching, let us compare the two. \nCritics of packet switching have often argued that packet switching is not suita -\nble for real-time services (for example, telephone calls and video conference calls) \nbecause of its variable and unpredictable end-to-end delays (due primarily to vari -\nable and unpredictable queuing delays). Proponents of packet switching argue that \n(1) it offers better sharing of transmission capacity than circuit switching and (2) it \nis simpler, more efficient, and less costly to implement than circuit switching. An  \ninteresting discussion of packet switching versus circuit switching is [Molinero-  \nFernandez 2002]. Generally speaking, people who do not like to hassle with  restaurant \nreservations prefer packet switching to circuit switching.\nWhy is packet switching more efficient? Let\u2019s look at a simple example. Sup -\npose users share a 1 Mbps link. Also suppose that each user alternates between peri -\nods of activity, when a user generates data at a constant rate of 100 kbps, and periods \nof inactivity, when a user generates no data. Suppose further that a user is active only \n10 percent of the time (and is idly drinking coffee during the remaining 90 percent \nof the time). With circuit switching, 100 kbps must be reserved  for each  user at all \ntimes. For example, with circuit-switched TDM, if a one-second frame is divided \ninto 10 time slots of 100 ms each, then each user would be allocated one time slot \nper frame.\nThus, the circuit-switched link can support only 10 ( = 1 Mbps/100 kbps) simul -\ntaneous users. With packet switching, the probability that a specific user is active \nis 0.1 (that is, 10 percent). If there are 35 users, the probability that there are 11 or \nmore simultaneously active users is approximately 0.0004. (Homework Problem P8 \noutlines how this probability is obtained.) When there are 10 or fewer simultane -\nously active users (which happens with probability 0.9996), the aggregate arrival \nrate of data is less than or equal to 1 Mbps, the output rate of the link. Thus, when \nthere are 10 or fewer active users, users\u2019 packets flow through the link essentially \n1.3  \u2022  THE NETWORK CORE      59\nwithout delay, as is the case with circuit switching. When there are more than 10 \nsimultaneously active users, then the aggregate arrival rate of packets exceeds the \noutput capacity of the link, and the output queue will begin to grow. (It continues to \ngrow until the aggregate input rate falls back below 1 Mbps, at which point the queue \nwill begin to diminish in length.) Because the probability of having more than 10 \nsimultaneously active users is minuscule in this example, packet switching provides \nessentially the same performance as circuit switching, but does so while allowing for \nmore than three times the number of users.\nLet\u2019s now consider a second simple example. Suppose there are 10 users and \nthat one user suddenly generates one thousand 1,000-bit packets, while other users \nremain quiescent and do not generate packets. Under TDM circuit switching with 10 \nslots per frame and each slot consisting of 1,000 bits, the active user can only use its \none time slot per frame to transmit data, while the remaining nine time slots in each \nframe remain idle. It will be 10 seconds before all of the active user\u2019s one million \nbits of data has been transmitted. In the case of packet switching, the active user can \ncontinuously send its packets at the full link rate of 1 Mbps, since there are no other \nusers generating packets that need to be multiplexed with the active user\u2019s packets. \nIn this case, all of the active user\u2019s data will be transmitted within 1 second.\nThe above examples illustrate two ways in which the performance of packet \nswitching can be superior to that of circuit switching. They also highlight the cru -\ncial difference between the two forms of sharing a link\u2019s transmission rate", "doc_id": "62219533-1281-4650-93f9-ad363b4cfcc3", "embedding": null, "doc_hash": "8b1625d24241226377b57ed5bce3bd78fa9eecf37154affe2405e1b572f7bf2d", "extra_info": null, "node_info": {"start": 142546, "end": 146494}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "d6825006-09ab-411a-b494-8862d6b5df86", "3": "afd0415f-2a85-4e3d-a0c3-c435d3e384e6"}}, "__type__": "1"}, "afd0415f-2a85-4e3d-a0c3-c435d3e384e6": {"__data__": {"text": "bits, the active user can only use its \none time slot per frame to transmit data, while the remaining nine time slots in each \nframe remain idle. It will be 10 seconds before all of the active user\u2019s one million \nbits of data has been transmitted. In the case of packet switching, the active user can \ncontinuously send its packets at the full link rate of 1 Mbps, since there are no other \nusers generating packets that need to be multiplexed with the active user\u2019s packets. \nIn this case, all of the active user\u2019s data will be transmitted within 1 second.\nThe above examples illustrate two ways in which the performance of packet \nswitching can be superior to that of circuit switching. They also highlight the cru -\ncial difference between the two forms of sharing a link\u2019s transmission rate among \nmultiple data streams. Circuit switching pre-allocates use of the transmission link \nregardless of demand, with allocated but unneeded link time going unused. Packet \nswitching on the other hand allocates link use on demand.  Link transmission capacity \nwill be shared on a packet-by-packet basis only among those users who have packets \nthat need to be transmitted over the link.\nAlthough packet switching and circuit switching are both prevalent in today\u2019s \ntelecommunication networks, the trend has certainly been in the direction of packet \nswitching. Even many of today\u2019s circuit-switched telephone networks are slowly \nmigrating toward packet switching. In particular, telephone networks often use \npacket switching for the expensive overseas portion of a telephone call.\n1.3.3 A Network of Networks\nWe saw earlier that end systems (PCs, smartphones, Web servers, mail servers, and \nso on) connect into the Internet via an access ISP. The access ISP can provide either \nwired or wireless connectivity, using an array of access technologies including DSL, \ncable, FTTH, Wi-Fi, and cellular. Note that the access ISP does not have to be a \ntelco or a cable company; instead it can be, for example, a university (providing \nInternet access to students, staff, and faculty), or a company (providing access for \nits employees). But connecting end users and content providers into an access ISP is \nonly a small piece of solving the puzzle of connecting the billions of end systems that \nmake up the Internet. To complete this puzzle, the access ISPs themselves must be \n60     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\ninterconnected. This is done by creating a network of networks \u2014understanding this \nphrase is the key to understanding the Internet.\nOver the years, the network of networks that forms the Internet has evolved into \na very complex structure. Much of this evolution is driven by economics and national \npolicy, rather than by performance considerations. In order to understand today\u2019s \nInternet network structure, let\u2019s incrementally build a series of network structures, \nwith each new structure being a better approximation of the complex Internet that we \nhave today. Recall that the overarching goal is to interconnect the access ISPs so that \nall end systems can send packets to each other. One naive approach would be to have \neach access ISP directly  connect with every other access ISP. Such a mesh design is, \nof course, much too costly for the access ISPs, as it would require each access ISP \nto have a separate communication link to each of the hundreds of thousands of other \naccess ISPs all over the world.\nOur first network structure, Network Structure 1 , interconnects all of the access \nISPs with a single  global transit ISP . Our (imaginary) global transit ISP is a network \nof routers and communication links that not only spans the globe, but also has at least \none router near each of the hundreds of thousands of access ISPs. Of course, it would \nbe very costly for the global ISP to build such an extensive network. To be profitable, \nit would naturally charge each of the access ISPs for connectivity, with the pricing \nreflecting (but not necessarily directly proportional to) the amount of", "doc_id": "afd0415f-2a85-4e3d-a0c3-c435d3e384e6", "embedding": null, "doc_hash": "f9ad7c24dbe3e750ad05b1dff54bee9852e765f6d6872ee53f88b0737bb65d91", "extra_info": null, "node_info": {"start": 146497, "end": 150545}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "62219533-1281-4650-93f9-ad363b4cfcc3", "3": "e51f519b-f653-4b41-99f8-53299da256e3"}}, "__type__": "1"}, "e51f519b-f653-4b41-99f8-53299da256e3": {"__data__": {"text": "course, much too costly for the access ISPs, as it would require each access ISP \nto have a separate communication link to each of the hundreds of thousands of other \naccess ISPs all over the world.\nOur first network structure, Network Structure 1 , interconnects all of the access \nISPs with a single  global transit ISP . Our (imaginary) global transit ISP is a network \nof routers and communication links that not only spans the globe, but also has at least \none router near each of the hundreds of thousands of access ISPs. Of course, it would \nbe very costly for the global ISP to build such an extensive network. To be profitable, \nit would naturally charge each of the access ISPs for connectivity, with the pricing \nreflecting (but not necessarily directly proportional to) the amount of traffic an access \nISP exchanges with the global ISP. Since the access ISP pays the global transit ISP, the \naccess ISP is said to be a customer  and the global transit ISP is said to be a provider .\nNow if some company builds and operates a global transit ISP that is profit -\nable, then it is natural for other companies to build their own global transit ISPs \nand compete with the original global transit ISP. This leads to Network Structure 2 ,  \nwhich consists of the hundreds of thousands of access ISPs and multiple  global \n transit ISPs. The access ISPs certainly prefer Network Structure 2 over Network \nStructure 1 since they can now choose among the competing global transit providers \nas a function of their pricing and services. Note, however, that the global transit ISPs \nthemselves must interconnect: Otherwise access ISPs connected to one of the global \ntransit providers would not be able to communicate with access ISPs connected to the  \nother global transit providers.\nNetwork Structure 2, just described, is a two-tier hierarchy with global transit \nproviders residing at the top tier and access ISPs at the bottom tier. This assumes \nthat global transit ISPs are not only capable of getting close to each and every access \nISP, but also find it economically desirable to do so. In reality, although some ISPs \ndo have impressive global coverage and do directly connect with many access ISPs, \nno ISP has presence in each and every city in the world. Instead, in any given region, \nthere may be a regional ISP  to which the access ISPs in the region connect. Each \nregional ISP then connects to tier-1 ISPs . Tier-1 ISPs are similar to our (imaginary) \nglobal transit ISP; but tier-1 ISPs, which actually do exist, do not have a presence \nin every city in the world. There are approximately a dozen tier-1 ISPs, including \nLevel 3 Communications, AT&T, Sprint, and NTT. Interestingly, no group officially \n1.3  \u2022  THE NETWORK CORE      61\nsanctions tier-1 status; as the saying goes\u2014if you have to ask if you\u2019re a member of \na group, you\u2019re probably not.\nReturning to this network of networks, not only are there multiple competing \ntier-1 ISPs, there may be multiple competing regional ISPs in a region. In such a \nhierarchy, each access ISP pays the regional ISP to which it connects, and each \nregional ISP pays the tier-1 ISP to which it connects. (An access ISP can also connect \ndirectly to a tier-1 ISP, in which case it pays the tier-1 ISP). Thus, there is customer-\nprovider relationship at each level of the hierarchy. Note that the tier-1 ISPs do not \npay anyone as they are at the top of the hierarchy. To further complicate matters, in \nsome regions, there may be a larger regional ISP (possibly spanning an entire coun -\ntry) to which the smaller regional ISPs in that region connect; the larger regional \nISP then connects to a tier-1 ISP. For example, in China, there are access ISPs in  \neach city, which connect to provincial ISPs, which in turn connect to national ISPs, \nwhich finally connect to tier-1", "doc_id": "e51f519b-f653-4b41-99f8-53299da256e3", "embedding": null, "doc_hash": "2c17a6fcf80adc71e4e9cacb8bcc9343e4d0ddb86603584485938556a94a35ca", "extra_info": null, "node_info": {"start": 150544, "end": 154385}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "afd0415f-2a85-4e3d-a0c3-c435d3e384e6", "3": "ae4876e2-4d48-418d-9fcf-802119b6a019"}}, "__type__": "1"}, "ae4876e2-4d48-418d-9fcf-802119b6a019": {"__data__": {"text": "ISP to which it connects. (An access ISP can also connect \ndirectly to a tier-1 ISP, in which case it pays the tier-1 ISP). Thus, there is customer-\nprovider relationship at each level of the hierarchy. Note that the tier-1 ISPs do not \npay anyone as they are at the top of the hierarchy. To further complicate matters, in \nsome regions, there may be a larger regional ISP (possibly spanning an entire coun -\ntry) to which the smaller regional ISPs in that region connect; the larger regional \nISP then connects to a tier-1 ISP. For example, in China, there are access ISPs in  \neach city, which connect to provincial ISPs, which in turn connect to national ISPs, \nwhich finally connect to tier-1 ISPs [Tian 2012]. We refer to this multi-tier hierarchy, \nwhich is still only a crude approximation of today\u2019s Internet, as Network Structure 3 .\nTo build a network that more closely resembles today\u2019s Internet, we must add \npoints of presence (PoPs), multi-homing, peering, and Internet exchange points \n(IXPs) to the hierarchical Network Structure 3. PoPs exist in all levels of the hier -\narchy, except for the bottom (access ISP) level. A PoP is simply a group of one or \nmore routers (at the same location) in the provider\u2019s network where customer ISPs \ncan connect into the provider ISP. For a customer network to connect to a provider\u2019s \nPoP, it can lease a high-speed link from a third-party telecommunications provider \nto directly connect one of its routers to a router at the PoP. Any ISP (except for tier-1 \nISPs) may choose to multi-home , that is, to connect to two or more provider ISPs. So, \nfor example, an access ISP may multi-home with two regional ISPs, or it may multi-\nhome with two regional ISPs and also with a tier-1 ISP. Similarly, a regional ISP may \nmulti-home with multiple tier-1 ISPs. When an ISP multi-homes, it can continue to \nsend and receive packets into the Internet even if one of its providers has a failure.\nAs we just learned, customer ISPs pay their provider ISPs to obtain global Inter -\nnet interconnectivity. The amount that a customer ISP pays a provider ISP reflects \nthe amount of traffic it exchanges with the provider. To reduce these costs, a pair \nof nearby ISPs at the same level of the hierarchy can peer , that is, they can directly \nconnect their networks together so that all the traffic between them passes over the \ndirect connection rather than through upstream intermediaries. When two ISPs peer, \nit is typically settlement-free, that is, neither ISP pays the other. As noted earlier, \ntier-1 ISPs also peer with one another, settlement-free. For a readable discussion of \npeering and customer-provider relationships, see [Van der Berg 2008]. Along these \nsame lines, a third-party company can create an Internet Exchange Point (IXP) , \nwhich is a meeting point where multiple ISPs can peer together. An IXP is typically \nin a stand-alone building with its own switches [Ager 2012]. There are over 400 \nIXPs in the Internet today [IXP List 2016]. We refer to this ecosystem\u2014consisting of \naccess ISPs, regional ISPs, tier-1 ISPs, PoPs, multi-homing, peering, and IXPs\u2014as \nNetwork Structure 4 .\n62     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\nWe now finally arrive at Network Structure 5,  which describes today\u2019s Internet. \nNetwork Structure 5, illustrated in Figure 1.15, builds on top of Network Structure \n4 by adding content-provider networks . Google is currently one of the leading \nexamples of such a content-provider network. As of this writing, it is estimated that \nGoogle has 50\u2013100 data centers distributed across North America, Europe, Asia, \nSouth America, and", "doc_id": "ae4876e2-4d48-418d-9fcf-802119b6a019", "embedding": null, "doc_hash": "2d149f0163c757c304fdd10ca042d15c037cf97302ea4fb5569bf205fe4d9f6c", "extra_info": null, "node_info": {"start": 154470, "end": 158113}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "e51f519b-f653-4b41-99f8-53299da256e3", "3": "6dc09ded-00e8-45ed-b90f-15bffa78c3c5"}}, "__type__": "1"}, "6dc09ded-00e8-45ed-b90f-15bffa78c3c5": {"__data__": {"text": "in the Internet today [IXP List 2016]. We refer to this ecosystem\u2014consisting of \naccess ISPs, regional ISPs, tier-1 ISPs, PoPs, multi-homing, peering, and IXPs\u2014as \nNetwork Structure 4 .\n62     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\nWe now finally arrive at Network Structure 5,  which describes today\u2019s Internet. \nNetwork Structure 5, illustrated in Figure 1.15, builds on top of Network Structure \n4 by adding content-provider networks . Google is currently one of the leading \nexamples of such a content-provider network. As of this writing, it is estimated that \nGoogle has 50\u2013100 data centers distributed across North America, Europe, Asia, \nSouth America, and Australia. Some of these data centers house over one hundred \nthousand servers, while other data centers are smaller, housing only hundreds of \nservers. The Google data centers are all interconnected via Google\u2019s private TCP/IP \nnetwork, which spans the entire globe but is nevertheless separate from the public \nInternet. Importantly, the Google private network only carries traffic to/from Google \nservers. As shown in Figure 1.15, the Google private network attempts to \u201cbypass\u201d \nthe upper tiers of the Internet by peering (settlement free) with lower-tier ISPs, either \nby directly connecting with them or by connecting with them at IXPs [Labovitz \n2010]. However, because many access ISPs can still only be reached by transiting \nthrough tier-1 networks, the Google network also connects to tier-1 ISPs, and pays \nthose ISPs for the traffic it exchanges with them. By creating its own network, a con -\ntent provider not only reduces its payments to upper-tier ISPs, but also has greater \ncontrol of how its services are ultimately delivered to end users. Google\u2019s network \ninfrastructure is described in greater detail in Section 2.6.\nIn summary, today\u2019s Internet\u2014a network of networks\u2014is complex, consisting \nof a dozen or so tier-1 ISPs and hundreds of thousands of lower-tier ISPs. The ISPs \nare diverse in their coverage, with some spanning multiple continents and oceans, \nand others limited to narrow geographic regions. The lower-tier ISPs connect to the \nhigher-tier ISPs, and the higher-tier ISPs interconnect with one another. Users and \ncontent providers are customers of lower-tier ISPs, and lower-tier ISPs are customers \nof higher-tier ISPs. In recent years, major content providers have also created their \nown networks and connect directly into lower-tier ISPs where possible.\nFigure 1.15  \u2666 Interconnection of ISPsaccess\nISPaccess\nISPaccess\nISPaccess\nISPaccess\nISPaccess\nISPaccess\nISPaccess\nISPRegional\nISPTier 1\nISPContent provider\n(e.g., Google)Tier 1\nISP\nIXP\nRegional\nISPIXP IXP\n1.4  \u2022  DELAY, LOSS, AND THROUGHPUT IN PACKET-SWITCHED NETWORKS      63\n1.4 Delay, Loss, and Throughput  \nin Packet-Switched Networks\nBack in Section 1.1 we said that the Internet can be viewed as an infrastructure that \nprovides services to distributed applications running on end systems. Ideally, we \nwould like Internet services to be able to move as much data as we want between any \ntwo end systems, instantaneously, without any loss of data. Alas, this is a lofty goal, \none that is unachievable in reality. Instead, computer networks necessarily constrain \nthroughput (the amount of data per second that can be transferred) between end sys -\ntems, introduce delays between end systems, and can actually lose packets. On one \nhand, it is unfortunate that the physical laws of reality introduce delay and loss as \nwell as constrain throughput. On the other hand, because computer networks have \nthese problems, there are many fascinating issues surrounding how to deal with the \nproblems\u2014more than enough issues to", "doc_id": "6dc09ded-00e8-45ed-b90f-15bffa78c3c5", "embedding": null, "doc_hash": "4a83cdd9c3f203dc40f6514409639deb3f336fa96fac153485ced1c68d0e7525", "extra_info": null, "node_info": {"start": 158118, "end": 161820}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "ae4876e2-4d48-418d-9fcf-802119b6a019", "3": "90d7236b-c218-4670-8ea5-7c24a954ef5b"}}, "__type__": "1"}, "90d7236b-c218-4670-8ea5-7c24a954ef5b": {"__data__": {"text": "an infrastructure that \nprovides services to distributed applications running on end systems. Ideally, we \nwould like Internet services to be able to move as much data as we want between any \ntwo end systems, instantaneously, without any loss of data. Alas, this is a lofty goal, \none that is unachievable in reality. Instead, computer networks necessarily constrain \nthroughput (the amount of data per second that can be transferred) between end sys -\ntems, introduce delays between end systems, and can actually lose packets. On one \nhand, it is unfortunate that the physical laws of reality introduce delay and loss as \nwell as constrain throughput. On the other hand, because computer networks have \nthese problems, there are many fascinating issues surrounding how to deal with the \nproblems\u2014more than enough issues to fill a course on computer networking and to \nmotivate thousands of PhD theses! In this section, we\u2019ll begin to examine and quan -\ntify delay, loss, and throughput in computer networks.\n1.4.1 Overview of Delay in Packet-Switched Networks\nRecall that a packet starts in a host (the source), passes through a series of routers, \nand ends its journey in another host (the destination). As a packet travels from one \nnode (host or router) to the subsequent node (host or router) along this path, the \npacket suffers from several types of delays at each  node along the path. The most \nimportant of these delays are the nodal processing delay , queuing delay , transmis-\nsion delay , and propagation delay ; together, these delays accumulate to give a total \nnodal delay . The performance of many Internet applications\u2014such as search, Web \nbrowsing, e-mail, maps, instant messaging, and voice-over-IP\u2014are greatly affected \nby network delays. In order to acquire a deep understanding of packet switching and \ncomputer networks, we must understand the nature and importance of these delays.\nTypes of Delay\nLet\u2019s explore these delays in the context of Figure 1.16. As part of its end-to-end \nroute between source and destination, a packet is sent from the upstream node \nthrough router A to router B. Our goal is to characterize the nodal delay at router A. \nNote that router A has an outbound link leading to router B. This link is preceded \nby a queue (also known as a buffer). When the packet arrives at router A from the \nupstream node, router A examines the packet\u2019s header to determine the appropriate \noutbound link for the packet and then directs the packet to this link. In this exam -\nple, the outbound link for the packet is the one that leads to router B. A packet can \nbe transmitted on a link only if there is no other packet currently being transmitted \non the link and if there are no other packets preceding it in the queue; if the link is \n64     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\n currently busy or if there are other packets already queued for the link, the newly \narriving packet will then join the queue.\nProcessing Delay\nThe time required to examine the packet\u2019s header and determine where to direct \nthe packet is part of the processing delay . The processing delay can also include \nother factors, such as the time needed to check for bit-level errors in the packet \nthat occurred in transmitting the packet\u2019s bits from the upstream node to router A. \nProcessing delays in high-speed routers are typically on the order of microseconds \nor less. After this nodal processing, the router directs the packet to the queue that \nprecedes the link to router B. (In Chapter 4 we\u2019ll study the details of how a router \noperates.)\nQueuing Delay\nAt the queue, the packet experiences a queuing delay  as it waits to be transmitted \nonto the link. The length of the queuing delay of a specific packet will depend on the \nnumber of earlier-arriving packets that are queued and waiting for", "doc_id": "90d7236b-c218-4670-8ea5-7c24a954ef5b", "embedding": null, "doc_hash": "d246dd59cc0bf0ab41635881748555f81bacfebcbfe3fe881218fb069f357bb8", "extra_info": null, "node_info": {"start": 161697, "end": 165528}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "6dc09ded-00e8-45ed-b90f-15bffa78c3c5", "3": "d4c3880d-3f3e-420a-83bf-cd904882846e"}}, "__type__": "1"}, "d4c3880d-3f3e-420a-83bf-cd904882846e": {"__data__": {"text": "packet is part of the processing delay . The processing delay can also include \nother factors, such as the time needed to check for bit-level errors in the packet \nthat occurred in transmitting the packet\u2019s bits from the upstream node to router A. \nProcessing delays in high-speed routers are typically on the order of microseconds \nor less. After this nodal processing, the router directs the packet to the queue that \nprecedes the link to router B. (In Chapter 4 we\u2019ll study the details of how a router \noperates.)\nQueuing Delay\nAt the queue, the packet experiences a queuing delay  as it waits to be transmitted \nonto the link. The length of the queuing delay of a specific packet will depend on the \nnumber of earlier-arriving packets that are queued and waiting for transmission onto \nthe link. If the queue is empty and no other packet is currently being transmitted, then \nour packet\u2019s queuing delay will be zero. On the other hand, if the traffic is heavy and \nmany other packets are also waiting to be transmitted, the queuing delay will be long. \nWe will see shortly that the number of packets that an arriving packet might expect \nto find is a function of the intensity and nature of the traffic arriving at the queue. \n Queuing delays can be on the order of microseconds to milliseconds in practice.\nTransmission Delay\nAssuming that packets are transmitted in a first-come-first-served manner, as is com -\nmon in packet-switched networks, our packet can be transmitted only after all the \npackets that have arrived before it have been transmitted. Denote the length of the Figure 1.16  \u2666 The nodal delay at router AA\nB\nNodal\nprocessingQueueing\n(waiting for\ntransmission)TransmissionPropagation\n1.4  \u2022  DELAY, LOSS, AND THROUGHPUT IN PACKET-SWITCHED NETWORKS      65\npacket by L bits, and denote the transmission rate of the link from router A to router \nB by R bits/sec. For example, for a 10 Mbps Ethernet link, the rate is R = 10 Mbps; \nfor a 100 Mbps Ethernet link, the rate is R = 100 Mbps. The transmission delay  is \nL/R. This is the amount of time required to push (that is, transmit) all of the packet\u2019s \nbits into the link. Transmission delays are typically on the order of microseconds to \nmilliseconds in practice.\nPropagation Delay\nOnce a bit is pushed into the link, it needs to propagate to router B. The time required \nto propagate from the beginning of the link to router B is the propagation delay . The \nbit propagates at the propagation speed of the link. The propagation speed depends \non the physical medium of the link (that is, fiber optics, twisted-pair copper wire, and \nso on) and is in the range of\n 2#108 meters/sec to 3#108 meters/sec\nwhich is equal to, or a little less than, the speed of light. The propagation delay is the \ndistance between two routers divided by the propagation speed. That is, the propaga -\ntion delay is d/s, where d is the distance between router A and router B and s is the \npropagation speed of the link. Once the last bit of the packet propagates to node B, \nit and all the preceding bits of the packet are stored in router B. The whole process \nthen continues with router B now performing the forwarding. In wide-area networks, \npropagation delays are on the order of milliseconds.\nComparing Transmission and Propagation Delay\nNewcomers to the field of computer networking sometimes have difficulty under -\nstanding the difference between transmission delay and propagation delay. The dif -\nference is subtle but important. The transmission delay is the amount of time required \nfor the router to push out the packet; it is a function of the packet\u2019s length and the \ntransmission rate of the link, but has nothing to do with the distance between the two \nrouters. The propagation delay, on the other hand, is", "doc_id": "d4c3880d-3f3e-420a-83bf-cd904882846e", "embedding": null, "doc_hash": "73246896e9b193bc29eb823518af64d3be14c9e162671b21ec5baa885514449d", "extra_info": null, "node_info": {"start": 165584, "end": 169361}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "90d7236b-c218-4670-8ea5-7c24a954ef5b", "3": "6f846041-1670-4913-b300-358a77d8fb8b"}}, "__type__": "1"}, "6f846041-1670-4913-b300-358a77d8fb8b": {"__data__": {"text": "last bit of the packet propagates to node B, \nit and all the preceding bits of the packet are stored in router B. The whole process \nthen continues with router B now performing the forwarding. In wide-area networks, \npropagation delays are on the order of milliseconds.\nComparing Transmission and Propagation Delay\nNewcomers to the field of computer networking sometimes have difficulty under -\nstanding the difference between transmission delay and propagation delay. The dif -\nference is subtle but important. The transmission delay is the amount of time required \nfor the router to push out the packet; it is a function of the packet\u2019s length and the \ntransmission rate of the link, but has nothing to do with the distance between the two \nrouters. The propagation delay, on the other hand, is the time it takes a bit to propa -\ngate from one router to the next; it is a function of the distance between the two rout -\ners, but has nothing to do with the packet\u2019s length or the transmission rate of the link.\nAn analogy might clarify the notions of transmission and propagation delay. \nConsider a highway that has a tollbooth every 100 kilometers, as shown in Figure \n1.17. You can think of the highway segments between tollbooths as links and the \ntollbooths as routers. Suppose that cars travel (that is, propagate) on the highway \nat a rate of 100 km/hour (that is, when a car leaves a tollbooth, it instantaneously \naccelerates to 100 km/hour and maintains that speed between tollbooths). Suppose \nnext that 10 cars, traveling together as a caravan, follow each other in a fixed order. \nYou can think of each car as a bit and the caravan as a packet. Also suppose that each VideoNote\nExploring propagation \ndelay and transmission \ndelay\n66     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\ntollbooth services (that is, transmits) a car at a rate of one car per 12 seconds, and that \nit is late at night so that the caravan\u2019s cars are the only cars on the highway. Finally, \nsuppose that whenever the first car of the caravan arrives at a tollbooth, it waits at \nthe entrance until the other nine cars have arrived and lined up behind it. (Thus the \nentire caravan must be stored at the tollbooth before it can begin to be forwarded.) \nThe time required for the tollbooth to push the entire caravan onto the highway is  \n(10 cars)/(5 cars/minute) =2 minutes . This time is analogous to the transmission \ndelay in a router. The time required for a car to travel from the exit of one tollbooth \nto the next tollbooth is 100 km/(100 km/hour) =1 hour . This time is analogous to \npropagation delay. Therefore, the time from when the caravan is stored in front of a \ntollbooth until the caravan is stored in front of the next tollbooth is the sum of trans -\nmission delay and propagation delay\u2014in this example, 62 minutes.\nLet\u2019s explore this analogy a bit more. What would happen if the tollbooth ser -\nvice time for a caravan were greater than the time for a car to travel between toll -\nbooths? For example, suppose now that the cars travel at the rate of 1,000 km/hour \nand the tollbooth services cars at the rate of one car per minute. Then the traveling \ndelay between two tollbooths is 6 minutes and the time to serve a caravan is 10 min -\nutes. In this case, the first few cars in the caravan will arrive at the second tollbooth \nbefore the last cars in the caravan leave the first tollbooth. This situation also arises \nin packet-switched networks\u2014the first bits in a packet can arrive at a router while \nmany of the remaining bits in the packet are still waiting to be transmitted by the \npreceding router.\nIf a picture speaks a thousand words, then an animation must speak a million \nwords. The Web", "doc_id": "6f846041-1670-4913-b300-358a77d8fb8b", "embedding": null, "doc_hash": "49746c3d0623143cfc6150de7e96b7522754dd982fa560e72b5a40d220e4d821", "extra_info": null, "node_info": {"start": 169333, "end": 173048}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "d4c3880d-3f3e-420a-83bf-cd904882846e", "3": "f56508a0-c32e-4f19-b1fa-80a3ceb450d7"}}, "__type__": "1"}, "f56508a0-c32e-4f19-b1fa-80a3ceb450d7": {"__data__": {"text": "between toll -\nbooths? For example, suppose now that the cars travel at the rate of 1,000 km/hour \nand the tollbooth services cars at the rate of one car per minute. Then the traveling \ndelay between two tollbooths is 6 minutes and the time to serve a caravan is 10 min -\nutes. In this case, the first few cars in the caravan will arrive at the second tollbooth \nbefore the last cars in the caravan leave the first tollbooth. This situation also arises \nin packet-switched networks\u2014the first bits in a packet can arrive at a router while \nmany of the remaining bits in the packet are still waiting to be transmitted by the \npreceding router.\nIf a picture speaks a thousand words, then an animation must speak a million \nwords. The Web site for this text book  provides an interactive Java applet that nicely \nillustrates and contrasts transmission delay and propagation delay. The reader is \nhighly encouraged to visit that applet. [Smith 2009] also provides a very readable \ndiscussion of propagation, queueing, and transmission delays.\nIf we let dproc, dqueue, dtrans, and dprop denote the processing, queuing, transmis -\nsion, and propagation delays, then the total nodal delay is given by\n dnodal=dproc+dqueue+dtrans+dprop\nThe contribution of these delay components can vary significantly. For example, \ndprop can be negligible (for example, a couple of microseconds) for a link connecting Figure 1.17  \u2666 Caravan analogyTen-car\ncaravanToll\nboothToll\nbooth100 km 100 km\n1.4  \u2022  DELAY, LOSS, AND THROUGHPUT IN PACKET-SWITCHED NETWORKS      67\ntwo routers on the same university campus; however, dprop is hundreds of millisec -\nonds for two routers interconnected by a geostationary satellite link, and can be the \ndominant term in dnodal. Similarly, dtrans can range from negligible to significant. Its \ncontribution is typically negligible for transmission rates of 10 Mbps and higher (for \nexample, for LANs); however, it can be hundreds of milliseconds for large Internet \npackets sent over low-speed dial-up modem links. The processing delay, dproc, is \noften negligible; however, it strongly influences a router\u2019s maximum throughput, \nwhich is the maximum rate at which a router can forward packets.\n1.4.2 Queuing Delay and Packet Loss\nThe most complicated and interesting component of nodal delay is the queuing \ndelay,  dqueue. In fact, queuing delay is so important and interesting in computer net -\nworking that thousands of papers and numerous books have been written about it \n[Bertsekas 1991; Daigle 1991; Kleinrock 1975, Kleinrock 1976; Ross 1995]. We \ngive only a high-level, intuitive discussion of queuing delay here; the more curious \nreader may want to browse through some of the books (or even eventually write a \nPhD thesis on the subject!). Unlike the other three delays (namely, dproc,  dtrans, and \n dprop), the queuing delay can vary from packet to packet. For example, if 10 packets \narrive at an empty queue at the same time, the first packet transmitted will suffer no \nqueuing delay, while the last packet transmitted will suffer a relatively large queuing \ndelay (while it waits for the other nine packets to be transmitted). Therefore, when \ncharacterizing queuing delay, one typically uses statistical measures, such as average \nqueuing delay, variance of queuing delay, and the probability that the queuing delay \nexceeds some specified value.\nWhen is the queuing delay large and when is it insignificant? The answer to this \nquestion depends on the rate at which traffic arrives at the queue, the transmission \nrate of the link, and the nature of the arriving traffic, that is, whether the traffic arrives \nperiodically or arrives in bursts. To gain some insight here, let a denote the average \nrate at which packets arrive at", "doc_id": "f56508a0-c32e-4f19-b1fa-80a3ceb450d7", "embedding": null, "doc_hash": "cee888219b43cfd38fd3d1f7138de5117119c09e78f3236bf26f2288362784f9", "extra_info": null, "node_info": {"start": 173113, "end": 176874}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "6f846041-1670-4913-b300-358a77d8fb8b", "3": "e78f13a9-05b3-44d4-bf44-ca15c435a03d"}}, "__type__": "1"}, "e78f13a9-05b3-44d4-bf44-ca15c435a03d": {"__data__": {"text": "the first packet transmitted will suffer no \nqueuing delay, while the last packet transmitted will suffer a relatively large queuing \ndelay (while it waits for the other nine packets to be transmitted). Therefore, when \ncharacterizing queuing delay, one typically uses statistical measures, such as average \nqueuing delay, variance of queuing delay, and the probability that the queuing delay \nexceeds some specified value.\nWhen is the queuing delay large and when is it insignificant? The answer to this \nquestion depends on the rate at which traffic arrives at the queue, the transmission \nrate of the link, and the nature of the arriving traffic, that is, whether the traffic arrives \nperiodically or arrives in bursts. To gain some insight here, let a denote the average \nrate at which packets arrive at the queue ( a is in units of packets/sec). Recall that R \nis the transmission rate; that is, it is the rate (in bits/sec) at which bits are pushed out \nof the queue. Also suppose, for simplicity, that all packets consist of L bits. Then the \naverage rate at which bits arrive at the queue is La bits/sec. Finally, assume that the \nqueue is very big, so that it can hold essentially an infinite number of bits. The ratio \nLa/R,  called the traffic intensity , often plays an important role in estimating the \nextent of the queuing delay. If La/R  > 1, then the average rate at which bits arrive at \nthe queue exceeds the rate at which the bits can be transmitted from the queue. In this \nunfortunate situation, the queue will tend to increase without bound and the queuing \ndelay will approach infinity! Therefore, one of the golden rules in traffic engineering \nis: Design your system so that the traffic intensity is no greater than 1.\nNow consider the case La/R  \u2264 1. Here, the nature of the arriving traffic impacts \nthe queuing delay. For example, if packets arrive periodically\u2014that is, one packet \narrives every L/R seconds\u2014then every packet will arrive at an empty queue and \n68     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\nthere will be no queuing delay. On the other hand, if packets arrive in bursts but \nperiodically, there can be a significant average queuing delay. For example, sup -\npose N packets arrive simultaneously every (L/R)N  seconds. Then the first packet \ntransmitted has no queuing delay; the second packet transmitted has a queuing delay \nof L/R seconds; and more generally, the nth packet transmitted has a queuing delay \nof (n-1)L/R seconds. We leave it as an exercise for you to calculate the average \nqueuing delay in this example.\nThe two examples of periodic arrivals described above are a bit academic. \n Typically, the arrival process to a queue is random;  that is, the arrivals do not fol -\nlow any pattern and the packets are spaced apart by random amounts of time. In this \nmore realistic case, the quantity La/R  is not usually sufficient to fully characterize the \nqueuing delay statistics. Nonetheless, it is useful in gaining an intuitive understand -\ning of the extent of the queuing delay. In particular, if the traffic intensity is close to \nzero, then packet arrivals are few and far between and it is unlikely that an arriving \npacket will find another packet in the queue. Hence, the average queuing delay will \nbe close to zero. On the other hand, when the traffic intensity is close to 1, there will \nbe intervals of time when the arrival rate exceeds the transmission capacity (due to \nvariations in packet arrival rate), and a queue will form during these periods of time; \nwhen the arrival rate is less than the transmission capacity, the length of the queue \nwill shrink. Nonetheless, as the traffic intensity approaches 1, the average queue \nlength gets larger and larger. The qualitative dependence of average queuing delay \non the traffic intensity is shown in Figure 1.18.\nOne important aspect of Figure 1.18 is the fact that as the traffic intensity", "doc_id": "e78f13a9-05b3-44d4-bf44-ca15c435a03d", "embedding": null, "doc_hash": "61055f115a1383893ae4a1080ff540a4ad99343519e38fc1742bb8465269b2f6", "extra_info": null, "node_info": {"start": 176800, "end": 180728}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "f56508a0-c32e-4f19-b1fa-80a3ceb450d7", "3": "767d2f30-b24b-4503-86fd-a5f3ac532c3b"}}, "__type__": "1"}, "767d2f30-b24b-4503-86fd-a5f3ac532c3b": {"__data__": {"text": "then packet arrivals are few and far between and it is unlikely that an arriving \npacket will find another packet in the queue. Hence, the average queuing delay will \nbe close to zero. On the other hand, when the traffic intensity is close to 1, there will \nbe intervals of time when the arrival rate exceeds the transmission capacity (due to \nvariations in packet arrival rate), and a queue will form during these periods of time; \nwhen the arrival rate is less than the transmission capacity, the length of the queue \nwill shrink. Nonetheless, as the traffic intensity approaches 1, the average queue \nlength gets larger and larger. The qualitative dependence of average queuing delay \non the traffic intensity is shown in Figure 1.18.\nOne important aspect of Figure 1.18 is the fact that as the traffic intensity \napproaches 1, the average queuing delay increases rapidly. A small percentage \nincrease in the intensity will result in a much larger percentage-wise increase in \ndelay. Perhaps you have experienced this phenomenon on the highway. If you regu-\nlarly drive on a road that is typically congested, the fact that the road is typically \nFigure 1.18  \u2666 Dependence of average queuing delay on traffic intensity\nAverage queuing delay\nLa/R1\n1.4  \u2022  DELAY, LOSS, AND THROUGHPUT IN PACKET-SWITCHED NETWORKS      69\ncongested means that its traffic intensity is close to 1. If some event causes an even \nslightly larger-than-usual amount of traffic, the delays you experience can be huge.\nTo really get a good feel for what queuing delays are about, you are encouraged \nonce again to visit the textbook Web site, which provides an interactive Java applet \nfor a queue. If you set the packet arrival rate high enough so that the traffic intensity \nexceeds 1, you will see the queue slowly build up over time.\nPacket Loss\nIn our discussions above, we have assumed that the queue is capable of holding an \ninfinite number of packets. In reality a queue preceding a link has finite capacity, \nalthough the queuing capacity greatly depends on the router design and cost. Because \nthe queue capacity is finite, packet delays do not really approach infinity as the traffic \nintensity approaches 1. Instead, a packet can arrive to find a full queue. With no place \nto store such a packet, a router will drop  that packet; that is, the packet will be lost. \nThis overflow at a queue can again be seen in the Java applet for a queue when the \ntraffic intensity is greater than 1.\nFrom an end-system viewpoint, a packet loss will look like a packet having \nbeen transmitted into the network core but never emerging from the network at the \ndestination. The fraction of lost packets increases as the traffic intensity increases. \nTherefore, performance at a node is often measured not only in terms of delay, but \nalso in terms of the probability of packet loss. As we\u2019ll discuss in the subsequent \nchapters, a lost packet may be retransmitted on an end-to-end basis in order to ensure \nthat all data are eventually transferred from source to destination.\n1.4.3 End-to-End Delay\nOur discussion up to this point has focused on the nodal delay, that is, the delay at a \nsingle router. Let\u2019s now consider the total delay from source to destination. To get a \nhandle on this concept, suppose there are N-1 routers between the source host and \nthe destination host. Let\u2019s also suppose for the moment that the network is uncon -\ngested (so that queuing delays are negligible), the processing delay at each router \nand at the source host is dproc, the transmission rate out of each router and out of the \nsource host is R bits/sec, and the propagation on each link is dprop. The nodal delays \naccumulate and give an end-to-end delay,\n dend-end=N (dproc+dtrans+dprop) ( 1.2)\nwhere, once again, dtrans=L/R, where L is the packet size. Note that", "doc_id": "767d2f30-b24b-4503-86fd-a5f3ac532c3b", "embedding": null, "doc_hash": "dd46a0fbb4aa6d3b5866e92812abcb6f3bde33a648e1aa690d962280d3c961c0", "extra_info": null, "node_info": {"start": 180730, "end": 184558}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "e78f13a9-05b3-44d4-bf44-ca15c435a03d", "3": "9d51f697-8ec6-4e8d-8cda-ee852483ad15"}}, "__type__": "1"}, "9d51f697-8ec6-4e8d-8cda-ee852483ad15": {"__data__": {"text": "at a \nsingle router. Let\u2019s now consider the total delay from source to destination. To get a \nhandle on this concept, suppose there are N-1 routers between the source host and \nthe destination host. Let\u2019s also suppose for the moment that the network is uncon -\ngested (so that queuing delays are negligible), the processing delay at each router \nand at the source host is dproc, the transmission rate out of each router and out of the \nsource host is R bits/sec, and the propagation on each link is dprop. The nodal delays \naccumulate and give an end-to-end delay,\n dend-end=N (dproc+dtrans+dprop) ( 1.2)\nwhere, once again, dtrans=L/R, where L is the packet size. Note that Equation 1.2 \nis a generalization of Equation 1.1, which did not take into account processing and \npropagation delays. We leave it to you to generalize Equation 1.2 to the case of \n heterogeneous delays at the nodes and to the presence of an average queuing delay \nat each node.\n70     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\nTraceroute\nTo get a hands-on feel for end-to-end delay in a computer network, we can make use \nof the Traceroute program. Traceroute is a simple program that can run in any Inter -\nnet host. When the user specifies a destination hostname, the program in the source \nhost sends multiple, special packets toward that destination. As these packets work \ntheir way toward the destination, they pass through a series of routers. When a router \nreceives one of these special packets, it sends back to the source a short message that \ncontains the name and address of the router.\nMore specifically, suppose there are N-1 routers between the source and the \ndestination. Then the source will send N special packets into the network, with each \npacket addressed to the ultimate destination. These N special packets are marked 1 \nthrough N, with the first packet marked 1 and the last packet marked N. When the \nnth router receives the nth packet marked n, the router does not forward the packet \ntoward its destination, but instead sends a message back to the source. When the \ndestination host receives the Nth packet, it too returns a message back to the source. \nThe source records the time that elapses between when it sends a packet and when it \nreceives the corresponding return message; it also records the name and address of \nthe router (or the destination host) that returns the message. In this manner, the source \ncan reconstruct the route taken by packets flowing from source to destination, and the \nsource can determine the round-trip delays to all the intervening routers. Traceroute \nactually repeats the experiment just described three times, so the source actually \nsends 3\t\u2022\tN packets to the destination. RFC 1393 describes Traceroute in detail.\nHere is an example of the output of the Traceroute program, where the route was \nbeing traced from the source host gaia.cs.umass.edu (at the University of  Massachusetts) \nto the host cis.poly.edu (at Polytechnic University in Brooklyn). The output has six \ncolumns: the first column is the n value described above, that is, the number of the \nrouter along the route; the second column is the name of the router; the third column is \nthe address of the router (of the form xxx.xxx.xxx.xxx); the last three columns are the \nround-trip delays for three experiments. If the source receives fewer than three messages \nfrom any given router (due to packet loss in the network), Traceroute places an asterisk \njust after the router number and reports fewer than three round-trip times for that router.VideoNote\nUsing Traceroute to \ndiscover network  \npaths and measure \nnetwork delay\n1  cs-gw (128.119.240.254) 1.009 ms 0.899 ms 0.993 ms\n2  128.119.3.154 (128.119.3.154)", "doc_id": "9d51f697-8ec6-4e8d-8cda-ee852483ad15", "embedding": null, "doc_hash": "6501b20041ea63312dd968869bb6f2ac817a23068f9403235174ef717471eb6e", "extra_info": null, "node_info": {"start": 184677, "end": 188410}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "767d2f30-b24b-4503-86fd-a5f3ac532c3b", "3": "87ef98f8-3a25-42ba-8cc2-7268a2c8cafa"}}, "__type__": "1"}, "87ef98f8-3a25-42ba-8cc2-7268a2c8cafa": {"__data__": {"text": "column is the n value described above, that is, the number of the \nrouter along the route; the second column is the name of the router; the third column is \nthe address of the router (of the form xxx.xxx.xxx.xxx); the last three columns are the \nround-trip delays for three experiments. If the source receives fewer than three messages \nfrom any given router (due to packet loss in the network), Traceroute places an asterisk \njust after the router number and reports fewer than three round-trip times for that router.VideoNote\nUsing Traceroute to \ndiscover network  \npaths and measure \nnetwork delay\n1  cs-gw (128.119.240.254) 1.009 ms 0.899 ms 0.993 ms\n2  128.119.3.154 (128.119.3.154) 0.931 ms 0.441 ms 0.651 ms\n3  -border4-rt-gi-1-3.gw.umass.edu (128.119.2.194) 1.032 ms 0.484 ms 0.451 ms\n4  -acr1-ge-2-1-0.Boston.cw.net (208.172.51.129) 10.006 ms 8.150 ms 8.460 ms\n5  -agr4-loopback.NewYork.cw.net (206.24.194.104) 12.272 ms 14.344 ms 13.267 ms\n6  -acr2-loopback.NewYork.cw.net (206.24.194.62) 13.225 ms 12.292 ms 12.148 ms\n7  -pos10-2.core2.NewYork1.Level3.net (209.244.160.133) 12.218 ms 11.823 ms 11.793 ms\n8   -gige9-1-52.hsipaccess1.NewYork1.Level3.net (64.159.17.39) 13.081 ms 11.556 ms 13.297 ms\n9  -p0-0.polyu.bbnplanet.net (4.25.109.122) 12.716 ms 13.052 ms 12.786 ms\n10 cis.poly.edu (128.238.32.126) 14.080 ms 13.035 ms 12.802 ms\n1.4  \u2022  DELAY, LOSS, AND THROUGHPUT IN PACKET-SWITCHED NETWORKS      71\nIn the trace above there are nine routers between the source and the destination. \nMost of these routers have a name, and all of them have addresses. For exam -\nple, the name of Router 3 is border4-rt-gi-1-3.gw.umass.edu  and its \naddress is 128.119.2.194 . Looking at the data provided for this same router, \nwe see that in the first of the three trials the round-trip delay between the source \nand the router was 1.03 msec. The round-trip delays for the subsequent two trials \nwere 0.48 and 0.45 msec. These round-trip delays include all of the delays just \ndiscussed, including transmission delays, propagation delays, router processing \ndelays, and queuing delays. Because the queuing delay is varying with time, the \nround-trip delay of packet n sent to a router n can sometimes be longer than the \nround-trip delay of packet n+1 sent to router n+1. Indeed, we observe this phe -\nnomenon in the above example: the delays to Router 6 are larger than the delays \nto Router 7!\nWant to try out Traceroute for yourself? We highly  recommended that you visit \nhttp://www.traceroute.org, which provides a Web interface to an extensive list of \nsources for route tracing. You choose a source and supply the hostname for any \ndestination. The Traceroute program then does all the work. There are a number of \nfree software programs that provide a graphical interface to Traceroute; one of our \nfavorites is PingPlotter [PingPlotter 2016].\nEnd System, Application, and Other Delays\nIn addition to processing, transmission, and propagation delays, there can be addi -\ntional significant delays in the end systems. For example,", "doc_id": "87ef98f8-3a25-42ba-8cc2-7268a2c8cafa", "embedding": null, "doc_hash": "475d800e30f3a1634e0c5f83ca544087131dc497d54f3c3d9f649202cf0b8c8e", "extra_info": null, "node_info": {"start": 188394, "end": 191431}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "9d51f697-8ec6-4e8d-8cda-ee852483ad15", "3": "e5f4e55f-921a-4f3d-ad5d-ea891eabbce9"}}, "__type__": "1"}, "e5f4e55f-921a-4f3d-ad5d-ea891eabbce9": {"__data__": {"text": "this phe -\nnomenon in the above example: the delays to Router 6 are larger than the delays \nto Router 7!\nWant to try out Traceroute for yourself? We highly  recommended that you visit \nhttp://www.traceroute.org, which provides a Web interface to an extensive list of \nsources for route tracing. You choose a source and supply the hostname for any \ndestination. The Traceroute program then does all the work. There are a number of \nfree software programs that provide a graphical interface to Traceroute; one of our \nfavorites is PingPlotter [PingPlotter 2016].\nEnd System, Application, and Other Delays\nIn addition to processing, transmission, and propagation delays, there can be addi -\ntional significant delays in the end systems. For example, an end system wanting \nto transmit a packet into a shared medium (e.g., as in a WiFi or cable modem sce -\nnario) may purposefully  delay its transmission as part of its protocol for sharing the \nmedium with other end systems; we\u2019ll consider such protocols in detail in Chapter 6 .  \nAnother important delay is media packetization delay, which is present in Voice-\nover-IP (VoIP) applications. In VoIP, the sending side must first fill a packet with \nencoded digitized speech before passing the packet to the Internet. This time to fill a \npacket\u2014called the packetization delay\u2014can be significant and can impact the user-\nperceived quality of a VoIP call. This issue will be further explored in a homework \nproblem at the end of this chapter.\n1.4.4 Throughput in Computer Networks\nIn addition to delay and packet loss, another critical performance measure in com -\nputer networks is end-to-end throughput. To define throughput, consider transferring \na large file from Host A to Host B across a computer network. This transfer might \nbe, for example, a large video clip from one peer to another in a P2P file sharing \nsystem. The instantaneous throughput  at any instant of time is the rate (in bits/\nsec) at which Host B is receiving the file. (Many applications, including many P2P \n72     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\nfile sharing  systems, display the instantaneous throughput during downloads in the \nuser interface\u2014perhaps you have observed this before!) If the file consists of F bits \nand the transfer takes T seconds for Host B to receive all F bits, then the aver-\nage throughput  of the file transfer is F/T bits/sec. For some applications, such as \nInternet telephony, it is desirable to have a low delay and an instantaneous through -\nput consistently above some threshold (for example, over 24 kbps for some Internet \ntelephony applications and over 256 kbps for some real-time video applications). For \nother applications, including those involving file transfers, delay is not critical, but it \nis desirable to have the highest possible throughput.\nTo gain further insight into the important concept of throughput, let\u2019s consider \na few examples. Figure 1.19(a) shows two end systems, a server and a client, con -\nnected by two communication links and a router. Consider the throughput for a file \ntransfer from the server to the client. Let Rs denote the rate of the link between the  \nserver and the router; and Rc denote the rate of the link between the router and  \nthe client. Suppose that the only bits being sent in the entire network are those \nfrom the server to the client. We now ask, in this ideal scenario, what is the server-  \nto-client throughput? To answer this question, we may think of bits as fluid and com -\nmunication links as pipes . Clearly, the server cannot pump bits through its link at a \nrate faster than Rs bps; and the router cannot forward bits at a rate faster than Rc bps. \nIf Rs6Rc, then the bits pumped by the server will \u201cflow\u201d right through the router \nand arrive at the client at a rate of Rs bps, giving a throughput of Rs bps. If, on the", "doc_id": "e5f4e55f-921a-4f3d-ad5d-ea891eabbce9", "embedding": null, "doc_hash": "a4d5cb4e92a8eb802a0142c208f336bfaf7ae9e4e0d1b77172be654c11d40766", "extra_info": null, "node_info": {"start": 191378, "end": 195241}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "87ef98f8-3a25-42ba-8cc2-7268a2c8cafa", "3": "dd607c41-f9f2-41a9-8d65-5944e639858a"}}, "__type__": "1"}, "dd607c41-f9f2-41a9-8d65-5944e639858a": {"__data__": {"text": "denote the rate of the link between the  \nserver and the router; and Rc denote the rate of the link between the router and  \nthe client. Suppose that the only bits being sent in the entire network are those \nfrom the server to the client. We now ask, in this ideal scenario, what is the server-  \nto-client throughput? To answer this question, we may think of bits as fluid and com -\nmunication links as pipes . Clearly, the server cannot pump bits through its link at a \nrate faster than Rs bps; and the router cannot forward bits at a rate faster than Rc bps. \nIf Rs6Rc, then the bits pumped by the server will \u201cflow\u201d right through the router \nand arrive at the client at a rate of Rs bps, giving a throughput of Rs bps. If, on the \nother hand, Rc6Rs, then the router will not be able to forward bits as quickly as it \nreceives them. In this case, bits will only leave the router at rate Rc, giving an end-\nto-end throughput of Rc. (Note also that if bits continue to arrive at the router at rate \nRs, and continue to leave the router at Rc, the backlog of bits at the router waiting \nFigure 1.19  \u2666 Throughput for a file transfer from server to clientServerRs\nR1 R2 RNRc\nClient\nServera.\nb.Client\n1.4  \u2022  DELAY, LOSS, AND THROUGHPUT IN PACKET-SWITCHED NETWORKS      73\nfor transmission to the client will grow and grow\u2014a most undesirable situation!) \nThus, for this simple two-link network, the throughput is min {Rc, Rs}, that is, it is the \ntransmission rate of the bottleneck link . Having determined the throughput, we can \nnow approximate the time it takes to transfer a large file of F bits from server to cli -\nent as F/min{Rs, Rc}. For a specific example, suppose you are downloading an MP3 \nfile of F = 32 million bits, the server has a transmission rate of Rs=2 Mbps, and \nyou have an access link of Rc=1 Mbps. The time needed to transfer the file is then \n32 seconds. Of course, these expressions for throughput and transfer time are only \napproximations, as they do not account for store-and-forward and processing delays \nas well as protocol issues.\nFigure 1. 19(b) now shows a network with N links between the server and the \nclient, with the transmission rates of the N links being R1, R2, c, RN. Applying \nthe same analysis as for the two-link network, we find that the throughput for a file \ntransfer from server to client is min {R1, R2, c, RN}, which is once again the trans -\nmission rate of the bottleneck link along the path between server and client.\nNow consider another example motivated by today\u2019s Internet. Figure 1.20(a) \nshows two end systems, a server and a client, connected to a computer network. \nConsider the throughput for a file transfer from the server to the client. The server is \nconnected to the network with an access link of rate Rs and the client is connected to \nthe network with an access link of rate Rc. Now suppose that all the links in the core \nof the communication network have very high transmission rates, much higher than \nRs and Rc. Indeed, today, the core of the Internet is over-provisioned with high speed \nlinks that experience little congestion. Also suppose that the only bits being sent in \nthe entire network are those from the server to the client. Because the core of the \ncomputer network is like a wide pipe in this example, the rate at which bits can flow \nfrom source to destination is again the minimum of Rs and Rc, that is, throughput = \nmin{Rs, Rc}. Therefore, the constraining factor for throughput in today\u2019s Internet is \ntypically the access network.\nFor a final example, consider Figure 1.20(b) in which there are 10 servers and \n10 clients connected to the core of the computer network. In this example, there are \n10 simultaneous downloads taking place, involving 10 client-server pairs. Suppose \nthat these 10 downloads are the only traffic in the network at the current time.", "doc_id": "dd607c41-f9f2-41a9-8d65-5944e639858a", "embedding": null, "doc_hash": "f0979f63265fc1cc609b8163c0314c26784cf9f928967901f918286b353175ae", "extra_info": null, "node_info": {"start": 195283, "end": 199142}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "e5f4e55f-921a-4f3d-ad5d-ea891eabbce9", "3": "883ce6b3-73f9-49ff-a697-215c6bf883cb"}}, "__type__": "1"}, "883ce6b3-73f9-49ff-a697-215c6bf883cb": {"__data__": {"text": "with high speed \nlinks that experience little congestion. Also suppose that the only bits being sent in \nthe entire network are those from the server to the client. Because the core of the \ncomputer network is like a wide pipe in this example, the rate at which bits can flow \nfrom source to destination is again the minimum of Rs and Rc, that is, throughput = \nmin{Rs, Rc}. Therefore, the constraining factor for throughput in today\u2019s Internet is \ntypically the access network.\nFor a final example, consider Figure 1.20(b) in which there are 10 servers and \n10 clients connected to the core of the computer network. In this example, there are \n10 simultaneous downloads taking place, involving 10 client-server pairs. Suppose \nthat these 10 downloads are the only traffic in the network at the current time. As \nshown in the figure, there is a link in the core that is traversed by all 10 downloads. \nDenote R for the transmission rate of this link R. Let\u2019s suppose that all server access \nlinks have the same rate Rs, all client access links have the same rate Rc, and the \ntransmission rates of all the links in the core\u2014except the one common link of rate \nR\u2014are much larger than Rs, Rc, and R. Now we ask, what are the throughputs of \nthe downloads? Clearly, if the rate of the common link, R, is large\u2014say a hun -\ndred times larger than both Rs and Rc\u2014then the throughput for each download will \nonce again be min {Rs, Rc}. But what if the rate of the common link is of the same \norder as Rs and Rc? What will the throughput be in this case? Let\u2019s take a look at \na specific example. Suppose Rs=2 Mbps, Rc=1 Mbps, R=5 Mbps, and the \n74     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\ncommon link divides its transmission rate equally among the 10 downloads. Then \nthe bottleneck for each download is no longer in the access network, but is now \ninstead the shared link in the core, which only provides each download with 500 \nkbps of throughput. Thus the end-to-end throughput for each download is now \nreduced to 500 kbps.\nThe examples in Figure 1.19 and Figure 1.20(a) show that throughput depends \non the transmission rates of the links over which the data flows. We saw that when \nthere is no other intervening traffic, the throughput can simply be approximated as \nthe minimum transmission rate along the path between source and destination. The \nexample in Figure 1.20(b) shows that more generally the throughput depends not \nonly on the transmission rates of the links along the path, but also on the interven -\ning traffic. In particular, a link with a high transmission rate may nonetheless be the \nbottleneck link for a file transfer if many other data flows are also passing through \nthat link. We will examine throughput in computer networks more closely in the \nhomework problems and in the subsequent chapters.Figure 1.20  \u2666  End-to-end throughput: (a) Client downloads a file from \n server; (b) 10 clients  downloading with 10 serversServer\nRs\nRc\na. b.Client 10 Clients10 Servers\nBottleneck\nlink of\ncapacity R\n1.5  \u2022  PROTOCOL LAYERS AND THEIR SERVICE MODELS      75\n1.5 Protocol Layers and Their Service Models\nFrom our discussion thus far, it is apparent that the Internet is an extremely  com -\nplicated system. We have seen that there are many pieces to the Internet: numerous \napplications and protocols, various types of end systems, packet switches, and vari -\nous types of link-level media. Given this enormous complexity, is there any hope of \norganizing a network architecture, or at least our discussion of network architecture? \nFortunately, the answer to both questions is yes.\n1.5.1 Layered Architecture\nBefore attempting to organize our thoughts on Internet architecture, let\u2019s look \nfor a human analogy. Actually, we deal with complex systems all the time in our \neveryday life. Imagine", "doc_id": "883ce6b3-73f9-49ff-a697-215c6bf883cb", "embedding": null, "doc_hash": "e189f32ebcbfee8c403251cbe4ab5e0b0c6c03289d882d8edd7e01710ffa18a1", "extra_info": null, "node_info": {"start": 199060, "end": 202890}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "dd607c41-f9f2-41a9-8d65-5944e639858a", "3": "784ae904-6fd9-4e1b-9d8e-41919cc443ec"}}, "__type__": "1"}, "784ae904-6fd9-4e1b-9d8e-41919cc443ec": {"__data__": {"text": "     75\n1.5 Protocol Layers and Their Service Models\nFrom our discussion thus far, it is apparent that the Internet is an extremely  com -\nplicated system. We have seen that there are many pieces to the Internet: numerous \napplications and protocols, various types of end systems, packet switches, and vari -\nous types of link-level media. Given this enormous complexity, is there any hope of \norganizing a network architecture, or at least our discussion of network architecture? \nFortunately, the answer to both questions is yes.\n1.5.1 Layered Architecture\nBefore attempting to organize our thoughts on Internet architecture, let\u2019s look \nfor a human analogy. Actually, we deal with complex systems all the time in our \neveryday life. Imagine if someone asked you to describe, for example, the air -\nline system. How would you find the structure to describe this complex system \nthat has ticketing agents, baggage checkers, gate personnel, pilots, airplanes, \nair traffic control, and a worldwide system for routing airplanes? One way to \ndescribe this system might be to describe the series of actions you take (or oth -\ners take for you) when you fly on an airline. You purchase your ticket, check \nyour bags, go to the gate, and eventually get loaded onto the plane. The plane \ntakes off and is routed to its destination. After your plane lands, you deplane at \nthe gate and claim your bags. If the trip was bad, you complain about the flight \nto the ticket agent (getting nothing for your effort). This scenario is shown in \nFigure 1.21.\nFigure 1.21  \u2666 Taking an airplane trip: actionsTicket (purchase)\nBaggage (check)\nGates (load)\nRunway takeoff\nAirplane routingTicket (complain)\nBaggage (claim)\nGates (unload)\nRunway landing\nAirplane routing\nAirplane routing\n76     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\nAlready, we can see some analogies here with computer networking: You are \nbeing shipped from source to destination by the airline; a packet is shipped from \nsource host to destination host in the Internet. But this is not quite the analogy we \nare after. We are looking for some structure  in Figure 1.21. Looking at Figure 1.21, \nwe note that there is a ticketing function at each end; there is also a baggage func -\ntion for already-ticketed passengers, and a gate function for already-ticketed and \nalready-baggage-checked passengers. For passengers who have made it through the \ngate (that is, passengers who are already ticketed, baggage-checked, and through the \ngate), there is a takeoff and landing function, and while in flight, there is an airplane-\nrouting function. This suggests that we can look at the functionality in Figure 1.21 in \na horizontal  manner, as shown in Figure 1.22.\nFigure 1. 22 has divided the airline functionality into layers, providing a frame -\nwork in which we can discuss airline travel. Note that each layer, combined with the \nlayers below it, implements some functionality, some service.  At the ticketing layer \nand below, airline-counter-to-airline-counter transfer of a person is accomplished. At \nthe baggage layer and below, baggage-check-to-baggage-claim transfer of a person \nand bags is accomplished. Note that the baggage layer provides this service only to an \nalready-ticketed person. At the gate layer, departure-gate-to-arrival-gate transfer of \na person and bags is accomplished. At the takeoff/landing layer, runway-to-runway  \ntransfer of people and their bags is accomplished. Each layer provides its service \nby (1) performing certain actions within that layer (for example, at the gate layer, \nloading and unloading people from an airplane) and by (2) using the services of the \nlayer directly below it (for example, in the gate layer, using the runway-to-runway \npassenger transfer", "doc_id": "784ae904-6fd9-4e1b-9d8e-41919cc443ec", "embedding": null, "doc_hash": "628030eaa70f44f0cf2372a444f60aafeb1749cf8bdc1c1895bc889624606788", "extra_info": null, "node_info": {"start": 202938, "end": 206705}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "883ce6b3-73f9-49ff-a697-215c6bf883cb", "3": "08781c35-368d-4fce-af89-8ceb7eb5d90c"}}, "__type__": "1"}, "08781c35-368d-4fce-af89-8ceb7eb5d90c": {"__data__": {"text": "transfer of a person is accomplished. At \nthe baggage layer and below, baggage-check-to-baggage-claim transfer of a person \nand bags is accomplished. Note that the baggage layer provides this service only to an \nalready-ticketed person. At the gate layer, departure-gate-to-arrival-gate transfer of \na person and bags is accomplished. At the takeoff/landing layer, runway-to-runway  \ntransfer of people and their bags is accomplished. Each layer provides its service \nby (1) performing certain actions within that layer (for example, at the gate layer, \nloading and unloading people from an airplane) and by (2) using the services of the \nlayer directly below it (for example, in the gate layer, using the runway-to-runway \npassenger transfer service of the takeoff/landing layer).\nA layered architecture allows us to discuss a well-defined, specific part of a \nlarge and complex system. This simplification itself is of considerable value by \nproviding modularity, making it much easier to change the implementation of the \nservice provided by the layer. As long as the layer provides the same service to the \nlayer above it, and uses the same services from the layer below it, the remainder of Figure 1.22  \u2666 Horizontal layering of airline functionalityTicket (purchase)\nBaggage (check)\nGates (load)\nRunway takeoff\nAirplane routing Airplane routing Airplane routingTicket (complain)\nBaggage (claim)\nGates (unload)\nRunway landing\nAirplane routingTicket\nBaggage\nGate\nTakeof f/Landing\nDeparture airport Intermediate air-traf\ufb01c\ncontrol centers\n1.5  \u2022  PROTOCOL LAYERS AND THEIR SERVICE MODELS      77\nthe system remains unchanged when a layer\u2019s implementation is changed. (Note \nthat changing the implementation of a service is very different from changing the \nservice itself!) For example, if the gate functions were changed (for instance, to have \npeople board and disembark by height), the remainder of the airline system would \nremain unchanged since the gate layer still provides the same function (loading and \nunloading people); it simply implements that function in a different manner after the \nchange. For large and complex systems that are constantly being updated, the ability \nto change the implementation of a service without affecting other components of the \nsystem is another important advantage of layering.\nProtocol Layering\nBut enough about airlines. Let\u2019s now turn our attention to network protocols. To \nprovide structure to the design of network protocols, network designers organize \nprotocols\u2014and the network hardware and software that implement the protocols\u2014\nin layers . Each protocol belongs to one of the layers, just as each function in the \nairline architecture in Figure 1.22 belonged to a layer. We are again interested in \nthe services  that a layer offers to the layer above\u2014the so-called service model  of \na layer. Just as in the case of our airline example, each layer provides its service \nby (1) performing certain actions within that layer and by (2) using the services \nof the layer directly below it. For example, the services provided by layer n may \ninclude reliable delivery of messages from one edge of the network to the other. \nThis might be implemented by using an unreliable edge-to-edge message delivery \nservice of layer n-1, and adding layer n functionality to detect and retransmit \nlost messages.\nA protocol layer can be implemented in software, in hardware, or in a combina -\ntion of the two. Application-layer protocols\u2014such as HTTP and SMTP\u2014are almost \nalways implemented in software in the end systems; so are transport-layer protocols. \nBecause the physical layer and data link layers are responsible for handling commu -\nnication over a specific link, they are typically implemented in a network interface \ncard (for example, Ethernet or WiFi interface cards) associated with a given link. The \nnetwork layer is often a mixed implementation of hardware and software. Also note \nthat just as the functions in the", "doc_id": "08781c35-368d-4fce-af89-8ceb7eb5d90c", "embedding": null, "doc_hash": "85fb44f6c48da9a67e8f59dd9ceac6cc5d1fb06f054ceb7e8bf78c05812e10ef", "extra_info": null, "node_info": {"start": 206700, "end": 210672}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "784ae904-6fd9-4e1b-9d8e-41919cc443ec", "3": "f57ad530-a18f-40e4-a40f-02d8ddb8adb5"}}, "__type__": "1"}, "f57ad530-a18f-40e4-a40f-02d8ddb8adb5": {"__data__": {"text": "\nThis might be implemented by using an unreliable edge-to-edge message delivery \nservice of layer n-1, and adding layer n functionality to detect and retransmit \nlost messages.\nA protocol layer can be implemented in software, in hardware, or in a combina -\ntion of the two. Application-layer protocols\u2014such as HTTP and SMTP\u2014are almost \nalways implemented in software in the end systems; so are transport-layer protocols. \nBecause the physical layer and data link layers are responsible for handling commu -\nnication over a specific link, they are typically implemented in a network interface \ncard (for example, Ethernet or WiFi interface cards) associated with a given link. The \nnetwork layer is often a mixed implementation of hardware and software. Also note \nthat just as the functions in the layered airline architecture were distributed among \nthe various airports and flight control centers that make up the system, so too is a \nlayer n protocol distributed  among the end systems, packet switches, and other com -\nponents that make up the network. That is, there\u2019s often a piece of a layer n protocol \nin each of these network components.\nProtocol layering has conceptual and structural advantages [RFC 3439]. As \nwe have seen, layering provides a structured way to discuss system components. \nModularity makes it easier to update system components. We mention, however, \nthat some researchers and networking engineers are vehemently opposed to layering \n[Wakeman 1992]. One potential drawback of layering is that one layer may duplicate \nlower-layer functionality. For example, many protocol stacks provide error recovery \n78     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\non both a per-link basis and an end-to-end basis. A second potential drawback is that \nfunctionality at one layer may need information (for example, a timestamp value) \nthat is present only in another layer; this violates the goal of separation of layers.\nWhen taken together, the protocols of the various layers are called the protocol \nstack . The Internet protocol stack consists of five layers: the physical, link, network, \ntransport, and application layers, as shown in Figure 1.23(a). If you examine the \nTable of Contents, you will see that we have roughly organized this book using the \nlayers of the Internet protocol stack. We take a top-down approach , first covering \nthe application layer and then proceeding downward.\nApplication Layer\nThe application layer is where network applications and their application-layer pro -\ntocols reside. The Internet\u2019s application layer includes many protocols, such as the \nHTTP protocol (which provides for Web document request and transfer), SMTP \n(which provides for the transfer of e-mail messages), and FTP (which provides for \nthe transfer of files between two end systems). We\u2019ll see that certain network func -\ntions, such as the translation of human-friendly names for Internet end systems like \nwww.ietf.org to a 32-bit network address, are also done with the help of a specific \napplication-layer protocol, namely, the domain name system (DNS). We\u2019ll see in \nChapter 2 that it is very easy to create and deploy our own new application-layer \nprotocols.\nAn application-layer protocol is distributed over multiple end systems, with the \napplication in one end system using the protocol to exchange packets of information \nwith the application in another end system. We\u2019ll refer to this packet of information \nat the application layer as a message .Figure 1.23  \u2666 The Internet protocol stack (a) and OSI reference model (b)TransportApplication\nNetwork\nLink\nPhysical\na.  Five-layer\n Internet\n protocol stackTransportSessionApplication\nPresentation\nNetwork\nLink\nPhysical\nb.  Seven-layer\n ISO OSI\n reference model\n1.5  \u2022  PROTOCOL LAYERS AND THEIR SERVICE MODELS      79\nTransport Layer\nThe Internet\u2019s transport layer transports application-layer messages between applica -\ntion endpoints. In the Internet there are two transport protocols,", "doc_id": "f57ad530-a18f-40e4-a40f-02d8ddb8adb5", "embedding": null, "doc_hash": "5aa2395064790cbd9e76d672ad6d06c263dd18d2c6d0ac778e8870d0de8935a8", "extra_info": null, "node_info": {"start": 210630, "end": 214616}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "08781c35-368d-4fce-af89-8ceb7eb5d90c", "3": "4948a8bd-9e2e-4f80-80d1-db57c3ea4466"}}, "__type__": "1"}, "4948a8bd-9e2e-4f80-80d1-db57c3ea4466": {"__data__": {"text": "protocol is distributed over multiple end systems, with the \napplication in one end system using the protocol to exchange packets of information \nwith the application in another end system. We\u2019ll refer to this packet of information \nat the application layer as a message .Figure 1.23  \u2666 The Internet protocol stack (a) and OSI reference model (b)TransportApplication\nNetwork\nLink\nPhysical\na.  Five-layer\n Internet\n protocol stackTransportSessionApplication\nPresentation\nNetwork\nLink\nPhysical\nb.  Seven-layer\n ISO OSI\n reference model\n1.5  \u2022  PROTOCOL LAYERS AND THEIR SERVICE MODELS      79\nTransport Layer\nThe Internet\u2019s transport layer transports application-layer messages between applica -\ntion endpoints. In the Internet there are two transport protocols, TCP and UDP, either of \nwhich can transport application-layer messages. TCP provides a  connection-oriented \nservice to its applications. This service includes guaranteed delivery of application-\nlayer messages to the destination and flow control (that is, sender/receiver speed \nmatching). TCP also breaks long messages into shorter  segments and provides a \ncongestion-control mechanism, so that a source throttles its transmission rate when \nthe network is congested. The UDP protocol provides a connectionless service to its \napplications. This is a no-frills service that provides no reliability, no flow control, \nand no congestion control. In this book, we\u2019ll refer to a transport-layer packet as a \nsegment .\nNetwork Layer\nThe Internet\u2019s network layer is responsible for moving network-layer packets known \nas datagrams  from one host to another. The Internet transport-layer protocol (TCP \nor UDP) in a source host passes a transport-layer segment and a destination address \nto the network layer, just as you would give the postal service a letter with a destina -\ntion address. The network layer then provides the service of delivering the segment \nto the transport layer in the destination host.\nThe Internet\u2019s network layer includes the celebrated IP protocol, which defines \nthe fields in the datagram as well as how the end systems and routers act on these \nfields. There is only one IP protocol, and all Internet components that have a network \nlayer must run the IP protocol. The Internet\u2019s network layer also contains routing \nprotocols that determine the routes that datagrams take between sources and destina -\ntions. The Internet has many routing protocols. As we saw in Section 1.3, the Internet \nis a network of networks, and within a network, the network administrator can run \nany routing protocol desired. Although the network layer contains both the IP pro -\ntocol and numerous routing protocols, it is often simply referred to as the IP layer, \nreflecting the fact that IP is the glue that binds the Internet together.\nLink Layer\nThe Internet\u2019s network layer routes a datagram through a series of routers between \nthe source and destination. To move a packet from one node (host or router) to the \nnext node in the route, the network layer relies on the services of the link layer. In \nparticular, at each node, the network layer passes the datagram down to the link \nlayer, which delivers the datagram to the next node along the route. At this next node, \nthe link layer passes the datagram up to the network layer.\nThe services provided by the link layer depend on the specific link-layer proto -\ncol that is employed over the link. For example, some link-layer protocols provide \n80     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\nreliable delivery, from transmitting node, over one link, to receiving node. Note that \nthis reliable delivery service is different from the reliable delivery service of TCP, \nwhich provides reliable delivery from one end system to another. Examples of link-\nlayer protocols include Ethernet, WiFi, and the cable access network\u2019s DOCSIS pro -\ntocol. As datagrams typically need to traverse several links to travel from source to \ndestination, a", "doc_id": "4948a8bd-9e2e-4f80-80d1-db57c3ea4466", "embedding": null, "doc_hash": "9d164b6ed2e36b05f9afd4259924d88a2e789dfb723f3de252c3f3d40830a7cd", "extra_info": null, "node_info": {"start": 214634, "end": 218608}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "f57ad530-a18f-40e4-a40f-02d8ddb8adb5", "3": "8cc96437-fa97-48f9-a074-c25edd207890"}}, "__type__": "1"}, "8cc96437-fa97-48f9-a074-c25edd207890": {"__data__": {"text": "this next node, \nthe link layer passes the datagram up to the network layer.\nThe services provided by the link layer depend on the specific link-layer proto -\ncol that is employed over the link. For example, some link-layer protocols provide \n80     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\nreliable delivery, from transmitting node, over one link, to receiving node. Note that \nthis reliable delivery service is different from the reliable delivery service of TCP, \nwhich provides reliable delivery from one end system to another. Examples of link-\nlayer protocols include Ethernet, WiFi, and the cable access network\u2019s DOCSIS pro -\ntocol. As datagrams typically need to traverse several links to travel from source to \ndestination, a datagram may be handled by different link-layer protocols at different \nlinks along its route. For example, a datagram may be handled by Ethernet on one \nlink and by PPP on the next link. The network layer will receive a different service \nfrom each of the different link-layer protocols. In this book, we\u2019ll refer to the link-\nlayer packets as frames .\nPhysical Layer\nWhile the job of the link layer is to move entire frames from one network element to \nan adjacent network element, the job of the physical layer is to move the individual \nbits within the frame from one node to the next. The protocols in this layer are again \nlink dependent and further depend on the actual transmission medium of the link (for \nexample, twisted-pair copper wire, single-mode fiber optics). For example, Ether -\nnet has many physical-layer protocols: one for twisted-pair copper wire, another for \ncoaxial cable, another for fiber, and so on. In each case, a bit is moved across the link \nin a different way.\nThe OSI Model\nHaving discussed the Internet protocol stack in detail, we should mention that it is not \nthe only protocol stack around. In particular, back in the late 1970s, the International \nOrganization for Standardization (ISO) proposed that computer networks be organ -\nized around seven layers, called the Open Systems Interconnection (OSI) model \n[ISO 2016]. The OSI model took shape when the protocols that were to become the \nInternet protocols were in their infancy, and were but one of many different protocol \nsuites under development; in fact, the inventors of the original OSI model probably \ndid not have the Internet in mind when creating it. Nevertheless, beginning in the \nlate 1970s, many training and university courses picked up on the ISO mandate and \norganized courses around the seven-layer model. Because of its early impact on net -\nworking education, the seven-layer model continues to linger on in some networking \ntextbooks and training courses.\nThe seven layers of the OSI reference model, shown in Figure 1.23(b), are: \napplication layer, presentation layer, session layer, transport layer, network layer, \ndata link layer, and physical layer. The functionality of five of these layers is roughly \nthe same as their similarly named Internet counterparts. Thus, let\u2019s consider the two \nadditional layers present in the OSI reference model\u2014the presentation layer and the \nsession layer. The role of the presentation layer is to provide services that allow com -\nmunicating applications to interpret the meaning of data exchanged. These services \n1.5  \u2022  PROTOCOL LAYERS AND THEIR SERVICE MODELS      81\ninclude data compression and data encryption (which are self-explanatory) as well as \ndata description (which frees the applications from having to worry about the inter -\nnal format in which data are represented/stored\u2014formats that may differ from one \ncomputer to another). The session layer provides for delimiting and synchronization \nof data exchange, including the means to build a checkpointing and recovery scheme.\nThe fact that the Internet lacks two layers found in the OSI reference model \nposes a couple of interesting questions: Are the services provided by these layers \nunimportant? What if an application needs  one of these services? The Internet\u2019s \nanswer to both of these questions is the same\u2014it\u2019s up", "doc_id": "8cc96437-fa97-48f9-a074-c25edd207890", "embedding": null, "doc_hash": "c23d5e28628a9ac83b70d680899691748790ea66aba12d03b3052cfd32f1506a", "extra_info": null, "node_info": {"start": 218639, "end": 222734}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "4948a8bd-9e2e-4f80-80d1-db57c3ea4466", "3": "57b1cdc2-be4c-499b-9aa9-f9ebf79af525"}}, "__type__": "1"}, "57b1cdc2-be4c-499b-9aa9-f9ebf79af525": {"__data__": {"text": " \u2022  PROTOCOL LAYERS AND THEIR SERVICE MODELS      81\ninclude data compression and data encryption (which are self-explanatory) as well as \ndata description (which frees the applications from having to worry about the inter -\nnal format in which data are represented/stored\u2014formats that may differ from one \ncomputer to another). The session layer provides for delimiting and synchronization \nof data exchange, including the means to build a checkpointing and recovery scheme.\nThe fact that the Internet lacks two layers found in the OSI reference model \nposes a couple of interesting questions: Are the services provided by these layers \nunimportant? What if an application needs  one of these services? The Internet\u2019s \nanswer to both of these questions is the same\u2014it\u2019s up to the application developer. \nIt\u2019s up to the application developer to decide if a service is important, and if the ser -\nvice is important, it\u2019s up to the application developer to build that functionality into \nthe application.\n1.5.2 Encapsulation\nFigure 1. 24 shows the physical path that data takes down a sending end system\u2019s \nprotocol stack, up and down the protocol stacks of an intervening link-layer switch \nFigure 1.24  \u2666   Hosts, routers, and link-layer switches; each contains \na  different set of layers, reflecting their differences in \n functionalityM\nM\nM\nMHt\nHt\nHtHn\nHn Hl\nHt Hn Hl\nLink-layer switch\nRouterApplication\nTransport\nNetwork\nLink\nPhysicalMessage\nSegment\nDatagram\nFrame\nM\nM\nM\nMHt\nHt\nHtHn\nHn HlLink\nPhysicalSource\nNetwork\nLink\nPhysicalDestination\nApplication\nTransport\nNetwork\nLink\nPhysicalMH t Hn Hl M\nHt Hn MH t Hn M\nHt Hn Hl MH t Hn Hl M\n82     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\nand router, and then up the protocol stack at the receiving end system. As we discuss \nlater in this book, routers and link-layer switches are both packet switches. Similar \nto end systems, routers and link-layer switches organize their networking hardware \nand software into layers. But routers and link-layer switches do not implement all of \nthe layers in the protocol stack; they typically implement only the bottom layers. As \nshown in Figure 1.24, link-layer switches implement layers 1 and 2; routers imple -\nment layers 1 through 3. This means, for example, that Internet routers are capable of \nimplementing the IP protocol (a layer 3 protocol), while link-layer switches are not. \nWe\u2019ll see later that while link-layer switches do not recognize IP addresses, they are \ncapable of recognizing layer 2 addresses, such as Ethernet addresses. Note that hosts \nimplement all five layers; this is consistent with the view that the Internet architec -\nture puts much of its complexity at the edges of the network.\nFigure 1. 24 also illustrates the important concept of encapsulation . At the send -\ning host, an application-layer message  (M in Figure 1.24) is passed to the transport \nlayer. In the simplest case, the transport layer takes the message and appends addi -\ntional information (so-called transport-layer header information, Ht in Figure 1.24) \nthat will be used by the receiver-side transport layer. The application-layer message \nand the transport-layer header information together constitute the transport-layer \nsegment . The transport-layer segment thus encapsulates the application-layer mes -\nsage. The added information might include information allowing the receiver-side \ntransport layer to deliver the message up to the appropriate application, and error-\ndetection bits that allow the receiver to determine whether bits in the message have \nbeen changed in route. The transport layer then passes the segment to the network \nlayer, which adds network-layer header information ( Hn in Figure 1.24) such", "doc_id": "57b1cdc2-be4c-499b-9aa9-f9ebf79af525", "embedding": null, "doc_hash": "eb246b0754bf5acef5c9459824de8acd2436319b4da27006b71885598c4e4a57", "extra_info": null, "node_info": {"start": 222714, "end": 226440}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "8cc96437-fa97-48f9-a074-c25edd207890", "3": "823e160d-7330-4c5e-b33d-227d6d54427a"}}, "__type__": "1"}, "823e160d-7330-4c5e-b33d-227d6d54427a": {"__data__": {"text": "\nlayer. In the simplest case, the transport layer takes the message and appends addi -\ntional information (so-called transport-layer header information, Ht in Figure 1.24) \nthat will be used by the receiver-side transport layer. The application-layer message \nand the transport-layer header information together constitute the transport-layer \nsegment . The transport-layer segment thus encapsulates the application-layer mes -\nsage. The added information might include information allowing the receiver-side \ntransport layer to deliver the message up to the appropriate application, and error-\ndetection bits that allow the receiver to determine whether bits in the message have \nbeen changed in route. The transport layer then passes the segment to the network \nlayer, which adds network-layer header information ( Hn in Figure 1.24) such as \nsource and destination end system addresses, creating a network-layer datagram . \nThe datagram is then passed to the link layer, which (of course!) will add its own \nlink-layer header information and create a link-layer frame . Thus, we see that at \neach layer, a packet has two types of fields: header fields and a payload field . The \npayload is typically a packet from the layer above.\nA useful analogy here is the sending of an interoffice memo from one corpo -\nrate branch office to another via the public postal service. Suppose Alice, who is in \none branch office, wants to send a memo to Bob, who is in another branch office. \nThe memo  is analogous to the application-layer message . Alice puts the memo in \nan interoffice envelope with Bob\u2019s name and department written on the front of \nthe envelope. The interoffice envelope  is analogous to a transport-layer segment \u2014it \ncontains header information (Bob\u2019s name and department number) and it encap -\nsulates the application-layer message (the memo). When the sending branch-office \nmailroom receives the interoffice envelope, it puts the interoffice envelope inside \nyet another envelope, which is suitable for sending through the public postal service. \nThe sending mailroom also writes the postal address of the sending and receiving \nbranch offices on the postal envelope. Here, the postal envelope  is analogous to the \ndatagram \u2014it encapsulates the transport-layer segment (the interoffice envelope), \nwhich encapsulates the original message (the memo). The postal service delivers the \n1.6  \u2022  NETWORKS UNDER ATTACK      83\npostal envelope to the receiving branch-office mailroom. There, the process of de-\nencapsulation is begun. The mailroom extracts the interoffice memo and forwards it \nto Bob. Finally, Bob opens the envelope and removes the memo.\nThe process of encapsulation can be more complex than that described above. \nFor example, a large message may be divided into multiple transport-layer segments \n(which might themselves each be divided into multiple network-layer datagrams). \nAt the receiving end, such a segment must then be reconstructed from its constituent \ndatagrams.\n1.6 Networks Under Attack\nThe Internet has become mission critical for many institutions today, including large \nand small companies, universities, and government agencies. Many individuals also \nrely on the Internet for many of their professional, social, and personal activities. \nBillions of \u201cthings,\u201d including wearables and home devices, are currently being con -\nnected to the Internet. But behind all this utility and excitement, there is a dark side, \na side where \u201cbad guys\u201d attempt to wreak havoc in our daily lives by damaging our \nInternet-connected computers, violating our privacy, and rendering inoperable the \nInternet services on which we depend.\nThe field of network security is about how the bad guys can attack computer \nnetworks and about how we, soon-to-be experts in computer networking, can defend \nnetworks against those attacks, or better yet, design new architectures that are \nimmune to such attacks in the first place. Given the frequency and variety of exist -\ning attacks", "doc_id": "823e160d-7330-4c5e-b33d-227d6d54427a", "embedding": null, "doc_hash": "6652cc7902020c686d69973e0861f599a4cd2d5839d056cf708a67333aa0dd60", "extra_info": null, "node_info": {"start": 226367, "end": 230374}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "57b1cdc2-be4c-499b-9aa9-f9ebf79af525", "3": "13687b7f-e02f-4d0f-aea6-47326c102e6e"}}, "__type__": "1"}, "13687b7f-e02f-4d0f-aea6-47326c102e6e": {"__data__": {"text": "also \nrely on the Internet for many of their professional, social, and personal activities. \nBillions of \u201cthings,\u201d including wearables and home devices, are currently being con -\nnected to the Internet. But behind all this utility and excitement, there is a dark side, \na side where \u201cbad guys\u201d attempt to wreak havoc in our daily lives by damaging our \nInternet-connected computers, violating our privacy, and rendering inoperable the \nInternet services on which we depend.\nThe field of network security is about how the bad guys can attack computer \nnetworks and about how we, soon-to-be experts in computer networking, can defend \nnetworks against those attacks, or better yet, design new architectures that are \nimmune to such attacks in the first place. Given the frequency and variety of exist -\ning attacks as well as the threat of new and more destructive future attacks, network \nsecurity has become a central topic in the field of computer networking. One of the \nfeatures of this textbook is that it brings network security issues to the forefront.\nSince we don\u2019t yet have expertise in computer networking and Internet protocols, \nwe\u2019ll begin here by surveying some of today\u2019s more prevalent security-related prob -\nlems. This will whet our appetite for more substantial discussions in the upcoming \nchapters. So we begin here by simply asking, what can go wrong? How are computer \nnetworks vulnerable? What are some of the more prevalent types of attacks today?\nThe Bad Guys Can Put Malware into Your Host Via the Internet\nWe attach devices to the Internet because we want to receive/send data from/to the \nInternet. This includes all kinds of good stuff, including Instagram posts, Internet \nsearch results, streaming music, video conference calls, streaming movies, and \nso on. But, unfortunately, along with all that good stuff comes malicious stuff\u2014 \ncollectively known as malware \u2014that can also enter and infect our devices. Once \nmalware infects our device it can do all kinds of devious things, including deleting  \nour files and installing spyware that collects our private information, such as social \n84     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\n security numbers, passwords, and keystrokes, and then sends this (over the Internet, \nof course!) back to the bad guys. Our compromised host may also be enrolled in \na network of thousands of similarly compromised devices, collectively known as \na botnet , which the bad guys control and leverage for spam e-mail distribution or \ndistributed denial-of-service attacks (soon to be discussed) against targeted hosts.\nMuch of the malware out there today is self-replicating : once it infects one host, \nfrom that host it seeks entry into other hosts over the Internet, and from  the newly \ninfected hosts, it seeks entry into yet more hosts. In this manner, self- replicating mal -\nware can spread exponentially fast. Malware can spread in the form of a virus or a \nworm. Viruses  are malware that require some form of user interaction to infect the \nuser\u2019s device. The classic example is an e-mail attachment containing malicious exe -\ncutable code. If a user receives and opens such an attachment, the user inadvertently \nruns the malware on the device. Typically, such e-mail viruses are self-replicating: once \nexecuted, the virus may send an identical message with an identical malicious attach -\nment to, for example, every recipient in the user\u2019s address book. Worms  are malware \nthat can enter a device without any explicit user interaction. For example, a user may \nbe running a vulnerable network application to which an attacker can send malware. \nIn some cases, without any user intervention, the application may accept the malware \nfrom the Internet and run it, creating a worm. The worm in the newly infected device \nthen scans the Internet, searching for other hosts running the same vulnerable network \napplication. When it finds other vulnerable hosts, it sends a copy of itself to those hosts. \nToday, malware, is pervasive and costly to defend against. As you", "doc_id": "13687b7f-e02f-4d0f-aea6-47326c102e6e", "embedding": null, "doc_hash": "6e93fcbef0f522a8957f2b4f58de7ebe4403b5f3221c9580703d4e8e8b6fc9c0", "extra_info": null, "node_info": {"start": 230413, "end": 234471}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "823e160d-7330-4c5e-b33d-227d6d54427a", "3": "374a13fd-f67b-4275-877f-a5a560e808b9"}}, "__type__": "1"}, "374a13fd-f67b-4275-877f-a5a560e808b9": {"__data__": {"text": "viruses are self-replicating: once \nexecuted, the virus may send an identical message with an identical malicious attach -\nment to, for example, every recipient in the user\u2019s address book. Worms  are malware \nthat can enter a device without any explicit user interaction. For example, a user may \nbe running a vulnerable network application to which an attacker can send malware. \nIn some cases, without any user intervention, the application may accept the malware \nfrom the Internet and run it, creating a worm. The worm in the newly infected device \nthen scans the Internet, searching for other hosts running the same vulnerable network \napplication. When it finds other vulnerable hosts, it sends a copy of itself to those hosts. \nToday, malware, is pervasive and costly to defend against. As you work through this \ntextbook, we encourage you to think about the following question: What can computer \nnetwork designers do to defend Internet-attached devices from malware attacks?\nThe Bad Guys Can Attack Servers and Network Infrastructure\nAnother broad class of security threats are known as denial-of-service (DoS) \nattacks . As the name suggests, a DoS attack renders a network, host, or other piece \nof infrastructure unusable by legitimate users. Web servers, e-mail servers, DNS \nservers (discussed in Chapter 2 ), and institutional networks can all be subject to DoS \nattacks. Internet DoS attacks are extremely common, with thousands of DoS attacks \noccurring every year [Moore 2001]. The site Digital Attack Map allows use to visu -\nalize the top daily DoS attacks worldwide [DAM 2016]. Most Internet DoS attacks \nfall into one of three categories:\n\u2022 Vulnerability attack.   This involves sending a few well-crafted messages to a \nvulnerable application or operating system running on a targeted host. If the right \nsequence of packets is sent to a vulnerable application or operating system, the \nservice can stop or, worse, the host can crash.\n\u2022 Bandwidth flooding.   The attacker sends a deluge of packets to the targeted \nhost\u2014so many packets that the target\u2019s access link becomes clogged, preventing \nlegitimate packets from reaching the server.\n1.6  \u2022  NETWORKS UNDER ATTACK      85\n\u2022 Connection flooding.   The attacker establishes a large number of half-open or \nfully open TCP connections (TCP connections are discussed in Chapter 3) at the \ntarget host. The host can become so bogged down with these bogus connections \nthat it stops accepting legitimate connections.\nLet\u2019s now explore the bandwidth-flooding attack in more detail. Recalling our \ndelay and loss analysis discussion in Section 1.4.2, it\u2019s evident that if the server \nhas an access rate of R bps, then the attacker will need to send traffic at a rate of \napproximately R bps to cause damage. If R is very large, a single attack source \nmay not be able to generate enough traffic to harm the server. Furthermore, if all \nthe traffic emanates from a single source, an upstream router may be able to detect \nthe attack and block all traffic from that source before the traffic gets near the \nserver. In a distributed DoS (DDoS)  attack, illustrated in Figure 1.25, the attacker \ncontrols multiple sources and has each source blast traffic at the target. With this \napproach, the aggregate traffic rate across all the controlled sources needs to be \napproximately R to cripple the  service. DDoS attacks leveraging botnets with thou -\nsands of comprised hosts are a common occurrence today [DAM 2016]. DDos \nattacks are much harder to detect and defend against than a DoS attack from a \nsingle host.\nWe encourage you to consider the following question as you work your way \nthrough this book: What can computer network designers do to defend against DoS \nattacks? We will see that different defenses are needed for the three types of DoS \nattacks.\nFigure 1.25  \u2666 A distributed denial-of-service attackAttacker\u201cstart\n    attack\u201dSlave\nSlave\nSlaveVictim\nSlaveSlave\n86     CHAPTER 1 \u2002\u2002\u2022", "doc_id": "374a13fd-f67b-4275-877f-a5a560e808b9", "embedding": null, "doc_hash": "eec2742d483fa0830f0a04429f68c3f05541c2f45df2761aefa0d42ad4efb837", "extra_info": null, "node_info": {"start": 234486, "end": 238450}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "13687b7f-e02f-4d0f-aea6-47326c102e6e", "3": "55469b63-dc24-4ecd-bd44-0e357586bf53"}}, "__type__": "1"}, "55469b63-dc24-4ecd-bd44-0e357586bf53": {"__data__": {"text": "this \napproach, the aggregate traffic rate across all the controlled sources needs to be \napproximately R to cripple the  service. DDoS attacks leveraging botnets with thou -\nsands of comprised hosts are a common occurrence today [DAM 2016]. DDos \nattacks are much harder to detect and defend against than a DoS attack from a \nsingle host.\nWe encourage you to consider the following question as you work your way \nthrough this book: What can computer network designers do to defend against DoS \nattacks? We will see that different defenses are needed for the three types of DoS \nattacks.\nFigure 1.25  \u2666 A distributed denial-of-service attackAttacker\u201cstart\n    attack\u201dSlave\nSlave\nSlaveVictim\nSlaveSlave\n86     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\nThe Bad Guys Can Sniff Packets\nMany users today access the Internet via wireless devices, such as WiFi-connected \nlaptops or handheld devices with cellular Internet connections (covered in Chapter 7 ).  \nWhile ubiquitous Internet access is extremely convenient and enables marvelous \nnew applications for mobile users, it also creates a major security vulnerability\u2014by \nplacing a passive receiver in the vicinity of the wireless transmitter, that receiver \ncan obtain a copy of every packet that is transmitted! These packets can contain all \nkinds of sensitive information, including passwords, social security numbers, trade \nsecrets, and private personal messages. A passive receiver that records a copy of \nevery packet that flies by is called a packet sniffer .\nSniffers can be deployed in wired environments as well. In wired broadcast envi -\nronments, as in many Ethernet LANs, a packet sniffer can obtain copies of broadcast \npackets sent over the LAN. As described in Section 1.2, cable access technologies \nalso broadcast packets and are thus vulnerable to sniffing. Furthermore, a bad guy \nwho gains access to an institution\u2019s access router or access link to the Internet may be \nable to plant a sniffer that makes a copy of every packet going to/from the organiza -\ntion. Sniffed packets can then be analyzed offline for sensitive information.\nPacket-sniffing software is freely available at various Web sites and as commercial \nproducts. Professors teaching a networking course have been known to assign lab exer -\ncises that involve writing a packet-sniffing and application-layer data reconstruction \nprogram. Indeed, the Wireshark [Wireshark 2016] labs associated with this text (see the \nintroductory Wireshark lab at the end of this chapter) use exactly such a packet sniffer!\nBecause packet sniffers are passive\u2014that is, they do not inject packets into the \nchannel\u2014they are difficult to detect. So, when we send packets into a wireless chan -\nnel, we must accept the possibility that some bad guy may be recording copies of our \npackets. As you may have guessed, some of the best defenses against packet sniffing \ninvolve cryptography. We will examine cryptography as it applies to network secu -\nrity in Chapter 8.\nThe Bad Guys Can Masquerade as Someone You Trust\nIt is surprisingly easy ( you will have the knowledge to do so shortly as you proceed \nthrough this text!) to create a packet with an arbitrary source address, packet content, \nand destination address and then transmit this hand-crafted packet into the Internet, \nwhich will dutifully forward the packet to its destination. Imagine the unsuspecting \nreceiver (say an Internet router) who receives such a packet, takes the (false) source \naddress as being truthful, and then performs some command embedded in the pack -\net\u2019s contents (say modifies its forwarding table). The ability to inject packets into the \nInternet with a false source address is known as IP spoofing , and is but one of many \nways in which one user can masquerade as another user.\nTo solve this problem, we will need end-point authentication,  that is, a mecha -\nnism that will allow us to determine with certainty", "doc_id": "55469b63-dc24-4ecd-bd44-0e357586bf53", "embedding": null, "doc_hash": "55825d13c19a7e616cd3a082e95af9fe2ce54c4d167c59b5c5aa4b3284735b9f", "extra_info": null, "node_info": {"start": 238515, "end": 242446}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "374a13fd-f67b-4275-877f-a5a560e808b9", "3": "f12e966a-9701-4a0f-b787-b9c856297b8c"}}, "__type__": "1"}, "f12e966a-9701-4a0f-b787-b9c856297b8c": {"__data__": {"text": "text!) to create a packet with an arbitrary source address, packet content, \nand destination address and then transmit this hand-crafted packet into the Internet, \nwhich will dutifully forward the packet to its destination. Imagine the unsuspecting \nreceiver (say an Internet router) who receives such a packet, takes the (false) source \naddress as being truthful, and then performs some command embedded in the pack -\net\u2019s contents (say modifies its forwarding table). The ability to inject packets into the \nInternet with a false source address is known as IP spoofing , and is but one of many \nways in which one user can masquerade as another user.\nTo solve this problem, we will need end-point authentication,  that is, a mecha -\nnism that will allow us to determine with certainty if a message originates from \n1.7  \u2022  HISTORY OF COMPUTER NETWORKING AND THE INTERNET      87\nwhere we think it does. Once again, we encourage you to think about how this can \nbe done for network applications and protocols as you progress through the chapters \nof this book . We will explore mechanisms for end-point authentication in Chapter 8 .\nIn closing this section, it\u2019s worth considering how the Internet got to be such \nan insecure place in the first place. The answer, in essence, is that the Internet was \noriginally designed to be that way, based on the model of \u201ca group of mutually trust -\ning users attached to a transparent network\u201d [Blumenthal 2001]\u2014a model in which \n(by definition) there is no need for security. Many aspects of the original Internet \narchitecture deeply reflect this notion of mutual trust. For example, the ability for \none user to send a packet to any other user is the default rather than a requested/\ngranted capability, and user identity is taken at declared face value, rather than being \nauthenticated by default.\nBut today\u2019s Internet certainly does not involve \u201cmutually trusting users.\u201d None -\ntheless, today\u2019s users still need to communicate when they don\u2019t necessarily trust \neach other, may wish to communicate anonymously, may communicate indirectly \nthrough third parties (e.g., Web caches, which we\u2019ll study in Chapter 2, or mobility-\nassisting agents, which we\u2019ll study in Chapter 7 ), and may distrust the hardware, \nsoftware, and even the air through which they communicate. We now have many \nsecurity-related challenges before us as we progress through this book: We should \nseek defenses against sniffing, end-point masquerading, man-in-the-middle attacks, \nDDoS attacks, malware, and more. We should keep in mind that communication \namong mutually trusted users is the exception rather than the rule. Welcome to the \nworld of modern computer networking!\n1.7 History of Computer Networking and  \nthe Internet\nSections 1. 1 through 1.6 presented an overview of the technology of computer net -\nworking and the Internet. You should know enough now to impress your family and \nfriends! However, if you really want to be a big hit at the next cocktail party, you \nshould sprinkle your discourse with tidbits about the fascinating history of the Inter -\nnet [Segaller 1998].\n1.7.1 The Development of Packet Switching: 1961\u20131972\nThe field of computer networking and today\u2019s Internet trace their beginnings back to \nthe early 1960s, when the telephone network was the world\u2019s dominant communica -\ntion network. Recall from Section 1.3 that the telephone network uses circuit switch -\ning to transmit information from a sender to a receiver\u2014an appropriate choice given \nthat voice is transmitted at a constant rate between sender and receiver. Given the \n88     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\nincreasing importance of computers in the early 1960s and the advent of timeshared \ncomputers, it was perhaps natural to consider how to hook computers together so that \nthey could be shared among geographically distributed users. The traffic generated \nby such users was likely to be bursty \u2014intervals of activity, such as the sending of a \ncommand to a", "doc_id": "f12e966a-9701-4a0f-b787-b9c856297b8c", "embedding": null, "doc_hash": "1dc3a08feffdf4be5c132e5d02ae9a050ce35c6a741168e03a33dd2742ace299", "extra_info": null, "node_info": {"start": 242396, "end": 246398}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "55469b63-dc24-4ecd-bd44-0e357586bf53", "3": "7836b5b7-597a-473f-a7dd-022ab96bf35f"}}, "__type__": "1"}, "7836b5b7-597a-473f-a7dd-022ab96bf35f": {"__data__": {"text": "Internet trace their beginnings back to \nthe early 1960s, when the telephone network was the world\u2019s dominant communica -\ntion network. Recall from Section 1.3 that the telephone network uses circuit switch -\ning to transmit information from a sender to a receiver\u2014an appropriate choice given \nthat voice is transmitted at a constant rate between sender and receiver. Given the \n88     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\nincreasing importance of computers in the early 1960s and the advent of timeshared \ncomputers, it was perhaps natural to consider how to hook computers together so that \nthey could be shared among geographically distributed users. The traffic generated \nby such users was likely to be bursty \u2014intervals of activity, such as the sending of a \ncommand to a remote computer, followed by periods of inactivity while waiting for \na reply or while contemplating the received response.\nThree research groups around the world, each unaware of the others\u2019 work \n[Leiner 1998], began inventing packet switching as an efficient and robust alterna -\ntive to circuit switching. The first published work on packet-switching techniques \nwas that of Leonard Kleinrock [Kleinrock 1961; Kleinrock 1964], then a graduate \nstudent at MIT. Using queuing theory, Kleinrock\u2019s work elegantly demonstrated the \neffectiveness of the packet-switching approach for bursty traffic sources. In 1964, \nPaul Baran [Baran 1964] at the Rand Institute had begun investigating the use of \npacket switching for secure voice over military networks, and at the National Physi -\ncal Laboratory in England, Donald Davies and Roger Scantlebury were also devel -\noping their ideas on packet switching.\nThe work at MIT, Rand, and the NPL laid the foundations for today\u2019s Internet. \nBut the Internet also has a long history of a let\u2019s-build-it-and-demonstrate-it attitude \nthat also dates back to the 1960s. J. C. R. Licklider [DEC 1990] and Lawrence Rob -\nerts, both colleagues of Kleinrock\u2019s at MIT, went on to lead the computer science \nprogram at the Advanced Research Projects Agency (ARPA) in the United States. \nRoberts published an overall plan for the ARPAnet [Roberts 1967], the first packet-\nswitched computer network and a direct ancestor of today\u2019s public Internet. On \nLabor Day in 1969, the first packet switch was installed at UCLA under Kleinrock\u2019s \nsupervision, and three additional packet switches were installed shortly thereafter at \nthe Stanford Research Institute (SRI), UC Santa Barbara, and the University of Utah \n(Figure 1. 26). The fledgling precursor to the Internet was four nodes large by the end \nof 1969. Kleinrock recalls the very first use of the network to perform a remote login \nfrom UCLA to SRI, crashing the system [Kleinrock 2004].\nBy 1972, ARPAnet had grown to approximately 15 nodes and was given its \nfirst public demonstration by Robert Kahn. The first host-to-host protocol between \nARPAnet end systems, known as the network-control protocol (NCP), was com -\npleted [RFC 001]. With an end-to-end protocol available, applications could now be \nwritten. Ray Tomlinson wrote the first e-mail program in 1972.\n1.7.2 Proprietary Networks and Internetworking:  \n1972\u20131980\nThe initial ARPAnet was a single, closed network. In order to communicate with an \nARPAnet host, one had to be actually attached to another ARPAnet IMP. In the early \nto mid-1970s, additional stand-alone packet-switching networks besides ARPAnet \ncame into being: ALOHANet, a microwave network linking universities on the \nHawaiian islands [Abramson 1970], as well as DARPA\u2019s packet-satellite [RFC 829]  \n1.7  \u2022  HISTORY OF COMPUTER NETWORKING AND THE INTERNET      89\nand packet-radio networks [Kahn 1978]; Telenet, a BBN commercial packet- switching", "doc_id": "7836b5b7-597a-473f-a7dd-022ab96bf35f", "embedding": null, "doc_hash": "643494e7b09a65886ce71cc722f080c26a6b1dc499c0d58ab58f38ab28eb4daa", "extra_info": null, "node_info": {"start": 246394, "end": 250150}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "f12e966a-9701-4a0f-b787-b9c856297b8c", "3": "eb13f5d3-1fab-4a9b-945b-0373a3455e48"}}, "__type__": "1"}, "eb13f5d3-1fab-4a9b-945b-0373a3455e48": {"__data__": {"text": "program in 1972.\n1.7.2 Proprietary Networks and Internetworking:  \n1972\u20131980\nThe initial ARPAnet was a single, closed network. In order to communicate with an \nARPAnet host, one had to be actually attached to another ARPAnet IMP. In the early \nto mid-1970s, additional stand-alone packet-switching networks besides ARPAnet \ncame into being: ALOHANet, a microwave network linking universities on the \nHawaiian islands [Abramson 1970], as well as DARPA\u2019s packet-satellite [RFC 829]  \n1.7  \u2022  HISTORY OF COMPUTER NETWORKING AND THE INTERNET      89\nand packet-radio networks [Kahn 1978]; Telenet, a BBN commercial packet- switching \nnetwork based on ARPAnet technology; Cyclades, a French packet-switching net -\nwork pioneered by Louis Pouzin [Think 2012]; Time-sharing networks such as \nTymnet and the GE Information Services network, among others, in the late 1960s \nand early 1970s [Schwartz 1977]; IBM\u2019s SNA (1969\u20131974), which paralleled the \nARPAnet work [Schwartz 1977].\nThe number of networks was growing. With perfect hindsight we can see that the \ntime was ripe for developing an encompassing architecture for connecting networks \ntogether. Pioneering work on interconnecting networks (under the sponsorship of \nthe Defense Advanced Research Projects Agency (DARPA)), in essence creating Figure 1.26  \u2666 An early packet switch\n\n90     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\na network of networks,  was done by Vinton Cerf and Robert Kahn [Cerf 1974]; the \nterm internetting  was coined to describe this work.\nThese architectural principles were embodied in TCP. The early versions of \nTCP, however, were quite different from today\u2019s TCP. The early versions of TCP \ncombined a reliable in-sequence delivery of data via end-system retransmission (still \npart of today\u2019s TCP) with forwarding functions (which today are performed by IP). \nEarly experimentation with TCP, combined with the recognition of the importance \nof an unreliable, non-flow-controlled, end-to-end transport service for applications \nsuch as packetized voice, led to the separation of IP out of TCP and the development \nof the UDP protocol. The three key Internet protocols that we see today\u2014TCP, UDP, \nand IP\u2014were conceptually in place by the end of the 1970s.\nIn addition to the DARPA Internet-related research, many other important net -\nworking activities were underway. In Hawaii, Norman Abramson was developing  \nALOHAnet, a packet-based radio network that allowed multiple remote sites \non the Hawaiian Islands to communicate with each other. The ALOHA protocol  \n[Abramson 1970] was the first multiple-access protocol, allowing geographically  \ndistributed users to share a single broadcast communication medium (a radio \n frequency). Metcalfe and Boggs built on Abramson\u2019s multiple-access protocol work \nwhen they developed the Ethernet protocol [Metcalfe 1976] for wire-based shared \nbroadcast networks. Interestingly, Metcalfe and Boggs\u2019 Ethernet protocol was moti -\nvated by the need to connect multiple PCs, printers, and shared disks [Perkins 1994]. \nTwenty-five years ago, well before the PC revolution and the explosion of networks, \nMetcalfe and Boggs were laying the foundation for today\u2019s PC LANs.\n1.7.3 A Proliferation of Networks: 1980\u20131990\nBy the end of the 1970s, approximately two hundred hosts were connected to the \nARPAnet. By the end of the 1980s the number of hosts connected to the public \n Internet, a confederation of networks looking much like today\u2019s Internet, would \nreach a hundred thousand. The 1980s would be a time of tremendous growth.\nMuch of that growth resulted from several distinct efforts to", "doc_id": "eb13f5d3-1fab-4a9b-945b-0373a3455e48", "embedding": null, "doc_hash": "2669033c0657cd3424e7bd5738b958a7dff541646c63bd93998aac2bc673e1c7", "extra_info": null, "node_info": {"start": 250281, "end": 253904}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "7836b5b7-597a-473f-a7dd-022ab96bf35f", "3": "af6ea6d1-6b5d-4878-82bf-c90e8c1b32be"}}, "__type__": "1"}, "af6ea6d1-6b5d-4878-82bf-c90e8c1b32be": {"__data__": {"text": "Metcalfe and Boggs\u2019 Ethernet protocol was moti -\nvated by the need to connect multiple PCs, printers, and shared disks [Perkins 1994]. \nTwenty-five years ago, well before the PC revolution and the explosion of networks, \nMetcalfe and Boggs were laying the foundation for today\u2019s PC LANs.\n1.7.3 A Proliferation of Networks: 1980\u20131990\nBy the end of the 1970s, approximately two hundred hosts were connected to the \nARPAnet. By the end of the 1980s the number of hosts connected to the public \n Internet, a confederation of networks looking much like today\u2019s Internet, would \nreach a hundred thousand. The 1980s would be a time of tremendous growth.\nMuch of that growth resulted from several distinct efforts to create computer \nnetworks linking universities together. BITNET provided e-mail and file transfers \namong several universities in the Northeast. CSNET (computer science network) \nwas formed to link university researchers who did not have access to ARPAnet. In \n1986, NSFNET was created to provide access to NSF-sponsored supercomputing \ncenters. Starting with an initial backbone speed of 56 kbps, NSFNET\u2019s backbone \nwould be running at 1.5 Mbps by the end of the decade and would serve as a primary \nbackbone linking regional networks.\nIn the ARPAnet community, many of the final pieces of today\u2019s Internet archi -\ntecture were falling into place. January 1, 1983 saw the official deployment of TCP/\nIP as the new standard host protocol for ARPAnet (replacing the NCP protocol). \nThe transition [RFC 801] from NCP to TCP/IP was a flag day event\u2014all hosts \nwere required to transfer over to TCP/IP as of that day. In the late 1980s, important \n1.7  \u2022  HISTORY OF COMPUTER NETWORKING AND THE INTERNET      91\nextensions were made to TCP to implement host-based congestion control [Jacobson \n1988]. The DNS, used to map between a human-readable Internet name (for exam -\nple, gaia.cs.umass.edu) and its 32-bit IP address, was also developed [RFC 1034].\nParalleling this development of the ARPAnet (which was for the most part a \nUS effort), in the early 1980s the French launched the Minitel project, an ambitious \nplan to bring data networking into everyone\u2019s home. Sponsored by the French gov -\nernment, the Minitel system consisted of a public packet-switched network (based \non the X.25 protocol suite), Minitel servers, and inexpensive terminals with built-in \nlow-speed modems. The Minitel became a huge success in 1984 when the French \ngovernment gave away a free Minitel terminal to each French household that wanted \none. Minitel sites included free sites\u2014such as a telephone directory site\u2014as well as \nprivate sites, which collected a usage-based fee from each user. At its peak in the mid \n1990s, it offered more than 20,000 services, ranging from home banking to special -\nized research databases. The Minitel was in a large proportion of French homes 10 \nyears before most Americans had ever heard of the Internet.\n1.7.4 The Internet Explosion: The 1990s\nThe 1990s were ushered in with a number of events that symbolized the continued \nevolution and the soon-to-arrive commercialization of the Internet. ARPAnet, the \nprogenitor of the Internet, ceased to exist. In 1991, NSFNET lifted its restrictions on \nthe use of NSFNET for commercial purposes. NSFNET itself would be decommis -\nsioned in 1995, with Internet backbone traffic being carried by commercial Internet \nService Providers.\nThe main event of the 1990s was to be the emergence of the World Wide Web \napplication, which brought the Internet into the homes and businesses of millions \nof people worldwide. The Web served as a platform for enabling and deploying \nhundreds of new applications that we take for granted today, including search (e.g., \nGoogle and Bing) Internet commerce", "doc_id": "af6ea6d1-6b5d-4878-82bf-c90e8c1b32be", "embedding": null, "doc_hash": "4eb520e071c021bb3c23b29e8986fb50b20b9b11fd8e0402ee94390285c436c2", "extra_info": null, "node_info": {"start": 253842, "end": 257606}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "eb13f5d3-1fab-4a9b-945b-0373a3455e48", "3": "e9cef8fd-5e32-453f-9d0b-a4863bb5737c"}}, "__type__": "1"}, "e9cef8fd-5e32-453f-9d0b-a4863bb5737c": {"__data__": {"text": "1990s were ushered in with a number of events that symbolized the continued \nevolution and the soon-to-arrive commercialization of the Internet. ARPAnet, the \nprogenitor of the Internet, ceased to exist. In 1991, NSFNET lifted its restrictions on \nthe use of NSFNET for commercial purposes. NSFNET itself would be decommis -\nsioned in 1995, with Internet backbone traffic being carried by commercial Internet \nService Providers.\nThe main event of the 1990s was to be the emergence of the World Wide Web \napplication, which brought the Internet into the homes and businesses of millions \nof people worldwide. The Web served as a platform for enabling and deploying \nhundreds of new applications that we take for granted today, including search (e.g., \nGoogle and Bing) Internet commerce (e.g., Amazon and eBay) and social networks \n(e.g., Facebook).\nThe Web was invented at CERN by Tim Berners-Lee between 1989 and 1991 \n[Berners-Lee 1989], based on ideas originating in earlier work on hypertext from the \n1940s by Vannevar Bush [Bush 1945] and since the 1960s by Ted Nelson [Xanadu \n2012]. Berners-Lee and his associates developed initial versions of HTML, HTTP, \na Web server, and a browser\u2014the four key components of the Web. Around the end \nof 1993 there were about two hundred Web servers in operation, this collection of \nservers being just a harbinger of what was about to come. At about this time sev -\neral researchers were developing Web browsers with GUI interfaces, including Marc \nAndreessen, who along with Jim Clark, formed Mosaic Communications, which \nlater became Netscape Communications Corporation [Cusumano 1998; Quittner \n1998]. By 1995, university students were using Netscape browsers to surf the Web \non a daily basis. At about this time companies\u2014big and small\u2014began to operate \nWeb servers and transact commerce over the Web. In 1996, Microsoft started to \n92     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\nmake browsers, which started the browser war between Netscape and Microsoft, \nwhich Microsoft won a few years later [Cusumano 1998].\nThe second half of the 1990s was a period of tremendous growth and innovation \nfor the Internet, with major corporations and thousands of startups creating Internet \nproducts and services. By the end of the millennium the Internet was supporting \nhundreds of popular applications, including four killer applications:\n\u2022 E-mail, including attachments and Web-accessible e-mail\n\u2022 The Web, including Web browsing and Internet commerce\n\u2022 Instant messaging, with contact lists\n\u2022 Peer-to-peer file sharing of MP3s, pioneered by Napster\nInterestingly, the first two killer applications came from the research community, \nwhereas the last two were created by a few young entrepreneurs.\nThe period from 1995 to 2001 was a roller-coaster ride for the Internet in the \nfinancial markets. Before they were even profitable, hundreds of Internet startups \nmade initial public offerings and started to be traded in a stock market. Many com -\npanies were valued in the billions of dollars without having any significant revenue \nstreams. The Internet stocks collapsed in 2000\u20132001, and many startups shut down. \nNevertheless, a number of companies emerged as big winners in the Internet space, \nincluding Microsoft, Cisco, Yahoo, e-Bay, Google, and Amazon.\n1.7.5 The New Millennium\nInnovation in computer networking continues at a rapid pace. Advances are being \nmade on all fronts, including deployments of faster routers and higher transmission \nspeeds in both access networks and in network backbones. But the following devel -\nopments merit special attention:\n\u2022 Since the beginning of the millennium, we have been seeing aggressive deploy -\nment of broadband Internet access to homes\u2014not only cable modems and DSL \nbut also fiber to the home, as discussed in Section 1.2. This high-speed Internet \naccess has set the stage for a wealth of video applications, including the distribu -\ntion", "doc_id": "e9cef8fd-5e32-453f-9d0b-a4863bb5737c", "embedding": null, "doc_hash": "0e5b25a6cf5ded08b06a611420b11c186e6ce99d6023490870a50a144d6efcff", "extra_info": null, "node_info": {"start": 257539, "end": 261490}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "af6ea6d1-6b5d-4878-82bf-c90e8c1b32be", "3": "5dde6ed3-02ec-4256-8a46-e5d3fdedc978"}}, "__type__": "1"}, "5dde6ed3-02ec-4256-8a46-e5d3fdedc978": {"__data__": {"text": "of companies emerged as big winners in the Internet space, \nincluding Microsoft, Cisco, Yahoo, e-Bay, Google, and Amazon.\n1.7.5 The New Millennium\nInnovation in computer networking continues at a rapid pace. Advances are being \nmade on all fronts, including deployments of faster routers and higher transmission \nspeeds in both access networks and in network backbones. But the following devel -\nopments merit special attention:\n\u2022 Since the beginning of the millennium, we have been seeing aggressive deploy -\nment of broadband Internet access to homes\u2014not only cable modems and DSL \nbut also fiber to the home, as discussed in Section 1.2. This high-speed Internet \naccess has set the stage for a wealth of video applications, including the distribu -\ntion of user-generated video (for example, YouTube), on-demand streaming of \nmovies and television shows (e.g., Netflix), and multi-person video conference \n(e.g., Skype, Facetime, and Google Hangouts).\n\u2022 The increasing ubiquity of high-speed (54 Mbps and higher) public WiFi net -\nworks and medium-speed (tens of Mbps) Internet access via 4G cellular teleph -\nony networks is not only making it possible to remain constantly connected while \non the move, but also enabling new location-specific applications such as Yelp, \nTinder, Yik Yak, and Waz. The number of wireless devices connecting to the \nInternet surpassed the number of wired devices in 2011. This high-speed wireless \n1.8  \u2022  SUMMARY      93\naccess has set the stage for the rapid emergence of hand-held computers (iPhones, \nAndroids, iPads, and so on), which enjoy constant and untethered access to the \nInternet.\n\u2022 Online social networks\u2014such as Facebook, Instagram, Twitter, and WeChat \n(hugely popular in China)\u2014have created massive people networks on top of the \nInternet. Many of these social networks are extensively used for messaging as \nwell as photo sharing. Many Internet users today \u201clive\u201d primarily within one or \nmore social networks. Through their APIs, the online social networks create plat -\nforms for new networked applications and distributed games.\n\u2022 As discussed in Section 1.3.3, online service providers, such as Google and \nMicrosoft, have deployed their own extensive private networks, which not only \nconnect together their globally distributed data centers, but are used to bypass the \nInternet as much as possible by peering directly with lower-tier ISPs. As a result, \nGoogle provides search results and e-mail access almost instantaneously, as if \ntheir data centers were running within one\u2019s own computer.\n\u2022 Many Internet commerce companies are now running their applications in the \n\u201ccloud\u201d\u2014such as in Amazon\u2019s EC2, in Google\u2019s Application Engine, or in \nMicrosoft\u2019s Azure. Many companies and universities have also migrated their \nInternet applications (e.g., e-mail and Web hosting) to the cloud. Cloud compa -\nnies not only provide applications scalable computing and storage environments, \nbut also provide the applications implicit access to their high-performance private \nnetworks.\n1.8 Summary\nIn this chapter we\u2019ve covered a tremendous amount of material! We\u2019ve looked at \nthe various pieces of hardware and software that make up the Internet in particular \nand computer networks in general. We started at the edge of the network, looking at \nend systems and applications, and at the transport service provided to the applica -\ntions running on the end systems. We also looked at the link-layer technologies and \nphysical media typically found in the access network. We then dove deeper inside \nthe network, into the network core, identifying packet switching and circuit switch -\ning as the two basic approaches for transporting data through a telecommunication \nnetwork, and we examined the strengths and weaknesses of each approach. We also \nexamined the structure of the global Internet, learning that the Internet is a network \nof networks. We saw that the Internet\u2019s", "doc_id": "5dde6ed3-02ec-4256-8a46-e5d3fdedc978", "embedding": null, "doc_hash": "b16ab54c519662032ffa1f249ddf231757cc279c8b91d9ba81fed51b9904d201", "extra_info": null, "node_info": {"start": 261512, "end": 265443}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "e9cef8fd-5e32-453f-9d0b-a4863bb5737c", "3": "fb9bfa1f-b567-40ad-a89b-02a8ab70b023"}}, "__type__": "1"}, "fb9bfa1f-b567-40ad-a89b-02a8ab70b023": {"__data__": {"text": "amount of material! We\u2019ve looked at \nthe various pieces of hardware and software that make up the Internet in particular \nand computer networks in general. We started at the edge of the network, looking at \nend systems and applications, and at the transport service provided to the applica -\ntions running on the end systems. We also looked at the link-layer technologies and \nphysical media typically found in the access network. We then dove deeper inside \nthe network, into the network core, identifying packet switching and circuit switch -\ning as the two basic approaches for transporting data through a telecommunication \nnetwork, and we examined the strengths and weaknesses of each approach. We also \nexamined the structure of the global Internet, learning that the Internet is a network \nof networks. We saw that the Internet\u2019s hierarchical structure, consisting of higher- \nand lower-tier ISPs, has allowed it to scale to include thousands of networks.\nIn the second part of this introductory chapter, we examined several topics cen-\ntral to the field of computer networking. We first examined the causes of delay, \nthroughput and packet loss in a packet-switched network. We developed simple \n94     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\nquantitative models for transmission, propagation, and queuing delays as well as \nfor throughput; we\u2019ll make extensive use of these delay models in the homework \nproblems throughout this book. Next we examined protocol layering and service \nmodels, key architectural principles in networking that we will also refer back to \nthroughout this book. We also surveyed some of the more prevalent security attacks \nin the Internet day. We finished our introduction to networking with a brief history \nof computer networking. The first chapter in itself constitutes a mini-course in com -\nputer networking.\nSo, we have indeed covered a tremendous amount of ground in this first chapter ! \nIf you\u2019re a bit overwhelmed, don\u2019t worry. In the following chapters we\u2019ll revisit all \nof these ideas, covering them in much more detail (that\u2019s a promise, not a threat!). \nAt this point, we hope you leave this chapter with a still-developing intuition for the \npieces that make up a network, a still-developing command of the vocabulary of \nnetworking (don\u2019t be shy about referring back to this chapter), and an ever-growing \ndesire to learn more about networking. That\u2019s the task ahead of us for the rest of this \nbook.\nRoad-Mapping This Book\nBefore starting any trip, you should always glance at a road map in order to become \nfamiliar with the major roads and junctures that lie ahead. For the trip we are about \nto embark on, the ultimate destination is a deep understanding of the how, what, and \nwhy of computer networks. Our road map is the sequence of chapters of this book:\n 1. Computer Networks and the Internet\n 2. Application Layer\n 3. Transport Layer\n 4. Network Layer: Data Plane\n 5. Network Layer: Control Plane\n 6. The Link Layer and LANs\n 7. Wireless and Mobile Networks\n 8. Security in Computer Networks\n 9. Multimedia Networking\nChapters 2 through 6 are the five core chapters of this book. You should notice \nthat these chapters are organized around the top four layers of the five-layer Internet \nprotocol. Further note that our journey will begin at the top of the Internet protocol \nstack, namely, the application layer, and will work its way downward. The rationale \nbehind this top-down journey is that once we understand the applications, we can \nunderstand the network services needed to support these applications. We can then, \nin turn, examine the various ways in which such services might be implemented by \na network architecture. Covering applications early thus provides motivation for the \nremainder of the text.\nHOMEWORK PROBLEMS AND QUESTIONS      95\nThe second half of the book\u2014Chapters 7 through 9\u2014zooms in on three \nenormously important (and somewhat independent) topics in modern computer", "doc_id": "fb9bfa1f-b567-40ad-a89b-02a8ab70b023", "embedding": null, "doc_hash": "d7ebea6ebc5544e1c776d0c8aefb6df759f0f1d43c698e780b46faba1b5af116", "extra_info": null, "node_info": {"start": 265384, "end": 269359}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "5dde6ed3-02ec-4256-8a46-e5d3fdedc978", "3": "fe829457-6dc6-47ba-8620-0784d9c685f3"}}, "__type__": "1"}, "fe829457-6dc6-47ba-8620-0784d9c685f3": {"__data__": {"text": "these chapters are organized around the top four layers of the five-layer Internet \nprotocol. Further note that our journey will begin at the top of the Internet protocol \nstack, namely, the application layer, and will work its way downward. The rationale \nbehind this top-down journey is that once we understand the applications, we can \nunderstand the network services needed to support these applications. We can then, \nin turn, examine the various ways in which such services might be implemented by \na network architecture. Covering applications early thus provides motivation for the \nremainder of the text.\nHOMEWORK PROBLEMS AND QUESTIONS      95\nThe second half of the book\u2014Chapters 7 through 9\u2014zooms in on three \nenormously important (and somewhat independent) topics in modern computer \nnetworking. In Chapter 7, we examine wireless and mobile networks, includ -\ning wireless LANs (including WiFi and Bluetooth), Cellular telephony networks \n(including GSM, 3G, and 4G), and mobility (in both IP and GSM networks).  \nChapter 8, which addresses security in computer networks, first looks at the under -\npinnings of encryption and network security, and then we examine how the basic \ntheory is being applied in a broad range of Internet contexts. The last chapter, which \naddresses multimedia networking, examines audio and video applications such as \nInternet phone, video conferencing, and streaming of stored media. We also look \nat how a packet-switched network can be designed to provide consistent quality of \nservice to audio and video applications.\nHomework Problems and Questions\nChapter 1 Review Questions\nSECTION 1.1\n R1. What is the difference between a host and an end system? List several differ-\nent types of end systems. Is a Web server an end system?\n R2. Describe the protocol that might be used by two people having a telephonic \nconversation to initiate and end the conversation.\n R3. Why are standards important for protocols?\nSECTION 1.2\n R4. List six access technologies. Classify each one as home access, enterprise \naccess, or wide-area wireless access.\n R5. Is HFC transmission rate dedicated or shared among users? Are collisions \npossible in a downstream HFC channel? Why or why not?\n R6. What access network technologies would be most suitable for providing \nInternet access in rural areas?\n R7. Dial-up modems and DSL both use the telephone line (a twisted-pair copper cable) \nas their transmission medium. Why then is DSL much faster than dial-up access?\n R8. What are some of the physical media that Ethernet can run over?\n R9. Dial-up modems, HFC, DSL and FTTH are all used for residential access. \nFor each of these access technologies, provide a range of  transmission rates \nand comment on whether the transmission rate is shared or dedicated.\n R10. Describe the different wireless technologies you use during the day and their \ncharacteristics. If you have a choice between multiple technologies, why do \nyou prefer one over another?\n96     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\nSECTION 1.3\n R11. Suppose there is exactly one packet switch between a sending host and a \nreceiving host. The transmission rates between the sending host and the \nswitch and between the switch and the receiving host are R1 and R2, respec-\ntively. Assuming that the switch uses store-and-forward packet switching, \nwhat is the total end-to-end delay to send a packet of length L? (Ignore queu-\ning, propagation delay, and processing delay.)\n R12. What advantage does a circuit-switched network have over a packet-switched \nnetwork? What advantages does TDM have over FDM in a circuit-switched \nnetwork?\n R13. Suppose users share a 2 Mbps link. Also suppose each user transmits contin-\nuously at 1 Mbps when transmitting, but each user transmits only 20 percent \nof the time. (See the discussion of statistical multiplexing in", "doc_id": "fe829457-6dc6-47ba-8620-0784d9c685f3", "embedding": null, "doc_hash": "bcaf9b0b3164f9fb5752d1c720086d5e44d8f79d3a5cc51a40bff52fab1e4c39", "extra_info": null, "node_info": {"start": 269392, "end": 273255}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "fb9bfa1f-b567-40ad-a89b-02a8ab70b023", "3": "7399d33a-97ee-4188-a725-6684bc671b7a"}}, "__type__": "1"}, "7399d33a-97ee-4188-a725-6684bc671b7a": {"__data__": {"text": "and a \nreceiving host. The transmission rates between the sending host and the \nswitch and between the switch and the receiving host are R1 and R2, respec-\ntively. Assuming that the switch uses store-and-forward packet switching, \nwhat is the total end-to-end delay to send a packet of length L? (Ignore queu-\ning, propagation delay, and processing delay.)\n R12. What advantage does a circuit-switched network have over a packet-switched \nnetwork? What advantages does TDM have over FDM in a circuit-switched \nnetwork?\n R13. Suppose users share a 2 Mbps link. Also suppose each user transmits contin-\nuously at 1 Mbps when transmitting, but each user transmits only 20 percent \nof the time. (See the discussion of statistical multiplexing in Section 1.3.)\na. When circuit switching is used, how many users can be supported?\nb. For the remainder of this problem, suppose packet switching is used. Why \nwill there be essentially no queuing delay before the link if two or fewer \nusers transmit at the same time? Why will there be a queuing delay if \nthree users transmit at the same time?\nc. Find the probability that a given user is transmitting.\nd. Suppose now there are three users. Find the probability that at any given \ntime, all three users are transmitting simultaneously. Find the fraction of \ntime during which the queue grows.\n R14. Why will two ISPs at the same level of the hierarchy often peer with each \nother? How does an IXP earn money?\n R15. Why is a content provider considered a different Internet entity today? How \ndoes a content provider connect to other ISPs? Why?\nSECTION 1.4\n R16. Consider sending a packet from a source host to a destination host over a \nfixed route. List the delay components in the end-to-end delay. Which of \nthese delays are constant and which are variable?\n R17. Visit the Transmission Versus Propagation Delay applet at the companion \nWeb site. Among the rates, propagation delay, and packet sizes available, find \na combination for which the sender finishes transmitting before the first bit of \nthe packet reaches the receiver. Find another combination for which the first \nbit of the packet reaches the receiver before the sender finishes transmitting.\n R18. A user can directly connect to a server through either long-range wireless \nor a twisted-pair cable for transmitting a 1500-bytes file. The transmission \nrates\u00a0of the wireless and wired media are 2 and 100 Mbps, respectively. \nAssume that the propagation speed in air is 3 3 108 m/s, while the speed in \nHOMEWORK PROBLEMS AND QUESTIONS      97\nthe twisted pair is 2 3 108 m/s. If the user is located 1 km away from the \nserver, what is the nodal delay when using each of the two technologies?\n R19. Suppose Host A wants to send a large file to Host B. The path from Host A to Host \nB has three links, of rates R1=500 kbps, R2=2 Mbps, and R3=1 Mbps.\na. Assuming no other traffic in the network, what is the throughput for the \nfile transfer?\nb. Suppose the file is 4 million bytes. Dividing the file size by the through-\nput, roughly how long will it take to transfer the file to Host B?\nc. Repeat (a) and (b), but now with R2 reduced to 100 kbps.\n R20. Suppose end system A wants to send a large file to end system B. At a very \nhigh level, describe how end system A creates packets from the file. When \none of these packets arrives to a router, what information in the packet does \nthe router use to determine the link onto which the packet is forwarded? \nWhy is packet switching in the Internet analogous to driving from one city to \nanother and asking directions along the way?\n R21. Visit the Queuing and Loss applet at the companion Web site. What is the \nmaximum emission rate and the minimum transmission rate? With those \nrates, what is the traffic intensity? Run the", "doc_id": "7399d33a-97ee-4188-a725-6684bc671b7a", "embedding": null, "doc_hash": "62eb75607224f63fb15f105230913d8624c1c12b3cc5fb1934296475a8d2e0fb", "extra_info": null, "node_info": {"start": 273300, "end": 277085}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "fe829457-6dc6-47ba-8620-0784d9c685f3", "3": "f4c46dc6-91ad-4562-969d-3ceab4817eb5"}}, "__type__": "1"}, "f4c46dc6-91ad-4562-969d-3ceab4817eb5": {"__data__": {"text": "roughly how long will it take to transfer the file to Host B?\nc. Repeat (a) and (b), but now with R2 reduced to 100 kbps.\n R20. Suppose end system A wants to send a large file to end system B. At a very \nhigh level, describe how end system A creates packets from the file. When \none of these packets arrives to a router, what information in the packet does \nthe router use to determine the link onto which the packet is forwarded? \nWhy is packet switching in the Internet analogous to driving from one city to \nanother and asking directions along the way?\n R21. Visit the Queuing and Loss applet at the companion Web site. What is the \nmaximum emission rate and the minimum transmission rate? With those \nrates, what is the traffic intensity? Run the applet with these rates and deter-\nmine how long it takes for packet loss to occur. Then repeat the experiment \na second time and determine again how long it takes for packet loss to occur. \nAre the values different? Why or why not?\nSECTION 1.5\n R22. If two end-systems are connected through multiple routers and the data-link \nlevel between them ensures reliable data delivery, is a transport protocol offer -\ning reliable data delivery between these two end-systems necessary? Why?\n R23. What are the five layers in the Internet protocol stack? What are the principal \nresponsibilities of each of these layers?\n R24. What do encapsulation and de-encapsulation mean? Why are they needed in \na layered protocol stack?\n R25. Which layers in the Internet protocol stack does a router process? Which lay-\ners does a link-layer switch process? Which layers does a host process?\nSECTION 1.6\n R26. You are in a university classroom and you want to spy on what websites your \nclassmates are visiting with their laptops during the course lecture. If they all con -\nnect to the Internet through the university\u2019s WiFi network, what could you do?\n R27. Describe how a botnet can be created and how it can be used for a DDoS attack.\n R28. Suppose Alice and Bob are sending packets to each other over a computer \nnetwork. Suppose Trudy positions herself in the network so that she can \ncapture all the packets sent by Alice and send whatever she wants to Bob; she \ncan also capture all the packets sent by Bob and send whatever she wants to \nAlice. List some of the malicious things Trudy can do from this position.\n98     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\nProblems\n P1. Design and describe an application-level protocol to be used between an \nautomatic teller machine and a bank\u2019s centralized computer. Your protocol \nshould allow a user\u2019s card and password to be verified, the account bal-\nance (which is maintained at the centralized computer) to be queried, and an \naccount withdrawal to be made (that is, money disbursed to the user). Your \nprotocol entities should be able to handle the all-too-common case in which \nthere is not enough money in the account to cover the withdrawal. Specify \nyour protocol by listing the messages exchanged and the action taken by the \nautomatic teller machine or the bank\u2019s centralized computer on transmission \nand receipt of messages. Sketch the operation of your protocol for the case of \na simple withdrawal with no errors, using a diagram similar to that in Figure 1.2.  \nExplicitly state the assumptions made by your protocol about the underlying \nend-to-end transport service.\n P2. Equation 1.1 gives a formula for the end-to-end delay of sending one packet \nof length L over N links of transmission rate R. Generalize this formula for \nsending P such packets back-to-back over the N links.\n P3. Consider an application that transmits data at a steady rate (for example, the \nsender generates an N-bit unit of data every k time units, where k is small \nand fixed). Also, when such an application starts, it will continue running", "doc_id": "f4c46dc6-91ad-4562-969d-3ceab4817eb5", "embedding": null, "doc_hash": "0a4cb3002e91f948afe5eb2a304b9be96466f5bfbfded9812a7f529eac04db53", "extra_info": null, "node_info": {"start": 277100, "end": 280931}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "7399d33a-97ee-4188-a725-6684bc671b7a", "3": "0038fcb3-eae5-4c1e-9b43-d8128598e6da"}}, "__type__": "1"}, "0038fcb3-eae5-4c1e-9b43-d8128598e6da": {"__data__": {"text": "on transmission \nand receipt of messages. Sketch the operation of your protocol for the case of \na simple withdrawal with no errors, using a diagram similar to that in Figure 1.2.  \nExplicitly state the assumptions made by your protocol about the underlying \nend-to-end transport service.\n P2. Equation 1.1 gives a formula for the end-to-end delay of sending one packet \nof length L over N links of transmission rate R. Generalize this formula for \nsending P such packets back-to-back over the N links.\n P3. Consider an application that transmits data at a steady rate (for example, the \nsender generates an N-bit unit of data every k time units, where k is small \nand fixed). Also, when such an application starts, it will continue running \nfor a relatively long period of time. Answer the following questions, briefly \njustifying your answer:\na. Would a packet-switched network or a circuit-switched network be more \nappropriate for this application? Why?\nb. Suppose that a packet-switched network is used and the only traffic in \nthis network comes from such applications as described above. Further -\nmore, assume that the sum of the application data rates is less than the \ncapacities of each and every link. Is some form of congestion control \nneeded? Why?\n P4. Consider the circuit-switched network in Figure 1.13. Recall that there are \n4 circuits on each link. Label the four switches A, B, C, and D, going in the \nclockwise direction.\na. What is the maximum number of simultaneous connections that can be in \nprogress at any one time in this network?\nb. Suppose that all connections are between switches A and C. What is the \nmaximum number of simultaneous connections that can be in progress?\nc. Suppose we want to make four connections between switches A and C, \nand another four connections between switches B and D. Can we  \nroute these calls through the four links to accommodate all eight \n connections?\nPROBLEMS      99\n P5. Review the car-caravan analogy in Section 1.4. Assume a propagation speed \nof 100 km/hour.\na. Suppose the caravan travels 150 km, beginning in front of one tollbooth, \npassing through a second tollbooth, and finishing just after a third toll-\nbooth. What is the end-to-end delay?\nb. Repeat (a), now assuming that there are eight cars in the caravan instead \nof ten.\n P6. This elementary problem begins to explore propagation delay and transmis-\nsion delay, two central concepts in data networking. Consider two hosts, A \nand B, connected by a single link of rate R bps. Suppose that the two hosts \nare separated by m meters, and suppose the propagation speed along the link \nis s meters/sec. Host A is to send a packet of size L bits to Host B.\na. Express the propagation delay,  dprop, in terms of m and s.\nb. Determine the transmission time of the packet,  dtrans, in terms of L and R.\nc. Ignoring processing and queuing delays, obtain an expression for the end-\nto-end delay.\nd. Suppose Host A begins to transmit the packet at time t = 0. At time t = \n dtrans, where is the last bit of the packet?\ne. Suppose  dprop is greater than  dtrans. At time  t=dtrans, where is the first \nbit of the packet?\nf. Suppose  dprop is less than  dtrans. At time t=dtrans, where is the first bit of \nthe packet?\ng. Suppose s=2.5#108, L=120 bits , and R=56 kbps.  Find the distance \nm so that  dprop equals  dtrans.\n P7. In this problem, we consider sending real-time voice from Host A to Host B \nover a packet-switched network (VoIP). Host A converts analog voice to a \ndigital 64 kbps bit stream on the fly. Host A then groups the bits into 56-byte \npackets.", "doc_id": "0038fcb3-eae5-4c1e-9b43-d8128598e6da", "embedding": null, "doc_hash": "1eb1549cdd809b34cb826b74cbeea842c268047ea8c449317788c4c41d511e91", "extra_info": null, "node_info": {"start": 280929, "end": 284517}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "f4c46dc6-91ad-4562-969d-3ceab4817eb5", "3": "baea3c86-272a-480f-8f90-fe50cd8d977d"}}, "__type__": "1"}, "baea3c86-272a-480f-8f90-fe50cd8d977d": {"__data__": {"text": "= 0. At time t = \n dtrans, where is the last bit of the packet?\ne. Suppose  dprop is greater than  dtrans. At time  t=dtrans, where is the first \nbit of the packet?\nf. Suppose  dprop is less than  dtrans. At time t=dtrans, where is the first bit of \nthe packet?\ng. Suppose s=2.5#108, L=120 bits , and R=56 kbps.  Find the distance \nm so that  dprop equals  dtrans.\n P7. In this problem, we consider sending real-time voice from Host A to Host B \nover a packet-switched network (VoIP). Host A converts analog voice to a \ndigital 64 kbps bit stream on the fly. Host A then groups the bits into 56-byte \npackets. There is one link between Hosts A and B; its transmission rate is \n2 Mbps and its propagation delay is 10 msec. As soon as Host A gathers a \npacket, it sends it to Host B. As soon as Host B receives an entire packet, it \nconverts the packet\u2019s bits to an analog signal. How much time elapses from \nthe time a bit is created (from the original analog signal at Host A) until the \nbit is decoded (as part of the analog signal at Host B)?\n P8. Suppose users share a 3 Mbps link. Also suppose each user requires 150 kbps \nwhen transmitting, but each user transmits only 10 percent of the time. (See \nthe discussion of packet switching versus circuit switching in Section 1.3.)\na. When circuit switching is used, how many users can be supported?\nb. For the remainder of this problem, suppose packet switching is used. Find \nthe probability that a given user is transmitting.VideoNote\nExploring propagation \ndelay and transmission \ndelay\n100     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\nc. Suppose there are 120 users. Find the probability that at any given time, \nexactly n users are transmitting simultaneously. ( Hint: Use the binomial \ndistribution.)\nd. Find the probability that there are 21 or more users transmitting \n simultaneously.\n P9. Consider the discussion in Section 1.3 of packet switching versus circuit switch -\ning in which an example is provided with a 1 Mbps link. Users are generating \ndata at a rate of 100 kbps when busy, but are busy generating data only with \nprobability p=0.1. Suppose that the 1 Mbps link is replaced by a 1 Gbps link.\na. What is N, the maximum number of users that can be supported simulta-\nneously under circuit switching?\nb. Now consider packet switching and a user population of M users. Give a \nformula (in terms of p, M, N) for the probability that more than N users \nare sending data.\n P10. Consider the network illustrated in Figure 1.16. Assume the two hosts on the \nleft of the figure start transmitting packets of 1500 bytes at the same time \ntowards Router B. Suppose the link rates between the hosts and Router  \nA is 4-Mbps. One link has a 6-ms propagation delay and the other has a 2-ms \npropagation delay. Will queuing delay occur at Router A?\n P11. Consider the scenario in Problem P10 again, but now assume the links \nbetween the hosts and Router A have different rates R1 and R2 byte/s in \naddition to different propagation delays d1 and d2. Assume the packet lengths \nfor the two hosts are of L bytes. For what values of the propagation delay will \nno queuing delay occur at Router A?\n P12. Consider a client and a server connected through one router. Assume the router \ncan start transmitting an incoming packet after receiving its first h bytes instead \nof the whole packet. Suppose that the link rates are R byte/s and that the client \ntransmits one packet with a size of L bytes to the server. What is the end-to-end \ndelay? Assume the propagation, processing, and queuing", "doc_id": "baea3c86-272a-480f-8f90-fe50cd8d977d", "embedding": null, "doc_hash": "b48ffede3ad583a1f51d65b95df2a916603d611b1b803aba77f155e51dbbf0b1", "extra_info": null, "node_info": {"start": 284644, "end": 288199}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "0038fcb3-eae5-4c1e-9b43-d8128598e6da", "3": "0df5351b-918e-4775-a471-6ffcd4182ebf"}}, "__type__": "1"}, "0df5351b-918e-4775-a471-6ffcd4182ebf": {"__data__": {"text": "P11. Consider the scenario in Problem P10 again, but now assume the links \nbetween the hosts and Router A have different rates R1 and R2 byte/s in \naddition to different propagation delays d1 and d2. Assume the packet lengths \nfor the two hosts are of L bytes. For what values of the propagation delay will \nno queuing delay occur at Router A?\n P12. Consider a client and a server connected through one router. Assume the router \ncan start transmitting an incoming packet after receiving its first h bytes instead \nof the whole packet. Suppose that the link rates are R byte/s and that the client \ntransmits one packet with a size of L bytes to the server. What is the end-to-end \ndelay? Assume the propagation, processing, and queuing delays are negligible. \nGeneralize the previous result to a scenario where the client and the server are \ninterconnected by N routers.\n P13. (a)  Suppose N packets arrive simultaneously to a link at which no packets \nare currently being transmitted or queued. Each packet is of length L and \nthe link has transmission rate R. What is the average queuing delay for \nthe N packets?\nPROBLEMS      101\n(b) Now suppose that N such packets arrive to the link every LN/R  seconds. \nWhat is the average queuing delay of a packet?\n P14. Consider the queuing delay in a router buffer. Let I denote traffic intensity; \nthat is, I=La/R. Suppose that the queuing delay takes the form IL/R (1-I) \nfor I61.\na. Provide a formula for the total delay, that is, the queuing delay plus the \ntransmission delay.\nb. Plot the total delay as a function of L /R.\n P15. Let a denote the rate of packets arriving at a link in packets/sec, and let \u00b5 \ndenote the link\u2019s transmission rate in packets/sec. Based on the formula for \nthe total delay (i.e., the queuing delay plus the transmission delay) derived \nin the previous problem, derive a formula for the total delay in terms of a \nand \u00b5.\n P16. Consider a router buffer preceding an outbound link. In this problem, you \nwill use Little\u2019s formula, a famous formula from queuing theory. Let N \ndenote the average number of packets in the buffer plus the packet being \ntransmitted. Let a denote the rate of packets arriving at the link. Let d denote \nthe average total delay (i.e., the queuing delay plus the transmission delay) \nexperienced by a packet. Little\u2019s formula is N = a \u00b7 d. Suppose that on aver-\nage, the buffer contains 10 packets, and the average packet queuing delay \nis 10 msec. The link\u2019s transmission rate is 100 packets/sec. Using Little\u2019s \nformula, what is the average packet arrival rate, assuming there is no packet \nloss?\n P17. Consider the network illustrated in Figure 1.12. Would Equation 1.2 hold in \nsuch a scenario? If so, under which conditions? If not, why? (Assume N is the \nnumber of links between a source and a destination in the figure.)\n P18. Perform a Traceroute between source and destination on the same continent \nat three different hours of the day.\na. Find the average and standard deviation of the round-trip delays at each of \nthe three hours.\nb. Find the number of routers in the path at each of the three hours. Did the \npaths change during any of the hours?\nc. Try to identify the number of ISP networks that the Traceroute packets \npass through from source to destination. Routers with similar names and/\nor similar IP addresses should be considered as part of the same ISP. In \nyour experiments, do the largest delays occur at the peering interfaces \nbetween adjacent ISPs?\nd. Repeat the above for a source and destination on different continents. \nCompare the intra-continent and inter-continent results.VideoNote\nUsing Traceroute to \ndiscover network  \npaths and", "doc_id": "0df5351b-918e-4775-a471-6ffcd4182ebf", "embedding": null, "doc_hash": "170db5810bd00487a7c7d94f67d9daa3d55609fe21530bfa3b2f73cae3f13988", "extra_info": null, "node_info": {"start": 288083, "end": 291755}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "baea3c86-272a-480f-8f90-fe50cd8d977d", "3": "d9195d25-0b41-40f2-b155-8c86540fee66"}}, "__type__": "1"}, "d9195d25-0b41-40f2-b155-8c86540fee66": {"__data__": {"text": "the same continent \nat three different hours of the day.\na. Find the average and standard deviation of the round-trip delays at each of \nthe three hours.\nb. Find the number of routers in the path at each of the three hours. Did the \npaths change during any of the hours?\nc. Try to identify the number of ISP networks that the Traceroute packets \npass through from source to destination. Routers with similar names and/\nor similar IP addresses should be considered as part of the same ISP. In \nyour experiments, do the largest delays occur at the peering interfaces \nbetween adjacent ISPs?\nd. Repeat the above for a source and destination on different continents. \nCompare the intra-continent and inter-continent results.VideoNote\nUsing Traceroute to \ndiscover network  \npaths and measure \nnetwork delay\n102     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\n P19. (a)  Visit the site www.traceroute.org and perform traceroutes from two dif-\nferent cities in France to the same destination host in the United States. \nHow many links are the same in the two traceroutes? Is the transatlantic \nlink the same?\n(b)  Repeat (a) but this time choose one city in France and another city in \nGermany.\n(c)  Pick a city in the United States, and perform traceroutes to two hosts, \neach in a different city in China. How many links are common in \nthe two traceroutes? Do the two traceroutes diverge before reaching \nChina?\n P20. Consider the throughput example corresponding to Figure 1.20(b). Now \nsuppose that there are M client-server pairs rather than 10. Denote Rs, Rc, \nand R for the rates of the server links, client links, and network link. Assume \nall other links have abundant capacity and that there is no other traffic in the \nnetwork besides the traffic generated by the M client-server pairs. Derive a \ngeneral expression for throughput in terms of Rs, Rc, R, and M.\n P21. Assume a client and a server can connect through either network (a) or (b) in \nFigure 1.19. Assume that Ri 5 (Rc 1 Rs) / i, for i 5 1, 2, ..., N. In what case \nwill network (a) have a higher throughput than network (b)?\n P22. Consider Figure 1.19(b). Suppose that each link between the server and the \nclient has a packet loss probability p, and the packet loss probabilities for \nthese links are independent. What is the probability that a packet (sent by the \nserver) is successfully received by the receiver? If a packet is lost in the path \nfrom the server to the client, then the server will re-transmit the packet. On \naverage, how many times will the server re-transmit the packet in order for \nthe client to successfully receive the packet?\n P23. Consider Figure 1.19(a). Assume that we know the bottleneck link along the \npath from the server to the client is the first link with rate Rs bits/sec. Suppose \nwe send a pair of packets back to back from the server to the client, and there \nis no other traffic on this path. Assume each packet of size L bits, and both \nlinks have the same propagation delay  dprop.\na. What is the packet inter-arrival time at the destination? That is, how much \ntime elapses from when the last bit of the first packet arrives until the last \nbit of the second packet arrives?\nb. Now assume that the second link is the bottleneck link (i.e., Rc6Rs). Is \nit possible that the second packet queues at the input queue of the second \nlink? Explain. Now suppose that the server sends the second packet T \nseconds after sending the first packet. How large must T be to ensure no \nqueuing before the second link? Explain.\nPROBLEMS      103\n P24. Consider a user who needs to transmit 1.5 gigabytes of data to a server. The \nuser lives in a small town where only dial-up access is available. A bus", "doc_id": "d9195d25-0b41-40f2-b155-8c86540fee66", "embedding": null, "doc_hash": "26c1b1f44ed8d58e6a5834342839fb3be522ca21111ba76101bfd6969dcbf337", "extra_info": null, "node_info": {"start": 291707, "end": 295415}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "0df5351b-918e-4775-a471-6ffcd4182ebf", "3": "1134c719-c299-48d7-bd1d-17dae46639a4"}}, "__type__": "1"}, "1134c719-c299-48d7-bd1d-17dae46639a4": {"__data__": {"text": "What is the packet inter-arrival time at the destination? That is, how much \ntime elapses from when the last bit of the first packet arrives until the last \nbit of the second packet arrives?\nb. Now assume that the second link is the bottleneck link (i.e., Rc6Rs). Is \nit possible that the second packet queues at the input queue of the second \nlink? Explain. Now suppose that the server sends the second packet T \nseconds after sending the first packet. How large must T be to ensure no \nqueuing before the second link? Explain.\nPROBLEMS      103\n P24. Consider a user who needs to transmit 1.5 gigabytes of data to a server. The \nuser lives in a small town where only dial-up access is available. A bus visits \nthe small town once a day from the closest city, located 150 km away, and stops \nin front of the user\u2019s house. The bus has a 100-Mbps WiFi connection. It can \ncollect data from users in rural areas and transfer them to the Internet through a \n1 Gbps link once it gets back to the city. Suppose the average speed of the bus is \n60 km/h. What is the fastest way the user can transfer the data to the server?\n P25. Suppose two hosts, A and B, are separated by 20,000 kilometers and are con-\nnected by a direct link of R = 2 Mbps. Suppose the propagation speed over \nthe link is 2.5 #108 meters/sec.\na. Calculate the bandwidth-delay product, R # dprop.\nb. Consider sending a file of 800,000 bits from Host A to Host B. Suppose \nthe file is sent continuously as one large message. What is the maximum \nnumber of bits that will be in the link at any given time?\nc. Provide an interpretation of the bandwidth-delay product.\nd. What is the width (in meters) of a bit in the link? Is it longer than a \n football field?\ne. Derive a general expression for the width of a bit in terms of the propaga-\ntion speed s, the transmission rate R, and the length of the link m.\n P26. Consider problem P25 but now with a link of R 5 1 Gbps. \na. Calculate the bandwidth-delay product, R ? dprop.\nb. Consider sending a file of 800,000 bits from Host A to Host B. Suppose \nthe file is sent continuously as one big message. What is the maximum \nnumber of bits that will be in the link at any given time?\nc. What is the width (in meters) of a bit in the link?\n P27. Consider the scenario illustrated in Figure 1.19(a). Assume Rs is 20 Mbps, \nRc is 10 Mbps, and the server is continuously sending traffic to the client. \nAlso assume the router between the server and the client can buffer at most \nfour\u00a0messages. After how many messages sent by the server will packet loss \nstarts occurring at the router?\n P28. Generalize the result obtained in Problem P27 for the case where the router \ncan buffer m messages.\n P29. Suppose there is a 10-Mbps microwave link between a geostationary satellite \nand its base station on Earth. Every minute the satellite takes a digital photo and \nsends it to the base station. Assume a propagation speed of 2.4 #108 meters/sec.\na. What is the propagation delay of the link?\nb. What is the bandwidth-delay product, R # dprop?\nc. Let x denote the size of the photo. What is the minimum value of x for the \nmicrowave link to be continuously transmitting?\n104     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\n P30. Consider the airline travel analogy in our discussion of layering in Section 1.5, \nand the addition of headers to protocol data units as they flow down the proto -\ncol stack. Is there an equivalent notion of header information that is added to \npassengers and baggage as they move down the airline protocol stack?\n P31. In modern packet-switched networks, including the Internet, the source host", "doc_id": "1134c719-c299-48d7-bd1d-17dae46639a4", "embedding": null, "doc_hash": "7fb6dffe26ab066e4c908785dfcc006dfbdd92e63671c5d00898833a616d9819", "extra_info": null, "node_info": {"start": 295498, "end": 299129}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "d9195d25-0b41-40f2-b155-8c86540fee66", "3": "fff2b8b2-ae55-4a9a-bfa6-a21ee2f77ebc"}}, "__type__": "1"}, "fff2b8b2-ae55-4a9a-bfa6-a21ee2f77ebc": {"__data__": {"text": "#108 meters/sec.\na. What is the propagation delay of the link?\nb. What is the bandwidth-delay product, R # dprop?\nc. Let x denote the size of the photo. What is the minimum value of x for the \nmicrowave link to be continuously transmitting?\n104     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\n P30. Consider the airline travel analogy in our discussion of layering in Section 1.5, \nand the addition of headers to protocol data units as they flow down the proto -\ncol stack. Is there an equivalent notion of header information that is added to \npassengers and baggage as they move down the airline protocol stack?\n P31. In modern packet-switched networks, including the Internet, the source host \nsegments long, application-layer messages (for example, an image or a music \nfile) into smaller packets and sends the packets into the network. The receiver \nthen reassembles the packets back into the original message. We refer to \nthis process as message  segmentation . Figure 1.27 illustrates the end-to-end \ntransport of a message with and without message segmentation. Consider a \nmessage that is 8 #106 bits long that is to be sent from source to destination \nin Figure 1.27. Suppose each link in the figure is 2 Mbps. Ignore propagation, \nqueuing, and processing delays.\na. Consider sending the message from source to destination without  message \nsegmentation. How long does it take to move the message from the source \nhost to the first packet switch? Keeping in mind that each switch uses \nstore-and-forward packet switching, what is the total time to move the \nmessage from source host to destination host?\nb. Now suppose that the message is segmented into 800 packets, with each \npacket being 10,000 bits long. How long does it take to move the first \npacket from source host to the first switch? When the first packet is being \nsent from the first switch to the second switch, the second packet is being \nsent from the source host to the first switch. At what time will the second \npacket be fully received at the first switch?\nc. How long does it take to move the file from source host to destination \nhost when message segmentation is used? Compare this result with your \nanswer in part (a) and comment.\nFigure 1.27  \u2666   End-to-end message transport: (a) without message \n segmentation; (b) with message segmentationSource a. Packet switch Packet switch DestinationMessage\nSource b. Packet switchPacket\nPacket switch Destination\nWIRESHARK LAB      105\nd. In addition to reducing delay, what are reasons to use message \n segmentation?\ne. Discuss the drawbacks of message segmentation.\n P32. Consider Problem P31 and assume that the propagation delay is 250 ms. Recal -\nculate the total time needed to transfer the source data with and without segmen -\ntation. Is segmentation more beneficial or less if there is propagation delay?\n P33. Consider sending a large file of F bits from Host A to Host B. There are three \nlinks (and two switches) between A and B, and the links are uncongested \n(that is, no queuing delays). Host A segments the file into segments of S bits \neach and adds 80 bits of header to each segment, forming packets of L = 80 \n+ S bits. Each link has a transmission rate of R bps. Find the value of S that \nminimizes the delay of moving the file from Host A to Host B. Disregard \npropagation delay.\n P34. Early versions of TCP combined functions for both forwarding and reliable \ndelivery. How are these TCP variants located in the ISO/OSI protocol stack? \nWhy were forwarding functions later separated from TCP? What were the \nconsequences?\nWireshark Lab\n\u201cTell me and I forget. Show me and I remember. Involve me and I understand. \u201d\nChinese proverb\nOne\u2019s understanding of network protocols can often be greatly deepened by seeing \nthem in action and by playing around with them\u2014observing the sequence of mes", "doc_id": "fff2b8b2-ae55-4a9a-bfa6-a21ee2f77ebc", "embedding": null, "doc_hash": "ef3628aca5267f4d4a12662913a466f591b18bafe1071fa8dddabe2af4a1a22e", "extra_info": null, "node_info": {"start": 299121, "end": 302966}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "1134c719-c299-48d7-bd1d-17dae46639a4", "3": "3f8555fc-1beb-45b2-ac52-ff6aa57d8928"}}, "__type__": "1"}, "3f8555fc-1beb-45b2-ac52-ff6aa57d8928": {"__data__": {"text": "header to each segment, forming packets of L = 80 \n+ S bits. Each link has a transmission rate of R bps. Find the value of S that \nminimizes the delay of moving the file from Host A to Host B. Disregard \npropagation delay.\n P34. Early versions of TCP combined functions for both forwarding and reliable \ndelivery. How are these TCP variants located in the ISO/OSI protocol stack? \nWhy were forwarding functions later separated from TCP? What were the \nconsequences?\nWireshark Lab\n\u201cTell me and I forget. Show me and I remember. Involve me and I understand. \u201d\nChinese proverb\nOne\u2019s understanding of network protocols can often be greatly deepened by seeing \nthem in action and by playing around with them\u2014observing the sequence of mes -\nsages exchanged between two protocol entities, delving into the details of protocol \noperation, causing protocols to perform certain actions, and observing these actions \nand their consequences. This can be done in simulated scenarios or in a real net -\nwork environment such as the Internet. The Java applets at the textbook Web site \ntake the first approach. In the Wireshark labs, we\u2019ll take the latter approach. You\u2019ll \nrun network applications in various scenarios using a computer on your desk, at \nhome, or in a lab. You\u2019ll observe the network protocols in your computer, interacting \nand exchanging messages with protocol entities executing elsewhere in the Inter -\nnet. Thus, you and your computer will be an integral part of these live labs. You\u2019ll \nobserve\u2014and you\u2019ll learn\u2014by doing.\nThe basic tool for observing the messages exchanged between executing pro -\ntocol entities is called a packet sniffer . As the name suggests, a packet sniffer pas -\nsively copies (sniffs) messages being sent from and received by your computer; it \nalso displays the contents of the various protocol fields of these captured messages. \nA screenshot of the Wireshark packet sniffer is shown in Figure 1.28. Wireshark \nis a free packet sniffer that runs on Windows, Linux/Unix, and Mac computers. \n106     CHAPTER 1 \u2002\u2002\u2022 \u2002\u2002 COMPUTER NETWORKS AND THE INTERNET\nThroughout the textbook, you will find Wireshark labs that allow you to explore \na number of the protocols studied in the chapter. In this first Wireshark lab, you\u2019ll \nobtain and install a copy of Wireshark, access a Web site, and capture and examine \nthe protocol messages being exchanged between your Web browser and the Web \nserver.\nYou can find full details about this first Wireshark lab (including instructions about \nhow to obtain and install Wireshark) at the Web site http://www.pearsonglobaleditions  \n.com/kurose.Figure 1.28  \u2666   A Wireshark screenshot (Wireshark screenshot reprinted  \nby permission of the Wireshark Foundation.)Command\nmenus\nListing  of\ncaptured\npackets\nDetails  of\nselected\npacket\nheader\nPacket\ncontents  in\nhexadecimal\nand ASCII\n\n107What made you decide to specialize in networking/Internet technology?\nAs a PhD student at MIT in 1959, I looked around and found that most of my classmates \nwere doing research in the area of information theory and coding theory. At MIT, there was \nthe great researcher, Claude Shannon, who had launched these fields and had solved most \nof the important problems already. The research problems that were left were hard and of \nlesser consequence. So I decided to launch out in a new area that no one else had yet con -\nceived of. Remember that at MIT I was surrounded by lots of computers, and it was clear to \nme that soon these machines would need to communicate with each other. At the time, there \nwas no effective way for them to do so, so I decided to develop the technology that would \npermit efficient and reliable data networks to be", "doc_id": "3f8555fc-1beb-45b2-ac52-ff6aa57d8928", "embedding": null, "doc_hash": "b5382f8bc3eab0810dc61955e3f1d9cd28f279cc49f5f64b5c52b3a7d636f6d7", "extra_info": null, "node_info": {"start": 302939, "end": 306632}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "fff2b8b2-ae55-4a9a-bfa6-a21ee2f77ebc", "3": "b41ee02e-c3c0-4b46-b4f8-9d834b8195bf"}}, "__type__": "1"}, "b41ee02e-c3c0-4b46-b4f8-9d834b8195bf": {"__data__": {"text": "in networking/Internet technology?\nAs a PhD student at MIT in 1959, I looked around and found that most of my classmates \nwere doing research in the area of information theory and coding theory. At MIT, there was \nthe great researcher, Claude Shannon, who had launched these fields and had solved most \nof the important problems already. The research problems that were left were hard and of \nlesser consequence. So I decided to launch out in a new area that no one else had yet con -\nceived of. Remember that at MIT I was surrounded by lots of computers, and it was clear to \nme that soon these machines would need to communicate with each other. At the time, there \nwas no effective way for them to do so, so I decided to develop the technology that would \npermit efficient and reliable data networks to be created.\nWhat was your first job in the computer industry? What did it entail?\nI went to the evening session at CCNY from 1951 to 1957 for my bachelor\u2019s degree \nin electrical engineering. During the day, I worked first as a technician and then as an \nengineer at a small, industrial electronics firm called Photobell. While there, I introduced \ndigital technology to their product line. Essentially, we were using photoelectric devices \nto detect the presence of certain items (boxes, people, etc.) and the use of a circuit known \nthen as a bistable  multivibrator  was just the kind of technology we needed to bring \ndigital processing into this field of detection. These circuits happen to be the building \nblocks for computers, and have come to be known as flip-flops  or switches  in today\u2019s \nvernacular.\nWhat was going through your mind when you sent the first host-to-host message (from \nUCLA to the Stanford Research Institute)?\nFrankly, we had no idea of the importance of that event. We had not prepared a special \nmessage of historic significance, as did so many inventors of the past (Samuel Morse with \n\u201cWhat hath God wrought.\u201d or Alexander Graham Bell with \u201cWatson, come here! I want \nyou.\u201d or Neal Amstrong with \u201cThat\u2019s one small step for a man, one giant leap for mankind.\u201d)  \nThose guys were smart ! They understood media and public relations. All we wanted to do \nwas to login to the SRI computer. So we typed the \u201cL\u201d, which was correctly received, we \ntyped the \u201co\u201d which was received, and then we typed the \u201cg\u201d which caused the SRI host Leonard Kleinrock\nLeonard Kleinrock is a professor of computer science at the University \nof California, Los Angeles. In 1969, his computer at UCLA became \nthe first node of the Internet. His creation of packet-switching prin -\nciples in 1961 became the technology behind the Internet. He \nreceived his B.E.E. from the City College of New York (CCNY) and \nhis masters and PhD in electrical engineering from MIT.AN INTERVIEW WITH\u2026\n\n108computer to crash! So, it turned out that our message was the shortest and perhaps the most \nprophetic message ever, namely \u201cLo!\u201d as in \u201cLo and behold!\u201d\nEarlier that year, I was quoted in a UCLA press release saying that once the network \nwas up and running, it would be possible to gain access to computer utilities from our \nhomes and offices as easily as we gain access to electricity and telephone connectivity. So \nmy vision at that time was that the Internet would be ubiquitous, always on, always avail -\nable, anyone with any device could connect from any location, and it would be invisible. \nHowever, I never anticipated that my 99-year-old mother would use the Internet\u2014and \nindeed she did!\nWhat is your vision for the future of networking?\nThe easy part of the vision is to predict the infrastructure itself. I anticipate that we see con -\nsiderable deployment of nomadic computing, mobile devices, and smart spaces. Indeed, the \navailability of lightweight, inexpensive, high-performance, portable computing, and com -\nmunication devices (plus the ubiquity of the Internet) has enabled us", "doc_id": "b41ee02e-c3c0-4b46-b4f8-9d834b8195bf", "embedding": null, "doc_hash": "222ceadf14ffa5abab05a8a10337d40f6be83303a3632a7fa1fd3e569e079f1d", "extra_info": null, "node_info": {"start": 306580, "end": 310480}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "3f8555fc-1beb-45b2-ac52-ff6aa57d8928", "3": "003f90ab-0657-4e5e-9672-253174157aca"}}, "__type__": "1"}, "003f90ab-0657-4e5e-9672-253174157aca": {"__data__": {"text": "to computer utilities from our \nhomes and offices as easily as we gain access to electricity and telephone connectivity. So \nmy vision at that time was that the Internet would be ubiquitous, always on, always avail -\nable, anyone with any device could connect from any location, and it would be invisible. \nHowever, I never anticipated that my 99-year-old mother would use the Internet\u2014and \nindeed she did!\nWhat is your vision for the future of networking?\nThe easy part of the vision is to predict the infrastructure itself. I anticipate that we see con -\nsiderable deployment of nomadic computing, mobile devices, and smart spaces. Indeed, the \navailability of lightweight, inexpensive, high-performance, portable computing, and com -\nmunication devices (plus the ubiquity of the Internet) has enabled us to become nomads. \nNomadic computing refers to the technology that enables end users who travel from place to \nplace to gain access to Internet services in a transparent fashion, no matter where they travel \nand no matter what device they carry or gain access to. The harder part of the vision is to \npredict the applications and services, which have consistently surprised us in dramatic ways \n(e-mail, search technologies, the World Wide Web, blogs, social networks, user generation, \nand sharing of music, photos, and videos, etc.). We are on the verge of a new class of sur -\nprising and innovative mobile applications delivered to our hand-held devices.\nThe next step will enable us to move out from the netherworld of cyberspace to the \nphysical world of smart spaces. Our environments (desks, walls, vehicles, watches, belts, \nand so on) will come alive with technology, through actuators, sensors, logic, processing, \nstorage, cameras, microphones, speakers, displays, and communication. This embedded \ntechnology will allow our environment to provide the IP services we want. When I walk \ninto a room, the room will know I entered. I will be able to communicate with my environ -\nment naturally, as in spoken English; my requests will generate replies that present Web \npages to me from wall displays, through my eyeglasses, as speech, holograms, and so forth.\nLooking a bit further out, I see a networking future that includes the following addi -\ntional key components. I see intelligent software agents deployed across the network whose \nfunction it is to mine data, act on that data, observe trends, and carry out tasks dynamically \nand adaptively. I see considerably more network traffic generated not so much by humans, \nbut by these embedded devices and these intelligent software agents. I see large collec -\ntions of self-organizing systems controlling this vast, fast network. I see huge amounts of \ninformation flashing across this network instantaneously with this information undergoing \nenormous processing and filtering. The Internet will essentially be a pervasive global nerv -\nous system. I see all these things and more as we move headlong through the twenty-first \ncentury.\n109What people have inspired you professionally?\nBy far, it was Claude Shannon from MIT, a brilliant researcher who had the ability to relate \nhis mathematical ideas to the physical world in highly intuitive ways. He was on my PhD \nthesis committee.\nDo you have any advice for students entering the networking/Internet field?\nThe Internet and all that it enables is a vast new frontier, full of amazing challenges. There \nis room for great innovation. Don\u2019t be constrained by today\u2019s technology. Reach out and \nimagine what could be and then make it happen.\nThis page intentionally left blank\n111Network applications are the raisons d\u2019\u00eatre  of a computer network\u2014if we couldn\u2019t  \nconceive of any useful applications, there wouldn\u2019t be any need for networking infra -\nstructure and protocols to support them. Since the Internet\u2019s inception, numerous useful \nand entertaining applications have indeed been created. These applications have been the \ndriving force behind the Internet\u2019s success, motivating people in homes,", "doc_id": "003f90ab-0657-4e5e-9672-253174157aca", "embedding": null, "doc_hash": "5b54377a04a7f3a8f86f98a81d282b233219f5721fdd3511fc2b1009628fec76", "extra_info": null, "node_info": {"start": 310462, "end": 314491}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "b41ee02e-c3c0-4b46-b4f8-9d834b8195bf", "3": "175501a3-51f3-4057-a506-3e7e3f9e5d28"}}, "__type__": "1"}, "175501a3-51f3-4057-a506-3e7e3f9e5d28": {"__data__": {"text": "entering the networking/Internet field?\nThe Internet and all that it enables is a vast new frontier, full of amazing challenges. There \nis room for great innovation. Don\u2019t be constrained by today\u2019s technology. Reach out and \nimagine what could be and then make it happen.\nThis page intentionally left blank\n111Network applications are the raisons d\u2019\u00eatre  of a computer network\u2014if we couldn\u2019t  \nconceive of any useful applications, there wouldn\u2019t be any need for networking infra -\nstructure and protocols to support them. Since the Internet\u2019s inception, numerous useful \nand entertaining applications have indeed been created. These applications have been the \ndriving force behind the Internet\u2019s success, motivating people in homes, schools, govern -\nments, and businesses to make the Internet an integral part of their daily activities.\nInternet applications include the classic text-based applications that became pop -\nular in the 1970s and 1980s: text e-mail, remote access to computers, file transfers, and  \nnewsgroups. They include the killer application of the mid-1990s, the World Wide \nWeb, encompassing Web surfing, search, and electronic commerce. They include \ninstant messaging and P2P file sharing, the two killer applications introduced at the \nend of the millennium. In the new millennium, new and highly compelling applica -\ntions continue to emerge, including voice over IP and video conferencing such as \nSkype, Facetime, and Google Hangouts; user generated video such as YouTube and \nmovies on demand such as Netflix; multiplayer online games such as Second Life \nand World of Warcraft. During this same period, we have seen the emergence of a \nnew generation of social networking applications\u2014such as Facebook, Instagram, \nTwitter, and WeChat\u2014which have created engaging human networks on top of the \nInternet\u2019s network or routers and communication links. And most recently, along \nwith the arrival of the smartphone, there has been a profusion of location based \nmobile apps, including popular check-in, dating, and road-traffic forecasting apps \n(such as Yelp, Tinder, Waz, and Yik Yak). Clearly, there has been no slowing down \nof new and exciting Internet applications. Perhaps some of the readers of this text \nwill create the next generation of killer Internet applications!2CHAPTER\nApplication \nLayer\n\n112     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nIn this chapter we study the conceptual and implementation aspects of network \napplications. We begin by defining key application-layer concepts, including net -\nwork services required by applications, clients and servers, processes, and transport-\nlayer interfaces. We examine several network applications in detail, including the Web, \ne-mail, DNS, peer-to-peer (P2P) file distribution, and video streaming. (Chapter 9  will \nfurther examine multimedia applications, including streaming video and VoIP.) We \nthen cover network application development, over both TCP and UDP. In particular, \nwe study the socket interface and walk through some simple client-server applica -\ntions in Python. We also provide several fun and interesting socket programming \nassignments at the end of the chapter.\nThe application layer is a particularly good place to start our study of protocols. \nIt\u2019s familiar ground. We\u2019re acquainted with many of the applications that rely on \nthe protocols we\u2019ll study. It will give us a good feel for what protocols are all about \nand will introduce us to many of the same issues that we\u2019ll see again when we study \ntransport, network, and link layer protocols.\n2.1 Principles of Network Applications\nSuppose you have an idea for a new network application. Perhaps this application \nwill be a great service to humanity, or will please your professor, or will bring you \ngreat wealth, or will simply be fun to develop. Whatever the motivation may be, let\u2019s \nnow examine how you transform the idea into a real-world network application.\nAt the core of network application development is writing programs that run on", "doc_id": "175501a3-51f3-4057-a506-3e7e3f9e5d28", "embedding": null, "doc_hash": "5e75cf11286ec89eb63756cb9c777f1e54495f55a83c50cad7053571829648de", "extra_info": null, "node_info": {"start": 314549, "end": 318559}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "003f90ab-0657-4e5e-9672-253174157aca", "3": "1a36bbb8-7a17-427a-9076-deb36cd9e4dc"}}, "__type__": "1"}, "1a36bbb8-7a17-427a-9076-deb36cd9e4dc": {"__data__": {"text": "place to start our study of protocols. \nIt\u2019s familiar ground. We\u2019re acquainted with many of the applications that rely on \nthe protocols we\u2019ll study. It will give us a good feel for what protocols are all about \nand will introduce us to many of the same issues that we\u2019ll see again when we study \ntransport, network, and link layer protocols.\n2.1 Principles of Network Applications\nSuppose you have an idea for a new network application. Perhaps this application \nwill be a great service to humanity, or will please your professor, or will bring you \ngreat wealth, or will simply be fun to develop. Whatever the motivation may be, let\u2019s \nnow examine how you transform the idea into a real-world network application.\nAt the core of network application development is writing programs that run on \ndifferent end systems and communicate with each other over the network. For exam -\nple, in the Web application there are two distinct programs that communicate with \neach other: the browser program running in the user\u2019s host (desktop, laptop, tablet, \nsmartphone, and so on); and the Web server program running in the Web server host. \nAs another example, in a P2P file-sharing system there is a program in each host that \nparticipates in the file-sharing community. In this case, the programs in the various \nhosts may be similar or identical.\nThus, when developing your new application, you need to write software that \nwill run on multiple end systems. This software could be written, for example, in \nC, Java, or Python. Importantly, you do not need to write software that runs on net -\nwork-core devices, such as routers or link-layer switches. Even if you wanted to \nwrite application software for these network-core devices, you wouldn\u2019t be able to \ndo so. As we learned in Chapter 1, and as shown earlier in Figure 1.24, network-core  \ndevices do not function at the application layer but instead function at lower layers\u2014\nspecifically at the network layer and below. This basic design\u2014namely, confining \napplication software to the end systems\u2014as shown in Figure 2.1, has facilitated the \nrapid development and deployment of a vast array of network applications.\n2.1  \u2022  PRINCIPLES OF NETWORK APPLICATIONS      113\nNational or\nGlobal ISP\nMobile Network\nLocal or\nRegional ISP\nEnterprise NetworkHome Network\nTransport\nNetwork\nLink\nPhysicalApplicationTransport\nNetwork\nLinkApplication\nPhysical\nTransport\nNetwork\nLink\nPhysicalApplication\nFigure 2.1  \u2666  Communication for a network application takes place  \nbetween end systems at the application layer\n114     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\n2.1.1  Network Application Architectures\nBefore diving into software coding, you should have a broad architectural plan for \nyour application. Keep in mind that an application\u2019s architecture is distinctly differ -\nent from the network architecture (e.g., the five-layer Internet architecture discussed \nin Chapter 1 ). From the application developer\u2019s perspective, the network architec -\nture is fixed and provides a specific set of services to applications. The application  \narchitecture , on the other hand, is designed by the application developer and dic -\ntates how the application is structured over the various end systems. In choosing \nthe application architecture, an application developer will likely draw on one of the \ntwo predominant architectural paradigms used in modern network applications: the \nclient-server architecture or the peer-to-peer (P2P) architecture.\nIn a client-server architecture , there is an always-on host, called the server , \nwhich services requests from many other hosts, called clients . A classic example \nis the Web application for which an always-on Web server services requests from \nbrowsers running on client hosts. When a Web server receives a request for an object \nfrom a client host, it responds by sending the requested object to the client host. \nNote that with the client-server architecture, clients do not directly communicate \nwith each other; for example, in the Web application, two", "doc_id": "1a36bbb8-7a17-427a-9076-deb36cd9e4dc", "embedding": null, "doc_hash": "4989e304bf60005657e3cab786bc04837b7c2bcf3fcca4e6c7754c098b64c143", "extra_info": null, "node_info": {"start": 318523, "end": 322559}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "175501a3-51f3-4057-a506-3e7e3f9e5d28", "3": "66946692-6537-44f6-a66f-a4dda36ccc67"}}, "__type__": "1"}, "66946692-6537-44f6-a66f-a4dda36ccc67": {"__data__": {"text": "In choosing \nthe application architecture, an application developer will likely draw on one of the \ntwo predominant architectural paradigms used in modern network applications: the \nclient-server architecture or the peer-to-peer (P2P) architecture.\nIn a client-server architecture , there is an always-on host, called the server , \nwhich services requests from many other hosts, called clients . A classic example \nis the Web application for which an always-on Web server services requests from \nbrowsers running on client hosts. When a Web server receives a request for an object \nfrom a client host, it responds by sending the requested object to the client host. \nNote that with the client-server architecture, clients do not directly communicate \nwith each other; for example, in the Web application, two browsers do not directly \ncommunicate. Another characteristic of the client-server architecture is that the \nserver has a fixed, well-known address, called an IP address (which we\u2019ll discuss \nsoon). Because the server has a fixed, well-known address, and because the server is \nalways on, a client can always contact the server by sending a packet to the server\u2019s \nIP address. Some of the better-known applications with a client-server architecture \ninclude the Web, FTP, Telnet, and e-mail. The client-server architecture is shown in \nFigure 2.2(a).\nOften in a client-server application, a single-server host is incapable of keep -\ning up with all the requests from clients. For example, a popular social-networking \nsite can quickly become overwhelmed if it has only one server handling all of its \nrequests. For this reason, a data center , housing a large number of hosts, is often \nused to create a powerful virtual server. The most popular Internet services\u2014such as \nsearch engines (e.g., Google, Bing, Baidu), Internet commerce (e.g., Amazon, eBay, \nAlibaba), Web-based e-mail (e.g., Gmail and Yahoo Mail), social networking (e.g., \nFacebook, Instagram, Twitter, and WeChat)\u2014employ one or more data centers. As \ndiscussed in Section 1.3.3, Google has 30 to 50 data centers distributed around the \nworld, which collectively handle search, YouTube, Gmail, and other services. A \ndata center can have hundreds of thousands of servers, which must be powered and \nmaintained. Additionally, the service providers must pay recurring interconnection \nand bandwidth costs for sending data from their data centers.\nIn a P2P architecture , there is minimal (or no) reliance on dedicated servers in \ndata centers. Instead the application exploits direct communication between pairs of \nintermittently connected hosts, called peers . The peers are not owned by the service \nprovider, but are instead desktops and laptops controlled by users, with most of the \n2.1  \u2022  PRINCIPLES OF NETWORK APPLICATIONS      115\npeers residing in homes, universities, and offices. Because the peers communicate \nwithout passing through a dedicated server, the architecture is called peer-to-peer. \nMany of today\u2019s most popular and traffic-intensive applications are based on P2P \narchitectures. These applications include file sharing (e.g., BitTorrent), peer-assisted \ndownload acceleration (e.g., Xunlei), and Internet telephony and video conference \n(e.g., Skype). The P2P architecture is illustrated in Figure 2.2(b). We mention that \nsome applications have hybrid architectures, combining both client-server and P2P \nelements. For example, for many instant messaging applications, servers are used to \ntrack the IP addresses of users, but user-to-user messages are sent directly between \nuser hosts (without passing through intermediate servers).\nOne of the most compelling features of P2P architectures is their self- \nscalability . For example, in a P2P file-sharing application, although each peer gener -\nates workload by requesting files, each peer also adds service capacity to the system \nby distributing files to", "doc_id": "66946692-6537-44f6-a66f-a4dda36ccc67", "embedding": null, "doc_hash": "de7a2a47d0262fe73758828e81cf761dda810e7ca7cabfb424ec87b7c65598a1", "extra_info": null, "node_info": {"start": 322537, "end": 326448}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "1a36bbb8-7a17-427a-9076-deb36cd9e4dc", "3": "b4ccbf3f-1ce6-422c-ab7d-9399e77fe42f"}}, "__type__": "1"}, "b4ccbf3f-1ce6-422c-ab7d-9399e77fe42f": {"__data__": {"text": "acceleration (e.g., Xunlei), and Internet telephony and video conference \n(e.g., Skype). The P2P architecture is illustrated in Figure 2.2(b). We mention that \nsome applications have hybrid architectures, combining both client-server and P2P \nelements. For example, for many instant messaging applications, servers are used to \ntrack the IP addresses of users, but user-to-user messages are sent directly between \nuser hosts (without passing through intermediate servers).\nOne of the most compelling features of P2P architectures is their self- \nscalability . For example, in a P2P file-sharing application, although each peer gener -\nates workload by requesting files, each peer also adds service capacity to the system \nby distributing files to other peers. P2P architectures are also cost effective, since \nthey normally don\u2019t require significant server infrastructure and server bandwidth a. Client-server ar chitectur e b. Peer-to-peer ar chitectur e\nFigure 2.2  \u2666 (a) Client-server architecture; (b) P2P architecture\n116     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\n(in contrast with clients-server designs with datacenters). However, P2P applica -\ntions face challenges of security, performance, and reliability due to their highly  \ndecentralized structure.\n2.1.2  Processes Communicating\nBefore building your network application, you also need a basic understanding of \nhow the programs, running in multiple end systems, communicate with each other. \nIn the jargon of operating systems, it is not actually programs but processes  that \ncommunicate. A process can be thought of as a program that is running within an end \nsystem. When processes are running on the same end system, they can communicate \nwith each other with interprocess communication, using rules that are governed by \nthe end system\u2019s operating system. But in this book we are not particularly interested \nin how processes in the same host communicate, but instead in how processes run -\nning on different  hosts (with potentially different operating systems) communicate.\nProcesses on two different end systems communicate with each other by \nexchanging messages  across the computer network. A sending process creates and \nsends messages into the network; a receiving process receives these messages and \npossibly responds by sending messages back. Figure 2.1 illustrates that processes \ncommunicating with each other reside in the application layer of the five-layer pro -\ntocol stack.\nClient and Server Processes\nA network application consists of pairs of processes that send messages to each \nother over a network. For example, in the Web application a client browser process \nexchanges messages with a Web server process. In a P2P file-sharing system, a file \nis transferred from a process in one peer to a process in another peer. For each pair of \ncommunicating processes, we typically label one of the two processes as the client  and \nthe other process as the server . With the Web, a browser is a client process and a Web \nserver is a server process. With P2P file sharing, the peer that is downloading the file \nis labeled as the client, and the peer that is uploading the file is labeled as the server.\nYou may have observed that in some applications, such as in P2P file sharing, \na process can be both a client and a server. Indeed, a process in a P2P file-sharing \nsystem can both upload and download files. Nevertheless, in the context of any given \ncommunication session between a pair of processes, we can still label one process \nas the client and the other process as the server. We define the client and server pro -\ncesses as follows:\nIn the context of a communication session between a pair of processes, the pro -\ncess that initiates the communication (that is, initially contacts the other process \nat the beginning of the session) is labeled as the client . The process that waits to \nbe contacted to begin the session is the server .\n2.1  \u2022  PRINCIPLES OF NETWORK APPLICATIONS      117\nIn the Web, a browser process initializes contact with a Web server", "doc_id": "b4ccbf3f-1ce6-422c-ab7d-9399e77fe42f", "embedding": null, "doc_hash": "0ac238fbb4cfb2644f8ec31326952f9e2f16a8b7f4f8a06792280dc20ecfae04", "extra_info": null, "node_info": {"start": 326495, "end": 330546}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "66946692-6537-44f6-a66f-a4dda36ccc67", "3": "bac4a870-a4a4-478f-b20e-37d650d60e51"}}, "__type__": "1"}, "bac4a870-a4a4-478f-b20e-37d650d60e51": {"__data__": {"text": "in P2P file sharing, \na process can be both a client and a server. Indeed, a process in a P2P file-sharing \nsystem can both upload and download files. Nevertheless, in the context of any given \ncommunication session between a pair of processes, we can still label one process \nas the client and the other process as the server. We define the client and server pro -\ncesses as follows:\nIn the context of a communication session between a pair of processes, the pro -\ncess that initiates the communication (that is, initially contacts the other process \nat the beginning of the session) is labeled as the client . The process that waits to \nbe contacted to begin the session is the server .\n2.1  \u2022  PRINCIPLES OF NETWORK APPLICATIONS      117\nIn the Web, a browser process initializes contact with a Web server process; \nhence the browser process is the client and the Web server process is the server. In \nP2P file sharing, when Peer A asks Peer B to send a specific file, Peer A is the cli -\nent and Peer B is the server in the context of this specific communication session. \nWhen there\u2019s no confusion, we\u2019ll sometimes also use the terminology \u201cclient side \nand server side of an application.\u201d At the end of this chapter, we\u2019ll step through sim -\nple code for both the client and server sides of network applications.\nThe Interface Between the Process and the Computer Network\nAs noted above, most applications consist of pairs of communicating processes, with \nthe two processes in each pair sending messages to each other. Any message sent \nfrom one process to another must go through the underlying network. A process \nsends messages into, and receives messages from, the network through a software \ninterface called a socket . Let\u2019s consider an analogy to help us understand processes \nand sockets. A process is analogous to a house and its socket is analogous to its door. \nWhen a process wants to send a message to another process on another host, it shoves \nthe message out its door (socket). This sending process assumes that there is a trans -\nportation infrastructure on the other side of its door that will transport the message to \nthe door of the destination process. Once the message arrives at the destination host, \nthe message passes through the receiving process\u2019s door (socket), and the receiving \nprocess then acts on the message.\nFigure 2. 3 illustrates socket communication between two processes that com -\nmunicate over the Internet. (Figure 2.3 assumes that the underlying transport proto -\ncol used by the processes is the Internet\u2019s TCP protocol.) As shown in this figure, a \nsocket is the interface between the application layer and the transport layer within \na host. It is also referred to as the Application Programming Interface (API)  \nbetween the application and the network, since the socket is the programming inter -\nface with which network applications are built. The application developer has con -\ntrol of everything on the application-layer side of the socket but has little control of \nthe transport-layer side of the socket. The only control that the application developer \nhas on the transport-layer side is (1) the choice of transport protocol and (2) perhaps \nthe ability to fix a few transport-layer parameters such as maximum buffer and maxi -\nmum segment sizes (to be covered in Chapter 3 ). Once the application developer \nchooses a transport protocol (if a choice is available), the application is built using \nthe transport-layer services provided by that protocol. We\u2019ll explore sockets in some \ndetail in Section 2.7.\nAddressing Processes\nIn order to send postal mail to a particular destination, the destination needs to have \nan address. Similarly, in order for a process running on one host to send packets to \na process running on another host, the receiving process needs to have an address. \n118     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nTo identify the receiving process, two pieces of information need to be specified: (1) \nthe address of the host and (2) an identifier that specifies the receiving process in the \ndestination host.\nIn the Internet, the host is identified by its IP address . We\u2019ll", "doc_id": "bac4a870-a4a4-478f-b20e-37d650d60e51", "embedding": null, "doc_hash": "6a5aae6cb1e3484b6c0ef324af0b7c28e7356bcb1b8389a44c7e5424128bdc85", "extra_info": null, "node_info": {"start": 330523, "end": 334680}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "b4ccbf3f-1ce6-422c-ab7d-9399e77fe42f", "3": "6701fa1e-4cc0-4b8e-bcb6-98be9ac5b253"}}, "__type__": "1"}, "6701fa1e-4cc0-4b8e-bcb6-98be9ac5b253": {"__data__": {"text": "(if a choice is available), the application is built using \nthe transport-layer services provided by that protocol. We\u2019ll explore sockets in some \ndetail in Section 2.7.\nAddressing Processes\nIn order to send postal mail to a particular destination, the destination needs to have \nan address. Similarly, in order for a process running on one host to send packets to \na process running on another host, the receiving process needs to have an address. \n118     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nTo identify the receiving process, two pieces of information need to be specified: (1) \nthe address of the host and (2) an identifier that specifies the receiving process in the \ndestination host.\nIn the Internet, the host is identified by its IP address . We\u2019ll discuss IP addresses \nin great detail in Chapter 4. For now, all we need to know is that an IP address is a \n32-bit quantity that we can think of as uniquely identifying the host. In addition to \nknowing the address of the host to which a message is destined, the sending process \nmust also identify the receiving process (more specifically, the receiving socket) \nrunning in the host. This information is needed because in general a host could be \nrunning many network applications. A destination port number  serves this purpose. \nPopular applications have been assigned specific port numbers. For example, a Web \nserver is identified by port number 80. A mail server process (using the SMTP proto -\ncol) is identified by port number 25. A list of well-known port numbers for all Inter -\nnet standard protocols can be found at www.iana.org. We\u2019ll examine port numbers \nin detail in Chapter 3.\n2.1.3  Transport Services Available to Applications\nRecall that a socket is the interface between the application process and the trans -\nport-layer protocol. The application at the sending side pushes messages through the \nsocket. At the other side of the socket, the transport-layer protocol has the responsi -\nbility of getting the messages to the socket of the receiving process.\nMany networks, including the Internet, provide more than one transport-layer \nprotocol. When you develop an application, you must choose one of the available ProcessHost or\nserverHost or\nserver\nControlled\nby application\ndeveloperControlled\nby application\ndeveloperProcess\nTCP with\nbuffers,\nvariables InternetControlled\nby operating\nsystemControlled\nby operating\nsystemTCP with\nbuffers,\nvariablesSocket Socket\nFigure 2.3  \u2666  Application processes, sockets, and underlying transport  \nprotocol\n2.1  \u2022  PRINCIPLES OF NETWORK APPLICATIONS      119\ntransport-layer protocols. How do you make this choice? Most likely, you would \nstudy the services provided by the available transport-layer protocols, and then pick \nthe protocol with the services that best match your application\u2019s needs. The situation \nis similar to choosing either train or airplane transport for travel between two cities. \nYou have to choose one or the other, and each transportation mode offers different \nservices. (For example, the train offers downtown pickup and drop-off, whereas the \nplane offers shorter travel time.)\nWhat are the services that a transport-layer protocol can offer to applications \ninvoking it? We can broadly classify the possible services along four dimensions: \nreliable data transfer, throughput, timing, and security.\nReliable Data Transfer\nAs discussed in Chapter 1, packets can get lost within a computer network. For \nexample, a packet can overflow a buffer in a router, or can be discarded by a host or \nrouter after having some of its bits corrupted. For many applications\u2014such as elec -\ntronic mail, file transfer, remote host access, Web document transfers, and financial \napplications\u2014data loss can have devastating consequences (in the latter case, for \neither the bank or the customer!). Thus, to support these applications, something has \nto be done to guarantee that the data sent by one end of the application is delivered \ncorrectly and completely to the other end of the application. If a protocol provides", "doc_id": "6701fa1e-4cc0-4b8e-bcb6-98be9ac5b253", "embedding": null, "doc_hash": "dd56b662ca8e08609b62786cf7a6eb61deab511dd4a13d5000e80b8c8ba0c864", "extra_info": null, "node_info": {"start": 334715, "end": 338767}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "bac4a870-a4a4-478f-b20e-37d650d60e51", "3": "30018590-5c66-444c-bf2c-6021d644b552"}}, "__type__": "1"}, "30018590-5c66-444c-bf2c-6021d644b552": {"__data__": {"text": "the possible services along four dimensions: \nreliable data transfer, throughput, timing, and security.\nReliable Data Transfer\nAs discussed in Chapter 1, packets can get lost within a computer network. For \nexample, a packet can overflow a buffer in a router, or can be discarded by a host or \nrouter after having some of its bits corrupted. For many applications\u2014such as elec -\ntronic mail, file transfer, remote host access, Web document transfers, and financial \napplications\u2014data loss can have devastating consequences (in the latter case, for \neither the bank or the customer!). Thus, to support these applications, something has \nto be done to guarantee that the data sent by one end of the application is delivered \ncorrectly and completely to the other end of the application. If a protocol provides \nsuch a guaranteed data delivery service, it is said to provide reliable data transfer . \nOne important service that a transport-layer protocol can potentially provide to an \napplication is process-to-process reliable data transfer. When a transport protocol \nprovides this service, the sending process can just pass its data into the socket and \nknow with complete confidence that the data will arrive without errors at the receiv -\ning process.\nWhen a transport-layer protocol doesn\u2019t provide reliable data transfer, some of \nthe data sent by the sending process may never arrive at the receiving process. This \nmay be acceptable for loss-tolerant applications , most notably multimedia applica -\ntions such as conversational audio/video that can tolerate some amount of data loss. \nIn these multimedia applications, lost data might result in a small glitch in the audio/\nvideo\u2014not a crucial impairment.\nThroughput\nIn Chapter 1 we introduced the concept of available throughput, which, in the \ncontext of a communication session between two processes along a network path, \nis the rate at which the sending process can deliver bits to the receiving process. \nBecause other sessions will be sharing the bandwidth along the network path, and \nbecause these other sessions will be coming and going, the available throughput \ncan fluctuate with time. These observations lead to another natural service that a \ntransport-layer protocol could provide, namely, guaranteed available throughput at \n120     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nsome specified rate. With such a service, the application could request a guaranteed \nthroughput of r bits/sec, and the transport protocol would then ensure that the avail -\nable throughput is always at least r bits/sec. Such a guaranteed throughput service \nwould appeal to many applications. For example, if an Internet telephony applica -\ntion encodes voice at 32 kbps, it needs to send data into the network and have data \ndelivered to the receiving application at this rate. If the transport protocol cannot \nprovide this throughput, the application would need to encode at a lower rate (and \nreceive enough throughput to sustain this lower coding rate) or may have to give up, \nsince receiving, say, half of the needed throughput is of little or no use to this Inter -\nnet telephony application. Applications that have throughput requirements are said \nto be bandwidth-sensitive applications . Many current multimedia applications are \nbandwidth sensitive, although some multimedia applications may use adaptive cod -\ning techniques to encode digitized voice or video at a rate that matches the currently \navailable throughput.\nWhile bandwidth-sensitive applications have specific throughput requirements, \nelastic applications  can make use of as much, or as little, throughput as happens to \nbe available. Electronic mail, file transfer, and Web transfers are all elastic applica -\ntions. Of course, the more throughput, the better. There\u2019san adage that says that one \ncannot be too rich, too thin, or have too much throughput!\nTiming\nA transport-layer protocol can also provide timing guarantees. As with throughput \nguarantees, timing guarantees can come in many shapes and forms. An example \nguarantee might be that every bit that the sender pumps into the socket arrives at the", "doc_id": "30018590-5c66-444c-bf2c-6021d644b552", "embedding": null, "doc_hash": "3341ffd45fabafbc5d4ddf4f0fc3d0cd9aaf783aaaa16eae7a4f91341343860a", "extra_info": null, "node_info": {"start": 338717, "end": 342849}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "6701fa1e-4cc0-4b8e-bcb6-98be9ac5b253", "3": "e29e5397-96c3-4792-a3e1-7eff15a93804"}}, "__type__": "1"}, "e29e5397-96c3-4792-a3e1-7eff15a93804": {"__data__": {"text": "techniques to encode digitized voice or video at a rate that matches the currently \navailable throughput.\nWhile bandwidth-sensitive applications have specific throughput requirements, \nelastic applications  can make use of as much, or as little, throughput as happens to \nbe available. Electronic mail, file transfer, and Web transfers are all elastic applica -\ntions. Of course, the more throughput, the better. There\u2019san adage that says that one \ncannot be too rich, too thin, or have too much throughput!\nTiming\nA transport-layer protocol can also provide timing guarantees. As with throughput \nguarantees, timing guarantees can come in many shapes and forms. An example \nguarantee might be that every bit that the sender pumps into the socket arrives at the \nreceiver\u2019s socket no more than 100 msec later. Such a service would be appealing to \ninteractive real-time applications, such as Internet telephony, virtual environments, \nteleconferencing, and multiplayer games, all of which require tight timing constraints \non data delivery in order to be effective. ( See Chapter 9, [Gauthier 1999; Ramjee \n1994].) Long delays in Internet telephony, for example, tend to result in unnatural \npauses in the conversation; in a multiplayer game or virtual interactive environment, \na long delay between taking an action and seeing the response from the environment \n(for example, from another player at the end of an end-to-end connection) makes the \napplication feel less realistic. For non-real-time applications, lower delay is always \npreferable to higher delay, but no tight constraint is placed on the end-to-end delays.\nSecurity\nFinally, a transport protocol can provide an application with one or more security \nservices. For example, in the sending host, a transport protocol can encrypt all data \ntransmitted by the sending process, and in the receiving host, the transport-layer pro -\ntocol can decrypt the data before delivering the data to the receiving process. Such a \nservice would provide confidentiality between the two processes, even if the data is \n2.1  \u2022  PRINCIPLES OF NETWORK APPLICATIONS      121\nsomehow observed between sending and receiving processes. A transport protocol \ncan also provide other security services in addition to confidentiality, including data \nintegrity and end-point authentication, topics that we\u2019ll cover in detail in Chapter 8.\n2.1.4  Transport Services Provided by the Internet\nUp until this point, we have been considering transport services that a computer net -\nwork could  provide in general. Let\u2019s now get more specific and examine the type of \ntransport services provided by the Internet. The Internet (and, more generally, TCP/\nIP networks) makes two transport protocols available to applications, UDP and TCP. \nWhen you (as an application developer) create a new network application for the \nInternet, one of the first decisions you have to make is whether to use UDP or TCP. \nEach of these protocols offers a different set of services to the invoking applications. \nFigure 2.4 shows the service requirements for some selected applications.\nTCP Services\nThe TCP service model includes a connection-oriented service and a reliable data \ntransfer service. When an application invokes TCP as its transport protocol, the \napplication receives both of these services from TCP.\n\u2022 Connection-oriented service.  TCP has the client and server exchange transport-\nlayer control information with each other before  the application-level mes -\nsages begin to flow. This so-called handshaking procedure alerts the client \nand server, allowing them to prepare for an onslaught of packets. After the \nhandshaking phase, a TCP connection  is said to exist between the sockets \nApplication Data Loss Throughput Time-Sensitive\nFile transfer/download No loss Elastic No\nE-mail No loss Elastic No\nWeb documents No loss Elastic (few kbps )N o\nInternet telephony/\nVideo conferencingLoss-tolerant Audio: few kbps\u20131Mbps\nVideo: 10 kbps\u20135 MbpsYes: 100s of msec\nStreaming", "doc_id": "e29e5397-96c3-4792-a3e1-7eff15a93804", "embedding": null, "doc_hash": "3ea2f840fc88ea564bb24eec4287446224e99da0a78fe8eb7b3c8221c53b033b", "extra_info": null, "node_info": {"start": 342884, "end": 346885}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "30018590-5c66-444c-bf2c-6021d644b552", "3": "d8f05422-4f16-49a2-a2ad-a12023c5a8af"}}, "__type__": "1"}, "d8f05422-4f16-49a2-a2ad-a12023c5a8af": {"__data__": {"text": "the \napplication receives both of these services from TCP.\n\u2022 Connection-oriented service.  TCP has the client and server exchange transport-\nlayer control information with each other before  the application-level mes -\nsages begin to flow. This so-called handshaking procedure alerts the client \nand server, allowing them to prepare for an onslaught of packets. After the \nhandshaking phase, a TCP connection  is said to exist between the sockets \nApplication Data Loss Throughput Time-Sensitive\nFile transfer/download No loss Elastic No\nE-mail No loss Elastic No\nWeb documents No loss Elastic (few kbps )N o\nInternet telephony/\nVideo conferencingLoss-tolerant Audio: few kbps\u20131Mbps\nVideo: 10 kbps\u20135 MbpsYes: 100s of msec\nStreaming stored Loss-tolerant Same as abov eY es: few seconds\naudio/video\nInteractive games Loss-tolerant Few kbps\u201310 kbps Yes: 100s of msec\nSmartphone messaging No loss Elastic Yes and no\nFigure 2.4  \u2666 Requirements of selected network applications\n122     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nof the two processes. The connection is a full-duplex connection in that the two \nprocesses can send messages to each other over the connection at the same time. \nWhen the application finishes sending messages, it must tear down the connec -\ntion. In Chapter 3 we\u2019ll discuss connection-oriented service in detail and examine \nhow it is implemented.\n\u2022 Reliable data transfer service.  The communicating processes can rely on TCP to \ndeliver all data sent without error and in the proper order. When one side of the \napplication passes a stream of bytes into a socket, it can count on TCP to deliver the \nsame stream of bytes to the receiving socket, with no missing or duplicate bytes.\nTCP also includes a congestion-control mechanism, a service for the general \nwelfare of the Internet rather than for the direct benefit of the communicating pro -\ncesses. The TCP congestion-control mechanism throttles a sending process (client or \nserver) when the network is congested between sender and receiver. As we will see \nSECURING TCP\nNeither TCP nor UDP provides any encryption\u2014the data that the sending process \npasses into its socket is the same data that travels over the network to the destina -\ntion process. So, for example, if the sending process sends a password in cleartext \n(i.e., unencrypted) into its socket, the cleartext password will travel over all the links \nbetween sender and receiver, potentially getting sniffed and discovered at any of \nthe intervening links. Because privacy and other security issues have become critical \nfor many applications, the Internet community has developed an enhancement for \nTCP, called Secure Sockets Layer (SSL) . TCP-enhanced-with-SSL not only does \neverything that traditional TCP does but also provides critical process-to-process \nsecurity services, including encryption, data integrity, and end-point authentication. \nWe emphasize that SSL is not a third Internet transport protocol, on the same level as \nTCP and UDP, but instead is an enhancement of TCP, with the enhancements being \nimplemented in the application layer. In particular, if an application wants to use \nthe services of SSL, it needs to include SSL code (existing, highly optimized libraries \nand classes) in both the client and server sides of the application. SSL has its own \nsocket API that is similar to the traditional TCP socket API. When an application uses \nSSL, the sending process passes cleartext data to the SSL socket; SSL in the sending \nhost then encrypts the data and passes the encrypted data to the TCP socket. The \nencrypted data travels over the Internet to the TCP socket in the receiving process. \nThe receiving socket passes the encrypted data to SSL, which decrypts the data. \nFinally, SSL passes the cleartext data through its SSL socket to the receiving process. \nWe\u2019ll cover SSL in some detail in Chapter 8 .FOCUS ON SECURITY\n\n2.1  \u2022  PRINCIPLES OF NETWORK", "doc_id": "d8f05422-4f16-49a2-a2ad-a12023c5a8af", "embedding": null, "doc_hash": "ed0ce1aa5665d30f96f2175262d7c0c83e28a4aaf4fad7c986f1b3c27ae826d1", "extra_info": null, "node_info": {"start": 346902, "end": 350822}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "e29e5397-96c3-4792-a3e1-7eff15a93804", "3": "3adff088-506d-431f-bff0-2a2f0a68a45c"}}, "__type__": "1"}, "3adff088-506d-431f-bff0-2a2f0a68a45c": {"__data__": {"text": "services of SSL, it needs to include SSL code (existing, highly optimized libraries \nand classes) in both the client and server sides of the application. SSL has its own \nsocket API that is similar to the traditional TCP socket API. When an application uses \nSSL, the sending process passes cleartext data to the SSL socket; SSL in the sending \nhost then encrypts the data and passes the encrypted data to the TCP socket. The \nencrypted data travels over the Internet to the TCP socket in the receiving process. \nThe receiving socket passes the encrypted data to SSL, which decrypts the data. \nFinally, SSL passes the cleartext data through its SSL socket to the receiving process. \nWe\u2019ll cover SSL in some detail in Chapter 8 .FOCUS ON SECURITY\n\n2.1  \u2022  PRINCIPLES OF NETWORK APPLICATIONS      123\nin Chapter 3, TCP congestion control also attempts to limit each TCP connection to \nits fair share of network bandwidth.\nUDP Services\nUDP is a no-frills, lightweight transport protocol, providing minimal services. UDP \nis connectionless, so there is no handshaking before the two processes start to com -\nmunicate. UDP provides an unreliable data transfer service\u2014that is, when a process \nsends a message into a UDP socket, UDP provides no guarantee that the message \nwill ever reach the receiving process. Furthermore, messages that do arrive at the \nreceiving process may arrive out of order.\nUDP does not include a congestion-control mechanism, so the sending side of \nUDP can pump data into the layer below (the network layer) at any rate it pleases. \n(Note, however, that the actual end-to-end throughput may be less than this rate due \nto the limited transmission capacity of intervening links or due to congestion).\nServices Not Provided by Internet Transport Protocols\nWe have organized transport protocol services along four dimensions: reliable data \ntransfer, throughput, timing, and security. Which of these services are provided \nby TCP and UDP? We have already noted that TCP provides reliable end-to-end \ndata transfer. And we also know that TCP can be easily enhanced at the application \nlayer with SSL to provide security services. But in our brief description of TCP and \nUDP, conspicuously missing was any mention of throughput or timing guarantees\u2014  \nservices not provided by today\u2019s Internet transport protocols. Does this mean that \ntime-sensitive applications such as Internet telephony cannot run in today\u2019s Internet? \nThe answer is clearly no\u2014the Internet has been hosting time-sensitive applications \nfor many years. These applications often work fairly well because they have been \ndesigned to cope, to the greatest extent possible, with this lack of guarantee. We\u2019ll \ninvestigate several of these design tricks in Chapter 9 . Nevertheless, clever design \nhas its limitations when delay is excessive, or the end-to-end throughput is limited. \nIn summary, today\u2019s Internet can often provide satisfactory service to time-sensitive \napplications, but it cannot provide any timing or throughput guarantees.\nFigure 2. 5 indicates the transport protocols used by some popular Internet appli -\ncations. We see that e-mail, remote terminal access, the Web, and file transfer all \nuse TCP. These applications have chosen TCP primarily because TCP provides reli -\nable data transfer, guaranteeing that all data will eventually get to its destination. \nBecause Internet telephony applications (such as Skype) can often tolerate some loss \nbut require a minimal rate to be effective, developers of Internet telephony applica -\ntions usually prefer to run their applications over UDP, thereby circumventing TCP\u2019s \ncongestion control mechanism and packet overheads. But because many firewalls \nare configured to block (most types of) UDP traffic, Internet telephony applications \noften are designed to use TCP as a backup if UDP communication fails.\n124     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION", "doc_id": "3adff088-506d-431f-bff0-2a2f0a68a45c", "embedding": null, "doc_hash": "13fb5b7edf068ece4c5411927bc613bf8bedadb219f9729e47d8484ef73082af", "extra_info": null, "node_info": {"start": 350811, "end": 354709}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "d8f05422-4f16-49a2-a2ad-a12023c5a8af", "3": "b250db54-beeb-40cb-b33f-888e2eebf77e"}}, "__type__": "1"}, "b250db54-beeb-40cb-b33f-888e2eebf77e": {"__data__": {"text": "Web, and file transfer all \nuse TCP. These applications have chosen TCP primarily because TCP provides reli -\nable data transfer, guaranteeing that all data will eventually get to its destination. \nBecause Internet telephony applications (such as Skype) can often tolerate some loss \nbut require a minimal rate to be effective, developers of Internet telephony applica -\ntions usually prefer to run their applications over UDP, thereby circumventing TCP\u2019s \ncongestion control mechanism and packet overheads. But because many firewalls \nare configured to block (most types of) UDP traffic, Internet telephony applications \noften are designed to use TCP as a backup if UDP communication fails.\n124     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\n2.1.5  Application-Layer Protocols\nWe have just learned that network processes communicate with each other by sending \nmessages into sockets. But how are these messages structured? What are the meanings \nof the various fields in the messages? When do the processes send the messages? These \nquestions bring us into the realm of application-layer protocols. An application-layer \nprotocol  defines how an application\u2019s processes, running on different end systems, \npass messages to each other. In particular, an application-layer protocol defines:\n\u2022 The types of messages exchanged, for example, request messages and response \nmessages\n\u2022 The syntax of the various message types, such as the fields in the message and \nhow the fields are delineated\n\u2022 The semantics of the fields, that is, the meaning of the information in the fields\n\u2022 Rules for determining when and how a process sends messages and responds to \nmessages\nSome application-layer protocols are specified in RFCs and are therefore in the \npublic domain. For example, the Web\u2019s application-layer protocol, HTTP (the \nHyperText Transfer Protocol [RFC 2616]), is available as an RFC. If a browser \ndeveloper follows the rules of the HTTP RFC, the browser will be able to retrieve \nWeb pages from any Web server that has also followed the rules of the HTTP RFC. \nMany other application-layer protocols are proprietary and intentionally not avail -\nable in the public domain. For example, Skype uses proprietary application-layer \nprotocols.Application Application-Layer Protocol Underlying Transport Protocol\nElectronic mail\nRemote terminal access\nWeb\nFile transfer\nStreaming multimedia\nInternet telephonySMTP [RFC 5321]\nTelnet [RFC 854]\nHTTP [RFC 2616]\nFTP [RFC 959]\nHTTP (e.g., YouTube)\nSIP [RFC 3261], RTP [RFC 3550], or proprietary\n(e.g., Skype)TCP\nTCP\nTCP\nTCP\nTCP\nUDP or TCP\nFigure 2.5  \u2666  Popular Internet applications, their application-layer  \nprotocols, and their underlying transport protocols\n2.1  \u2022  PRINCIPLES OF NETWORK APPLICATIONS      125\nIt is important to distinguish between network applications and application-layer \nprotocols. An application-layer protocol is only one piece of a network application \n(albeit, a very important piece of the application from our point of view!). Let\u2019s look \nat a couple of examples. The Web is a client-server application that allows users \nto obtain documents from Web servers on demand. The Web application consists \nof many components, including a standard for document formats (that is, HTML), \nWeb browsers (for example, Firefox and Microsoft Internet Explorer), Web servers \n(for example, Apache and Microsoft servers), and an application-layer protocol. The \nWeb\u2019s application-layer protocol, HTTP, defines the format and sequence of mes -\nsages exchanged between browser and Web server. Thus, HTTP is only one piece \n(albeit, an important piece) of the Web application. As another example, an Internet \ne-mail application also has many components, including mail servers that house user \nmailboxes; mail clients (such as Microsoft Outlook) that allow users to read and \ncreate messages; a standard for defining the structure of an", "doc_id": "b250db54-beeb-40cb-b33f-888e2eebf77e", "embedding": null, "doc_hash": "d9043183f9722672f2f522e44dd34643b687b443367b0c4502fbcc8a4474ce7b", "extra_info": null, "node_info": {"start": 354736, "end": 358622}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "3adff088-506d-431f-bff0-2a2f0a68a45c", "3": "0676ccc1-8cf9-4bf9-b5e9-420c91fed017"}}, "__type__": "1"}, "0676ccc1-8cf9-4bf9-b5e9-420c91fed017": {"__data__": {"text": "Web is a client-server application that allows users \nto obtain documents from Web servers on demand. The Web application consists \nof many components, including a standard for document formats (that is, HTML), \nWeb browsers (for example, Firefox and Microsoft Internet Explorer), Web servers \n(for example, Apache and Microsoft servers), and an application-layer protocol. The \nWeb\u2019s application-layer protocol, HTTP, defines the format and sequence of mes -\nsages exchanged between browser and Web server. Thus, HTTP is only one piece \n(albeit, an important piece) of the Web application. As another example, an Internet \ne-mail application also has many components, including mail servers that house user \nmailboxes; mail clients (such as Microsoft Outlook) that allow users to read and \ncreate messages; a standard for defining the structure of an e-mail message; and \napplication-layer protocols that define how messages are passed between servers, \nhow messages are passed between servers and mail clients, and how the contents \nof message headers are to be interpreted. The principal application-layer protocol \nfor electronic mail is SMTP (Simple Mail Transfer Protocol) [RFC 5321]. Thus,  \ne-mail\u2019s principal application-layer protocol, SMTP, is only one piece (albeit an \nimportant piece) of the e-mail application.\n2.1.6  Network Applications Covered in This Book\nNew public domain and proprietary Internet applications are being developed \nevery day. Rather than covering a large number of Internet applications in an \nencyclopedic manner, we have chosen to focus on a small number of applications \nthat are both pervasive and important. In this chapter we discuss five important \napplications: the Web, electronic mail, directory service video streaming, and \nP2P applications. We first discuss the Web, not only because it is an enormously \npopular application, but also because its application-layer protocol, HTTP, is \nstraightforward and easy to understand. We then discuss electronic mail, the \nInternet\u2019s first killer application. E-mail is more complex than the Web in the \nsense that it makes use of not one but several application-layer protocols. After \ne-mail, we cover DNS, which provides a directory service for the Internet. Most \nusers do not interact with DNS directly; instead, users invoke DNS indirectly \nthrough other applications (including the Web, file transfer, and electronic mail). \nDNS illustrates nicely how a piece of core network functionality (network-name \nto network-address translation) can be implemented at the application layer in \nthe Internet. We then discuss P2P file sharing applications, and complete our \napplication study by discussing video streaming on demand, including dis -\ntributing stored video over content distribution networks. In Chapter 9, we\u2019ll \ncover multimedia applications in more depth, including voice over IP and video  \nconferencing.\n126     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\n2.2 The Web and HTTP\nUntil the early 1990s the Internet was used primarily by researchers, academics, \nand university students to log in to remote hosts, to transfer files from local hosts \nto remote hosts and vice versa, to receive and send news, and to receive and send \nelectronic mail. Although these applications were (and continue to be) extremely \nuseful, the Internet was essentially unknown outside of the academic and research \ncommunities. Then, in the early 1990s, a major new application arrived on the \nscene\u2014the World Wide Web [Berners-Lee 1994]. The Web was the first Internet \napplication that caught the general public\u2019s eye. It dramatically changed, and con -\ntinues to change, how people interact inside and outside their work environments. \nIt elevated the Internet from just one of many data networks to essentially the one \nand only data network.\nPerhaps what appeals the most to users is that the Web operates on demand . \nUsers receive what they want, when they want it. This is unlike traditional broadcast \nradio and television, which force users to tune in when the content provider makes \nthe content available. In addition to being available on demand, the Web has many \nother", "doc_id": "0676ccc1-8cf9-4bf9-b5e9-420c91fed017", "embedding": null, "doc_hash": "802656b807ec2c2b5a8b7cdcbbaa7592cf9cb54848402f9e5efd12866f83ddb6", "extra_info": null, "node_info": {"start": 358515, "end": 362675}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "b250db54-beeb-40cb-b33f-888e2eebf77e", "3": "394fdc66-c328-4cd3-ba47-d7587b00dd1e"}}, "__type__": "1"}, "394fdc66-c328-4cd3-ba47-d7587b00dd1e": {"__data__": {"text": "\nuseful, the Internet was essentially unknown outside of the academic and research \ncommunities. Then, in the early 1990s, a major new application arrived on the \nscene\u2014the World Wide Web [Berners-Lee 1994]. The Web was the first Internet \napplication that caught the general public\u2019s eye. It dramatically changed, and con -\ntinues to change, how people interact inside and outside their work environments. \nIt elevated the Internet from just one of many data networks to essentially the one \nand only data network.\nPerhaps what appeals the most to users is that the Web operates on demand . \nUsers receive what they want, when they want it. This is unlike traditional broadcast \nradio and television, which force users to tune in when the content provider makes \nthe content available. In addition to being available on demand, the Web has many \nother wonderful features that people love and cherish. It is enormously easy for any \nindividual to make information available over the Web\u2014everyone can become a \npublisher at extremely low cost. Hyperlinks and search engines help us navigate \nthrough an ocean of information. Photos and videos stimulate our senses. Forms, \nJavaScript, Java applets, and many other devices enable us to interact with pages and \nsites. And the Web and its protocols serve as a platform for YouTube, Web-based \ne-mail (such as Gmail), and most mobile Internet applications, including Instagram \nand Google Maps.\n2.2.1 Overview of HTTP\nThe HyperText Transfer Protocol (HTTP) , the Web\u2019s application-layer protocol, \nis at the heart of the Web. It is defined in [RFC 1945] and [RFC 2616]. HTTP is \nimplemented in two programs: a client program and a server program. The client \nprogram and server program, executing on different end systems, talk to each other \nby exchanging HTTP messages. HTTP defines the structure of these messages and \nhow the client and server exchange the messages. Before explaining HTTP in detail, \nwe should review some Web terminology.\nA Web page  (also called a document) consists of objects. An object  is \nsimply a file\u2014such as an HTML file, a JPEG image, a Java applet, or a video  \nclip\u2014that is addressable by a single URL. Most Web pages consist of a base \nHTML file  and several referenced objects. For example, if a Web page con -\ntains HTML text and five JPEG images, then the Web page has six objects: the \nbase HTML file plus the five images. The base HTML file references the other \nobjects in the page with the objects\u2019 URLs. Each URL has two components: the \n2.2  \u2022  THE WEB AND HTTP      127\nhostname of the server that houses the object and the object\u2019s path name. For \nexample, the URL\nhttp://www.someSchool.edu/someDepartment/picture.gif\nhas www.someSchool.edu  for a hostname and /someDepartment/picture.\ngif for a path name. Because Web browsers  (such as Internet Explorer and Firefox) \nimplement the client side of HTTP, in the context of the Web, we will use the words \nbrowser  and client  interchangeably. Web servers , which implement the server side \nof HTTP, house Web objects, each addressable by a URL. Popular Web servers \ninclude Apache and Microsoft Internet Information Server.\nHTTP defines how Web clients request Web pages from Web servers and how \nservers transfer Web pages to clients. We discuss the interaction between client \nand server in detail later, but the general idea is illustrated in Figure 2.6. When a  \nuser requests a Web page (for example, clicks on a hyperlink), the browser sends \nHTTP request messages for the objects in the page to the server. The server receives \nthe requests and responds with HTTP response messages that contain the objects.\nHTTP uses TCP as its underlying transport protocol (rather than running on top \nof UDP). The HTTP client first initiates a TCP connection with the server. Once the \nconnection is established, the browser and the server processes access TCP through \ntheir socket interfaces. As described in Section 2.1, on the client side the socket inter -\nface is the door between the client process and the TCP connection; on the server side \nit is the door between the server process", "doc_id": "394fdc66-c328-4cd3-ba47-d7587b00dd1e", "embedding": null, "doc_hash": "32458996d0ee53975191576f90a3a19a9570767f4bd4cb10f7aa1113bed82211", "extra_info": null, "node_info": {"start": 362686, "end": 366814}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "0676ccc1-8cf9-4bf9-b5e9-420c91fed017", "3": "83f1d845-a91a-4c18-a050-c27824c477f8"}}, "__type__": "1"}, "83f1d845-a91a-4c18-a050-c27824c477f8": {"__data__": {"text": "We discuss the interaction between client \nand server in detail later, but the general idea is illustrated in Figure 2.6. When a  \nuser requests a Web page (for example, clicks on a hyperlink), the browser sends \nHTTP request messages for the objects in the page to the server. The server receives \nthe requests and responds with HTTP response messages that contain the objects.\nHTTP uses TCP as its underlying transport protocol (rather than running on top \nof UDP). The HTTP client first initiates a TCP connection with the server. Once the \nconnection is established, the browser and the server processes access TCP through \ntheir socket interfaces. As described in Section 2.1, on the client side the socket inter -\nface is the door between the client process and the TCP connection; on the server side \nit is the door between the server process and the TCP connection. The client sends \nHTTP request messages into its socket interface and receives HTTP response mes -\nsages from its socket interface. Similarly, the HTTP server receives request messages \nHTTP request\nHTTP responseHTTP response\nHTTP request\nPC running\nInternet ExplorerAndroid smartphone\nrunning Google ChromeServer running\nApache Web server\nFigure 2.6  \u2666 HTTP request-response behavior\n128     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nfrom its socket interface and sends response messages into its socket interface. Once \nthe client sends a message into its socket interface, the message is out of the client\u2019s \nhands and is \u201cin the hands\u201d of TCP. Recall from Section 2.1 that TCP provides a \nreliable data transfer service to HTTP. This implies that each HTTP request message \nsent by a client process eventually arrives intact at the server; similarly, each HTTP \nresponse message sent by the server process eventually arrives intact at the client. \nHere we see one of the great advantages of a layered architecture\u2014HTTP need not \nworry about lost data or the details of how TCP recovers from loss or reordering of \ndata within the network. That is the job of TCP and the protocols in the lower layers \nof the protocol stack.\nIt is important to note that the server sends requested files to clients without \nstoring any state information about the client. If a particular client asks for the same \nobject twice in a period of a few seconds, the server does not respond by saying that \nit just served the object to the client; instead, the server resends the object, as it has \ncompletely forgotten what it did earlier. Because an HTTP server maintains no infor -\nmation about the clients, HTTP is said to be a stateless protocol . We also remark \nthat the Web uses the client-server application architecture, as described in Section \n2.1. A Web server is always on, with a fixed IP address, and it services requests from \npotentially millions of different browsers.\n2.2.2 Non-Persistent and Persistent Connections\nIn many Internet applications, the client and server communicate for an extended \nperiod of time, with the client making a series of requests and the server respond -\ning to each of the requests. Depending on the application and on how the applica -\ntion is being used, the series of requests may be made back-to-back, periodically \nat regular intervals, or intermittently. When this client-server interaction is \ntaking place over TCP, the application developer needs to make an important  \ndecision\u2014should each request/response pair be sent over a separate  TCP connec -\ntion, or should all of the requests and their corresponding responses be sent over \nthe same  TCP connection? In the former approach, the application is said to use  \nnon-persistent connections ; and in the latter approach, persistent connections . \nTo gain a deep understanding of this design issue, let\u2019s examine the advantages \nand disadvantages of persistent connections in the context of a specific applica -\ntion, namely, HTTP, which can use both non-persistent connections and per -\nsistent connections. Although HTTP uses persistent connections in its default \nmode, HTTP clients and servers can be configured to use non-persistent connec -\ntions instead.\nHTTP with Non-Persistent Connections\nLet\u2019s walk through", "doc_id": "83f1d845-a91a-4c18-a050-c27824c477f8", "embedding": null, "doc_hash": "3488d5c1f36ce50afaff77acd259ed37f7812862809c460d9c5d78a02da72bd2", "extra_info": null, "node_info": {"start": 366823, "end": 370998}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "394fdc66-c328-4cd3-ba47-d7587b00dd1e", "3": "0216e669-c49f-438f-a72d-4ffc37935518"}}, "__type__": "1"}, "0216e669-c49f-438f-a72d-4ffc37935518": {"__data__": {"text": "each request/response pair be sent over a separate  TCP connec -\ntion, or should all of the requests and their corresponding responses be sent over \nthe same  TCP connection? In the former approach, the application is said to use  \nnon-persistent connections ; and in the latter approach, persistent connections . \nTo gain a deep understanding of this design issue, let\u2019s examine the advantages \nand disadvantages of persistent connections in the context of a specific applica -\ntion, namely, HTTP, which can use both non-persistent connections and per -\nsistent connections. Although HTTP uses persistent connections in its default \nmode, HTTP clients and servers can be configured to use non-persistent connec -\ntions instead.\nHTTP with Non-Persistent Connections\nLet\u2019s walk through the steps of transferring a Web page from server to client for the \ncase of non-persistent connections. Let\u2019s suppose the page consists of a base HTML \n2.2  \u2022  THE WEB AND HTTP      129\nfile and 10 JPEG images, and that all 11 of these objects reside on the same server. \nFurther suppose the URL for the base HTML file is\nhttp://www.someSchool.edu/someDepartment/home.index\nHere is what happens:\n 1. The HTTP client process initiates a TCP connection to the server www \n.someSchool.edu  on port number 80, which is the default port number for \nHTTP. Associated with the TCP connection, there will be a socket at the client \nand a socket at the server.\n 2. The HTTP client sends an HTTP request message to the server via its socket. \nThe request message includes the path name /someDepartment/home \n.index . (We will discuss HTTP messages in some detail below.)\n 3. The HTTP server process receives the request message via its socket, retrieves \nthe object /someDepartment/home.index  from its storage (RAM or \ndisk), encapsulates the object in an HTTP response message, and sends the \nresponse message to the client via its socket.\n 4. The HTTP server process tells TCP to close the TCP connection. (But TCP \ndoesn\u2019t actually terminate the connection until it knows for sure that the client \nhas received the response message intact.)\n 5. The HTTP client receives the response message. The TCP connection termi -\nnates. The message indicates that the encapsulated object is an HTML file. The \nclient extracts the file from the response message, examines the HTML file, and \nfinds references to the 10 JPEG objects.\n 6. The first four steps are then repeated for each of the referenced JPEG objects.\nAs the browser receives the Web page, it displays the page to the user. Two dif -\nferent browsers may interpret (that is, display to the user) a Web page in somewhat \ndifferent ways. HTTP has nothing to do with how a Web page is interpreted by a cli -\nent. The HTTP specifications ([RFC 1945] and [RFC 2616]) define only the commu -\nnication protocol between the client HTTP program and the server HTTP program.\nThe steps above illustrate the use of non-persistent connections, where each TCP \nconnection is closed after the server sends the object\u2014the connection does not per -\nsist for other objects. Note that each TCP connection transports exactly one request \nmessage and one response message. Thus, in this example, when a user requests the \nWeb page, 11 TCP connections are generated.\nIn the steps described above, we were intentionally vague about whether the  \nclient obtains the 10 JPEGs over 10 serial TCP connections, or whether some of the \nJPEGs are obtained over parallel TCP connections. Indeed, users can configure modern \nbrowsers to control the degree of parallelism. In their default modes, most browsers open \n5 to 10 parallel TCP connections, and each of these connections handles one request-\nresponse transaction. If the user prefers, the maximum number of parallel connections \n130     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\ncan be set to one, in which case the 10 connections are established serially. As we\u2019ll see \nin the next chapter, the use of parallel connections shortens the response", "doc_id": "0216e669-c49f-438f-a72d-4ffc37935518", "embedding": null, "doc_hash": "2e2290ced1a26d443c20792754d093c6eafb16e1fbeffa274b4abaf7cb3b7a7c", "extra_info": null, "node_info": {"start": 371039, "end": 375035}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "83f1d845-a91a-4c18-a050-c27824c477f8", "3": "a3f328e3-a3ad-49dc-927c-f3bba8778f32"}}, "__type__": "1"}, "a3f328e3-a3ad-49dc-927c-f3bba8778f32": {"__data__": {"text": "11 TCP connections are generated.\nIn the steps described above, we were intentionally vague about whether the  \nclient obtains the 10 JPEGs over 10 serial TCP connections, or whether some of the \nJPEGs are obtained over parallel TCP connections. Indeed, users can configure modern \nbrowsers to control the degree of parallelism. In their default modes, most browsers open \n5 to 10 parallel TCP connections, and each of these connections handles one request-\nresponse transaction. If the user prefers, the maximum number of parallel connections \n130     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\ncan be set to one, in which case the 10 connections are established serially. As we\u2019ll see \nin the next chapter, the use of parallel connections shortens the response time.\nBefore continuing, let\u2019s do a back-of-the-envelope calculation to estimate the \namount of time that elapses from when a client requests the base HTML file until \nthe entire file is received by the client. To this end, we define the round-trip time \n(RTT) , which is the time it takes for a small packet to travel from client to server \nand then back to the client. The RTT includes packet-propagation delays, packet-\nqueuing delays in intermediate routers and switches, and packet-processing delays. \n(These delays were discussed in Section 1.4.) Now consider what happens when \na user clicks on a hyperlink. As shown in Figure 2.7, this causes the browser to \ninitiate a TCP connection between the browser and the Web server; this involves \na \u201cthree-way handshake\u201d\u2014the client sends a small TCP segment to the server, the \nserver acknowledges and responds with a small TCP segment, and, finally, the cli -\nent acknowledges back to the server. The first two parts of the three-way handshake \ntake one RTT. After completing the first two parts of the handshake, the client sends \nthe HTTP request message combined with the third part of the three-way handshake \n(the acknowledgment) into the TCP connection. Once the request message arrives at  \nTime\nat clientTime\nat serverInitiate TCP\nconnection\nRTT\nRequest \ufb01le\nRTT\nEntire \ufb01le receivedTime to transmit \ufb01le\nFigure 2.7  \u2666  Back-of-the-envelope calculation for the time needed  \nto request and receive an HTML file\n2.2  \u2022  THE WEB AND HTTP      131\nthe server, the server sends the HTML file into the TCP connection. This HTTP \nrequest/response eats up another RTT. Thus, roughly, the total response time is two \nRTTs plus the transmission time at the server of the HTML file.\nHTTP with Persistent Connections\nNon-persistent connections have some shortcomings. First, a brand-new connection \nmust be established and maintained for each requested object . For each of these \nconnections, TCP buffers must be allocated and TCP variables must be kept in both \nthe client and server. This can place a significant burden on the Web server, which \nmay be serving requests from hundreds of different clients simultaneously. Second, \nas we just described, each object suffers a delivery delay of two RTTs\u2014one RTT to \nestablish the TCP connection and one RTT to request and receive an object.\nWith HTTP 1.1 persistent connections, the server leaves the TCP connection \nopen after sending a response. Subsequent requests and responses between the same \nclient and server can be sent over the same connection. In particular, an entire Web \npage (in the example above, the base HTML file and the 10 images) can be sent over \na single persistent TCP connection. Moreover, multiple Web pages residing on the \nsame server can be sent from the server to the same client over a single persistent \nTCP connection. These requests for objects can be made back-to-back, without wait -\ning for replies to pending requests (pipelining). Typically, the HTTP server closes \na connection when it isn\u2019t used for a certain time (a configurable timeout interval). \nWhen the server receives", "doc_id": "a3f328e3-a3ad-49dc-927c-f3bba8778f32", "embedding": null, "doc_hash": "ec7dca2fb892356164fb32ab27975ed943eea08cb72fa300576ee77517432ed4", "extra_info": null, "node_info": {"start": 375071, "end": 378939}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "0216e669-c49f-438f-a72d-4ffc37935518", "3": "05ee2cdb-b0c7-4a89-bbe3-b681745d5ba3"}}, "__type__": "1"}, "05ee2cdb-b0c7-4a89-bbe3-b681745d5ba3": {"__data__": {"text": "and one RTT to request and receive an object.\nWith HTTP 1.1 persistent connections, the server leaves the TCP connection \nopen after sending a response. Subsequent requests and responses between the same \nclient and server can be sent over the same connection. In particular, an entire Web \npage (in the example above, the base HTML file and the 10 images) can be sent over \na single persistent TCP connection. Moreover, multiple Web pages residing on the \nsame server can be sent from the server to the same client over a single persistent \nTCP connection. These requests for objects can be made back-to-back, without wait -\ning for replies to pending requests (pipelining). Typically, the HTTP server closes \na connection when it isn\u2019t used for a certain time (a configurable timeout interval). \nWhen the server receives the back-to-back requests, it sends the objects back-to-\nback. The default mode of HTTP uses persistent connections with pipelining. Most \nrecently, HTTP/2 [RFC 7540] builds on HTTP 1.1 by allowing multiple requests \nand replies to be interleaved in the same  connection, and a mechanism for prioritiz -\ning HTTP message requests and replies within this connection. We\u2019ll quantitatively \ncompare the performance of non-persistent and persistent connections in the home -\nwork problems of Chapters 2 and 3. You are also encouraged to see [Heidemann \n1997; Nielsen 1997; RFC 7540].\n2.2.3 HTTP Message Format\nThe HTTP specifications [RFC 1945; RFC 2616; RFC 7540] include the definitions \nof the HTTP message formats. There are two types of HTTP messages, request mes -\nsages and response messages, both of which are discussed below.\nHTTP Request Message\nBelow we provide a typical HTTP request message:\nGET /somedir/page.html HTTP/1.1\nHost: www.someschool.edu\n132     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nConnection: close\nUser-agent: Mozilla/5.0\nAccept-language: fr\nWe can learn a lot by taking a close look at this simple request message. First of \nall, we see that the message is written in ordinary ASCII text, so that your ordinary \ncomputer-literate human being can read it. Second, we see that the message consists \nof five lines, each followed by a carriage return and a line feed. The last line is fol -\nlowed by an additional carriage return and line feed. Although this particular request \nmessage has five lines, a request message can have many more lines or as few as \none line. The first line of an HTTP request message is called the request line ; the \nsubsequent lines are called the header lines . The request line has three fields: the \nmethod field, the URL field, and the HTTP version field. The method field can take \non several different values, including GET,  POST,  HEAD,  PUT,  and DELETE . \nThe great majority of HTTP request messages use the GET method. The GET method \nis used when the browser requests an object, with the requested object identified in \nthe URL field. In this example, the browser is requesting the object /somedir/\npage.html . The version is self-explanatory; in this example, the browser imple -\nments version HTTP/1.1.\nNow let\u2019s look at the header lines in the example. The header line Host:  www \n.someschool.edu  specifies the host on which the object resides. You might \nthink that this header line is unnecessary, as there is already a TCP connection in \nplace to the host. But, as we\u2019ll see in Section 2.2.5, the information provided by the \nhost header line is required by Web proxy caches. By including the Connection: \nclose  header line, the browser is telling the server that it doesn\u2019t want to bother \nwith persistent connections; it wants the server to close the connection after sending \nthe requested object. The User-agent:  header line specifies the user agent, that \nis, the browser type that is making the request to the server. Here the user agent is \nMozilla/5.0, a Firefox browser. This header line is useful because the server can actu -\nally send different versions of the same", "doc_id": "05ee2cdb-b0c7-4a89-bbe3-b681745d5ba3", "embedding": null, "doc_hash": "bde8652c52ccbc050cb9cfc8f0500a33c2e2adb85d3679d2dc95e3d14daa1c45", "extra_info": null, "node_info": {"start": 378883, "end": 382852}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "a3f328e3-a3ad-49dc-927c-f3bba8778f32", "3": "b7514aee-8ae2-42fb-876c-2476281c1d2e"}}, "__type__": "1"}, "b7514aee-8ae2-42fb-876c-2476281c1d2e": {"__data__": {"text": " specifies the host on which the object resides. You might \nthink that this header line is unnecessary, as there is already a TCP connection in \nplace to the host. But, as we\u2019ll see in Section 2.2.5, the information provided by the \nhost header line is required by Web proxy caches. By including the Connection: \nclose  header line, the browser is telling the server that it doesn\u2019t want to bother \nwith persistent connections; it wants the server to close the connection after sending \nthe requested object. The User-agent:  header line specifies the user agent, that \nis, the browser type that is making the request to the server. Here the user agent is \nMozilla/5.0, a Firefox browser. This header line is useful because the server can actu -\nally send different versions of the same object to different types of user agents. (Each \nof the versions is addressed by the same URL.) Finally, the Accept-language:  \nheader indicates that the user prefers to receive a French version of the object, if such \nan object exists on the server; otherwise, the server should send its default version. \nThe Accept-language:  header is just one of many content negotiation headers \navailable in HTTP.\nHaving looked at an example, let\u2019s now look at the general format of a request \nmessage, as shown in Figure 2.8. We see that the general format closely follows our \nearlier example. You may have noticed, however, that after the header lines (and the \nadditional carriage return and line feed) there is an \u201centity body.\u201d The entity body \nis empty with the GET method, but is used with the POST  method. An HTTP client \noften uses the POST  method when the user fills out a form\u2014for example, when a \nuser provides search words to a search engine. With a POST  message, the user is still \nrequesting a Web page from the server, but the specific contents of the Web page \n2.2  \u2022  THE WEB AND HTTP      133\ndepend on what the user entered into the form fields. If the value of the method field \nis POST , then the entity body contains what the user entered into the form fields.\nWe would be remiss if we didn\u2019t mention that a request generated with a form \ndoes not necessarily use the POST  method. Instead, HTML forms often use the GET \nmethod and include the inputted data (in the form fields) in the requested URL. For \nexample, if a form uses the GET method, has two fields, and the inputs to the two \nfields are monkeys  and bananas , then the URL will have the structure www.\nsomesite.com/animalsearch?monkeys&bananas . In your day-to-day \nWeb surfing, you have probably noticed extended URLs of this sort.\nThe HEAD  method is similar to the GET method. When a server receives a \nrequest with the HEAD  method, it responds with an HTTP message but it leaves out \nthe requested object. Application developers often use the HEAD  method for debug -\nging. The PUT method is often used in conjunction with Web publishing tools. It \nallows a user to upload an object to a specific path (directory) on a specific Web \nserver. The PUT method is also used by applications that need to upload objects \nto Web servers. The DELETE  method allows a user, or an application, to delete an \nobject on a Web server.\nHTTP Response Message\nBelow we provide a typical HTTP response message. This response message could \nbe the response to the example request message just discussed.\nHTTP/1.1 200 OK\nConnection: close\nDate: Tue, 18 Aug 2015 15:44:04 GMTmethod sp sp crlf\ncrlf header \ufb01eld name:\nHeader lines\nBlank line\nEntity bodyRequest line\nvalue sp\ncrlf\ncrlfheader \ufb01eld name: value spURL Version\nFigure 2.8  \u2666 General format of an HTTP request message\n134     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nServer: Apache/2.2.3 (CentOS)\nLast-Modified: Tue, 18 Aug 2015 15:11:03 GMT\nContent-Length: 6821\nContent-Type: text/html \u00a0\n(data data data data data ...)\nLet\u2019s take a careful look at this response message. It has three sections:", "doc_id": "b7514aee-8ae2-42fb-876c-2476281c1d2e", "embedding": null, "doc_hash": "1ef3732d8a40c43242c96afb1b68ac72fce6438bd2ab93b22a74634a207b51d9", "extra_info": null, "node_info": {"start": 382891, "end": 386788}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "05ee2cdb-b0c7-4a89-bbe3-b681745d5ba3", "3": "8c3480f6-714c-4fda-bd6f-0d4625a39233"}}, "__type__": "1"}, "8c3480f6-714c-4fda-bd6f-0d4625a39233": {"__data__": {"text": "the response to the example request message just discussed.\nHTTP/1.1 200 OK\nConnection: close\nDate: Tue, 18 Aug 2015 15:44:04 GMTmethod sp sp crlf\ncrlf header \ufb01eld name:\nHeader lines\nBlank line\nEntity bodyRequest line\nvalue sp\ncrlf\ncrlfheader \ufb01eld name: value spURL Version\nFigure 2.8  \u2666 General format of an HTTP request message\n134     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nServer: Apache/2.2.3 (CentOS)\nLast-Modified: Tue, 18 Aug 2015 15:11:03 GMT\nContent-Length: 6821\nContent-Type: text/html \u00a0\n(data data data data data ...)\nLet\u2019s take a careful look at this response message. It has three sections: an initial \nstatus line , six header lines , and then the entity body . The entity body is the meat \nof the message\u2014it contains the requested object itself (represented by data data \ndata data data ... ). The status line has three fields: the protocol version \nfield, a status code, and a corresponding status message. In this example, the status \nline indicates that the server is using HTTP/1.1 and that everything is OK (that is, the \nserver has found, and is sending, the requested object).\nNow let\u2019s look at the header lines. The server uses the Connection: close  \nheader line to tell the client that it is going to close the TCP connection after sending \nthe message. The Date:  header line indicates the time and date when the HTTP \nresponse was created and sent by the server. Note that this is not the time when \nthe object was created or last modified; it is the time when the server retrieves the \nobject from its file system, inserts the object into the response message, and sends the \nresponse message. The Server:  header line indicates that the message was gener -\nated by an Apache Web server; it is analogous to the User-agent:  header line in \nthe HTTP request message. The Last-Modified:  header line indicates the time \nand date when the object was created or last modified. The Last-Modified:  \nheader, which we will soon cover in more detail, is critical for object caching, both \nin the local client and in network cache servers (also known as proxy servers). The \nContent-Length:  header line indicates the number of bytes in the object being \nsent. The Content-Type:  header line indicates that the object in the entity body \nis HTML text. (The object type is officially indicated by the Content-Type:  \nheader and not by the file extension.)\nHaving looked at an example, let\u2019s now examine the general format of a response \nmessage, which is shown in Figure 2.9. This general format of the response message \nmatches the previous example of a response message. Let\u2019s say a few additional \nwords about status codes and their phrases. The status code and associated phrase \nindicate the result of the request. Some common status codes and associated phrases \ninclude:\n\u2022 200 OK:  Request succeeded and the information is returned in the response.\n\u2022 301 Moved Permanently:  Requested object has been permanently moved; \nthe new URL is specified in Location : header of the response message. The \nclient software will automatically retrieve the new URL.\n\u2022 400 Bad Request:  This is a generic error code indicating that the request \ncould not be understood by the server.\n2.2  \u2022  THE WEB AND HTTP      135\n\u2022 404 Not Found:  The requested document does not exist on this server.\n\u2022 505 HTTP Version Not Supported:  The requested HTTP protocol ver -\nsion is not supported by the server.\nHow would you like to see a real HTTP response message? This is highly rec -\nommended and very easy to do! First Telnet into your favorite Web server. Then \ntype in a one-line request message for some object that is housed on the server. For \nexample, if you have access to a command prompt, type:\ntelnet gaia.cs.umass.edu 80\u00a0\nGET /kurose_ross/interactive/index.php HTTP/1.1\nHost: gaia.cs.umass.edu\n(Press the carriage return twice after typing the last line.) This opens a TCP", "doc_id": "8c3480f6-714c-4fda-bd6f-0d4625a39233", "embedding": null, "doc_hash": "1e34d1badd69119db8309baa28f5558f3cffed4c1c7807c698f2249b7b50b8fe", "extra_info": null, "node_info": {"start": 386922, "end": 390804}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "b7514aee-8ae2-42fb-876c-2476281c1d2e", "3": "7294a5b5-ce6d-405e-bc37-029cdffe4483"}}, "__type__": "1"}, "7294a5b5-ce6d-405e-bc37-029cdffe4483": {"__data__": {"text": " \u2022  THE WEB AND HTTP      135\n\u2022 404 Not Found:  The requested document does not exist on this server.\n\u2022 505 HTTP Version Not Supported:  The requested HTTP protocol ver -\nsion is not supported by the server.\nHow would you like to see a real HTTP response message? This is highly rec -\nommended and very easy to do! First Telnet into your favorite Web server. Then \ntype in a one-line request message for some object that is housed on the server. For \nexample, if you have access to a command prompt, type:\ntelnet gaia.cs.umass.edu 80\u00a0\nGET /kurose_ross/interactive/index.php HTTP/1.1\nHost: gaia.cs.umass.edu\n(Press the carriage return twice after typing the last line.) This opens a TCP con -\nnection to port 80 of the host gaia.cs.umass.edu  and then sends the HTTP \nrequest message. You should see a response message that includes the base HTML \nfile for the interactive homework problems for this textbook. If you\u2019d rather just see \nthe HTTP message lines and not receive the object itself, replace GET with HEAD .\nIn this section we discussed a number of header lines that can be used within \nHTTP request and response messages. The HTTP specification defines many, \nmany more header lines that can be inserted by browsers, Web servers, and net -\nwork cache servers. We have covered only a small number of the totality of header \nlines. We\u2019ll cover a few more below and another small number when we discuss \nnetwork Web caching in Section 2.2.5. A highly readable and comprehensive version sp sp crlf\ncrlf header \ufb01eld name:\nHeader lines\nBlank line\nEntity bodyStatus line\nvalue\ncrsp\nsp lf\ncrlfheader \ufb01eld name: valuestatus code phrase\nFigure 2.9  \u2666 General format of an HTTP response message\nVideoNote\nUsing Wireshark to \ninvestigate the HTTP \nprotocol\n136     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\ndiscussion of the HTTP protocol, including its headers and status codes, is given \nin [Krishnamurthy 2001].\nHow does a browser decide which header lines to include in a request mes -\nsage? How does a Web server decide which header lines to include in a response \nmessage? A browser will generate header lines as a function of the browser type \nand version (for example, an HTTP/1.0 browser will not generate any 1.1 header \nlines), the user configuration of the browser (for example, preferred language), and \nwhether the browser currently has a cached, but possibly out-of-date, version of the \nobject. Web servers behave similarly: There are different products, versions, and \nconfigurations, all of which influence which header lines are included in response \nmessages.\n2.2.4 User-Server Interaction: Cookies\nWe mentioned above that an HTTP server is stateless. This simplifies server design \nand has permitted engineers to develop high-performance Web servers that can han -\ndle thousands of simultaneous TCP connections. However, it is often desirable for \na Web site to identify users, either because the server wishes to restrict user access \nor because it wants to serve content as a function of the user identity. For these pur -\nposes, HTTP uses cookies. Cookies, defined in [RFC 6265], allow sites to keep track \nof users. Most major commercial Web sites use cookies today.\nAs shown in Figure 2.10, cookie technology has four components: (1) a cookie \nheader line in the HTTP response message; (2) a cookie header line in the HTTP \nrequest message; (3) a cookie file kept on the user\u2019s end system and managed by \nthe user\u2019s browser; and (4) a back-end database at the Web site. Using Figure 2.10, \nlet\u2019s walk through an example of how cookies work. Suppose Susan, who always \naccesses the Web using Internet Explorer from her home PC, contacts Amazon.com \nfor the first time. Let us suppose that in the past she has already visited the eBay site. \nWhen the request comes into the Amazon Web server, the server creates a unique \nidentification number and creates an", "doc_id": "7294a5b5-ce6d-405e-bc37-029cdffe4483", "embedding": null, "doc_hash": "48658d708dc1f8099e5c1fbb8ca97176c6f368d25e05fca05a0706877c7dddfd", "extra_info": null, "node_info": {"start": 390754, "end": 394627}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "8c3480f6-714c-4fda-bd6f-0d4625a39233", "3": "e625afda-7a21-4300-9f49-9ce43e09b0c9"}}, "__type__": "1"}, "e625afda-7a21-4300-9f49-9ce43e09b0c9": {"__data__": {"text": "allow sites to keep track \nof users. Most major commercial Web sites use cookies today.\nAs shown in Figure 2.10, cookie technology has four components: (1) a cookie \nheader line in the HTTP response message; (2) a cookie header line in the HTTP \nrequest message; (3) a cookie file kept on the user\u2019s end system and managed by \nthe user\u2019s browser; and (4) a back-end database at the Web site. Using Figure 2.10, \nlet\u2019s walk through an example of how cookies work. Suppose Susan, who always \naccesses the Web using Internet Explorer from her home PC, contacts Amazon.com \nfor the first time. Let us suppose that in the past she has already visited the eBay site. \nWhen the request comes into the Amazon Web server, the server creates a unique \nidentification number and creates an entry in its back-end database that is indexed \nby the identification number. The Amazon Web server then responds to Susan\u2019s \nbrowser, including in the HTTP response a Set-cookie:  header, which contains \nthe identification number. For example, the header line might be:\nSet-cookie: 1678\nWhen Susan\u2019s browser receives the HTTP response message, it sees the  \nSet-cookie:  header. The browser then appends a line to the special cookie file \nthat it manages. This line includes the hostname of the server and the identification \nnumber in the Set-cookie:  header. Note that the cookie file already has an entry \nfor eBay, since Susan has visited that site in the past. As Susan continues to browse \nthe Amazon site, each time she requests a Web page, her browser consults her cookie \nfile, extracts her identification number for this site, and puts a cookie header line that \n2.2  \u2022  THE WEB AND HTTP      137\nincludes the identification number in the HTTP request. Specifically, each of her \nHTTP requests to the Amazon server includes the header line:\nCookie: 1678\nIn this manner, the Amazon server is able to track Susan\u2019s activity at the Amazon \nsite. Although the Amazon Web site does not necessarily know Susan\u2019s name, it \nknows exactly which pages user 1678 visited, in which order, and at what times! Client host Server host\nusual http request msg\nusual http response\nSet-cookie: 1678usual http request msg\ncookie: 1678\nusual http response msg\nusual http request msg\ncookie: 1678\nusual http response msg\nTimeOne week laterebay: 8734\nServer creates\nID 1678 for user\nTime\nCookie \ufb01leKey:amazon: 1678\nebay: 8734\namazon: 1678\nebay: 8734Cookie-speci\ufb01c\nactionaccess\naccessentry in backend\ndatabase\nCookie-speci\ufb01c\naction\nFigure 2.10  \u2666 Keeping user state with cookies\n138     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nAmazon uses cookies to provide its shopping cart service\u2014Amazon can maintain a \nlist of all of Susan\u2019s intended purchases, so that she can pay for them collectively at \nthe end of the session.\nIf Susan returns to Amazon\u2019s site, say, one week later, her browser will con -\ntinue to put the header line Cookie: 1678  in the request messages. Amazon also \nrecommends products to Susan based on Web pages she has visited at Amazon in \nthe past. If Susan also registers herself with Amazon\u2014providing full name, e-mail \naddress, postal address, and credit card information\u2014Amazon can then include this \ninformation in its database, thereby associating Susan\u2019s name with her identifica -\ntion number (and all of the pages she has visited at the site in the past!). This is how  \nAmazon and other e-commerce sites provide \u201cone-click shopping\u201d\u2014when Susan \nchooses to purchase an item during a subsequent visit, she doesn\u2019t need to re-enter \nher name, credit card number, or address.\nFrom this discussion we see that cookies can be used to identify a user. The first \ntime a user visits a site, the user can provide a user identification (possibly his or her \nname). During the subsequent sessions, the browser passes a cookie header to the \nserver, thereby", "doc_id": "e625afda-7a21-4300-9f49-9ce43e09b0c9", "embedding": null, "doc_hash": "babcf104df2b00d471da641a5e0b31ecebac1d8f668b51ddb284d36eb471fcd7", "extra_info": null, "node_info": {"start": 394553, "end": 398388}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "7294a5b5-ce6d-405e-bc37-029cdffe4483", "3": "2b4177df-5136-47c1-a9d1-802fb5db7586"}}, "__type__": "1"}, "2b4177df-5136-47c1-a9d1-802fb5db7586": {"__data__": {"text": "with Amazon\u2014providing full name, e-mail \naddress, postal address, and credit card information\u2014Amazon can then include this \ninformation in its database, thereby associating Susan\u2019s name with her identifica -\ntion number (and all of the pages she has visited at the site in the past!). This is how  \nAmazon and other e-commerce sites provide \u201cone-click shopping\u201d\u2014when Susan \nchooses to purchase an item during a subsequent visit, she doesn\u2019t need to re-enter \nher name, credit card number, or address.\nFrom this discussion we see that cookies can be used to identify a user. The first \ntime a user visits a site, the user can provide a user identification (possibly his or her \nname). During the subsequent sessions, the browser passes a cookie header to the \nserver, thereby identifying the user to the server. Cookies can thus be used to create \na user session layer on top of stateless HTTP. For example, when a user logs in to \na Web-based e-mail application (such as Hotmail), the browser sends cookie infor -\nmation to the server, permitting the server to identify the user throughout the user\u2019s \nsession with the application.\nAlthough cookies often simplify the Internet shopping experience for the user, \nthey are controversial because they can also be considered as an invasion of privacy. \nAs we just saw, using a combination of cookies and user-supplied account informa -\ntion, a Web site can learn a lot about a user and potentially sell this information to a \nthird party. Cookie Central [Cookie Central 2016] includes extensive information on \nthe cookie controversy.\n2.2.5 Web Caching\nA Web cache \u2014also called a proxy server \u2014is a network entity that satisfies HTTP \nrequests on the behalf of an origin Web server. The Web cache has its own disk \nstorage and keeps copies of recently requested objects in this storage. As shown in  \nFigure 2. 11, a user\u2019s browser can be configured so that all of the user\u2019s HTTP requests \nare first directed to the Web cache. Once a browser is configured, each browser request \nfor an object is first directed to the Web cache. As an example, suppose a browser \nis requesting the object http://www.someschool.edu/campus.gif .  \nHere is what happens:\n 1. The browser establishes a TCP connection to the Web cache and sends an HTTP \nrequest for the object to the Web cache.\n 2. The Web cache checks to see if it has a copy of the object stored locally. If it \ndoes, the Web cache returns the object within an HTTP response message to the \nclient browser.\n2.2  \u2022  THE WEB AND HTTP      139\n 3. If the Web cache does not have the object, the Web cache opens a TCP connec -\ntion to the origin server, that is, to www.someschool.edu . The Web cache \nthen sends an HTTP request for the object into the cache-to-server TCP connec -\ntion. After receiving this request, the origin server sends the object within an \nHTTP response to the Web cache.\n 4. When the Web cache receives the object, it stores a copy in its local storage and \nsends a copy, within an HTTP response message, to the client browser (over the \nexisting TCP connection between the client browser and the Web cache).\nNote that a cache is both a server and a client at the same time. When it receives \nrequests from and sends responses to a browser, it is a server. When it sends requests \nto and receives responses from an origin server, it is a client.\nTypically a Web cache is purchased and installed by an ISP. For example, a uni -\nversity might install a cache on its campus network and configure all of the campus \nbrowsers to point to the cache. Or a major residential ISP (such as Comcast) might \ninstall one or more caches in its network and preconfigure its shipped browsers to \npoint to the installed caches.\nWeb caching has seen deployment in the Internet for two reasons. First, a Web \ncache can substantially reduce the response time for a client request, particularly if \nthe bottleneck bandwidth between the client and the origin server is much less than \nthe bottleneck", "doc_id": "2b4177df-5136-47c1-a9d1-802fb5db7586", "embedding": null, "doc_hash": "8ae801a324b92d54e1f1c224f3a35cb265931ce99a1b0945f7046ae64b9a971e", "extra_info": null, "node_info": {"start": 398383, "end": 402375}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "e625afda-7a21-4300-9f49-9ce43e09b0c9", "3": "baca0481-1f9f-4e6a-8ae3-aab998cdc2d6"}}, "__type__": "1"}, "baca0481-1f9f-4e6a-8ae3-aab998cdc2d6": {"__data__": {"text": "When it receives \nrequests from and sends responses to a browser, it is a server. When it sends requests \nto and receives responses from an origin server, it is a client.\nTypically a Web cache is purchased and installed by an ISP. For example, a uni -\nversity might install a cache on its campus network and configure all of the campus \nbrowsers to point to the cache. Or a major residential ISP (such as Comcast) might \ninstall one or more caches in its network and preconfigure its shipped browsers to \npoint to the installed caches.\nWeb caching has seen deployment in the Internet for two reasons. First, a Web \ncache can substantially reduce the response time for a client request, particularly if \nthe bottleneck bandwidth between the client and the origin server is much less than \nthe bottleneck bandwidth between the client and the cache. If there is a high-speed \nconnection between the client and the cache, as there often is, and if the cache has \nthe requested object, then the cache will be able to deliver the object rapidly to the \nclient. Second, as we will soon illustrate with an example, Web caches can sub -\nstantially reduce traffic on an institution\u2019s access link to the Internet. By reducing \ntraffic, the institution (for example, a company or a university) does not have to HTTP request\nHTTP responseHTTP request\nHTTP responseHTTP request\nHTTP response\nHTTP request\nHTTP responseClient\nOrigin\nserver\nOrigin\nserverClientProxy\nserver\nFigure 2.11  \u2666 Clients requesting objects through a Web cache\n140     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nupgrade bandwidth as quickly, thereby reducing costs. Furthermore, Web caches \ncan substantially reduce Web traffic in the Internet as a whole, thereby improving \nperformance for all applications.\nTo gain a deeper understanding of the benefits of caches, let\u2019s consider an exam -\nple in the context of Figure 2.12. This figure shows two networks\u2014the institutional \nnetwork and the rest of the public Internet. The institutional network is a high-speed \nLAN. A router in the institutional network and a router in the Internet are connected \nby a 15 Mbps link. The origin servers are attached to the Internet but are located all \nover the globe. Suppose that the average object size is 1 Mbits and that the average \nrequest rate from the institution\u2019s browsers to the origin servers is 15 requests per \nsecond. Suppose that the HTTP request messages are negligibly small and thus cre -\nate no traffic in the networks or in the access link (from institutional router to Internet \nrouter). Also suppose that the amount of time it takes from when the router on the \nInternet side of the access link in Figure 2.12 forwards an HTTP request (within an \nIP datagram) until it receives the response (typically within many IP datagrams) is \ntwo seconds on average. Informally, we refer to this last delay as the \u201cInternet delay.\u201d\nPublic Inter net\nInstitutional network15 Mbps access link\n100 Mbps LANOrigin servers\nFigure 2.12  \u2666 Bottleneck between an institutional network and the Internet\n2.2  \u2022  THE WEB AND HTTP      141\nThe total response time\u2014that is, the time from the browser\u2019s request of an \nobject until its receipt of the object\u2014is the sum of the LAN delay, the access delay \n(that is, the delay between the two routers), and the Internet delay. Let\u2019s now do \na very crude calculation to estimate this delay. The traffic intensity on the LAN  \n(see Section 1.4.2) is\n(15 requests/sec) #(1 Mbits/request)/(100 Mbps) =0.15\nwhereas the traffic intensity on the access link (from the Internet router to institution \nrouter) is\n(15 requests/sec) #(1 Mbits/request)/(15 Mbps) =1\nA traffic intensity of 0.15 on a LAN typically results in, at most, tens of millisec -\nonds of delay; hence, we can neglect the LAN delay. However, as discussed in \nSection 1.4.2, as the traffic intensity approaches 1 (as is the case of the", "doc_id": "baca0481-1f9f-4e6a-8ae3-aab998cdc2d6", "embedding": null, "doc_hash": "6cd403cf173937a65ee33c88d590c5d90b060582c91676b3d2dd28901534a059", "extra_info": null, "node_info": {"start": 402360, "end": 406236}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "2b4177df-5136-47c1-a9d1-802fb5db7586", "3": "c862e8c6-0ac1-42ec-a7f0-d8e249bfe0ee"}}, "__type__": "1"}, "c862e8c6-0ac1-42ec-a7f0-d8e249bfe0ee": {"__data__": {"text": "the access delay \n(that is, the delay between the two routers), and the Internet delay. Let\u2019s now do \na very crude calculation to estimate this delay. The traffic intensity on the LAN  \n(see Section 1.4.2) is\n(15 requests/sec) #(1 Mbits/request)/(100 Mbps) =0.15\nwhereas the traffic intensity on the access link (from the Internet router to institution \nrouter) is\n(15 requests/sec) #(1 Mbits/request)/(15 Mbps) =1\nA traffic intensity of 0.15 on a LAN typically results in, at most, tens of millisec -\nonds of delay; hence, we can neglect the LAN delay. However, as discussed in \nSection 1.4.2, as the traffic intensity approaches 1 (as is the case of the access link \nin Figure 2.12), the delay on a link becomes very large and grows without bound. \nThus, the average response time to satisfy requests is going to be on the order of \nminutes, if not more, which is unacceptable for the institution\u2019s users. Clearly \nsomething must be done.\nOne possible solution is to increase the access rate from 15 Mbps to, say, 100 \nMbps. This will lower the traffic intensity on the access link to 0.15, which translates \nto negligible delays between the two routers. In this case, the total response time \nwill roughly be two seconds, that is, the Internet delay. But this solution also means \nthat the institution must upgrade its access link from 15 Mbps to 100 Mbps, a costly \nproposition.\nNow consider the alternative solution of not upgrading the access link but \ninstead installing a Web cache in the institutional network. This solution is illustrated \nin Figure 2.13. Hit rates\u2014the fraction of requests that are satisfied by a cache\u2014  \ntypically range from 0.2 to 0.7 in practice. For illustrative purposes, let\u2019s suppose \nthat the cache provides a hit rate of 0.4 for this institution. Because the clients and \nthe cache are connected to the same high-speed LAN, 40 percent of the requests will \nbe satisfied almost immediately, say, within 10 milliseconds, by the cache. Neverthe -\nless, the remaining 60 percent of the requests still need to be satisfied by the origin \nservers. But with only 60 percent of the requested objects passing through the access \nlink, the traffic intensity on the access link is reduced from 1.0 to 0.6. Typically, a \ntraffic intensity less than 0.8 corresponds to a small delay, say, tens of milliseconds, \non a 15 Mbps link. This delay is negligible compared with the two-second Internet \ndelay. Given these considerations, average delay therefore is\n0.4#(0.01 seconds) +0.6#(2.01 seconds)\nwhich is just slightly greater than 1.2 seconds. Thus, this second solution provides an \neven lower response time than the first solution, and it doesn\u2019t require the institution \n142     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nto upgrade its link to the Internet. The institution does, of course, have to purchase \nand install a Web cache. But this cost is low\u2014many caches use public-domain soft -\nware that runs on inexpensive PCs.\nThrough the use of Content Distribution Networks (CDNs) , Web caches are \nincreasingly playing an important role in the Internet. A CDN company installs many \ngeographically distributed caches throughout the Internet, thereby localizing much of \nthe traffic. There are shared CDNs (such as Akamai and Limelight) and dedicated CDNs \n(such as Google and Netflix). We will discuss CDNs in more detail in Section 2.6.\nThe Conditional GET\nAlthough caching can reduce user-perceived response times, it introduces a new \nproblem\u2014the copy of an object residing in the cache may be stale. In other words, \nthe object housed in the Web server may have been modified since the copy was \ncached at the client. Fortunately, HTTP has a mechanism that allows a cache to Public Inter net\nInstitutional network15 Mbps access link\nInstitutional\ncache100 Mbps LANOrigin servers\nFigure", "doc_id": "c862e8c6-0ac1-42ec-a7f0-d8e249bfe0ee", "embedding": null, "doc_hash": "82a1660f7119f511a23604ac57a3753155dcb9c8e655c23d531fa68e321d106b", "extra_info": null, "node_info": {"start": 406353, "end": 410167}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "baca0481-1f9f-4e6a-8ae3-aab998cdc2d6", "3": "f88acf6b-1ee2-4bd7-8acc-e3617274792e"}}, "__type__": "1"}, "f88acf6b-1ee2-4bd7-8acc-e3617274792e": {"__data__": {"text": "(CDNs) , Web caches are \nincreasingly playing an important role in the Internet. A CDN company installs many \ngeographically distributed caches throughout the Internet, thereby localizing much of \nthe traffic. There are shared CDNs (such as Akamai and Limelight) and dedicated CDNs \n(such as Google and Netflix). We will discuss CDNs in more detail in Section 2.6.\nThe Conditional GET\nAlthough caching can reduce user-perceived response times, it introduces a new \nproblem\u2014the copy of an object residing in the cache may be stale. In other words, \nthe object housed in the Web server may have been modified since the copy was \ncached at the client. Fortunately, HTTP has a mechanism that allows a cache to Public Inter net\nInstitutional network15 Mbps access link\nInstitutional\ncache100 Mbps LANOrigin servers\nFigure 2.13  \u2666 Adding a cache to the institutional network\n2.2  \u2022  THE WEB AND HTTP      143\nverify that its objects are up to date. This mechanism is called the conditional \nGET . An HTTP request message is a so-called conditional GET message if (1) \nthe request message uses the GET method and (2) the request message includes an  \nIf-Modified-Since:  header line.\nTo illustrate how the conditional GET operates, let\u2019s walk through an example. \nFirst, on the behalf of a requesting browser, a proxy cache sends a request message \nto a Web server:\nGET /fruit/kiwi.gif HTTP/1.1\nHost: www.exotiquecuisine.com\nSecond, the Web server sends a response message with the requested object to the \ncache:\nHTTP/1.1 200 OK\nDate: Sat, 3 Oct 2015 15:39:29\nServer: Apache/1.3.0 (Unix)\nLast-Modified: Wed, 9 Sep 2015 09:23:24\nContent-Type: image/gif\u00a0\n(data data data data data ...)\nThe cache forwards the object to the requesting browser but also caches the object \nlocally. Importantly, the cache also stores the last-modified date along with the \nobject. Third, one week later, another browser requests the same object via the cache, \nand the object is still in the cache. Since this object may have been modified at the \nWeb server in the past week, the cache performs an up-to-date check by issuing a \nconditional GET. Specifically, the cache sends:\nGET /fruit/kiwi.gif HTTP/1.1\nHost: www.exotiquecuisine.com\nIf-modified-since: Wed, 9 Sep 2015 09:23:24\nNote that the value of the If-modified-since:  header line is exactly equal \nto the value of the Last-Modified:  header line that was sent by the server one \nweek ago. This conditional GET is telling the server to send the object only if the \nobject has been modified since the specified date. Suppose the object has not been \nmodified since 9 Sep 2015 09:23:24. Then, fourth, the Web server sends a response \nmessage to the cache:\nHTTP/1.1 304 Not Modified\nDate: Sat, 10 Oct 2015 15:39:29\nServer: Apache/1.3.0 (Unix)\u00a0\n(empty entity body)\n144     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nWe see that in response to the conditional GET, the Web server still sends a \nresponse message but does not include the requested object in the response message.  \nIncluding the requested object would only waste bandwidth and increase user-  \nperceived response time, particularly if the object is large. Note that this last response \nmessage has 304 Not Modified  in the status line, which tells the cache that it \ncan go ahead and forward its (the proxy cache\u2019s) cached copy of the object to the \nrequesting browser.\nThis ends our discussion of HTTP, the first Internet protocol (an application-\nlayer protocol) that we\u2019ve studied in detail. We\u2019ve seen the format of HTTP mes -\nsages and the actions taken by the Web client and server as these messages are \nsent and received. We\u2019ve also studied a bit of the Web\u2019s application infrastructure, \nincluding caches, cookies, and back-end databases, all of which are tied in", "doc_id": "f88acf6b-1ee2-4bd7-8acc-e3617274792e", "embedding": null, "doc_hash": "975d3db250c3203ae581f0688737d5deb34cab8a189eb76dfeff6fdc1dbe10aa", "extra_info": null, "node_info": {"start": 410025, "end": 413781}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "c862e8c6-0ac1-42ec-a7f0-d8e249bfe0ee", "3": "1b2b1f92-464f-4c7c-9d24-1c16fa34e359"}}, "__type__": "1"}, "1b2b1f92-464f-4c7c-9d24-1c16fa34e359": {"__data__": {"text": "in the response message.  \nIncluding the requested object would only waste bandwidth and increase user-  \nperceived response time, particularly if the object is large. Note that this last response \nmessage has 304 Not Modified  in the status line, which tells the cache that it \ncan go ahead and forward its (the proxy cache\u2019s) cached copy of the object to the \nrequesting browser.\nThis ends our discussion of HTTP, the first Internet protocol (an application-\nlayer protocol) that we\u2019ve studied in detail. We\u2019ve seen the format of HTTP mes -\nsages and the actions taken by the Web client and server as these messages are \nsent and received. We\u2019ve also studied a bit of the Web\u2019s application infrastructure, \nincluding caches, cookies, and back-end databases, all of which are tied in some way \nto the HTTP protocol.\n2.3 Electronic Mail in the Internet\nElectronic mail has been around since the beginning of the Internet. It was the most \npopular application when the Internet was in its infancy [Segaller 1998], and has \nbecome more elaborate and powerful over the years. It remains one of the Internet\u2019s \nmost important and utilized applications.\nAs with ordinary postal mail, e-mail is an asynchronous communication \nmedium\u2014people send and read messages when it is convenient for them, without \nhaving to coordinate with other people\u2019s schedules. In contrast with postal mail, \nelectronic mail is fast, easy to distribute, and inexpensive. Modern e-mail has \nmany powerful features, including messages with attachments, hyperlinks, HTML-  \nformatted text, and embedded photos.\nIn this section, we examine the application-layer protocols that are at the heart \nof Internet e-mail. But before we jump into an in-depth discussion of these protocols, \nlet\u2019s take a high-level view of the Internet mail system and its key components.\nFigure 2. 14 presents a high-level view of the Internet mail system. We see from \nthis diagram that it has three major components: user agents , mail servers , and the \nSimple Mail Transfer Protocol (SMTP) . We now describe each of these compo -\nnents in the context of a sender, Alice, sending an e-mail message to a recipient, \nBob. User agents allow users to read, reply to, forward, save, and compose mes -\nsages. Microsoft Outlook and Apple Mail are examples of user agents for e-mail. \nWhen Alice is finished composing her message, her user agent sends the message to \nher mail server, where the message is placed in the mail server\u2019s outgoing message \nqueue. When Bob wants to read a message, his user agent retrieves the message from \nhis mailbox in his mail server.\nMail servers form the core of the e-mail infrastructure. Each recipient, such as \nBob, has a mailbox  located in one of the mail servers. Bob\u2019s mailbox manages and \n2.3  \u2022  ELECTRONIC MAIL IN THE INTERNET      145\nmaintains the messages that have been sent to him. A typical message starts its jour -\nney in the sender\u2019s user agent, travels to the sender\u2019s mail server, and travels to the \nrecipient\u2019s mail server, where it is deposited in the recipient\u2019s mailbox. When Bob \nwants to access the messages in his mailbox, the mail server containing his mailbox \nauthenticates Bob (with usernames and passwords). Alice\u2019s mail server must also \ndeal with failures in Bob\u2019s mail server. If Alice\u2019s server cannot deliver mail to Bob\u2019s \nserver, Alice\u2019s server holds the message in a message queue  and attempts to transfer \nthe message later. Reattempts are often done every 30 minutes or so; if there is no \nsuccess after several days, the server removes the message and notifies the sender \n(Alice) with an e-mail message.\nSMTP is the principal application-layer protocol for Internet electronic mail. It \nuses the reliable data transfer service of TCP to transfer mail from the sender\u2019s mail \nserver to the recipient\u2019s mail server. As with most application-layer protocols,", "doc_id": "1b2b1f92-464f-4c7c-9d24-1c16fa34e359", "embedding": null, "doc_hash": "453e76896d8c05f86c36728dde2ad836654da3b07408283dd17780d5483afca9", "extra_info": null, "node_info": {"start": 413820, "end": 417696}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "f88acf6b-1ee2-4bd7-8acc-e3617274792e", "3": "75c77758-5db0-4f99-be80-f4f6545c78f2"}}, "__type__": "1"}, "75c77758-5db0-4f99-be80-f4f6545c78f2": {"__data__": {"text": "mailbox, the mail server containing his mailbox \nauthenticates Bob (with usernames and passwords). Alice\u2019s mail server must also \ndeal with failures in Bob\u2019s mail server. If Alice\u2019s server cannot deliver mail to Bob\u2019s \nserver, Alice\u2019s server holds the message in a message queue  and attempts to transfer \nthe message later. Reattempts are often done every 30 minutes or so; if there is no \nsuccess after several days, the server removes the message and notifies the sender \n(Alice) with an e-mail message.\nSMTP is the principal application-layer protocol for Internet electronic mail. It \nuses the reliable data transfer service of TCP to transfer mail from the sender\u2019s mail \nserver to the recipient\u2019s mail server. As with most application-layer protocols, SMTP Outgoing\nmessa ge queue Key:\nUser mailboxSMTPUser agent\nUser agentUser agent\nUser agent\nUser agent\nUser agentMail server\nMail serverMail serverSMTP\nSMTP\nFigure 2.14  \u2666 A high-level view of the Internet e-mail system\n146     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nhas two sides: a client side, which executes on the sender\u2019s mail server, and a server \nside, which executes on the recipient\u2019s mail server. Both the client and server sides of \nSMTP run on every mail server. When a mail server sends mail to other mail servers, \nit acts as an SMTP client. When a mail server receives mail from other mail servers, \nit acts as an SMTP server.\n2.3.1  SMTP\nSMTP, defined in RFC 5321, is at the heart of Internet electronic mail. As men -\ntioned above, SMTP transfers messages from senders\u2019 mail servers to the recipients\u2019 \nmail servers. SMTP is much older than HTTP. (The original SMTP RFC dates back \nto 1982, and SMTP was around long before that.) Although SMTP has numerous \nwonderful qualities, as evidenced by its ubiquity in the Internet, it is nevertheless \na legacy technology that possesses certain archaic characteristics. For example, it \nrestricts the body (not just the headers) of all mail messages to simple 7-bit ASCII. \nThis restriction made sense in the early 1980s when transmission capacity was scarce \nand no one was e-mailing large attachments or large image, audio, or video files. But \ntoday, in the multimedia era, the 7-bit ASCII restriction is a bit of a pain\u2014it requires \nbinary multimedia data to be encoded to ASCII before being sent over SMTP; and it \nrequires the corresponding ASCII message to be decoded back to binary after SMTP \ntransport. Recall from Section 2.2 that HTTP does not require multimedia data to be \nASCII encoded before transfer.\nTo illustrate the basic operation of SMTP, let\u2019s walk through a common sce -\nnario. Suppose Alice wants to send Bob a simple ASCII message.\n 1. Alice invokes her user agent for e-mail, provides Bob\u2019s e-mail address (for \nexample, bob@someschool.edu ), composes a message, and instructs the \nuser agent to send the message.\n 2. Alice\u2019s user agent sends the message to her mail server, where it is placed in a \nmessage queue.\n 3. The client side of SMTP, running on Alice\u2019s mail server, sees the message in the \nmessage queue. It opens a TCP connection to an SMTP server, running on Bob\u2019s \nmail server.\n 4. After some initial SMTP handshaking, the SMTP client sends Alice\u2019s message \ninto the TCP connection.\n 5. At Bob\u2019s mail server, the server side of SMTP receives the message. Bob\u2019s mail \nserver then places the message in Bob\u2019s mailbox.\n 6. Bob invokes his user agent to read the message at his convenience.\nThe scenario is summarized in Figure 2.15.\nIt is important to observe that SMTP does not normally use intermediate mail serv -\ners for sending mail, even when the two mail servers are located at opposite ends of \nthe world. If", "doc_id": "75c77758-5db0-4f99-be80-f4f6545c78f2", "embedding": null, "doc_hash": "ac5e1a91a184fe08e7d716a39f80a4564496afa2f04687b70a27821bb8ed9d5a", "extra_info": null, "node_info": {"start": 417712, "end": 421383}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "1b2b1f92-464f-4c7c-9d24-1c16fa34e359", "3": "0cb0f0ca-c0d0-4d8a-8158-071ed394dcec"}}, "__type__": "1"}, "0cb0f0ca-c0d0-4d8a-8158-071ed394dcec": {"__data__": {"text": "client side of SMTP, running on Alice\u2019s mail server, sees the message in the \nmessage queue. It opens a TCP connection to an SMTP server, running on Bob\u2019s \nmail server.\n 4. After some initial SMTP handshaking, the SMTP client sends Alice\u2019s message \ninto the TCP connection.\n 5. At Bob\u2019s mail server, the server side of SMTP receives the message. Bob\u2019s mail \nserver then places the message in Bob\u2019s mailbox.\n 6. Bob invokes his user agent to read the message at his convenience.\nThe scenario is summarized in Figure 2.15.\nIt is important to observe that SMTP does not normally use intermediate mail serv -\ners for sending mail, even when the two mail servers are located at opposite ends of \nthe world. If Alice\u2019s server is in Hong Kong and Bob\u2019s server is in St. Louis, the TCP \n2.3  \u2022  ELECTRONIC MAIL IN THE INTERNET      147\nconnection is a direct connection between the Hong Kong and St. Louis servers. In \nparticular, if Bob\u2019s mail server is down, the message remains in Alice\u2019s mail server and \nwaits for a new attempt\u2014the message does not get placed in some intermediate mail \nserver.\nLet\u2019s now take a closer look at how SMTP transfers a message from a sending mail \nserver to a receiving mail server. We will see that the SMTP protocol has many simi -\nlarities with protocols that are used for face-to-face human interaction. First, the client \nSMTP (running on the sending mail server host) has TCP establish a connection to port \n25 at the server SMTP (running on the receiving mail server host). If the server is down, \nthe client tries again later. Once this connection is established, the server and client per -\nform some application-layer handshaking\u2014just as humans often introduce themselves \nbefore transferring information from one to another, SMTP clients and servers intro -\nduce themselves before transferring information. During this SMTP handshaking phase,  \nthe SMTP client indicates the e-mail address of the sender (the person who generated \nthe message) and the e-mail address of the recipient. Once the SMTP client and server \nhave introduced themselves to each other, the client sends the message. SMTP can \ncount on the reliable data transfer service of TCP to get the message to the server with -\nout errors. The client then repeats this process over the same TCP connection if it has \nother messages to send to the server; otherwise, it instructs TCP to close the connection.\nLet\u2019s next take a look at an example transcript of messages exchanged between an \nSMTP client (C) and an SMTP server (S). The hostname of the client is crepes.fr   \nand the hostname of the server is hamburger.edu . The ASCII text lines prefaced \nwith C: are exactly the lines the client sends into its TCP socket, and the ASCII text \nlines prefaced with S: are exactly the lines the server sends into its TCP socket. The \nfollowing transcript begins as soon as the TCP connection is established.\nS:\u00a0\u00a0220 hamburger.edu\nC:\u00a0\u00a0HELO crepes.frSMTPAlice\u2019 s\nmail serverBob\u2019s\nmail server\nAlice\u2019 s\nagentBob\u2019s\nagent1\n2 4 6\n5\nMessage queue Key:\nUser mailbox3\nFigure 2.15  \u2666 Alice sends a message to Bob\n148     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nS:\u00a0\u00a0250 Hello crepes.fr, pleased to meet you\nC:\u00a0\u00a0MAIL FROM: <alice@crepes.fr>\nS:\u00a0\u00a0250 alice@crepes.fr ... Sender ok\nC:\u00a0\u00a0RCPT TO: <bob@hamburger.edu>\nS:\u00a0\u00a0250 bob@hamburger.edu ... Recipient ok\nC:\u00a0\u00a0DATA\nS:\u00a0\u00a0354 Enter mail, end with \u201d.\u201d on a line by itself\nC:\u00a0\u00a0Do you like ketchup?\nC:\u00a0\u00a0How about", "doc_id": "0cb0f0ca-c0d0-4d8a-8158-071ed394dcec", "embedding": null, "doc_hash": "294a231ed821ff60b27895684ece710adf27e3fc30857bbfe8e8e2fc86d9e1ae", "extra_info": null, "node_info": {"start": 421440, "end": 424873}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "75c77758-5db0-4f99-be80-f4f6545c78f2", "3": "e6c04656-69e4-4498-a122-f28d359bde54"}}, "__type__": "1"}, "e6c04656-69e4-4498-a122-f28d359bde54": {"__data__": {"text": "s\nagentBob\u2019s\nagent1\n2 4 6\n5\nMessage queue Key:\nUser mailbox3\nFigure 2.15  \u2666 Alice sends a message to Bob\n148     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nS:\u00a0\u00a0250 Hello crepes.fr, pleased to meet you\nC:\u00a0\u00a0MAIL FROM: <alice@crepes.fr>\nS:\u00a0\u00a0250 alice@crepes.fr ... Sender ok\nC:\u00a0\u00a0RCPT TO: <bob@hamburger.edu>\nS:\u00a0\u00a0250 bob@hamburger.edu ... Recipient ok\nC:\u00a0\u00a0DATA\nS:\u00a0\u00a0354 Enter mail, end with \u201d.\u201d on a line by itself\nC:\u00a0\u00a0Do you like ketchup?\nC:\u00a0\u00a0How about pickles?\nC:\u00a0\u00a0.\nS:\u00a0\u00a0250 Message accepted for delivery\nC:\u00a0\u00a0QUIT\nS:\u00a0\u00a0221 hamburger.edu closing connection\nIn the example above, the client sends a message (\u201c Do you like ketchup? \nHow about pickles? \u201d) from mail server crepes.fr  to mail server  \nhamburger.edu . As part of the dialogue, the client issued five commands: \nHELO  (an abbreviation for HELLO), MAIL FROM , RCPT TO , DATA , and QUIT . \nThese commands are self-explanatory. The client also sends a line consisting of a \nsingle period, which indicates the end of the message to the server. (In ASCII jar -\ngon, each message ends with CRLF.CRLF , where CR and LF stand for carriage \nreturn and line feed, respectively.) The server issues replies to each command, \nwith each reply having a reply code and some (optional) English-language expla -\nnation. We mention here that SMTP uses persistent connections: If the sending \nmail server has several messages to send to the same receiving mail server, it can \nsend all of the messages over the same TCP connection. For each message, the \nclient begins the process with a new MAIL FROM: crepes.fr , designates the \nend of message with an isolated period, and issues QUIT  only after all messages \nhave been sent.\nIt is highly recommended that you use Telnet to carry out a direct dialogue with \nan SMTP server. To do this, issue\ntelnet serverName 25\nwhere serverName  is the name of a local mail server. When you do this, you are \nsimply establishing a TCP connection between your local host and the mail server. \nAfter typing this line, you should immediately receive the 220 reply from the \nserver. Then issue the SMTP commands HELO , MAIL FROM , RCPT TO , DATA , \nCRLF.CRLF , and QUIT  at the appropriate times. It is also highly recommended \nthat you do Programming Assignment 3 at the end of this chapter. In that assign -\nment, you\u2019ll build a simple user agent that implements the client side of SMTP. It \nwill allow you to send an e-mail message to an arbitrary recipient via a local mail \nserver.\n2.3  \u2022  ELECTRONIC MAIL IN THE INTERNET      149\n2.3.2  Comparison with HTTP\nLet\u2019s now briefly compare SMTP with HTTP. Both protocols are used to transfer \nfiles from one host to another: HTTP transfers files (also called objects) from a Web \nserver to a Web client (typically a browser); SMTP transfers files (that is, e-mail \nmessages) from one mail server to another mail server. When transferring the files, \nboth persistent HTTP and SMTP use persistent connections. Thus, the two protocols \nhave common characteristics. However, there are important differences. First, HTTP \nis mainly a pull protocol \u2014someone loads information on a Web server and users \nuse HTTP to pull the information from the server at their convenience. In particular, \nthe TCP connection is initiated by the machine that wants to receive the file. On the \nother hand, SMTP is primarily a push protocol \u2014the sending mail server pushes  \nthe file to the receiving mail server. In particular, the TCP connection is", "doc_id": "e6c04656-69e4-4498-a122-f28d359bde54", "embedding": null, "doc_hash": "a9c3e135565d34c17c1d60a93b3eac9a85da9eaf78d00c1532f85fc9a25d2201", "extra_info": null, "node_info": {"start": 425075, "end": 428513}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "0cb0f0ca-c0d0-4d8a-8158-071ed394dcec", "3": "da036ab2-5737-44c9-a823-dcda4355dcdb"}}, "__type__": "1"}, "da036ab2-5737-44c9-a823-dcda4355dcdb": {"__data__": {"text": "to another: HTTP transfers files (also called objects) from a Web \nserver to a Web client (typically a browser); SMTP transfers files (that is, e-mail \nmessages) from one mail server to another mail server. When transferring the files, \nboth persistent HTTP and SMTP use persistent connections. Thus, the two protocols \nhave common characteristics. However, there are important differences. First, HTTP \nis mainly a pull protocol \u2014someone loads information on a Web server and users \nuse HTTP to pull the information from the server at their convenience. In particular, \nthe TCP connection is initiated by the machine that wants to receive the file. On the \nother hand, SMTP is primarily a push protocol \u2014the sending mail server pushes  \nthe file to the receiving mail server. In particular, the TCP connection is initiated by \nthe machine that wants to send the file.\nA second difference, which we alluded to earlier, is that SMTP requires each \nmessage, including the body of each message, to be in 7-bit ASCII format. If the \nmessage contains characters that are not 7-bit ASCII (for example, French characters \nwith accents) or contains binary data (such as an image file), then the message has to \nbe encoded into 7-bit ASCII. HTTP data does not impose this restriction.\nA third important difference concerns how a document consisting of text \nand images (along with possibly other media types) is handled. As we learned in  \nSection 2. 2, HTTP encapsulates each object in its own HTTP response message. \nSMTP places all of the message\u2019s objects into one message.\n2.3.3  Mail Message Formats\nWhen Alice writes an ordinary snail-mail letter to Bob, she may include all kinds \nof peripheral header information at the top of the letter, such as Bob\u2019s address, her \nown return address, and the date. Similarly, when an e-mail message is sent from \none person to another, a header containing peripheral information precedes the \nbody of the message itself. This peripheral information is contained in a series of \nheader lines, which are defined in RFC 532 2. The header lines and the body of the \nmessage are separated by a blank line (that is, by CRLF ). RFC 5322 specifies the \nexact format for mail header lines as well as their semantic interpretations. As with \nHTTP, each header line contains readable text, consisting of a keyword followed \nby a colon followed by a value. Some of the keywords are required and others are \noptional. Every header must have a From:  header line and a To: header line; \na header may include a Subject:  header line as well as other optional header \nlines. It is important to note that these header lines are different  from the SMTP \ncommands we studied in Section 2.4.1 (even though they contain some common \nwords such as \u201c from \u201d and \u201c to\u201d). The commands in that section were part of the \nSMTP handshaking protocol; the header lines examined in this section are part of \nthe mail message itself.\n150     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nA typical message header looks like this:\nFrom: alice@crepes.fr\nTo: bob@hamburger.edu\nSubject: Searching for the meaning of life.\nAfter the message header, a blank line follows; then the message body (in ASCII) \nfollows. You should use Telnet to send a message to a mail server that contains \nsome header lines, including the Subject:  header line. To do this, issue telnet \nserverName 25,  as discussed in Section 2.4.1.\n2.3.4  Mail Access Protocols\nOnce SMTP delivers the message from Alice\u2019s mail server to Bob\u2019s mail server, \nthe message is placed in Bob\u2019s mailbox. Throughout this discussion we have tacitly \nassumed that Bob reads his mail by logging onto the server host and then executing a \nmail reader that runs on that host. Up until the early 1990s this was the standard way \nof doing things. But today, mail access uses a client-server architecture\u2014the typical \nuser reads e-mail with a client that executes on the user\u2019s end system, for", "doc_id": "da036ab2-5737-44c9-a823-dcda4355dcdb", "embedding": null, "doc_hash": "a59c684f4e0e72ffdbf0a15d90c281ff1ca29bccf091b445b97b684e221dbd6a", "extra_info": null, "node_info": {"start": 428215, "end": 432146}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "e6c04656-69e4-4498-a122-f28d359bde54", "3": "0a66faa1-9327-4ebc-bd93-9a59d806cc87"}}, "__type__": "1"}, "0a66faa1-9327-4ebc-bd93-9a59d806cc87": {"__data__": {"text": "\nfollows. You should use Telnet to send a message to a mail server that contains \nsome header lines, including the Subject:  header line. To do this, issue telnet \nserverName 25,  as discussed in Section 2.4.1.\n2.3.4  Mail Access Protocols\nOnce SMTP delivers the message from Alice\u2019s mail server to Bob\u2019s mail server, \nthe message is placed in Bob\u2019s mailbox. Throughout this discussion we have tacitly \nassumed that Bob reads his mail by logging onto the server host and then executing a \nmail reader that runs on that host. Up until the early 1990s this was the standard way \nof doing things. But today, mail access uses a client-server architecture\u2014the typical \nuser reads e-mail with a client that executes on the user\u2019s end system, for example, \non an office PC, a laptop, or a smartphone. By executing a mail client on a local PC, \nusers enjoy a rich set of features, including the ability to view multimedia messages \nand attachments.\nGiven that Bob (the recipient) executes his user agent on his local PC, it is natural \nto consider placing a mail server on his local PC as well. With this approach, Alice\u2019s \nmail server would dialogue directly with Bob\u2019s PC. There is a problem with this \napproach, however. Recall that a mail server manages mailboxes and runs the client \nand server sides of SMTP. If Bob\u2019s mail server were to reside on his local PC, then \nBob\u2019s PC would have to remain always on, and connected to the Internet, in order to \nreceive new mail, which can arrive at any time. This is impractical for many Internet \nusers. Instead, a typical user runs a user agent on the local PC but accesses its mailbox \nstored on an always-on shared mail server. This mail server is shared with other users \nand is typically maintained by the user\u2019s ISP (for example, university or company).\nNow let\u2019s consider the path an e-mail message takes when it is sent from Alice \nto Bob. We just learned that at some point along the path the e-mail message needs \nto be deposited in Bob\u2019s mail server. This could be done simply by having Alice\u2019s \nuser agent send the message directly to Bob\u2019s mail server. And this could be done \nwith SMTP\u2014indeed, SMTP has been designed for pushing e-mail from one host to \nanother. However, typically the sender\u2019s user agent does not dialogue directly with \nthe recipient\u2019s mail server. Instead, as shown in Figure 2.16, Alice\u2019s user agent uses \nSMTP to push the e-mail message into her mail server, then Alice\u2019s mail server uses \nSMTP (as an SMTP client) to relay the e-mail message to Bob\u2019s mail server. Why \nthe two-step procedure? Primarily because without relaying through Alice\u2019s mail \nserver, Alice\u2019s user agent doesn\u2019t have any recourse to an unreachable destination \n2.3  \u2022  ELECTRONIC MAIL IN THE INTERNET      151\nmail server. By having Alice first deposit the e-mail in her own mail server, Alice\u2019s \nmail server can repeatedly try to send the message to Bob\u2019s mail server, say every \n30 minutes, until Bob\u2019s mail server becomes operational. (And if Alice\u2019s mail server \nis down, then she has the recourse of complaining to her system administrator!) The \nSMTP RFC defines how the SMTP commands can be used to relay a message across \nmultiple SMTP servers.\nBut there is still one missing piece to the puzzle! How does a recipient like Bob, \nrunning a user agent on his local PC, obtain his messages, which are sitting in a mail \nserver within Bob\u2019s ISP? Note that Bob\u2019s user agent can\u2019t use SMTP to obtain the \nmessages because obtaining the messages is a pull operation, whereas SMTP is a \npush protocol. The puzzle is completed by introducing a special mail access protocol \nthat transfers messages from Bob\u2019s mail server to his local PC. There are currently a \nnumber of popular mail access protocols, including Post", "doc_id": "0a66faa1-9327-4ebc-bd93-9a59d806cc87", "embedding": null, "doc_hash": "ffc28fa6fce4f6c3e3add3d792f2884339939689ba0b53da839153f651fc1059", "extra_info": null, "node_info": {"start": 432215, "end": 435981}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "da036ab2-5737-44c9-a823-dcda4355dcdb", "3": "c7f361dc-6053-4813-a191-0b47bcfe60b2"}}, "__type__": "1"}, "c7f361dc-6053-4813-a191-0b47bcfe60b2": {"__data__": {"text": "mail server \nis down, then she has the recourse of complaining to her system administrator!) The \nSMTP RFC defines how the SMTP commands can be used to relay a message across \nmultiple SMTP servers.\nBut there is still one missing piece to the puzzle! How does a recipient like Bob, \nrunning a user agent on his local PC, obtain his messages, which are sitting in a mail \nserver within Bob\u2019s ISP? Note that Bob\u2019s user agent can\u2019t use SMTP to obtain the \nmessages because obtaining the messages is a pull operation, whereas SMTP is a \npush protocol. The puzzle is completed by introducing a special mail access protocol \nthat transfers messages from Bob\u2019s mail server to his local PC. There are currently a \nnumber of popular mail access protocols, including Post Office Protocol\u2014Version \n3 (POP3),  Internet Mail Access Protocol (IMAP) , and HTTP.\nFigure 2. 16 provides a summary of the protocols that are used for Internet mail: \nSMTP is used to transfer mail from the sender\u2019s mail server to the recipient\u2019s mail \nserver; SMTP is also used to transfer mail from the sender\u2019s user agent to the send -\ner\u2019s mail server. A mail access protocol, such as POP3, is used to transfer mail from \nthe recipient\u2019s mail server to the recipient\u2019s user agent.\nPOP3\nPOP3 is an extremely simple mail access protocol. It is defined in [RFC 1939], \nwhich is short and quite readable. Because the protocol is so simple, its functionality \nis rather limited. POP3 begins when the user agent (the client) opens a TCP connec -\ntion to the mail server (the server) on port 110. With the TCP connection established, \nPOP3 progresses through three phases: authorization, transaction, and update. Dur -\ning the first phase, authorization, the user agent sends a username and a password \n(in the clear) to authenticate the user. During the second phase, transaction, the user \nagent retrieves messages; also during this phase, the user agent can mark messages \nfor deletion, remove deletion marks, and obtain mail statistics. The third phase, \nupdate, occurs after the client has issued the quit  command, ending the POP3 ses -\nsion; at this time, the mail server deletes the messages that were marked for deletion.SMTPAlice\u2019 s\nmail serverBob\u2019s\nmail server\nAlice\u2019 s\nagentBob\u2019s\nagentSMTP POP3,\nIMAP , or\nHTTP\nFigure 2.16  \u2666 E-mail protocols and their communicating entities\n152     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nIn a POP3 transaction, the user agent issues commands, and the server responds \nto each command with a reply. There are two possible responses: +OK (sometimes \nfollowed by server-to-client data), used by the server to indicate that the previous \ncommand was fine; and -ERR , used by the server to indicate that something was \nwrong with the previous command.\nThe authorization phase has two principal commands: user  <username>  and \npass  <password> . To illustrate these two commands, we suggest that you Telnet \ndirectly into a POP3 server, using port 110, and issue these commands. Suppose that \nmailServer  is the name of your mail server. You will see something like:\ntelnet mailServer 110\n+OK POP3 server ready\nuser bob\n+OK\npass hungry\n+OK user successfully logged on\nIf you misspell a command, the POP3 server will reply with an -ERR  message.\nNow let\u2019s take a look at the transaction phase. A user agent using POP3 can \noften be configured (by the user) to \u201cdownload and delete\u201d or to \u201cdownload and \nkeep.\u201d The sequence of commands issued by a POP3 user agent depends on which \nof these two modes the user agent is operating in. In the download-and-delete mode, \nthe user agent will issue the list , retr , and dele  commands. As an example, \nsuppose the user has two messages in his or", "doc_id": "c7f361dc-6053-4813-a191-0b47bcfe60b2", "embedding": null, "doc_hash": "678e573981ee6d321a6bdad1e93b83fcdde04db797384c4814ee9679208b807a", "extra_info": null, "node_info": {"start": 435965, "end": 439650}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "0a66faa1-9327-4ebc-bd93-9a59d806cc87", "3": "a4d23552-d941-4a19-8aa5-4de839c229cd"}}, "__type__": "1"}, "a4d23552-d941-4a19-8aa5-4de839c229cd": {"__data__": {"text": " is the name of your mail server. You will see something like:\ntelnet mailServer 110\n+OK POP3 server ready\nuser bob\n+OK\npass hungry\n+OK user successfully logged on\nIf you misspell a command, the POP3 server will reply with an -ERR  message.\nNow let\u2019s take a look at the transaction phase. A user agent using POP3 can \noften be configured (by the user) to \u201cdownload and delete\u201d or to \u201cdownload and \nkeep.\u201d The sequence of commands issued by a POP3 user agent depends on which \nof these two modes the user agent is operating in. In the download-and-delete mode, \nthe user agent will issue the list , retr , and dele  commands. As an example, \nsuppose the user has two messages in his or her mailbox. In the dialogue below, C: \n(standing for client) is the user agent and S: (standing for server) is the mail server. \nThe transaction will look something like:\nC: list\nS: 1 498\nS: 2 912\nS: .\nC: retr 1\nS: (blah blah ...\nS: .................\nS: ..........blah)\nS: .\nC: dele 1\nC: retr 2\nS: (blah blah ...\nS: .................\nS: ..........blah)\nS: .\nC: dele 2\n2.3  \u2022  ELECTRONIC MAIL IN THE INTERNET      153\nC: quit\nS: +OK POP3 server signing off\nThe user agent first asks the mail server to list the size of each of the stored messages. \nThe user agent then retrieves and deletes each message from the server. Note that \nafter the authorization phase, the user agent employed only four commands: list , \nretr , dele , and quit . The syntax for these commands is defined in RFC 1939. \nAfter processing the quit  command, the POP3 server enters the update phase and \nremoves messages 1 and 2 from the mailbox.\nA problem with this download-and-delete mode is that the recipient, Bob, may \nbe nomadic and may want to access his mail messages from multiple machines, for \nexample, his office PC, his home PC, and his portable computer. The download- and-\ndelete mode partitions Bob\u2019s mail messages over these three machines; in particular, \nif Bob first reads a message on his office PC, he will not be able to reread the mes -\nsage from his portable at home later in the evening. In the download-and-keep mode, \nthe user agent leaves the messages on the mail server after downloading them. In this \ncase, Bob can reread messages from different machines; he can access a message \nfrom work and access it again later in the week from home.\nDuring a POP3 session between a user agent and the mail server, the POP3 \nserver maintains some state information; in particular, it keeps track of which user \nmessages have been marked deleted. However, the POP3 server does not carry state \ninformation across POP3 sessions. This lack of state information across sessions \ngreatly simplifies the implementation of a POP3 server.\nIMAP\nWith POP3 access, once Bob has downloaded his messages to the local machine, he \ncan create mail folders and move the downloaded messages into the folders. Bob can \nthen delete messages, move messages across folders, and search for messages (by \nsender name or subject). But this paradigm\u2014namely, folders and messages in the \nlocal machine\u2014poses a problem for the nomadic user, who would prefer to maintain \na folder hierarchy on a remote server that can be accessed from any computer. This \nis not possible with POP3\u2014the POP3 protocol does not provide any means for a user \nto create remote folders and assign messages to folders.\nTo solve this and other problems, the IMAP protocol, defined in [RFC 3501], \nwas invented. Like POP3, IMAP is a mail access protocol. It has many more features \nthan POP3, but it is also significantly more complex. (And thus the client and server \nside implementations are significantly more", "doc_id": "a4d23552-d941-4a19-8aa5-4de839c229cd", "embedding": null, "doc_hash": "d23c1d899a49216b4b5609c1da4bfd9b4cab27417b9aed39e3ccbf1c2ca82ab6", "extra_info": null, "node_info": {"start": 439718, "end": 443356}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "c7f361dc-6053-4813-a191-0b47bcfe60b2", "3": "e9820dda-d073-4cbf-af12-5692d93985f2"}}, "__type__": "1"}, "e9820dda-d073-4cbf-af12-5692d93985f2": {"__data__": {"text": "move messages across folders, and search for messages (by \nsender name or subject). But this paradigm\u2014namely, folders and messages in the \nlocal machine\u2014poses a problem for the nomadic user, who would prefer to maintain \na folder hierarchy on a remote server that can be accessed from any computer. This \nis not possible with POP3\u2014the POP3 protocol does not provide any means for a user \nto create remote folders and assign messages to folders.\nTo solve this and other problems, the IMAP protocol, defined in [RFC 3501], \nwas invented. Like POP3, IMAP is a mail access protocol. It has many more features \nthan POP3, but it is also significantly more complex. (And thus the client and server \nside implementations are significantly more complex.)\nAn IMAP server will associate each message with a folder; when a message first \narrives at the server, it is associated with the recipient\u2019s INBOX folder. The recipient \ncan then move the message into a new, user-created folder, read the message, delete \nthe message, and so on. The IMAP protocol provides commands to allow users to \ncreate folders and move messages from one folder to another. IMAP also provides \n154     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\ncommands that allow users to search remote folders for messages matching specific \ncriteria. Note that, unlike POP3, an IMAP server maintains user state information \nacross IMAP sessions\u2014for example, the names of the folders and which messages \nare associated with which folders.\nAnother important feature of IMAP is that it has commands that permit a user \nagent to obtain components of messages. For example, a user agent can obtain just \nthe message header of a message or just one part of a multipart MIME message. This \nfeature is useful when there is a low-bandwidth connection (for example, a slow-speed \nmodem link) between the user agent and its mail server. With a low-bandwidth connec -\ntion, the user may not want to download all of the messages in its mailbox, particularly \navoiding long messages that might contain, for example, an audio or video clip.\nWeb-Based E-Mail\nMore and more users today are sending and accessing their e-mail through their Web \nbrowsers. Hotmail introduced Web-based access in the mid 1990s. Now Web-based \ne-mail is also provided by Google, Yahoo!, as well as just about every major univer -\nsity and corporation. With this service, the user agent is an ordinary Web browser, \nand the user communicates with its remote mailbox via HTTP. When a recipient, \nsuch as Bob, wants to access a message in his mailbox, the e-mail message is sent \nfrom Bob\u2019s mail server to Bob\u2019s browser using the HTTP protocol rather than the \nPOP3 or IMAP protocol. When a sender, such as Alice, wants to send an e-mail \nmessage, the e-mail message is sent from her browser to her mail server over HTTP \nrather than over SMTP. Alice\u2019s mail server, however, still sends messages to, and \nreceives messages from, other mail servers using SMTP.\n2.4 DNS\u2014The Internet\u2019s Directory Service\nWe human beings can be identified in many ways. For example, we can be identified \nby the names that appear on our birth certificates. We can be identified by our social \nsecurity numbers. We can be identified by our driver\u2019s license numbers. Although \neach of these identifiers can be used to identify people, within a given context one \nidentifier may be more appropriate than another. For example, the computers at the \nIRS (the infamous tax-collecting agency in the United States) prefer to use fixed-\nlength social security numbers rather than birth certificate names. On the other hand, \nordinary people prefer the more mnemonic birth certificate names rather than social \nsecurity numbers. (Indeed, can you imagine saying, \u201cHi. My name is 132-67-9875. \nPlease meet my husband, 178-87-1146.\u201d)\nJust as humans can be identified in many ways, so too can Internet hosts. One \nidentifier for a host is", "doc_id": "e9820dda-d073-4cbf-af12-5692d93985f2", "embedding": null, "doc_hash": "d93853d0471463c5e380635b58bdfc6e94214fb4f4e821281a710547837d4787", "extra_info": null, "node_info": {"start": 443305, "end": 447214}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "a4d23552-d941-4a19-8aa5-4de839c229cd", "3": "312b811b-a96c-4a63-bb2f-4ca0aab9eef6"}}, "__type__": "1"}, "312b811b-a96c-4a63-bb2f-4ca0aab9eef6": {"__data__": {"text": "on our birth certificates. We can be identified by our social \nsecurity numbers. We can be identified by our driver\u2019s license numbers. Although \neach of these identifiers can be used to identify people, within a given context one \nidentifier may be more appropriate than another. For example, the computers at the \nIRS (the infamous tax-collecting agency in the United States) prefer to use fixed-\nlength social security numbers rather than birth certificate names. On the other hand, \nordinary people prefer the more mnemonic birth certificate names rather than social \nsecurity numbers. (Indeed, can you imagine saying, \u201cHi. My name is 132-67-9875. \nPlease meet my husband, 178-87-1146.\u201d)\nJust as humans can be identified in many ways, so too can Internet hosts. One \nidentifier for a host is its hostname . Hostnames\u2014such as www.facebook.com, \nwww.google.com , gaia.cs.umass.edu \u2014are mnemonic and are therefore \n2.4  \u2022  DNS\u2014THE INTERNET\u2019S DIRECTORY SERVICE      155\nappreciated by humans. However, hostnames provide little, if any, information about \nthe location within the Internet of the host. (A hostname such as www.eurecom.\nfr, which ends with the country code .fr, tells us that the host is probably in \nFrance, but doesn\u2019t say much more.) Furthermore, because hostnames can consist of \nvariable-length alphanumeric characters, they would be difficult to process by rout -\ners. For these reasons, hosts are also identified by so-called IP addresses .\nWe discuss IP addresses in some detail in Chapter 4, but it is useful to say a \nfew brief words about them now. An IP address consists of four bytes and has a \nrigid hierarchical structure. An IP address looks like 121.7.106.83 , where each \nperiod separates one of the bytes expressed in decimal notation from 0 to 255. An IP \naddress is hierarchical because as we scan the address from left to right, we obtain \nmore and more specific information about where the host is located in the Internet \n(that is, within which network, in the network of networks). Similarly, when we scan \na postal address from bottom to top, we obtain more and more specific information \nabout where the addressee is located.\n2.4.1  Services Provided by DNS\nWe have just seen that there are two ways to identify a host\u2014by a hostname and \nby an IP address. People prefer the more mnemonic hostname identifier, while \nrouters prefer fixed-length, hierarchically structured IP addresses. In order to rec -\noncile these preferences, we need a directory service that translates hostnames to \nIP addresses. This is the main task of the Internet\u2019s domain name system (DNS) . \nThe DNS is (1) a distributed database implemented in a hierarchy of DNS servers ,  \nand (2) an application-layer protocol that allows hosts to query the distributed \ndatabase. The DNS servers are often UNIX machines running the Berkeley Inter -\nnet Name Domain (BIND) software [BIND 2016]. The DNS protocol runs over \nUDP and uses port 53.\nDNS is commonly employed by other application-layer protocols\u2014including \nHTTP and SMTP to translate user-supplied hostnames to IP addresses. As an exam -\nple, consider what happens when a browser (that is, an HTTP client), running on \nsome user\u2019s host, requests the URL www.someschool.edu/index.html . In \norder for the user\u2019s host to be able to send an HTTP request message to the Web \nserver www.someschool.edu , the user\u2019s host must first obtain the IP address of \nwww.someschool.edu . This is done as follows.\n 1. The same user machine runs the client side of the DNS application.\n 2. The browser extracts the hostname, www.someschool.edu , from the URL \nand passes the hostname to the client side of the DNS application.\n 3. The DNS client sends a query containing the hostname to a DNS server.\n 4. The DNS client eventually receives", "doc_id": "312b811b-a96c-4a63-bb2f-4ca0aab9eef6", "embedding": null, "doc_hash": "71dda7feea6c10fc7893ac630b60866ff44cfc07c635317bba36c3032876291d", "extra_info": null, "node_info": {"start": 447161, "end": 450948}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "e9820dda-d073-4cbf-af12-5692d93985f2", "3": "912055bf-dcd8-4f39-a9e2-eef36278b269"}}, "__type__": "1"}, "912055bf-dcd8-4f39-a9e2-eef36278b269": {"__data__": {"text": "exam -\nple, consider what happens when a browser (that is, an HTTP client), running on \nsome user\u2019s host, requests the URL www.someschool.edu/index.html . In \norder for the user\u2019s host to be able to send an HTTP request message to the Web \nserver www.someschool.edu , the user\u2019s host must first obtain the IP address of \nwww.someschool.edu . This is done as follows.\n 1. The same user machine runs the client side of the DNS application.\n 2. The browser extracts the hostname, www.someschool.edu , from the URL \nand passes the hostname to the client side of the DNS application.\n 3. The DNS client sends a query containing the hostname to a DNS server.\n 4. The DNS client eventually receives a reply, which includes the IP address for \nthe hostname.\n 5. Once the browser receives the IP address from DNS, it can initiate a TCP con -\nnection to the HTTP server process located at port 80 at that IP address.\n156     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nWe see from this example that DNS adds an additional delay\u2014sometimes  \nsubstantial\u2014to the Internet applications that use it. Fortunately, as we discuss below, \nthe desired IP address is often cached in a \u201cnearby\u201d DNS server, which helps to \nreduce DNS network traffic as well as the average DNS delay.\nDNS provides a few other important services in addition to translating host -\nnames to IP addresses:\n\u2022 Host aliasing.  A host with a complicated hostname can have one or more  \nalias names. For example, a hostname such as relay1.west-coast  \n.enterprise.com  could have, say, two aliases such as enterprise.com   \nand www.enterprise.com . In this case, the hostname relay1 \n.west-coast.enterprise.com  is said to be a canonical hostname . Alias \nhostnames, when present, are typically more mnemonic than canonical host -\nnames. DNS can be invoked by an application to obtain the canonical hostname \nfor a supplied alias hostname as well as the IP address of the host.\n\u2022 Mail server aliasing.  For obvious reasons, it is highly desirable that e-mail \naddresses be mnemonic. For example, if Bob has an account with Yahoo Mail, \nBob\u2019s e-mail address might be as simple as bob@yahoo.mail . However, the \nhostname of the Yahoo mail server is more complicated and much less mnemonic \nthan simply yahoo.com  (for example, the canonical hostname might be some -\nthing like relay1.west-coast.yahoo.com ). DNS can be invoked by a \nmail application to obtain the canonical hostname for a supplied alias hostname \nas well as the IP address of the host. In fact, the MX record (see below) permits a \ncompany\u2019s mail server and Web server to have identical (aliased) hostnames; for \nexample, a company\u2019s Web server and mail server can both be called enter-\nprise.com .\n\u2022 Load distribution.  DNS is also used to perform load distribution among repli -\ncated servers, such as replicated Web servers. Busy sites, such as cnn.com , are \nreplicated over multiple servers, with each server running on a different end sys -\ntem and each having a different IP address. For replicated Web servers, a set of IP \naddresses is thus associated with one canonical hostname. The DNS database con -\ntains this set of IP addresses. When clients make a DNS query for a name mapped \nto a set of addresses, the server responds with the entire set of IP addresses, but \nrotates the ordering of the addresses within each reply. Because a client typically \nsends its HTTP request message to the IP address that is listed first in the set, DNS \nrotation distributes the traffic among the replicated servers. DNS rotation is also \nused for e-mail so that multiple mail servers can have the same alias name. Also, \ncontent distribution companies such as Akamai have used DNS in more sophisti", "doc_id": "912055bf-dcd8-4f39-a9e2-eef36278b269", "embedding": null, "doc_hash": "5377cba7711627c46e1e90c90d7ad64c063ef0dfc71758a23b8b2e1898e938f4", "extra_info": null, "node_info": {"start": 451045, "end": 454747}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "312b811b-a96c-4a63-bb2f-4ca0aab9eef6", "3": "ed655cc9-84ac-4d60-900a-ac2543bc0aa8"}}, "__type__": "1"}, "ed655cc9-84ac-4d60-900a-ac2543bc0aa8": {"__data__": {"text": "multiple servers, with each server running on a different end sys -\ntem and each having a different IP address. For replicated Web servers, a set of IP \naddresses is thus associated with one canonical hostname. The DNS database con -\ntains this set of IP addresses. When clients make a DNS query for a name mapped \nto a set of addresses, the server responds with the entire set of IP addresses, but \nrotates the ordering of the addresses within each reply. Because a client typically \nsends its HTTP request message to the IP address that is listed first in the set, DNS \nrotation distributes the traffic among the replicated servers. DNS rotation is also \nused for e-mail so that multiple mail servers can have the same alias name. Also, \ncontent distribution companies such as Akamai have used DNS in more sophisti -\ncated ways [Dilley 2002] to provide Web content distribution (see Section 2.6.3).\nThe DNS is specified in RFC 1034 and RFC 1035, and updated in several addi -\ntional RFCs. It is a complex system, and we only touch upon key aspects of its \n2.4  \u2022  DNS\u2014THE INTERNET\u2019S DIRECTORY SERVICE      157\noperation here. The interested reader is referred to these RFCs and the book by Albitz \nand Liu [Albitz 1993]; see also the retrospective paper [Mockapetris 1988], which \nprovides a nice description of the what and why of DNS, and [Mockapetris 2005].\n2.4.2  Overview of How DNS Works\nWe now present a high-level overview of how DNS works. Our discussion will focus \non the hostname-to-IP-address translation service.\nSuppose that some application (such as a Web browser or a mail reader) running \nin a user\u2019s host needs to translate a hostname to an IP address. The application will \ninvoke the client side of DNS, specifying the hostname that needs to be translated. \n(On many UNIX-based machines, gethostbyname()  is the function call that \nan application calls in order to perform the translation.) DNS in the user\u2019s host then \ntakes over, sending a query message into the network. All DNS query and reply mes -\nsages are sent within UDP datagrams to port 53. After a delay, ranging from millisec -\nonds to seconds, DNS in the user\u2019s host receives a DNS reply message that provides \nthe desired mapping. This mapping is then passed to the invoking application. Thus, \nfrom the perspective of the invoking application in the user\u2019s host, DNS is a black \nbox providing a simple, straightforward translation service. But in fact, the black box \nthat implements the service is complex, consisting of a large number of DNS servers \ndistributed around the globe, as well as an application-layer protocol that specifies \nhow the DNS servers and querying hosts communicate.\nA simple design for DNS would have one DNS server that contains all the map -\npings. In this centralized design, clients simply direct all queries to the single DNS \nserver, and the DNS server responds directly to the querying clients. Although the DNS: CRITICAL NETWORK FUNCTIONS VIA THE CLIENT-SERVER PARADIGM\nLike HTTP, FTP, and SMTP, the DNS protocol is an application-layer protocol since it (1) \nruns between communicating end systems using the client-server paradigm and (2) relies \non an underlying end-to-end transport protocol to transfer DNS messages between com -\nmunicating end systems. In another sense, however, the role of the DNS is quite different \nfrom Web, file transfer, and e-mail applications. Unlike these applications, the DNS is \nnot an application with which a user directly interacts. Instead, the DNS provides a core \nInternet function\u2014namely, translating hostnames to their underlying IP addresses, for user \napplications and other software in the Internet. We noted in Section 1.2 that much of the \ncomplexity in the Internet architecture is located at the \u201cedges\u201d of the network.  The DNS, \nwhich", "doc_id": "ed655cc9-84ac-4d60-900a-ac2543bc0aa8", "embedding": null, "doc_hash": "f85e3f963d32863539cacd49a6c193f964113779fe0a4496a3484e7719848214", "extra_info": null, "node_info": {"start": 454646, "end": 458455}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "912055bf-dcd8-4f39-a9e2-eef36278b269", "3": "b7876235-9acd-41a8-950c-7983282c0f9d"}}, "__type__": "1"}, "b7876235-9acd-41a8-950c-7983282c0f9d": {"__data__": {"text": "protocol since it (1) \nruns between communicating end systems using the client-server paradigm and (2) relies \non an underlying end-to-end transport protocol to transfer DNS messages between com -\nmunicating end systems. In another sense, however, the role of the DNS is quite different \nfrom Web, file transfer, and e-mail applications. Unlike these applications, the DNS is \nnot an application with which a user directly interacts. Instead, the DNS provides a core \nInternet function\u2014namely, translating hostnames to their underlying IP addresses, for user \napplications and other software in the Internet. We noted in Section 1.2 that much of the \ncomplexity in the Internet architecture is located at the \u201cedges\u201d of the network.  The DNS, \nwhich implements the critical name-to-address translation process using clients and servers \nlocated at the edge of the network, is yet another example of that design philosophy.PRINCIPLES IN PRACTICE\n\n158     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nsimplicity of this design is attractive, it is inappropriate for today\u2019s Internet, with its \nvast (and growing) number of hosts. The problems with a centralized design include:\n\u2022 A single point of failure.  If the DNS server crashes, so does the entire Internet!\n\u2022 Traffic volume.  A single DNS server would have to handle all DNS queries (for \nall the HTTP requests and e-mail messages generated from hundreds of millions \nof hosts).\n\u2022 Distant centralized database.  A single DNS server cannot be \u201cclose to\u201d all the \nquerying clients. If we put the single DNS server in New York City, then all que -\nries from Australia must travel to the other side of the globe, perhaps over slow \nand congested links. This can lead to significant delays.\n\u2022 Maintenance.  The single DNS server would have to keep records for all Internet \nhosts. Not only would this centralized database be huge, but it would have to be \nupdated frequently to account for every new host.\nIn summary, a centralized database in a single DNS server simply doesn\u2019t scale.  \nConsequently, the DNS is distributed by design. In fact, the DNS is a wonderful \nexample of how a distributed database can be implemented in the Internet.\nA Distributed, Hierarchical Database\nIn order to deal with the issue of scale, the DNS uses a large number of servers, \norganized in a hierarchical fashion and distributed around the world. No single DNS \nserver has all of the mappings for all of the hosts in the Internet. Instead, the map -\npings are distributed across the DNS servers. To a first approximation, there are three \nclasses of DNS servers\u2014root DNS servers, top-level domain (TLD) DNS servers, \nand authoritative DNS servers\u2014organized in a hierarchy as shown in Figure 2.17. \nTo understand how these three classes of servers interact, suppose a DNS client \nwants to determine the IP address for the hostname www.amazon.com . To a first \nedu DNS servers org DNS servers com DNS servers\nnyu.edu\nDNS serversfacebook.com\nDNS serversamazon.com\nDNS serverspbs.org\nDNS serversumass.edu\nDNS serversRoot DNS servers\nFigure 2.17  \u2666 Portion of the hierarchy of DNS servers\n2.4  \u2022  DNS\u2014THE INTERNET\u2019S DIRECTORY SERVICE      159\napproximation, the following events will take place. The client first contacts one of \nthe root servers, which returns IP addresses for TLD servers for the top-level domain \ncom. The client then contacts one of these TLD servers, which returns the IP address \nof an authoritative server for amazon.com . Finally, the client contacts one of the \nauthoritative servers for amazon.com , which returns the IP address for the host -\nname www.amazon.com . We\u2019ll soon examine this DNS lookup process in more \ndetail. But let\u2019s first take", "doc_id": "b7876235-9acd-41a8-950c-7983282c0f9d", "embedding": null, "doc_hash": "7e78f8fc5f7a81b071e276d6cc21bbd3b9acb9e98d1dcbd8d5ac1893e43014f2", "extra_info": null, "node_info": {"start": 458498, "end": 462192}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "ed655cc9-84ac-4d60-900a-ac2543bc0aa8", "3": "9d2fe1b7-26ab-4fc2-a838-345cc68f746f"}}, "__type__": "1"}, "9d2fe1b7-26ab-4fc2-a838-345cc68f746f": {"__data__": {"text": "serversumass.edu\nDNS serversRoot DNS servers\nFigure 2.17  \u2666 Portion of the hierarchy of DNS servers\n2.4  \u2022  DNS\u2014THE INTERNET\u2019S DIRECTORY SERVICE      159\napproximation, the following events will take place. The client first contacts one of \nthe root servers, which returns IP addresses for TLD servers for the top-level domain \ncom. The client then contacts one of these TLD servers, which returns the IP address \nof an authoritative server for amazon.com . Finally, the client contacts one of the \nauthoritative servers for amazon.com , which returns the IP address for the host -\nname www.amazon.com . We\u2019ll soon examine this DNS lookup process in more \ndetail. But let\u2019s first take a closer look at these three classes of DNS servers:\n\u2022 Root DNS servers.  There are over 400 root name servers scattered all over the \nworld. Figure 2.18 shows the countries that have root names servers, with coun -\ntries having more than ten darkly shaded. These root name servers are managed \nby 13 different organizations. The full list of root name servers, along with the \norganizations that manage them and their IP addresses can be found at [Root \nServers 2016]. Root name servers provide the IP addresses of the TLD servers.\n\u2022 Top-level domain (TLD) servers.  For each of the top-level domains \u2014 top-level \ndomains such as com, org, net, edu, and gov, and all of the country top-level \ndomains such as uk, fr, ca, and jp \u2014 there is TLD server (or server cluster). The \ncompany Verisign Global Registry Services maintains the TLD servers for the \ncom top-level domain, and the company Educause maintains the TLD servers for \nthe edu top-level domain. The network infrastructure supporting a TLD can be \nlarge and complex; see [Osterweil 2012] for a nice overview of the Verisign net-\nwork. See [TLD list 2016] for a list of all top-level domains. TLD servers provide \nthe IP addresses for authoritative DNS servers.\n0 Servers\n1\u201310 Servers\n11+ ServersKey:\nFigure 2.18  \u2666 DNS root servers in 2016\n160     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\n\u2022 Authoritative DNS servers.  Every organization with publicly accessible hosts \n(such as Web servers and mail servers) on the Internet must provide publicly \naccessible DNS records that map the names of those hosts to IP addresses. An \norganization\u2019s authoritative DNS server houses these DNS records. An organi -\nzation can choose to implement its own authoritative DNS server to hold these \nrecords; alternatively, the organization can pay to have these records stored in an \nauthoritative DNS server of some service provider. Most universities and large \ncompanies implement and maintain their own primary and secondary (backup) \nauthoritative DNS server.\nThe root, TLD, and authoritative DNS servers all belong to the hierarchy of \nDNS servers, as shown in Figure 2.17. There is another important type of DNS server \ncalled the local DNS server . A local DNS server does not strictly belong to the hier -\narchy of servers but is nevertheless central to the DNS architecture. Each ISP\u2014such \nas a residential ISP or an institutional ISP\u2014has a local DNS server (also called a \ndefault name server). When a host connects to an ISP, the ISP provides the host with \nthe IP addresses of one or more of its local DNS servers (typically through DHCP , \nwhich is discussed in Chapter 4). You can easily determine the IP address of your \nlocal DNS server by accessing network status windows in Windows or UNIX. A \nhost\u2019s local DNS server is typically \u201cclose to\u201d the host. For an institutional ISP, the \nlocal DNS server may be on the same LAN as the host; for a residential ISP, it is \ntypically separated from the host by no more than a few routers.", "doc_id": "9d2fe1b7-26ab-4fc2-a838-345cc68f746f", "embedding": null, "doc_hash": "563e0e8eabd611821da19522b0b41686301890aef0e9e660f8b2ea2786e30b66", "extra_info": null, "node_info": {"start": 462255, "end": 465929}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "b7876235-9acd-41a8-950c-7983282c0f9d", "3": "67004150-8359-4a5f-bc63-b144d75a98e5"}}, "__type__": "1"}, "67004150-8359-4a5f-bc63-b144d75a98e5": {"__data__": {"text": "-\narchy of servers but is nevertheless central to the DNS architecture. Each ISP\u2014such \nas a residential ISP or an institutional ISP\u2014has a local DNS server (also called a \ndefault name server). When a host connects to an ISP, the ISP provides the host with \nthe IP addresses of one or more of its local DNS servers (typically through DHCP , \nwhich is discussed in Chapter 4). You can easily determine the IP address of your \nlocal DNS server by accessing network status windows in Windows or UNIX. A \nhost\u2019s local DNS server is typically \u201cclose to\u201d the host. For an institutional ISP, the \nlocal DNS server may be on the same LAN as the host; for a residential ISP, it is \ntypically separated from the host by no more than a few routers. When a host makes \na DNS query, the query is sent to the local DNS server, which acts a proxy, forward -\ning the query into the DNS server hierarchy, as we\u2019ll discuss in more detail below.\nLet\u2019s take a look at a simple example. Suppose the host cse.nyu.edu  desires \nthe IP address of gaia.cs.umass.edu . Also suppose that NYU\u2019s ocal DNS \nserver for cse.nyu.edu  is called dns.nyu.edu  and that an authoritative DNS \nserver for gaia.cs.umass.edu  is called dns.umass.edu . As shown in Fig -\nure 2. 19, the host cse.nyu.edu  first sends a DNS query message to its local DNS \nserver, dns.nyu.edu . The query message contains the hostname to be translated, \nnamely, gaia.cs.umass.edu . The local DNS server forwards the query mes -\nsage to a root DNS server. The root DNS server takes note of the edu suffix and \nreturns to the local DNS server a list of IP addresses for TLD servers responsible \nfor edu. The local DNS server then resends the query message to one of these TLD \nservers. The TLD server takes note of the umass.edu  suffix and responds with \nthe IP address of the authoritative DNS server for the University of Massachusetts, \nnamely, dns.umass.edu . Finally, the local DNS server resends the query mes -\nsage directly to dns.umass.edu , which responds with the IP address of gaia \n.cs.umass.edu . Note that in this example, in order to obtain the mapping for one \nhostname, eight DNS messages were sent: four query messages and four reply mes -\nsages! We\u2019ll soon see how DNS caching reduces this query traffic.\nOur previous example assumed that the TLD server knows the authoritative \nDNS server for the hostname. In general this not always true. Instead, the TLD server \n2.4  \u2022  DNS\u2014THE INTERNET\u2019S DIRECTORY SERVICE      161\nmay know only of an intermediate DNS server, which in turn knows the authorita -\ntive DNS server for the hostname. For example, suppose again that the University of \nMassachusetts has a DNS server for the university, called dns.umass.edu . Also \nsuppose that each of the departments at the University of Massachusetts has its own \nDNS server, and that each departmental DNS server is authoritative for all hosts in \nthe department. In this case, when the intermediate DNS server, dns.umass.edu , \nreceives a query for a host with a hostname ending with cs.umass.edu , it returns \nto dns.nyu.edu  the IP address of dns.cs.umass.edu , which is authoritative \nfor all hostnames ending with cs.umass.edu . The local DNS server dns.nyu \n.edu  then sends the query to the authoritative DNS server, which returns the desired \nmapping to the local DNS server, which in turn returns the mapping to the requesting \nhost. In this case, a total of 10 DNS messages are sent!\nThe example shown in Figure 2.19 makes use of both recursive queries  \nand iterative", "doc_id": "67004150-8359-4a5f-bc63-b144d75a98e5", "embedding": null, "doc_hash": "89bce5303d31cea4eb9b18c490e0917b66daeec84b6d7e9527c88b6b6207d22e", "extra_info": null, "node_info": {"start": 465899, "end": 469422}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "9d2fe1b7-26ab-4fc2-a838-345cc68f746f", "3": "c2e26826-75bc-4c4e-826c-23a822e09554"}}, "__type__": "1"}, "c2e26826-75bc-4c4e-826c-23a822e09554": {"__data__": {"text": "DNS server is authoritative for all hosts in \nthe department. In this case, when the intermediate DNS server, dns.umass.edu , \nreceives a query for a host with a hostname ending with cs.umass.edu , it returns \nto dns.nyu.edu  the IP address of dns.cs.umass.edu , which is authoritative \nfor all hostnames ending with cs.umass.edu . The local DNS server dns.nyu \n.edu  then sends the query to the authoritative DNS server, which returns the desired \nmapping to the local DNS server, which in turn returns the mapping to the requesting \nhost. In this case, a total of 10 DNS messages are sent!\nThe example shown in Figure 2.19 makes use of both recursive queries  \nand iterative queries . The query sent from cse.nyu.edu  to dns.nyu.edu  Requesting host\ncse.nyu.eduLocal DNS server TLD DNS server\ndns.nyu.eduRoot DNS server\n1\n82\n74\n53\n6\nAuthoritative DNS server\ndns.umass.edu\ngaia.cs.umass.edu\nFigure 2.19  \u2666 Interaction of the various DNS servers\n162     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nis a recursive query, since the query asks dns.nyu.edu  to obtain the mapping \non its behalf. But the subsequent three queries are iterative since all of the replies \nare directly returned to dns.nyu.edu . In theory, any DNS query can be itera -\ntive or recursive. For example, Figure 2.20 shows a DNS query chain for which all  \nof the queries are recursive. In practice, the queries typically follow the pattern in \nFigure 2. 19: The query from the requesting host to the local DNS server is recursive, \nand the remaining queries are iterative.\nDNS Caching\nOur discussion thus far has ignored DNS caching , a critically important feature \nof the DNS system. In truth, DNS extensively exploits DNS caching in order to \nimprove the delay performance and to reduce the number of DNS messages  \nRequesting host\ncse.nyu.eduLocal DNS server TLD DNS server\ndns.nyu.eduRoot DNS server\n1\n85\n42\n7\nAuthoritative DNS server\ndns.umass.edu\ngaia.cs.umass.edu63\nFigure 2.20  \u2666 Recursive queries in DNS\n2.4  \u2022  DNS\u2014THE INTERNET\u2019S DIRECTORY SERVICE      163\nricocheting around the Internet. The idea behind DNS caching is very simple. In a \nquery chain, when a DNS server receives a DNS reply (containing, for example, a \nmapping from a hostname to an IP address), it can cache the mapping in its local \nmemory. For example, in Figure 2.19, each time the local DNS server dns.nyu.edu  \nreceives a reply from some DNS server, it can cache any of the information con -\ntained in the reply. If a hostname/IP address pair is cached in a DNS server and \nanother query arrives to the DNS server for the same hostname, the DNS server \ncan provide the desired IP address, even if it is not authoritative for the hostname. \nBecause hosts and mappings between hostnames and IP addresses are by no means \npermanent, DNS servers discard cached information after a period of time (often \nset to two days).\nAs an example, suppose that a host apricot.nyu.edu  queries dns \n.nyu.edu  for the IP address for the hostname cnn.com . Furthermore,  suppose \nthat a few hours later, another NYU host, say, kiwi.nyu.edu , also queries \ndns.nyu.edu  with the same hostname. Because of caching, the local DNS \nserver will be able to immediately return the IP address of cnn.com  to this \nsecond requesting host without having to query any other DNS servers. A local \nDNS server can also cache the IP", "doc_id": "c2e26826-75bc-4c4e-826c-23a822e09554", "embedding": null, "doc_hash": "f5f632ad17bcfb8120521dab4c3e4a8b42a441ce0e6c97d44f40c640b4c17e32", "extra_info": null, "node_info": {"start": 469465, "end": 472812}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "67004150-8359-4a5f-bc63-b144d75a98e5", "3": "a59760aa-1bed-4458-a457-a1f3d52dd50f"}}, "__type__": "1"}, "a59760aa-1bed-4458-a457-a1f3d52dd50f": {"__data__": {"text": "if it is not authoritative for the hostname. \nBecause hosts and mappings between hostnames and IP addresses are by no means \npermanent, DNS servers discard cached information after a period of time (often \nset to two days).\nAs an example, suppose that a host apricot.nyu.edu  queries dns \n.nyu.edu  for the IP address for the hostname cnn.com . Furthermore,  suppose \nthat a few hours later, another NYU host, say, kiwi.nyu.edu , also queries \ndns.nyu.edu  with the same hostname. Because of caching, the local DNS \nserver will be able to immediately return the IP address of cnn.com  to this \nsecond requesting host without having to query any other DNS servers. A local \nDNS server can also cache the IP addresses of TLD servers, thereby allowing \nthe local DNS server to bypass the root DNS servers in a query chain. In fact, \nbecause of caching, root servers are bypassed for all but a very small fraction of \nDNS queries.\n2.4.3  DNS Records and Messages\nThe DNS servers that together implement the DNS distributed database store \nresource records (RRs) , including RRs that provide hostname-to-IP address map -\npings. Each DNS reply message carries one or more resource records. In this and \nthe following subsection, we provide a brief overview of DNS resource records and \nmessages; more details can be found in [Albitz 1993] or in the DNS RFCs [RFC \n1034; RFC 1035].\nA resource record is a four-tuple that contains the following fields:\n(Name, Value, Type, TTL)\nTTL is the time to live of the resource record; it determines when a resource should \nbe removed from a cache. In the example records given below, we ignore the TTL \nfield. The meaning of Name  and Value  depend on Type :\n\u2022 If Type=A , then Name  is a hostname and Value  is the IP address for the host -\nname. Thus, a Type A record provides the standard hostname-to-IP address map -\nping. As an example, (relay1.bar.foo.com, 145.37.93.126, A)  is \na Type A record.\n164     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\n\u2022 If Type=NS , then Name  is a domain (such as foo.com ) and Value  is the host -\nname of an authoritative DNS server that knows how to obtain the IP addresses \nfor hosts in the domain. This record is used to route DNS queries further along in \nthe query chain. As an example, (foo.com, dns.foo.com, NS)  is a Type \nNS record.\n\u2022 If Type=CNAME , then Value  is a canonical hostname for the alias hostname \nName . This record can provide querying hosts the canonical name for a host -\nname. As an example, (foo.com, relay1.bar.foo.com, CNAME)  is a \nCNAME record.\n\u2022 If Type=MX , then Value  is the canonical name of a mail server that has an alias \nhostname Name . As an example, (foo.com, mail.bar.foo.com, MX)  \nis an MX record. MX records allow the hostnames of mail servers to have simple \naliases. Note that by using the MX record, a company can have the same aliased \nname for its mail server and for one of its other servers (such as its Web server). \nTo obtain the canonical name for the mail server, a DNS client would query for \nan MX record; to obtain the canonical name for the other server, the DNS client \nwould query for the CNAME record.\nIf a DNS server is authoritative for a particular hostname, then the DNS server \nwill contain a Type A record for the hostname. (Even if the DNS server is not author -\nitative, it may contain a Type A record in its cache.) If a server is not authoritative for \na hostname, then the server will contain a Type NS record for the domain that includes \nthe hostname; it will also contain a Type A record that", "doc_id": "a59760aa-1bed-4458-a457-a1f3d52dd50f", "embedding": null, "doc_hash": "7b3e20d2e9236f7c658eecd43aea00ec5c1cd40bba938408b9efd557a8b542e1", "extra_info": null, "node_info": {"start": 472790, "end": 476325}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "c2e26826-75bc-4c4e-826c-23a822e09554", "3": "df1b5363-2cf9-4c33-bcdf-7ca7792ccbd3"}}, "__type__": "1"}, "df1b5363-2cf9-4c33-bcdf-7ca7792ccbd3": {"__data__": {"text": "mail servers to have simple \naliases. Note that by using the MX record, a company can have the same aliased \nname for its mail server and for one of its other servers (such as its Web server). \nTo obtain the canonical name for the mail server, a DNS client would query for \nan MX record; to obtain the canonical name for the other server, the DNS client \nwould query for the CNAME record.\nIf a DNS server is authoritative for a particular hostname, then the DNS server \nwill contain a Type A record for the hostname. (Even if the DNS server is not author -\nitative, it may contain a Type A record in its cache.) If a server is not authoritative for \na hostname, then the server will contain a Type NS record for the domain that includes \nthe hostname; it will also contain a Type A record that provides the IP address of \nthe DNS server in the Value  field of the NS record. As an example, suppose an \nedu TLD server is not authoritative for the host gaia.cs.umass.edu . Then this \nserver will contain a record for a domain that includes the host gaia.cs.umass \n.edu , for example, (umass.edu, dns.umass.edu, NS) . The edu TLD server \nwould also contain a Type A record, which maps the DNS server dns.umass.edu  \nto an IP address, for example, (dns.umass.edu, 128.119.40.111, A) .\nDNS Messages\nEarlier in this section, we referred to DNS query and reply messages. These are the \nonly two kinds of DNS messages. Furthermore, both query and reply messages have \nthe same format, as shown in Figure 2.21.The semantics of the various fields in a \nDNS message are as follows:\n\u2022 The first 12 bytes is the header section , which has a number of fields. The first \nfield is a 16-bit number that identifies the query. This identifier is copied into the \nreply message to a query, allowing the client to match received replies with sent \nqueries. There are a number of flags in the flag field. A 1-bit query/reply flag indi -\ncates whether the message is a query (0) or a reply (1). A 1-bit authoritative flag is \n2.4  \u2022  DNS\u2014THE INTERNET\u2019S DIRECTORY SERVICE      165\nset in a reply message when a DNS server is an authoritative server for a queried \nname. A 1-bit recursion-desired flag is set when a client (host or DNS server) \ndesires that the DNS server perform recursion when it doesn\u2019t have the record. A \n1-bit recursion-available field is set in a reply if the DNS server supports recur -\nsion. In the header, there are also four number-of fields. These fields indicate the \nnumber of occurrences of the four types of data sections that follow the header.\n\u2022 The question section  contains information about the query that is being made. \nThis section includes (1) a name field that contains the name that is being que -\nried, and (2) a type field that indicates the type of question being asked about the \nname\u2014for example, a host address associated with a name (Type A) or the mail \nserver for a name (Type MX).\n\u2022 In a reply from a DNS server, the answer section  contains the resource records for \nthe name that was originally queried. Recall that in each resource record there is the \nType  (for example, A, NS, CNAME, and MX), the Value , and the TTL. A reply can \nreturn multiple RRs in the answer, since a hostname can have multiple IP addresses \n(for example, for replicated Web servers, as discussed earlier in this section).\n\u2022 The authority section  contains records of other authoritative servers.\n\u2022 The additional section  contains other helpful records. For example, the answer \nfield in a reply to an MX query contains a resource record providing the canoni -\ncal hostname of a mail server. The additional section contains a Type A record \nproviding the IP address for the canonical hostname of the mail server.Identi\ufb01cation\nNumber of questions\nNumber of authority RRs\nName, type \ufb01elds", "doc_id": "df1b5363-2cf9-4c33-bcdf-7ca7792ccbd3", "embedding": null, "doc_hash": "0a109f3db698be30daad6a56cc66f40d04c43e86a94983624cf66ffebc032fe5", "extra_info": null, "node_info": {"start": 476265, "end": 480062}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "a59760aa-1bed-4458-a457-a1f3d52dd50f", "3": "22fa3d72-9f23-492d-b7cc-f873051bda69"}}, "__type__": "1"}, "22fa3d72-9f23-492d-b7cc-f873051bda69": {"__data__": {"text": "Recall that in each resource record there is the \nType  (for example, A, NS, CNAME, and MX), the Value , and the TTL. A reply can \nreturn multiple RRs in the answer, since a hostname can have multiple IP addresses \n(for example, for replicated Web servers, as discussed earlier in this section).\n\u2022 The authority section  contains records of other authoritative servers.\n\u2022 The additional section  contains other helpful records. For example, the answer \nfield in a reply to an MX query contains a resource record providing the canoni -\ncal hostname of a mail server. The additional section contains a Type A record \nproviding the IP address for the canonical hostname of the mail server.Identi\ufb01cation\nNumber of questions\nNumber of authority RRs\nName, type \ufb01elds for\na query12 bytes\nRRs in response to query\nRecords for\nauthoritative servers\nAdditional \u201chelpful\u201d\ninfo that may be usedFlags\nNumber of answer RRs\nNumber of additional RRs\nAuthority\n(variable number of resource records)\nAdditional information\n(variable number of resource records)Answers\n(variable number of resource records)Questions\n(variable number of questions)\nFigure 2.21  \u2666 DNS message format\n166     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nHow would you like to send a DNS query message directly from the host you\u2019re \nworking on to some DNS server? This can easily be done with the nslookup program , \nwhich is available from most Windows and UNIX platforms. For example, from a Win -\ndows host, open the Command Prompt and invoke the nslookup program by simply typ -\ning \u201cnslookup.\u201d After invoking nslookup, you can send a DNS query to any DNS server \n(root, TLD, or authoritative). After receiving the reply message from the DNS server, \nnslookup will display the records included in the reply (in a human-readable format). As \nan alternative to running nslookup from your own host, you can visit one of many Web \nsites that allow you to remotely employ nslookup. (Just type \u201cnslookup\u201d into a search \nengine and you\u2019ll be brought to one of these sites.) The DNS Wireshark lab at the end of \nthis chapter will allow you to explore the DNS in much more detail.\nInserting Records into the DNS Database\nThe discussion above focused on how records are retrieved from the DNS database. \nYou might be wondering how records get into the database in the first place. Let\u2019s \nlook at how this is done in the context of a specific example. Suppose you have \njust created an exciting new startup company called Network Utopia. The first thing \nyou\u2019ll surely want to do is register the domain name networkutopia.com  at \na registrar. A registrar  is a commercial entity that verifies the uniqueness of the \ndomain name, enters the domain name into the DNS database (as discussed below), \nand collects a small fee from you for its services. Prior to 1999, a single registrar, \nNetwork Solutions, had a monopoly on domain name registration for com, net, \nand org domains. But now there are many registrars competing for customers, and \nthe Internet Corporation for Assigned Names and Numbers (ICANN) accredits the \nvarious registrars. A complete list of accredited registrars is available at http://\nwww.internic.net .\nWhen you register the domain name networkutopia.com  with some reg -\nistrar, you also need to provide the registrar with the names and IP addresses of \nyour primary and secondary authoritative DNS servers. Suppose the names and IP \naddresses are dns1.networkutopia.com , dns2.networkutopia.com , \n212.2.212.1,  and 212.212.212.2.  For each of these two authoritative DNS \nservers, the registrar would then make sure that a Type NS and a Type A record are \nentered into the TLD com servers. Specifically, for the primary authoritative server \nfor networkutopia.com , the registrar would insert the following two resource \nrecords into", "doc_id": "22fa3d72-9f23-492d-b7cc-f873051bda69", "embedding": null, "doc_hash": "3e77ad548e7ed5251288e0121e7dbf2208974efead76da15f5dd54281ecb2263", "extra_info": null, "node_info": {"start": 480071, "end": 483874}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "df1b5363-2cf9-4c33-bcdf-7ca7792ccbd3", "3": "3b88facf-a83a-4191-892b-950147b58eaf"}}, "__type__": "1"}, "3b88facf-a83a-4191-892b-950147b58eaf": {"__data__": {"text": "A complete list of accredited registrars is available at http://\nwww.internic.net .\nWhen you register the domain name networkutopia.com  with some reg -\nistrar, you also need to provide the registrar with the names and IP addresses of \nyour primary and secondary authoritative DNS servers. Suppose the names and IP \naddresses are dns1.networkutopia.com , dns2.networkutopia.com , \n212.2.212.1,  and 212.212.212.2.  For each of these two authoritative DNS \nservers, the registrar would then make sure that a Type NS and a Type A record are \nentered into the TLD com servers. Specifically, for the primary authoritative server \nfor networkutopia.com , the registrar would insert the following two resource \nrecords into the DNS system:\n(networkutopia.com, dns1.networkutopia.com, NS)\n(dns1.networkutopia.com, 21 2.212.212. 1, A)\nYou\u2019ll also have to make sure that the Type A resource record for your Web server \nwww.networkutopia.com  and the Type MX resource record for your mail \nserver mail.networkutopia.com  are entered into your authoritative DNS \n2.4  \u2022  DNS\u2014THE INTERNET\u2019S DIRECTORY SERVICE      167\nDNS VULNERABILITIES\nWe have seen that DNS is a critical component of the Internet infrastructure, with \nmany important services\u2014including the Web and e-mail\u2014simply incapable of func -\ntioning without it. We therefore naturally ask, how can DNS be attacked? Is DNS a \nsitting duck, waiting to be knocked out of service, while taking most Internet applica -\ntions down with it?\nThe first type of attack that comes to mind is a DDoS bandwidth-flooding attack \n(see Section 1.6 ) against DNS servers. For example, an attacker could attempt to \nsend to each DNS root server a deluge of packets, so many that the majority of \nlegitimate DNS queries never get answered. Such a large-scale DDoS attack against \nDNS root servers actually took place on October 21, 200 2. In this attack, the attack -\ners leveraged a botnet to send truck loads of ICMP ping messages to each of the \n13 DNS root IP addresses. (ICMP messages are discussed in Section 5.6 . For now, \nit suffices to know that ICMP packets are special types of IP datagrams.) Fortunately, \nthis large-scale attack caused minimal damage, having little or no impact on users\u2019 \nInternet experience. The attackers did succeed at directing a deluge of packets at the \nroot servers. But many of the DNS root servers were protected by packet filters, con -\nfigured to always block all ICMP ping messages directed at the root servers. These \nprotected servers were thus spared and functioned as normal. Furthermore, most local \nDNS servers cache the IP addresses of top-level-domain servers, allowing the query \nprocess to often bypass the DNS root servers.\nA potentially more effective DDoS attack against DNS would be send a deluge of \nDNS queries to top-level-domain servers, for example, to all the top-level-domain serv -\ners that handle the .com domain. It would be harder to filter DNS queries directed \nto DNS servers; and top-level-domain servers are not as easily bypassed as are root \nservers. But the severity of such an attack would be partially mitigated by caching in \nlocal DNS servers.\nDNS could potentially be attacked in other ways. In a man-in-the-middle attack, \nthe attacker intercepts queries from hosts and returns bogus replies. In the DNS poi -\nsoning attack, the attacker sends bogus replies to a DNS server, tricking the server \ninto accepting bogus records into its cache. Either of these attacks could be used, \nfor example, to redirect an unsuspecting Web user to the attacker\u2019s Web site. These \nattacks, however, are difficult to implement, as they require intercepting packets or \nthrottling", "doc_id": "3b88facf-a83a-4191-892b-950147b58eaf", "embedding": null, "doc_hash": "b5a7220ea7594fdf4db9df6cf71a3b5d6ce7f0fb144d4b23d2ecafe40045636f", "extra_info": null, "node_info": {"start": 483903, "end": 487577}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "22fa3d72-9f23-492d-b7cc-f873051bda69", "3": "d0b81fb1-2dd8-4e89-aea8-c56aef7a99e0"}}, "__type__": "1"}, "d0b81fb1-2dd8-4e89-aea8-c56aef7a99e0": {"__data__": {"text": "servers; and top-level-domain servers are not as easily bypassed as are root \nservers. But the severity of such an attack would be partially mitigated by caching in \nlocal DNS servers.\nDNS could potentially be attacked in other ways. In a man-in-the-middle attack, \nthe attacker intercepts queries from hosts and returns bogus replies. In the DNS poi -\nsoning attack, the attacker sends bogus replies to a DNS server, tricking the server \ninto accepting bogus records into its cache. Either of these attacks could be used, \nfor example, to redirect an unsuspecting Web user to the attacker\u2019s Web site. These \nattacks, however, are difficult to implement, as they require intercepting packets or \nthrottling servers [Skoudis 2006].\nIn summary, DNS has demonstrated itself to be surprisingly robust against attacks. \nTo date, there hasn\u2019t been an attack that has successfully impeded the DNS service. FOCUS ON SECURITY\n\n168     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nservers. (Until recently, the contents of each DNS server were configured statically, \nfor example, from a configuration file created by a system manager. More recently, \nan UPDATE option has been added to the DNS protocol to allow data to be dynami -\ncally added or deleted from the database via DNS messages. [RFC 2136] and [RFC \n3007] specify DNS dynamic updates.)\nOnce all of these steps are completed, people will be able to visit your Web site \nand send e-mail to the employees at your company. Let\u2019s conclude our discussion of \nDNS by verifying that this statement is true. This verification also helps to solidify \nwhat we have learned about DNS. Suppose Alice in Australia wants to view the \nWeb page www.networkutopia.com . As discussed earlier, her host will first \nsend a DNS query to her local DNS server. The local DNS server will then contact a \nTLD com server. (The local DNS server will also have to contact a root DNS server \nif the address of a TLD com server is not cached.) This TLD server contains the \nType NS and Type A resource records listed above, because the registrar had these \nresource records inserted into all of the TLD com servers. The TLD com server \nsends a reply to Alice\u2019s local DNS server, with the reply containing the two resource \nrecords. The local DNS server then sends a DNS query to 212.212.212.1 , ask-\ning for the Type A record corresponding to www.networkutopia.com . This \nrecord provides the IP address of the desired Web server, say, 212.212.71.4 , \nwhich the local DNS server passes back to Alice\u2019s host. Alice\u2019s browser can now \ninitiate a TCP connection to the host 212.212.71.4  and send an HTTP request \nover the connection. Whew! There\u2019s a lot more going on than what meets the eye \nwhen one surfs the Web!\n2.5 Peer-to-Peer File Distribution\nThe applications described in this chapter thus far\u2014including the Web, e-mail, and \nDNS\u2014all employ client-server architectures with significant reliance on always-on \ninfrastructure servers. Recall from Section 2.1.1 that with a P2P architecture, there \nis minimal (or no) reliance on always-on infrastructure servers. Instead, pairs of \nintermittently connected hosts, called peers, communicate directly with each other. \nThe peers are not owned by a service provider, but are instead desktops and laptops \ncontrolled by users.\nIn this section we consider a very natural P2P application, namely, distributing \na large file from a single server to a large number of hosts (called peers). The file \nmight be a new version of the Linux operating system, a software patch for an existing \noperating system or application, an MP3 music file, or an MPEG video file. In client-\nserver file distribution, the server must send a copy of the file to each of the", "doc_id": "d0b81fb1-2dd8-4e89-aea8-c56aef7a99e0", "embedding": null, "doc_hash": "49512820c1d58bb3d04fb606dced93e2b42c98eddcf275c047ba39da0bfb02f5", "extra_info": null, "node_info": {"start": 487591, "end": 491305}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "3b88facf-a83a-4191-892b-950147b58eaf", "3": "9332b2b1-965a-498a-8a52-66b04793ecad"}}, "__type__": "1"}, "9332b2b1-965a-498a-8a52-66b04793ecad": {"__data__": {"text": "servers. Recall from Section 2.1.1 that with a P2P architecture, there \nis minimal (or no) reliance on always-on infrastructure servers. Instead, pairs of \nintermittently connected hosts, called peers, communicate directly with each other. \nThe peers are not owned by a service provider, but are instead desktops and laptops \ncontrolled by users.\nIn this section we consider a very natural P2P application, namely, distributing \na large file from a single server to a large number of hosts (called peers). The file \nmight be a new version of the Linux operating system, a software patch for an existing \noperating system or application, an MP3 music file, or an MPEG video file. In client-\nserver file distribution, the server must send a copy of the file to each of the peers\u2014\nplacing an enormous burden on the server and consuming a large amount of server \nbandwidth. In P2P file distribution, each peer can redistribute any portion of the \n2.5  \u2022  PEER-TO-PEER FILE DISTRIBUTION      169\nfile it has received to any other peers, thereby assisting the server in the distribution \nprocess. As of 2016, the most popular P2P file distribution protocol is BitTorrent. \nOriginally developed by Bram Cohen, there are now many different independent Bit -\nTorrent clients conforming to the BitTorrent protocol, just as there are a number of \nWeb browser clients that conform to the HTTP protocol. In this subsection, we first \nexamine the self-scalability of P2P architectures in the context of file distribution. \nWe then describe BitTorrent in some detail, highlighting its most important charac -\nteristics and features.\nScalability of P2P Architectures\nTo compare client-server architectures with peer-to-peer architectures, and illustrate \nthe inherent self-scalability of P2P, we now consider a simple quantitative model \nfor distributing a file to a fixed set of peers for both architecture types. As shown in \nFigure 2. 22, the server and the peers are connected to the Internet with access links. \nDenote the upload rate of the server\u2019s access link by us, the upload rate of the ith \npeer\u2019s access link by ui, and the download rate of the ith peer\u2019s access link by di. Also \ndenote the size of the file to be distributed (in bits) by F and the number of peers that \nwant to obtain a copy of the file by N. The distribution time  is the time it takes to get \nInternetFile: F\nServer\nusu1 u2\nu3d1\nd2\nd3\nu4\nu5 u6d4\nd5d6uNdN\nFigure 2.22  \u2666 An illustrative file distribution problem\n170     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\na copy of the file to all N peers. In our analysis of the distribution time below, for both \nclient-server and P2P architectures, we make the simplifying (and generally accurate \n[Akella 2003]) assumption that the Internet core has abundant bandwidth, implying \nthat all of the bottlenecks are in access networks. We also suppose that the server \nand clients are not participating in any other network applications, so that all of their \nupload and download access bandwidth can be fully devoted to distributing this file.\nLet\u2019s first determine the distribution time for the client-server architecture, \nwhich we denote by Dcs. In the client-server architecture, none of the peers aids in \ndistributing the file. We make the following observations:\n\u2022 The server must transmit one copy of the file to each of the N peers. Thus the \nserver must transmit NF bits. Since the server\u2019s upload rate is us, the time to dis -\ntribute the file must be at least NF/us.\n\u2022 Let dmin denote the download rate of the peer with the lowest download rate, that \nis, dmin=min5d1, dp, . . . , dN6. The peer with the lowest download rate cannot \nobtain all F bits of the file in less than", "doc_id": "9332b2b1-965a-498a-8a52-66b04793ecad", "embedding": null, "doc_hash": "69384f544138c35f9165f224f85f698998ff24c4b7e2540fbf0f8d26675646fc", "extra_info": null, "node_info": {"start": 491257, "end": 494946}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "d0b81fb1-2dd8-4e89-aea8-c56aef7a99e0", "3": "a9f2fba3-8782-4448-8c1f-7aa1651152b0"}}, "__type__": "1"}, "a9f2fba3-8782-4448-8c1f-7aa1651152b0": {"__data__": {"text": "can be fully devoted to distributing this file.\nLet\u2019s first determine the distribution time for the client-server architecture, \nwhich we denote by Dcs. In the client-server architecture, none of the peers aids in \ndistributing the file. We make the following observations:\n\u2022 The server must transmit one copy of the file to each of the N peers. Thus the \nserver must transmit NF bits. Since the server\u2019s upload rate is us, the time to dis -\ntribute the file must be at least NF/us.\n\u2022 Let dmin denote the download rate of the peer with the lowest download rate, that \nis, dmin=min5d1, dp, . . . , dN6. The peer with the lowest download rate cannot \nobtain all F bits of the file in less than F/dmin seconds. Thus the minimum distri -\nbution time is at least F/dmin.\nPutting these two observations together, we obtain\nDcs\u00damaxbNF\nus , F\ndminr.\nThis provides a lower bound on the minimum distribution time for the client-server \narchitecture. In the homework problems you will be asked to show that the server can \nschedule its transmissions so that the lower bound is actually achieved. So let\u2019s take \nthis lower bound provided above as the actual distribution time, that is,\n Dcs=maxbNF\nus, F\ndminr ( 2.1)\nWe see from Equation 2.1 that for N large enough, the client-server distribution time \nis given by NF/us. Thus, the distribution time increases linearly with the number of \npeers N. So, for example, if the number of peers from one week to the next increases \na thousand-fold from a thousand to a million, the time required to distribute the file \nto all peers increases by 1,000.\nLet\u2019s now go through a similar analysis for the P2P architecture, where each peer \ncan assist the server in distributing the file. In particular, when a peer receives some \nfile data, it can use its own upload capacity to redistribute the data to other peers. Cal -\nculating the distribution time for the P2P architecture is somewhat more complicated \nthan for the client-server architecture, since the distribution time depends on how \neach peer distributes portions of the file to the other peers. Nevertheless, a simple \n2.5  \u2022  PEER-TO-PEER FILE DISTRIBUTION      171\nexpression for the minimal distribution time can be obtained [Kumar 2006]. To this \nend, we first make the following observations:\n\u2022 At the beginning of the distribution, only the server has the file. To get this file \ninto the community of peers, the server must send each bit of the file at least once \ninto its access link. Thus, the minimum distribution time is at least F/us. (Unlike \nthe client-server scheme, a bit sent once by the server may not have to be sent by \nthe server again, as the peers may redistribute the bit among themselves.)\n\u2022 As with the client-server architecture, the peer with the lowest download rate \ncannot obtain all F bits of the file in less than F/dmin seconds. Thus the minimum \ndistribution time is at least F/dmin.\n\u2022 Finally, observe that the total upload capacity of the system as a whole is equal \nto the upload rate of the server plus the upload rates of each of the individual \npeers, that is, utotal=us+u1+g+uN. The system must deliver (upload) F \nbits to each of the N peers, thus delivering a total of NF bits. This cannot be done \nat a rate faster than utotal. Thus, the minimum distribution time is also at least \nNF/(us+u1+g+uN).\nPutting these three observations together, we obtain the minimum distribution \ntime for P2P, denoted by DP2P.\n DP2P\u00damax cF\nus, F\ndmin, NF\nus+aN\ni=1uis ( 2.2)\nEquation 2. 2 provides a lower bound for the minimum distribution time for the P2P", "doc_id": "a9f2fba3-8782-4448-8c1f-7aa1651152b0", "embedding": null, "doc_hash": "176ae8f215dcd7c312d25a331c48409c98920f4226d1ce5a400013bf542de75f", "extra_info": null, "node_info": {"start": 495023, "end": 498598}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "9332b2b1-965a-498a-8a52-66b04793ecad", "3": "1cb06d55-a4fd-496a-bb58-0f87d2ed8aad"}}, "__type__": "1"}, "1cb06d55-a4fd-496a-bb58-0f87d2ed8aad": {"__data__": {"text": "of the system as a whole is equal \nto the upload rate of the server plus the upload rates of each of the individual \npeers, that is, utotal=us+u1+g+uN. The system must deliver (upload) F \nbits to each of the N peers, thus delivering a total of NF bits. This cannot be done \nat a rate faster than utotal. Thus, the minimum distribution time is also at least \nNF/(us+u1+g+uN).\nPutting these three observations together, we obtain the minimum distribution \ntime for P2P, denoted by DP2P.\n DP2P\u00damax cF\nus, F\ndmin, NF\nus+aN\ni=1uis ( 2.2)\nEquation 2. 2 provides a lower bound for the minimum distribution time for the P2P \narchitecture. It turns out that if we imagine that each peer can redistribute a bit as \nsoon as it receives the bit, then there is a redistribution scheme that actually achieves \nthis lower bound [Kumar 2006]. (We will prove a special case of this result in the \nhomework.) In reality, where chunks of the file are redistributed rather than indi -\nvidual bits, Equation 2.2 serves as a good approximation of the actual minimum \ndistribution time. Thus, let\u2019s take the lower bound provided by Equation 2.2 as the \nactual minimum distribution time, that is,\n DP2P=max cF\nus, F\ndmin, NF\nus+aN\ni=1uis ( 2.3)\nFigure 2. 23 compares the minimum distribution time for the client-server and \nP2P architectures assuming that all peers have the same upload rate u. In Figure 2.23, \nwe have set F/u=1 hour, us=10u, and dmin\u00daus. Thus, a peer can transmit the \nentire file in one hour, the server transmission rate is 10 times the peer upload rate, \n172     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nand (for simplicity) the peer download rates are set large enough so as not to have \nan effect. We see from Figure 2.23 that for the client-server architecture, the distri -\nbution time increases linearly and without bound as the number of peers increases. \nHowever, for the P2P architecture, the minimal distribution time is not only always \nless than the distribution time of the client-server architecture; it is also less than one \nhour for any number of peers N. Thus, applications with the P2P architecture can be \nself-scaling. This scalability is a direct consequence of peers being redistributors as \nwell as consumers of bits.\nBitTorrent\nBitTorrent is a popular P2P protocol for file distribution [Chao 2011]. In BitTorrent \nlingo, the collection of all peers participating in the distribution of a particular file is \ncalled a torrent . Peers in a torrent download equal-size chunks  of the file from one \nanother, with a typical chunk size of 256 kbytes. When a peer first joins a torrent, it \nhas no chunks. Over time it accumulates more and more chunks. While it downloads \nchunks it also uploads chunks to other peers. Once a peer has acquired the entire \nfile, it may (selfishly) leave the torrent, or (altruistically) remain in the torrent and \ncontinue to upload chunks to other peers. Also, any peer may leave the torrent at any \ntime with only a subset of chunks, and later rejoin the torrent.\nLet\u2019s now take a closer look at how BitTorrent operates. Since BitTorrent is \na rather complicated protocol and system, we\u2019ll only describe its most important \nmechanisms, sweeping some of the details under the rug; this will allow us to see \nthe forest through the trees. Each torrent has an infrastructure node called a tracker . 0\n5 10 15 20 25 30 0\nNMinimum distributioin tiime\n350.51.52.5\n1.03.0\n2.03.5\nClient-Server\nP2P\nFigure 2.23  \u2666 Distribution time for P2P and client-server", "doc_id": "1cb06d55-a4fd-496a-bb58-0f87d2ed8aad", "embedding": null, "doc_hash": "5de60cb0041c968055ff35848fdb3de9b8ebe5aa47d71f3cd1850aee6581c593", "extra_info": null, "node_info": {"start": 498656, "end": 502150}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "a9f2fba3-8782-4448-8c1f-7aa1651152b0", "3": "5988199f-801a-4965-9cf6-6fb0a092f582"}}, "__type__": "1"}, "5988199f-801a-4965-9cf6-6fb0a092f582": {"__data__": {"text": "remain in the torrent and \ncontinue to upload chunks to other peers. Also, any peer may leave the torrent at any \ntime with only a subset of chunks, and later rejoin the torrent.\nLet\u2019s now take a closer look at how BitTorrent operates. Since BitTorrent is \na rather complicated protocol and system, we\u2019ll only describe its most important \nmechanisms, sweeping some of the details under the rug; this will allow us to see \nthe forest through the trees. Each torrent has an infrastructure node called a tracker . 0\n5 10 15 20 25 30 0\nNMinimum distributioin tiime\n350.51.52.5\n1.03.0\n2.03.5\nClient-Server\nP2P\nFigure 2.23  \u2666 Distribution time for P2P and client-server architectures\n2.5  \u2022  PEER-TO-PEER FILE DISTRIBUTION      173\nWhen a peer joins a torrent, it registers itself with the tracker and periodically informs \nthe tracker that it is still in the torrent. In this manner, the tracker keeps track of the \npeers that are participating in the torrent. A given torrent may have fewer than ten or \nmore than a thousand peers participating at any instant of time.\nAs shown in Figure 2.24, when a new peer, Alice, joins the torrent, the tracker \nrandomly selects a subset of peers (for concreteness, say 50) from the set of partici -\npating peers, and sends the IP addresses of these 50 peers to Alice. Possessing this \nlist of peers, Alice attempts to establish concurrent TCP connections with all the \npeers on this list. Let\u2019s call all the peers with which Alice succeeds in establishing a \nTCP connection \u201cneighboring peers.\u201d (In Figure 2.24, Alice is shown to have only \nthree neighboring peers. Normally, she would have many more.) As time evolves, \nsome of these peers may leave and other peers (outside the initial 50) may attempt to \nestablish TCP connections with Alice. So a peer\u2019s neighboring peers will fluctuate \nover time.\nAt any given time, each peer will have a subset of chunks from the file, with dif -\nferent peers having different subsets. Periodically, Alice will ask each of her neigh -\nboring peers (over the TCP connections) for the list of the chunks they have. If Alice \nhas L different neighbors, she will obtain L lists of chunks. With this knowledge, Tracker\nTrading chunksPeer\nObtain\nlist of\npeers\nAlice\nFigure 2.24  \u2666 File distribution with BitTorrent\n174     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nAlice will issue requests (again over the TCP connections) for chunks she currently \ndoes not have.\nSo at any given instant of time, Alice will have a subset of chunks and will know \nwhich chunks her neighbors have. With this information, Alice will have two impor -\ntant decisions to make. First, which chunks should she request first from her neigh -\nbors? And second, to which of her neighbors should she send requested chunks? In \ndeciding which chunks to request, Alice uses a technique called rarest first . The \nidea is to determine, from among the chunks she does not have, the chunks that are \nthe rarest among her neighbors (that is, the chunks that have the fewest repeated cop -\nies among her neighbors) and then request those rarest chunks first. In this manner, \nthe rarest chunks get more quickly redistributed, aiming to (roughly) equalize the \nnumbers of copies of each chunk in the torrent.\nTo determine which requests she responds to, BitTorrent uses a clever trading \nalgorithm. The basic idea is that Alice gives priority to the neighbors that are cur -\nrently supplying her data at the highest rate . Specifically, for each of her neighbors, \nAlice continually measures the rate at which she receives bits and determines the \nfour peers that are", "doc_id": "5988199f-801a-4965-9cf6-6fb0a092f582", "embedding": null, "doc_hash": "11d81b8423e8ea1cf941d499509f1e23647f64067d254e7e3363883ddc196432", "extra_info": null, "node_info": {"start": 502105, "end": 505699}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "1cb06d55-a4fd-496a-bb58-0f87d2ed8aad", "3": "cf47a9ad-a0f5-481e-8530-b0094df08148"}}, "__type__": "1"}, "cf47a9ad-a0f5-481e-8530-b0094df08148": {"__data__": {"text": "is to determine, from among the chunks she does not have, the chunks that are \nthe rarest among her neighbors (that is, the chunks that have the fewest repeated cop -\nies among her neighbors) and then request those rarest chunks first. In this manner, \nthe rarest chunks get more quickly redistributed, aiming to (roughly) equalize the \nnumbers of copies of each chunk in the torrent.\nTo determine which requests she responds to, BitTorrent uses a clever trading \nalgorithm. The basic idea is that Alice gives priority to the neighbors that are cur -\nrently supplying her data at the highest rate . Specifically, for each of her neighbors, \nAlice continually measures the rate at which she receives bits and determines the \nfour peers that are feeding her bits at the highest rate. She then reciprocates by send -\ning chunks to these same four peers. Every 10 seconds, she recalculates the rates \nand possibly modifies the set of four peers. In BitTorrent lingo, these four peers are \nsaid to be unchoked . Importantly, every 30 seconds, she also picks one additional \nneighbor at random and sends it chunks. Let\u2019s call the randomly chosen peer Bob. \nIn BitTorrent lingo, Bob is said to be optimistically unchoked . Because Alice is \nsending data to Bob, she may become one of Bob\u2019s top four uploaders, in which case \nBob would start to send data to Alice. If the rate at which Bob sends data to Alice \nis high enough, Bob could then, in turn, become one of Alice\u2019s top four uploaders. \nIn other words, every 30 seconds, Alice will randomly choose a new trading partner \nand initiate trading with that partner. If the two peers are satisfied with the trading, \nthey will put each other in their top four lists and continue trading with each other \nuntil one of the peers finds a better partner. The effect is that peers capable of upload -\ning at compatible rates tend to find each other. The random neighbor selection also \nallows new peers to get chunks, so that they can have something to trade. All other \nneighboring peers besides these five peers (four \u201ctop\u201d peers and one probing peer) \nare \u201cchoked,\u201d that is, they do not receive any chunks from Alice. BitTorrent has \na number of interesting mechanisms that are not discussed here, including pieces \n(mini-chunks), pipelining, random first selection, endgame mode, and anti-snubbing \n[Cohen 2003].\nThe incentive mechanism for trading just described is often referred to as tit-for-\ntat [Cohen 2003]. It has been shown that this incentive scheme can be circumvented \n[Liogkas 2006; Locher 2006; Piatek 2007]. Nevertheless, the BitTorrent ecosystem \nis wildly successful, with millions of simultaneous peers actively sharing files in \nhundreds of thousands of torrents. If BitTorrent had been designed without tit-for-tat \n(or a variant), but otherwise exactly the same, BitTorrent would likely not even exist \nnow, as the majority of the users would have been freeriders [Saroiu 2002].\n2.6  \u2022  VIDEO STREAMING AND CONTENT DISTRIBUTION NETWORKS      175\nWe close our discussion on P2P by briefly mentioning another application of P2P, \nnamely, Distributed Hast Table (DHT). A distributed hash table is a simple database, \nwith the database records being distributed over the peers in a P2P system. DHTs have \nbeen widely implemented (e.g., in BitTorrent) and have been the subject of extensive \nresearch. An overview is provided in a Video Note in the companion website. \n2.6 Video Streaming and Content Distribution \nNetworks\nStreaming prerecorded video now accounts for the majority of the traffic in residen-\ntial ISPs in North America. In particular, the Netflix and YouTube services alone \nconsumed a whopping 37% and 16%, respectively, of residential ISP traffic in 2015 \n[Sandvine 2015]. In this section we will provide an overview of how", "doc_id": "cf47a9ad-a0f5-481e-8530-b0094df08148", "embedding": null, "doc_hash": "1372ae6e2cebfb46173270d767efd430405eaf87dcea97d6bc588a7a659af84e", "extra_info": null, "node_info": {"start": 505638, "end": 509439}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "5988199f-801a-4965-9cf6-6fb0a092f582", "3": "74579c95-b9e9-4f2a-a976-af9cd3e7ccfd"}}, "__type__": "1"}, "74579c95-b9e9-4f2a-a976-af9cd3e7ccfd": {"__data__": {"text": "by briefly mentioning another application of P2P, \nnamely, Distributed Hast Table (DHT). A distributed hash table is a simple database, \nwith the database records being distributed over the peers in a P2P system. DHTs have \nbeen widely implemented (e.g., in BitTorrent) and have been the subject of extensive \nresearch. An overview is provided in a Video Note in the companion website. \n2.6 Video Streaming and Content Distribution \nNetworks\nStreaming prerecorded video now accounts for the majority of the traffic in residen-\ntial ISPs in North America. In particular, the Netflix and YouTube services alone \nconsumed a whopping 37% and 16%, respectively, of residential ISP traffic in 2015 \n[Sandvine 2015]. In this section we will provide an overview of how popular video \nstreaming services are implemented in today\u2019s Internet. We will see they are imple -\nmented using application-level protocols and servers that function in some ways like \na cache. In Chapter 9, devoted to multimedia networking, we will further examine \nInternet video as well as other Internet multimedia services.\n2.6.1  Internet Video\nIn streaming stored video applications, the underlying medium is prerecorded video, \nsuch as a movie, a television show, a prerecorded sporting event, or a prerecorded \nuser-generated video (such as those commonly seen on YouTube). These prere -\ncorded videos are placed on servers, and users send requests to the servers to view \nthe videos on demand . Many Internet companies today provide streaming video, \nincluding, Netflix, YouTube (Google), Amazon, and Youku.\nBut before launching into a discussion of video streaming, we should first get \na quick feel for the video medium itself. A video is a sequence of images, typi -\ncally being displayed at a constant rate, for example, at 24 or 30 images per second. \nAn uncompressed, digitally encoded image consists of an array of pixels, with each \npixel encoded into a number of bits to represent luminance and color. An important \ncharacteristic of video is that it can be compressed, thereby trading off video quality \nwith bit rate. Today\u2019s off-the-shelf compression algorithms can compress a video to \nessentially any bit rate desired. Of course, the higher the bit rate, the better the image \nquality and the better the overall user viewing experience.\nFrom a networking perspective, perhaps the most salient characteristic of video \nis its high bit rate. Compressed Internet video typically ranges from 100 kbps for \nlow-quality video to over 3 Mbps for streaming high-definition movies; 4K stream -\ning envisions a bitrate of more than 10 Mbps. This can translate to huge amount of \ntraffic and storage, particularly for high-end video. For example, a single 2 Mbps VideoNote\nWalking though \ndistributed hash tables\n176     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nvideo with a duration of 67 minutes will consume 1 gigabyte of storage and traffic. \nBy far, the most important performance measure for streaming video is average end-\nto-end throughput. In order to provide continuous playout, the network must provide \nan average throughput to the streaming application that is at least as large as the bit \nrate of the compressed video.\nWe can also use compression to create multiple versions of the same video, each \nat a different quality level. For example, we can use compression to create, say, three \nversions of the same video, at rates of 300 kbps, 1 Mbps, and 3 Mbps. Users can then \ndecide which version they want to watch as a function of their current available band -\nwidth. Users with high-speed Internet connections might choose the 3 Mbps version; \nusers watching the video over 3G with a smartphone might choose the 300 kbps version.\n2.6.2  HTTP Streaming and DASH\nIn HTTP streaming, the video is simply stored at an HTTP server as an ordinary \nfile with a specific URL. When a user wants to see the video, the client establishes \na TCP connection with the server and issues an HTTP GET request for that URL. \nThe server then sends the video file, within an HTTP response message, as quickly \nas", "doc_id": "74579c95-b9e9-4f2a-a976-af9cd3e7ccfd", "embedding": null, "doc_hash": "83b42b67e981feb38ecb295c188aa50f32706568db74305ddaddc4db9abc3663", "extra_info": null, "node_info": {"start": 509417, "end": 513495}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "cf47a9ad-a0f5-481e-8530-b0094df08148", "3": "a0d2cb06-36e3-4c85-ae7c-bae29f3d73de"}}, "__type__": "1"}, "a0d2cb06-36e3-4c85-ae7c-bae29f3d73de": {"__data__": {"text": "video, each \nat a different quality level. For example, we can use compression to create, say, three \nversions of the same video, at rates of 300 kbps, 1 Mbps, and 3 Mbps. Users can then \ndecide which version they want to watch as a function of their current available band -\nwidth. Users with high-speed Internet connections might choose the 3 Mbps version; \nusers watching the video over 3G with a smartphone might choose the 300 kbps version.\n2.6.2  HTTP Streaming and DASH\nIn HTTP streaming, the video is simply stored at an HTTP server as an ordinary \nfile with a specific URL. When a user wants to see the video, the client establishes \na TCP connection with the server and issues an HTTP GET request for that URL. \nThe server then sends the video file, within an HTTP response message, as quickly \nas the underlying network protocols and traffic conditions will allow. On the client \nside, the bytes are collected in a client application buffer. Once the number of bytes \nin this buffer exceeds a predetermined threshold, the client application begins play -\nback\u2014specifically, the streaming video application periodically grabs video frames \nfrom the client application buffer, decompresses the frames, and displays them on \nthe user\u2019s screen. Thus, the video streaming application is displaying video as it is \nreceiving and buffering frames corresponding to latter parts of the video.\nAlthough HTTP streaming, as described in the previous paragraph, has been \nextensively deployed in practice (for example, by YouTube since its inception), it has \na major shortcoming: All clients receive the same encoding of the video, despite the \nlarge variations in the amount of bandwidth available to a client, both across different \nclients and also over time for the same client. This has led to the development of a new \ntype of HTTP-based streaming, often referred to as Dynamic Adaptive Streaming \nover HTTP (DASH) . In DASH, the video is encoded into several different versions, \nwith each version having a different bit rate and, correspondingly, a different quality \nlevel. The client dynamically requests chunks of video segments of a few seconds in \nlength. When the amount of available bandwidth is high, the client naturally selects \nchunks from a high-rate version; and when the available bandwidth is low, it naturally \nselects from a low-rate version. The client selects different chunks one at a time with \nHTTP GET request messages [Akhshabi 2011].\nDASH allows clients with different Internet access rates to stream in video at \ndifferent encoding rates. Clients with low-speed 3G connections can receive a low \nbit-rate (and low-quality) version, and clients with fiber connections can receive a \nhigh-quality version. DASH also allows a client to adapt to the available bandwidth \nif the available end-to-end bandwidth changes during the session. This feature is \n2.6  \u2022  VIDEO STREAMING AND CONTENT DISTRIBUTION NETWORKS      177\nparticularly important for mobile users, who typically see their bandwidth availabil -\nity fluctuate as they move with respect to the base stations.\nWith DASH, each video version is stored in the HTTP server, each with a differ -\nent URL. The HTTP server also has a manifest file , which provides a URL for each \nversion along with its bit rate. The client first requests the manifest file and learns \nabout the various versions. The client then selects one chunk at a time by specifying a \nURL and a byte range in an HTTP GET request message for each chunk. While down -\nloading chunks, the client also measures the received bandwidth and runs a rate deter -\nmination algorithm to select the chunk to request next. Naturally, if the client has a lot \nof video buffered and if the measured receive bandwidth is high, it will choose a chunk \nfrom a high-bitrate version. And naturally if the client has little video buffered and the \nmeasured received bandwidth is low, it will choose a chunk from a low-bitrate version. \nDASH therefore allows the client to freely switch among different quality levels.\n2.6.3  Content Distribution Networks\nToday, many Internet video companies are distributing on-demand multi-Mbps \nstreams to millions of users on a daily", "doc_id": "a0d2cb06-36e3-4c85-ae7c-bae29f3d73de", "embedding": null, "doc_hash": "dbe85772ed878c62bcc4d0b2ae8c56acde20279b9200202f6ee3fe1c39117222", "extra_info": null, "node_info": {"start": 513474, "end": 517679}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "74579c95-b9e9-4f2a-a976-af9cd3e7ccfd", "3": "5c845ae8-265e-4d36-bc0c-995a8653fef9"}}, "__type__": "1"}, "5c845ae8-265e-4d36-bc0c-995a8653fef9": {"__data__": {"text": "one chunk at a time by specifying a \nURL and a byte range in an HTTP GET request message for each chunk. While down -\nloading chunks, the client also measures the received bandwidth and runs a rate deter -\nmination algorithm to select the chunk to request next. Naturally, if the client has a lot \nof video buffered and if the measured receive bandwidth is high, it will choose a chunk \nfrom a high-bitrate version. And naturally if the client has little video buffered and the \nmeasured received bandwidth is low, it will choose a chunk from a low-bitrate version. \nDASH therefore allows the client to freely switch among different quality levels.\n2.6.3  Content Distribution Networks\nToday, many Internet video companies are distributing on-demand multi-Mbps \nstreams to millions of users on a daily basis. YouTube, for example, with a library \nof hundreds of millions of videos, distributes hundreds of millions of video streams \nto users around the world every day. Streaming all this traffic to locations all over \nthe world while providing continuous playout and high interactivity is clearly a chal -\nlenging task.\nFor an Internet video company, perhaps the most straightforward approach to \nproviding streaming video service is to build a single massive data center, store all \nof its videos in the data center, and stream the videos directly from the data center \nto clients worldwide. But there are three major problems with this approach. First, if \nthe client is far from the data center, server-to-client packets will cross many com -\nmunication links and likely pass through many ISPs, with some of the ISPs possibly \nlocated on different continents. If one of these links provides a throughput that is less \nthan the video consumption rate, the end-to-end throughput will also be below the \nconsumption rate, resulting in annoying freezing delays for the user. (Recall from \nChapter 1 that the end-to-end throughput of a stream is governed by the throughput \nat the bottleneck link.) The likelihood of this happening increases as the number of \nlinks in the end-to-end path increases. A second drawback is that a popular video will \nlikely be sent many times over the same communication links. Not only does this \nwaste network bandwidth, but the Internet video company itself will be paying its \nprovider ISP (connected to the data center) for sending the same  bytes into the Inter -\nnet over and over again. A third problem with this solution is that a single data center \nrepresents a single point of failure\u2014if the data center or its links to the Internet goes \ndown, it would not be able to distribute any video streams.\nIn order to meet the challenge of distributing massive amounts of video data \nto users distributed around the world, almost all major video-streaming companies \nmake use of Content Distribution Networks (CDNs) . A CDN manages servers in \n178     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nmultiple geographically distributed locations, stores copies of the videos (and other \ntypes of Web content, including documents, images, and audio) in its servers, and \nattempts to direct each user request to a CDN location that will provide the best user \nexperience. The CDN may be a private CDN , that is, owned by the content provider \nitself; for example, Google\u2019s CDN distributes YouTube videos and other types of \ncontent. The CDN may alternatively be a third-party CDN  that distributes content \non behalf of multiple content providers; Akamai, Limelight and Level-3 all operate \nthird-party CDNs. A very readable overview of modern CDNs is [Leighton 2009; \nNygren 2010].\nCDNs typically adopt one of two different server placement philosophies \n[Huang 2008]:\n\u2022 Enter Deep.  One philosophy, pioneered by Akamai, is to enter deep  into the \naccess networks of Internet Service Providers, by deploying server clusters in \naccess ISPs all over the world. (Access networks are described in Section 1.3.) \nAkamai takes this approach with clusters in approximately 1,700 locations. The \ngoal is to get close to end users, thereby improving user-perceived delay and", "doc_id": "5c845ae8-265e-4d36-bc0c-995a8653fef9", "embedding": null, "doc_hash": "1cf50ecdbe06d1a93726aee8a631af6c73fadcfdb6e16f17eb0ce622c5ece2c1", "extra_info": null, "node_info": {"start": 517675, "end": 521764}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "a0d2cb06-36e3-4c85-ae7c-bae29f3d73de", "3": "a313f9b2-6bc9-4e46-b218-e646e9357f56"}}, "__type__": "1"}, "a313f9b2-6bc9-4e46-b218-e646e9357f56": {"__data__": {"text": "The CDN may alternatively be a third-party CDN  that distributes content \non behalf of multiple content providers; Akamai, Limelight and Level-3 all operate \nthird-party CDNs. A very readable overview of modern CDNs is [Leighton 2009; \nNygren 2010].\nCDNs typically adopt one of two different server placement philosophies \n[Huang 2008]:\n\u2022 Enter Deep.  One philosophy, pioneered by Akamai, is to enter deep  into the \naccess networks of Internet Service Providers, by deploying server clusters in \naccess ISPs all over the world. (Access networks are described in Section 1.3.) \nAkamai takes this approach with clusters in approximately 1,700 locations. The \ngoal is to get close to end users, thereby improving user-perceived delay and \nthroughput by decreasing the number of links and routers between the end user \nand the CDN server from which it receives content. Because of this highly dis -\ntributed design, the task of maintaining and managing the clusters becomes chal -\nlenging.\n\u2022 Bring Home.  A second design philosophy, taken by Limelight and many other \nCDN companies, is to bring the ISPs home  by building large clusters at a smaller \nnumber (for example, tens) of sites. Instead of getting inside the access ISPs, \nthese CDNs typically place their clusters in Internet Exchange Points (IXPs) (see \nSection 1.3 ). Compared with the enter-deep design philosophy, the bring-home \ndesign typically results in lower maintenance and management overhead, pos -\nsibly at the expense of higher delay and lower throughput to end users.\nOnce its clusters are in place, the CDN replicates content across its clusters. The \nCDN may not want to place a copy of every video in each cluster, since some videos \nare rarely viewed or are only popular in some countries. In fact, many CDNs do not \npush videos to their clusters but instead use a simple pull strategy: If a client requests \na video from a cluster that is not storing the video, then the cluster retrieves the \nvideo (from a central repository or from another cluster) and stores a copy locally \nwhile streaming the video to the client at the same time. Similar Web caching (see \nSection 2.2. 5), when a cluster\u2019s storage becomes full, it removes videos that are not \nfrequently requested.\nCDN Operation\nHaving identified the two major approaches toward deploying a CDN, let\u2019s now dive \ndown into the nuts and bolts of how a CDN operates. When a browser in a user\u2019s \n2.6  \u2022  VIDEO STREAMING AND CONTENT DISTRIBUTION NETWORKS      179\nhost is instructed to retrieve a specific video (identified by a URL), the CDN must \nintercept the request so that it can (1) determine a suitable CDN server cluster for that \nclient at that time, and (2) redirect the client\u2019s request to a server in that cluster. We\u2019ll \nshortly discuss how a CDN can determine a suitable cluster. But first let\u2019s examine \nthe mechanics behind intercepting and redirecting a request.\nMost CDNs take advantage of DNS to intercept and redirect requests; an inter -\nesting discussion of such a use of the DNS is [Vixie 2009]. Let\u2019s consider a simple GOOGLE\u2019S NETWORK INFRASTRUCTURE\nTo support its vast array of cloud services\u2014including search, Gmail, calendar, \nYouTube video, maps, documents, and social networks\u2014Google has deployed an \nextensive private network and CDN infrastructure. Google\u2019s CDN infrastructure has \nthree tiers of server clusters:\n\u2022\t Fourteen \u201cmega data centers,\u201d with eight in North America, four in Europe, and \ntwo in Asia [Google Locations 2016], with each data center having on the order \nof 100,000 servers. These mega data centers are responsible for serving dynamic \n(and often personalized) content, including search results and Gmail messages.\n\u2022\t An estimated 50 clusters in IXPs scattered throughout the world, with each cluster \nconsisting on the order", "doc_id": "a313f9b2-6bc9-4e46-b218-e646e9357f56", "embedding": null, "doc_hash": "a44a077fccbfaf0edbec937d45302dc9a0f7746102ce4e0430acf41980149ca1", "extra_info": null, "node_info": {"start": 521812, "end": 525622}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "5c845ae8-265e-4d36-bc0c-995a8653fef9", "3": "a22cdac0-7bd7-4822-b847-8a456dbab849"}}, "__type__": "1"}, "a22cdac0-7bd7-4822-b847-8a456dbab849": {"__data__": {"text": "Let\u2019s consider a simple GOOGLE\u2019S NETWORK INFRASTRUCTURE\nTo support its vast array of cloud services\u2014including search, Gmail, calendar, \nYouTube video, maps, documents, and social networks\u2014Google has deployed an \nextensive private network and CDN infrastructure. Google\u2019s CDN infrastructure has \nthree tiers of server clusters:\n\u2022\t Fourteen \u201cmega data centers,\u201d with eight in North America, four in Europe, and \ntwo in Asia [Google Locations 2016], with each data center having on the order \nof 100,000 servers. These mega data centers are responsible for serving dynamic \n(and often personalized) content, including search results and Gmail messages.\n\u2022\t An estimated 50 clusters in IXPs scattered throughout the world, with each cluster \nconsisting on the order of 100\u2013500 servers [Adhikari 2011a]. These clusters are \nresponsible for serving static content, including YouTube videos [Adhikari 2011a].\n\u2022\t Many hundreds of \u201center-deep\u201d clusters located within an access ISP. Here a cluster \ntypically consists of tens of servers within a single rack. These enter-deep  servers \nperform TCP splitting (see Section 3.7 ) and serve static content [Chen 2011], \nincluding the static portions of Web pages that embody search results.\nAll of these data centers and cluster locations are networked together with \nGoogle\u2019s own private network. When a user makes a search query, often the query \nis first sent over the local ISP to a nearby enter-deep cache, from where the static \ncontent is retrieved; while providing the static content to the client, the nearby cache \nalso forwards the query over Google\u2019s private network to one of the mega data cent -\ners, from where the personalized search results are retrieved. For a YouTube video, \nthe video itself may come from one of the bring-home caches, whereas portions of \nthe Web page surrounding the video may come from the nearby enter-deep cache, \nand the advertisements surrounding the video come from the data centers. In sum -\nmary, except for the local ISPs, the Google cloud services are largely provided by a \nnetwork infrastructure that is independent of the public Internet.CASE STUDY\n\n180     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nexample to illustrate how the DNS is typically involved. Suppose a content provider, \nNetCinema, employs the third-party CDN company, KingCDN, to distribute its vid -\neos to its customers. On the NetCinema Web pages, each of its videos is assigned a \nURL that includes the string \u201cvideo\u201d and a unique identifier for the video itself; for \nexample, Transformers 7  might be assigned http://video.netcinema.com/6Y7B23V. \nSix steps then occur, as shown in Figure 2.25:\n 1. The user visits the Web page at NetCinema.\n 2. When the user clicks on the link http://video.netcinema.com/6Y7B23V, the \nuser\u2019s host sends a DNS query for video.netcinema.com.\n 3. The user\u2019s Local DNS Server (LDNS) relays the DNS query to an authoritative \nDNS server for NetCinema, which observes the string \u201cvideo\u201d in the host -\nname video.netcinema.com. To \u201chand over\u201d the DNS query to KingCDN, \ninstead of returning an IP address, the NetCinema authoritative DNS server \nreturns to the LDNS a hostname in the KingCDN\u2019s domain, for example, \na1105.kingcdn.com.\n 4. From this point on, the DNS query enters into KingCDN\u2019s private DNS infra -\nstructure. The user\u2019s LDNS then sends a second query, now for a1105.kingcdn.\ncom, and KingCDN\u2019s DNS system eventually returns the IP addresses of a \nKingCDN content server to the LDNS. It is thus here, within the KingCDN\u2019s \nDNS system, that the CDN server from which the client will receive its content", "doc_id": "a22cdac0-7bd7-4822-b847-8a456dbab849", "embedding": null, "doc_hash": "016eca50716f24f8064efbd4de6169314d074ac5f8e5f4442ead343bc46bd57b", "extra_info": null, "node_info": {"start": 525594, "end": 529191}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "a313f9b2-6bc9-4e46-b218-e646e9357f56", "3": "73b28b77-810f-4f14-be49-b87e119cae14"}}, "__type__": "1"}, "73b28b77-810f-4f14-be49-b87e119cae14": {"__data__": {"text": "-\nname video.netcinema.com. To \u201chand over\u201d the DNS query to KingCDN, \ninstead of returning an IP address, the NetCinema authoritative DNS server \nreturns to the LDNS a hostname in the KingCDN\u2019s domain, for example, \na1105.kingcdn.com.\n 4. From this point on, the DNS query enters into KingCDN\u2019s private DNS infra -\nstructure. The user\u2019s LDNS then sends a second query, now for a1105.kingcdn.\ncom, and KingCDN\u2019s DNS system eventually returns the IP addresses of a \nKingCDN content server to the LDNS. It is thus here, within the KingCDN\u2019s \nDNS system, that the CDN server from which the client will receive its content \nis specified.\nLocal\nDNS serverNetCinema authoritative\n DNS serverwww.NetCinema.com\nKingCDN authoritative\nserver\nKingCDN content\ndistribution server2\n5\n631\n4\nFigure 2.25  \u2666 DNS redirects a user\u2019s request to a CDN server\n2.6  \u2022  VIDEO STREAMING AND CONTENT DISTRIBUTION NETWORKS      181\n 5. The LDNS forwards the IP address of the content-serving CDN node to the \nuser\u2019s host.\n 6. Once the client receives the IP address for a KingCDN content server, it estab -\nlishes a direct TCP connection with the server at that IP address and issues an \nHTTP GET request for the video. If DASH is used, the server will first send to \nthe client a manifest file with a list of URLs, one for each version of the video, \nand the client will dynamically select chunks from the different versions.\nCluster Selection Strategies\nAt the core of any CDN deployment is a cluster selection strategy , that is, a mecha -\nnism for dynamically directing clients to a server cluster or a data center within the \nCDN. As we just saw, the CDN learns the IP address of the client\u2019s LDNS server \nvia the client\u2019s DNS lookup. After learning this IP address, the CDN needs to select \nan appropriate cluster based on this IP address. CDNs generally employ proprietary \ncluster selection strategies. We now briefly survey a few approaches, each of which \nhas its own advantages and disadvantages.\nOne simple strategy is to assign the client to the cluster that is geographically clos -\nest. Using commercial geo-location databases (such as Quova [Quova 2016] and Max-\nMind [MaxMind 2016]), each LDNS IP address is mapped to a geographic location. \nWhen a DNS request is received from a particular LDNS, the CDN chooses the geo -\ngraphically closest cluster, that is, the cluster that is the fewest kilometers from the LDNS \n\u201cas the bird flies.\u201d Such a solution can work reasonably well for a large fraction of the cli -\nents [Agarwal 2009]. However, for some clients, the solution may perform poorly, since \nthe geographically closest cluster may not be the closest cluster in terms of the length \nor number of hops of the network path. Furthermore, a problem inherent with all DNS-\nbased approaches is that some end-users are configured to use remotely located LDNSs \n[Shaikh 2001; Mao 2002], in which case the LDNS location may be far from the client\u2019s \nlocation. Moreover, this simple strategy ignores the variation in delay and available band -\nwidth over time of Internet paths, always assigning the same cluster to a particular client.\nIn order to determine the best cluster for a client based on the current  traffic \nconditions, CDNs can instead perform periodic real-time measurements  of delay \nand loss performance between their clusters and clients. For instance, a CDN can \nhave each of its clusters periodically send probes (for example, ping messages or \nDNS queries) to all of the LDNSs around the world. One drawback of this approach \nis that many LDNSs are configured to not respond to such probes.\n2.6.4 ", "doc_id": "73b28b77-810f-4f14-be49-b87e119cae14", "embedding": null, "doc_hash": "dc0ab1dcd27fe5831a02be85dba3ec636b4fc0657246429dc73942bf86fbe695", "extra_info": null, "node_info": {"start": 529325, "end": 532932}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "a22cdac0-7bd7-4822-b847-8a456dbab849", "3": "5d5d4530-9f45-4334-8888-d5f020a9cd94"}}, "__type__": "1"}, "5d5d4530-9f45-4334-8888-d5f020a9cd94": {"__data__": {"text": "\n[Shaikh 2001; Mao 2002], in which case the LDNS location may be far from the client\u2019s \nlocation. Moreover, this simple strategy ignores the variation in delay and available band -\nwidth over time of Internet paths, always assigning the same cluster to a particular client.\nIn order to determine the best cluster for a client based on the current  traffic \nconditions, CDNs can instead perform periodic real-time measurements  of delay \nand loss performance between their clusters and clients. For instance, a CDN can \nhave each of its clusters periodically send probes (for example, ping messages or \nDNS queries) to all of the LDNSs around the world. One drawback of this approach \nis that many LDNSs are configured to not respond to such probes.\n2.6.4  Case Studies: Netflix, YouTube, and Kankan\nWe conclude our discussion of streaming stored video by taking a look at three \nhighly successful large-scale deployments: Netflix, YouTube, and Kankan. We\u2019ll \nsee that each of these systems take a very different approach, yet employ many of the \nunderlying principles discussed in this section.\n182     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nNetflix\nGenerating 37% of the downstream traffic in residential ISPs in North America in \n2015, Netflix has become the leading service provider for online movies and TV series \nin the United States [Sandvine 2015]. As we discuss below, Netflix video distribution \nhas two major components: the Amazon cloud and its own private CDN infrastructure.\nNetflix has a Web site that handles numerous functions, including user registra -\ntion and login, billing, movie catalogue for browsing and searching, and a movie \nrecommendation system. As shown in Figure 2.26, this Web site (and its associated \nbackend databases) run entirely on Amazon servers in the Amazon cloud. Addition-\nally, the Amazon cloud handles the following critical functions:\n\u2022 Content ingestion.  Before Netflix can distribute a movie to its customers, it must \nfirst ingest and process the movie. Netflix receives studio master versions of \nmovies and uploads them to hosts in the Amazon cloud.\n\u2022 Content processing.  The machines in the Amazon cloud create many different \nformats for each movie, suitable for a diverse array of client video players run -\nning on desktop computers, smartphones, and game consoles connected to televi -\nsions. A different version is created for each of these formats and at multiple bit \nrates, allowing for adaptive streaming over HTTP using DASH.\n\u2022 Uploading versions to its CDN.  Once all of the versions of a movie have been \ncreated, the hosts in the Amazon cloud upload the versions to its CDN.\nAmazon Cloud\nCDN serverCDN serverUpload\nversions\nto CDNs\nCDN server\nClientManifest \n\ufb01le\nVideo\nchunks\n(DASH)\nFigure 2.26  \u2666 Netflix video streaming platform\n2.6  \u2022  VIDEO STREAMING AND CONTENT DISTRIBUTION NETWORKS      183\nWhen Netflix first rolled out its video streaming service in 2007, it employed \nthree third-party CDN companies to distribute its video content. Netflix has since \ncreated its own private CDN, from which it now streams all of its videos. (Netflix \nstill uses Akamai to distribute its Web pages, however.) To create its own CDN, Net -\nflix has installed server racks both in IXPs and within residential ISPs themselves. \nNetflix currently has server racks in over 50 IXP locations; see [Netflix Open Con -\nnect 2016] for a current list of IXPs housing Netflix racks. There are also hundreds \nof ISP locations housing Netflix racks; also see [Netflix Open Connect 2016], where \nNetflix provides to potential ISP partners instructions about installing a (free) Net -\nflix rack for their networks. Each server in the rack has several 10 Gbps Ethernet \nports and over 100 terabytes of storage. The number of servers in a rack varies: IXP \ninstallations often have tens of servers and contain the entire Netflix streaming video \nlibrary, including multiple versions of the videos to support DASH; local IXPs may \nonly have one", "doc_id": "5d5d4530-9f45-4334-8888-d5f020a9cd94", "embedding": null, "doc_hash": "3aa90b7a1bdcf5b4b4edc88dd2a8d4e79901470bab52a80ab81c3aecb4c4008c", "extra_info": null, "node_info": {"start": 532821, "end": 536803}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "73b28b77-810f-4f14-be49-b87e119cae14", "3": "c690a244-8d72-4327-8a25-993256b7619a"}}, "__type__": "1"}, "c690a244-8d72-4327-8a25-993256b7619a": {"__data__": {"text": "create its own CDN, Net -\nflix has installed server racks both in IXPs and within residential ISPs themselves. \nNetflix currently has server racks in over 50 IXP locations; see [Netflix Open Con -\nnect 2016] for a current list of IXPs housing Netflix racks. There are also hundreds \nof ISP locations housing Netflix racks; also see [Netflix Open Connect 2016], where \nNetflix provides to potential ISP partners instructions about installing a (free) Net -\nflix rack for their networks. Each server in the rack has several 10 Gbps Ethernet \nports and over 100 terabytes of storage. The number of servers in a rack varies: IXP \ninstallations often have tens of servers and contain the entire Netflix streaming video \nlibrary, including multiple versions of the videos to support DASH; local IXPs may \nonly have one server and contain only the most popular videos. Netflix does not \nuse pull-caching (Section 2.2.5) to populate its CDN servers in the IXPs and ISPs. \nInstead, Netflix distributes by pushing the videos to its CDN servers during off-peak \nhours. For those locations that cannot hold the entire library, Netflix pushes only \nthe most popular videos, which are determined on a day-to-day basis. The Netflix \nCDN design is described in some detail in the YouTube videos [Netflix Video 1] and \n[Netflix Video 2].\nHaving described the components of the Netflix architecture, let\u2019s take a closer \nlook at the interaction between the client and the various servers that are involved in \nmovie delivery. As indicated earlier, the Web pages for browsing the Netflix video \nlibrary are served from servers in the Amazon cloud. When a user selects a movie to \nplay, the Netflix software, running in the Amazon cloud, first determines which of \nits CDN servers have copies of the movie. Among the servers that have the movie, \nthe software then determines the \u201cbest\u201d server for that client request. If the client is \nusing a residential ISP that has a Netflix CDN server rack installed in that ISP, and \nthis rack has a copy of the requested movie, then a server in this rack is typically \nselected. If not, a server at a nearby IXP is typically selected.\nOnce Netflix determines the CDN server that is to deliver the content, it sends \nthe client the IP address of the specific server as well as a manifest file, which has \nthe URLs for the different versions of the requested movie. The client and that CDN \nserver then directly interact using a proprietary version of DASH. Specifically, \nas described in Section 2.6.2, the client uses the byte-range header in HTTP GET \nrequest messages, to request chunks from the different versions of the movie. Netflix \nuses chunks that are approximately four-seconds long [Adhikari 2012]. While the \nchunks are being downloaded, the client measures the received throughput and runs \na rate-determination algorithm to determine the quality of the next chunk to request.\nNetflix embodies many of the key principles discussed earlier in this section, \nincluding adaptive streaming and CDN distribution. However, because Netflix uses \nits own private CDN, which distributes only video (and not Web pages), Netflix \nhas been able to simplify and tailor its CDN design. In particular, Netflix does not \n184     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nneed to employ DNS redirect, as discussed in Section 2.6.3, to connect a particular \nclient to a CDN server; instead, the Netflix software (running in the Amazon cloud) \ndirectly tells the client to use a particular CDN server. Furthermore, the Netflix CDN \nuses push caching rather than pull caching (Section 2.2.5): content is pushed into the \nservers at scheduled times at off-peak hours, rather than dynamically during cache \nmisses.\nYouTube\nWith 300 hours of video uploaded to YouTube every minute and several billion \nvideo views per day [YouTube 2016], YouTube is indisputably the world\u2019s largest \nvideo-sharing site. YouTube began its service in April 2005 and was acquired by \nGoogle in November 2006. Although the Google/YouTube design and protocols are \nproprietary, through several independent measurement efforts we can gain a", "doc_id": "c690a244-8d72-4327-8a25-993256b7619a", "embedding": null, "doc_hash": "40c9f7177fa51aaba766c287d09b909126ece68dab62d8054a034e6c920da625", "extra_info": null, "node_info": {"start": 536755, "end": 540876}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "5d5d4530-9f45-4334-8888-d5f020a9cd94", "3": "94113faf-0897-45a1-9f32-6654bcb8d06b"}}, "__type__": "1"}, "94113faf-0897-45a1-9f32-6654bcb8d06b": {"__data__": {"text": "as discussed in Section 2.6.3, to connect a particular \nclient to a CDN server; instead, the Netflix software (running in the Amazon cloud) \ndirectly tells the client to use a particular CDN server. Furthermore, the Netflix CDN \nuses push caching rather than pull caching (Section 2.2.5): content is pushed into the \nservers at scheduled times at off-peak hours, rather than dynamically during cache \nmisses.\nYouTube\nWith 300 hours of video uploaded to YouTube every minute and several billion \nvideo views per day [YouTube 2016], YouTube is indisputably the world\u2019s largest \nvideo-sharing site. YouTube began its service in April 2005 and was acquired by \nGoogle in November 2006. Although the Google/YouTube design and protocols are \nproprietary, through several independent measurement efforts we can gain a basic \nunderstanding about how YouTube operates [Zink 2009; Torres 2011; Adhikari \n2011a]. As with Netflix, YouTube makes extensive use of CDN technology to dis -\ntribute its videos [Torres 2011]. Similar to Netflix, Google uses its own private CDN \nto distribute YouTube videos, and has installed server clusters in many hundreds \nof different IXP and ISP locations. From these locations and directly from its huge \ndata centers, Google distributes YouTube videos [Adhikari 2011a]. Unlike Netflix, \nhowever, Google uses pull caching, as described in Section 2.2.5, and DNS redirect, \nas described in Section 2.6.3. Most of the time, Google\u2019s cluster-selection strategy \ndirects the client to the cluster for which the RTT between client and cluster is the \nlowest; however, in order to balance the load across clusters, sometimes the client is \ndirected (via DNS) to a more distant cluster [Torres 2011].\nYouTube employs HTTP streaming, often making a small number of differ -\nent versions available for a video, each with a different bit rate and corresponding \nquality level. YouTube does not employ adaptive streaming (such as DASH), but \ninstead requires the user to manually select a version. In order to save bandwidth and \nserver resources that would be wasted by repositioning or early termination, You -\nTube uses the HTTP byte range request to limit the flow of transmitted data after a \ntarget amount of video is prefetched.\nSeveral million videos are uploaded to YouTube every day. Not only are You -\nTube videos streamed from server to client over HTTP, but YouTube uploaders also \nupload their videos from client to server over HTTP. YouTube processes each video \nit receives, converting it to a YouTube video format and creating multiple versions \nat different bit rates. This processing takes place entirely within Google data centers. \n(See the case study on Google\u2019s network infrastructure in Section 2.6.3.)\nKankan\nWe just saw that dedicated servers, operated by private CDNs, stream Netflix and \nYouTube videos to clients. Netflix and YouTube have to pay not only for the server \n2.7  \u2022  SOCKET PROGRAMMING: CREATING NETWORK APPLICATIONS      185\nhardware but also for the bandwidth the servers use to distribute the videos. Given \nthe scale of these services and the amount of bandwidth they are consuming, such a \nCDN deployment can be costly.\nWe conclude this section by describing an entirely different approach for provid -\ning video on demand over the Internet at a large scale\u2014one that allows the service \nprovider to significantly reduce its infrastructure and bandwidth costs. As you might \nsuspect, this approach uses P2P delivery instead of (or along with) client-server \ndelivery. Since 2011, Kankan (owned and operated by Xunlei) has been deploying \nP2P video delivery with great success, with tens of millions of users every month \n[Zhang 2015].\nAt a high level, P2P video streaming is very similar to BitTorrent file download -\ning. When a peer wants to see a video, it contacts a tracker to discover other peers in \nthe system that have a copy of that video. This requesting peer then requests chunks \nof the video in parallel from the other peers that have the video. Different from \ndownloading with BitTorrent, however, requests are preferentially made for", "doc_id": "94113faf-0897-45a1-9f32-6654bcb8d06b", "embedding": null, "doc_hash": "fe62c2f31545c055acf69d84805c7f665d69bd06976fbb3158f8daa843e50f72", "extra_info": null, "node_info": {"start": 540869, "end": 544976}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "c690a244-8d72-4327-8a25-993256b7619a", "3": "30599ab0-8819-4189-8395-9cc4ea87d9a8"}}, "__type__": "1"}, "30599ab0-8819-4189-8395-9cc4ea87d9a8": {"__data__": {"text": "to significantly reduce its infrastructure and bandwidth costs. As you might \nsuspect, this approach uses P2P delivery instead of (or along with) client-server \ndelivery. Since 2011, Kankan (owned and operated by Xunlei) has been deploying \nP2P video delivery with great success, with tens of millions of users every month \n[Zhang 2015].\nAt a high level, P2P video streaming is very similar to BitTorrent file download -\ning. When a peer wants to see a video, it contacts a tracker to discover other peers in \nthe system that have a copy of that video. This requesting peer then requests chunks \nof the video in parallel from the other peers that have the video. Different from \ndownloading with BitTorrent, however, requests are preferentially made for chunks \nthat are to be played back in the near future in order to ensure continuous playback \n[Dhungel 2012].\nRecently, Kankan has migrated to a hybrid CDN-P2P streaming system \n[Zhang 2015]. Specifically, Kankan now deploys a few hundred servers within \nChina and pushes video content to these servers. This Kankan CDN plays a major \nrole in the start-up stage of video streaming. In most cases, the client requests the \nbeginning of the content from CDN servers, and in parallel requests content from \npeers. When the total P2P traffic is sufficient for video playback, the client will \ncease streaming from the CDN and only stream from peers. But if the P2P stream -\ning traffic becomes insufficient, the client will restart CDN connections and return \nto the mode of hybrid CDN-P2P streaming. In this manner, Kankan can ensure \nshort initial start-up delays while minimally relying on costly infrastructure servers \nand bandwidth.\n2.7 Socket Programming: Creating Network \nApplications\nNow that we\u2019ve looked at a number of important network applications, let\u2019s explore \nhow network application programs are actually created. Recall from Section 2.1 that \na typical network application consists of a pair of programs\u2014a client program and \na server program\u2014residing in two different end systems. When these two programs \nare executed, a client process and a server process are created, and these processes \ncommunicate with each other by reading from, and writing to, sockets. When creat -\ning a network application, the developer\u2019s main task is therefore to write the code for \nboth the client and server programs.\n186     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nThere are two types of network applications. One type is an implementation \nwhose operation is specified in a protocol standard, such as an RFC or some other \nstandards document; such an application is sometimes referred to as \u201copen,\u201d since \nthe rules specifying its operation are known to all. For such an implementation, the \nclient and server programs must conform to the rules dictated by the RFC. For exam -\nple, the client program could be an implementation of the client side of the HTTP \nprotocol, described in Section 2.2 and precisely defined in RFC 2616; similarly, \nthe server program could be an implementation of the HTTP server protocol, also \nprecisely defined in RFC 2616. If one developer writes code for the client program \nand another developer writes code for the server program, and both developers care -\nfully follow the rules of the RFC, then the two programs will be able to interoper -\nate. Indeed, many of today\u2019s network applications involve communication between \nclient and server programs that have been created by independent developers\u2014for \nexample, a Google Chrome browser communicating with an Apache Web server, or \na BitTorrent client communicating with BitTorrent tracker.\nThe other type of network application is a proprietary network application. In \nthis case the client and server programs employ an application-layer protocol that has \nnot been openly published in an RFC or elsewhere. A single developer (or develop -\nment team) creates both the client and server programs, and the developer has com -\nplete control over what goes in the code. But because the code does not implement \nan open protocol, other independent", "doc_id": "30599ab0-8819-4189-8395-9cc4ea87d9a8", "embedding": null, "doc_hash": "02c9621ab025bf88991717e668d78932aa6843159062ec08cf3d0bbd3ef478f7", "extra_info": null, "node_info": {"start": 545033, "end": 549113}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "94113faf-0897-45a1-9f32-6654bcb8d06b", "3": "682a680d-048a-48d4-8778-cae71b780d30"}}, "__type__": "1"}, "682a680d-048a-48d4-8778-cae71b780d30": {"__data__": {"text": "the server program, and both developers care -\nfully follow the rules of the RFC, then the two programs will be able to interoper -\nate. Indeed, many of today\u2019s network applications involve communication between \nclient and server programs that have been created by independent developers\u2014for \nexample, a Google Chrome browser communicating with an Apache Web server, or \na BitTorrent client communicating with BitTorrent tracker.\nThe other type of network application is a proprietary network application. In \nthis case the client and server programs employ an application-layer protocol that has \nnot been openly published in an RFC or elsewhere. A single developer (or develop -\nment team) creates both the client and server programs, and the developer has com -\nplete control over what goes in the code. But because the code does not implement \nan open protocol, other independent developers will not be able to develop code that \ninteroperates with the application.\nIn this section, we\u2019ll examine the key issues in developing a client-server appli -\ncation, and we\u2019ll \u201cget our hands dirty\u201d by looking at code that implements a very \nsimple client-server application. During the development phase, one of the first deci -\nsions the developer must make is whether the application is to run over TCP or over \nUDP. Recall that TCP is connection oriented and provides a reliable byte-stream \nchannel through which data flows between two end systems. UDP is connectionless \nand sends independent packets of data from one end system to the other, without any \nguarantees about delivery. Recall also that when a client or server program imple -\nments a protocol defined by an RFC, it should use the well-known port number \nassociated with the protocol; conversely, when developing a proprietary application, \nthe developer must be careful to avoid using such well-known port numbers. (Port \nnumbers were briefly discussed in Section 2.1. They are covered in more detail in \nChapter 3.)\nWe introduce UDP and TCP socket programming by way of a simple UDP \napplication and a simple TCP application. We present the simple UDP and TCP \napplications in Python 3. We could have written the code in Java, C, or C++, but we \nchose Python mostly because Python clearly exposes the key socket concepts. With \nPython there are fewer lines of code, and each line can be explained to the novice \nprogrammer without difficulty. But there\u2019s no need to be frightened if you are not \nfamiliar with Python. You should be able to easily follow the code if you have expe -\nrience programming in Java, C, or C++.\n2.7  \u2022  SOCKET PROGRAMMING: CREATING NETWORK APPLICATIONS      187\nIf you are interested in client-server programming with Java, you are encour -\naged to see the Companion Website for this textbook; in fact, you can find there \nall the examples in this section (and associated labs) in Java. For readers who are \ninterested in client-server programming in C, there are several good references avail -\nable [Donahoo 2001; Stevens 1997; Frost 1994; Kurose 1996]; our Python examples \nbelow have a similar look and feel to C.\n2.7.1  Socket Programming with UDP\nIn this subsection, we\u2019ll write simple client-server programs that use UDP; in the \nfollowing section, we\u2019ll write similar programs that use TCP.\nRecall from Section 2.1 that processes running on different machines communi -\ncate with each other by sending messages into sockets. We said that each process is \nanalogous to a house and the process\u2019s socket is analogous to a door. The application \nresides on one side of the door in the house; the transport-layer protocol resides on \nthe other side of the door in the outside world. The application developer has control \nof everything on the application-layer side of the socket; however, it has little control \nof the transport-layer side.\nNow let\u2019s take a closer look at the interaction between two communicating pro -\ncesses that use UDP sockets. Before the sending process can push a packet of data \nout the socket door, when using UDP, it must first attach", "doc_id": "682a680d-048a-48d4-8778-cae71b780d30", "embedding": null, "doc_hash": "59be0514af2748ff628db2c5c74afa8fa19139e6d40a95e8484c987bac074eec", "extra_info": null, "node_info": {"start": 548997, "end": 553055}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "30599ab0-8819-4189-8395-9cc4ea87d9a8", "3": "a57f860f-4df0-42be-aa93-56ac770f3125"}}, "__type__": "1"}, "a57f860f-4df0-42be-aa93-56ac770f3125": {"__data__": {"text": "programs that use TCP.\nRecall from Section 2.1 that processes running on different machines communi -\ncate with each other by sending messages into sockets. We said that each process is \nanalogous to a house and the process\u2019s socket is analogous to a door. The application \nresides on one side of the door in the house; the transport-layer protocol resides on \nthe other side of the door in the outside world. The application developer has control \nof everything on the application-layer side of the socket; however, it has little control \nof the transport-layer side.\nNow let\u2019s take a closer look at the interaction between two communicating pro -\ncesses that use UDP sockets. Before the sending process can push a packet of data \nout the socket door, when using UDP, it must first attach a destination address to \nthe packet. After the packet passes through the sender\u2019s socket, the Internet will use \nthis destination address to route the packet through the Internet to the socket in the \nreceiving process. When the packet arrives at the receiving socket, the receiving \nprocess will retrieve the packet through the socket, and then inspect the packet\u2019s \ncontents and take appropriate action.\nSo you may be now wondering, what goes into the destination address that \nis attached to the packet? As you might expect, the destination host\u2019s IP address \nis part of the destination address. By including the destination IP address in the \npacket, the routers in the Internet will be able to route the packet through the \nInternet to the destination host. But because a host may be running many net -\nwork application processes, each with one or more sockets, it is also necessary \nto identify the particular socket in the destination host. When a socket is created, \nan identifier, called a port number , is assigned to it. So, as you might expect, \nthe packet\u2019s destination address also includes the socket\u2019s port number. In sum -\nmary, the sending process attaches to the packet a destination address, which con -\nsists of the destination host\u2019s IP address and the destination socket\u2019s port number.  \nMoreover, as we shall soon see, the sender\u2019s source address\u2014consisting of the \nIP address of the source host and the port number of the source socket\u2014are also \nattached to the packet. However, attaching the source address to the packet is typi -\ncally not done by the UDP application code; instead it is automatically done by the \nunderlying operating system.\n188     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nWe\u2019ll use the following simple client-server application to demonstrate socket \nprogramming for both UDP and TCP:\n 1. The client reads a line of characters (data) from its keyboard and sends the data \nto the server.\n 2. The server receives the data and converts the characters to uppercase.\n 3. The server sends the modified data to the client.\n 4. The client receives the modified data and displays the line on its screen.\nFigure 2. 27 highlights the main socket-related activity of the client and server that \ncommunicate over the UDP transport service.\nNow let\u2019s get our hands dirty and take a look at the client-server program \npair for a UDP implementation of this simple application. We also provide a \ndetailed, line-by-line analysis after each program. We\u2019ll begin with the UDP cli -\nent, which will send a simple application-level message to the server. In order for \nCreate  socket, port=x :Server\nserverSocket =\nsocket(AF_INET,SOCK_DGRAM)(Running on serverIP)Client\nRead UDP segment from\nserverSocket\nWrite reply to\nspecifying client address,\nport numberserverSocketCreate datagram with serverIP\nand port=x ;\nsend datagram via\nclientSocketCreate socket:\nclientSocket =\nsocket(AF_INET,SOCK_DGRAM)\nRead datagram from\nclientSocket\nClose\nclientSocket\nFigure 2.27  \u2666 The client-server application using UDP\n2.7  \u2022  SOCKET PROGRAMMING: CREATING NETWORK APPLICATIONS ", "doc_id": "a57f860f-4df0-42be-aa93-56ac770f3125", "embedding": null, "doc_hash": "573c13c5d1bdbc52224181f34ea587617e94c0043309650be1fb12beeefa57cf", "extra_info": null, "node_info": {"start": 553146, "end": 557022}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "682a680d-048a-48d4-8778-cae71b780d30", "3": "7bd8bf7d-d01f-466c-9b04-8f3f3709303d"}}, "__type__": "1"}, "7bd8bf7d-d01f-466c-9b04-8f3f3709303d": {"__data__": {"text": "a \ndetailed, line-by-line analysis after each program. We\u2019ll begin with the UDP cli -\nent, which will send a simple application-level message to the server. In order for \nCreate  socket, port=x :Server\nserverSocket =\nsocket(AF_INET,SOCK_DGRAM)(Running on serverIP)Client\nRead UDP segment from\nserverSocket\nWrite reply to\nspecifying client address,\nport numberserverSocketCreate datagram with serverIP\nand port=x ;\nsend datagram via\nclientSocketCreate socket:\nclientSocket =\nsocket(AF_INET,SOCK_DGRAM)\nRead datagram from\nclientSocket\nClose\nclientSocket\nFigure 2.27  \u2666 The client-server application using UDP\n2.7  \u2022  SOCKET PROGRAMMING: CREATING NETWORK APPLICATIONS      189\nthe server to be able to receive and reply to the client\u2019s message, it must be ready \nand running\u2014that is, it must be running as a process before the client sends its \nmessage.\nThe client program is called UDPClient.py, and the server program is called \nUDPServer.py. In order to emphasize the key issues, we intentionally provide code \nthat is minimal. \u201cGood code\u201d would certainly have a few more auxiliary lines, in \nparticular for handling error cases. For this application, we have arbitrarily chosen \n12000 for the server port number.\nUDPClient.py\nHere is the code for the client side of the application:\nfrom socket import *\nserverName = \u2019hostname\u2019\nserverPort = 12000\nclientSocket = socket(AF_INET, SOCK_DGRAM)\nmessage = raw_input(\u2019Input lowercase sentence:\u2019)\nclientSocket.sendto(message.encode(),(serverName, serverPort))\nmodifiedMessage, serverAddress = clientSocket.recvfrom(2048)\nprint(modifiedMessage.decode())\nclientSocket.close()\nNow let\u2019s take a look at the various lines of code in UDPClient.py.\nfrom socket import *\nThe socket  module forms the basis of all network communications in Python. By \nincluding this line, we will be able to create sockets within our program.\nserverName = \u2019hostname\u2019\nserverPort = 12000\nThe first line sets the variable serverName  to the string \u2018hostname\u2019. Here, we pro -\nvide a string containing either the IP address of the server (e.g., \u201c128.138.3 2.126\u201d) \nor the hostname of the server (e.g., \u201ccis.poly.edu\u201d). If we use the hostname, then a \nDNS lookup will automatically be performed to get the IP address.) The second line \nsets the integer variable serverPort  to 12000.\nclientSocket = socket(AF_INET, SOCK_DGRAM)\n190     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nThis line creates the client\u2019s socket, called clientSocket . The first param -\neter indicates the address family; in particular, AF_INET  indicates that the \nunderlying network is using IPv4. (Do not worry about this now\u2014we will dis -\ncuss IPv4 in Chapter 4 .) The second parameter indicates that the socket is of \ntype SOCK_DGRAM , which means it is a UDP socket (rather than a TCP socket). \nNote that we are not specifying the port number of the client socket when we \ncreate it; we are instead letting the operating system do this for us. Now that the \nclient process\u2019s door has been created, we will want to create a message to send \nthrough the door.\nmessage = raw_input(\u2019Input lowercase sentence:\u2019)\nraw_input()  is a built-in function in Python. When this command is executed, \nthe user at the client is prompted with the words \u201cInput lowercase sentence:\u201d The \nuser then uses her keyboard to input a line, which is put into the variable message . \nNow that we have a socket and a message, we will want to send the message through \nthe socket to the destination host.\nclientSocket.sendto(message.encode(),(serverName, serverPort))\nIn the above line,", "doc_id": "7bd8bf7d-d01f-466c-9b04-8f3f3709303d", "embedding": null, "doc_hash": "57ab3814e9dd16279a35158d5d6515b6008addf465d89ea2f61ece6c89f9a5b9", "extra_info": null, "node_info": {"start": 557088, "end": 560624}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "a57f860f-4df0-42be-aa93-56ac770f3125", "3": "6723783b-dd5f-40e7-a1dd-c814f6a2a398"}}, "__type__": "1"}, "6723783b-dd5f-40e7-a1dd-c814f6a2a398": {"__data__": {"text": "\nNote that we are not specifying the port number of the client socket when we \ncreate it; we are instead letting the operating system do this for us. Now that the \nclient process\u2019s door has been created, we will want to create a message to send \nthrough the door.\nmessage = raw_input(\u2019Input lowercase sentence:\u2019)\nraw_input()  is a built-in function in Python. When this command is executed, \nthe user at the client is prompted with the words \u201cInput lowercase sentence:\u201d The \nuser then uses her keyboard to input a line, which is put into the variable message . \nNow that we have a socket and a message, we will want to send the message through \nthe socket to the destination host.\nclientSocket.sendto(message.encode(),(serverName, serverPort))\nIn the above line, we first convert the message from string type to byte type, as we \nneed to send bytes into a socket; this is done with the encode()  method. The  \nmethod sendto()  attaches the destination address ( serverName,  serverPort )  \nto the message and sends the resulting packet into the process\u2019s socket,  \nclientSocket . (As mentioned earlier, the source address is also attached to \nthe packet, although this is done automatically rather than explicitly by the code.)  \nSending a client-to-server message via a UDP socket is that simple! After sending \nthe packet, the client waits to receive data from the server.\nmodifiedMessage, serverAddress = clientSocket.recvfrom(2048)\nWith the above line, when a packet arrives from the Internet at the client\u2019s socket, the \npacket\u2019s data is put into the variable modifiedMessage  and the packet\u2019s source \naddress is put into the variable serverAddress . The variable serverAddress  \ncontains both the server\u2019s IP address and the server\u2019s port number. The program \nUDPClient doesn\u2019t actually need this server address information, since it already \nknows the server address from the outset; but this line of Python provides the server \naddress nevertheless. The method recvfrom  also takes the buffer size 2048 as \ninput. (This buffer size works for most purposes.)\nprint(modifiedMessage.decode())\n2.7  \u2022  SOCKET PROGRAMMING: CREATING NETWORK APPLICATIONS      191\nThis line prints out modifiedMessage on the user\u2019s display, after converting the mes -\nsage from bytes to string. It should be the original line that the user typed, but now \ncapitalized.\nclientSocket.close()\nThis line closes the socket. The process then terminates.\nUDPServer.py\nLet\u2019s now take a look at the server side of the application:\nfrom socket import *\nserverPort = 12000\nserverSocket = socket(AF_INET, SOCK_DGRAM)\nserverSocket.bind((\u2019\u2019, serverPort))\nprint(\u201dThe server is ready to receive\u201d)\nwhile True:\n    message, clientAddress = serverSocket.recvfrom(2048)\n    modifiedMessage = message.decode().upper()\n    serverSocket.sendto(modifiedMessage.encode(), clientAddress)\nNote that the beginning of UDPServer is similar to UDPClient. It also imports the \nsocket module, also sets the integer variable serverPort  to 12000, and also  \ncreates a socket of type SOCK_DGRAM  (a UDP socket). The first line of code that is \nsignificantly different from UDPClient is:\nserverSocket.bind((\u2019\u2019, serverPort))\nThe above line binds (that is, assigns) the port number 12000 to the server\u2019s socket. \nThus in UDPServer, the code (written by the application developer) is explicitly \nassigning a port number to the socket. In this manner, when anyone sends a packet to \nport 12000 at the IP address of the server, that packet will be directed to this socket. \nUDPServer then enters a while loop; the while loop will allow UDPServer to receive \nand process packets from clients indefinitely. In the while loop, UDPServer waits for \na packet to arrive.\nmessage, clientAddress =", "doc_id": "6723783b-dd5f-40e7-a1dd-c814f6a2a398", "embedding": null, "doc_hash": "fef81ad6db5095f0baa04b7aa14ba24cb97e773c1d340738dd1d0679178d5641", "extra_info": null, "node_info": {"start": 560580, "end": 564312}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "7bd8bf7d-d01f-466c-9b04-8f3f3709303d", "3": "a072a5c8-8fc4-4f72-8437-42bfe7b23c5c"}}, "__type__": "1"}, "a072a5c8-8fc4-4f72-8437-42bfe7b23c5c": {"__data__": {"text": "socket of type SOCK_DGRAM  (a UDP socket). The first line of code that is \nsignificantly different from UDPClient is:\nserverSocket.bind((\u2019\u2019, serverPort))\nThe above line binds (that is, assigns) the port number 12000 to the server\u2019s socket. \nThus in UDPServer, the code (written by the application developer) is explicitly \nassigning a port number to the socket. In this manner, when anyone sends a packet to \nport 12000 at the IP address of the server, that packet will be directed to this socket. \nUDPServer then enters a while loop; the while loop will allow UDPServer to receive \nand process packets from clients indefinitely. In the while loop, UDPServer waits for \na packet to arrive.\nmessage, clientAddress = serverSocket.recvfrom(2048)\nThis line of code is similar to what we saw in UDPClient. When a packet arrives \nat the server\u2019s socket, the packet\u2019s data is put into the variable message  and the \n192     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\npacket\u2019s source address is put into the variable clientAddress . The variable \n clientAddress contains both the client\u2019s IP address and the client\u2019s port number. \nHere, UDPServer will make use of this address information, as it provides a return \naddress, similar to the return address with ordinary postal mail. With this source \naddress information, the server now knows to where it should direct its reply.\nmodifiedMessage = message.decode().upper()\nThis line is the heart of our simple application. It takes the line sent by the client and, \nafter converting the message to a string, uses the method upper()  to capitalize it.\nserverSocket.sendto(modifiedMessage.encode(), clientAddress)\nThis last line attaches the client\u2019s address (IP address and port number) to the capital -\nized message (after converting the string to bytes), and sends the resulting packet into \nthe server\u2019s socket. (As mentioned earlier, the server address is also attached to the  \npacket, although this is done automatically rather than explicitly by the code.) The \nInternet will then deliver the packet to this client address. After the server sends  \nthe packet, it remains in the while loop, waiting for another UDP packet to arrive \n(from any client running on any host).\nTo test the pair of programs, you run UDPClient.py on one host and UDPServer.\npy on another host. Be sure to include the proper hostname or IP address of the server \nin UDPClient.py. Next, you execute UDPServer.py, the compiled server program, in \nthe server host. This creates a process in the server that idles until it is contacted by \nsome client. Then you execute UDPClient.py, the compiled client program, in the \nclient. This creates a process in the client. Finally, to use the application at the client, \nyou type a sentence followed by a carriage return.\nTo develop your own UDP client-server application, you can begin by slightly \nmodifying the client or server programs. For example, instead of converting all \nthe letters to uppercase, the server could count the number of times the letter s \nappears and return this number. Or you can modify the client so that after receiv -\ning a capitalized sentence, the user can continue to send more sentences to the \nserver.\n2.7.2  Socket Programming with TCP\nUnlike UDP, TCP is a connection-oriented protocol. This means that before the cli -\nent and server can start to send data to each other, they first need to handshake and \nestablish a TCP connection. One end of the TCP connection is attached to the client \nsocket and the other end is attached to a server socket. When creating the TCP con -\nnection, we associate with it the client socket address (IP address and port number) \nand the server socket address (IP address and port number). With the TCP connec -\ntion established, when one side wants to send data to the other side, it just drops the \n2.7  \u2022  SOCKET PROGRAMMING: CREATING NETWORK APPLICATIONS     ", "doc_id": "a072a5c8-8fc4-4f72-8437-42bfe7b23c5c", "embedding": null, "doc_hash": "3d8538e2bdd4469dbf032de24cedbbad4b31ad43c298678aa450901c48e76a9e", "extra_info": null, "node_info": {"start": 564351, "end": 568236}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "6723783b-dd5f-40e7-a1dd-c814f6a2a398", "3": "d42276af-a365-477d-9e7b-4afa9d4b0b92"}}, "__type__": "1"}, "d42276af-a365-477d-9e7b-4afa9d4b0b92": {"__data__": {"text": "user can continue to send more sentences to the \nserver.\n2.7.2  Socket Programming with TCP\nUnlike UDP, TCP is a connection-oriented protocol. This means that before the cli -\nent and server can start to send data to each other, they first need to handshake and \nestablish a TCP connection. One end of the TCP connection is attached to the client \nsocket and the other end is attached to a server socket. When creating the TCP con -\nnection, we associate with it the client socket address (IP address and port number) \nand the server socket address (IP address and port number). With the TCP connec -\ntion established, when one side wants to send data to the other side, it just drops the \n2.7  \u2022  SOCKET PROGRAMMING: CREATING NETWORK APPLICATIONS      193\ndata into the TCP connection via its socket. This is different from UDP, for which \nthe server must attach a destination address to the packet before dropping it into the \nsocket.\nNow let\u2019s take a closer look at the interaction of client and server programs \nin TCP. The client has the job of initiating contact with the server. In order for the \nserver to be able to react to the client\u2019s initial contact, the server has to be ready. This \nimplies two things. First, as in the case of UDP, the TCP server must be running as \na process before the client attempts to initiate contact. Second, the server program \nmust have a special door\u2014more precisely, a special socket\u2014that welcomes some \ninitial contact from a client process running on an arbitrary host. Using our house/\ndoor analogy for a process/socket, we will sometimes refer to the client\u2019s initial con -\ntact as \u201cknocking on the welcoming door.\u201d\nWith the server process running, the client process can initiate a TCP connection \nto the server. This is done in the client program by creating a TCP socket. When the \nclient creates its TCP socket, it specifies the address of the welcoming socket in the \nserver, namely, the IP address of the server host and the port number of the socket. \nAfter creating its socket, the client initiates a three-way handshake and establishes a \nTCP connection with the server. The three-way handshake, which takes place within \nthe transport layer, is completely invisible to the client and server programs.\nDuring the three-way handshake, the client process knocks on the welcom -\ning door of the server process. When the server \u201chears\u201d the knocking, it creates a \nnew door\u2014more precisely, a new socket that is dedicated to that particular  client. \nIn our example below, the welcoming door is a TCP socket object that we call \n serverSocket ; the newly created socket dedicated to the client making the con -\nnection is called connectionSocket . Students who are encountering TCP sock -\nets for the first time sometimes confuse the welcoming socket (which is the initial \npoint of contact for all clients wanting to communicate with the server), and each \nnewly created server-side connection socket that is subsequently created for com -\nmunicating with each client.\nFrom the application\u2019s perspective, the client\u2019s socket and the server\u2019s con -\nnection socket are directly connected by a pipe. As shown in Figure 2.28, the cli -\nent process can send arbitrary bytes into its socket, and TCP guarantees that the \nserver process will receive (through the connection socket) each byte in the order \nsent. TCP thus provides a reliable service between the client and server processes. \nFurthermore, just as people can go in and out the same door, the client process \nnot only sends bytes into but also receives bytes from its socket; similarly, the \nserver process not only receives bytes from but also sends bytes into its connec -\ntion socket.\nWe use the same simple client-server application to demonstrate socket pro -\ngramming with TCP: The client sends one line of data to the server, the server \ncapitalizes the line and sends it back to the client. Figure 2.29 highlights the main \nsocket-related activity of the client and server that communicate over the TCP trans -\nport service.\n194     CHAPTER", "doc_id": "d42276af-a365-477d-9e7b-4afa9d4b0b92", "embedding": null, "doc_hash": "620a8844f47953365a4cd3a958fb41ad82c590c5c62a962d8b88f005c1451f7c", "extra_info": null, "node_info": {"start": 568220, "end": 572275}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "a072a5c8-8fc4-4f72-8437-42bfe7b23c5c", "3": "db0a5c3b-2258-460a-8f11-1dcbf09be334"}}, "__type__": "1"}, "db0a5c3b-2258-460a-8f11-1dcbf09be334": {"__data__": {"text": "its socket, and TCP guarantees that the \nserver process will receive (through the connection socket) each byte in the order \nsent. TCP thus provides a reliable service between the client and server processes. \nFurthermore, just as people can go in and out the same door, the client process \nnot only sends bytes into but also receives bytes from its socket; similarly, the \nserver process not only receives bytes from but also sends bytes into its connec -\ntion socket.\nWe use the same simple client-server application to demonstrate socket pro -\ngramming with TCP: The client sends one line of data to the server, the server \ncapitalizes the line and sends it back to the client. Figure 2.29 highlights the main \nsocket-related activity of the client and server that communicate over the TCP trans -\nport service.\n194     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nTCPClient.py\nHere is the code for the client side of the application:\nfrom socket import *\nserverName = \u2019servername\u2019\nserverPort = 12000\nclientSocket = socket(AF_INET, SOCK_STREAM)\nclientSocket.connect((serverName,serverPort))\nsentence = raw_input(\u2019Input lowercase sentence:\u2019)\nclientSocket.send(sentence.encode())\nmodifiedSentence = clientSocket.recv(1024)\nprint(\u2019From Server: \u2019, modifiedSentence.decode())\u00a0\nclientSocket.close()\nLet\u2019s now take a look at the various lines in the code that differ significantly from the \nUDP implementation. The first such line is the creation of the client socket.\nclientSocket = socket(AF_INET, SOCK_STREAM)\nThis line creates the client\u2019s socket, called clientSocket . The first parameter \nagain indicates that the underlying network is using IPv4. The second parameter Client pr ocess Server pr ocess\nClient\nsocketWelcoming\nsocket\nThree-way handshake\nConnection\nsocketbytes\nbytes\nFigure 2.28  \u2666 The TCPServer process has two sockets\n2.7  \u2022  SOCKET PROGRAMMING: CREATING NETWORK APPLICATIONS      195\nindicates that the socket is of type SOCK_STREAM , which means it is a TCP socket \n(rather than a UDP socket). Note that we are again not specifying the port number of \nthe client socket when we create it; we are instead letting the operating system do this \nfor us. Now the next line of code is very different from what we saw in UDPClient:\nclientSocket.connect((serverName,serverPort))\nRecall that before the client can send data to the server (or vice versa) using a TCP \nsocket, a TCP connection must first be established between the client and server. The Close\nconnectionSocketWrite reply to\nconnectionSocketRead request from\nconnectionSocketCreate  socket, port=x ,\nfor incoming request:Server\nserverSocket =\nsocket()\nWait for incoming\nconnection request:\nconnectionSocket =\nserverSocket.accept()(Running on serverIP)Client\nTCP\nconnection setupCreate socket, connect\nto serverIP, port=x:\nclientSocket =\nsocket()\nRead reply from\nclientSocketSend request using\nclientSocket\nClose\nclientSocket\nFigure 2.29  \u2666 The client-server application using TCP\n196     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nabove line initiates the TCP connection between the client and server. The parameter \nof the connect()  method is the address of the server side of the connection. After \nthis line of code is executed, the three-way handshake is performed and a TCP con -\nnection is established between the client and server.\nsentence = raw_input(\u2019Input lowercase sentence:\u2019)\nAs with UDPClient, the above obtains a sentence from the user. The string  \nsentence  continues to gather characters until the user ends the line by typing a \ncarriage return. The next line of code is also very different from UDPClient:\nclientSocket.send(sentence.encode())\nThe above line sends the sentence  through the client\u2019s socket and into the TCP \nconnection. Note that the program does not explicitly create a packet and attach the \ndestination address", "doc_id": "db0a5c3b-2258-460a-8f11-1dcbf09be334", "embedding": null, "doc_hash": "70fca6d119bfd093e0dd29183d782f1c09012b93de20f3479fd39a1dcbc1cde2", "extra_info": null, "node_info": {"start": 572202, "end": 576009}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "d42276af-a365-477d-9e7b-4afa9d4b0b92", "3": "2a34c7ad-8c01-4530-8524-717ddfdb4ff6"}}, "__type__": "1"}, "2a34c7ad-8c01-4530-8524-717ddfdb4ff6": {"__data__": {"text": "between the client and server. The parameter \nof the connect()  method is the address of the server side of the connection. After \nthis line of code is executed, the three-way handshake is performed and a TCP con -\nnection is established between the client and server.\nsentence = raw_input(\u2019Input lowercase sentence:\u2019)\nAs with UDPClient, the above obtains a sentence from the user. The string  \nsentence  continues to gather characters until the user ends the line by typing a \ncarriage return. The next line of code is also very different from UDPClient:\nclientSocket.send(sentence.encode())\nThe above line sends the sentence  through the client\u2019s socket and into the TCP \nconnection. Note that the program does not explicitly create a packet and attach the \ndestination address to the packet, as was the case with UDP sockets. Instead the cli -\nent program simply drops the bytes in the string sentence  into the TCP connec -\ntion. The client then waits to receive bytes from the server.\nmodifiedSentence = clientSocket.recv(2048)\nWhen characters arrive from the server, they get placed into the string  \nmodifiedSentence . Characters continue to accumulate in modifiedSen-\ntence  until the line ends with a carriage return character. After printing the capital -\nized sentence, we close the client\u2019s socket:\nclientSocket.close()\nThis last line closes the socket and, hence, closes the TCP connection between the \nclient and the server. It causes TCP in the client to send a TCP message to TCP in \nthe server (see Section 3.5).\nTCPServer.py\nNow let\u2019s take a look at the server program.\nfrom socket import *\nserverPort = 12000\nserverSocket = socket(AF_INET,SOCK_STREAM)\nserverSocket.bind((\u2019\u2019,serverPort))\nserverSocket.listen(1)\nprint(\u2019The server is ready to receive\u2019)\n2.7  \u2022  SOCKET PROGRAMMING: CREATING NETWORK APPLICATIONS      197\nwhile True:\n    connectionSocket, addr = serverSocket.accept()\n    sentence = connectionSocket.recv(1024).decode()\n    capitalizedSentence = sentence.upper()\n    connectionSocket.send(capitalizedSentence.encode())\u00a0\n    connectionSocket.close()\nLet\u2019s now take a look at the lines that differ significantly from UDPServer and TCP -\nClient. As with TCPClient, the server creates a TCP socket with:\nserverSocket=socket(AF_INET,SOCK_STREAM)\nSimilar to UDPServer, we associate the server port number, serverPort , with \nthis socket:\nserverSocket.bind((\u2019\u2019,serverPort))\nBut with TCP, serverSocket  will be our welcoming socket. After establish -\ning this welcoming door, we will wait and listen for some client to knock on the \ndoor:\nserverSocket.listen(1)\nThis line has the server listen for TCP connection requests from the client. The \nparameter specifies the maximum number of queued connections (at least 1).\nconnectionSocket, addr = serverSocket.accept()\nWhen a client knocks on this door, the program invokes the accept()  method for \nserverSocket, which creates a new socket in the server, called  connectionSocket , \ndedicated to this particular client. The client and server then complete the hand -\nshaking, creating a TCP connection between the client\u2019s clientSocket  and the \nserver\u2019s connectionSocket . With the TCP connection established, the client \nand server can now send bytes to each other over the connection. With TCP, all bytes \nsent from one side not are not only guaranteed to arrive at the other side but also \nguaranteed arrive in order.\nconnectionSocket.close()\nIn this program, after sending the modified sentence to the client, we close the con -\nnection socket. But since serverSocket  remains open, another client can now \nknock on the door and send the server a sentence to modify.\n198     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nThis", "doc_id": "2a34c7ad-8c01-4530-8524-717ddfdb4ff6", "embedding": null, "doc_hash": "c3e25d1e03ce3726ae8f7ceee35a102e15b005a8c90916ef60a0e038ecd76c44", "extra_info": null, "node_info": {"start": 576044, "end": 579734}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "db0a5c3b-2258-460a-8f11-1dcbf09be334", "3": "424bcb02-6067-4319-9d41-d35dee0572b4"}}, "__type__": "1"}, "424bcb02-6067-4319-9d41-d35dee0572b4": {"__data__": {"text": "server, called  connectionSocket , \ndedicated to this particular client. The client and server then complete the hand -\nshaking, creating a TCP connection between the client\u2019s clientSocket  and the \nserver\u2019s connectionSocket . With the TCP connection established, the client \nand server can now send bytes to each other over the connection. With TCP, all bytes \nsent from one side not are not only guaranteed to arrive at the other side but also \nguaranteed arrive in order.\nconnectionSocket.close()\nIn this program, after sending the modified sentence to the client, we close the con -\nnection socket. But since serverSocket  remains open, another client can now \nknock on the door and send the server a sentence to modify.\n198     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nThis completes our discussion of socket programming in TCP. You are encour -\naged to run the two programs in two separate hosts, and also to modify them to \nachieve slightly different goals. You should compare the UDP program pair with the \nTCP program pair and see how they differ. You should also do many of the socket \nprogramming assignments described at the ends of Chapter 2, 4, and 9. Finally, we \nhope someday, after mastering these and more advanced socket programs, you will \nwrite your own popular network application, become very rich and famous, and \nremember the authors of this textbook!\n2.8 Summary\nIn this chapter, we\u2019ve studied the conceptual and the implementation aspects of \nnetwork applications. We\u2019ve learned about the ubiquitous client-server architecture \nadopted by many Internet applications and seen its use in the HTTP, SMTP, POP3, \nand DNS protocols. We\u2019ve studied these important application-level protocols, \nand their corresponding associated applications (the Web, file transfer, e-mail, and \nDNS) in some detail. We\u2019ve learned about the P2P architecture and how it is used \nin many applications. We\u2019ve also learned about streaming video, and how modern \nvideo distribution systems leverage CDNs. We\u2019ve examined how the socket API \ncan be used to build network applications. We\u2019ve walked through the use of sock -\nets for connection-oriented (TCP) and connectionless (UDP) end-to-end transport \nservices. The first step in our journey down the layered network architecture is now \ncomplete!\nAt the very beginning of this book, in Section 1.1, we gave a rather vague, bare-\nbones definition of a protocol: \u201cthe format and the order of messages exchanged \nbetween two or more communicating entities, as well as the actions taken on the \ntransmission and/or receipt of a message or other event.\u201d The material in this chapter, \nand in particular our detailed study of the HTTP, SMTP, POP3, and DNS protocols, \nhas now added considerable substance to this definition. Protocols are a key concept \nin networking; our study of application protocols has now given us the opportunity \nto develop a more intuitive feel for what protocols are all about.\nIn Section 2.1, we described the service models that TCP and UDP offer to \napplications that invoke them. We took an even closer look at these service models \nwhen we developed simple applications that run over TCP and UDP in Section 2.7. \nHowever, we have said little about how TCP and UDP provide these service models. \nFor example, we know that TCP provides a reliable data service, but we haven\u2019t said \nyet how it does so. In the next chapter we\u2019ll take a careful look at not only the what, \nbut also the how and why of transport protocols.\nEquipped with knowledge about Internet application structure and application-\nlevel protocols, we\u2019re now ready to head further down the protocol stack and exam -\nine the transport layer in Chapter 3.\nHOMEWORK PROBLEMS AND QUESTIONS      199\nHomework Problems and Questions\nChapter 2 Review Questions\nSECTION 2.1\n R1. List five nonproprietary Internet", "doc_id": "424bcb02-6067-4319-9d41-d35dee0572b4", "embedding": null, "doc_hash": "2082409f09035879b76bab95c18241f42f046ef2917df005f286ac1467c348ca", "extra_info": null, "node_info": {"start": 579746, "end": 583586}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "2a34c7ad-8c01-4530-8524-717ddfdb4ff6", "3": "41e08e14-04fa-461f-a2d3-c93fb1c8e7aa"}}, "__type__": "1"}, "41e08e14-04fa-461f-a2d3-c93fb1c8e7aa": {"__data__": {"text": "we developed simple applications that run over TCP and UDP in Section 2.7. \nHowever, we have said little about how TCP and UDP provide these service models. \nFor example, we know that TCP provides a reliable data service, but we haven\u2019t said \nyet how it does so. In the next chapter we\u2019ll take a careful look at not only the what, \nbut also the how and why of transport protocols.\nEquipped with knowledge about Internet application structure and application-\nlevel protocols, we\u2019re now ready to head further down the protocol stack and exam -\nine the transport layer in Chapter 3.\nHOMEWORK PROBLEMS AND QUESTIONS      199\nHomework Problems and Questions\nChapter 2 Review Questions\nSECTION 2.1\n R1. List five nonproprietary Internet applications and the application-layer proto-\ncols that they use.\n R2. What is the difference between network architecture and application architecture?\n R3. For a communication session between a pair of processes, which process is \nthe client and which is the server?\n R4. Why are the terms client and server still used in peer-to-peer applications?\n R5. What information is used by a process running on one host to identify a pro-\ncess running on another host?\n R6. What is the role of HTTP in a network application? What other components \nare needed to complete a Web application?\n R7. Referring to Figure 2.4, we see that none of the applications listed in Figure \n2.4 requires both no data loss and timing. Can you conceive of an application \nthat requires no data loss and that is also highly time-sensitive?\n R8. List the four broad classes of services that a transport protocol can provide. \nFor each of the service classes, indicate if either UDP or TCP (or both) pro-\nvides such a service.\n R9. Recall that TCP can be enhanced with SSL to provide process-to-process \nsecurity services, including encryption. Does SSL operate at the transport \nlayer or the application layer? If the application developer wants TCP to be \nenhanced with SSL, what does the developer have to do?\nSECTION 2.2\u20132.5\n R10. What is meant by a handshaking protocol?\n R11. What does a stateless protocol mean? Is IMAP stateless? What about SMTP?\n R12. How can websites keep track of users? Do they always need to use cookies?\n R13. Describe how Web caching can reduce the delay in receiving a requested \nobject. Will Web caching reduce the delay for all objects requested by a user \nor for only some of the objects? Why?\n R14. Telnet into a Web server and send a multiline request message. Include in \nthe request message the If-modified-since:  header line to force a \nresponse message with the 304 Not Modified  status code.\n R15. Are there any constraints on the format of the HTTP body? What about the \nemail message body sent with SMTP? How can arbitrary data be transmitted \nover SMTP?\n200     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\n R16. Suppose Alice, with a Web-based e-mail account (such as Hotmail or Gmail), \nsends a message to Bob, who accesses his mail from his mail server using \nPOP3. Discuss how the message gets from Alice\u2019s host to Bob\u2019s host. Be \nsure to list the series of application-layer protocols that are used to move the \nmessage between the two hosts.\n R17. Print out the header of an e-mail message you have recently received. How \nmany Received:  header lines are there? Analyze each of the header lines \nin the message.\n R18. Assume you have multiple devices, and you connect to your email provider \nusing POP3. You retrieve messages with the \u201cdownload and keep\u201d strategy \nfrom multiple devices. Can your email client tell if you have already read the \nmessage in this scenario?\n R19. Why are MX records needed? Would it not be enough to use a CNAME \nrecord? (Assume the email client looks up email addresses through a Type \nA\u00a0query and that the target host only runs an", "doc_id": "41e08e14-04fa-461f-a2d3-c93fb1c8e7aa", "embedding": null, "doc_hash": "0317c3dd3eb1001a243e6d79f020c8586279fe4375a22c88178db252e674040c", "extra_info": null, "node_info": {"start": 583622, "end": 587433}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "424bcb02-6067-4319-9d41-d35dee0572b4", "3": "70ebc787-36ab-44cb-a12b-08a8479d9cee"}}, "__type__": "1"}, "70ebc787-36ab-44cb-a12b-08a8479d9cee": {"__data__": {"text": "Alice\u2019s host to Bob\u2019s host. Be \nsure to list the series of application-layer protocols that are used to move the \nmessage between the two hosts.\n R17. Print out the header of an e-mail message you have recently received. How \nmany Received:  header lines are there? Analyze each of the header lines \nin the message.\n R18. Assume you have multiple devices, and you connect to your email provider \nusing POP3. You retrieve messages with the \u201cdownload and keep\u201d strategy \nfrom multiple devices. Can your email client tell if you have already read the \nmessage in this scenario?\n R19. Why are MX records needed? Would it not be enough to use a CNAME \nrecord? (Assume the email client looks up email addresses through a Type \nA\u00a0query and that the target host only runs an email server.)\n R20. What is the difference between recursive and iterative DNS queries?\nSECTION 2.5\n R21. Under what circumstances is file downloading through P2P much faster \nthan through a centralized client-server approach? Justify your answer using \nEquation 2.2.\n R22. Consider a new peer Alice that joins BitTorrent without possessing any chunks. \nWithout any chunks, she cannot become a top-four uploader for any of the other \npeers, since she has nothing to upload. How then will Alice get her first chunk?\n R23. Assume a BitTorrent tracker suddenly becomes unavailable. What are its \nconsequences? Can files still be downloaded?\nSECTION 2.6\n R24. CDNs typically adopt one of two different server placement philosophies. \nName and briefly describe them.\n R25. Besides network-related considerations such as delay, loss, and bandwidth \nperformance, there are other important factors that go into designing a CDN \nserver selection strategy. What are they?\nSECTION 2.7\n R26. In Section 2.7, the UDP server described needed only one socket, whereas \nthe TCP server needed two sockets. Why? If the TCP server were to support \nn simultaneous connections, each from a different client host, how many \nsockets would the TCP server need?\nPROBLEMS      201\n R27. For the client-server application over TCP described in Section 2.7, why \nmust the server program be executed before the client program? For the \nclient-server application over UDP, why may the client program be executed \nbefore the server program?\nProblems\n P1. True or false?\na. A user requests a Web page that consists of some text and three images. \nFor this page, the client will send one request message and receive four \nresponse messages.\nb. Two distinct Web pages (for example, www.mit.edu/research \n.html  and www.mit.edu/students.html ) can be sent over the \nsame persistent connection.\nc. With nonpersistent connections between browser and origin server, it is \npossible for a single TCP segment to carry two distinct HTTP request \nmessages.\nd. The Date:  header in the HTTP response message indicates when the \nobject in the response was last modified.\ne. HTTP response messages never have an empty message body.\n P2. SMS, iMessage, and WhatsApp are all smartphone real-time messaging \nsystems. After doing some research on the Internet, for each of these systems \nwrite one paragraph about the protocols they use. Then write a paragraph \nexplaining how they differ.\n P3. Assume you open a browser and enter http://yourbusiness.com/\nabout.html  in the address bar. What happens until the webpage is dis -\nplayed? Provide details about the protocol(s) used and a high-level description \nof the messages exchanged.\n P4. Consider the following string of ASCII characters that were captured by \nWireshark when the browser sent an HTTP GET message (i.e., this is the \nactual content of an HTTP GET message). The characters <cr><lf>  are \ncarriage return and line-feed characters (that is, the italized character string \n<cr>  in the text below represents the single carriage-return character that was \ncontained at that point in the HTTP header). Answer the following questions,", "doc_id": "70ebc787-36ab-44cb-a12b-08a8479d9cee", "embedding": null, "doc_hash": "40a4facd9686811f607cbe44da52dad7b610cf0655fd2c3de5f05d896842dab2", "extra_info": null, "node_info": {"start": 587413, "end": 591328}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "41e08e14-04fa-461f-a2d3-c93fb1c8e7aa", "3": "afea690d-c86d-4d12-9fd7-7e826fe9a3cd"}}, "__type__": "1"}, "afea690d-c86d-4d12-9fd7-7e826fe9a3cd": {"__data__": {"text": "they use. Then write a paragraph \nexplaining how they differ.\n P3. Assume you open a browser and enter http://yourbusiness.com/\nabout.html  in the address bar. What happens until the webpage is dis -\nplayed? Provide details about the protocol(s) used and a high-level description \nof the messages exchanged.\n P4. Consider the following string of ASCII characters that were captured by \nWireshark when the browser sent an HTTP GET message (i.e., this is the \nactual content of an HTTP GET message). The characters <cr><lf>  are \ncarriage return and line-feed characters (that is, the italized character string \n<cr>  in the text below represents the single carriage-return character that was \ncontained at that point in the HTTP header). Answer the following questions, \nindicating where in the HTTP GET message below you find the answer.\nGET /cs453/index.html HTTP/1.1 <cr><lf> Host: gai\na.cs.umass.edu <cr><lf> User-Agent: Mozilla/5.0 (\nWindows;U; Windows NT 5.1; en-US; rv:1.7.2) Gec\nko/20040804 Netscape/7.2 (ax) <cr><lf> Accept:ex\nt/xml, application/xml, application/xhtml+xml, text\n/html;q=0.9, text/plain;q=0.8,image/png,*/*;q=0.5\n202     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\n<cr><lf> Accept-Language: en-us,en;q=0.5 <cr><lf> Accept-\nEncoding: zip,deflate <cr><lf> Accept-Charset: ISO\n-8859-1,utf-8;q=0.7,*;q=0.7 <cr><lf> Keep-Alive: 300 <cr>\n<lf>Connection:keep-alive <cr><lf><cr><lf>\na. What is the URL of the document requested by the browser?\nb. What version of HTTP is the browser running?\nc. Does the browser request a non-persistent or a persistent connection?\nd. What is the IP address of the host on which the browser is running?\ne. What type of browser initiates this message? Why is the browser type \nneeded in an HTTP request message?\n P5. The text below shows the reply sent from the server in response to the HTTP \nGET message in the question above. Answer the following questions, indicat -\ning where in the message below you find the answer.\nHTTP/1.1 200 OK <cr><lf> Date: Tue, 07 Mar 2008\n12:39:45GMT <cr><lf> Server: Apache/2.0.52 (Fedora)\n<cr><lf> Last-Modified: Sat, 10 Dec2005 18:27:46 \nGMT<cr><lf> ETag: \u201d526c3-f22-a88a4c80\u201d <cr><lf> Accept- \nRanges: bytes <cr><lf> Content-Length: 3874 <cr><lf>  \nKeep-Alive: timeout=max=100 <cr><lf> Connection:\nKeep-Alive <cr><lf> Content-Type: text/html; charset= \nISO-8859-1 <cr><lf><cr><lf> <!doctype html public \u201d- \n//w3c//dtd html 4.0transitional//en\u201d> <lf><html><lf> \n<head><lf> <meta http-equiv=\u201dContent-Type\u201d  \ncontent=\u201dtext/html; charset=iso-8859-1\u201d> <lf> <meta\nname=\u201dGENERATOR\u201d content=\u201dMozilla/4.79 [en] (Windows NT\n5.0; U) Netscape]\u201d> <lf> <title>CMPSCI 453 / 591 /  \nNTU-ST550ASpring 2005 homepage</title> <lf></head><lf> \n<much more document text following here (not shown)>\na. Was the server able to successfully find the document or not? What time \nwas the document reply provided?\nb. When was the document last modified?\nc. How many bytes are there", "doc_id": "afea690d-c86d-4d12-9fd7-7e826fe9a3cd", "embedding": null, "doc_hash": "378efbb9fe9c8f8ffa2865164021e4e566d18588810d32cf4179491c43c254a4", "extra_info": null, "node_info": {"start": 591313, "end": 594240}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "70ebc787-36ab-44cb-a12b-08a8479d9cee", "3": "b7402726-19c8-492b-8bb3-a4eb0284c15c"}}, "__type__": "1"}, "b7402726-19c8-492b-8bb3-a4eb0284c15c": {"__data__": {"text": "html 4.0transitional//en\u201d> <lf><html><lf> \n<head><lf> <meta http-equiv=\u201dContent-Type\u201d  \ncontent=\u201dtext/html; charset=iso-8859-1\u201d> <lf> <meta\nname=\u201dGENERATOR\u201d content=\u201dMozilla/4.79 [en] (Windows NT\n5.0; U) Netscape]\u201d> <lf> <title>CMPSCI 453 / 591 /  \nNTU-ST550ASpring 2005 homepage</title> <lf></head><lf> \n<much more document text following here (not shown)>\na. Was the server able to successfully find the document or not? What time \nwas the document reply provided?\nb. When was the document last modified?\nc. How many bytes are there in the document being returned?\nd. What are the first 5 bytes of the document being returned? Did the server \nagree to a persistent connection?\n P6. Obtain the HTTP/1.1 specification (RFC 2616). Answer the following  \nquestions:\na. Explain the mechanism used for signaling between the client and server \nto indicate that a persistent connection is being closed. Can the client, the \nserver, or both signal the close of a connection?\nPROBLEMS      203\nb. What encryption services are provided by HTTP?\nc. Can a client open three or more simultaneous connections with a given \nserver?\nd. Either a server or a client may close a transport connection between them \nif either one detects the connection has been idle for some time. Is it \npossible that one side starts closing a connection while the other side is \ntransmitting data via this connection? Explain.\n P7. Assume that the RTT between a client and the local DNS server is TTl,  \nwhile the RTT between the local DNS server and other DNS servers is RTTr . \nAssume that no DNS server performs caching.\na. What is the total response time for the scenario illustrated in Figure 2.19?\nb. What is the total response time for the scenario illustrated in Figure 2.20?\nc. Assume now that the DNS record for the requested name is cached \nat the local DNS server. What is the total response time for the two \nscenarios?\n P8. Referring to Problem P7, suppose the HTML file references eight very small \nobjects on the same server. Neglecting transmission times, how much time \nelapses with\na. Non-persistent HTTP with no parallel TCP connections?\nb. Non-persistent HTTP with the browser configured for 5 parallel  \nconnections?\nc. Persistent HTTP?\n P9. Consider Figure 2.12, for which there is an institutional network connected to \nthe Internet. Suppose that the average object size is 850,000 bits and that the \naverage request rate from the institution\u2019s browsers to the origin servers is 16 \nrequests per second. Also suppose that the amount of time it takes from when \nthe router on the Internet side of the access link forwards an HTTP request \nuntil it receives the response is three seconds on average (see Section 2.2.5). \nModel the total average response time as the sum of the average access delay \n(that is, the delay from Internet router to institution router) and the average \nInternet delay. For the average access delay, use \u2206/(1-\u2206b), where \u2206 is \nthe average time required to send an object over the access link and b is the \narrival rate of objects to the access link.\na. Find the total average response time.\nb. Now suppose a cache is installed in the institutional LAN. Suppose the \nmiss rate is 0.4. Find the total response time.\n P10. Assume you request a webpage consisting of one document and five images. \nThe document size is 1 kbyte, all images have the same size of 50 kbytes, the \ndownload rate is 1 Mbps, and the RTT is 100 ms. How long does it take to \n204     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nobtain the whole webpage under the following conditions? (Assume no DNS \nname query is needed and the impact of the request line and the headers in \nthe HTTP messages is", "doc_id": "b7402726-19c8-492b-8bb3-a4eb0284c15c", "embedding": null, "doc_hash": "cd712adf26b4b6a4f1f9b691c62eb38d26b783b7fc2e044ac434dc30e9aac46a", "extra_info": null, "node_info": {"start": 594421, "end": 598093}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "afea690d-c86d-4d12-9fd7-7e826fe9a3cd", "3": "e85ff66d-99c4-4ab6-9fc0-397a00b31732"}}, "__type__": "1"}, "e85ff66d-99c4-4ab6-9fc0-397a00b31732": {"__data__": {"text": "is \nthe average time required to send an object over the access link and b is the \narrival rate of objects to the access link.\na. Find the total average response time.\nb. Now suppose a cache is installed in the institutional LAN. Suppose the \nmiss rate is 0.4. Find the total response time.\n P10. Assume you request a webpage consisting of one document and five images. \nThe document size is 1 kbyte, all images have the same size of 50 kbytes, the \ndownload rate is 1 Mbps, and the RTT is 100 ms. How long does it take to \n204     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nobtain the whole webpage under the following conditions? (Assume no DNS \nname query is needed and the impact of the request line and the headers in \nthe HTTP messages is negligible).\na. Nonpersistent HTTP with serial connections.\nb. Nonpersistent HTTP with two parallel connections.\nc. Nonpersistent HTTP with six parallel connections.\nd. Persistent HTTP with one connection.\n P11. Generalize the results obtained for the first and the last scenario in the previ-\nous problem to a document size of Ld bytes, N images with size of Li bytes \n(for 0 # i , N), a rate of R byte/s and an RTT of RTTavg.\n P12. Write a simple TCP program for a server that accepts lines of input from a \nclient and prints the lines onto the server\u2019s standard output. (You can do this \nby modifying the TCPServer.py program in the text.) Compile and execute \nyour program. On any other machine that contains a Web browser, set the \nproxy server in the browser to the host that is running your server program; \nalso configure the port number appropriately. Your browser should now send \nits GET request messages to your server, and your server should display the \nmessages on its standard output. Use this platform to determine whether your \nbrowser generates conditional GET messages for objects that are locally \ncached.\n P13. Describe a few scenarios in which mail access protocols are not needed.\n P14. Why does an SMTP server retry to transmit a message even though TCP is \nused to connect with the destination?\n P15. Read RFC 5321 for SMTP. What does MTA stand for? Consider the follow-\ning received spam e-mail (modified from a real spam e-mail). Assuming only \nthe originator of this spam e-mail is malicious and all other hosts are honest, \nidentify the malacious host that has generated this spam e-mail.\nFrom - Fri Nov 07 13:41:30 2008\nReturn-Path: <tennis5@pp33head.com>\nReceived: from barmail.cs.umass.edu (barmail.cs.umass.\nedu\nPROBLEMS      205\n[128.119.240.3]) by cs.umass.edu (8.13.1/8.12.6) for\n<hg@cs.umass.edu>; Fri, 7 Nov 2008 13:27:10 -0500\nReceived: from asusus-4b96 (localhost [127.0.0.1]) by\nbarmail.cs.umass.edu (Spam Firewall) for <hg@cs.umass.\nedu>; Fri, 7\nNov 2008 13:27:07 -0500 (EST)\nReceived: from asusus-4b96 ([58.88.21.177]) by barmail.\ncs.umass.edu\nfor <hg@cs.umass.edu>; Fri, 07 Nov 2008 13:27:07 -0500 \n(EST)\nReceived: from [58.88.21.177] by inbnd55.exchangeddd.\ncom; Sat, 8\nNov 2008 01:27:07 +0700\nFrom: \u201dJonny\u201d <tennis5@pp33head.com>\nTo: <hg@cs.umass.edu>\n\u00a0\nSubject: How to secure your savings\n P16. Read the DNS SRV RFC, RFC 2782. What is the purpose of the SRV \nrecord?\n P17. Consider accessing your e-mail with POP3.\na. Suppose you have configured your POP mail client to operate in the", "doc_id": "e85ff66d-99c4-4ab6-9fc0-397a00b31732", "embedding": null, "doc_hash": "b224468a6e6f5bd03c75b8bc8f005e6d333029af32b89e0e37ac4542b26432db", "extra_info": null, "node_info": {"start": 597965, "end": 601234}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "b7402726-19c8-492b-8bb3-a4eb0284c15c", "3": "8fad8fc3-5240-465d-98f8-d4e100ee4270"}}, "__type__": "1"}, "8fad8fc3-5240-465d-98f8-d4e100ee4270": {"__data__": {"text": "([58.88.21.177]) by barmail.\ncs.umass.edu\nfor <hg@cs.umass.edu>; Fri, 07 Nov 2008 13:27:07 -0500 \n(EST)\nReceived: from [58.88.21.177] by inbnd55.exchangeddd.\ncom; Sat, 8\nNov 2008 01:27:07 +0700\nFrom: \u201dJonny\u201d <tennis5@pp33head.com>\nTo: <hg@cs.umass.edu>\n\u00a0\nSubject: How to secure your savings\n P16. Read the DNS SRV RFC, RFC 2782. What is the purpose of the SRV \nrecord?\n P17. Consider accessing your e-mail with POP3.\na. Suppose you have configured your POP mail client to operate in the \ndownload-and-delete mode. Complete the following transaction:\nC: list\nS: 1 498\nS: 2 912\nS: .\nC: retr 1\nS: blah blah ...\nS: ..........blah\nS: .\n?\n?\nb. Suppose you have configured your POP mail client to operate in the \ndownload-and-keep mode. Complete the following transaction:\nC: list\nS: 1 498\nS: 2 912\nS: .\nC: retr 1\n206     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nS: blah blah ...\nS: ..........blah\nS: .\n?\u00a0\n?\nc. Suppose you have configured your POP mail client to operate in the down -\nload-and-keep mode. Using your transcript in part (b), suppose you retrieve \nmessages 1 and 2, exit POP, and then five minutes later you again access POP \nto retrieve new e-mail. Suppose that in the five-minute interval no new mes -\nsages have been sent to you. Provide a transcript of this second POP session.\n P18. a. What is a whois  database?\nb. Use various whois databases on the Internet to obtain the names of two \nDNS servers. Indicate which whois databases you used.\nc. Use nslookup on your local host to send DNS queries to three DNS serv-\ners: your local DNS server and the two DNS servers you found in part (b). \nTry querying for Type A, NS, and MX reports. Summarize your findings.\nd. Use nslookup to find a Web server that has multiple IP addresses. Does \nthe Web server of your institution (school or company) have multiple IP \naddresses?\ne. Use the ARIN whois database to determine the IP address range used by \nyour university.\nf. Describe how an attacker can use whois databases and the nslookup tool \nto perform reconnaissance on an institution before launching an attack.\ng. Discuss why whois databases should be publicly available.\n P19. In this problem, we use the useful dig tool available on Unix and Linux hosts to \nexplore the hierarchy of DNS servers. Recall that in Figure 2.19, a DNS server \nin the DNS hierarchy delegates a DNS query to a DNS server lower in the \nhierarchy, by sending back to the DNS client the name of that lower-level DNS \nserver. First read the man page for dig, and then answer the following questions.\na. Starting with a root DNS server (from one of the root servers [a-m].\nroot-servers.net), initiate a sequence of queries for the IP address for your \ndepartment\u2019s Web server by using dig. Show the list of the names of DNS \nservers in the delegation chain in answering your query.\nb. Repeat part (a) for several popular Web sites, such as google.com, yahoo \n.com, or amazon.com.\n P20. Consider the scenarios illustrated in Figures 2.12 and 2.13. Assume the rate \nof the institutional network is Rl and that of the bottleneck link is Rb. Suppose \nthere are N clients requesting a file of size L with HTTP at the same time. \nFor what values of Rl would the file transfer takes less time when a", "doc_id": "8fad8fc3-5240-465d-98f8-d4e100ee4270", "embedding": null, "doc_hash": "3ba8ed58aa647a6db0a0f35b4ff7ac48318279ff321b0e6fa7a55c11c5ef4d6b", "extra_info": null, "node_info": {"start": 601410, "end": 604628}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "e85ff66d-99c4-4ab6-9fc0-397a00b31732", "3": "ab8c3f47-5857-4522-812c-34df58b4d887"}}, "__type__": "1"}, "ab8c3f47-5857-4522-812c-34df58b4d887": {"__data__": {"text": "Starting with a root DNS server (from one of the root servers [a-m].\nroot-servers.net), initiate a sequence of queries for the IP address for your \ndepartment\u2019s Web server by using dig. Show the list of the names of DNS \nservers in the delegation chain in answering your query.\nb. Repeat part (a) for several popular Web sites, such as google.com, yahoo \n.com, or amazon.com.\n P20. Consider the scenarios illustrated in Figures 2.12 and 2.13. Assume the rate \nof the institutional network is Rl and that of the bottleneck link is Rb. Suppose \nthere are N clients requesting a file of size L with HTTP at the same time. \nFor what values of Rl would the file transfer takes less time when a proxy is \ninstalled at the institutional network? (Assume the RTT between a client and \nany other host in the institutional network is negligible.)\nPROBLEMS      207\n P21. Suppose that your department has a local DNS server for all computers in the \ndepartment. You are an ordinary user (i.e., not a network/system administra-\ntor). Can you determine if an external Web site was likely accessed from a \ncomputer in your department a couple of seconds ago? Explain.\n P22. Consider distributing a file of F=15 Gbits to N peers. The server has \nan upload rate of us=30 Mbps, and each peer has a download rate of \ndi=2 Mbps and an upload rate of u. For N=10, 100, and 1,000 and \nu=300 Kbps,  700 Kbps, and 2 Mbps, prepare a chart giving the minimum \ndistribution time for each of the combinations of N and u for both client-\nserver distribution and P2P distribution.\n P23. Consider distributing a file of F bits to N peers using a client-server archi-\ntecture. Assume a fluid model where the server can simultaneously transmit \nto multiple peers, transmitting to each peer at different rates, as long as the \ncombined rate does not exceed us.\na. Suppose that us/N\u2026dmin. Specify a distribution scheme that has a distri-\nbution time of NF/us.\nb. Suppose that us/N\u00dadmin. Specify a distribution scheme that has a distri-\nbution time of F/dmin.\nc. Conclude that the minimum distribution time is in general given by \nmax5NF/us, F/dmin6.\n P24. Consider distributing a file of F bits to N peers using a P2P architecture. \nAssume a fluid model. For simplicity assume that dmin is very large, so that \npeer download bandwidth is never a bottleneck.\na. Suppose that us\u2026(us+u1+. . .+uN)/N. Specify a distribution \nscheme that has a distribution time of F/us.\nb. Suppose that us\u00da(us+u1+. . .+uN)/N. Specify a distribution \nscheme that has a distribution time of NF/(us+u1+. . .+ uN).\nc. Conclude that the minimum distribution time is in general given by \nmax5F/us, NF/(us+u1+. . .+uN)6.\n P25. Suppose Bob joins a BitTorrent torrent, but he does not want to upload any \ndata to any other peers (so called free-riding).\na. Bob claims that he can receive a complete copy of the file that is shared \nby the swarm. Is Bob\u2019s claim possible? Why or why not?\nb. Bob further claims that he can further make his \u201cfree-riding\u201d more \nefficient by using a collection of multiple computers (with distinct IP \naddresses) in the computer lab in his department. How can he do that?\n208     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\n P26. Consider a DASH system for which there are N video versions (at N different \nrates and qualities) and N audio versions (at N different rates and qualities). \nSuppose we want to allow the player to choose at any time any of the N video \nversions and", "doc_id": "ab8c3f47-5857-4522-812c-34df58b4d887", "embedding": null, "doc_hash": "04eccda608abe68533f16d07bcdaa0d9d9491c2ac01e084cf1035e9b4ae2910b", "extra_info": null, "node_info": {"start": 604484, "end": 607918}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "8fad8fc3-5240-465d-98f8-d4e100ee4270", "3": "a9789f59-036d-41c4-af35-da4bfc5442b5"}}, "__type__": "1"}, "a9789f59-036d-41c4-af35-da4bfc5442b5": {"__data__": {"text": "upload any \ndata to any other peers (so called free-riding).\na. Bob claims that he can receive a complete copy of the file that is shared \nby the swarm. Is Bob\u2019s claim possible? Why or why not?\nb. Bob further claims that he can further make his \u201cfree-riding\u201d more \nefficient by using a collection of multiple computers (with distinct IP \naddresses) in the computer lab in his department. How can he do that?\n208     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\n P26. Consider a DASH system for which there are N video versions (at N different \nrates and qualities) and N audio versions (at N different rates and qualities). \nSuppose we want to allow the player to choose at any time any of the N video \nversions and any of the N audio versions.\na. If we create files so that the audio is mixed in with the video, so server \nsends only one media stream at given time, how many files will the server \nneed to store (each a different URL)?\nb. If the server instead sends the audio and video streams separately and has the \nclient synchronize the streams, how many files will the server need to store?\n P27. Install and compile the Python programs TCPClient and UDPClient on one \nhost and TCPServer and UDPServer on another host.\na. Suppose you run TCPClient before you run TCPServer. What happens? \nWhy?\nb. Suppose you run UDPClient before you run UDPServer. What happens? \nWhy?\nc. What happens if you use different port numbers for the client and server \nsides?\n P28. Suppose that in UDPClient.py, after we create the socket, we add the line:\nclientSocket.bind((\u2019\u2019, 5432))\nWill it become necessary to change UDPServer.py? What are the port num-\nbers for the sockets in UDPClient and UDPServer? What were they before \nmaking this change?\n P29. Can you configure your browser to open multiple simultaneous connections \nto a Web site? What are the advantages and disadvantages of having a large \nnumber of simultaneous TCP connections?\n P30. We have seen that Internet TCP sockets treat the data being sent as a \nbyte stream but UDP sockets recognize message boundaries. What are \none advantage and one disadvantage of byte-oriented API versus having \nthe API explicitly recognize and preserve application-defined message \nboundaries?\n P31. What is the server placement strategy adopted by Netflix for its CDN? How \nis content replicated at the different servers?\nSocket Programming Assignments\nThe Companion Website includes six socket programming assignments. The \nfirst four assignments are summarized below. The fifth assignment makes use \nof the ICMP protocol and is summarized at the end of Chapter 5. The sixth \nSOCKET PROGRAMMING ASSIGNMENTS      209\nassignment employs multimedia protocols and is summarized at the end of  \nChapter 9 . It is highly recommended that students complete several, if not all, of \nthese assignments. Students can find full details of these assignments, as well as \nimportant snippets of the Python code, at the Web site www.pearsonglobaleditions  \n.com/kurose.\nAssignment 1: Web Server\nIn this assignment, you will develop a simple Web server in Python that is capable of \nprocessing only one request. Specifically, your Web server will (i) create a connec -\ntion socket when contacted by a client (browser); (ii) receive the HTTP request from \nthis connection; (iii) parse the request to determine the specific file being requested; \n(iv) get the requested file from the server\u2019s file system; (v) create an HTTP response \nmessage consisting of the requested file preceded by header lines; and (vi) send the \nresponse over the TCP connection to the requesting browser. If a browser requests \na file that is not present in your server, your server should return a \u201c404 Not Found\u201d \nerror message.\nIn the Companion Website, we provide the skeleton code for your server. Your \njob is to complete the code, run your server,", "doc_id": "a9789f59-036d-41c4-af35-da4bfc5442b5", "embedding": null, "doc_hash": "e8fedce318fbbee10e90f57a107f6c8704b13ae29ae4e0365419b29b8dde1bfd", "extra_info": null, "node_info": {"start": 607910, "end": 611750}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "ab8c3f47-5857-4522-812c-34df58b4d887", "3": "758120e0-e770-4d85-9ca0-689fa290cc8a"}}, "__type__": "1"}, "758120e0-e770-4d85-9ca0-689fa290cc8a": {"__data__": {"text": "you will develop a simple Web server in Python that is capable of \nprocessing only one request. Specifically, your Web server will (i) create a connec -\ntion socket when contacted by a client (browser); (ii) receive the HTTP request from \nthis connection; (iii) parse the request to determine the specific file being requested; \n(iv) get the requested file from the server\u2019s file system; (v) create an HTTP response \nmessage consisting of the requested file preceded by header lines; and (vi) send the \nresponse over the TCP connection to the requesting browser. If a browser requests \na file that is not present in your server, your server should return a \u201c404 Not Found\u201d \nerror message.\nIn the Companion Website, we provide the skeleton code for your server. Your \njob is to complete the code, run your server, and then test your server by sending \nrequests from browsers running on different hosts. If you run your server on a host \nthat already has a Web server running on it, then you should use a different port than \nport 80 for your Web server.\nAssignment 2: UDP Pinger\nIn this programming assignment, you will write a client ping program in Python. \nYour client will send a simple ping message to a server, receive a corresponding \npong message back from the server, and determine the delay between when the client \nsent the ping message and received the pong message. This delay is called the Round \nTrip Time (RTT). The functionality provided by the client and server is similar to the \nfunctionality provided by standard ping program available in modern operating sys -\ntems. However, standard ping programs use the Internet Control Message Protocol \n(ICMP) (which we will study in Chapter 5 ). Here we will create a nonstandard (but \nsimple!) UDP-based ping program.\nYour ping program is to send 10 ping messages to the target server over UDP. \nFor each message, your client is to determine and print the RTT when the corre -\nsponding pong message is returned. Because UDP is an unreliable protocol, a packet \nsent by the client or server may be lost. For this reason, the client cannot wait indefi -\nnitely for a reply to a ping message. You should have the client wait up to one second \nfor a reply from the server; if no reply is received, the client should assume that the \npacket was lost and print a message accordingly.\nIn this assignment, you will be given the complete code for the server (available \nin the Companion Website). Your job is to write the client code, which will be very \n210     CHAPTER 2 \u2002\u2002\u2022 \u2002\u2002 APPLICATION LAYER\nsimilar to the server code. It is recommended that you first study carefully the server \ncode. You can then write your client code, liberally cutting and pasting lines from \nthe server code.\nAssignment 3: Mail Client\nThe goal of this programming assignment is to create a simple mail client that sends \ne-mail to any recipient. Your client will need to establish a TCP connection with \na mail server (e.g., a Google mail server), dialogue with the mail server using the \nSMTP protocol, send an e-mail message to a recipient (e.g., your friend) via the mail \nserver, and finally close the TCP connection with the mail server.\nFor this assignment, the Companion Website provides the skeleton code for \nyour client. Your job is to complete the code and test your client by sending e-mail \nto different user accounts. You may also try sending through different servers (for \nexample, through a Google mail server and through your university mail server).\nAssignment 4: Multi-Threaded Web Proxy\nIn this assignment, you will develop a Web proxy. When your proxy receives an \nHTTP request for an object from a browser, it generates a new HTTP request for \nthe same object and sends it to the origin server. When the proxy receives the cor -\nresponding HTTP response with the object from the origin server, it creates a new \nHTTP response, including the object, and sends it to the client. This proxy will be \nmulti-threaded, so that it will be able to handle multiple requests at the same time.\nFor this assignment, the Companion Website provides the skeleton code for the \nproxy server. Your job is to complete the code, and then test it by having different", "doc_id": "758120e0-e770-4d85-9ca0-689fa290cc8a", "embedding": null, "doc_hash": "01e0d7834fff371694eb51445a79bf96c009cf2fe5e14e7e454a8556b8f8219e", "extra_info": null, "node_info": {"start": 611651, "end": 615853}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "a9789f59-036d-41c4-af35-da4bfc5442b5", "3": "c6e39892-c10e-406b-a21b-f94f1fd3a3c5"}}, "__type__": "1"}, "c6e39892-c10e-406b-a21b-f94f1fd3a3c5": {"__data__": {"text": "user accounts. You may also try sending through different servers (for \nexample, through a Google mail server and through your university mail server).\nAssignment 4: Multi-Threaded Web Proxy\nIn this assignment, you will develop a Web proxy. When your proxy receives an \nHTTP request for an object from a browser, it generates a new HTTP request for \nthe same object and sends it to the origin server. When the proxy receives the cor -\nresponding HTTP response with the object from the origin server, it creates a new \nHTTP response, including the object, and sends it to the client. This proxy will be \nmulti-threaded, so that it will be able to handle multiple requests at the same time.\nFor this assignment, the Companion Website provides the skeleton code for the \nproxy server. Your job is to complete the code, and then test it by having different \nbrowsers request Web objects via your proxy.\nWireshark Lab: HTTP\nHaving gotten our feet wet with the Wireshark packet sniffer in Lab 1, we\u2019re now \nready to use Wireshark to investigate protocols in operation. In this lab, we\u2019ll explore \nseveral aspects of the HTTP protocol: the basic GET/reply interaction, HTTP message \nformats, retrieving large HTML files, retrieving HTML files with embedded URLs, \npersistent and non-persistent connections, and HTTP authentication and security.\nAs is the case with all Wireshark labs, the full description of this lab is available \nat this book\u2019s Web site, www.pearsonglobaleditions.com/kurose.\nWIRESHARK LAB: DNS      211\nWireshark Lab: DNS\nIn this lab, we take a closer look at the client side of the DNS, the protocol that \ntranslates Internet hostnames to IP addresses. Recall from Section 2.5 that the cli -\nent\u2019s role in the DNS is relatively simple\u2014a client sends a query to its local DNS \nserver and receives a response back. Much can go on under the covers, invisible to \nthe DNS clients, as the hierarchical DNS servers communicate with each other to \neither recursively or iteratively resolve the client\u2019s DNS query. From the DNS cli -\nent\u2019s standpoint, however, the protocol is quite simple\u2014a query is formulated to the \nlocal DNS server and a response is received from that server. We observe DNS in \naction in this lab.\nAs is the case with all Wireshark labs, the full description of this lab is available \nat this book\u2019s Web site, www.pearsonglobaleditions.com/kurose.\n212AN INTERVIEW WITH...\nMarc Andreessen\nMarc Andreessen is the co-creator of Mosaic, the Web browser \nthat popularized the World Wide Web in 1993. Mosaic had \na clean, easily understood interface and was the first browser to \ndisplay images in-line with text. In 1994, Marc Andreessen and \nJim Clark founded Netscape, whose browser was by far the most \npopular browser through the mid-1990s. Netscape also devel -\noped the Secure Sockets Layer (SSL) protocol and many Internet \nserver products, including mail servers and SSL-based Web serv -\ners. He is now a co-founder and general partner of venture capital \nfirm Andreessen Horowitz, overseeing portfolio development with \nholdings that include Facebook, Foursquare, Groupon, Jawbone, \nTwitter, and Zynga. He serves on numerous boards, including Bump, \neBay, Glam Media, Facebook, and Hewlett-Packard. He holds a \nBS in Computer Science from the University of Illinois at Urbana-\nChampaign.\nHow did you become interested in computing? Did you always know that you wanted to \nwork in information technology?\nThe video game and personal computing revolutions hit right when I was growing up\u2014\npersonal computing was the new technology frontier in the late 70\u2019s and early 80\u2019s. And \nit wasn\u2019t just Apple and the IBM PC, but hundreds of new companies like Commodore \nand Atari as well. I taught myself to program out of a book called \u201cInstant Freeze-Dried", "doc_id": "c6e39892-c10e-406b-a21b-f94f1fd3a3c5", "embedding": null, "doc_hash": "912bc00bad16f21d73484a962d5e654d8a71033b087d68ac2b310ae5c875f74f", "extra_info": null, "node_info": {"start": 615821, "end": 619601}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "758120e0-e770-4d85-9ca0-689fa290cc8a", "3": "e260a97c-200f-4e72-93b1-095e73040549"}}, "__type__": "1"}, "e260a97c-200f-4e72-93b1-095e73040549": {"__data__": {"text": "include Facebook, Foursquare, Groupon, Jawbone, \nTwitter, and Zynga. He serves on numerous boards, including Bump, \neBay, Glam Media, Facebook, and Hewlett-Packard. He holds a \nBS in Computer Science from the University of Illinois at Urbana-\nChampaign.\nHow did you become interested in computing? Did you always know that you wanted to \nwork in information technology?\nThe video game and personal computing revolutions hit right when I was growing up\u2014\npersonal computing was the new technology frontier in the late 70\u2019s and early 80\u2019s. And \nit wasn\u2019t just Apple and the IBM PC, but hundreds of new companies like Commodore \nand Atari as well. I taught myself to program out of a book called \u201cInstant Freeze-Dried \nBASIC\u201d at age 10, and got my first computer (a TRS-80 Color Computer\u2014look it up!) \nat age 1 2.\nPlease describe one or two of the most exciting projects you have worked on during your \ncareer. What were the biggest challenges?\nUndoubtedly the most exciting project was the original Mosaic web browser in \u201992\u2013\u201993\u2014\nand the biggest challenge was getting anyone to take it seriously back then. At the time, \neveryone thought the interactive future would be delivered as \u201cinteractive television\u201d by \nhuge companies, not as the Internet by startups.\n213What excites you about the future of networking and the Internet? What are your biggest \nconcerns?\nThe most exciting thing is the huge unexplored frontier of applications and services that \nprogrammers and entrepreneurs are able to explore\u2014the Internet has unleashed creativity \nat a level that I don\u2019t think we\u2019ve ever seen before. My biggest concern is the principle of \nunintended consequences\u2014we don\u2019t always know the implications of what we do, such as \nthe Internet being used by governments to run a new level of surveillance on citizens.\nIs there anything in particular students should be aware of as Web technology advances?\nThe rate of change\u2014the most important thing to learn is how to learn\u2014how to flexibly \nadapt to changes in the specific technologies, and how to keep an open mind on the new \nopportunities and possibilities as you move through your career.\nWhat people inspired you professionally?\nVannevar Bush, Ted Nelson, Doug Engelbart, Nolan Bushnell, Bill Hewlett and Dave \nPackard, Ken Olsen, Steve Jobs, Steve Wozniak, Andy Grove, Grace Hopper, Hedy Lamarr, \nAlan Turing, Richard Stallman.\nWhat are your recommendations for students who want to pursue careers in computing \nand information technology?\nGo as deep as you possibly can on understanding how technology is created, and then com -\nplement with learning how business works.\nCan technology solve the world\u2019s problems?\nNo, but we advance the standard of living of people through economic growth, and most \neconomic growth throughout history has come from technology\u2014so that\u2019s as good as it \ngets.\nThis page intentionally left blank\n215Residing between the application and network layers, the transport layer is a central \npiece of the layered network architecture. It has the critical role of providing com -\nmunication services directly to the application processes running on different hosts. \nThe pedagogic approach we take in this chapter is to alternate between discussions of \ntransport-layer principles and discussions of how these principles are implemented \nin existing protocols; as usual, particular emphasis will be given to Internet proto -\ncols, in particular the TCP and UDP transport-layer protocols.\nWe\u2019ll begin by discussing the relationship between the transport and network \nlayers. This sets the stage for examining the first critical function of the transport \nlayer\u2014extending the network layer\u2019s delivery service between two end systems to \na delivery service between two application-layer processes running on the end sys -\ntems. We\u2019ll illustrate this function in our coverage of the Internet\u2019s connectionless \ntransport protocol, UDP.\nWe\u2019ll then return to principles and", "doc_id": "e260a97c-200f-4e72-93b1-095e73040549", "embedding": null, "doc_hash": "138fcdf927f0fe28d2e38f457a580927c3e4b51e603d04e64742ac0cd1de46e4", "extra_info": null, "node_info": {"start": 619710, "end": 623648}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "c6e39892-c10e-406b-a21b-f94f1fd3a3c5", "3": "6d227109-1db4-4367-b41c-c43b1445c4d4"}}, "__type__": "1"}, "6d227109-1db4-4367-b41c-c43b1445c4d4": {"__data__": {"text": "we take in this chapter is to alternate between discussions of \ntransport-layer principles and discussions of how these principles are implemented \nin existing protocols; as usual, particular emphasis will be given to Internet proto -\ncols, in particular the TCP and UDP transport-layer protocols.\nWe\u2019ll begin by discussing the relationship between the transport and network \nlayers. This sets the stage for examining the first critical function of the transport \nlayer\u2014extending the network layer\u2019s delivery service between two end systems to \na delivery service between two application-layer processes running on the end sys -\ntems. We\u2019ll illustrate this function in our coverage of the Internet\u2019s connectionless \ntransport protocol, UDP.\nWe\u2019ll then return to principles and confront one of the most fundamental prob -\nlems in computer networking\u2014how two entities can communicate reliably over a \nmedium that may lose and corrupt data. Through a series of increasingly complicated \n(and realistic!) scenarios, we\u2019ll build up an array of techniques that transport proto -\ncols use to solve this problem. We\u2019ll then show how these principles are embodied \nin TCP, the Internet\u2019s connection-oriented transport protocol.\nWe\u2019ll next move on to a second fundamentally important problem in  \nnetworking\u2014controlling the transmission rate of transport-layer entities in order to \navoid, or recover from, congestion within the network. We\u2019ll consider the causes \nand consequences of congestion, as well as commonly used congestion-control 3CHAPTER\nTransport \nLayer\n\n216     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\ntechniques. After obtaining a solid understanding of the issues behind congestion \ncontrol, we\u2019ll study TCP\u2019s approach to congestion control.\n3.1 Introduction and Transport-Layer Services\nIn the previous two chapters we touched on the role of the transport layer and the \nservices that it provides. Let\u2019s quickly review what we have already learned about \nthe transport layer.\nA transport-layer protocol provides for logical communication  between \napplication processes running on different hosts. By logical communication , we \nmean that from an application\u2019s perspective, it is as if the hosts running the pro -\ncesses were directly connected; in reality, the hosts may be on opposite sides of the \nplanet, connected via numerous routers and a wide range of link types. Application \nprocesses use the logical communication provided by the transport layer to send \nmessages to each other, free from the worry of the details of the physical infra -\nstructure used to carry these messages. Figure 3.1 illustrates the notion of logical \ncommunication.\nAs shown in Figure 3.1, transport-layer protocols are implemented in the end \nsystems but not in network routers. On the sending side, the transport layer converts \nthe application-layer messages it receives from a sending application process into \ntransport-layer packets, known as transport-layer segments  in Internet terminology. \nThis is done by (possibly) breaking the application messages into smaller chunks \nand adding a transport-layer header to each chunk to create the transport-layer seg -\nment. The transport layer then passes the segment to the network layer at the send -\ning end system, where the segment is encapsulated within a network-layer packet (a \ndatagram) and sent to the destination. It\u2019s important to note that network routers act \nonly on the network-layer fields of the datagram; that is, they do not examine the \nfields of the transport-layer segment encapsulated with the datagram. On the receiv -\ning side, the network layer extracts the transport-layer segment from the datagram \nand passes the segment up to the transport layer. The transport layer then processes \nthe received segment, making the data in the segment available to the receiving \napplication.\nMore than one transport-layer protocol may be available to network applications. \nFor example, the Internet has two protocols\u2014TCP", "doc_id": "6d227109-1db4-4367-b41c-c43b1445c4d4", "embedding": null, "doc_hash": "81131beecc063cd37ad3d1a5ac1eafd8670ef14dba25caef526affcb3a073161", "extra_info": null, "node_info": {"start": 623585, "end": 627558}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "e260a97c-200f-4e72-93b1-095e73040549", "3": "7834d182-330a-4155-97d4-cc718d1d7eae"}}, "__type__": "1"}, "7834d182-330a-4155-97d4-cc718d1d7eae": {"__data__": {"text": "the segment to the network layer at the send -\ning end system, where the segment is encapsulated within a network-layer packet (a \ndatagram) and sent to the destination. It\u2019s important to note that network routers act \nonly on the network-layer fields of the datagram; that is, they do not examine the \nfields of the transport-layer segment encapsulated with the datagram. On the receiv -\ning side, the network layer extracts the transport-layer segment from the datagram \nand passes the segment up to the transport layer. The transport layer then processes \nthe received segment, making the data in the segment available to the receiving \napplication.\nMore than one transport-layer protocol may be available to network applications. \nFor example, the Internet has two protocols\u2014TCP and UDP. Each of these protocols \nprovides a different set of transport-layer services to the invoking application.\n3.1.1  Relationship Between Transport and Network Layers\nRecall that the transport layer lies just above the network layer in the protocol \nstack. Whereas a transport-layer protocol provides logical communication between \n3.1  \u2022  INTRODUCTION AND TRANSPORT-LAYER SERVICES      217\nNetwork\nData link\nPhysicalApplication\nTransportNetwork\nData link\nPhysicalNetwork\nData link\nPhysical\nNetwork\nData link\nPhysicalApplication\nTransportNetwork\nData link\nPhysicalNational or\nGlobal ISP\nMobile Network\nLocal or\nRegional ISP\nEnterprise NetworkHome Network\nLogical end-to-end transportNetwork\nData link\nPhysicalNetwork\nData link\nPhysical\nFigure 3.1  \u2666  The transport layer provides logical rather than physical  \ncommunication between application processes\n218     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nprocesses  running on different hosts, a network-layer protocol provides logical-  \ncommunication between hosts . This distinction is subtle but important. Let\u2019s exam -\nine this distinction with the aid of a household analogy.\nConsider two houses, one on the East Coast and the other on the West Coast, \nwith each house being home to a dozen kids. The kids in the East Coast household \nare cousins of the kids in the West Coast household. The kids in the two households \nlove to write to each other\u2014each kid writes each cousin every week, with each letter \ndelivered by the traditional postal service in a separate envelope. Thus, each house -\nhold sends 144 letters to the other household every week. (These kids would save a lot \nof money if they had e-mail!) In each of the households there is one kid\u2014Ann in the \nWest Coast house and Bill in the East Coast house\u2014responsible for mail collection  \nand mail distribution. Each week Ann visits all her brothers and sisters, collects the \nmail, and gives the mail to a postal-service mail carrier, who makes daily visits to \nthe house. When letters arrive at the West Coast house, Ann also has the job of dis -\ntributing the mail to her brothers and sisters. Bill has a similar job on the East Coast.\nIn this example, the postal service provides logical communication between the \ntwo houses\u2014the postal service moves mail from house to house, not from person to \nperson. On the other hand, Ann and Bill provide logical communication among the \ncousins\u2014Ann and Bill pick up mail from, and deliver mail to, their brothers and sis -\nters. Note that from the cousins\u2019 perspective, Ann and Bill are the mail service, even \nthough Ann and Bill are only a part (the end-system part) of the end-to-end delivery \nprocess. This household example serves as a nice analogy for explaining how the \ntransport layer relates to the network layer:\napplication messages =letters in envelopes\nprocesses =cousins\nhosts (also called end systems) =houses\ntransport-layer protocol =Ann and Bill\nnetwork-layer protocol =postal service (including mail carriers)\nContinuing with this analogy, note that Ann and Bill do all their work within \ntheir respective homes; they are not involved, for example, in sorting mail in \nany intermediate", "doc_id": "7834d182-330a-4155-97d4-cc718d1d7eae", "embedding": null, "doc_hash": "7101743d16dab3b7f850e2e7f1f94c337a3ee41afdcf4ae5d778cb79d764519f", "extra_info": null, "node_info": {"start": 627563, "end": 631510}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "6d227109-1db4-4367-b41c-c43b1445c4d4", "3": "3cf18bb8-514b-4544-80ab-abdfcf8d4c22"}}, "__type__": "1"}, "3cf18bb8-514b-4544-80ab-abdfcf8d4c22": {"__data__": {"text": "and Bill pick up mail from, and deliver mail to, their brothers and sis -\nters. Note that from the cousins\u2019 perspective, Ann and Bill are the mail service, even \nthough Ann and Bill are only a part (the end-system part) of the end-to-end delivery \nprocess. This household example serves as a nice analogy for explaining how the \ntransport layer relates to the network layer:\napplication messages =letters in envelopes\nprocesses =cousins\nhosts (also called end systems) =houses\ntransport-layer protocol =Ann and Bill\nnetwork-layer protocol =postal service (including mail carriers)\nContinuing with this analogy, note that Ann and Bill do all their work within \ntheir respective homes; they are not involved, for example, in sorting mail in \nany intermediate mail center or in moving mail from one mail center to another.  \nSimilarly, transport-layer protocols live in the end systems. Within an end system, a \ntransport protocol moves messages from application processes to the network edge \n(that is, the network layer) and vice versa, but it doesn\u2019t have any say about how the \nmessages are moved within the network core. In fact, as illustrated in Figure 3.1, \nintermediate routers neither act on, nor recognize, any information that the transport \nlayer may have added to the application messages.\nContinuing with our family saga, suppose now that when Ann and Bill go on \nvacation, another cousin pair\u2014say, Susan and Harvey\u2014substitute for them and pro -\nvide the household-internal collection and delivery of mail. Unfortunately for the \ntwo families, Susan and Harvey do not do the collection and delivery in exactly \n3.1  \u2022  INTRODUCTION AND TRANSPORT-LAYER SERVICES      219\nthe same way as Ann and Bill. Being younger kids, Susan and Harvey pick up and \ndrop off the mail less frequently and occasionally lose letters (which are sometimes \nchewed up by the family dog). Thus, the cousin-pair Susan and Harvey do not pro -\nvide the same set of services (that is, the same service model) as Ann and Bill. In \nan analogous manner, a computer network may make available multiple transport \nprotocols, with each protocol offering a different service model to applications.\nThe possible services that Ann and Bill can provide are clearly constrained by \nthe possible services that the postal service provides. For example, if the postal ser -\nvice doesn\u2019t provide a maximum bound on how long it can take to deliver mail \nbetween the two houses (for example, three days), then there is no way that Ann and \nBill can guarantee a maximum delay for mail delivery between any of the cousin \npairs. In a similar manner, the services that a transport protocol can provide are often \nconstrained by the service model of the underlying network-layer protocol. If the \nnetwork-layer protocol cannot provide delay or bandwidth guarantees for transport-\nlayer segments sent between hosts, then the transport-layer protocol cannot provide \ndelay or bandwidth guarantees for application messages sent between processes.\nNevertheless, certain services can be offered by a transport protocol even when \nthe underlying network protocol doesn\u2019t offer the corresponding service at the net -\nwork layer. For example, as we\u2019ll see in this chapter, a transport protocol can offer \nreliable data transfer service to an application even when the underlying network \nprotocol is unreliable, that is, even when the network protocol loses, garbles, or \nduplicates packets. As another example (which we\u2019ll explore in Chapter 8 when we \ndiscuss network security), a transport protocol can use encryption to guarantee that \napplication messages are not read by intruders, even when the network layer cannot \nguarantee the confidentiality of transport-layer segments.\n3.1.2  Overview of the Transport Layer in the Internet\nRecall that the Internet makes two distinct transport-layer protocols available to the \napplication layer. One of these protocols is UDP  (User Datagram Protocol), which \nprovides an unreliable, connectionless service to the invoking", "doc_id": "3cf18bb8-514b-4544-80ab-abdfcf8d4c22", "embedding": null, "doc_hash": "354dbc2ffb74217a626a5983c3b019554c971a5c21e693929ba7fc8280d248f5", "extra_info": null, "node_info": {"start": 631529, "end": 635556}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "7834d182-330a-4155-97d4-cc718d1d7eae", "3": "0098d255-3cc0-4b7f-b60c-2f02e695193c"}}, "__type__": "1"}, "0098d255-3cc0-4b7f-b60c-2f02e695193c": {"__data__": {"text": "this chapter, a transport protocol can offer \nreliable data transfer service to an application even when the underlying network \nprotocol is unreliable, that is, even when the network protocol loses, garbles, or \nduplicates packets. As another example (which we\u2019ll explore in Chapter 8 when we \ndiscuss network security), a transport protocol can use encryption to guarantee that \napplication messages are not read by intruders, even when the network layer cannot \nguarantee the confidentiality of transport-layer segments.\n3.1.2  Overview of the Transport Layer in the Internet\nRecall that the Internet makes two distinct transport-layer protocols available to the \napplication layer. One of these protocols is UDP  (User Datagram Protocol), which \nprovides an unreliable, connectionless service to the invoking application. The sec -\nond of these protocols is TCP  (Transmission Control Protocol), which provides a \nreliable, connection-oriented service to the invoking application. When designing a \nnetwork application, the application developer must specify one of these two trans -\nport protocols. As we saw in Section 2.7, the application developer selects between \nUDP and TCP when creating sockets.\nTo simplify terminology, we refer to the transport-layer packet as a segment . We \nmention, however, that the Internet literature (for example, the RFCs) also refers to \nthe transport-layer packet for TCP as a segment but often refers to the packet for UDP \nas a datagram. But this same Internet literature also uses the term datagram  for the \nnetwork-layer packet! For an introductory book on computer networking such as this, \nwe believe that it is less confusing to refer to both TCP and UDP packets as segments, \nand reserve the term datagram  for the network-layer packet.\n220     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nBefore proceeding with our brief introduction of UDP and TCP, it will be useful \nto say a few words about the Internet\u2019s network layer. (We\u2019ll learn about the network \nlayer in detail in Chapters 4 and 5.) The Internet\u2019s network-layer protocol has a \nname\u2014IP, for Internet Protocol. IP provides logical communication between hosts. \nThe IP service model is a best-effort delivery service . This means that IP makes \nits \u201cbest effort\u201d to deliver segments between communicating hosts, but it makes no \nguarantees.  In particular, it does not guarantee segment delivery, it does not guaran -\ntee orderly delivery of segments, and it does not guarantee the integrity of the data \nin the segments. For these reasons, IP is said to be an unreliable service . We also \nmention here that every host has at least one network-layer address, a so-called IP \naddress. We\u2019ll examine IP addressing in detail in Chapter 4; for this chapter we need \nonly keep in mind that each host has an IP address .\nHaving taken a glimpse at the IP service model, let\u2019s now summarize the service \nmodels provided by UDP and TCP. The most fundamental responsibility of UDP \nand TCP is to extend IP\u2019s delivery service between two end systems to a delivery \nservice between two processes running on the end systems. Extending host-to-host \ndelivery to process-to-process delivery is called transport-layer multiplexing  and  \ndemultiplexing . We\u2019ll discuss transport-layer multiplexing and demultiplexing in \nthe next section. UDP and TCP also provide integrity checking by including error-\ndetection fields in their segments\u2019 headers. These two minimal transport-layer \nservices\u2014process-to-process data delivery and error checking\u2014are the only two \nservices that UDP provides! In particular, like IP, UDP is an unreliable service\u2014it \ndoes not guarantee that data sent by one process will arrive intact (or at all!) to the \ndestination process. UDP is discussed in detail in Section 3.3.\nTCP, on the other hand, offers several", "doc_id": "0098d255-3cc0-4b7f-b60c-2f02e695193c", "embedding": null, "doc_hash": "0494b2157c913645b85ad6d4e2d10b555e136ff1f54ca2e18d4ee447f1140167", "extra_info": null, "node_info": {"start": 635506, "end": 639328}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "3cf18bb8-514b-4544-80ab-abdfcf8d4c22", "3": "70d92ff9-0889-49e3-96b5-9da267cb08bb"}}, "__type__": "1"}, "70d92ff9-0889-49e3-96b5-9da267cb08bb": {"__data__": {"text": "end systems. Extending host-to-host \ndelivery to process-to-process delivery is called transport-layer multiplexing  and  \ndemultiplexing . We\u2019ll discuss transport-layer multiplexing and demultiplexing in \nthe next section. UDP and TCP also provide integrity checking by including error-\ndetection fields in their segments\u2019 headers. These two minimal transport-layer \nservices\u2014process-to-process data delivery and error checking\u2014are the only two \nservices that UDP provides! In particular, like IP, UDP is an unreliable service\u2014it \ndoes not guarantee that data sent by one process will arrive intact (or at all!) to the \ndestination process. UDP is discussed in detail in Section 3.3.\nTCP, on the other hand, offers several additional services to applications. First \nand foremost, it provides reliable data transfer . Using flow control, sequence \nnumbers, acknowledgments, and timers (techniques we\u2019ll explore in detail in this \nchapter), TCP ensures that data is delivered from sending process to receiving pro -\ncess, correctly and in order. TCP thus converts IP\u2019s unreliable service between end \nsystems into a reliable data transport service between processes. TCP also provides \ncongestion control . Congestion control is not so much a service provided to the \ninvoking application as it is a service for the Internet as a whole, a service for the \ngeneral good. Loosely speaking, TCP congestion control prevents any one TCP con -\nnection from swamping the links and routers between communicating hosts with \nan excessive amount of traffic. TCP strives to give each connection traversing a \ncongested link an equal share of the link bandwidth. This is done by regulating the \nrate at which the sending sides of TCP connections can send traffic into the network. \nUDP traffic, on the other hand, is unregulated. An application using UDP transport \ncan send at any rate it pleases, for as long as it pleases.\nA protocol that provides reliable data transfer and congestion control is neces -\nsarily complex. We\u2019ll need several sections to cover the principles of reliable data \ntransfer and congestion control, and additional sections to cover the TCP protocol \nitself. These topics are investigated in Sections 3.4 through 3.8. The approach taken \n3.2  \u2022  MULTIPLEXING AND DEMULTIPLEXING      221\nin this chapter is to alternate between basic principles and the TCP protocol. For \nexample, we\u2019ll first discuss reliable data transfer in a general setting and then discuss \nhow TCP specifically provides reliable data transfer. Similarly, we\u2019ll first discuss \ncongestion control in a general setting and then discuss how TCP performs conges -\ntion control. But before getting into all this good stuff, let\u2019s first look at transport-\nlayer multiplexing and demultiplexing.\n3.2 Multiplexing and Demultiplexing\nIn this section, we discuss transport-layer multiplexing and demultiplexing, that \nis, extending the host-to-host delivery service provided by the network layer to a  \nprocess-to-process delivery service for applications running on the hosts. In order to \nkeep the discussion concrete, we\u2019ll discuss this basic transport-layer service in the \ncontext of the Internet. We emphasize, however, that a multiplexing/demultiplexing \nservice is needed for all computer networks.\nAt the destination host, the transport layer receives segments from the network \nlayer just below. The transport layer has the responsibility of delivering the data in \nthese segments to the appropriate application process running in the host. Let\u2019s take \na look at an example. Suppose you are sitting in front of your computer, and you are \ndownloading Web pages while running one FTP session and two Telnet sessions. \nYou therefore have four network application processes running\u2014two Telnet pro -\ncesses, one FTP process, and one HTTP process. When the transport layer in your \ncomputer receives data from the network layer below, it needs", "doc_id": "70d92ff9-0889-49e3-96b5-9da267cb08bb", "embedding": null, "doc_hash": "47d2929526d44ffed5584c014ca9aa93f5e8ce66e6f3b6dc7cf439164e66d9ee", "extra_info": null, "node_info": {"start": 639402, "end": 643326}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "0098d255-3cc0-4b7f-b60c-2f02e695193c", "3": "541cc6cc-d795-4ee2-bff1-676ce67a141d"}}, "__type__": "1"}, "541cc6cc-d795-4ee2-bff1-676ce67a141d": {"__data__": {"text": "we\u2019ll discuss this basic transport-layer service in the \ncontext of the Internet. We emphasize, however, that a multiplexing/demultiplexing \nservice is needed for all computer networks.\nAt the destination host, the transport layer receives segments from the network \nlayer just below. The transport layer has the responsibility of delivering the data in \nthese segments to the appropriate application process running in the host. Let\u2019s take \na look at an example. Suppose you are sitting in front of your computer, and you are \ndownloading Web pages while running one FTP session and two Telnet sessions. \nYou therefore have four network application processes running\u2014two Telnet pro -\ncesses, one FTP process, and one HTTP process. When the transport layer in your \ncomputer receives data from the network layer below, it needs to direct the received \ndata to one of these four processes. Let\u2019s now examine how this is done.\nFirst recall from Section 2.7 that a process (as part of a network application) \ncan have one or more sockets , doors through which data passes from the network to \nthe process and through which data passes from the process to the network. Thus, \nas shown in Figure 3.2, the transport layer in the receiving host does not actually \ndeliver data directly to a process, but instead to an intermediary socket. Because at \nany given time there can be more than one socket in the receiving host, each socket \nhas a unique identifier. The format of the identifier depends on whether the socket is \na UDP or a TCP socket, as we\u2019ll discuss shortly.\nNow let\u2019s consider how a receiving host directs an incoming transport-layer \nsegment to the appropriate socket. Each transport-layer segment has a set of fields in \nthe segment for this purpose. At the receiving end, the transport layer examines these \nfields to identify the receiving socket and then directs the segment to that socket. \nThis job of delivering the data in a transport-layer segment to the correct socket is \ncalled demultiplexing . The job of gathering data chunks at the source host from \ndifferent sockets, encapsulating each data chunk with header information (that will \nlater be used in demultiplexing) to create segments, and passing the segments to the \nnetwork layer is called multiplexing . Note that the transport layer in the middle host \n222     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nin Figure 3.2 must demultiplex segments arriving from the network layer below to \neither process P1 or P2 above; this is done by directing the arriving segment\u2019s data to \nthe corresponding process\u2019s socket. The transport layer in the middle host must also \ngather outgoing data from these sockets, form transport-layer segments, and pass \nthese segments down to the network layer. Although we have introduced multiplex -\ning and demultiplexing in the context of the Internet transport protocols, it\u2019s impor -\ntant to realize that they are concerns whenever a single protocol at one layer (at the \ntransport layer or elsewhere) is used by multiple protocols at the next higher layer.\nTo illustrate the demultiplexing job, recall the household analogy in the previous \nsection. Each of the kids is identified by his or her name. When Bill receives a batch \nof mail from the mail carrier, he performs a demultiplexing operation by observing \nto whom the letters are addressed and then hand delivering the mail to his brothers \nand sisters. Ann performs a multiplexing operation when she collects letters from her \nbrothers and sisters and gives the collected mail to the mail person.\nNow that we understand the roles of transport-layer multiplexing and demulti -\nplexing, let us examine how it is actually done in a host. From the discussion above, \nwe know that transport-layer multiplexing requires (1) that sockets have unique \nidentifiers, and (2) that each segment have special fields that indicate the socket to \nwhich the segment is to be delivered. These special fields, illustrated in Figure 3.3, \nare the source port number field  and", "doc_id": "541cc6cc-d795-4ee2-bff1-676ce67a141d", "embedding": null, "doc_hash": "eeeabe0092db2025f6c8dc60a821c59fdc823826b5efd2f65d224966e2d2a852", "extra_info": null, "node_info": {"start": 643248, "end": 647264}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "70d92ff9-0889-49e3-96b5-9da267cb08bb", "3": "9a78bb25-f818-47c1-aeed-738ed7d256f6"}}, "__type__": "1"}, "9a78bb25-f818-47c1-aeed-738ed7d256f6": {"__data__": {"text": "batch \nof mail from the mail carrier, he performs a demultiplexing operation by observing \nto whom the letters are addressed and then hand delivering the mail to his brothers \nand sisters. Ann performs a multiplexing operation when she collects letters from her \nbrothers and sisters and gives the collected mail to the mail person.\nNow that we understand the roles of transport-layer multiplexing and demulti -\nplexing, let us examine how it is actually done in a host. From the discussion above, \nwe know that transport-layer multiplexing requires (1) that sockets have unique \nidentifiers, and (2) that each segment have special fields that indicate the socket to \nwhich the segment is to be delivered. These special fields, illustrated in Figure 3.3, \nare the source port number field  and the destination port number field . (The UDP \nand TCP segments have other fields as well, as discussed in the subsequent sections \nof this chapter.) Each port number is a 16-bit number, ranging from 0 to 65535. \nThe port numbers ranging from 0 to 1023 are called well-known port numbers   \nand are restricted, which means that they are reserved for use by well-known Network\nKey:\nProcess SocketData link\nPhysicalTransportApplication\nNetworkApplication\nData link\nPhysicalTransport\nNetwork\nData link\nPhysicalTransportP3 P2 P1 P4Application\nFigure 3.2  \u2666 Transport-layer multiplexing and demultiplexing\n3.2  \u2022  MULTIPLEXING AND DEMULTIPLEXING      223\napplication protocols such as HTTP (which uses port number 80) and FTP (which \nuses port number 21). The list of well-known port numbers is given in RFC 1700 \nand is updated at http://www.iana.org [RFC 3232]. When we develop a new appli -\ncation (such as the simple application developed in Section 2.7), we must assign the \napplication a port number.\nIt should now be clear how the transport layer could  implement the demultiplex -\ning service: Each socket in the host could be assigned a port number, and when \na segment arrives at the host, the transport layer examines the destination port \nnumber in the segment and directs the segment to the corresponding socket. The \nsegment\u2019s data then passes through the socket into the attached process. As we\u2019ll \nsee, this is basically how UDP does it. However, we\u2019ll also see that multiplexing/\ndemultiplexing in TCP is yet more subtle.\nConnectionless Multiplexing and Demultiplexing\nRecall from Section 2.7.1 that the Python program running in a host can create a \nUDP socket with the line\nclientSocket = socket(AF_INET, SOCK_DGRAM)\nWhen a UDP socket is created in this manner, the transport layer automatically \nassigns a port number to the socket. In particular, the transport layer assigns a port \nnumber in the range 1024 to 65535 that is currently not being used by any other UDP \nport in the host. Alternatively, we can add a line into our Python program after we \ncreate the socket to associate a specific port number (say, 19157) to this UDP socket \nvia the socket bind()  method:\nclientSocket.bind((\u2019\u2019, 19157))Source port #32 bits\nDest. port #\nOther header \ufb01elds\nApplication\ndata\n(message)\nFigure 3.3  \u2666  Source and destination port-number fields in a transport-layer \nsegment\n224     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nIf the application developer writing the code were implementing the server side of \na \u201cwell-known protocol,\u201d then the developer would have to assign the correspond -\ning well-known port number. Typically, the client side of the application lets the \ntransport layer automatically (and transparently) assign the port number, whereas the \nserver side of the application assigns a specific port number.\nWith port numbers assigned to UDP sockets, we can now precisely describe \nUDP multiplexing/demultiplexing. Suppose a process in Host A, with UDP port", "doc_id": "9a78bb25-f818-47c1-aeed-738ed7d256f6", "embedding": null, "doc_hash": "e98b2d4cf4f892fe931e923986085e83b3c84e3a7c7f2c61be655792724e79b5", "extra_info": null, "node_info": {"start": 647300, "end": 651067}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "541cc6cc-d795-4ee2-bff1-676ce67a141d", "3": "2e4a2ce9-c0bc-4828-bf80-cd380c74176e"}}, "__type__": "1"}, "2e4a2ce9-c0bc-4828-bf80-cd380c74176e": {"__data__": {"text": "3.3  \u2666  Source and destination port-number fields in a transport-layer \nsegment\n224     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nIf the application developer writing the code were implementing the server side of \na \u201cwell-known protocol,\u201d then the developer would have to assign the correspond -\ning well-known port number. Typically, the client side of the application lets the \ntransport layer automatically (and transparently) assign the port number, whereas the \nserver side of the application assigns a specific port number.\nWith port numbers assigned to UDP sockets, we can now precisely describe \nUDP multiplexing/demultiplexing. Suppose a process in Host A, with UDP port \n19157, wants to send a chunk of application data to a process with UDP port 46428 in \nHost B. The transport layer in Host A creates a transport-layer segment that includes \nthe application data, the source port number (19157), the destination port number \n(46428), and two other values (which will be discussed later, but are unimportant for \nthe current discussion). The transport layer then passes the resulting segment to the \nnetwork layer. The network layer encapsulates the segment in an IP datagram and \nmakes a best-effort attempt to deliver the segment to the receiving host. If the seg -\nment arrives at the receiving Host B, the transport layer at the receiving host exam -\nines the destination port number in the segment (46428) and delivers the segment \nto its socket identified by port 46428. Note that Host B could be running multiple \nprocesses, each with its own UDP socket and associated port number. As UDP seg -\nments arrive from the network, Host B directs (demultiplexes) each segment to the \nappropriate socket by examining the segment\u2019s destination port number.\nIt is important to note that a UDP socket is fully identified by a two-tuple consist -\ning of a destination IP address and a destination port number. As a consequence, if \ntwo UDP segments have different source IP addresses and/or source port numbers, but \nhave the same destination  IP address and destination  port number, then the two seg -\nments will be directed to the same destination process via the same destination socket.\nYou may be wondering now, what is the purpose of the source port number? \nAs shown in Figure 3.4, in the A-to-B segment the source port number serves as \npart of a \u201creturn address\u201d\u2014when B wants to send a segment back to A, the destina -\ntion port in the B-to-A segment will take its value from the source port value of the \nA-to-B segment. (The complete return address is A\u2019s IP address and the source port \nnumber.) As an example, recall the UDP server program studied in Section 2.7. In \nUDPServer.py , the server uses the recvfrom()  method to extract the client-\nside (source) port number from the segment it receives from the client; it then sends \na new segment to the client, with the extracted source port number serving as the \ndestination port number in this new segment.\nConnection-Oriented Multiplexing and Demultiplexing\nIn order to understand TCP demultiplexing, we have to take a close look at TCP \nsockets and TCP connection establishment. One subtle difference between a \nTCP socket and a UDP socket is that a TCP socket is identified by a four-tuple: \n(source IP address, source port number, destination IP address, destination port \nnumber). Thus, when a TCP segment arrives from the network to a host, the host \nuses all four values to direct (demultiplex) the segment to the appropriate socket.  \n3.2  \u2022  MULTIPLEXING AND DEMULTIPLEXING      225\nIn particular, and in contrast with UDP, two arriving TCP segments with differ -\nent source IP addresses or source port numbers will (with the exception of a TCP \nsegment carrying the original connection-establishment request) be directed to two", "doc_id": "2e4a2ce9-c0bc-4828-bf80-cd380c74176e", "embedding": null, "doc_hash": "768073762265290d5a6c191f0fb72879f1abfbf44e65ddf941a1dab75914efbe", "extra_info": null, "node_info": {"start": 651167, "end": 654969}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "9a78bb25-f818-47c1-aeed-738ed7d256f6", "3": "2ff9161d-1468-4a17-aa2a-946f3be5f5e7"}}, "__type__": "1"}, "2ff9161d-1468-4a17-aa2a-946f3be5f5e7": {"__data__": {"text": "have to take a close look at TCP \nsockets and TCP connection establishment. One subtle difference between a \nTCP socket and a UDP socket is that a TCP socket is identified by a four-tuple: \n(source IP address, source port number, destination IP address, destination port \nnumber). Thus, when a TCP segment arrives from the network to a host, the host \nuses all four values to direct (demultiplex) the segment to the appropriate socket.  \n3.2  \u2022  MULTIPLEXING AND DEMULTIPLEXING      225\nIn particular, and in contrast with UDP, two arriving TCP segments with differ -\nent source IP addresses or source port numbers will (with the exception of a TCP \nsegment carrying the original connection-establishment request) be directed to two \ndifferent sockets. To gain further insight, let\u2019s reconsider the TCP client-server pro -\ngramming example in Section 2.7.2 :\n\u2022 The TCP server application has a \u201cwelcoming socket,\u201d that waits for connection-\nestablishment requests from TCP clients (see Figure 2.29)  on port number 12000.\n\u2022 The TCP client creates a socket and sends a connection establishment request \nsegment with the lines:\n clientSocket = socket(AF_INET, SOCK_STREAM)\n  clientSocket.connect((serverName,12000))\n\u2022 A connection-establishment request is nothing more than a TCP segment with \ndestination port number 12000 and a special connection-establishment bit set in \nthe TCP header (discussed in Section 3.5). The segment also includes a source \nport number that was chosen by the client.\n\u2022 When the host operating system of the computer running the server process \nreceives the incoming connection-request segment with destination port 12000, \nit locates the server process that is waiting to accept a connection on port number \n12000. The server process then creates a new socket:\n connectionSocket, addr = serverSocket.accept()Host AClient process\nSocket\nServer B\nsource port:\n19157dest. port:\n46428\nsource port:\n46428dest. port:\n19157\nFigure 3.4  \u2666 The inversion of source and destination port numbers\n226     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\n\u2022 Also, the transport layer at the server notes the following four values in the con -\nnection-request segment: (1) the source port number in the segment, (2) the IP \naddress of the source host, (3) the destination port number in the segment, and \n(4) its own IP address. The newly created connection socket is identified by these \nfour values; all subsequently arriving segments whose source port, source IP \naddress, destination port, and destination IP address match these four values will \nbe demultiplexed to this socket. With the TCP connection now in place, the client \nand server can now send data to each other.\nThe server host may support many simultaneous TCP connection sockets, with \neach socket attached to a process, and with each socket identified by its own four-\ntuple. When a TCP segment arrives at the host, all four fields (source IP address, \nsource port, destination IP address, destination port) are used to direct (demultiplex) \nthe segment to the appropriate socket.\nPORT SCANNING\nWe\u2019ve seen that a server process waits patiently on an open port for contact by a \nremote client. Some ports are reserved for well-known applications (e.g., Web, FTP, \nDNS, and SMTP servers); other ports are used by convention by popular applications \n(e.g., the Microsoft 2000 SQL server listens for requests on UDP port 1434). Thus, \nif we determine that a port is open on a host, we may be able to map that port to a \nspecific application running on the host. This is very useful for system administrators, \nwho are often interested in knowing which network applications are running on the \nhosts in their networks. But attackers, in order to \u201ccase the joint,\u201d also want to know \nwhich ports are open on target hosts. If a host is found to be running an application \nwith a known security flaw", "doc_id": "2ff9161d-1468-4a17-aa2a-946f3be5f5e7", "embedding": null, "doc_hash": "4b5fd59aa12d43a197e6aef1216c62d6bbb248d68079b70003626aacb88e034f", "extra_info": null, "node_info": {"start": 654929, "end": 658785}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "2e4a2ce9-c0bc-4828-bf80-cd380c74176e", "3": "80079f2f-6154-4b32-8825-57ca75e9afde"}}, "__type__": "1"}, "80079f2f-6154-4b32-8825-57ca75e9afde": {"__data__": {"text": "waits patiently on an open port for contact by a \nremote client. Some ports are reserved for well-known applications (e.g., Web, FTP, \nDNS, and SMTP servers); other ports are used by convention by popular applications \n(e.g., the Microsoft 2000 SQL server listens for requests on UDP port 1434). Thus, \nif we determine that a port is open on a host, we may be able to map that port to a \nspecific application running on the host. This is very useful for system administrators, \nwho are often interested in knowing which network applications are running on the \nhosts in their networks. But attackers, in order to \u201ccase the joint,\u201d also want to know \nwhich ports are open on target hosts. If a host is found to be running an application \nwith a known security flaw (e.g., a SQL server listening on port 1434 was subject to \na buffer overflow, allowing a remote user to execute arbitrary code on the vulnerable \nhost, a flaw exploited by the Slammer worm [CERT 2003\u201304]), then that host is ripe \nfor attack.\nDetermining which applications are listening on which ports is a relatively easy \ntask. Indeed there are a number of public domain programs, called port scanners, \nthat do just that. Perhaps the most widely used of these is nmap, freely available at \nhttp://nmap.org and included in most Linux distributions. For TCP, nmap sequentially \nscans ports, looking for ports that are accepting TCP connections. For UDP, nmap \nagain sequentially scans ports, looking for UDP ports that respond to transmitted UDP \nsegments. In both cases, nmap returns a list of open, closed, or unreachable ports. \nA host running nmap can attempt to scan any target host anywhere  in the Internet. \nWe\u2019ll revisit nmap in Section 3.5.6, when we discuss TCP connection management.FOCUS ON SECURITY\n\n3.2  \u2022  MULTIPLEXING AND DEMULTIPLEXING      227\nThe situation is illustrated in Figure 3.5, in which Host C initiates two HTTP \nsessions to server B, and Host A initiates one HTTP session to B. Hosts A and C \nand server B each have their own unique IP address\u2014A, C, and B, respectively. \nHost C assigns two different source port numbers (26145 and 7532) to its two HTTP \nconnections. Because Host A is choosing source port numbers independently of C, \nit might also assign a source port of 26145 to its HTTP connection. But this is not \na problem\u2014server B will still be able to correctly demultiplex the two connections \nhaving the same source port number, since the two connections have different source \nIP addresses.\nWeb Servers and TCP\nBefore closing this discussion, it\u2019s instructive to say a few additional words about \nWeb servers and how they use port numbers. Consider a host running a Web server, \nsuch as an Apache Web server, on port 80. When clients (for example, browsers) \nsend segments to the server, all segments will have destination port 80. In particular, \nboth the initial connection-establishment segments and the segments carrying HTTP source port:\n7532dest. port:\n80\nsource IP:\nCdest. IP:\nBsource port:\n26145dest. port:\n80\nsource IP:\nCdest. IP:\nB\nsource port:\n26145dest. port:\n80\nsource IP:\nAdest. IP:\nBPer-connection\nHTTP\nprocesses\nTransport-\nlayer\ndemultiplexingWeb \nserver BWeb client\nhost C\nWeb client\nhost A\nFigure 3.5  \u2666  Two clients, using the same destination port number (80) to \ncommunicate with the same Web server application\n228     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nrequest messages will have destination port 80. As we have just described, the server \ndistinguishes the segments from the different clients using source IP addresses and \nsource port numbers.\nFigure 3. 5 shows a Web server that spawns a new process for each connec -\ntion. As shown", "doc_id": "80079f2f-6154-4b32-8825-57ca75e9afde", "embedding": null, "doc_hash": "f477f6014ec6c2cdf75f0f1c5c047791c022c0038b863ea1f8abf6170b8cf135", "extra_info": null, "node_info": {"start": 658765, "end": 662430}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "2ff9161d-1468-4a17-aa2a-946f3be5f5e7", "3": "496d8c72-6361-4d6b-b821-5a893a485128"}}, "__type__": "1"}, "496d8c72-6361-4d6b-b821-5a893a485128": {"__data__": {"text": "port:\n80\nsource IP:\nCdest. IP:\nB\nsource port:\n26145dest. port:\n80\nsource IP:\nAdest. IP:\nBPer-connection\nHTTP\nprocesses\nTransport-\nlayer\ndemultiplexingWeb \nserver BWeb client\nhost C\nWeb client\nhost A\nFigure 3.5  \u2666  Two clients, using the same destination port number (80) to \ncommunicate with the same Web server application\n228     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nrequest messages will have destination port 80. As we have just described, the server \ndistinguishes the segments from the different clients using source IP addresses and \nsource port numbers.\nFigure 3. 5 shows a Web server that spawns a new process for each connec -\ntion. As shown in Figure 3.5, each of these processes has its own connection socket \nthrough which HTTP requests arrive and HTTP responses are sent. We mention, \nhowever, that there is not always a one-to-one correspondence between connection \nsockets and processes. In fact, today\u2019s high-performing Web servers often use only \none process, and create a new thread with a new connection socket for each new \nclient connection. (A thread can be viewed as a lightweight subprocess.) If you did \nthe first programming assignment in Chapter 2, you built a Web server that does just \nthis. For such a server, at any given time there may be many connection sockets (with \ndifferent identifiers) attached to the same process.\nIf the client and server are using persistent HTTP, then throughout the duration \nof the persistent connection the client and server exchange HTTP messages via the \nsame server socket. However, if the client and server use non-persistent HTTP, then \na new TCP connection is created and closed for every request/response, and hence \na new socket is created and later closed for every request/response. This frequent \ncreating and closing of sockets can severely impact the performance of a busy Web \nserver (although a number of operating system tricks can be used to mitigate the \nproblem). Readers interested in the operating system issues surrounding persistent \nand non-persistent HTTP are encouraged to see [Nielsen 1997; Nahum 2002].\nNow that we\u2019ve discussed transport-layer multiplexing and demultiplexing, let\u2019s \nmove on and discuss one of the Internet\u2019s transport protocols, UDP. In the next sec -\ntion we\u2019ll see that UDP adds little more to the network-layer protocol than a multi -\nplexing/demultiplexing service.\n3.3 Connectionless Transport: UDP\nIn this section, we\u2019ll take a close look at UDP, how it works, and what it does. \nWe encourage you to refer back to Section 2.1, which includes an overview of the \nUDP service model, and to Section 2.7.1 , which discusses socket programming using \nUDP.\nTo motivate our discussion about UDP, suppose you were interested in design -\ning a no-frills, bare-bones transport protocol. How might you go about doing this? \nYou might first consider using a vacuous transport protocol. In particular, on the \nsending side, you might consider taking the messages from the application process \nand passing them directly to the network layer; and on the receiving side, you might \nconsider taking the messages arriving from the network layer and passing them \ndirectly to the application process. But as we learned in the previous section, we have \n3.3  \u2022  CONNECTIONLESS TRANSPORT: UDP      229\nto do a little more than nothing! At the very least, the transport layer has to provide a \nmultiplexing/demultiplexing service in order to pass data between the network layer \nand the correct application-level process.\nUDP, defined in [RFC 768], does just about as little as a transport protocol can do. \nAside from the multiplexing/demultiplexing function and some light error checking, it \nadds nothing to IP. In fact, if the application developer chooses UDP instead of TCP, \nthen the application is almost directly talking with IP. UDP takes messages from the \napplication", "doc_id": "496d8c72-6361-4d6b-b821-5a893a485128", "embedding": null, "doc_hash": "af42fcbdfc8a1d7cdee2c50e221973299685bc9a19d659a7a42f20b7d642ecbb", "extra_info": null, "node_info": {"start": 662502, "end": 666371}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "80079f2f-6154-4b32-8825-57ca75e9afde", "3": "6d9d513a-b2dd-4a2f-94de-3c8fc13fc6ee"}}, "__type__": "1"}, "6d9d513a-b2dd-4a2f-94de-3c8fc13fc6ee": {"__data__": {"text": "arriving from the network layer and passing them \ndirectly to the application process. But as we learned in the previous section, we have \n3.3  \u2022  CONNECTIONLESS TRANSPORT: UDP      229\nto do a little more than nothing! At the very least, the transport layer has to provide a \nmultiplexing/demultiplexing service in order to pass data between the network layer \nand the correct application-level process.\nUDP, defined in [RFC 768], does just about as little as a transport protocol can do. \nAside from the multiplexing/demultiplexing function and some light error checking, it \nadds nothing to IP. In fact, if the application developer chooses UDP instead of TCP, \nthen the application is almost directly talking with IP. UDP takes messages from the \napplication process, attaches source and destination port number fields for the multi -\nplexing/demultiplexing service, adds two other small fields, and passes the resulting \nsegment to the network layer. The network layer encapsulates the transport-layer seg -\nment into an IP datagram and then makes a best-effort attempt to deliver the segment \nto the receiving host. If the segment arrives at the receiving host, UDP uses the destina -\ntion port number to deliver the segment\u2019s data to the correct application process. Note \nthat with UDP there is no handshaking between sending and receiving transport-layer \nentities before sending a segment. For this reason, UDP is said to be connectionless.\nDNS is an example of an application-layer protocol that typically uses UDP. \nWhen the DNS application in a host wants to make a query, it constructs a DNS query \nmessage and passes the message to UDP. Without performing any handshaking with \nthe UDP entity running on the destination end system, the host-side UDP adds header \nfields to the message and passes the resulting segment to the network layer. The net -\nwork layer encapsulates the UDP segment into a datagram and sends the datagram to \na name server. The DNS application at the querying host then waits for a reply to its \nquery. If it doesn\u2019t receive a reply (possibly because the underlying network lost the \nquery or the reply), it might try resending the query, try sending the query to another \nname server, or inform the invoking application that it can\u2019t get a reply.\nNow you might be wondering why an application developer would ever choose \nto build an application over UDP rather than over TCP. Isn\u2019t TCP always preferable, \nsince TCP provides a reliable data transfer service, while UDP does not? The answer \nis no, as some applications are better suited for UDP for the following reasons:\n\u2022 Finer application-level control over what data is sent, and when.  Under UDP, as \nsoon as an application process passes data to UDP, UDP will package the data \ninside a UDP segment and immediately pass the segment to the network layer. \nTCP, on the other hand, has a congestion-control mechanism that throttles the \ntransport-layer TCP sender when one or more links between the source and des -\ntination hosts become excessively congested. TCP will also continue to resend a \nsegment until the receipt of the segment has been acknowledged by the destina -\ntion, regardless of how long reliable delivery takes. Since real-time applications \noften require a minimum sending rate, do not want to overly delay segment trans -\nmission, and can tolerate some data loss, TCP\u2019s service model is not particularly \nwell matched to these applications\u2019 needs. As discussed below, these applications \ncan use UDP and implement, as part of the application, any additional functional -\nity that is needed beyond UDP\u2019s no-frills segment-delivery service.\n230     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\n\u2022 No connection establishment.  As we\u2019ll discuss later, TCP uses a three-way hand -\nshake before it starts to transfer data. UDP just blasts away without any formal", "doc_id": "6d9d513a-b2dd-4a2f-94de-3c8fc13fc6ee", "embedding": null, "doc_hash": "1916e79d1c06c5fd6a3c55244d794257b0c51c5fdd218c248aae0bc9227d8d7c", "extra_info": null, "node_info": {"start": 666293, "end": 670152}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "496d8c72-6361-4d6b-b821-5a893a485128", "3": "0893545c-063f-43d2-9b81-c551f4c97047"}}, "__type__": "1"}, "0893545c-063f-43d2-9b81-c551f4c97047": {"__data__": {"text": "destina -\ntion, regardless of how long reliable delivery takes. Since real-time applications \noften require a minimum sending rate, do not want to overly delay segment trans -\nmission, and can tolerate some data loss, TCP\u2019s service model is not particularly \nwell matched to these applications\u2019 needs. As discussed below, these applications \ncan use UDP and implement, as part of the application, any additional functional -\nity that is needed beyond UDP\u2019s no-frills segment-delivery service.\n230     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\n\u2022 No connection establishment.  As we\u2019ll discuss later, TCP uses a three-way hand -\nshake before it starts to transfer data. UDP just blasts away without any formal \npreliminaries. Thus UDP does not introduce any delay to establish a connection. \nThis is probably the principal reason why DNS runs over UDP rather than TCP\u2014\nDNS would be much slower if it ran over TCP. HTTP uses TCP rather than UDP, \nsince reliability is critical for Web pages with text. But, as we briefly discussed \nin Section 2.2 , the TCP connection-establishment delay in HTTP is an important \ncontributor to the delays associated with downloading Web documents. Indeed, \nthe QUIC protocol (Quick UDP Internet Connection, [Iyengar 2015]), used in \nGoogle\u2019s Chrome browser, uses UDP as its underlying transport protocol and \nimplements reliability in an application-layer protocol on top of UDP.\n\u2022 No connection state.  TCP maintains connection state in the end systems. This \nconnection state includes receive and send buffers, congestion-control param -\neters, and sequence and acknowledgment number parameters. We will see in  \nSection 3. 5 that this state information is needed to implement TCP\u2019s reliable data \ntransfer service and to provide congestion control. UDP, on the other hand, does \nnot maintain connection state and does not track any of these parameters. For this \nreason, a server devoted to a particular application can typically support many \nmore active clients when the application runs over UDP rather than TCP.\n\u2022 Small packet header overhead.  The TCP segment has 20 bytes of header over -\nhead in every segment, whereas UDP has only 8 bytes of overhead.\nFigure 3. 6 lists popular Internet applications and the transport protocols that \nthey use. As we expect, e-mail, remote terminal access, the Web, and file transfer \nrun over TCP\u2014all these applications need the reliable data transfer service of TCP.  \nNevertheless, many important applications run over UDP rather than TCP. For example, \nUDP is used to carry network management (SNMP; see Section 5.7) data. UDP is \npreferred to TCP in this case, since network management applications must often \nrun when the network is in a stressed state\u2014precisely when reliable, congestion-\ncontrolled data transfer is difficult to achieve. Also, as we mentioned earlier, DNS \nruns over UDP, thereby avoiding TCP\u2019s connection-establishment delays.\nAs shown in Figure 3.6, both UDP and TCP are somtimes used today with multi -\nmedia applications, such as Internet phone, real-time video conferencing, and stream -\ning of stored audio and video. We\u2019ll take a close look at these applications in Chapter 9 .  \nWe just mention now that all of these applications can tolerate a small amount of \npacket loss, so that reliable data transfer is not absolutely critical for the application\u2019s \nsuccess. Furthermore, real-time applications, like Internet phone and video confer -\nencing, react very poorly to TCP\u2019s congestion control. For these reasons, developers \nof multimedia applications may choose to run their applications over UDP instead \nof TCP. When packet loss rates are low, and with some organizations blocking UDP \ntraffic for security reasons (see Chapter 8 ), TCP becomes an increasingly attractive \nprotocol for streaming media transport.\n3.3  \u2022  CONNECTIONLESS TRANSPORT: UDP  ", "doc_id": "0893545c-063f-43d2-9b81-c551f4c97047", "embedding": null, "doc_hash": "d5e2508af8ffbacbff1dab341719c0689859c18a4661245f590adb57a7ef7c59", "extra_info": null, "node_info": {"start": 670201, "end": 674058}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "6d9d513a-b2dd-4a2f-94de-3c8fc13fc6ee", "3": "3448093c-6327-4996-99d6-102b01aa28c1"}}, "__type__": "1"}, "3448093c-6327-4996-99d6-102b01aa28c1": {"__data__": {"text": "and video. We\u2019ll take a close look at these applications in Chapter 9 .  \nWe just mention now that all of these applications can tolerate a small amount of \npacket loss, so that reliable data transfer is not absolutely critical for the application\u2019s \nsuccess. Furthermore, real-time applications, like Internet phone and video confer -\nencing, react very poorly to TCP\u2019s congestion control. For these reasons, developers \nof multimedia applications may choose to run their applications over UDP instead \nof TCP. When packet loss rates are low, and with some organizations blocking UDP \ntraffic for security reasons (see Chapter 8 ), TCP becomes an increasingly attractive \nprotocol for streaming media transport.\n3.3  \u2022  CONNECTIONLESS TRANSPORT: UDP      231\nAlthough commonly done today, running multimedia applications over UDP is \ncontroversial. As we mentioned above, UDP has no congestion control. But conges -\ntion control is needed to prevent the network from entering a congested state in which \nvery little useful work is done. If everyone were to start streaming high-bit-rate video \nwithout using any congestion control, there would be so much packet overflow at \nrouters that very few UDP packets would successfully traverse the source-to-desti -\nnation path. Moreover, the high loss rates induced by the uncontrolled UDP senders \nwould cause the TCP senders (which, as we\u2019ll see, do decrease their sending rates in \nthe face of congestion) to dramatically decrease their rates. Thus, the lack of conges -\ntion control in UDP can result in high loss rates between a UDP sender and receiver, \nand the crowding out of TCP sessions\u2014a potentially serious problem [Floyd 1999]. \nMany researchers have proposed new mechanisms to force all sources, including \nUDP sources, to perform adaptive congestion control [Mahdavi 1997; Floyd 2000; \nKohler 2006: RFC 4340].\nBefore discussing the UDP segment structure, we mention that it is possible for \nan application to have reliable data transfer when using UDP. This can be done if \nreliability is built into the application itself (for example, by adding acknowledgment \nand retransmission mechanisms, such as those we\u2019ll study in the next section). We \nmentioned earlier that the QUIC protocol [Iyengar 2015] used in Google\u2019s Chrome \nbrowser implements reliability in an application-layer protocol on top of UDP. But \nthis is a nontrivial task that would keep an application developer busy debugging for \na long time. Nevertheless, building reliability directly into the application allows the Electronic mail\nRemote terminal access\nWeb\nFile transfer\nRemote \ufb01le server\nStreaming multimedia\nInternet telephony\nNetwork management\nName translationSMTP\nTelnet\nHTTP\nFTP\nNFS\ntypically proprietary\ntypically proprietary\nSNMP\nDNSTCP\nTCP\nTCP\nTCP\nTypically UDP\nUDP or TCP\nUDP or TCP\nTypically UDP\nTypically UDPApplicationApplication-Layer\nProtocolUnderlying Transport\nProtocol\nFigure 3.6  \u2666  Popular Internet applications and their underlying transport  \nprotocols\n232     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\napplication to \u201chave its cake and eat it too. That is, application processes can commu -\nnicate reliably without being subjected to the transmission-rate constraints imposed \nby TCP\u2019s congestion-control mechanism.\n3.3.1  UDP Segment Structure\nThe UDP segment structure, shown in Figure 3.7, is defined in RFC 768. The applica -\ntion data occupies the data field of the UDP segment. For example, for DNS, the data \nfield contains either a query message or a response message. For a streaming audio \napplication, audio samples fill the data field. The UDP header has only four fields, \neach consisting of two bytes. As discussed in the previous section, the port numbers \nallow the destination host to pass the application data to the correct process", "doc_id": "3448093c-6327-4996-99d6-102b01aa28c1", "embedding": null, "doc_hash": "dbbe72664d669df6d6e99ebc2591bf53ba45caf86439ecbd2b44206140d6a24a", "extra_info": null, "node_info": {"start": 674014, "end": 677811}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "0893545c-063f-43d2-9b81-c551f4c97047", "3": "476e328e-dca9-4eae-92a6-624af44f730b"}}, "__type__": "1"}, "476e328e-dca9-4eae-92a6-624af44f730b": {"__data__": {"text": "LAYER\napplication to \u201chave its cake and eat it too. That is, application processes can commu -\nnicate reliably without being subjected to the transmission-rate constraints imposed \nby TCP\u2019s congestion-control mechanism.\n3.3.1  UDP Segment Structure\nThe UDP segment structure, shown in Figure 3.7, is defined in RFC 768. The applica -\ntion data occupies the data field of the UDP segment. For example, for DNS, the data \nfield contains either a query message or a response message. For a streaming audio \napplication, audio samples fill the data field. The UDP header has only four fields, \neach consisting of two bytes. As discussed in the previous section, the port numbers \nallow the destination host to pass the application data to the correct process run -\nning on the destination end system (that is, to perform the demultiplexing function).  \nThe length field specifies the number of bytes in the UDP segment (header plus \ndata). An explicit length value is needed since the size of the data field may differ \nfrom one UDP segment to the next. The checksum is used by the receiving host to \ncheck whether errors have been introduced into the segment. In truth, the check -\nsum is also calculated over a few of the fields in the IP header in addition to the \nUDP segment. But we ignore this detail in order to see the forest through the trees. \nWe\u2019ll discuss the checksum calculation below. Basic principles of error detection are \ndescribed in Section 6.2 . The length field specifies the length of the UDP segment, \nincluding the header, in bytes.\n3.3.2  UDP Checksum\nThe UDP checksum provides for error detection. That is, the checksum is used to \ndetermine whether bits within the UDP segment have been altered (for example, by \nnoise in the links or while stored in a router) as it moved from source to destination. \nSource port #32 bits\nDest. port #\nLength Checksum\nApplication\ndata\n(message)\nFigure 3.7  \u2666 UDP segment structure\n3.3  \u2022  CONNECTIONLESS TRANSPORT: UDP      233\nUDP at the sender side performs the 1s complement of the sum of all the 16-bit \nwords in the segment, with any overflow encountered during the sum being wrapped \naround. This result is put in the checksum field of the UDP segment. Here we give \na simple example of the checksum calculation. You can find details about efficient \nimplementation of the calculation in RFC 1071 and performance over real data in \n[Stone 1998; Stone 2000]. As an example, suppose that we have the following three \n16-bit words:\n0110011001100000\n0101010101010101\n1000111100001100\nThe sum of first two of these 16-bit words is\n0110011001100000\n0101010101010101\n1011101110110101\nAdding the third word to the above sum gives\n1011101110110101\n1000111100001100\n0100101011000010\nNote that this last addition had overflow, which was wrapped around. The 1s \ncomplement is obtained by converting all the 0s to 1s and converting all the 1s to \n0s. Thus the 1s complement of the sum 0100101011000010 is 1011010100111101, \nwhich becomes the checksum. At the receiver, all four 16-bit words are added, \nincluding the checksum. If no errors are introduced into the packet, then clearly the \nsum at the receiver will be 1111111111111111. If one of the bits is a 0, then we know \nthat errors have been introduced into the packet.\nYou may wonder why UDP provides a checksum in the first place, as many \nlink-layer protocols (including the popular Ethernet protocol) also provide error \nchecking. The reason is that there is no guarantee that all the links between source \nand destination provide error checking; that is, one of the links may use a link-layer \nprotocol that does not provide error checking. Furthermore, even if segments are \ncorrectly transferred across a link, it\u2019s", "doc_id": "476e328e-dca9-4eae-92a6-624af44f730b", "embedding": null, "doc_hash": "0adf95b53af2e22f5e5656aa94ff285816f7d696d6a9d6c8a43e80d1df0e9fe3", "extra_info": null, "node_info": {"start": 677810, "end": 681541}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "3448093c-6327-4996-99d6-102b01aa28c1", "3": "541192f5-0388-428e-926d-c25ee09034a0"}}, "__type__": "1"}, "541192f5-0388-428e-926d-c25ee09034a0": {"__data__": {"text": "1011010100111101, \nwhich becomes the checksum. At the receiver, all four 16-bit words are added, \nincluding the checksum. If no errors are introduced into the packet, then clearly the \nsum at the receiver will be 1111111111111111. If one of the bits is a 0, then we know \nthat errors have been introduced into the packet.\nYou may wonder why UDP provides a checksum in the first place, as many \nlink-layer protocols (including the popular Ethernet protocol) also provide error \nchecking. The reason is that there is no guarantee that all the links between source \nand destination provide error checking; that is, one of the links may use a link-layer \nprotocol that does not provide error checking. Furthermore, even if segments are \ncorrectly transferred across a link, it\u2019s possible that bit errors could be introduced \nwhen a segment is stored in a router\u2019s memory. Given that neither link-by-link reli -\nability nor in-memory error detection is guaranteed, UDP must provide error detec -\ntion at the transport layer, on an end-end basis , if the end-end data transfer service \nis to provide error detection. This is an example of the celebrated end-end principle  \nin system design [Saltzer 1984], which states that since certain functionality (error \ndetection, in this case) must be implemented on an end-end basis: \u201cfunctions placed \n234     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nat the lower levels may be redundant or of little value when compared to the cost of \nproviding them at the higher level.\u201d\nBecause IP is supposed to run over just about any layer-2 protocol, it is useful \nfor the transport layer to provide error checking as a safety measure. Although UDP \nprovides error checking, it does not do anything to recover from an error. Some \nimplementations of UDP simply discard the damaged segment; others pass the dam -\naged segment to the application with a warning.\nThat wraps up our discussion of UDP. We will soon see that TCP offers reli -\nable data transfer to its applications as well as other services that UDP doesn\u2019t offer. \nNaturally, TCP is also more complex than UDP. Before discussing TCP, however, \nit will be useful to step back and first discuss the underlying principles of reliable \ndata transfer.\n3.4 Principles of Reliable Data Transfer\nIn this section, we consider the problem of reliable data transfer in a general context. \nThis is appropriate since the problem of implementing reliable data transfer occurs \nnot only at the transport layer, but also at the link layer and the application layer as \nwell. The general problem is thus of central importance to networking. Indeed, if one \nhad to identify a \u201ctop-ten\u201d list of fundamentally important problems in all of net -\nworking, this would be a candidate to lead the list. In the next section we\u2019ll examine \nTCP and show, in particular, that TCP exploits many of the principles that we are \nabout to describe.\nFigure 3. 8 illustrates the framework for our study of reliable data transfer. The \nservice abstraction provided to the upper-layer entities is that of a reliable channel \nthrough which data can be transferred. With a reliable channel, no transferred data \nbits are corrupted (flipped from 0 to 1, or vice versa) or lost, and all are delivered in \nthe order in which they were sent. This is precisely the service model offered by TCP \nto the Internet applications that invoke it.\nIt is the responsibility of a reliable data transfer protocol  to implement this \nservice abstraction. This task is made difficult by the fact that the layer below  the \nreliable data transfer protocol may be unreliable. For example, TCP is a reliable data \ntransfer protocol that is implemented on top of an unreliable (IP) end-to-end network \nlayer. More generally, the layer beneath the two reliably communicating end points \nmight consist of a single physical link (as in the case of a link-level data transfer \nprotocol) or a global", "doc_id": "541192f5-0388-428e-926d-c25ee09034a0", "embedding": null, "doc_hash": "e227e5ef28e210110d98652038e9ec6a5e8d232d25add2c562376f64d2cfeef8", "extra_info": null, "node_info": {"start": 681529, "end": 685444}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "476e328e-dca9-4eae-92a6-624af44f730b", "3": "be45e8f7-287f-4624-8693-1b8eb6dfe9ec"}}, "__type__": "1"}, "be45e8f7-287f-4624-8693-1b8eb6dfe9ec": {"__data__": {"text": "no transferred data \nbits are corrupted (flipped from 0 to 1, or vice versa) or lost, and all are delivered in \nthe order in which they were sent. This is precisely the service model offered by TCP \nto the Internet applications that invoke it.\nIt is the responsibility of a reliable data transfer protocol  to implement this \nservice abstraction. This task is made difficult by the fact that the layer below  the \nreliable data transfer protocol may be unreliable. For example, TCP is a reliable data \ntransfer protocol that is implemented on top of an unreliable (IP) end-to-end network \nlayer. More generally, the layer beneath the two reliably communicating end points \nmight consist of a single physical link (as in the case of a link-level data transfer \nprotocol) or a global internetwork (as in the case of a transport-level protocol). For \nour purposes, however, we can view this lower layer simply as an unreliable point-\nto-point channel.\nIn this section, we will incrementally develop the sender and receiver sides of \na reliable data transfer protocol, considering increasingly complex models of the \nunderlying channel. For example, we\u2019ll consider what protocol mechanisms are \n3.4  \u2022  PRINCIPLES OF RELIABLE DATA TRANSFER      235\nneeded when the underlying channel can corrupt bits or lose entire packets. One \nassumption we\u2019ll adopt throughout our discussion here is that packets will be deliv -\nered in the order in which they were sent, with some packets possibly being lost; \nthat is, the underlying channel will not reorder packets. Figure 3.8(b) illustrates the \ninterfaces for our data transfer protocol. The sending side of the data transfer proto -\ncol will be invoked from above by a call to rdt_send() . It will pass the data to be \ndelivered to the upper layer at the receiving side. (Here rdt stands for reliable data \ntransfer  protocol and _send  indicates that the sending side of rdt is being called. \nThe first step in developing any protocol is to choose a good name!) On the receiving \nside, rdt_rcv()  will be called when a packet arrives from the receiving side of the \nchannel. When the rdt protocol wants to deliver data to the upper layer, it will do \nso by calling deliver_data() . In the following we use the terminology \u201cpacket\u201d \nrather than transport-layer \u201csegment.\u201d Because the theory developed in this section Reliable channel\nUnreliable channelrdt_send()\nudt_send()Sending\nprocessReceiver\nprocess\ndeliver_dataApplication\nlayer\nTransport\nlayer\na. Provided serviceNetwork\nlayer\nKey:\nData Packetb. Service implementationReliable data\ntransfer pr otocol\n(sending side)Reliable data\ntransfer pr otocol\n(receiving side)\nrdt_rcv()\nFigure 3.8  \u2666  Reliable data transfer: Service model and service  \nimplementation\n236     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\napplies to computer networks in general and not just to the Internet transport layer, \nthe generic term \u201cpacket\u201d is perhaps more appropriate here.\nIn this section we consider only the case of unidirectional data transfer , that is, \ndata transfer from the sending to the receiving side. The case of reliable bidirectional  \n(that is, full-duplex) data transfer  is conceptually no more difficult but considerably \nmore tedious to explain. Although we consider only unidirectional data transfer, it is \nimportant to note that the sending and receiving sides of our protocol will nonetheless \nneed to transmit packets in both directions, as indicated in Figure 3.8. We will see \nshortly that, in addition to exchanging packets containing the data to be transferred, \nthe sending and receiving sides of rdt will also need to exchange control packets \nback and forth. Both the send and receive sides of rdt send packets to the other side \nby a call to udt_send()  (where udt stands for", "doc_id": "be45e8f7-287f-4624-8693-1b8eb6dfe9ec", "embedding": null, "doc_hash": "e1b6113115b24bd2445045bfddf3ea4e6175b44a531d82a50cb42323b6965fbb", "extra_info": null, "node_info": {"start": 685445, "end": 689221}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "541192f5-0388-428e-926d-c25ee09034a0", "3": "562ccd3b-795d-4cab-9f30-efae14def32f"}}, "__type__": "1"}, "562ccd3b-795d-4cab-9f30-efae14def32f": {"__data__": {"text": ", that is, \ndata transfer from the sending to the receiving side. The case of reliable bidirectional  \n(that is, full-duplex) data transfer  is conceptually no more difficult but considerably \nmore tedious to explain. Although we consider only unidirectional data transfer, it is \nimportant to note that the sending and receiving sides of our protocol will nonetheless \nneed to transmit packets in both directions, as indicated in Figure 3.8. We will see \nshortly that, in addition to exchanging packets containing the data to be transferred, \nthe sending and receiving sides of rdt will also need to exchange control packets \nback and forth. Both the send and receive sides of rdt send packets to the other side \nby a call to udt_send()  (where udt stands for unreliable data transfer ).\n3.4.1  Building a Reliable Data Transfer Protocol\nWe now step through a series of protocols, each one becoming more complex, arriv -\ning at a flawless, reliable data transfer protocol.\nReliable Data Transfer over a Perfectly Reliable Channel: rdt1.0\nWe first consider the simplest case, in which the underlying channel is completely \nreliable. The protocol itself, which we\u2019ll call rdt1.0 , is trivial. The finite-state \nmachine (FSM)  definitions for the rdt1.0  sender and receiver are shown in \nFigure 3. 9. The FSM in Figure 3.9(a) defines the operation of the sender, while \nthe FSM in Figure 3.9(b) defines the operation of the receiver. It is important to \nnote that there are separate  FSMs for the sender and for the receiver. The sender \nand receiver FSMs in Figure 3.9 each have just one state. The arrows in the FSM \ndescription indicate the transition of the protocol from one state to another. (Since \neach FSM in Figure 3.9 has just one state, a transition is necessarily from the one \nstate back to itself; we\u2019ll see more complicated state diagrams shortly.) The event \ncausing the transition is shown above the horizontal line labeling the transition, and \nthe actions taken when the event occurs are shown below the horizontal line. When \nno action is taken on an event, or no event occurs and an action is taken, we\u2019ll use \nthe symbol \u039b below or above the horizontal, respectively, to explicitly denote the \nlack of an action or event. The initial state of the FSM is indicated by the dashed \narrow. Although the FSMs in Figure 3.9 have but one state, the FSMs we will see \nshortly have multiple states, so it will be important to identify the initial state of \neach FSM.\nThe sending side of rdt simply accepts data from the upper layer via the \nrdt_send(data)  event, creates a packet containing the data (via the action \nmake_pkt(data) ) and sends the packet into the channel. In practice, the  \nrdt_send(data)  event would result from a procedure call (for example, to \nrdt_send() ) by the upper-layer application.\n3.4  \u2022  PRINCIPLES OF RELIABLE DATA TRANSFER      237\nOn the receiving side, rdt receives a packet from the underlying channel via \nthe rdt_rcv(packet)  event, removes the data from the packet (via the action \nextract (packet, data) ) and passes the data up to the upper layer (via \nthe action deliver_data(data) ). In practice, the rdt_rcv(packet)  event \nwould result from a procedure call (for example, to rdt_rcv() ) from the lower-\nlayer protocol.\nIn this simple protocol, there is no difference between a unit of data and a packet. \nAlso, all packet flow is from the sender to receiver; with a perfectly reliable chan -\nnel there is no need for the receiver side to provide any feedback to the sender since \nnothing can go wrong! Note that we have also assumed that the receiver is able to \nreceive data as fast as", "doc_id": "562ccd3b-795d-4cab-9f30-efae14def32f", "embedding": null, "doc_hash": "9f5bf2d9281dd1ffcb0e258437120097fff70ef202808c5f2dd3f76632cfc33a", "extra_info": null, "node_info": {"start": 689238, "end": 692884}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "be45e8f7-287f-4624-8693-1b8eb6dfe9ec", "3": "2a7cddfa-560e-45e9-bd12-c2aa0a9e37e5"}}, "__type__": "1"}, "2a7cddfa-560e-45e9-bd12-c2aa0a9e37e5": {"__data__": {"text": "via \nthe rdt_rcv(packet)  event, removes the data from the packet (via the action \nextract (packet, data) ) and passes the data up to the upper layer (via \nthe action deliver_data(data) ). In practice, the rdt_rcv(packet)  event \nwould result from a procedure call (for example, to rdt_rcv() ) from the lower-\nlayer protocol.\nIn this simple protocol, there is no difference between a unit of data and a packet. \nAlso, all packet flow is from the sender to receiver; with a perfectly reliable chan -\nnel there is no need for the receiver side to provide any feedback to the sender since \nnothing can go wrong! Note that we have also assumed that the receiver is able to \nreceive data as fast as the sender happens to send data. Thus, there is no need for the \nreceiver to ask the sender to slow down!\nReliable Data Transfer over a Channel with Bit Errors: rdt2.0\nA more realistic model of the underlying channel is one in which bits in a packet may \nbe corrupted. Such bit errors typically occur in the physical components of a network \nas a packet is transmitted, propagates, or is buffered. We\u2019ll continue to assume for \nthe moment that all transmitted packets are received (although their bits may be cor -\nrupted) in the order in which they were sent.\nBefore developing a protocol for reliably communicating over such a channel, \nfirst consider how people might deal with such a situation. Consider how you yourself Wait for\ncall from\nabove\na.  rdt1.0: sending siderdt_send(data)\npacket=make_pkt(data)\nudt_send(packet)\nWait for\ncall from\nbelow\nb.  rdt1.0: receiving siderdt_rcv(packet)\nextract(packet,data)\ndeliver_data(data)\nFigure 3.9  \u2666 rdt1.0  \u2013 A protocol for a completely reliable channel\n238     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nmight dictate a long message over the phone. In a typical scenario, the message taker \nmight say \u201cOK\u201d after each sentence has been heard, understood, and recorded. If the \nmessage taker hears a garbled sentence, you\u2019re asked to repeat the garbled sentence. \nThis message-dictation protocol uses both positive acknowledgments  (\u201cOK\u201d) and \nnegative acknowledgments  (\u201cPlease repeat that.\u201d). These control messages allow \nthe receiver to let the sender know what has been received correctly, and what has \nbeen received in error and thus requires repeating. In a computer network setting, \nreliable data transfer protocols based on such retransmission are known as ARQ \n(Automatic Repeat reQuest) protocols .\nFundamentally, three additional protocol capabilities are required in ARQ pro -\ntocols to handle the presence of bit errors:\n\u2022 Error detection.  First, a mechanism is needed to allow the receiver to detect when \nbit errors have occurred. Recall from the previous section that UDP uses the Inter -\nnet checksum field for exactly this purpose. In Chapter 6 we\u2019ll examine error-\ndetection and -correction techniques in greater detail; these techniques allow the \nreceiver to detect and possibly correct packet bit errors. For now, we need only \nknow that these techniques require that extra bits (beyond the bits of original data \nto be transferred) be sent from the sender to the receiver; these bits will be gath -\nered into the packet checksum field of the rdt2.0  data packet.\n\u2022 Receiver feedback.  Since the sender and receiver are typically executing on dif -\nferent end systems, possibly separated by thousands of miles, the only way for \nthe sender to learn of the receiver\u2019s view of the world (in this case, whether or not \na packet was received correctly) is for the receiver to provide explicit feedback \nto the sender. The positive (ACK) and negative (NAK) acknowledgment replies \nin", "doc_id": "2a7cddfa-560e-45e9-bd12-c2aa0a9e37e5", "embedding": null, "doc_hash": "50259f4e960197bbef6480fa2253606bd93ddd29b81c02ce806220713c8b44dd", "extra_info": null, "node_info": {"start": 692946, "end": 696583}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "562ccd3b-795d-4cab-9f30-efae14def32f", "3": "4e4e7696-72a8-4b35-9358-1343f0b1c2ed"}}, "__type__": "1"}, "4e4e7696-72a8-4b35-9358-1343f0b1c2ed": {"__data__": {"text": "allow the \nreceiver to detect and possibly correct packet bit errors. For now, we need only \nknow that these techniques require that extra bits (beyond the bits of original data \nto be transferred) be sent from the sender to the receiver; these bits will be gath -\nered into the packet checksum field of the rdt2.0  data packet.\n\u2022 Receiver feedback.  Since the sender and receiver are typically executing on dif -\nferent end systems, possibly separated by thousands of miles, the only way for \nthe sender to learn of the receiver\u2019s view of the world (in this case, whether or not \na packet was received correctly) is for the receiver to provide explicit feedback \nto the sender. The positive (ACK) and negative (NAK) acknowledgment replies \nin the message-dictation scenario are examples of such feedback. Our rdt2.0  \nprotocol will similarly send ACK and NAK packets back from the receiver to \nthe sender. In principle, these packets need only be one bit long; for example, a 0 \nvalue could indicate a NAK and a value of 1 could indicate an ACK.\n\u2022 Retransmission.  A packet that is received in error at the receiver will be retrans -\nmitted by the sender.\nFigure 3. 10 shows the FSM representation of rdt2.0 , a data transfer \nprotocol employing error detection, positive acknowledgments, and negative \nacknowledgments.\nThe send side of rdt2.0  has two states. In the leftmost state, the send-side \nprotocol is waiting for data to be passed down from the upper layer. When the \nrdt_send(data)  event occurs, the sender will create a packet ( sndpkt ) con -\ntaining the data to be sent, along with a packet checksum (for example, as discussed \nin Section 3.3.2 for the case of a UDP segment), and then send the packet via the \nudt_send(sndpkt)  operation. In the rightmost state, the sender protocol is wait -\ning for an ACK or a NAK packet from the receiver. If an ACK packet is received \n3.4  \u2022  PRINCIPLES OF RELIABLE DATA TRANSFER      239\n(the notation rdt_rcv(rcvpkt) && isACK (rcvpkt)  in Figure 3.10 cor -\nresponds to this event), the sender knows that the most recently transmitted packet \nhas been received correctly and thus the protocol returns to the state of waiting for \ndata from the upper layer. If a NAK is received, the protocol retransmits the last \npacket and waits for an ACK or NAK to be returned by the receiver in response to \nthe retransmitted data packet. It is important to note that when the sender is in the \nwait-for-ACK-or-NAK state, it cannot  get more data from the upper layer; that is, the \nrdt_send()  event can not occur; that will happen only after the sender receives \nan ACK and leaves this state. Thus, the sender will not send a new piece of data until \nit is sure that the receiver has correctly received the current packet. Because of this \nbehavior, protocols such as rdt2.0  are known as stop-and-wait  protocols.Wait for\ncall from\nabove\na.  rdt2.0: sending side\nb.  rdt2.0: receiving siderdt_rcv(rcvpkt)&&corrupt(rcvpkt)\nsndpkt=make_pkt(NAK)\nudt_send(sndpkt)rdt_rcv(rcvpkt)&&", "doc_id": "4e4e7696-72a8-4b35-9358-1343f0b1c2ed", "embedding": null, "doc_hash": "00b6c7ecaaf0fef1a9b5c981cc7a95ba1b67172477c534992014462a5f080a35", "extra_info": null, "node_info": {"start": 696539, "end": 699562}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "2a7cddfa-560e-45e9-bd12-c2aa0a9e37e5", "3": "6c8a07cc-b73a-44fd-ad91-3e9acff195d6"}}, "__type__": "1"}, "6c8a07cc-b73a-44fd-ad91-3e9acff195d6": {"__data__": {"text": "it cannot  get more data from the upper layer; that is, the \nrdt_send()  event can not occur; that will happen only after the sender receives \nan ACK and leaves this state. Thus, the sender will not send a new piece of data until \nit is sure that the receiver has correctly received the current packet. Because of this \nbehavior, protocols such as rdt2.0  are known as stop-and-wait  protocols.Wait for\ncall from\nabove\na.  rdt2.0: sending side\nb.  rdt2.0: receiving siderdt_rcv(rcvpkt)&&corrupt(rcvpkt)\nsndpkt=make_pkt(NAK)\nudt_send(sndpkt)rdt_rcv(rcvpkt)&& isNAK(rcvpkt)\nudt_send(sndpkt)\nrdt_rcv(rcvpkt)&&isACK(rcvpkt)\n/H9011rdt_send(data)\nsndpkt=make_pkt(data,checksum)\nudt_send(sndpkt)\nrdt_rcv(rcvpkt)&&notcorrupt(rcvpkt)\nextract(rcvpkt,data)\ndeliver_data(data)\nsndpkt=make_pkt(ACK)\nudt_send(sndpkt)Wait for\ncall from\nbelowWait for\nACK or\nNAK\nFigure 3.10  \u2666 rdt2.0  \u2013 A protocol for a channel with bit errors\n240     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nThe receiver-side FSM for rdt2.0  still has a single state. On packet arrival, \nthe receiver replies with either an ACK or a NAK, depending on whether or not the \nreceived packet is corrupted. In Figure 3.10, the notation rdt_rcv(rcvpkt) && \ncorrupt(rcvpkt)  corresponds to the event in which a packet is received and is \nfound to be in error.\nProtocol rdt2.0  may look as if it works but, unfortunately, it has a fatal flaw. \nIn particular, we haven\u2019t accounted for the possibility that the ACK or NAK packet \ncould be corrupted! (Before proceeding on, you should think about how this prob -\nlem may be fixed.) Unfortunately, our slight oversight is not as innocuous as it may \nseem. Minimally, we will need to add checksum bits to ACK/NAK packets in order \nto detect such errors. The more difficult question is how the protocol should recover \nfrom errors in ACK or NAK packets. The difficulty here is that if an ACK or NAK \nis corrupted, the sender has no way of knowing whether or not the receiver has cor -\nrectly received the last piece of transmitted data.\nConsider three possibilities for handling corrupted ACKs or NAKs:\n\u2022 For the first possibility, consider what a human might do in the message-dictation \nscenario. If the speaker didn\u2019t understand the \u201cOK\u201d or \u201cPlease repeat that\u201d reply \nfrom the receiver, the speaker would probably ask, \u201cWhat did you say?\u201d (thus \nintroducing a new type of sender-to-receiver packet to our protocol). The receiver \nwould then repeat the reply. But what if the speaker\u2019s \u201cWhat did you say?\u201d is cor -\nrupted? The receiver, having no idea whether the garbled sentence was part of the \ndictation or a request to repeat the last reply, would probably then respond with \n\u201cWhat did you say?\u201d And then, of course, that response might be garbled. Clearly, \nwe\u2019re heading down a difficult path.\n\u2022 A second alternative is to add enough checksum bits to allow the sender not only \nto detect, but also to recover from, bit errors. This solves the immediate problem \nfor a channel that can corrupt packets but not lose them.\n\u2022 A third approach is for the sender simply to resend the current data packet when \nit receives a garbled ACK or NAK packet. This approach,", "doc_id": "6c8a07cc-b73a-44fd-ad91-3e9acff195d6", "embedding": null, "doc_hash": "7e7190c0d147c5fb2579fffe81c4286a9770d6e34c659246778cb7a6330b9eca", "extra_info": null, "node_info": {"start": 699705, "end": 702854}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "4e4e7696-72a8-4b35-9358-1343f0b1c2ed", "3": "c305562a-a177-4a64-b091-b9893b12e7c7"}}, "__type__": "1"}, "c305562a-a177-4a64-b091-b9893b12e7c7": {"__data__": {"text": "then repeat the reply. But what if the speaker\u2019s \u201cWhat did you say?\u201d is cor -\nrupted? The receiver, having no idea whether the garbled sentence was part of the \ndictation or a request to repeat the last reply, would probably then respond with \n\u201cWhat did you say?\u201d And then, of course, that response might be garbled. Clearly, \nwe\u2019re heading down a difficult path.\n\u2022 A second alternative is to add enough checksum bits to allow the sender not only \nto detect, but also to recover from, bit errors. This solves the immediate problem \nfor a channel that can corrupt packets but not lose them.\n\u2022 A third approach is for the sender simply to resend the current data packet when \nit receives a garbled ACK or NAK packet. This approach, however, introduces \nduplicate packets  into the sender-to-receiver channel. The fundamental diffi -\nculty with duplicate packets is that the receiver doesn\u2019t know whether the ACK \nor NAK it last sent was received correctly at the sender. Thus, it cannot know a \npriori  whether an arriving packet contains new data or is a retransmission!\nA simple solution to this new problem (and one adopted in almost all exist -\ning data transfer protocols, including TCP) is to add a new field to the data packet \nand have the sender number its data packets by putting a sequence number  into \nthis field. The receiver then need only check this sequence number to determine \nwhether or not the received packet is a retransmission. For this simple case of a \nstop-and-wait protocol, a 1-bit sequence number will suffice, since it will allow the \nreceiver to know whether the sender is resending the previously transmitted packet \n3.4  \u2022  PRINCIPLES OF RELIABLE DATA TRANSFER      241\n(the sequence number of the received packet has the same sequence number as the \nmost recently received packet) or a new packet (the sequence number changes, mov -\ning \u201cforward\u201d in modulo-2 arithmetic). Since we are currently assuming a channel \nthat does not lose packets, ACK and NAK packets do not themselves need to indicate \nthe sequence number of the packet they are acknowledging. The sender knows that a \nreceived ACK or NAK packet (whether garbled or not) was generated in response to \nits most recently transmitted data packet.\nFigures 3. 11 and 3.12 show the FSM description for rdt2.1 , our fixed version \nof rdt2.0 . The rdt2.1  sender and receiver FSMs each now have twice as many \nstates as before. This is because the protocol state must now reflect whether the \npacket currently being sent (by the sender) or expected (at the receiver) should have a \nsequence number of 0 or 1. Note that the actions in those states where a 0-numbered \npacket is being sent or expected are mirror images of those where a 1-numbered \npacket is being sent or expected; the only differences have to do with the handling \nof the sequence number.\nProtocol rdt2.1  uses both positive and negative acknowledgments from the \nreceiver to the sender. When an out-of-order packet is received, the receiver sends \na positive acknowledgment for the packet it has received. When a corrupted packet \nWait for\ncall 0 from\naboverdt_rcv(rcvpkt)&&\n(corrupt(rcvpkt)||\nisNAK(rcvpkt))\nudt_send(sndpkt)\nrdt_rcv(rcvpkt)&&\n(corrupt(rcvpkt)||\nisNAK(rcvpkt))\nudt_send(sndpkt)rdt_rcv(rcvpkt)\n&&notcorrupt(rcvpkt)\n&&isACK(rcvpkt)rdt_rcv(rcvpkt)\n&&notcorrupt(rcvpkt)\n&&isACK(rcvpkt)\n/H9011", "doc_id": "c305562a-a177-4a64-b091-b9893b12e7c7", "embedding": null, "doc_hash": "6009368b31f5972c15433074fbd1c4fc52a0b7f31c51b523ea350a4ae4009e11", "extra_info": null, "node_info": {"start": 702729, "end": 706090}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "6c8a07cc-b73a-44fd-ad91-3e9acff195d6", "3": "25c1ae24-c5c9-4cc5-a99a-bbe2c6ad066a"}}, "__type__": "1"}, "25c1ae24-c5c9-4cc5-a99a-bbe2c6ad066a": {"__data__": {"text": "to the sender. When an out-of-order packet is received, the receiver sends \na positive acknowledgment for the packet it has received. When a corrupted packet \nWait for\ncall 0 from\naboverdt_rcv(rcvpkt)&&\n(corrupt(rcvpkt)||\nisNAK(rcvpkt))\nudt_send(sndpkt)\nrdt_rcv(rcvpkt)&&\n(corrupt(rcvpkt)||\nisNAK(rcvpkt))\nudt_send(sndpkt)rdt_rcv(rcvpkt)\n&&notcorrupt(rcvpkt)\n&&isACK(rcvpkt)rdt_rcv(rcvpkt)\n&&notcorrupt(rcvpkt)\n&&isACK(rcvpkt)\n/H9011 /H9011rdt_send(data)\nsndpkt=make_pkt(0,data,checksum)\nudt_send(sndpkt)\nrdt_send(data)\nsndpkt=make_pkt(1,data,checksum)\nudt_send(sndpkt)Wait for\nACK or\nNAK 0\nWait for\nACK or\nNAK 1Wait for\ncall 1 from\nabove\nFigure 3.11  \u2666 rdt2.1  sender\n242     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nis received, the receiver sends a negative acknowledgment. We can accomplish the \nsame effect as a NAK if, instead of sending a NAK, we send an ACK for the last \ncorrectly received packet. A sender that receives two ACKs for the same packet (that \nis, receives duplicate ACKs ) knows that the receiver did not correctly receive the \npacket following the packet that is being ACKed twice. Our NAK-free reliable data \ntransfer protocol for a channel with bit errors is rdt2.2 , shown in Figures 3.13 and \n3.14. One subtle change between rtdt2.1  and rdt2.2  is that the receiver must \nnow include the sequence number of the packet being acknowledged by an ACK \nmessage (this is done by including the ACK, 0 or ACK, 1 argument in make_pkt()  \nin the receiver FSM), and the sender must now check the sequence number of the \npacket being acknowledged by a received ACK message (this is done by including \nthe 0 or 1 argument in isACK()  in the sender FSM).\nReliable Data Transfer over a Lossy Channel with Bit Errors: rdt3.0\nSuppose now that in addition to corrupting bits, the underlying channel can lose \npackets as well, a not-uncommon event in today\u2019s computer networks (including \nthe Internet). Two additional concerns must now be addressed by the protocol: how \nto detect packet loss and what to do when packet loss occurs. The use of check -\nsumming, sequence numbers, ACK packets, and retransmissions\u2014the techniques rdt_rcv(rcvpkt)&&notcorrupt\n(rcvpkt)&&has_seq0(rcvpkt)\nsndpkt=make_pkt(ACK,checksum)\nudt_send(sndpkt)rdt_rcv(rcvpkt)&& corrupt(rcvpkt)\nsndpkt=make_pkt(NAK,checksum)\nudt_send(sndpkt)rdt_rcv(rcvpkt)\n &&corrupt(rcvpkt)\nsndpkt=make_pkt(NAK,checksum)\nudt_send(sndpkt)\nsndpkt=make_pkt(ACK,checksum)\nudt_send(sndpkt)\nrdt_rcv(rcvpkt)&&notcorrupt(rcvpkt)\n&&has_seq1(rcvpkt)\nextract(rcvpkt,data)\ndeliver_data(data)\nsndpkt=make_pkt(ACK,checksum)\nudt_send(sndpkt)rdt_rcv(rcvpkt)&&notcorrupt(rcvpkt)\n", "doc_id": "25c1ae24-c5c9-4cc5-a99a-bbe2c6ad066a", "embedding": null, "doc_hash": "19748e5d87e44a253141be39bce2d1eaedcfa5d19b7d575ead1110ff28ab8144", "extra_info": null, "node_info": {"start": 706288, "end": 708905}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "c305562a-a177-4a64-b091-b9893b12e7c7", "3": "cfaec396-f598-4dfb-ad0b-4360dc65c4e7"}}, "__type__": "1"}, "cfaec396-f598-4dfb-ad0b-4360dc65c4e7": {"__data__": {"text": "&&corrupt(rcvpkt)\nsndpkt=make_pkt(NAK,checksum)\nudt_send(sndpkt)\nsndpkt=make_pkt(ACK,checksum)\nudt_send(sndpkt)\nrdt_rcv(rcvpkt)&&notcorrupt(rcvpkt)\n&&has_seq1(rcvpkt)\nextract(rcvpkt,data)\ndeliver_data(data)\nsndpkt=make_pkt(ACK,checksum)\nudt_send(sndpkt)rdt_rcv(rcvpkt)&&notcorrupt(rcvpkt)\n &&has_seq0(rcvpkt)\nextract(rcvpkt,data)\ndeliver_data(data)\nsndpkt=make_pkt(ACK,checksum)\nudt_send(sndpkt)\nWait for\n0 from\nbelowWait for\n1 from\nbelow rdt_rcv(rcvpkt)&& notcorrupt\n(rcvpkt)&&has_seq1(rcvpkt)\nFigure 3.12  \u2666 rdt2.1  receiver\n3.4  \u2022  PRINCIPLES OF RELIABLE DATA TRANSFER      243\nWait for\ncall 0 from\naboverdt_rcv(rcvpkt)&&\n(corrupt(rcvpkt)||\nisACK(rcvpkt,1))\nudt_send(sndpkt)\nrdt_rcv(rcvpkt)&&\n(corrupt(rcvpkt)||\nisACK(rcvpkt,0))\nudt_send(sndpkt)rdt_rcv(rcvpkt)\n&&notcorrupt(rcvpkt)\n&&isACK(rcvpkt,0)rdt_rcv(rcvpkt)\n&&notcorrupt(rcvpkt)\n&&isACK(rcvpkt,1)rdt_send(data)\nsndpkt=make_pkt(0,data,checksum)\nudt_send(sndpkt)\nrdt_send(data)\nsndpkt=make_pkt(1,data,checksum)\nudt_send(sndpkt)Wait for\nACK 0\nWait for\nACK 1/H9011 /H9011\nWait for\ncall 1 from\nabove\nFigure 3.13  \u2666 rdt2.2  sender\nalready developed in rdt2.2 \u2014will allow us to answer the latter concern. Handling \nthe first concern will require adding a new protocol mechanism.\nThere are many possible approaches toward dealing with packet loss (several \nmore of which are explored in the exercises at the end of the chapter). Here, we\u2019ll \nput the burden of detecting and recovering from lost packets on the sender. Suppose \nthat the sender transmits a data packet and either that packet, or the receiver\u2019s ACK \nof that packet, gets lost. In either case, no reply is forthcoming at the sender from the \nreceiver. If the sender is willing to wait long enough so that it is certain  that a packet \nhas been lost, it can simply retransmit the data packet. You should convince yourself \nthat this protocol does indeed work.\nBut how long must the sender wait to be certain that something has been lost? \nThe sender must clearly wait at least as long as a round-trip delay between the sender \nand receiver (which may include buffering at intermediate routers) plus whatever \namount of time is needed to process a packet at the receiver. In many networks, this \nworst-case maximum delay is very difficult even to estimate, much less know with \ncertainty. Moreover, the protocol should ideally recover from packet loss as soon as \npossible; waiting for a worst-case delay could mean a long wait until error recovery \n244     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nis initiated. The approach thus adopted in practice is for the sender to judiciously \nchoose a time value such that packet loss is likely, although not guaranteed, to have \nhappened. If an ACK is not received within this time, the packet is retransmitted. \nNote that", "doc_id": "cfaec396-f598-4dfb-ad0b-4360dc65c4e7", "embedding": null, "doc_hash": "2c8ffa393a41cb19ae8682cdc086ce53f2d2b40d0a1757568f3b816b595caa12", "extra_info": null, "node_info": {"start": 709022, "end": 711792}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "25c1ae24-c5c9-4cc5-a99a-bbe2c6ad066a", "3": "1212efff-8b75-4576-8b17-c0c60d3aba8a"}}, "__type__": "1"}, "1212efff-8b75-4576-8b17-c0c60d3aba8a": {"__data__": {"text": "the sender \nand receiver (which may include buffering at intermediate routers) plus whatever \namount of time is needed to process a packet at the receiver. In many networks, this \nworst-case maximum delay is very difficult even to estimate, much less know with \ncertainty. Moreover, the protocol should ideally recover from packet loss as soon as \npossible; waiting for a worst-case delay could mean a long wait until error recovery \n244     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nis initiated. The approach thus adopted in practice is for the sender to judiciously \nchoose a time value such that packet loss is likely, although not guaranteed, to have \nhappened. If an ACK is not received within this time, the packet is retransmitted. \nNote that if a packet experiences a particularly large delay, the sender may retrans -\nmit the packet even though neither the data packet nor its ACK have been lost. This \nintroduces the possibility of duplicate data packets  in the sender-to-receiver chan -\nnel. Happily, protocol rdt2.2  already has enough functionality (that is, sequence \nnumbers) to handle the case of duplicate packets.\nFrom the sender\u2019s viewpoint, retransmission is a panacea. The sender does not \nknow whether a data packet was lost, an ACK was lost, or if the packet or ACK was \nsimply overly delayed. In all cases, the action is the same: retransmit. Implement -\ning a time-based retransmission mechanism requires a countdown timer  that can \ninterrupt the sender after a given amount of time has expired. The sender will thus \nneed to be able to (1) start the timer each time a packet (either a first-time packet or \na retransmission) is sent, (2) respond to a timer interrupt (taking appropriate actions), \nand (3) stop the timer.\nFigure 3. 15 shows the sender FSM for rdt3.0 , a protocol that reliably transfers \ndata over a channel that can corrupt or lose packets; in the homework problems, you\u2019ll \nbe asked to provide the receiver FSM for rdt3.0 . Figure 3.16 shows how the pro -\ntocol operates with no lost or delayed packets and how it handles lost data packets. In \nFigure 3. 16, time moves forward from the top of the diagram toward the bottom of the Wait for\n0 from\nbelowrdt_rcv(rcvpkt)&&\n(corrupt(rcvpkt)||\nhas_seq0(rcvpkt))\nsndpkt=make_pkt(ACK,0,checksum)\nudt_send(sndpkt)\nrdt_rcv(rcvpkt)&&\n(corrupt(rcvpkt)||\nhas_seq1(rcvpkt))\nsndpkt=make_pkt(ACK,1,checksum)\nudt_send(sndpkt)\nrdt_rcv(rcvpkt)&&notcorrupt(rcvpkt)\n&&has_seq1(rcvpkt)\nextract(rcvpkt,data)\ndeliver_data(data)\nsndpkt=make_pkt(ACK,1,checksum)\nudt_send(sndpkt)rdt_rcv(rcvpkt)&&notcorrupt(rcvpkt)\n&&has_seq0(rcvpkt)\nextract(rcvpkt,data)\ndeliver_data(data)\nsndpkt=make_pkt(ACK,0,checksum)\nudt_send(sndpkt)\nWait for\n1 from\nbelow\nFigure 3.14  \u2666 rdt2.2  receiver\n3.4  \u2022  PRINCIPLES OF RELIABLE DATA TRANSFER      245\ndiagram; note that a receive time for a packet is necessarily later than the send time for \na packet as a result of transmission and propagation delays. In Figures 3.16(b)\u2013(d), the \nsend-side brackets indicate the times at which a timer is set and later times out. Sev -\neral of the more subtle aspects of this", "doc_id": "1212efff-8b75-4576-8b17-c0c60d3aba8a", "embedding": null, "doc_hash": "cb50ca971d8c789fec7205fa38437ad6664d889ae9a21820381828d1e474471f", "extra_info": null, "node_info": {"start": 711464, "end": 714568}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "cfaec396-f598-4dfb-ad0b-4360dc65c4e7", "3": "1c0a0333-4b6f-4ecd-9494-ec5e1c3a9a9f"}}, "__type__": "1"}, "1c0a0333-4b6f-4ecd-9494-ec5e1c3a9a9f": {"__data__": {"text": "for\n1 from\nbelow\nFigure 3.14  \u2666 rdt2.2  receiver\n3.4  \u2022  PRINCIPLES OF RELIABLE DATA TRANSFER      245\ndiagram; note that a receive time for a packet is necessarily later than the send time for \na packet as a result of transmission and propagation delays. In Figures 3.16(b)\u2013(d), the \nsend-side brackets indicate the times at which a timer is set and later times out. Sev -\neral of the more subtle aspects of this protocol are explored in the exercises at the end \nof this chapter. Because packet sequence numbers alternate between 0 and 1, protocol \nrdt3.0  is sometimes known as the alternating-bit protocol .\nWe have now assembled the key elements of a data transfer protocol. Check -\nsums, sequence numbers, timers, and positive and negative acknowledgment packets \neach play a crucial and necessary role in the operation of the protocol. We now have \na working reliable data transfer protocol!\n3.4.2  Pipelined Reliable Data Transfer Protocols\nProtocol rdt3.0  is a functionally correct protocol, but it is unlikely that anyone \nwould be happy with its performance, particularly in today\u2019s high-speed networks. \nAt the heart of rdt3.0 \u2019s performance problem is the fact that it is a stop-and-wait \nprotocol.Wait for\ncall 0 from\naboverdt_rcv(rcvpkt)&&\n(corrupt(rcvpkt)||\nisACK(rcvpkt,1))\ntimeout\nudt_send(sndpkt)\nstart_timer\nrdt_rcv(rcvpkt)\n/H9011 rdt_rcv(rcvpkt)&&\n(corrupt(rcvpkt)||\nisACK(rcvpkt,0))rdt_rcv(rcvpkt)\n&&notcorrupt(rcvpkt)\n&&isACK(rcvpkt,0)\nstop_timerrdt_rcv(rcvpkt)\n&&notcorrupt(rcvpkt)\n&&isACK(rcvpkt,1)\nstop_timer\ntimeout\nudt_send(sndpkt)\nstart_timerrdt_send(data)\nsndpkt=make_pkt(0,data,checksum)\nudt_send(sndpkt)\nstart_timer\nrdt_send(data)\nsndpkt=make_pkt(1,data,checksum)\nudt_send(sndpkt)\nstart_timerWait for\nACK 0\nWait for\nACK 1\n/H9011/H9011\nWait for\ncall 1 from\naboverdt_rcv(rcvpkt)\n/H9011\nFigure 3.15  \u2666 rdt3.0  sender\nVideoNote\nDeveloping a protocol \nand FSM representation \nfor a simple application-\nlayer protocol\n246     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nrcv pkt0\nsend ACK0\nrcv pkt1\nsend ACK1\nrcv pkt0\nsend ACK0Sender Receiver\na. Operation with no losspkt0\nACK0\npkt1\npkt0ACK1\nACK0\n(loss) Xb. Lost packet\nrcv pkt0\nsend ACK0\nrcv pkt1\nsend ACK1\nc. Lost ACKsend pkt0\nrcv ACK0\nsend pkt1\nrcv ACK1\nsend pkt0\nsend pkt0\nrcv ACK0\nsend pkt1\ntimeout\nresend pkt1\nrcv ACK1\nsend pkt0\nrcv pkt0\nsend ACK0rcv pkt1\n(detect\nduplicate)\nsend ACK1send pkt0\nrcv ACK0\nsend pkt1rcv pkt0\nsend ACK0\ntimeout\nresend pkt1rcv pkt1\nsend ACK1\nd. Premature timeoutrcv ACK1\nsend pkt0\nrcv ACK1\ndo nothingrcv pkt0\nsend ACK0rcv pkt 1\n(detect duplicate)\nsend ACK1Sender Receiver Receiver", "doc_id": "1c0a0333-4b6f-4ecd-9494-ec5e1c3a9a9f", "embedding": null, "doc_hash": "12439c172a860b545251537ebd39d13df14b10c124519e25e50f4bca6a11fe0c", "extra_info": null, "node_info": {"start": 714849, "end": 717427}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "1212efff-8b75-4576-8b17-c0c60d3aba8a", "3": "5a167dfc-8da4-4ab5-8550-9d9c54823aa7"}}, "__type__": "1"}, "5a167dfc-8da4-4ab5-8550-9d9c54823aa7": {"__data__": {"text": "ACK0\nrcv pkt1\nsend ACK1\nc. Lost ACKsend pkt0\nrcv ACK0\nsend pkt1\nrcv ACK1\nsend pkt0\nsend pkt0\nrcv ACK0\nsend pkt1\ntimeout\nresend pkt1\nrcv ACK1\nsend pkt0\nrcv pkt0\nsend ACK0rcv pkt1\n(detect\nduplicate)\nsend ACK1send pkt0\nrcv ACK0\nsend pkt1rcv pkt0\nsend ACK0\ntimeout\nresend pkt1rcv pkt1\nsend ACK1\nd. Premature timeoutrcv ACK1\nsend pkt0\nrcv ACK1\ndo nothingrcv pkt0\nsend ACK0rcv pkt 1\n(detect duplicate)\nsend ACK1Sender Receiver Receiver Sender\npkt0\nACK0\npkt1\nACK1\nACK1ACK0\nACK1\nACK0pkt1\npkt0pkt0\npkt1\npkt1\npkt0\nACK1\nACK0X (loss)pkt1rcv pkt0\nsend ACK0send pkt0\nrcv ACK0\nsend pkt1\ntimeout\nresend pkt1\nrcv ACK1\nsend pkt0\nrcv pkt0\nsend ACK0rcv pkt1\nsend ACK1Sender Receiver\npkt0\nACK0\npkt1\npkt0ACK1\nACK0\nFigure 3.16  \u2666 Operation of rdt3.0 , the alternating-bit protocol\n3.4  \u2022  PRINCIPLES OF RELIABLE DATA TRANSFER      247\nTo appreciate the performance impact of this stop-and-wait behavior, consider \nan idealized case of two hosts, one located on the West Coast of the United States \nand the other located on the East Coast, as shown in Figure 3.17. The speed-of-light \nround-trip propagation delay between these two end systems, RTT, is approximately \n30 milliseconds. Suppose that they are connected by a channel with a transmission \nrate, R, of 1 Gbps (109 bits per second). With a packet size, L, of 1,000 bytes (8,000 \nbits) per packet, including both header fields and data, the time needed to actually \ntransmit the packet into the 1 Gbps link is\ndtrans=L\nR=8000 bits>packet\n109 bits/sec=8 microsecond s\nFigure 3. 18(a) shows that with our stop-and-wait protocol, if the sender begins \nsending the packet at t=0, then at t=L/R=8 microseconds, the last bit enters \nthe channel at the sender side. The packet then makes its 15-msec cross-country jour -\nney, with the last bit of the packet emerging at the receiver at t=RTT/2 +L/R =\n15.008 msec.  Assuming for simplicity that ACK packets are extremely small (so that \nwe can ignore their transmission time) and that the receiver can send an ACK as soon \nas the last bit of a data packet is received, the ACK emerges back at the sender at \nt=RTT+L/R=30.008 msec.  At this point, the sender can now transmit the next \nmessage. Thus, in 30.008 msec, the sender was sending for only 0.008 msec. If we \ndefine the utilization  of the sender (or the channel) as the fraction of time the sender \nis actually busy sending bits into the channel, the analysis in Figure 3.18(a) shows \nthat the stop-and-wait protocol has a rather dismal sender utilization, Usender, of\nUsender=L>R\nRTT+L>R=.008\n30.008=0.0002 7Data packets Data packet\nACK packets\na. A stop-and-wait protocol in operation b. A pipelined protocol in operation\nFigure 3.17  \u2666 Stop-and-wait versus pipelined protocol\n248     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nFirst bit of \ufb01rst packet\ntransmitted, t = 0\nLast bit of \ufb01rst packet\ntransmitted, t =", "doc_id": "5a167dfc-8da4-4ab5-8550-9d9c54823aa7", "embedding": null, "doc_hash": "6373066f1bd245e69fb95da0a34ac9ac819989852878938af75f5ab2a325e3cb", "extra_info": null, "node_info": {"start": 717378, "end": 720218}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "1c0a0333-4b6f-4ecd-9494-ec5e1c3a9a9f", "3": "7d25e0f9-7a4d-49aa-aca7-a857821a0e34"}}, "__type__": "1"}, "7d25e0f9-7a4d-49aa-aca7-a857821a0e34": {"__data__": {"text": "(or the channel) as the fraction of time the sender \nis actually busy sending bits into the channel, the analysis in Figure 3.18(a) shows \nthat the stop-and-wait protocol has a rather dismal sender utilization, Usender, of\nUsender=L>R\nRTT+L>R=.008\n30.008=0.0002 7Data packets Data packet\nACK packets\na. A stop-and-wait protocol in operation b. A pipelined protocol in operation\nFigure 3.17  \u2666 Stop-and-wait versus pipelined protocol\n248     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nFirst bit of \ufb01rst packet\ntransmitted, t = 0\nLast bit of \ufb01rst packet\ntransmitted, t = L/R\nFirst bit of \ufb01rst packet\ntransmitted, t = 0\nLast bit of \ufb01rst packet\ntransmitted, t = L/RACK arrives, send next packet,\nt = RTT + L/R\na. Stop-and-wait operationSender Receiver\nRTTFirst bit of \ufb01rst packet arrives\nLast bit of \ufb01rst packet arrives, send ACK\nFirst bit of \ufb01rst packet arrives\nLast bit of \ufb01rst packet arrives, send ACK\nACK arrives, send next packet,\nt = RTT + L/R\nb. Pipelined operationSender Receiver\nRTT\nLast bit of 2nd packet arrives, send ACK\nLast bit of 3rd packet arrives, send ACK\nFigure 3.18  \u2666 Stop-and-wait and pipelined sending\n3.4  \u2022  PRINCIPLES OF RELIABLE DATA TRANSFER      249\nThat is, the sender was busy only 2.7 hundredths of one percent of the time! \nViewed another way, the sender was able to send only 1,000 bytes in 30.008 mil -\nliseconds, an effective throughput of only 267 kbps\u2014even though a 1 Gbps link \nwas available! Imagine the unhappy network manager who just paid a fortune for \na gigabit capacity link but manages to get a throughput of only 267 kilobits per \nsecond! This is a graphic example of how network protocols can limit the capabili -\nties provided by the underlying network hardware. Also, we have neglected lower-  \nlayer protocol-processing times at the sender and receiver, as well as the process -\ning and queuing delays that would occur at any intermediate routers between the \nsender and receiver. Including these effects would serve only to further increase the  \ndelay and further accentuate the poor performance.\nThe solution to this particular performance problem is simple: Rather than oper -\nate in a stop-and-wait manner, the sender is allowed to send multiple packets with -\nout waiting for acknowledgments, as illustrated in Figure 3.17(b). Figure 3.18(b) \nshows that if the sender is allowed to transmit three packets before having to wait for \nacknowledgments, the utilization of the sender is essentially tripled. Since the many \nin-transit sender-to-receiver packets can be visualized as filling a pipeline, this tech -\nnique is known as pipelining . Pipelining has the following consequences for reliable \ndata transfer protocols:\n\u2022 The range of sequence numbers must be increased, since each in-transit packet \n(not counting retransmissions) must have a unique sequence number and there \nmay be multiple, in-transit, unacknowledged packets.\n\u2022 The sender and receiver sides of the protocols may have to buffer more than one \npacket. Minimally, the sender will have to buffer packets that have been transmit -\nted but not yet acknowledged. Buffering of correctly received packets may also \nbe needed at the receiver, as discussed below.\n\u2022 The range of sequence numbers needed and the buffering requirements will \ndepend on the manner in which a data transfer protocol responds to lost, cor -\nrupted, and overly delayed packets. Two basic approaches toward pipelined", "doc_id": "7d25e0f9-7a4d-49aa-aca7-a857821a0e34", "embedding": null, "doc_hash": "139374664208f1c1b130013d874bd38d7add99c146d5ec0474b57dae0b01748b", "extra_info": null, "node_info": {"start": 720130, "end": 723529}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "5a167dfc-8da4-4ab5-8550-9d9c54823aa7", "3": "415d9c3a-5d44-41ca-bb6d-04ff70f83c4c"}}, "__type__": "1"}, "415d9c3a-5d44-41ca-bb6d-04ff70f83c4c": {"__data__": {"text": "for reliable \ndata transfer protocols:\n\u2022 The range of sequence numbers must be increased, since each in-transit packet \n(not counting retransmissions) must have a unique sequence number and there \nmay be multiple, in-transit, unacknowledged packets.\n\u2022 The sender and receiver sides of the protocols may have to buffer more than one \npacket. Minimally, the sender will have to buffer packets that have been transmit -\nted but not yet acknowledged. Buffering of correctly received packets may also \nbe needed at the receiver, as discussed below.\n\u2022 The range of sequence numbers needed and the buffering requirements will \ndepend on the manner in which a data transfer protocol responds to lost, cor -\nrupted, and overly delayed packets. Two basic approaches toward pipelined error \nrecovery can be identified: Go-Back-N  and selective repeat .\n3.4.3  Go-Back-N (GBN)\nIn a Go-Back-N (GBN) protocol , the sender is allowed to transmit multiple packets \n(when available) without waiting for an acknowledgment, but is constrained to have \nno more than some maximum allowable number, N, of unacknowledged packets in \nthe pipeline. We describe the GBN protocol in some detail in this section. But before \nreading on, you are encouraged to play with the GBN applet (an awesome applet!) \nat the companion Web site.\nFigure 3. 19 shows the sender\u2019s view of the range of sequence numbers in a GBN \nprotocol. If we define base  to be the sequence number of the oldest unacknowledged \n250     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\npacket and nextseqnum  to be the smallest unused sequence number (that is, the \nsequence number of the next packet to be sent), then four intervals in the range of \nsequence numbers can be identified. Sequence numbers in the interval [ 0,base-1 ] \ncorrespond to packets that have already been transmitted and acknowledged. The inter -\nval [base,nextseqnum-1]  corresponds to packets that have been sent but not \nyet acknowledged. Sequence numbers in the interval [nextseqnum,base+N-1]  \ncan be used for packets that can be sent immediately, should data arrive from the \nupper layer. Finally, sequence numbers greater than or equal to base+N  cannot \nbe used until an unacknowledged packet currently in the pipeline (specifically, the \npacket with sequence number base ) has been acknowledged.\nAs suggested by Figure 3.19, the range of permissible sequence numbers for \ntransmitted but not yet acknowledged packets can be viewed as a window of size N \nover the range of sequence numbers. As the protocol operates, this window slides \nforward over the sequence number space. For this reason, N is often referred to as the \nwindow size  and the GBN protocol itself as a sliding-window protocol . You might \nbe wondering why we would even limit the number of outstanding, unacknowledged \npackets to a value of N in the first place. Why not allow an unlimited number of such \npackets? We\u2019ll see in Section 3.5 that flow control is one reason to impose a limit \non the sender. We\u2019ll examine another reason to do so in Section 3.7, when we study \nTCP congestion control.\nIn practice, a packet\u2019s sequence number is carried in a fixed-length field in the \npacket header. If k is the number of bits in the packet sequence number field, the \nrange of sequence numbers is thus [0,2k-1]. With a finite range of sequence num -\nbers, all arithmetic involving sequence numbers must then be done using modulo 2k \narithmetic. (That is, the sequence number space can be thought of as a ring of size \n2k, where sequence number 2k-1 is immediately followed by sequence number 0.) \nRecall that rdt3.0  had a 1-bit sequence number and a range of sequence numbers \nof [0,1]. Several of the problems at the end of this chapter explore the consequences", "doc_id": "415d9c3a-5d44-41ca-bb6d-04ff70f83c4c", "embedding": null, "doc_hash": "38d12cb7751919122e0b38f572336fa7dd3866e9025fd0261339f50cf59b7384", "extra_info": null, "node_info": {"start": 723351, "end": 727088}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "7d25e0f9-7a4d-49aa-aca7-a857821a0e34", "3": "82007428-c9bb-4f94-b8a7-282102e19199"}}, "__type__": "1"}, "82007428-c9bb-4f94-b8a7-282102e19199": {"__data__": {"text": "to do so in Section 3.7, when we study \nTCP congestion control.\nIn practice, a packet\u2019s sequence number is carried in a fixed-length field in the \npacket header. If k is the number of bits in the packet sequence number field, the \nrange of sequence numbers is thus [0,2k-1]. With a finite range of sequence num -\nbers, all arithmetic involving sequence numbers must then be done using modulo 2k \narithmetic. (That is, the sequence number space can be thought of as a ring of size \n2k, where sequence number 2k-1 is immediately followed by sequence number 0.) \nRecall that rdt3.0  had a 1-bit sequence number and a range of sequence numbers \nof [0,1]. Several of the problems at the end of this chapter explore the consequences \nof a finite range of sequence numbers. We will see in Section 3.5 that TCP has a \n32-bit sequence number field, where TCP sequence numbers count bytes in the byte \nstream rather than packets.\nFigures 3. 20 and 3.21 give an extended FSM description of the sender and \nreceiver sides of an ACK-based, NAK-free, GBN protocol. We refer to this FSM base nextseqnum\nWindow size\nNKey:\nAlready\nACK\u2019d\nSent, not\nyet ACK\u2019dUsable,\nnot yet sent\nNot usable\nFigure 3.19  \u2666 Sender\u2019s view of sequence numbers in Go-Back-N\n3.4  \u2022  PRINCIPLES OF RELIABLE DATA TRANSFER      251\nrdt_send(data)\nif(nextseqnum<base+N){\n   sndpkt[nextseqnum]=make_pkt(nextseqnum,data,checksum)\n   udt_send(sndpkt[nextseqnum])\n   if(base==nextseqnum)\n      start_timer\n   nextseqnum++\n   }\nelse\n   refuse_data(data)\n/H9011\nrdt_rcv(rcvpkt )&&notcorrupt(rcvpkt)\nbase=getacknum(rcvpkt)+1\nIf(base==nextseqnum)\n   stop_timer\nelse\n   start_timerrdt_rcv(rcvpkt) &&corrupt(rcvpkt)/H9011\nbase=1\nnextseqnum=1\ntimeout\nstart_timer\nudt_send(sndpkt[base])\nudt_send(sndpkt[base+1])\n...\nudt_send(sndpkt[nextseqnum-1])Wait\nFigure 3.20  \u2666 Extended FSM description of the GBN sender\nrdt_rcv(rcvpkt)\n  &&notcorrupt(rcvpkt)\n  &&hasseqnum(rcvpkt,expectedseqnum)\nextract(rcvpkt,data)\ndeliver_data(data)\nsndpkt=make_pkt(expectedseqnum,ACK,checksum)\nudt_send(sndpkt)\nexpectedseqnum++\n/H9011\nexpectedseqnum=1\nsndpkt=make_pkt(0,ACK,checksum)default\nudt_send(sndpkt)Wait\nFigure 3.21  \u2666 Extended FSM description of the GBN receiver\n252     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\ndescription as an extended FSM  because we have added variables (similar to  \nprogramming-language variables) for base  and nextseqnum , and added opera -\ntions on these variables and conditional actions involving these variables. Note that \nthe extended FSM specification is now beginning to look somewhat like a program -\nming-language specification. [Bochman 1984] provides an excellent survey of addi -\ntional extensions to FSM techniques as well as other programming-language-based \ntechniques for specifying protocols.\nThe GBN sender must respond to three types of events:\n\u2022 Invocation from above.  When rdt_send()  is called from above, the sender \nfirst checks to see if the window is full, that is, whether there are N outstand -\ning,", "doc_id": "82007428-c9bb-4f94-b8a7-282102e19199", "embedding": null, "doc_hash": "55cb0819b1a1103de094b463f69950cdcfdebef2686dc016900353ab0ca309b7", "extra_info": null, "node_info": {"start": 727144, "end": 730118}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "415d9c3a-5d44-41ca-bb6d-04ff70f83c4c", "3": "70c808f9-c25b-4c0b-9474-3ba19375040c"}}, "__type__": "1"}, "70c808f9-c25b-4c0b-9474-3ba19375040c": {"__data__": {"text": "LAYER\ndescription as an extended FSM  because we have added variables (similar to  \nprogramming-language variables) for base  and nextseqnum , and added opera -\ntions on these variables and conditional actions involving these variables. Note that \nthe extended FSM specification is now beginning to look somewhat like a program -\nming-language specification. [Bochman 1984] provides an excellent survey of addi -\ntional extensions to FSM techniques as well as other programming-language-based \ntechniques for specifying protocols.\nThe GBN sender must respond to three types of events:\n\u2022 Invocation from above.  When rdt_send()  is called from above, the sender \nfirst checks to see if the window is full, that is, whether there are N outstand -\ning, unacknowledged packets. If the window is not full, a packet is created and \nsent, and variables are appropriately updated. If the window is full, the sender \nsimply returns the data back to the upper layer, an implicit indication that the \nwindow is full. The upper layer would presumably then have to try again later. \nIn a real implementation, the sender would more likely have either buffered (but \nnot immediately sent) this data, or would have a synchronization mechanism \n(for example, a semaphore or a flag) that would allow the upper layer to call  \nrdt_send()  only when the window is not full.\n\u2022 Receipt of an ACK.  In our GBN protocol, an acknowledgment for a packet with \nsequence number n will be taken to be a cumulative acknowledgment , indicat -\ning that all packets with a sequence number up to and including n have been \ncorrectly received at the receiver. We\u2019ll come back to this issue shortly when we \nexamine the receiver side of GBN.\n\u2022 A timeout event.  The protocol\u2019s name, \u201cGo-Back-N,\u201d is derived from the sender\u2019s \nbehavior in the presence of lost or overly delayed packets. As in the stop-and-wait \nprotocol, a timer will again be used to recover from lost data or acknowledgment \npackets. If a timeout occurs, the sender resends all packets that have been previ -\nously sent but that have not yet been acknowledged. Our sender in Figure 3.20 \nuses only a single timer, which can be thought of as a timer for the oldest trans -\nmitted but not yet acknowledged packet. If an ACK is received but there are still \nadditional transmitted but not yet acknowledged packets, the timer is restarted. If \nthere are no outstanding, unacknowledged packets, the timer is stopped.\nThe receiver\u2019s actions in GBN are also simple. If a packet with sequence number \nn is received correctly and is in order (that is, the data last delivered to the upper layer \ncame from a packet with sequence number n-1), the receiver sends an ACK for \npacket n and delivers the data portion of the packet to the upper layer. In all other \ncases, the receiver discards the packet and resends an ACK for the most recently \nreceived in-order packet. Note that since packets are delivered one at a time to the \nupper layer, if packet k has been received and delivered, then all packets with a \n3.4  \u2022  PRINCIPLES OF RELIABLE DATA TRANSFER      253\nsequence number lower than k have also been delivered. Thus, the use of cumulative \nacknowledgments is a natural choice for GBN.\nIn our GBN protocol, the receiver discards out-of-order packets. Although \nit may seem silly and wasteful to discard a correctly received (but out-of-order) \npacket, there is some justification for doing so. Recall that the receiver must \ndeliver data in order to the upper layer. Suppose now that packet n is expected, but \npacket n+1 arrives. Because data must be delivered in order, the receiver could  \nbuffer (save) packet n+1 and then deliver this packet to the upper layer after it \nhad later received and delivered packet n. However, if packet n is lost, both it", "doc_id": "70c808f9-c25b-4c0b-9474-3ba19375040c", "embedding": null, "doc_hash": "ecff028c0048759d26e2e9feab7ed95ded39feb87ad6ce19fcec6a14619cf010", "extra_info": null, "node_info": {"start": 730083, "end": 733870}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "82007428-c9bb-4f94-b8a7-282102e19199", "3": "89453cfd-9157-4090-9f74-91ee81e132e4"}}, "__type__": "1"}, "89453cfd-9157-4090-9f74-91ee81e132e4": {"__data__": {"text": "TRANSFER      253\nsequence number lower than k have also been delivered. Thus, the use of cumulative \nacknowledgments is a natural choice for GBN.\nIn our GBN protocol, the receiver discards out-of-order packets. Although \nit may seem silly and wasteful to discard a correctly received (but out-of-order) \npacket, there is some justification for doing so. Recall that the receiver must \ndeliver data in order to the upper layer. Suppose now that packet n is expected, but \npacket n+1 arrives. Because data must be delivered in order, the receiver could  \nbuffer (save) packet n+1 and then deliver this packet to the upper layer after it \nhad later received and delivered packet n. However, if packet n is lost, both it and \npacket n+1 will eventually be retransmitted as a result of the GBN retransmis -\nsion rule at the sender. Thus, the receiver can simply discard packet n+1. The \nadvantage of this approach is the simplicity of receiver buffering\u2014the receiver \nneed not buffer any out-of-order packets. Thus, while the sender must maintain \nthe upper and lower bounds of its window and the position of nextseqnum  \nwithin this window, the only piece of information the receiver need maintain is \nthe sequence number of the next in-order packet. This value is held in the variable \nexpectedseqnum , shown in the receiver FSM in Figure 3.21. Of course, the \ndisadvantage of throwing away a correctly received packet is that the subsequent \nretransmission of that packet might be lost or garbled and thus even more retrans -\nmissions would be required.\nFigure 3. 22 shows the operation of the GBN protocol for the case of a window \nsize of four packets. Because of this window size limitation, the sender sends pack -\nets 0 through 3 but then must wait for one or more of these packets to be acknowl -\nedged before proceeding. As each successive ACK (for example, ACK0  and ACK1 ) \nis received, the window slides forward and the sender can transmit one new packet \n(pkt4 and pkt5, respectively). On the receiver side, packet 2 is lost and thus packets \n3, 4, and 5 are found to be out of order and are discarded.\nBefore closing our discussion of GBN, it is worth noting that an implementa -\ntion of this protocol in a protocol stack would likely have a structure similar to that \nof the extended FSM in Figure 3.20. The implementation would also likely be in \nthe form of various procedures that implement the actions to be taken in response to \nthe various events that can occur. In such event-based programming , the various \nprocedures are called (invoked) either by other procedures in the protocol stack, or \nas the result of an interrupt. In the sender, these events would be (1) a call from the \nupper-layer entity to invoke rdt_send() , (2) a timer interrupt, and (3) a call from \nthe lower layer to invoke rdt_rcv()  when a packet arrives. The programming \nexercises at the end of this chapter will give you a chance to actually implement these \nroutines in a simulated, but realistic, network setting.\nWe note here that the GBN protocol incorporates almost all of the techniques \nthat we will encounter when we study the reliable data transfer components of TCP \nin Section 3.5. These techniques include the use of sequence numbers, cumulative \nacknowledgments, checksums, and a timeout/retransmit operation.\n254     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\n3.4.4  Selective Repeat (SR)\nThe GBN protocol allows the sender to potentially \u201cfill the pipeline\u201d in Figure 3.17 \nwith packets, thus avoiding the channel utilization problems we noted with stop-\nand-wait protocols. There are, however, scenarios in which GBN itself suffers from \nperformance problems. In particular, when the window size and bandwidth-delay \nproduct are both large, many", "doc_id": "89453cfd-9157-4090-9f74-91ee81e132e4", "embedding": null, "doc_hash": "8c9134cfc64cd538b4177325549117548fbdb418b1d0e48490249e0778989b18", "extra_info": null, "node_info": {"start": 733912, "end": 737659}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "70c808f9-c25b-4c0b-9474-3ba19375040c", "3": "6a6175a6-ef3b-4fc7-a0ed-d1f549557493"}}, "__type__": "1"}, "6a6175a6-ef3b-4fc7-a0ed-d1f549557493": {"__data__": {"text": "almost all of the techniques \nthat we will encounter when we study the reliable data transfer components of TCP \nin Section 3.5. These techniques include the use of sequence numbers, cumulative \nacknowledgments, checksums, and a timeout/retransmit operation.\n254     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\n3.4.4  Selective Repeat (SR)\nThe GBN protocol allows the sender to potentially \u201cfill the pipeline\u201d in Figure 3.17 \nwith packets, thus avoiding the channel utilization problems we noted with stop-\nand-wait protocols. There are, however, scenarios in which GBN itself suffers from \nperformance problems. In particular, when the window size and bandwidth-delay \nproduct are both large, many packets can be in the pipeline. A single packet error \ncan thus cause GBN to retransmit a large number of packets, many unnecessarily. \nAs the probability of channel errors increases, the pipeline can become filled with \nthese unnecessary retransmissions. Imagine, in our message-dictation scenario, that Sender Receiver\n send pkt0\n send pkt1\n send pkt2\nsend pkt3\n  (wait)\n rcv ACK0\nsend pkt4\n rcv ACK1\nsend pkt5\nsend pkt2\nsend pkt3\nsend pkt4\nsend pkt5pkt2 timeoutrcv pkt0\nsend ACK0\nrcv pkt1\nsend ACK1\nrcv pkt3, discard\nsend ACK1\nrcv pkt4, discard\nsend ACK1\nrcv pkt5, discard\nsend ACK1\nrcv pkt2, deliver\nsend ACK2\nrcv pkt3, deliver\nsend ACK3X\n(loss)\nFigure 3.22  \u2666 Go-Back-N in operation\n3.4  \u2022  PRINCIPLES OF RELIABLE DATA TRANSFER      255\nif every time a word was garbled, the surrounding 1,000 words (for example, a win -\ndow size of 1,000 words) had to be repeated. The dictation would be slowed by all \nof the reiterated words.\nAs the name suggests, selective-repeat protocols avoid unnecessary retrans -\nmissions by having the sender retransmit only those packets that it suspects were \nreceived in error (that is, were lost or corrupted) at the receiver. This individual, \nas-needed, retransmission will require that the receiver individually  acknowledge \ncorrectly received packets. A window size of N will again be used to limit the num -\nber of outstanding, unacknowledged packets in the pipeline. However, unlike GBN, \nthe sender will have already received ACKs for some of the packets in the window. \nFigure 3. 23 shows the SR sender\u2019s view of the sequence number space. Figure 3.24 \ndetails the various actions taken by the SR sender.\nThe SR receiver will acknowledge a correctly received packet whether or not it is \nin order. Out-of-order packets are buffered until any missing packets (that is, packets \nwith lower sequence numbers) are received, at which point a batch of packets can be \ndelivered in order to the upper layer. Figure 3.25 itemizes the various actions taken by \nthe SR receiver. Figure 3.26 shows an example of SR operation in the presence of lost \npackets. Note that in Figure 3.26, the receiver initially buffers packets 3, 4, and 5, and \ndelivers them together with packet 2 to the upper layer when packet 2 is finally received.\nsend_base nextseqnum\nWindow size\nNKey:\nKey:Already\nACK\u2019d\nSent, not\nyet ACK\u2019dUsable,\nnot yet sent\nNot usable\nOut of order\n(buffered) but\nalready ACK\u2019d\nExpected, not\nyet receivedAcceptable\n(within\nwindow)\nNot usablea. Sender view of sequence numbers\nb. Receiver view of sequence numbersrcv_base\nWindow size\nN\nFigure 3.23  \u2666  Selective-repeat (SR) sender and receiver views  \nof sequence-number space\n256    ", "doc_id": "6a6175a6-ef3b-4fc7-a0ed-d1f549557493", "embedding": null, "doc_hash": "97ade81f28ac0a2f6a33b00df8e586cced3a01c21ca8b870411036c7d6188f90", "extra_info": null, "node_info": {"start": 737670, "end": 741030}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "89453cfd-9157-4090-9f74-91ee81e132e4", "3": "47c1b622-256f-46df-ba92-7129b00109b6"}}, "__type__": "1"}, "47c1b622-256f-46df-ba92-7129b00109b6": {"__data__": {"text": "SR operation in the presence of lost \npackets. Note that in Figure 3.26, the receiver initially buffers packets 3, 4, and 5, and \ndelivers them together with packet 2 to the upper layer when packet 2 is finally received.\nsend_base nextseqnum\nWindow size\nNKey:\nKey:Already\nACK\u2019d\nSent, not\nyet ACK\u2019dUsable,\nnot yet sent\nNot usable\nOut of order\n(buffered) but\nalready ACK\u2019d\nExpected, not\nyet receivedAcceptable\n(within\nwindow)\nNot usablea. Sender view of sequence numbers\nb. Receiver view of sequence numbersrcv_base\nWindow size\nN\nFigure 3.23  \u2666  Selective-repeat (SR) sender and receiver views  \nof sequence-number space\n256     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nIt is important to note that in Step 2 in Figure 3.25, the receiver reacknowledges \n(rather than ignores) already received packets with certain sequence numbers below  \nthe current window base. You should convince yourself that this reacknowledgment \nis indeed needed. Given the sender and receiver sequence number spaces in Figure \n3.23, for example, if there is no ACK for packet send_base  propagating from the 1.Data received from above. When data is received from above, the SR sender\nchecks the next available sequence number for the packet. If the sequence\nnumber is within the sender\u2019s window, the data is packetized and sent; other-\nwise it is either bu\ufb00ered or returned to the upper layer for later transmission, \nas in GBN.\n2.Timeout .Timers are again used to protect against lost packets. However, each\npacket must now have its own logical timer, since only a single packet will \nbe transmitted on timeout. A single hardware timer can be used to mimic the\noperation of multiple logical timers [Varghese 1997].\n3.ACK received . If an ACK is received, the SR sender marks that packet as \nhaving been received, provided it is in the window. If the packet\u2019s sequence\nnumber is equal to send_base , the window base is moved forward to the \nunacknowledged packet with the smallest sequence number. If the window\nmoves and there are untransmitted packets with sequence numbers that now\nfall within the window, these packets are transmitted.\nFigure 3.24  \u2666 SR sender events and actions\n1.Packet with sequence number in [rcv_base, rcv_base+N-1] is cor-\nrectly r eceived. In this case, the received packet falls within the receiver \u2019s win-\ndow and a selective ACK packet is returned to the sender. If the packet was no t\npreviously received, it is bu ffered. If this packet has a sequence number equal to\nthe base of the receive window (rcv_basein Figure 3.22), then this packet,\nand any previously buffered and consecutively numbered (beginning with\nrcv_base ) packets are delivered to the upper layer . The receive window is\nthen moved forward by the number of packets delivered to the upper layer . As\nan example, consider Figure 3.26. When a packet with a sequence number of\nrcv_base=2 is received, it and packets 3, 4, and 5 can be delivered to th e\nupper layer .\n2.Packet with sequence number in [rcv_base-N, rcv_base-1] is cor-\nrectly received. In this case, an ACK must be generated, even though this is a\npacket that the receiver has previously acknowledged.\n3.Otherwise. Ignore the packet.\nFigure 3.25  \u2666 SR receiver events and actions\n3.4  \u2022  PRINCIPLES OF RELIABLE DATA TRANSFER      257\nreceiver to the sender, the sender will eventually retransmit packet send_base , \neven though it is clear (to us, not the sender!) that the receiver has already received \nthat packet. If the receiver were not to acknowledge this packet, the sender\u2019s win -\ndow would never move forward! This example", "doc_id": "47c1b622-256f-46df-ba92-7129b00109b6", "embedding": null, "doc_hash": "69ed32b601b4d1a1e023cd4d8a54056784300ff1795ad521f0d5ae9cdc4ad1e2", "extra_info": null, "node_info": {"start": 741072, "end": 744632}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "6a6175a6-ef3b-4fc7-a0ed-d1f549557493", "3": "0ec9b492-9ff8-483a-8ff4-94e2785bcf85"}}, "__type__": "1"}, "0ec9b492-9ff8-483a-8ff4-94e2785bcf85": {"__data__": {"text": "to th e\nupper layer .\n2.Packet with sequence number in [rcv_base-N, rcv_base-1] is cor-\nrectly received. In this case, an ACK must be generated, even though this is a\npacket that the receiver has previously acknowledged.\n3.Otherwise. Ignore the packet.\nFigure 3.25  \u2666 SR receiver events and actions\n3.4  \u2022  PRINCIPLES OF RELIABLE DATA TRANSFER      257\nreceiver to the sender, the sender will eventually retransmit packet send_base , \neven though it is clear (to us, not the sender!) that the receiver has already received \nthat packet. If the receiver were not to acknowledge this packet, the sender\u2019s win -\ndow would never move forward! This example illustrates an important aspect of \nSR protocols (and many other protocols as well). The sender and receiver will not \nalways have an identical view of what has been received correctly and what has not. \nFor SR protocols, this means that the sender and receiver windows will not always \ncoincide.pkt0 rcvd, delivered, ACK0 sent\n0 1 2 3 4 5 6 7 8 9\npkt1 rcvd, delivered, ACK1 sent\n0 1 2 3 4 5 6 7 8 9\npkt3 rcvd, bu\ufb00ered, ACK3 sent\n0 1 2 3 4 5 6 7 8 9\npkt4 rcvd, bu\ufb00ered, ACK4 sent\n0 1 2 3 4 5 6 7 8 9\npkt5 rcvd; bu\ufb00ered, ACK5 sent\n0 1 2 3 4 5 6 7 8 9\npkt2 rcvd, pkt2,pkt3,pkt4,pkt5\ndelivered, ACK2 sent\n0 1 2 3 4 5 6 7 8 9pkt0 sent\n0 1 2 3 4 5 6 7 8 9\npkt1 sent\n0 1 2 3 4 5 6 7 8 9\npkt2 sent\n0 1 2 3 4 5 6 7 8 9\npkt3 sent, window full\n0 1 2 3 4 5 6 7 8 9\nACK0 rcvd, pkt4 sent\n0 1 2 3 4 5 6 7 8 9\nACK1 rcvd, pkt5 sent\n0 1 2 3 4 5 6 7 8 9\npkt2 TIMEOUT, pkt2\nresent\n0 1 2 3 4 5 6 7 8 9\nACK3 rcvd, nothing sent\n0 1 2 3 4 5 6 7 8 9X\n(loss)Sender Receiver\nFigure 3.26  \u2666 SR operation\n258     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nThe lack of synchronization between sender and receiver windows has impor -\ntant consequences when we are faced with the reality of a finite range of sequence \nnumbers. Consider what could happen, for example, with a finite range of four packet \nsequence numbers, 0, 1, 2, 3, and a window size of three. Suppose packets 0 through \n2 are transmitted and correctly received and acknowledged at the receiver. At this \npoint, the receiver\u2019s window is over the fourth, fifth, and sixth packets, which have \nsequence numbers 3, 0, and 1, respectively. Now consider two scenarios. In the first \nscenario, shown in Figure 3.27(a), the ACKs for the first three packets are lost and \nthe sender retransmits these packets. The receiver thus next receives a packet with \nsequence number 0\u2014a copy of the first packet sent.\nIn the second scenario, shown in Figure 3.27(b), the ACKs for the first three \npackets are all delivered correctly. The sender thus moves its window forward and \nsends the fourth, fifth, and sixth packets, with sequence numbers 3, 0, and 1, respec -\ntively. The packet with sequence number 3 is lost, but the packet with sequence \nnumber 0 arrives\u2014a packet containing new data.\nNow consider the receiver\u2019s viewpoint in Figure 3.27, which has a figurative \ncurtain between the sender and the receiver, since the receiver cannot \u201csee\u201d the \nactions taken by the sender. All the receiver observes is", "doc_id": "0ec9b492-9ff8-483a-8ff4-94e2785bcf85", "embedding": null, "doc_hash": "2d40d48c088bb3f3b37c219e13b96cd1cf3f7d4af5863dc089914620a6055381", "extra_info": null, "node_info": {"start": 744632, "end": 747707}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "47c1b622-256f-46df-ba92-7129b00109b6", "3": "22283e06-18b7-4678-886d-d07291bff80b"}}, "__type__": "1"}, "22283e06-18b7-4678-886d-d07291bff80b": {"__data__": {"text": "these packets. The receiver thus next receives a packet with \nsequence number 0\u2014a copy of the first packet sent.\nIn the second scenario, shown in Figure 3.27(b), the ACKs for the first three \npackets are all delivered correctly. The sender thus moves its window forward and \nsends the fourth, fifth, and sixth packets, with sequence numbers 3, 0, and 1, respec -\ntively. The packet with sequence number 3 is lost, but the packet with sequence \nnumber 0 arrives\u2014a packet containing new data.\nNow consider the receiver\u2019s viewpoint in Figure 3.27, which has a figurative \ncurtain between the sender and the receiver, since the receiver cannot \u201csee\u201d the \nactions taken by the sender. All the receiver observes is the sequence of messages \nit receives from the channel and sends into the channel. As far as it is concerned, \nthe two scenarios in Figure 3.27 are identical.  There is no way of distinguishing the \nretransmission of the first packet from an original transmission of the fifth packet. \nClearly, a window size that is 1 less than the size of the sequence number space \nwon\u2019t work. But how small must the window size be? A problem at the end of the \nchapter asks you to show that the window size must be less than or equal to half the \nsize of the sequence number space for SR protocols.\nAt the companion Web site, you will find an applet that animates the operation \nof the SR protocol. Try performing the same experiments that you did with the GBN \napplet. Do the results agree with what you expect?\nThis completes our discussion of reliable data transfer protocols. We\u2019ve covered \na lot of ground and introduced numerous mechanisms that together provide for reli -\nable data transfer. Table 3.1 summarizes these mechanisms. Now that we have seen \nall of these mechanisms in operation and can see the \u201cbig picture,\u201d we encourage you \nto review this section again to see how these mechanisms were incrementally added \nto cover increasingly complex (and realistic) models of the channel connecting the \nsender and receiver, or to improve the performance of the protocols.\nLet\u2019s conclude our discussion of reliable data transfer protocols by consider -\ning one remaining assumption in our underlying channel model. Recall that we \nhave assumed that packets cannot be reordered within the channel between the \nsender and receiver. This is generally a reasonable assumption when the sender and \nreceiver are connected by a single physical wire. However, when the \u201cchannel\u201d \nconnecting the two is a network, packet reordering can occur. One manifestation of \npacket reordering is that old copies of a packet with a sequence or acknowledgment \n3.4  \u2022  PRINCIPLES OF RELIABLE DATA TRANSFER      259\npkt0timeout\nretransmit pkt0\n0 1 2 3 0 1 2pkt0\npkt1\npkt20 1 2 3 0 1 2\n0 1 2 3 0 1 2\n0 1 2 3 0 1 20 1 2 3 0 1 2ACK0\nACK1\nACK2x0 1 2 3 0 1 2\n0 1 2 3 0 1 2Sender window\n(after receipt)\na.\nb.Receiver window\n(after receipt)\nreceive packet\nwith seq number 0\n0 1 2 3 0 1 2pkt0\npkt1\npkt2\npkt3\npkt00 1 2 3 0 1 2\n0 1 2 3 0 1 2\n0 1 2 3 0 1 20 1 2 3 0 1 2 ACK0\nACK1\nACK20 1 2 3 0 1 2\n0 1 2 3 0 1 2Sender window\n(after receipt)Receiver window\n(after receipt)\nreceive packet\nwith seq number 00 1 2 3 0 1 2x\nx\nx\nFigure 3.27  \u2666  SR receiver dilemma with too-large windows: A new packet \nor a retransmission?\n260     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nnumber of x can appear, even though neither the sender\u2019s nor the receiver\u2019s win", "doc_id": "22283e06-18b7-4678-886d-d07291bff80b", "embedding": null, "doc_hash": "d8795b1cbca9d06580c8197ff278e34f82ec1ef749d44e52a3aaf3beed2f14f7", "extra_info": null, "node_info": {"start": 747660, "end": 751071}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "0ec9b492-9ff8-483a-8ff4-94e2785bcf85", "3": "18ef4fdb-1970-481d-8d55-74f75accde8c"}}, "__type__": "1"}, "18ef4fdb-1970-481d-8d55-74f75accde8c": {"__data__": {"text": "0\n0 1 2 3 0 1 2pkt0\npkt1\npkt2\npkt3\npkt00 1 2 3 0 1 2\n0 1 2 3 0 1 2\n0 1 2 3 0 1 20 1 2 3 0 1 2 ACK0\nACK1\nACK20 1 2 3 0 1 2\n0 1 2 3 0 1 2Sender window\n(after receipt)Receiver window\n(after receipt)\nreceive packet\nwith seq number 00 1 2 3 0 1 2x\nx\nx\nFigure 3.27  \u2666  SR receiver dilemma with too-large windows: A new packet \nor a retransmission?\n260     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nnumber of x can appear, even though neither the sender\u2019s nor the receiver\u2019s win -\ndow contains x. With packet reordering, the channel can be thought of as essen -\ntially buffering packets and spontaneously emitting these packets at any point in \nthe future. Because sequence numbers may be reused, some care must be taken to \nguard against such duplicate packets. The approach taken in practice is to ensure \nthat a sequence number is not reused until the sender is \u201csure\u201d that any previously \nsent packets with sequence number x are no longer in the network. This is done \nby assuming that a packet cannot \u201clive\u201d in the network for longer than some fixed \nmaximum amount of time. A maximum packet lifetime of approximately three \nminutes is assumed in the TCP extensions for high-speed networks [RFC 1323]. \n[Sunshine 1978] describes a method for using sequence numbers such that reorder -\ning problems can be completely avoided.Table 3.1  \u2666 Summary of reliable data transfer mechanisms and their useMechanism Use, Comments\nChecksum Used to detect bit errors in a transmitted packet.\nTimer Used to timeout/retransmit a packet, possibly because the packet (or its ACK) \nwas lost within the channel. Because timeouts can occur when a packet is delayed \nbut not lost (premature timeout), or when a packet has been received by the \nreceiver but the receiver-to-sender ACK has been lost, duplicate copies of a packet \nmay be received by a receiver.\nSequence number Used for sequential numbering of packets of data flowing from sender to receiver. \nGaps in the sequence numbers of received packets allow the receiver to detect a \nlost packet. Packets with duplicate sequence numbers allow the receiver to detect \nduplicate copies of a packet.\nAcknowledgment Used by the receiver to tell the sender that a packet or set of packets has been \nreceived correctly. Acknowledgments will typically carry the sequence number of \nthe packet or packets being acknowledged. Acknowledgments may be individual \nor cumulative, depending on the protocol.\nNegative acknowledgment Used by the receiver to tell the sender that a packet has not been received \ncorrectly. Negative acknowledgments will typically carry the sequence number  \nof the packet that was not received correctly.\nWindow, pipelining The sender may be restricted to sending only packets with sequence numbers that \nfall within a given range. By allowing multiple packets to be transmitted but not \nyet acknowledged, sender utilization can be increased over a stop-and-wait mode \nof operation. We\u2019ll see shortly that the window size may be set on the basis of \nthe receiver\u2019s ability to receive and buffer messages, or the level of congestion in \nthe network, or both.\n3.5  \u2022  CONNECTION-ORIENTED TRANSPORT: TCP      261\n3.5 Connection-Oriented Transport: TCP\nNow that we have covered the underlying principles of reliable data transfer, \nlet\u2019s turn to TCP\u2014the Internet\u2019s transport-layer, connection-oriented, reliable \ntransport protocol. In this section, we\u2019ll see that in order to provide reliable \ndata transfer, TCP relies on many of the underlying principles discussed in \nthe previous section, including error detection, retransmissions, cumulative \nacknowledgments, timers, and header", "doc_id": "18ef4fdb-1970-481d-8d55-74f75accde8c", "embedding": null, "doc_hash": "710cc4e69b9caf3164375f50b517e61a51d6708e3ad031bdbb885ee7cb8908f7", "extra_info": null, "node_info": {"start": 751300, "end": 754921}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "22283e06-18b7-4678-886d-d07291bff80b", "3": "f7e7b774-111b-452a-a812-0e820b3fd651"}}, "__type__": "1"}, "f7e7b774-111b-452a-a812-0e820b3fd651": {"__data__": {"text": "that the window size may be set on the basis of \nthe receiver\u2019s ability to receive and buffer messages, or the level of congestion in \nthe network, or both.\n3.5  \u2022  CONNECTION-ORIENTED TRANSPORT: TCP      261\n3.5 Connection-Oriented Transport: TCP\nNow that we have covered the underlying principles of reliable data transfer, \nlet\u2019s turn to TCP\u2014the Internet\u2019s transport-layer, connection-oriented, reliable \ntransport protocol. In this section, we\u2019ll see that in order to provide reliable \ndata transfer, TCP relies on many of the underlying principles discussed in \nthe previous section, including error detection, retransmissions, cumulative \nacknowledgments, timers, and header fields for sequence and acknowledgment \nnumbers. TCP is defined in RFC 793, RFC 1122, RFC 1323, RFC 2018, and \nRFC 2581.\n3.5.1  The TCP Connection\nTCP is said to be connection-oriented  because before one application process can \nbegin to send data to another, the two processes must first \u201chandshake\u201d with each \nother\u2014that is, they must send some preliminary segments to each other to establish \nthe parameters of the ensuing data transfer. As part of TCP connection establish -\nment, both sides of the connection will initialize many TCP state variables (many of \nwhich will be discussed in this section and in Section 3.7) associated with the TCP \nconnection.\nThe TCP \u201cconnection\u201d is not an end-to-end TDM or FDM circuit as in a circuit-\nswitched network. Instead, the \u201cconnection\u201d is a logical one, with common state \nresiding only in the TCPs in the two communicating end systems. Recall that because \nthe TCP protocol runs only in the end systems and not in the intermediate network \nelements (routers and link-layer switches), the intermediate network elements do \nnot maintain TCP connection state. In fact, the intermediate routers are completely \noblivious to TCP connections; they see datagrams, not connections.\nA TCP connection provides a full-duplex service : If there is a TCP con -\nnection between Process A on one host and Process B on another host, then \napplication-layer data can flow from Process A to Process B at the same time \nas application-layer data flows from Process B to Process A. A TCP connec -\ntion is also always point-to-point , that is, between a single sender and a single \nreceiver. So-called \u201cmulticasting\u201d (see the online supplementary materials for \nthis text)\u2014the transfer of data from one sender to many receivers in a single \nsend operation\u2014is not possible with TCP. With TCP, two hosts are company \nand three are a crowd!\nLet\u2019s now take a look at how a TCP connection is established. Suppose a process \nrunning in one host wants to initiate a connection with another process in another \nhost. Recall that the process that is initiating the connection is called the client  \nprocess , while the other process is called the server process . The client application \nprocess first informs the client transport layer that it wants to establish a connection \n262     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nto a process in the server. Recall from Section 2.7.2, a Python client program does \nthis by issuing the command\nclientSocket.connect((serverName,serverPort))\nwhere serverName  is the name of the server and serverPort  identifies the \nprocess on the server. TCP in the client then proceeds to establish a TCP connec -\ntion with TCP in the server. At the end of this section we discuss in some detail the \nconnection-establishment procedure. For now it suffices to know that the client first \nsends a special TCP segment; the server responds with a second special TCP seg -\nment; and finally the client responds again with a third special segment. The first \ntwo segments carry no payload, that is, no application-layer data; the third of these \nsegments may carry a payload. Because three segments are sent between the two \nhosts, this", "doc_id": "f7e7b774-111b-452a-a812-0e820b3fd651", "embedding": null, "doc_hash": "9908c0cb573cc2152b68ae0d732d521d6355f8c540ebb237aa1bf2596e8fc715", "extra_info": null, "node_info": {"start": 754707, "end": 758562}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "18ef4fdb-1970-481d-8d55-74f75accde8c", "3": "fd4e72a8-a1e2-4a3e-a821-b896a92a3fbb"}}, "__type__": "1"}, "fd4e72a8-a1e2-4a3e-a821-b896a92a3fbb": {"__data__": {"text": "2.7.2, a Python client program does \nthis by issuing the command\nclientSocket.connect((serverName,serverPort))\nwhere serverName  is the name of the server and serverPort  identifies the \nprocess on the server. TCP in the client then proceeds to establish a TCP connec -\ntion with TCP in the server. At the end of this section we discuss in some detail the \nconnection-establishment procedure. For now it suffices to know that the client first \nsends a special TCP segment; the server responds with a second special TCP seg -\nment; and finally the client responds again with a third special segment. The first \ntwo segments carry no payload, that is, no application-layer data; the third of these \nsegments may carry a payload. Because three segments are sent between the two \nhosts, this connection-establishment procedure is often referred to as a three-way \nhandshake .VINTON CERF, ROBERT KAHN, AND TCP/IP\nIn the early 1970s, packet-switched networks began to proliferate, with the \nARPAnet\u2014the precursor of the Internet\u2014being just one of many networks. Each of \nthese networks had its own protocol. Two researchers, Vinton Cerf and Robert Kahn, \nrecognized the importance of interconnecting these networks and invented a cross-\nnetwork protocol called TCP/IP, which stands for Transmission Control Protocol/\nInternet Protocol. Although Cerf and Kahn began by seeing the protocol as a single \nentity, it was later split into its two parts, TCP and IP, which operated separately. \nCerf and Kahn published a paper on TCP/IP in May 1974 in IEEE Transactions on \nCommunications Technology  [Cerf 1974].\nThe TCP/IP protocol, which is the bread and butter of today\u2019s Internet, was \ndevised before PCs, workstations, smartphones, and tablets, before the prolifera -\ntion of Ethernet, cable, and DSL, WiFi, and other access network technologies, and \nbefore the Web, social media, and streaming video. Cerf and Kahn saw the need \nfor a networking protocol that, on the one hand, provides broad support for yet-to-\nbe-defined applications and, on the other hand, allows arbitrary hosts and link-layer \nprotocols to interoperate.\nIn 2004, Cerf and Kahn received the ACM\u2019s Turing Award, considered the \n\u201cNobel Prize of Computing\u201d for \u201cpioneering work on internetworking, including the \ndesign and implementation of the Internet\u2019s basic communications protocols, TCP/IP, \nand for inspired leadership in networking.\u201dCASE HISTORY\n\n3.5  \u2022  CONNECTION-ORIENTED TRANSPORT: TCP      263\nOnce a TCP connection is established, the two application processes can send \ndata to each other. Let\u2019s consider the sending of data from the client process to the \nserver process. The client process passes a stream of data through the socket (the \ndoor of the process), as described in Section 2.7. Once the data passes through the \ndoor, the data is in the hands of TCP running in the client. As shown in Figure 3.28, \nTCP directs this data to the connection\u2019s send buffer , which is one of the buffers that \nis set aside during the initial three-way handshake. From time to time, TCP will grab \nchunks of data from the send buffer and pass the data to the network layer. Interest -\ningly, the TCP specification [RFC 793] is very laid back about specifying when TCP \nshould actually send buffered data, stating that TCP should \u201csend that data in seg -\nments at its own convenience.\u201d The maximum amount of data that can be grabbed \nand placed in a segment is limited by the maximum segment size (MSS) . The MSS \nis typically set by first determining the length of the largest link-layer frame that \ncan be sent by the local sending host (the so-called maximum transmission unit, \nMTU ), and then setting the MSS to ensure that a TCP segment (when encapsulated \nin an IP", "doc_id": "fd4e72a8-a1e2-4a3e-a821-b896a92a3fbb", "embedding": null, "doc_hash": "31a1ad10b5e67a5520326cca9be51b2f8842dcb9d9d15fa2d3e32688f1f0344e", "extra_info": null, "node_info": {"start": 758482, "end": 762223}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "f7e7b774-111b-452a-a812-0e820b3fd651", "3": "bdfe6449-eae2-4f07-ac55-4bbb34ad4224"}}, "__type__": "1"}, "bdfe6449-eae2-4f07-ac55-4bbb34ad4224": {"__data__": {"text": "\nis set aside during the initial three-way handshake. From time to time, TCP will grab \nchunks of data from the send buffer and pass the data to the network layer. Interest -\ningly, the TCP specification [RFC 793] is very laid back about specifying when TCP \nshould actually send buffered data, stating that TCP should \u201csend that data in seg -\nments at its own convenience.\u201d The maximum amount of data that can be grabbed \nand placed in a segment is limited by the maximum segment size (MSS) . The MSS \nis typically set by first determining the length of the largest link-layer frame that \ncan be sent by the local sending host (the so-called maximum transmission unit, \nMTU ), and then setting the MSS to ensure that a TCP segment (when encapsulated \nin an IP datagram) plus the TCP/IP header length (typically 40 bytes) will fit into a \nsingle link-layer frame. Both Ethernet and PPP link-layer protocols have an MTU of \n1,500 bytes. Thus a typical value of MSS is 1460 bytes. Approaches have also been \nproposed for discovering the path MTU\u2014the largest link-layer frame that can be sent \non all links from source to destination [RFC 1191]\u2014and setting the MSS based on \nthe path MTU value. Note that the MSS is the maximum amount of application-layer \ndata in the segment, not the maximum size of the TCP segment including headers. \n(This terminology is confusing, but we have to live with it, as it is well entrenched.)\nTCP pairs each chunk of client data with a TCP header, thereby forming TCP \nsegments . The segments are passed down to the network layer, where they are sepa -\nrately encapsulated within network-layer IP datagrams. The IP datagrams are then \nsent into the network. When TCP receives a segment at the other end, the segment\u2019s \ndata is placed in the TCP connection\u2019s receive buffer, as shown in Figure 3.28. The \napplication reads the stream of data from this buffer. Each side of the connection has \nProcess\nwrites dataProcess\nreads data\nTCP\nsend\nbufferSocket\nTCP\nreceive\nbufferSocket\nSegment Segment\nFigure 3.28  \u2666 TCP send and receive buffers\n264     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nits own send buffer and its own receive buffer. (You can see the online flow-control \napplet at http://www.awl.com/kurose-ross, which provides an animation of the send \nand receive buffers.)\nWe see from this discussion that a TCP connection consists of buffers, variables, \nand a socket connection to a process in one host, and another set of buffers, vari -\nables, and a socket connection to a process in another host. As mentioned earlier, no \nbuffers or variables are allocated to the connection in the network elements (routers, \nswitches, and repeaters) between the hosts.\n3.5.2  TCP Segment Structure\nHaving taken a brief look at the TCP connection, let\u2019s examine the TCP segment \nstructure. The TCP segment consists of header fields and a data field. The data field \ncontains a chunk of application data. As mentioned above, the MSS limits the maxi -\nmum size of a segment\u2019s data field. When TCP sends a large file, such as an image \nas part of a Web page, it typically breaks the file into chunks of size MSS (except \nfor the last chunk, which will often be less than the MSS). Interactive applications, \nhowever, often transmit data chunks that are smaller than the MSS; for example, with \nremote login applications like Telnet, the data field in the TCP segment is often only \none byte. Because the TCP header is typically 20 bytes (12 bytes more than the UDP \nheader), segments sent by Telnet may be only 21 bytes in length.\nFigure 3. 29 shows the structure of the TCP segment. As with UDP, the header \nincludes source and destination port numbers , which are used for multiplexing/\ndemultiplexing data from/to", "doc_id": "bdfe6449-eae2-4f07-ac55-4bbb34ad4224", "embedding": null, "doc_hash": "37a923cef562a21ba0b414eee908e26efa48196d9ebad1214c18332892f36269", "extra_info": null, "node_info": {"start": 762259, "end": 765988}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "fd4e72a8-a1e2-4a3e-a821-b896a92a3fbb", "3": "701f12d9-8cfd-4dd5-81e4-4f94e93a3c6d"}}, "__type__": "1"}, "701f12d9-8cfd-4dd5-81e4-4f94e93a3c6d": {"__data__": {"text": "segment\u2019s data field. When TCP sends a large file, such as an image \nas part of a Web page, it typically breaks the file into chunks of size MSS (except \nfor the last chunk, which will often be less than the MSS). Interactive applications, \nhowever, often transmit data chunks that are smaller than the MSS; for example, with \nremote login applications like Telnet, the data field in the TCP segment is often only \none byte. Because the TCP header is typically 20 bytes (12 bytes more than the UDP \nheader), segments sent by Telnet may be only 21 bytes in length.\nFigure 3. 29 shows the structure of the TCP segment. As with UDP, the header \nincludes source and destination port numbers , which are used for multiplexing/\ndemultiplexing data from/to upper-layer applications. Also, as with UDP, the header \nincludes a checksum field . A TCP segment header also contains the following fields:\n\u2022 The 32-bit sequence number field  and the 32-bit acknowledgment number \nfield  are used by the TCP sender and receiver in implementing a reliable data \ntransfer service, as discussed below.\n\u2022 The 16-bit receive window  field is used for flow control. We will see shortly that \nit is used to indicate the number of bytes that a receiver is willing to accept.\n\u2022 The 4-bit header length field  specifies the length of the TCP header in 32-bit \nwords. The TCP header can be of variable length due to the TCP options field. \n(Typically, the options field is empty, so that the length of the typical TCP header \nis 20 bytes.)\n\u2022 The optional and variable-length options field  is used when a sender and receiver \nnegotiate the maximum segment size (MSS) or as a window scaling factor for use \nin high-speed networks. A time-stamping option is also defined. See RFC 854 \nand RFC 1323 for additional details.\n\u2022 The flag field  contains 6 bits. The ACK bit  is used to indicate that the value \ncarried in the acknowledgment field is valid; that is, the segment contains an \nacknowledgment for a segment that has been successfully received. The RST , \n3.5  \u2022  CONNECTION-ORIENTED TRANSPORT: TCP      265\nSYN , and FIN bits are used for connection setup and teardown, as we will discuss \nat the end of this section. The CWR and ECE bits are used in explicit congestion \nnotification , as discussed in Section 3.7.2 . Setting the PSH  bit indicates that the \nreceiver should pass the data to the upper layer immediately. Finally, the URG  bit \nis used to indicate that there is data in this segment that the sending-side upper-\nlayer entity has marked as \u201curgent.\u201d The location of the last byte of this urgent \ndata is indicated by the 16-bit urgent data pointer field . TCP must inform the \nreceiving-side upper-layer entity when urgent data exists and pass it a pointer to \nthe end of the urgent data. (In practice, the PSH, URG, and the urgent data pointer \nare not used. However, we mention these fields for completeness.)\nOur experience as teachers is that our students sometimes find discussion of \npacket formats rather dry and perhaps a bit boring. For a fun and fanciful look at \nTCP header fields, particularly if you love Legos\u2122 as we do, see [Pomeranz 2010].\nSequence Numbers and Acknowledgment Numbers\nTwo of the most important fields in the TCP segment header are the sequence number \nfield and the acknowledgment number field. These fields are a critical part of TCP\u2019s \nreliable data transfer service. But before discussing how these fields are used to pro -\nvide reliable data transfer, let us first explain what exactly TCP puts in these fields.Source port #\nInternet checksumHeader\nlengthUnused\nURGECECWR\nACK\nPSH\nRST\nSYN\nFIN32 bits\nDest port #\nReceive window\nUrgent data pointerSequence number\nAcknowledgment number\nOptions\nData\nFigure 3.29  \u2666 TCP segment structure\n266     CHAPTER 3", "doc_id": "701f12d9-8cfd-4dd5-81e4-4f94e93a3c6d", "embedding": null, "doc_hash": "777c8d6bbf74cfb79339ee2e96551645beb64843e2ac0c9c94545ad047f428f2", "extra_info": null, "node_info": {"start": 765995, "end": 769777}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "bdfe6449-eae2-4f07-ac55-4bbb34ad4224", "3": "54c76691-f270-41f7-8d50-b8367fb52902"}}, "__type__": "1"}, "54c76691-f270-41f7-8d50-b8367fb52902": {"__data__": {"text": "fanciful look at \nTCP header fields, particularly if you love Legos\u2122 as we do, see [Pomeranz 2010].\nSequence Numbers and Acknowledgment Numbers\nTwo of the most important fields in the TCP segment header are the sequence number \nfield and the acknowledgment number field. These fields are a critical part of TCP\u2019s \nreliable data transfer service. But before discussing how these fields are used to pro -\nvide reliable data transfer, let us first explain what exactly TCP puts in these fields.Source port #\nInternet checksumHeader\nlengthUnused\nURGECECWR\nACK\nPSH\nRST\nSYN\nFIN32 bits\nDest port #\nReceive window\nUrgent data pointerSequence number\nAcknowledgment number\nOptions\nData\nFigure 3.29  \u2666 TCP segment structure\n266     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nTCP views data as an unstructured, but ordered, stream of bytes. TCP\u2019s use of \nsequence numbers reflects this view in that sequence numbers are over the stream \nof transmitted bytes and not over the series of transmitted segments. The sequence \nnumber for a segment  is therefore the byte-stream number of the first byte in the \nsegment. Let\u2019s look at an example. Suppose that a process in Host A wants to send a \nstream of data to a process in Host B over a TCP connection. The TCP in Host A will \nimplicitly number each byte in the data stream. Suppose that the data stream consists \nof a file consisting of 500,000 bytes, that the MSS is 1,000 bytes, and that the first \nbyte of the data stream is numbered 0. As shown in Figure 3.30, TCP constructs 500 \nsegments out of the data stream. The first segment gets assigned sequence number \n0, the second segment gets assigned sequence number 1,000, the third segment gets \nassigned sequence number 2,000, and so on. Each sequence number is inserted in the \nsequence number field in the header of the appropriate TCP segment.\nNow let\u2019s consider acknowledgment numbers. These are a little trickier than \nsequence numbers. Recall that TCP is full-duplex, so that Host A may be receiving \ndata from Host B while it sends data to Host B (as part of the same TCP connection). \nEach of the segments that arrive from Host B has a sequence number for the data \nflowing from B to A. The acknowledgment number that Host A puts in its segment \nis the sequence number of the next byte Host A is expecting from Host B.  It is good \nto look at a few examples to understand what is going on here. Suppose that Host A \nhas received all bytes numbered 0 through 535 from B and suppose that it is about \nto send a segment to Host B. Host A is waiting for byte 536 and all the subsequent \nbytes in Host B\u2019s data stream. So Host A puts 536 in the acknowledgment number \nfield of the segment it sends to B.\nAs another example, suppose that Host A has received one segment from Host \nB containing bytes 0 through 535 and another segment containing bytes 900 through \n1,000. For some reason Host A has not yet received bytes 536 through 899. In this \nexample, Host A is still waiting for byte 536 (and beyond) in order to re-create B\u2019s \ndata stream. Thus, A\u2019s next segment to B will contain 536 in the acknowledgment \nnumber field. Because TCP only acknowledges bytes up to the first missing byte in \nthe stream, TCP is said to provide cumulative acknowledgments .01 1,000 1,999 499,999File\nData for 1st segment Data for 2nd segment\nFigure 3.30  \u2666 Dividing file data into TCP segments\n3.5  \u2022  CONNECTION-ORIENTED TRANSPORT: TCP      267\nThis last example also brings up an important but subtle issue. Host A received \nthe third segment (bytes 900 through 1,000) before receiving the second segment \n(bytes 536 through 899). Thus, the third segment arrived out of order. The sub -\ntle issue is: What does a host do when it receives out-of-order segments in a TCP \nconnection?", "doc_id": "54c76691-f270-41f7-8d50-b8367fb52902", "embedding": null, "doc_hash": "8acab53b15d76a1b433897faf0eaa44388e212d310a3448d2f9f6eb270e2bc20", "extra_info": null, "node_info": {"start": 769769, "end": 773523}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "701f12d9-8cfd-4dd5-81e4-4f94e93a3c6d", "3": "f88163e5-65fb-40ce-90ed-fb2ea2cbc5fb"}}, "__type__": "1"}, "f88163e5-65fb-40ce-90ed-fb2ea2cbc5fb": {"__data__": {"text": "acknowledgment \nnumber field. Because TCP only acknowledges bytes up to the first missing byte in \nthe stream, TCP is said to provide cumulative acknowledgments .01 1,000 1,999 499,999File\nData for 1st segment Data for 2nd segment\nFigure 3.30  \u2666 Dividing file data into TCP segments\n3.5  \u2022  CONNECTION-ORIENTED TRANSPORT: TCP      267\nThis last example also brings up an important but subtle issue. Host A received \nthe third segment (bytes 900 through 1,000) before receiving the second segment \n(bytes 536 through 899). Thus, the third segment arrived out of order. The sub -\ntle issue is: What does a host do when it receives out-of-order segments in a TCP \nconnection? Interestingly, the TCP RFCs do not impose any rules here and leave \nthe decision up to the programmers implementing a TCP implementation. There \nare basically two choices: either (1) the receiver immediately discards out-of-order \nsegments (which, as we discussed earlier, can simplify receiver design), or (2) the \nreceiver keeps the out-of-order bytes and waits for the missing bytes to fill in the \ngaps. Clearly, the latter choice is more efficient in terms of network bandwidth, and \nis the approach taken in practice.\nIn Figure 3.30, we assumed that the initial sequence number was zero. In truth, \nboth sides of a TCP connection randomly choose an initial sequence number. This \nis done to minimize the possibility that a segment that is still present in the network \nfrom an earlier, already-terminated connection between two hosts is mistaken for a \nvalid segment in a later connection between these same two hosts (which also happen \nto be using the same port numbers as the old connection) [Sunshine 1978].\nTelnet: A Case Study for Sequence and Acknowledgment Numbers\nTelnet, defined in RFC 854, is a popular application-layer protocol used for remote \nlogin. It runs over TCP and is designed to work between any pair of hosts. Unlike the \nbulk data transfer applications discussed in Chapter 2, Telnet is an interactive appli -\ncation. We discuss a Telnet example here, as it nicely illustrates TCP sequence and \nacknowledgment numbers. We note that many users now prefer to use the SSH proto -\ncol rather than Telnet, since data sent in a Telnet connection (including passwords!) \nare not encrypted, making Telnet vulnerable to eavesdropping attacks (as discussed \nin Section 8.7).\nSuppose Host A initiates a Telnet session with Host B. Because Host A initiates \nthe session, it is labeled the client, and Host B is labeled the server. Each character \ntyped by the user (at the client) will be sent to the remote host; the remote host will \nsend back a copy of each character, which will be displayed on the Telnet user\u2019s \nscreen. This \u201cecho back\u201d is used to ensure that characters seen by the Telnet user \nhave already been received and processed at the remote site. Each character thus \ntraverses the network twice between the time the user hits the key and the time the \ncharacter is displayed on the user\u2019s monitor.\nNow suppose the user types a single letter, \u2018C,\u2019 and then grabs a coffee. Let\u2019s \nexamine the TCP segments that are sent between the client and server. As shown \nin Figure 3.31, we suppose the starting sequence numbers are 42 and 79 for the cli -\nent and server, respectively. Recall that the sequence number of a segment is the \nsequence number of the first byte in the data field. Thus, the first segment sent from \nthe client will have sequence number 42; the first segment sent from the server will \nhave sequence number 79. Recall that the acknowledgment number is the sequence \n268     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nnumber of the next byte of data that the host is waiting for. After the TCP connec -\ntion is established but before any data is sent, the client is waiting for byte 79 and the \nserver is waiting for byte 42.\nAs shown in", "doc_id": "f88163e5-65fb-40ce-90ed-fb2ea2cbc5fb", "embedding": null, "doc_hash": "465ffbd0b248330c1ace16e8c3648010f3032207a38dd0486336a1ec5443573a", "extra_info": null, "node_info": {"start": 773593, "end": 777442}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "54c76691-f270-41f7-8d50-b8367fb52902", "3": "bc68ceb6-55c2-4100-b8eb-1b06b3ced4f5"}}, "__type__": "1"}, "bc68ceb6-55c2-4100-b8eb-1b06b3ced4f5": {"__data__": {"text": "\nexamine the TCP segments that are sent between the client and server. As shown \nin Figure 3.31, we suppose the starting sequence numbers are 42 and 79 for the cli -\nent and server, respectively. Recall that the sequence number of a segment is the \nsequence number of the first byte in the data field. Thus, the first segment sent from \nthe client will have sequence number 42; the first segment sent from the server will \nhave sequence number 79. Recall that the acknowledgment number is the sequence \n268     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nnumber of the next byte of data that the host is waiting for. After the TCP connec -\ntion is established but before any data is sent, the client is waiting for byte 79 and the \nserver is waiting for byte 42.\nAs shown in Figure 3.31, three segments are sent. The first segment is sent from \nthe client to the server, containing the 1-byte ASCII representation of the letter \u2018C\u2019 in \nits data field. This first segment also has 42 in its sequence number field, as we just \ndescribed. Also, because the client has not yet received any data from the server, this \nfirst segment will have 79 in its acknowledgment number field.\nThe second segment is sent from the server to the client. It serves a dual purpose. \nFirst it provides an acknowledgment of the data the server has received. By putting \n43 in the acknowledgment field, the server is telling the client that it has successfully \nreceived everything up through byte 42 and is now waiting for bytes 43 onward. The \nsecond purpose of this segment is to echo back the letter \u2018C.\u2019 Thus, the second seg -\nment has the ASCII representation of \u2018C\u2019 in its data field. This second segment has \nthe sequence number 79, the initial sequence number of the server-to-client data flow \nof this TCP connection, as this is the very first byte of data that the server is send -\ning. Note that the acknowledgment for client-to-server data is carried in a segment Time TimeHost A Host B\nUser types\n'C'Seq=42, ACK=79, data='C'\nSeq=79, ACK=43, data='C'\nSeq=43, ACK=80Host ACKs\nreceipt of 'C',\nechoes back 'C'\nHost ACKs\nreceipt of\nechoed 'C'\nFigure 3.31  \u2666  Sequence and acknowledgment numbers for a simple Telnet \napplication over TCP\n3.5  \u2022  CONNECTION-ORIENTED TRANSPORT: TCP      269\ncarrying server-to-client data; this acknowledgment is said to be piggybacked  on the \nserver-to-client data segment.\nThe third segment is sent from the client to the server. Its sole purpose is to \nacknowledge the data it has received from the server. (Recall that the second seg -\nment contained data\u2014the letter \u2018C\u2019\u2014from the server to the client.) This segment \nhas an empty data field (that is, the acknowledgment is not being piggybacked with \nany client-to-server data). The segment has 80 in the acknowledgment number field \nbecause the client has received the stream of bytes up through byte sequence number \n79 and it is now waiting for bytes 80 onward. You might think it odd that this seg -\nment also has a sequence number since the segment contains no data. But because \nTCP has a sequence number field, the segment needs to have some sequence number.\n3.5.3  Round-Trip Time Estimation and Timeout\nTCP, like our rdt protocol in Section 3.4, uses a timeout/retransmit mechanism to \nrecover from lost segments. Although this is conceptually simple, many subtle issues \narise when we implement a timeout/retransmit mechanism in an actual protocol such \nas TCP. Perhaps the most obvious question is the length of the timeout intervals. \nClearly, the timeout should be larger than the connection\u2019s round-trip time (RTT), \nthat is, the time from when a segment is sent until it is acknowledged. Otherwise, \nunnecessary retransmissions would be sent. But how much larger? How should the \nRTT be", "doc_id": "bc68ceb6-55c2-4100-b8eb-1b06b3ced4f5", "embedding": null, "doc_hash": "0079b55403842ae74888f3fb94e635b47ed431a84212151fe129815dd97f6af0", "extra_info": null, "node_info": {"start": 777380, "end": 781141}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "f88163e5-65fb-40ce-90ed-fb2ea2cbc5fb", "3": "60690e63-973a-4d9b-80ab-3658fa56eabc"}}, "__type__": "1"}, "60690e63-973a-4d9b-80ab-3658fa56eabc": {"__data__": {"text": "segment contains no data. But because \nTCP has a sequence number field, the segment needs to have some sequence number.\n3.5.3  Round-Trip Time Estimation and Timeout\nTCP, like our rdt protocol in Section 3.4, uses a timeout/retransmit mechanism to \nrecover from lost segments. Although this is conceptually simple, many subtle issues \narise when we implement a timeout/retransmit mechanism in an actual protocol such \nas TCP. Perhaps the most obvious question is the length of the timeout intervals. \nClearly, the timeout should be larger than the connection\u2019s round-trip time (RTT), \nthat is, the time from when a segment is sent until it is acknowledged. Otherwise, \nunnecessary retransmissions would be sent. But how much larger? How should the \nRTT be estimated in the first place? Should a timer be associated with each and \nevery unacknowledged segment? So many questions! Our discussion in this section \nis based on the TCP work in [Jacobson 1988] and the current IETF recommendations \nfor managing TCP timers [RFC 6298].\nEstimating the Round-Trip Time\nLet\u2019s begin our study of TCP timer management by considering how TCP estimates \nthe round-trip time between sender and receiver. This is accomplished as follows. \nThe sample RTT, denoted SampleRTT , for a segment is the amount of time between \nwhen the segment is sent (that is, passed to IP) and when an acknowledgment for \nthe segment is received. Instead of measuring a SampleRTT  for every transmitted \nsegment, most TCP implementations take only one SampleRTT  measurement at \na time. That is, at any point in time, the SampleRTT  is being estimated for only \none of the transmitted but currently unacknowledged segments, leading to a new \nvalue of SampleRTT  approximately once every RTT. Also, TCP never computes a  \nSampleRTT  for a segment that has been retransmitted; it only measures  \nSampleRTT  for segments that have been transmitted once [Karn 1987]. (A problem \nat the end of the chapter asks you to consider why.)\nObviously, the SampleRTT  values will fluctuate from segment to segment due \nto congestion in the routers and to the varying load on the end systems. Because of \nthis fluctuation, any given SampleRTT  value may be atypical. In order to estimate \n270     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\na typical RTT, it is therefore natural to take some sort of average of the SampleRTT  \nvalues. TCP maintains an average, called EstimatedRTT , of the SampleRTT  \nvalues. Upon obtaining a new SampleRTT , TCP updates EstimatedRTT  accord -\ning to the following formula:\nEstimatedRTT  = (1 \u2013 \u03b1) # EstimatedRTT  + \u03b1 # SampleRTT\nThe formula above is written in the form of a programming-language state -\nment\u2014the new value of EstimatedRTT  is a weighted combination of the previous \nvalue of EstimatedRTT  and the new value for SampleRTT . The recommended \nvalue of \u03b1 is \u03b1 = 0.125 (that is, 1/8) [RFC 6298], in which case the formula above \nbecomes:\nEstimatedRTT  = 0.875  # EstimatedRTT  + 0.125  # SampleRTT\nNote that EstimatedRTT  is a weighted average of the SampleRTT  values. As \ndiscussed in a homework problem at the end of this chapter, this weighted average \nputs more weight on recent samples than on old samples. This is natural, as the more \nrecent samples better reflect the current congestion in the network. In statistics, such \nan average is called an exponential weighted moving average (EWMA) . The word \n\u201cexponential\u201d appears in EWMA because the weight of a given SampleRTT  decays \nexponentially fast as the updates proceed. In the homework problems you will be \nasked to derive the exponential term in EstimatedRTT .\nFigure 3. 32 shows the SampleRTT  values and", "doc_id": "60690e63-973a-4d9b-80ab-3658fa56eabc", "embedding": null, "doc_hash": "f0c2f70d39f9705bae971548807b5546a3ce2870b85b3000347bc12715590ddf", "extra_info": null, "node_info": {"start": 781127, "end": 784783}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "bc68ceb6-55c2-4100-b8eb-1b06b3ced4f5", "3": "7c92a40b-749f-4220-aa2a-456cbcc16922"}}, "__type__": "1"}, "7c92a40b-749f-4220-aa2a-456cbcc16922": {"__data__": {"text": " = 0.875  # EstimatedRTT  + 0.125  # SampleRTT\nNote that EstimatedRTT  is a weighted average of the SampleRTT  values. As \ndiscussed in a homework problem at the end of this chapter, this weighted average \nputs more weight on recent samples than on old samples. This is natural, as the more \nrecent samples better reflect the current congestion in the network. In statistics, such \nan average is called an exponential weighted moving average (EWMA) . The word \n\u201cexponential\u201d appears in EWMA because the weight of a given SampleRTT  decays \nexponentially fast as the updates proceed. In the homework problems you will be \nasked to derive the exponential term in EstimatedRTT .\nFigure 3. 32 shows the SampleRTT  values and EstimatedRTT  for a value \nof \u03b1 = 1/8 for a TCP connection between gaia.cs.umass.edu  (in Amherst, \nMassachusetts) to fantasia.eurecom.fr  (in the south of France). Clearly, \nthe variations in the SampleRTT  are smoothed out in the computation of the \nEstimatedRTT .\nIn addition to having an estimate of the RTT, it is also valuable to have a meas-\nure of the variability of the RTT. [RFC 6298] defines the RTT variation, DevRTT , \nas an estimate of how much SampleRTT  typically deviates from EstimatedRTT :\nDevRTT  = (1 \u2013 \u03b2) # DevRTT  + \u03b2 # | SampleRTT  \u2013 EstimatedRTT  |\nNote that DevRTT  is an EWMA of the difference between SampleRTT  and \nEstimatedRTT . If the SampleRTT  values have little fluctuation, then DevRTT  \nwill be small; on the other hand, if there is a lot of fluctuation, DevRTT  will be large. \nThe recommended value of \u03b2 is 0.25.\nSetting and Managing the Retransmission Timeout Interval\nGiven values of EstimatedRTT  and DevRTT , what value should be used for \nTCP\u2019s timeout interval? Clearly, the interval should be greater than or equal to  \n3.5  \u2022  CONNECTION-ORIENTED TRANSPORT: TCP      271\nEstimatedRTT , or unnecessary retransmissions would be sent. But the timeout \ninterval should not be too much larger than EstimatedRTT ; otherwise, when a \nsegment is lost, TCP would not quickly retransmit the segment, leading to large  \ndata transfer delays. It is therefore desirable to set the timeout equal to the  \nEstimatedRTT  plus some margin. The margin should be large when there is a lot \nof fluctuation in the SampleRTT  values; it should be small when there is little fluc -\ntuation. The value of DevRTT  should thus come into play here. All of these consid -\nerations are taken into account in TCP\u2019s method for determining the retransmission \ntimeout interval:\nTimeoutInterval  = EstimatedRTT  + 4 # DevRTT\nAn initial TimeoutInterval  value of 1 second is recommended [RFC \n6298]. Also, when a timeout occurs, the value of TimeoutInterval  is doubled \nto avoid a premature timeout occurring for a subsequent segment that will soon be \nacknowledged. However, as soon as a segment is received and EstimatedRTT  is \nupdated, the TimeoutInterval  is again computed using the formula above.TCP provides reliable data transfer by using positive acknowledgments and timers in much \nthe same way that we studied in Section 3.4. TCP acknowledges data that has been \nreceived correctly, and it then retransmits segments when segments or their corresponding \nacknowledgments are thought to be lost or corrupted. Certain versions of TCP also have \nan implicit NAK mechanism\u2014with TCP\u2019s fast retransmit mechanism, the receipt of three \nduplicate ACKs for a given segment serves as an implicit NAK for the following segment, \ntriggering retransmission of that segment before timeout. TCP uses sequences of numbers to \nallow the receiver to", "doc_id": "7c92a40b-749f-4220-aa2a-456cbcc16922", "embedding": null, "doc_hash": "4e4a49cf81d31da5e9ced8feb3e980cf4006dba3dbdbe7c8173649e08d7d9f50", "extra_info": null, "node_info": {"start": 784826, "end": 788403}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "60690e63-973a-4d9b-80ab-3658fa56eabc", "3": "0f96876f-ba61-4a33-a309-06399c8eee17"}}, "__type__": "1"}, "0f96876f-ba61-4a33-a309-06399c8eee17": {"__data__": {"text": "a segment is received and EstimatedRTT  is \nupdated, the TimeoutInterval  is again computed using the formula above.TCP provides reliable data transfer by using positive acknowledgments and timers in much \nthe same way that we studied in Section 3.4. TCP acknowledges data that has been \nreceived correctly, and it then retransmits segments when segments or their corresponding \nacknowledgments are thought to be lost or corrupted. Certain versions of TCP also have \nan implicit NAK mechanism\u2014with TCP\u2019s fast retransmit mechanism, the receipt of three \nduplicate ACKs for a given segment serves as an implicit NAK for the following segment, \ntriggering retransmission of that segment before timeout. TCP uses sequences of numbers to \nallow the receiver to identify lost or duplicate segments. Just as in the case of our reliable \ndata transfer protocol, rdt3.0 , TCP cannot itself tell for certain if a segment, or its ACK, is \nlost, corrupted, or overly delayed. At the sender, TCP\u2019s response will be the same: retrans -\nmit the segment in question.\nTCP also uses pipelining, allowing the sender to have multiple transmitted but yet-to-\nbe-acknowledged segments outstanding at any given time. We saw earlier that pipelining \ncan greatly improve a session\u2019s throughput when the ratio of the segment size to round-\ntrip delay is small. The specific number of outstanding, unacknowledged segments that a \nsender can have is determined by TCP\u2019s flow-control and congestion-control mechanisms. \nTCP flow control is discussed at the end of this section; TCP congestion control is discussed \nin Section 3.7. For the time being, we must simply be aware that the TCP sender uses \npipelining.PRINCIPLES IN PRACTICE\n\n272     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\n3.5.4  Reliable Data Transfer\nRecall that the Internet\u2019s network-layer service (IP service) is unreliable. IP does \nnot guarantee datagram delivery, does not guarantee in-order delivery of datagrams, \nand does not guarantee the integrity of the data in the datagrams. With IP service, \ndatagrams can overflow router buffers and never reach their destination, datagrams \ncan arrive out of order, and bits in the datagram can get corrupted (flipped from 0 to \n1 and vice versa). Because transport-layer segments are carried across the network \nby IP datagrams, transport-layer segments can suffer from these problems as well.\nTCP creates a reliable data transfer service  on top of IP\u2019s unreliable best-\neffort service. TCP\u2019s reliable data transfer service ensures that the data stream that \na process reads out of its TCP receive buffer is uncorrupted, without gaps, with -\nout duplication, and in sequence; that is, the byte stream is exactly the same byte \nstream that was sent by the end system on the other side of the connection. How TCP \nprovides a reliable data transfer involves many of the principles that we studied in  \nSection 3.4.\nIn our earlier development of reliable data transfer techniques, it was conceptu -\nally easiest to assume that an individual timer is associated with each transmitted \nbut not yet acknowledged segment. While this is great in theory, timer management \ncan require considerable overhead. Thus, the recommended TCP timer management RTT (milliseconds)\n150200250300350\n100\n18 15 22 29 36 43 50\nTime (seconds)Sample RTT\n57 64 71 78 85 92 99 106Estimated RTT\nFigure 3.32  \u2666 RTT samples and RTT estimates\n3.5  \u2022  CONNECTION-ORIENTED TRANSPORT: TCP      273\nprocedures [RFC 6298] use only a single  retransmission timer, even if there are mul -\ntiple transmitted but not yet acknowledged segments. The TCP protocol described in \nthis section follows this single-timer", "doc_id": "0f96876f-ba61-4a33-a309-06399c8eee17", "embedding": null, "doc_hash": "1d8fe19acb2b4b2189b2107d7ec33f81857df77fe26dfec10879fd8858e526b2", "extra_info": null, "node_info": {"start": 788361, "end": 792010}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "7c92a40b-749f-4220-aa2a-456cbcc16922", "3": "66dd6657-7c1e-4ed7-9c1f-1ea7e2c6e4c0"}}, "__type__": "1"}, "66dd6657-7c1e-4ed7-9c1f-1ea7e2c6e4c0": {"__data__": {"text": "conceptu -\nally easiest to assume that an individual timer is associated with each transmitted \nbut not yet acknowledged segment. While this is great in theory, timer management \ncan require considerable overhead. Thus, the recommended TCP timer management RTT (milliseconds)\n150200250300350\n100\n18 15 22 29 36 43 50\nTime (seconds)Sample RTT\n57 64 71 78 85 92 99 106Estimated RTT\nFigure 3.32  \u2666 RTT samples and RTT estimates\n3.5  \u2022  CONNECTION-ORIENTED TRANSPORT: TCP      273\nprocedures [RFC 6298] use only a single  retransmission timer, even if there are mul -\ntiple transmitted but not yet acknowledged segments. The TCP protocol described in \nthis section follows this single-timer recommendation.\nWe will discuss how TCP provides reliable data transfer in two incremental \nsteps. We first present a highly simplified description of a TCP sender that uses only \ntimeouts to recover from lost segments; we then present a more complete description \nthat uses duplicate acknowledgments in addition to timeouts. In the ensuing discus -\nsion, we suppose that data is being sent in only one direction, from Host A to Host B, \nand that Host A is sending a large file.\nFigure 3. 33 presents a highly simplified description of a TCP sender. We see \nthat there are three major events related to data transmission and retransmission \nin the TCP sender: data received from application above; timer timeout; and ACK \n/* Assume sender is not constrained by TCP \ufb02ow or congestion control, that data from above is less\nthan MSS in size, and that data transfer is in one direction only. */\nNextSeqNum=InitialSeqNumber\nSendBase=InitialSeqNumber\nloop (forever) {\nswitch(event)\nevent: data received from application above\ncreate TCP segment with sequence number NextSeqNum\nif (timer currently not running)\nstart timer\npass segment to IP\nNextSeqNum=NextSeqNum+length(data)\nbreak;\nevent: timer timeout\nretransmit not-yet-acknowledged segment with\nsmallest sequence number\nstart timer\nbreak;\nevent: ACK received, with ACK \ufb01eld value of y\nif (y > SendBase) {\nSendBase=y\nif (there are currently any not-yet-acknowledged segments)\nstart timer\n}\nbreak;\n} /* end of loop forever */\nFigure 3.33  \u2666 Simplified TCP sender\n274     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nreceipt. Upon the occurrence of the first major event, TCP receives data from the \napplication, encapsulates the data in a segment, and passes the segment to IP. Note \nthat each segment includes a sequence number that is the byte-stream number of \nthe first data byte in the segment, as described in Section 3.5.2. Also note that if the \ntimer is already not running for some other segment, TCP starts the timer when the \nsegment is passed to IP. (It is helpful to think of the timer as being associated with \nthe oldest unacknowledged segment.) The expiration interval for this timer is the \nTimeoutInterval , which is calculated from EstimatedRTT  and DevRTT , as \ndescribed in Section 3.5.3.\nThe second major event is the timeout. TCP responds to the timeout event by \nretransmitting the segment that caused the timeout. TCP then restarts the timer.\nThe third major event that must be handled by the TCP sender is the arrival of \nan acknowledgment segment (ACK) from the receiver (more specifically, a segment \ncontaining a valid ACK field value). On the occurrence of this event, TCP compares \nthe ACK value y with its variable SendBase . The TCP state variable SendBase  \nis the sequence number of the oldest unacknowledged byte. (Thus SendBase\u20131  is \nthe sequence number of the last byte that is known to have been received correctly \nand in order at the receiver.) As indicated earlier, TCP uses cumulative acknowl -\nedgments, so that y acknowledges", "doc_id": "66dd6657-7c1e-4ed7-9c1f-1ea7e2c6e4c0", "embedding": null, "doc_hash": "ef02dbdc2b16d03ff6b9223055930857c3f05f82a2b805348be1ff8353e61a83", "extra_info": null, "node_info": {"start": 792070, "end": 795763}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "0f96876f-ba61-4a33-a309-06399c8eee17", "3": "029f66e3-9a64-4565-8628-06604c6c38c5"}}, "__type__": "1"}, "029f66e3-9a64-4565-8628-06604c6c38c5": {"__data__": {"text": "second major event is the timeout. TCP responds to the timeout event by \nretransmitting the segment that caused the timeout. TCP then restarts the timer.\nThe third major event that must be handled by the TCP sender is the arrival of \nan acknowledgment segment (ACK) from the receiver (more specifically, a segment \ncontaining a valid ACK field value). On the occurrence of this event, TCP compares \nthe ACK value y with its variable SendBase . The TCP state variable SendBase  \nis the sequence number of the oldest unacknowledged byte. (Thus SendBase\u20131  is \nthe sequence number of the last byte that is known to have been received correctly \nand in order at the receiver.) As indicated earlier, TCP uses cumulative acknowl -\nedgments, so that y acknowledges the receipt of all bytes before byte number y. If  \ny > SendBase , then the ACK is acknowledging one or more previously unac -\nknowledged segments. Thus the sender updates its SendBase  variable; it also \nrestarts the timer if there currently are any not-yet-acknowledged segments.\nA Few Interesting Scenarios\nWe have just described a highly simplified version of how TCP provides reliable data \ntransfer. But even this highly simplified version has many subtleties. To get a good \nfeeling for how this protocol works, let\u2019s now walk through a few simple scenarios. \nFigure 3. 34 depicts the first scenario, in which Host A sends one segment to Host B. \nSuppose that this segment has sequence number 92 and contains 8 bytes of data. After \nsending this segment, Host A waits for a segment from B with acknowledgment num -\nber 100. Although the segment from A is received at B, the acknowledgment from B \nto A gets lost. In this case, the timeout event occurs, and Host A retransmits the same \nsegment. Of course, when Host B receives the retransmission, it observes from the \nsequence number that the segment contains data that has already been received. Thus, \nTCP in Host B will discard the bytes in the retransmitted segment.\nIn a second scenario, shown in Figure 3.35, Host A sends two segments back to \nback. The first segment has sequence number 92 and 8 bytes of data, and the second \nsegment has sequence number 100 and 20 bytes of data. Suppose that both segments \narrive intact at B, and B sends two separate acknowledgments for each of these seg -\nments. The first of these acknowledgments has acknowledgment number 100; the \nsecond has acknowledgment number 120. Suppose now that neither of the acknowl -\nedgments arrives at Host A before the timeout. When the timeout event occurs, Host \n3.5  \u2022  CONNECTION-ORIENTED TRANSPORT: TCP      275\nA resends the first segment with sequence number 92 and restarts the timer. As long \nas the ACK for the second segment arrives before the new timeout, the second seg -\nment will not be retransmitted.\nIn a third and final scenario, suppose Host A sends the two segments, exactly \nas in the second example. The acknowledgment of the first segment is lost in the \nnetwork, but just before the timeout event, Host A receives an acknowledgment with \nacknowledgment number 120. Host A therefore knows that Host B has received  \neverything  up through byte 119; so Host A does not resend either of the two  \nsegments. This scenario is illustrated in Figure 3.36.\nDoubling the Timeout Interval\nWe now discuss a few modifications that most TCP implementations employ. The \nfirst concerns the length of the timeout interval after a timer expiration. In this modi -\nfication, whenever the timeout event occurs, TCP retransmits the not-yet-acknowl -\nedged segment with the smallest sequence number, as described above. But each \ntime TCP retransmits, it sets the next timeout interval to twice the previous value, Time TimeHost A Host B\nTimeoutSeq=92, 8 bytes data\nSeq=92, 8 bytes", "doc_id": "029f66e3-9a64-4565-8628-06604c6c38c5", "embedding": null, "doc_hash": "95ebff3f5eb6b7aadbcc35623b86ede01d7bda8061a0cd10549154eeb41261b8", "extra_info": null, "node_info": {"start": 795713, "end": 799492}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "66dd6657-7c1e-4ed7-9c1f-1ea7e2c6e4c0", "3": "7bf45709-be08-423a-8210-c807bc32be2f"}}, "__type__": "1"}, "7bf45709-be08-423a-8210-c807bc32be2f": {"__data__": {"text": "with \nacknowledgment number 120. Host A therefore knows that Host B has received  \neverything  up through byte 119; so Host A does not resend either of the two  \nsegments. This scenario is illustrated in Figure 3.36.\nDoubling the Timeout Interval\nWe now discuss a few modifications that most TCP implementations employ. The \nfirst concerns the length of the timeout interval after a timer expiration. In this modi -\nfication, whenever the timeout event occurs, TCP retransmits the not-yet-acknowl -\nedged segment with the smallest sequence number, as described above. But each \ntime TCP retransmits, it sets the next timeout interval to twice the previous value, Time TimeHost A Host B\nTimeoutSeq=92, 8 bytes data\nSeq=92, 8 bytes dataACK=100\nACK=100X\n(loss)\nFigure 3.34  \u2666 Retransmission due to a lost acknowledgment\n276     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nrather than deriving it from the last EstimatedRTT  and DevRTT  (as described \nin Section 3.5.3). For example, suppose TimeoutInterval  associated with \nthe oldest not yet acknowledged segment is .75 sec when the timer first expires. \nTCP will then retransmit this segment and set the new expiration time to 1.5 sec. If \nthe timer expires again 1.5 sec later, TCP will again retransmit this segment, now \nsetting the expiration time to 3.0 sec. Thus the intervals grow exponentially after \neach retransmission. However, whenever the timer is started after either of the two \nother events (that is, data received from application above, and ACK received), the  \nTimeoutInterval  is derived from the most recent values of EstimatedRTT  \nand DevRTT .\nThis modification provides a limited form of congestion control. (More com -\nprehensive forms of TCP congestion control will be studied in Section 3.7.) The \ntimer expiration is most likely caused by congestion in the network, that is, too many \npackets arriving at one (or more) router queues in the path between the source and \ndestination, causing packets to be dropped and/or long queuing delays. In times of \ncongestion, if the sources continue to retransmit packets persistently, the congestion Time TimeHost A Host B\nseq=92 timeout intervalSeq=92, 8 bytes data\nSeq=100, 20 bytes data\nACK=100\nACK=120ACK=120\nseq=92 timeout intervalSeq=92, 8 bytes data\nFigure 3.35  \u2666 Segment 100 not retransmitted\n3.5  \u2022  CONNECTION-ORIENTED TRANSPORT: TCP      277\nmay get worse. Instead, TCP acts more politely, with each sender retransmitting after \nlonger and longer intervals. We will see that a similar idea is used by Ethernet when \nwe study CSMA/CD in Chapter 6.\nFast Retransmit\nOne of the problems with timeout-triggered retransmissions is that the timeout period \ncan be relatively long. When a segment is lost, this long timeout period forces the \nsender to delay resending the lost packet, thereby increasing the end-to-end delay. \nFortunately, the sender can often detect packet loss well before the timeout event \noccurs by noting so-called duplicate ACKs. A duplicate ACK  is an ACK that reac -\nknowledges a segment for which the sender has already received an earlier acknowl -\nedgment. To understand the sender\u2019s response to a duplicate ACK, we must look at \nwhy the receiver sends a duplicate ACK in the first place. Table 3.2 summarizes the \nTCP receiver\u2019s ACK generation policy [RFC 5681]. When a TCP receiver receives Time TimeHost A Host B\nSeq=92 timeout intervalSeq=92, 8 bytes data\nSeq=100,  20 bytes dataACK=100\nACK=120X\n(loss)\nFigure 3.36  \u2666  A cumulative acknowledgment avoids retransmission of the \nfirst segment\n278  ", "doc_id": "7bf45709-be08-423a-8210-c807bc32be2f", "embedding": null, "doc_hash": "0bf42427bd7cd8693f16704d9d7b0465a444802ebf9eec20ff0a58bfc9e9f29a", "extra_info": null, "node_info": {"start": 799509, "end": 803050}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "029f66e3-9a64-4565-8628-06604c6c38c5", "3": "0a19c473-2bb9-4bb7-b819-42880281c30a"}}, "__type__": "1"}, "0a19c473-2bb9-4bb7-b819-42880281c30a": {"__data__": {"text": "\noccurs by noting so-called duplicate ACKs. A duplicate ACK  is an ACK that reac -\nknowledges a segment for which the sender has already received an earlier acknowl -\nedgment. To understand the sender\u2019s response to a duplicate ACK, we must look at \nwhy the receiver sends a duplicate ACK in the first place. Table 3.2 summarizes the \nTCP receiver\u2019s ACK generation policy [RFC 5681]. When a TCP receiver receives Time TimeHost A Host B\nSeq=92 timeout intervalSeq=92, 8 bytes data\nSeq=100,  20 bytes dataACK=100\nACK=120X\n(loss)\nFigure 3.36  \u2666  A cumulative acknowledgment avoids retransmission of the \nfirst segment\n278     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\na segment with a sequence number that is larger than the next, expected, in-order \nsequence number, it detects a gap in the data stream\u2014that is, a missing segment. \nThis gap could be the result of lost or reordered segments within the network. Since \nTCP does not use negative acknowledgments, the receiver cannot send an explicit \nnegative acknowledgment back to the sender. Instead, it simply reacknowledges \n(that is, generates a duplicate ACK for) the last in-order byte of data it has received. \n(Note that Table 3.2 allows for the case that the receiver does not discard out-of-\norder segments.)\nBecause a sender often sends a large number of segments back to back, if one \nsegment is lost, there will likely be many back-to-back duplicate ACKs. If the TCP \nsender receives three duplicate ACKs for the same data, it takes this as an indication \nthat the segment following the segment that has been ACKed three times has been \nlost. (In the homework problems, we consider the question of why the sender waits \nfor three duplicate ACKs, rather than just a single duplicate ACK.) In the case that \nthree duplicate ACKs are received, the TCP sender performs a fast retransmit  [RFC \n5681], retransmitting the missing segment before  that segment\u2019s timer expires. This \nis shown in Figure 3.37, where the second segment is lost, then retransmitted before \nits timer expires. For TCP with fast retransmit, the following code snippet replaces \nthe ACK received event in Figure 3.33:\nevent: ACK received, with ACK field value of y\n            if (y > SendBase) {\n            SendBase=y\n            if (there are currently any not yet\n                       acknowledged segments)\n               start timer\n               }Table 3.2  \u2666 TCP ACK Generation Recommendation [RFC 5681]Event TCP Receiver Action\nArrival of in-order segment with expected sequence number. All  \ndata up to expected sequence number already acknowledged.Delayed ACK. Wait up to 500 msec for arrival of another in-order segment.  \nIf next in-order segment does not arrive in this interval, send an ACK.\nArrival of in-order segment with expected sequence number. One  \nother in-order segment waiting for ACK transmission.One Immediately send single cumulative ACK, ACKing both in-order segments.\nArrival of out-of-order segment with higher-than-expected sequence \nnumber. Gap detected.Immediately send duplicate ACK, indicating sequence number of next \nexpected byte (which is the lower end of the gap).\nArrival of segment that partially or completely fills in gap in  \nreceived data.Immediately send ACK, provided that segment starts at the lower end  \nof gap.\n3.5  \u2022  CONNECTION-ORIENTED TRANSPORT: TCP      279\nHost A Host", "doc_id": "0a19c473-2bb9-4bb7-b819-42880281c30a", "embedding": null, "doc_hash": "acacdfb0d88f70809518aeefdaf4bcf5862a5ceca9eac3930c119c2e1bd68a6a", "extra_info": null, "node_info": {"start": 803145, "end": 806496}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "7bf45709-be08-423a-8210-c807bc32be2f", "3": "46f24e46-b7b7-472e-99d9-ebb7ed92c898"}}, "__type__": "1"}, "46f24e46-b7b7-472e-99d9-ebb7ed92c898": {"__data__": {"text": "segment.  \nIf next in-order segment does not arrive in this interval, send an ACK.\nArrival of in-order segment with expected sequence number. One  \nother in-order segment waiting for ACK transmission.One Immediately send single cumulative ACK, ACKing both in-order segments.\nArrival of out-of-order segment with higher-than-expected sequence \nnumber. Gap detected.Immediately send duplicate ACK, indicating sequence number of next \nexpected byte (which is the lower end of the gap).\nArrival of segment that partially or completely fills in gap in  \nreceived data.Immediately send ACK, provided that segment starts at the lower end  \nof gap.\n3.5  \u2022  CONNECTION-ORIENTED TRANSPORT: TCP      279\nHost A Host B\nseq=100, 20 bytes of dataTimeout\nTime TimeXseq=100, 20 bytes of dataseq=92, 8 bytes of data\nseq=120, 15 bytes of data\nseq=135, 6 bytes of data\nseq=141, 16 bytes of dataack=100\nack=100\nack=100\nack=100\nFigure 3.37  \u2666  Fast retransmit: retransmitting the missing segment before \nthe segment\u2019s timer expires\n            else {/* a duplicate ACK for already ACKed\n                   segment */\n               increment number of duplicate ACKs\n                   received for y\n               if (number of duplicate ACKS received\n                   for y==3)\n                   /* TCP fast retransmit */\n                   resend segment with sequence number y\n               }\n           break;\nWe noted earlier that many subtle issues arise when a timeout/retransmit mech-\nanism is implemented in an actual protocol such as TCP. The procedures above, \nwhich have evolved as a result of more than 20 years of experience with TCP timers, \nshould convince you that this is indeed the case!\n280     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nGo-Back-N or Selective Repeat?\nLet us close our study of TCP\u2019s error-recovery mechanism by considering the fol -\nlowing question: Is TCP a GBN or an SR protocol? Recall that TCP acknowledg -\nments are cumulative and correctly received but out-of-order segments are not \nindividually ACKed by the receiver. Consequently, as shown in Figure 3.33 (see \nalso Figure 3.19), the TCP sender need only maintain the smallest sequence number \nof a transmitted but unacknowledged byte ( SendBase ) and the sequence number \nof the next byte to be sent ( NextSeqNum ). In this sense, TCP looks a lot like a \nGBN-style protocol. But there are some striking differences between TCP and Go-\nBack-N. Many TCP implementations will buffer correctly received but out-of-order \nsegments [Stevens 1994]. Consider also what happens when the sender sends a \nsequence of segments 1, 2, . . . , N, and all of the segments arrive in order without \nerror at the receiver. Further suppose that the acknowledgment for packet n6N \ngets lost, but the remaining N-1 acknowledgments arrive at the sender before \ntheir respective timeouts. In this example, GBN would retransmit not only packet n, \nbut also all of the subsequent packets n+1, n+2, . . . , N. TCP, on the other hand, \nwould retransmit at most one segment, namely, segment n. Moreover, TCP would \nnot even retransmit segment", "doc_id": "46f24e46-b7b7-472e-99d9-ebb7ed92c898", "embedding": null, "doc_hash": "550fea750737558d7cf194eca9273212dd4b80dd992ca321098e6052b531fc92", "extra_info": null, "node_info": {"start": 806421, "end": 809507}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "0a19c473-2bb9-4bb7-b819-42880281c30a", "3": "a8bd8d56-4e6a-48dc-98ef-4e8a0175a2d1"}}, "__type__": "1"}, "a8bd8d56-4e6a-48dc-98ef-4e8a0175a2d1": {"__data__": {"text": "Go-\nBack-N. Many TCP implementations will buffer correctly received but out-of-order \nsegments [Stevens 1994]. Consider also what happens when the sender sends a \nsequence of segments 1, 2, . . . , N, and all of the segments arrive in order without \nerror at the receiver. Further suppose that the acknowledgment for packet n6N \ngets lost, but the remaining N-1 acknowledgments arrive at the sender before \ntheir respective timeouts. In this example, GBN would retransmit not only packet n, \nbut also all of the subsequent packets n+1, n+2, . . . , N. TCP, on the other hand, \nwould retransmit at most one segment, namely, segment n. Moreover, TCP would \nnot even retransmit segment n if the acknowledgment for segment n+1 arrived \nbefore the timeout for segment n.\nA proposed modification to TCP, the so-called selective acknowledgment   \n[RFC 2018], allows a TCP receiver to acknowledge out-of-order segments selectively \nrather than just cumulatively acknowledging the last correctly received, in-order  \nsegment. When combined with selective retransmission\u2014skipping the retransmis -\nsion of segments that have already been selectively acknowledged by the receiver\u2014\nTCP looks a lot like our generic SR protocol. Thus, TCP\u2019s error-recovery mechanism \nis probably best categorized as a hybrid of GBN and SR protocols.\n3.5.5  Flow Control\nRecall that the hosts on each side of a TCP connection set aside a receive buffer \nfor the connection. When the TCP connection receives bytes that are correct and in \nsequence, it places the data in the receive buffer. The associated application process \nwill read data from this buffer, but not necessarily at the instant the data arrives. \nIndeed, the receiving application may be busy with some other task and may not even \nattempt to read the data until long after it has arrived. If the application is relatively \nslow at reading the data, the sender can very easily overflow the connection\u2019s receive \nbuffer by sending too much data too quickly.\nTCP provides a flow-control service  to its applications to eliminate the pos -\nsibility of the sender overflowing the receiver\u2019s buffer. Flow control is thus a speed-\nmatching service\u2014matching the rate at which the sender is sending against the rate \nat which the receiving application is reading. As noted earlier, a TCP sender can also \nbe throttled due to congestion within the IP network; this form of sender control is \n3.5  \u2022  CONNECTION-ORIENTED TRANSPORT: TCP      281\nreferred to as congestion control , a topic we will explore in detail in Sections 3.6 \nand 3. 7. Even though the actions taken by flow and congestion control are similar \n(the throttling of the sender), they are obviously taken for very different reasons. \nUnfortunately, many authors use the terms interchangeably, and the savvy reader \nwould be wise to distinguish between them. Let\u2019s now discuss how TCP provides its \nflow-control service. In order to see the forest for the trees, we suppose throughout \nthis section that the TCP implementation is such that the TCP receiver discards out-\nof-order segments.\nTCP provides flow control by having the sender  maintain a variable called \nthe receive window . Informally, the receive window is used to give the sender an \nidea of how much free buffer space is available at the receiver. Because TCP is \nfull-duplex, the sender at each side of the connection maintains a distinct receive \nwindow. Let\u2019s investigate the receive window in the context of a file transfer. Sup -\npose that Host A is sending a large file to Host B over a TCP connection. Host B \nallocates a receive buffer to this connection; denote its size by RcvBuffer . From \ntime to time, the application process in Host B reads from the buffer. Define the \nfollowing variables:\n\u2022", "doc_id": "a8bd8d56-4e6a-48dc-98ef-4e8a0175a2d1", "embedding": null, "doc_hash": "e2ae89cf7afd52a7b48dd16d63a9b6cfe93b409fd8f656da7c9a05e37df69e8b", "extra_info": null, "node_info": {"start": 809536, "end": 813299}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "46f24e46-b7b7-472e-99d9-ebb7ed92c898", "3": "48283385-c28d-4960-8952-e984b2ad89dd"}}, "__type__": "1"}, "48283385-c28d-4960-8952-e984b2ad89dd": {"__data__": {"text": "the TCP implementation is such that the TCP receiver discards out-\nof-order segments.\nTCP provides flow control by having the sender  maintain a variable called \nthe receive window . Informally, the receive window is used to give the sender an \nidea of how much free buffer space is available at the receiver. Because TCP is \nfull-duplex, the sender at each side of the connection maintains a distinct receive \nwindow. Let\u2019s investigate the receive window in the context of a file transfer. Sup -\npose that Host A is sending a large file to Host B over a TCP connection. Host B \nallocates a receive buffer to this connection; denote its size by RcvBuffer . From \ntime to time, the application process in Host B reads from the buffer. Define the \nfollowing variables:\n\u2022 LastByteRead : the number of the last byte in the data stream read from the \nbuffer by the application process in B\n\u2022 LastByteRcvd : the number of the last byte in the data stream that has arrived \nfrom the network and has been placed in the receive buffer at B\nBecause TCP is not permitted to overflow the allocated buffer, we must have\nLastByteRcvd \u2013 LastByteRead \u2026RcvBuffer\nThe receive window, denoted rwnd  is set to the amount of spare room in the buffer:\nrwnd = RcvBuffer \u2013 [LastByteRcvd \u2013 LastByteRead]\nBecause the spare room changes with time, rwnd  is dynamic. The variable rwnd  is \nillustrated in Figure 3.38.\nHow does the connection use the variable rwnd  to provide the flow-control \nservice? Host B tells Host A how much spare room it has in the connection buffer \nby placing its current value of rwnd  in the receive window field of every segment it \nsends to A. Initially, Host B sets rwnd = RcvBuffer . Note that to pull this off, \nHost B must keep track of several connection-specific variables.\nHost A in turn keeps track of two variables, LastByteSent  and Last-\nByteAcked , which have obvious meanings. Note that the difference between these \ntwo variables, LastByteSent \u2013 LastByteAcked , is the amount of unac -\nknowledged data that A has sent into the connection. By keeping the amount of \nunacknowledged data less than the value of rwnd , Host A is assured that it is not \n282     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\noverflowing the receive buffer at Host B. Thus, Host A makes sure throughout the \nconnection\u2019s life that\nLastByteSent \u2013 LastByteAcked \u2026rwnd\nThere is one minor technical problem with this scheme. To see this, suppose Host \nB\u2019s receive buffer becomes full so that rwnd  = 0. After advertising rwnd  = 0 to \nHost A, also suppose that B has nothing  to send to A. Now consider what happens. \nAs the application process at B empties the buffer, TCP does not send new seg -\nments with new rwnd  values to Host A; indeed, TCP sends a segment to Host A \nonly if it has data to send or if it has an acknowledgment to send. Therefore, Host \nA is never informed that some space has opened up in Host B\u2019s receive buffer\u2014\nHost A is blocked and can transmit no more data! To solve this problem, the TCP \nspecification requires Host A to continue to send segments with one data byte when \nB\u2019s receive window is zero. These segments will be acknowledged by the receiver. \nEventually the buffer will begin to empty and the acknowledgments will contain a \nnonzero rwnd  value.\nThe online site at http://www.awl.com/kurose-ross for this book provides an \ninteractive Java applet that illustrates the operation of the TCP receive window.\nHaving described TCP\u2019s flow-control service, we briefly mention here that UDP \ndoes not provide flow control and consequently, segments may be lost at the receiver \ndue to buffer overflow. For example, consider sending a series of UDP segments \nfrom a process on Host A to a process on Host B. For a typical UDP implementation, \nUDP will", "doc_id": "48283385-c28d-4960-8952-e984b2ad89dd", "embedding": null, "doc_hash": "8d4169a1a80d1d2681beff1627cec36968a37e37a7223f4de6e4d1633e3718bd", "extra_info": null, "node_info": {"start": 813231, "end": 816993}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "a8bd8d56-4e6a-48dc-98ef-4e8a0175a2d1", "3": "93f20904-079c-402b-9784-c1c2d041feaa"}}, "__type__": "1"}, "93f20904-079c-402b-9784-c1c2d041feaa": {"__data__": {"text": "requires Host A to continue to send segments with one data byte when \nB\u2019s receive window is zero. These segments will be acknowledged by the receiver. \nEventually the buffer will begin to empty and the acknowledgments will contain a \nnonzero rwnd  value.\nThe online site at http://www.awl.com/kurose-ross for this book provides an \ninteractive Java applet that illustrates the operation of the TCP receive window.\nHaving described TCP\u2019s flow-control service, we briefly mention here that UDP \ndoes not provide flow control and consequently, segments may be lost at the receiver \ndue to buffer overflow. For example, consider sending a series of UDP segments \nfrom a process on Host A to a process on Host B. For a typical UDP implementation, \nUDP will append the segments in a finite-sized buffer that \u201cprecedes\u201d the corre -\nsponding socket (that is, the door to the process). The process reads one entire seg -\nment at a time from the buffer. If the process does not read the segments fast enough \nfrom the buffer, the buffer will overflow and segments will get dropped.Application\nprocess Data\nfrom IPTCP data\nin bufferrwndRcvBu\ufb00er\nSpare room\nFigure 3.38  \u2666  The receive window (rwnd)  and the receive buffer \n(RcvBuffer)\n3.5  \u2022  CONNECTION-ORIENTED TRANSPORT: TCP      283\n3.5.6  TCP Connection Management\nIn this subsection we take a closer look at how a TCP connection is established and \ntorn down. Although this topic may not seem particularly thrilling, it is important \nbecause TCP connection establishment can significantly add to perceived delays (for \nexample, when surfing the Web). Furthermore, many of the most common network \nattacks\u2014including the incredibly popular SYN flood attack\u2014exploit vulnerabilities \nin TCP connection management. Let\u2019s first take a look at how a TCP connection is \nestablished. Suppose a process running in one host (client) wants to initiate a con -\nnection with another process in another host (server). The client application process \nfirst informs the client TCP that it wants to establish a connection to a process in the \nserver. The TCP in the client then proceeds to establish a TCP connection with the \nTCP in the server in the following manner:\n\u2022 Step 1.  The client-side TCP first sends a special TCP segment to the server-side \nTCP. This special segment contains no application-layer data. But one of the flag \nbits in the segment\u2019s header (see Figure 3.29), the SYN bit, is set to 1. For this \nreason, this special segment is referred to as a SYN segment. In addition, the cli-\nent randomly chooses an initial sequence number ( client_isn ) and puts this \nnumber in the sequence number field of the initial TCP SYN segment. This seg -\nment is encapsulated within an IP datagram and sent to the server. There has been \nconsiderable interest in properly randomizing the choice of the client_isn  in \norder to avoid certain security attacks [CERT 2001\u201309].\n\u2022 Step 2.  Once the IP datagram containing the TCP SYN segment arrives at the \nserver host (assuming it does arrive!), the server extracts the TCP SYN segment \nfrom the datagram, allocates the TCP buffers and variables to the connection, \nand sends a connection-granted segment to the client TCP. (We\u2019ll see in Chapter \n8 that the allocation of these buffers and variables before completing the third \nstep of the three-way handshake makes TCP vulnerable to a denial-of-service \nattack known as SYN flooding.) This connection-granted segment also contains \nno application-layer data. However, it does contain three important pieces of \ninformation in the segment header. First, the SYN bit is set to 1. Second, the \nacknowledgment field of the TCP segment header is set to client_isn+1 . \nFinally, the server chooses its own initial sequence number ( server_isn ) and \nputs this value in the sequence number field of the", "doc_id": "93f20904-079c-402b-9784-c1c2d041feaa", "embedding": null, "doc_hash": "239fc46289a0ae372db43095e141c0f19165af0f784ac034d6b89c8bd86a376d", "extra_info": null, "node_info": {"start": 817001, "end": 820830}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "48283385-c28d-4960-8952-e984b2ad89dd", "3": "093d3b27-11ab-45d7-831a-f68b76e944f5"}}, "__type__": "1"}, "093d3b27-11ab-45d7-831a-f68b76e944f5": {"__data__": {"text": "segment \nfrom the datagram, allocates the TCP buffers and variables to the connection, \nand sends a connection-granted segment to the client TCP. (We\u2019ll see in Chapter \n8 that the allocation of these buffers and variables before completing the third \nstep of the three-way handshake makes TCP vulnerable to a denial-of-service \nattack known as SYN flooding.) This connection-granted segment also contains \nno application-layer data. However, it does contain three important pieces of \ninformation in the segment header. First, the SYN bit is set to 1. Second, the \nacknowledgment field of the TCP segment header is set to client_isn+1 . \nFinally, the server chooses its own initial sequence number ( server_isn ) and \nputs this value in the sequence number field of the TCP segment header. This \nconnection-granted segment is saying, in effect, \u201cI received your SYN packet to \nstart a connection with your initial sequence number, client_isn . I agree to \nestablish this connection. My own initial sequence number is server_isn .\u201d \nThe connection-granted segment is referred to as a SYNACK segment .\n\u2022 Step 3.  Upon receiving the SYNACK segment, the client also allocates buffers \nand variables to the connection. The client host then sends the server yet another \nsegment; this last segment acknowledges the server\u2019s connection-granted segment \n(the client does so by putting the value server_isn+1  in the acknowledgment \n284     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nfield of the TCP segment header). The SYN bit is set to zero, since the connection \nis established. This third stage of the three-way handshake may carry client-to-\nserver data in the segment payload.\nOnce these three steps have been completed, the client and server hosts can send \nsegments containing data to each other. In each of these future segments, the SYN \nbit will be set to zero. Note that in order to establish the connection, three packets \nare sent between the two hosts, as illustrated in Figure 3.39. For this reason, this \nconnection-establishment procedure is often referred to as a three-way handshake . \nSeveral aspects of the TCP three-way handshake are explored in the homework prob -\nlems (Why are initial sequence numbers needed? Why is a three-way handshake, \nas opposed to a two-way handshake, needed?). It\u2019s interesting to note that a rock \nclimber and a belayer (who is stationed below the rock climber and whose job it is \nto handle the climber\u2019s safety rope) use a three-way-handshake communication pro -\ntocol that is identical to TCP\u2019s to ensure that both sides are ready before the climber \nbegins ascent.\nAll good things must come to an end, and the same is true with a TCP connec -\ntion. Either of the two processes participating in a TCP connection can end the con -\nnection. When a connection ends, the \u201cresources\u201d (that is, the buffers and variables) \nTime TimeClient host\nConnection\nrequest\nConnection\ngrantedServer host\nSYN=1, seq=client_isn\nSYN=1, seq=server_isn,\nack=client_isn+1\nSYN=0, seq=client_isn+1,\nack=server_isn+1ACK\nFigure 3.39  \u2666 TCP three-way handshake: segment exchange\n3.5  \u2022  CONNECTION-ORIENTED TRANSPORT: TCP      285\nin the hosts are deallocated. As an example, suppose the client decides to close the \nconnection, as shown in Figure 3.40. The client application process issues a close \ncommand. This causes the client TCP to send a special TCP segment to the server \nprocess. This special segment has a flag bit in the segment\u2019s header, the FIN bit (see \nFigure 3. 29), set to 1. When the server receives this segment, it sends the client an \nacknowledgment segment in return. The server then sends its own", "doc_id": "093d3b27-11ab-45d7-831a-f68b76e944f5", "embedding": null, "doc_hash": "44d0e53855841383e6fa549a1172a00bf85cba3981f532d7bc8f08f7664d5b9e", "extra_info": null, "node_info": {"start": 820814, "end": 824445}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "93f20904-079c-402b-9784-c1c2d041feaa", "3": "8217fdb0-8046-41a6-9d53-0364989c7076"}}, "__type__": "1"}, "8217fdb0-8046-41a6-9d53-0364989c7076": {"__data__": {"text": "seq=client_isn+1,\nack=server_isn+1ACK\nFigure 3.39  \u2666 TCP three-way handshake: segment exchange\n3.5  \u2022  CONNECTION-ORIENTED TRANSPORT: TCP      285\nin the hosts are deallocated. As an example, suppose the client decides to close the \nconnection, as shown in Figure 3.40. The client application process issues a close \ncommand. This causes the client TCP to send a special TCP segment to the server \nprocess. This special segment has a flag bit in the segment\u2019s header, the FIN bit (see \nFigure 3. 29), set to 1. When the server receives this segment, it sends the client an \nacknowledgment segment in return. The server then sends its own shutdown segment, \nwhich has the FIN bit set to 1. Finally, the client acknowledges the server\u2019s shutdown \nsegment. At this point, all the resources in the two hosts are now deallocated.\nDuring the life of a TCP connection, the TCP protocol running in each host \nmakes transitions through various TCP states . Figure 3.41 illustrates a typical \nsequence of TCP states that are visited by the client  TCP. The client TCP begins in \nthe CLOSED state. The application on the client side initiates a new TCP connec -\ntion (by creating a Socket object in our Java examples as in the Python examples \nfrom Chapter 2). This causes TCP in the client to send a SYN segment to TCP in the \nserver. After having sent the SYN segment, the client TCP enters the SYN_SENT \nstate. While in the SYN_SENT state, the client TCP waits for a segment from the \nserver TCP that includes an acknowledgment for the client\u2019s previous segment and Time TimeClient\nClose\nCloseServer\nFIN\nACKACK\nFIN\nClosedTimed wait\nFigure 3.40  \u2666 Closing a TCP connection\n286     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nhas the SYN bit set to 1. Having received such a segment, the client TCP enters the \nESTABLISHED state. While in the ESTABLISHED state, the TCP client can send \nand receive TCP segments containing payload (that is, application-generated) data.\nSuppose that the client application decides it wants to close the connection. (Note \nthat the server could also choose to close the connection.) This causes the client TCP \nto send a TCP segment with the FIN bit set to 1 and to enter the FIN_WAIT_1 state. \nWhile in the FIN_WAIT_1 state, the client TCP waits for a TCP segment from the \nserver with an acknowledgment. When it receives this segment, the client TCP enters \nthe FIN_WAIT_2 state. While in the FIN_WAIT_2 state, the client waits for another \nsegment from the server with the FIN bit set to 1; after receiving this segment, the client \nTCP acknowledges the server\u2019s segment and enters the TIME_WAIT state. The TIME_\nWAIT state lets the TCP client resend the final acknowledgment in case the ACK is \nlost. The time spent in the TIME_WAIT state is implementation-dependent, but typical \nvalues are 30 seconds, 1 minute, and 2 minutes. After the wait, the connection formally \ncloses and all resources on the client side (including port numbers) are released.\nFigure 3. 42 illustrates the series of states typically visited by the server-side \nTCP, assuming the client begins connection teardown. The transitions are self-\nexplanatory. In these two state-transition diagrams, we have only shown how a TCP \nconnection is normally established and shut down. We have not described what hap -\npens in certain pathological scenarios, for example, when both sides of a connection \nwant to initiate or shut down at the same time. If you are interested in learning about CLOSED\nSYN_SENT\nESTABLISHED\nFIN_WAIT_1FIN_WAIT_2TIME_WAITSend SYN\nSend FIN\nReceive ACK, \nsend", "doc_id": "8217fdb0-8046-41a6-9d53-0364989c7076", "embedding": null, "doc_hash": "f198dfe03791f796d02705402ff8aee3f88fb160e7f56fcb6302885e396ad7ae", "extra_info": null, "node_info": {"start": 824563, "end": 828127}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "093d3b27-11ab-45d7-831a-f68b76e944f5", "3": "97046f3a-f31b-41aa-9144-102757848f19"}}, "__type__": "1"}, "97046f3a-f31b-41aa-9144-102757848f19": {"__data__": {"text": "and 2 minutes. After the wait, the connection formally \ncloses and all resources on the client side (including port numbers) are released.\nFigure 3. 42 illustrates the series of states typically visited by the server-side \nTCP, assuming the client begins connection teardown. The transitions are self-\nexplanatory. In these two state-transition diagrams, we have only shown how a TCP \nconnection is normally established and shut down. We have not described what hap -\npens in certain pathological scenarios, for example, when both sides of a connection \nwant to initiate or shut down at the same time. If you are interested in learning about CLOSED\nSYN_SENT\nESTABLISHED\nFIN_WAIT_1FIN_WAIT_2TIME_WAITSend SYN\nSend FIN\nReceive ACK, \nsend nothingWait 30 seconds\nReceive FIN, \nsend ACKReceive SYN & ACK, \nsend ACKClient application\ninitiates a TCP connection\nClient application\ninitiates close connection\nFigure 3.41  \u2666 A typical sequence of TCP states visited by a client TCP\n3.5  \u2022  CONNECTION-ORIENTED TRANSPORT: TCP      287\nthis and other advanced issues concerning TCP, you are encouraged to see Stevens\u2019 \ncomprehensive book [Stevens 1994].\nOur discussion above has assumed that both the client and server are prepared \nto communicate, i.e., that the server is listening on the port to which the client sends \nits SYN segment. Let\u2019s consider what happens when a host receives a TCP segment \nwhose port numbers or source IP address do not match with any of the ongoing sock -\nets in the host. For example, suppose a host receives a TCP SYN packet with desti -\nnation port 80, but the host is not accepting connections on port 80 (that is, it is not \nrunning a Web server on port 80). Then the host will send a special reset segment to \nthe source. This TCP segment has the RST flag bit (see Section 3.5.2) set to 1. Thus, \nwhen a host sends a reset segment, it is telling the source \u201cI don\u2019t have a socket for \nthat segment. Please do not resend the segment.\u201d When a host receives a UDP packet \nwhose destination port number doesn\u2019t match with an ongoing UDP socket, the host \nsends a special ICMP datagram, as discussed in Chapter 5.\nNow that we have a good understanding of TCP connection management, let\u2019s \nrevisit the nmap port-scanning tool and examine more closely how it works. To explore \na specific TCP port, say port 6789, on a target host, nmap will send a TCP SYN seg -\nment with destination port 6789 to that host. There are three possible outcomes:\n\u2022 The source host receives a TCP SYNACK segment from the target host . Since this \nmeans that an application is running with TCP port 6789 on the target post, nmap \nreturns \u201copen.\u201dCLOSED\nLISTEN\nSYN_RCVD\nESTABLISHEDCLOSE_WAITLAST_ACK\nReceive FIN,\nsend ACKReceive ACK, \nsend nothing\nSend FINReceive SYN \nsend SYN & AC KServer application\ncreates a listen socket\nReceive ACK, \nsend nothing\nFigure 3.42  \u2666  A typical sequence of TCP states visited by a server-side TCP\n288     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nTHE SYN FLOOD ATTACK\nWe\u2019ve seen in our discussion of TCP\u2019s three-way handshake that a server allocates \nand initializes connection variables and buffers in response to a received SYN. The \nserver then sends a SYNACK in response, and awaits an ACK segment from the cli -\nent. If the client does not send an ACK to complete the third step of this 3-way hand -\nshake, eventually (often after a minute or more) the server will terminate the half-open \nconnection and reclaim the allocated resources.\nThis TCP connection management protocol sets the stage for a classic Denial of \nService (DoS)", "doc_id": "97046f3a-f31b-41aa-9144-102757848f19", "embedding": null, "doc_hash": "b7adb80859fa8d569c9b4921b880797260a4b2bd91e6760607dfb3abb9aa4a0d", "extra_info": null, "node_info": {"start": 828029, "end": 831588}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "8217fdb0-8046-41a6-9d53-0364989c7076", "3": "a2bb940d-dbd3-439b-a08e-8652dbe38ffd"}}, "__type__": "1"}, "a2bb940d-dbd3-439b-a08e-8652dbe38ffd": {"__data__": {"text": "3.42  \u2666  A typical sequence of TCP states visited by a server-side TCP\n288     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nTHE SYN FLOOD ATTACK\nWe\u2019ve seen in our discussion of TCP\u2019s three-way handshake that a server allocates \nand initializes connection variables and buffers in response to a received SYN. The \nserver then sends a SYNACK in response, and awaits an ACK segment from the cli -\nent. If the client does not send an ACK to complete the third step of this 3-way hand -\nshake, eventually (often after a minute or more) the server will terminate the half-open \nconnection and reclaim the allocated resources.\nThis TCP connection management protocol sets the stage for a classic Denial of \nService (DoS) attack known as the SYN flood attack . In this attack, the attacker(s) send \na large number of TCP SYN segments, without completing the third handshake step. With \nthis deluge of SYN segments, the server\u2019s connection resources become exhausted as \nthey are allocated (but never used!) for half-open connections; legitimate clients are then \ndenied service. Such SYN flooding attacks were among the first documented DoS attacks \n[CERT SYN 1996]. Fortunately, an effective defense known as SYN cookies  [RFC \n4987] are now deployed in most major operating systems. SYN cookies work as follows:\n\u2022  When the server receives a SYN segment, it does not know if the segment is \ncoming from a legitimate user or is part of a SYN flood attack. So, instead of \ncreating a half-open TCP connection for this SYN, the server creates an initial \nTCP sequence number that is a complicated function (hash function) of source \nand destination IP addresses and port numbers of the SYN segment, as well as \na secret number only known to the server. This carefully crafted initial sequence \nnumber is the so-called \u201ccookie.\u201d The server then sends the client a SYNACK \npacket with this special initial sequence number. Importantly, the server does not \nremember the cookie or any other state information corresponding to the SYN .\n\u2022  A legitimate client will return an ACK segment. When the server receives this \nACK, it must verify that the ACK corresponds to some SYN sent earlier. But how \nis this done if the server maintains no memory about SYN segments? As you may \nhave guessed, it is done with the cookie. Recall that for a legitimate ACK, the \nvalue in the acknowledgment field is equal to the initial sequence number in the \nSYNACK (the cookie value in this case) plus one (see Figure 3.39). The server \ncan then run the same hash function using the source and destination IP address \nand port numbers in the SYNACK (which are the same as in the original SYN) \nand the secret number. If the result of the function plus one is the same as the \nacknowledgment (cookie) value in the client\u2019s SYNACK, the server concludes that \nthe ACK corresponds to an earlier SYN segment and is hence valid. The server \nthen creates a fully open connection along with a socket.\n\u2022  On the other hand, if the client does not return an ACK segment, then the origi -\nnal SYN has done no harm at the server, since the server hasn\u2019t yet allocated \nany resources in response to the original bogus SYN.FOCUS ON SECURITY\n\n3.6  \u2022  PRINCIPLES OF CONGESTION CONTROL      289\n\u2022 The source host receives a TCP RST segment from the target host . This means \nthat the SYN segment reached the target host, but the target host is not running \nan application with TCP port 6789. But the attacker at least knows that the seg -\nments destined to the host at port 6789 are not blocked by any firewall on the path \nbetween source and target hosts. (Firewalls are discussed in Chapter 8.)\n\u2022 The source receives nothing . This likely means that the SYN segment was blocked \nby an intervening firewall and never reached the target host.\nNmap is", "doc_id": "a2bb940d-dbd3-439b-a08e-8652dbe38ffd", "embedding": null, "doc_hash": "8566c0ab0572b6de2262aec39bb09d370397833fd3dcb21eddc516230f12a209", "extra_info": null, "node_info": {"start": 831638, "end": 835429}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "97046f3a-f31b-41aa-9144-102757848f19", "3": "19b5bf85-6e1b-49f5-83d6-3ffadbae0ad1"}}, "__type__": "1"}, "19b5bf85-6e1b-49f5-83d6-3ffadbae0ad1": {"__data__": {"text": "yet allocated \nany resources in response to the original bogus SYN.FOCUS ON SECURITY\n\n3.6  \u2022  PRINCIPLES OF CONGESTION CONTROL      289\n\u2022 The source host receives a TCP RST segment from the target host . This means \nthat the SYN segment reached the target host, but the target host is not running \nan application with TCP port 6789. But the attacker at least knows that the seg -\nments destined to the host at port 6789 are not blocked by any firewall on the path \nbetween source and target hosts. (Firewalls are discussed in Chapter 8.)\n\u2022 The source receives nothing . This likely means that the SYN segment was blocked \nby an intervening firewall and never reached the target host.\nNmap is a powerful tool that can \u201ccase the joint\u201d not only for open TCP ports, \nbut also for open UDP ports, for firewalls and their configurations, and even for the \nversions of applications and operating systems. Most of this is done by manipulating \nTCP connection-management segments [Skoudis 2006]. You can download nmap \nfrom www.nmap.org.\nThis completes our introduction to error control and flow control in TCP. In \nSection 3. 7 we\u2019ll return to TCP and look at TCP congestion control in some depth. \nBefore doing so, however, we first step back and examine congestion-control issues \nin a broader context.\n3.6 Principles of Congestion Control\nIn the previous sections, we examined both the general principles and specific TCP \nmechanisms used to provide for a reliable data transfer service in the face of packet \nloss. We mentioned earlier that, in practice, such loss typically results from the over -\nflowing of router buffers as the network becomes congested. Packet retransmission \nthus treats a symptom of network congestion (the loss of a specific transport-layer \nsegment) but does not treat the cause of network congestion\u2014too many sources \nattempting to send data at too high a rate. To treat the cause of network congestion, \nmechanisms are needed to throttle senders in the face of network congestion.\nIn this section, we consider the problem of congestion control in a general con -\ntext, seeking to understand why congestion is a bad thing, how network congestion \nis manifested in the performance received by upper-layer applications, and various \napproaches that can be taken to avoid, or react to, network congestion. This more \ngeneral study of congestion control is appropriate since, as with reliable data trans -\nfer, it is high on our \u201ctop-ten\u201d list of fundamentally important problems in network -\ning. The following section contains a detailed study of TCP\u2019s congestion-control \nalgorithm.\n3.6.1  The Causes and the Costs of Congestion\nLet\u2019s begin our general study of congestion control by examining three increas -\ningly complex scenarios in which congestion occurs. In each case, we\u2019ll look at why  \n290     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\ncongestion occurs in the first place and at the cost of congestion (in terms of resources \nnot fully utilized and poor performance received by the end systems). We\u2019ll not (yet) \nfocus on how to react to, or avoid, congestion but rather focus on the simpler issue of \nunderstanding what happens as hosts increase their transmission rate and the network \nbecomes congested.\nScenario 1: Two Senders, a Router with Infinite Buffers\nWe begin by considering perhaps the simplest congestion scenario possible: Two \nhosts (A and B) each have a connection that shares a single hop between source and \ndestination, as shown in Figure 3.43.\nLet\u2019s assume that the application in Host A is sending data into the connection \n(for example, passing data to the transport-level protocol via a socket) at an average \nrate of lin bytes/sec. These data are original in the sense that each unit of data is sent \ninto", "doc_id": "19b5bf85-6e1b-49f5-83d6-3ffadbae0ad1", "embedding": null, "doc_hash": "635110caee72e7f32716d28fa76afcc7cf1b91cb4233262ea0e9ab7f8f8702fb", "extra_info": null, "node_info": {"start": 835444, "end": 839199}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "a2bb940d-dbd3-439b-a08e-8652dbe38ffd", "3": "57854cd6-c4b9-468c-9d6a-c6413646bfb2"}}, "__type__": "1"}, "57854cd6-c4b9-468c-9d6a-c6413646bfb2": {"__data__": {"text": "received by the end systems). We\u2019ll not (yet) \nfocus on how to react to, or avoid, congestion but rather focus on the simpler issue of \nunderstanding what happens as hosts increase their transmission rate and the network \nbecomes congested.\nScenario 1: Two Senders, a Router with Infinite Buffers\nWe begin by considering perhaps the simplest congestion scenario possible: Two \nhosts (A and B) each have a connection that shares a single hop between source and \ndestination, as shown in Figure 3.43.\nLet\u2019s assume that the application in Host A is sending data into the connection \n(for example, passing data to the transport-level protocol via a socket) at an average \nrate of lin bytes/sec. These data are original in the sense that each unit of data is sent \ninto the socket only once. The underlying transport-level protocol is a simple one. \nData is encapsulated and sent; no error recovery (for example, retransmission), flow \ncontrol, or congestion control is performed. Ignoring the additional overhead due \nto adding transport- and lower-layer header information, the rate at which Host A \noffers traffic to the router in this first scenario is thus lin bytes/sec. Host B operates \nin a similar manner, and we assume for simplicity that it too is sending at a rate of \nlin bytes/sec. Packets from Hosts A and B pass through a router and over a shared \noutgoing link of capacity R. The router has buffers that allow it to store incoming \npackets when the packet-arrival rate exceeds the outgoing link\u2019s capacity. In this first \nscenario, we assume that the router has an infinite amount of buffer space.\nFigure 3. 44 plots the performance of Host A\u2019s connection under this first sce -\nnario. The left graph plots the per-connection throughput  (number of bytes per \nHost B\nUnlimited shared\noutput link buf fers/H9261in: original data\nHost A Host D Host C/H9261out \nFigure 3.43  \u2666  Congestion scenario 1: Two connections sharing a single \nhop with infinite buffers\n3.6  \u2022  PRINCIPLES OF CONGESTION CONTROL      291\nsecond at the receiver) as a function of the connection-sending rate. For a sending \nrate between 0 and R/2, the throughput at the receiver equals the sender\u2019s sending \nrate\u2014everything sent by the sender is received at the receiver with a finite delay. \nWhen the sending rate is above R/2, however, the throughput is only R/2. This upper \nlimit on throughput is a consequence of the sharing of link capacity between two \nconnections. The link simply cannot deliver packets to a receiver at a steady-state \nrate that exceeds R/2. No matter how high Hosts A and B set their sending rates, they \nwill each never see a throughput higher than R/2.\nAchieving a per-connection throughput of R/2 might actually appear to be a good \nthing, because the link is fully utilized in delivering packets to their destinations. The \nright-hand graph in Figure 3.44, however, shows the consequence of operating near link \ncapacity. As the sending rate approaches R/2 (from the left), the average delay becomes \nlarger and larger. When the sending rate exceeds R/2, the average number of queued \npackets in the router is unbounded, and the average delay between source and destina -\ntion becomes infinite (assuming that the connections operate at these sending rates for \nan infinite period of time and there is an infinite amount of buffering available). Thus, \nwhile operating at an aggregate throughput of near R may be ideal from a throughput \nstandpoint, it is far from ideal from a delay standpoint. Even in this (extremely) ideal -\nized scenario, we\u2019ve already found one cost of a congested network\u2014large queuing \ndelays are experienced as the packet-arrival rate nears the link capacity.\nScenario 2: Two Senders and a Router with Finite Buffers\nLet\u2019s now slightly modify scenario 1 in the", "doc_id": "57854cd6-c4b9-468c-9d6a-c6413646bfb2", "embedding": null, "doc_hash": "3e9fe489fccabe8e61d714a9b5a402cb9132076dd66c09a0832061b6fbe3bdce", "extra_info": null, "node_info": {"start": 839128, "end": 842925}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "19b5bf85-6e1b-49f5-83d6-3ffadbae0ad1", "3": "2923f0c6-861d-4ce7-b0d5-d0e9218546fc"}}, "__type__": "1"}, "2923f0c6-861d-4ce7-b0d5-d0e9218546fc": {"__data__": {"text": "sending rate exceeds R/2, the average number of queued \npackets in the router is unbounded, and the average delay between source and destina -\ntion becomes infinite (assuming that the connections operate at these sending rates for \nan infinite period of time and there is an infinite amount of buffering available). Thus, \nwhile operating at an aggregate throughput of near R may be ideal from a throughput \nstandpoint, it is far from ideal from a delay standpoint. Even in this (extremely) ideal -\nized scenario, we\u2019ve already found one cost of a congested network\u2014large queuing \ndelays are experienced as the packet-arrival rate nears the link capacity.\nScenario 2: Two Senders and a Router with Finite Buffers\nLet\u2019s now slightly modify scenario 1 in the following two ways (see Figure 3.45). \nFirst, the amount of router buffering is assumed to be finite. A consequence of this \nreal-world assumption is that packets will be dropped when arriving to an already-\nfull buffer. Second, we assume that each connection is reliable. If a packet containing R/2\nR/2\nDelay\nR/2/H9261in /H9261in/H9261out\na. b.\nFigure 3.44  \u2666  Congestion scenario 1: Throughput and delay as a function \nof host sending rate\n292     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\na transport-level segment is dropped at the router, the sender will eventually retrans -\nmit it. Because packets can be retransmitted, we must now be more careful with our \nuse of the term sending rate . Specifically, let us again denote the rate at which the \napplication sends original data into the socket by lin bytes/sec. The rate at which the \ntransport layer sends segments (containing original data and retransmitted data) into \nthe network will be denoted l\u2032in bytes/sec. l\u2032in is sometimes referred to as the offered \nload to the network.\nThe performance realized under scenario 2 will now depend strongly on how \nretransmission is performed. First, consider the unrealistic case that Host A is able \nto somehow (magically!) determine whether or not a buffer is free in the router and \nthus sends a packet only when a buffer is free. In this case, no loss would occur, lin \nwould be equal to l\u2032in, and the throughput of the connection would be equal to lin. \nThis case is shown in Figure 3.46(a). From a throughput standpoint, performance \nis ideal\u2014everything that is sent is received. Note that the average host sending rate \ncannot exceed R/2 under this scenario, since packet loss is assumed never to occur.\nConsider next the slightly more realistic case that the sender retransmits only \nwhen a packet is known for certain to be lost. (Again, this assumption is a bit of \na stretch. However, it is possible that the sending host might set its timeout large \nenough to be virtually assured that a packet that has not been acknowledged has been \nlost.) In this case, the performance might look something like that shown in Figure \n3.46(b). To appreciate what is happening here, consider the case that the offered \nload, l\u2032in (the rate of original data transmission plus retransmissions), equals R/2. \nAccording to Figure 3.46(b), at this value of the offered load, the rate at which data Finite shared output\nlink buf fersHost B Host A Host D Host C/H9261out /H9261in: original data\n/H9261\u2019in: original data, plus\nretransmitted data\nFigure 3.45  \u2666  Scenario 2: Two hosts (with retransmissions) and a router \nwith finite buffers\n3.6  \u2022  PRINCIPLES OF CONGESTION CONTROL      293\nare delivered to the receiver application is R/3. Thus, out of the 0.5 R units of data \ntransmitted, 0.333 R bytes/sec (on average) are original data and 0.166 R bytes/sec (on \naverage) are retransmitted data. We see here another cost of a", "doc_id": "2923f0c6-861d-4ce7-b0d5-d0e9218546fc", "embedding": null, "doc_hash": "0808a505f81dd5850acd8dba5cf7bbd7d65a0c9d13be2deeee36128c6e0e8eb7", "extra_info": null, "node_info": {"start": 842929, "end": 846597}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "57854cd6-c4b9-468c-9d6a-c6413646bfb2", "3": "abc72242-8a0e-44b1-9a57-07336ce970c0"}}, "__type__": "1"}, "abc72242-8a0e-44b1-9a57-07336ce970c0": {"__data__": {"text": "\nAccording to Figure 3.46(b), at this value of the offered load, the rate at which data Finite shared output\nlink buf fersHost B Host A Host D Host C/H9261out /H9261in: original data\n/H9261\u2019in: original data, plus\nretransmitted data\nFigure 3.45  \u2666  Scenario 2: Two hosts (with retransmissions) and a router \nwith finite buffers\n3.6  \u2022  PRINCIPLES OF CONGESTION CONTROL      293\nare delivered to the receiver application is R/3. Thus, out of the 0.5 R units of data \ntransmitted, 0.333 R bytes/sec (on average) are original data and 0.166 R bytes/sec (on \naverage) are retransmitted data. We see here another cost of a congested network\u2014\nthe sender must perform retransmissions in order to compensate for dropped (lost) \npackets due to buffer overflow.\nFinally, let us consider the case that the sender may time out prematurely and \nretransmit a packet that has been delayed in the queue but not yet lost. In this case, \nboth the original data packet and the retransmission may reach the receiver. Of \ncourse, the receiver needs but one copy of this packet and will discard the retrans -\nmission. In this case, the work done by the router in forwarding the retransmitted \ncopy of the original packet was wasted, as the receiver will have already received \nthe original copy of this packet. The router would have better used the link trans -\nmission capacity to send a different packet instead. Here then is yet another cost of \na congested network\u2014unneeded retransmissions by the sender in the face of large \ndelays may cause a router to use its link bandwidth to forward unneeded copies of a \npacket.  Figure 3.46 (c) shows the throughput versus offered load when each packet \nis assumed to be forwarded (on average) twice by the router. Since each packet is \nforwarded twice, the throughput will have an asymptotic value of R/4 as the offered \nload approaches R/2.\nScenario 3: Four Senders, Routers with Finite Buffers, and  \nMultihop Paths\nIn our final congestion scenario, four hosts transmit packets, each over overlap -\nping two-hop paths, as shown in Figure 3.47. We again assume that each host uses \na timeout/retransmission mechanism to implement a reliable data transfer service, \nthat all hosts have the same value of lin, and that all router links have capacity  \nR bytes/sec.R/2\nR/2 R/2/H9261out\na. b.R/2/H9261outR/3R/2\nR/2/H9261outR/4\nc./H9261\u2019in /H9261\u2019in /H9261\u2019in\nFigure 3.46  \u2666 Scenario 2 performance with finite buffers\n294     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nLet\u2019s consider the connection from Host A to Host C, passing through routers \nR1 and R2. The A\u2013C connection shares router R1 with the D\u2013B connection and \nshares router R2 with the B\u2013D connection. For extremely small values of lin, buffer \noverflows are rare (as in congestion scenarios 1 and 2), and the throughput approxi -\nmately equals the offered load. For slightly larger values of lin, the corresponding \nthroughput is also larger, since more original data is being transmitted into the net -\nwork and delivered to the destination, and overflows are still rare. Thus, for small \nvalues of lin, an increase in lin results in an increase in lout.\nHaving considered the case of extremely low traffic, let\u2019s next examine the case \nthat lin (and hence l\u2032in) is extremely large. Consider router R2. The A\u2013C traffic \narriving to router R2 (which arrives at R2 after being forwarded from R1) can have \nan arrival rate at R2 that is at most R, the capacity of the link from R1", "doc_id": "abc72242-8a0e-44b1-9a57-07336ce970c0", "embedding": null, "doc_hash": "83698abf172585eea9463185c42c28765c5c1fe2165d12c8836818dd8ecb4cce", "extra_info": null, "node_info": {"start": 846722, "end": 850174}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "2923f0c6-861d-4ce7-b0d5-d0e9218546fc", "3": "95990c9d-b7f3-4f76-b347-9db57205d2b2"}}, "__type__": "1"}, "95990c9d-b7f3-4f76-b347-9db57205d2b2": {"__data__": {"text": "in congestion scenarios 1 and 2), and the throughput approxi -\nmately equals the offered load. For slightly larger values of lin, the corresponding \nthroughput is also larger, since more original data is being transmitted into the net -\nwork and delivered to the destination, and overflows are still rare. Thus, for small \nvalues of lin, an increase in lin results in an increase in lout.\nHaving considered the case of extremely low traffic, let\u2019s next examine the case \nthat lin (and hence l\u2032in) is extremely large. Consider router R2. The A\u2013C traffic \narriving to router R2 (which arrives at R2 after being forwarded from R1) can have \nan arrival rate at R2 that is at most R, the capacity of the link from R1 to R2, regard -\nless of the value of lin. If l\u2032in is extremely large for all connections (including the  Host B Host A\nR1\nR4 R2\nR3Host C Host DFinite shared output\nlink buf fers/H9261in: original data\n/H9261\u2019in: original\ndata, plus\nretransmitted\ndata/H9261out\nFigure 3.47  \u2666 Four senders, routers with finite buffers, and multihop paths\n3.6  \u2022  PRINCIPLES OF CONGESTION CONTROL      295\nB\u2013D connection), then the arrival rate of B\u2013D traffic at R2 can be much larger than \nthat of the A\u2013C traffic. Because the A\u2013C and B\u2013D traffic must compete at router \nR2 for the limited amount of buffer space, the amount of A\u2013C traffic that success -\nfully gets through R2 (that is, is not lost due to buffer overflow) becomes smaller \nand smaller as the offered load from B\u2013D gets larger and larger. In the limit, as the \noffered load approaches infinity, an empty buffer at R2 is immediately filled by a \nB\u2013D packet, and the throughput of the A\u2013C connection at R2 goes to zero. This, in \nturn, implies that the A\u2013C end-to-end throughput goes to zero  in the limit of heavy \ntraffic. These considerations give rise to the offered load versus throughput tradeoff \nshown in Figure 3.48.\nThe reason for the eventual decrease in throughput with increasing offered \nload is evident when one considers the amount of wasted work done by the net -\nwork. In the high-traffic scenario outlined above, whenever a packet is dropped at \na second-hop router, the work done by the first-hop router in forwarding a packet \nto the second-hop router ends up being \u201cwasted.\u201d The network would have been \nequally well off (more accurately, equally bad off) if the first router had simply \ndiscarded that packet and remained idle. More to the point, the transmission capac -\nity used at the first router to forward the packet to the second router could have \nbeen much more profitably used to transmit a different packet. (For example, when \nselecting a packet for transmission, it might be better for a router to give priority \nto packets that have already traversed some number of upstream routers.) So here \nwe see yet another cost of dropping a packet due to congestion\u2014when a packet \nis dropped along a path, the transmission capacity that was used at each of the \nupstream links to forward that packet to the point at which it is dropped ends up \nhaving been wasted.R/2 /H9261out\n/H9261\u2019in\nFigure 3.48  \u2666  Scenario 3 performance with finite buffers and multihop \npaths\n296     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\n3.6.2  Approaches to Congestion Control\nIn Section 3.7, we\u2019ll examine TCP\u2019s specific approach to congestion control in great \ndetail. Here, we identify the two broad approaches to congestion control that are \ntaken in practice and discuss specific network architectures and congestion-control \nprotocols embodying", "doc_id": "95990c9d-b7f3-4f76-b347-9db57205d2b2", "embedding": null, "doc_hash": "17e98ae240990a2ffd95b5dafedb4a2bfe76510b831ff80f0cab1e63ce135819", "extra_info": null, "node_info": {"start": 850098, "end": 853605}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "abc72242-8a0e-44b1-9a57-07336ce970c0", "3": "5bc1c6f9-3622-436d-9fce-b879a860f4a4"}}, "__type__": "1"}, "5bc1c6f9-3622-436d-9fce-b879a860f4a4": {"__data__": {"text": "packet \nis dropped along a path, the transmission capacity that was used at each of the \nupstream links to forward that packet to the point at which it is dropped ends up \nhaving been wasted.R/2 /H9261out\n/H9261\u2019in\nFigure 3.48  \u2666  Scenario 3 performance with finite buffers and multihop \npaths\n296     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\n3.6.2  Approaches to Congestion Control\nIn Section 3.7, we\u2019ll examine TCP\u2019s specific approach to congestion control in great \ndetail. Here, we identify the two broad approaches to congestion control that are \ntaken in practice and discuss specific network architectures and congestion-control \nprotocols embodying these approaches.\nAt the highest level, we can distinguish among congestion-control approaches \nby whether the network layer provides explicit assistance to the transport layer for \ncongestion-control purposes:\n\u2022 End-to-end congestion control . In an end-to-end approach to congestion control, \nthe network layer provides no explicit support to the transport layer for conges -\ntion-control purposes. Even the presence of network congestion must be inferred \nby the end systems based only on observed network behavior (for example, packet \nloss and delay). We\u2019ll see shortly in Section 3.7.1 that TCP takes this end-to-end \napproach toward congestion control, since the IP layer is not required to provide \nfeedback to hosts regarding network congestion. TCP segment loss (as indicated \nby a timeout or the receipt of three duplicate acknowledgments) is taken as an \nindication of network congestion, and TCP decreases its window size accord -\ningly. We\u2019ll also see a more recent proposal for TCP congestion control that \nuses increasing round-trip segment delay as an indicator of increased network  \ncongestion\n\u2022 Network-assisted congestion control . With network-assisted congestion control, \nrouters provide explicit feedback to the sender and/or receiver regarding the con -\ngestion state of the network. This feedback may be as simple as a single bit indi -\ncating congestion at a link \u2013 an approach taken in the early IBM SNA [Schwartz \n1982], DEC DECnet [Jain 1989; Ramakrishnan 1990] architectures, and ATM \n[Black 1995] network architectures. More sophisticated feedback is also possible. \nFor example, in ATM Available Bite Rate (ABR)  congestion control, a router \ninforms the sender of the maximum host sending rate it (the router) can support \non an outgoing link. As noted above, the Internet-default versions of IP and TCP \nadopt an end-to-end approach towards congestion control. We\u2019ll see, however, \nin Section 3.7.2  that, more recently, IP and TCP may also optionally implement \nnetwork-assisted congestion control.\nFor network-assisted congestion control, congestion information is typically \nfed back from the network to the sender in one of two ways, as shown in Figure \n3.49. Direct feedback may be sent from a network router to the sender. This form \nof notification typically takes the form of a choke packet (essentially saying, \u201cI\u2019m \ncongested!\u201d). The second and more common form of notification occurs when a \nrouter marks/updates a field in a packet flowing from sender to receiver to indicate \ncongestion. Upon receipt of a marked packet, the receiver then notifies the sender of \nthe congestion indication. This latter form of notification takes a full round-trip time.\n3.7  \u2022  TCP CONGESTION CONTROL      297\n3.7 TCP Congestion Control\nIn this section we return to our study of TCP. As we learned in Section 3.5, TCP pro -\nvides a reliable transport service between two processes running on different hosts. \nAnother key component of", "doc_id": "5bc1c6f9-3622-436d-9fce-b879a860f4a4", "embedding": null, "doc_hash": "5d989181d2168ef71dd5de0d11cf01ed03c180d88770f688626fcbcf3274867a", "extra_info": null, "node_info": {"start": 853648, "end": 857263}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "95990c9d-b7f3-4f76-b347-9db57205d2b2", "3": "f4ef81c2-9b05-4f10-8e89-77e6c59ad74e"}}, "__type__": "1"}, "f4ef81c2-9b05-4f10-8e89-77e6c59ad74e": {"__data__": {"text": "typically takes the form of a choke packet (essentially saying, \u201cI\u2019m \ncongested!\u201d). The second and more common form of notification occurs when a \nrouter marks/updates a field in a packet flowing from sender to receiver to indicate \ncongestion. Upon receipt of a marked packet, the receiver then notifies the sender of \nthe congestion indication. This latter form of notification takes a full round-trip time.\n3.7  \u2022  TCP CONGESTION CONTROL      297\n3.7 TCP Congestion Control\nIn this section we return to our study of TCP. As we learned in Section 3.5, TCP pro -\nvides a reliable transport service between two processes running on different hosts. \nAnother key component of TCP is its congestion-control mechanism. As indicated \nin the previous section, TCP must use end-to-end congestion control rather than net -\nwork-assisted congestion control, since the IP layer provides no explicit feedback to \nthe end systems regarding network congestion.\nThe approach taken by TCP is to have each sender limit the rate at which it \nsends traffic into its connection as a function of perceived network congestion. If \na TCP sender perceives that there is little congestion on the path between itself and \nthe destination, then the TCP sender increases its send rate; if the sender perceives \nthat there is congestion along the path, then the sender reduces its send rate. But this \napproach raises three questions. First, how does a TCP sender limit the rate at which \nit sends traffic into its connection? Second, how does a TCP sender perceive that \nthere is congestion on the path between itself and the destination? And third, what \nalgorithm should the sender use to change its send rate as a function of perceived \nend-to-end congestion?\nLet\u2019s first examine how a TCP sender limits the rate at which it sends traffic into \nits connection. In Section 3.5 we saw that each side of a TCP connection consists of \na receive buffer, a send buffer, and several variables ( LastByteRead , rwnd , and \nso on). The TCP congestion-control mechanism operating at the sender keeps track Host A\nNetwork feedback via receiver\nDirect network\nfeedbackHost B\nFigure 3.49  \u2666  Two feedback pathways for network-indicated congestion \ninformation\n298     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nof an additional variable, the congestion window . The congestion window, denoted \ncwnd , imposes a constraint on the rate at which a TCP sender can send traffic into \nthe network. Specifically, the amount of unacknowledged data at a sender may not \nexceed the minimum of cwnd  and rwnd , that is:\nLastByteSent \u2013 LastByteAcked \u2026 min{cwnd, rwnd}\nIn order to focus on congestion control (as opposed to flow control), let us henceforth \nassume that the TCP receive buffer is so large that the receive-window constraint can \nbe ignored; thus, the amount of unacknowledged data at the sender is solely limited \nby cwnd . We will also assume that the sender always has data to send, i.e., that all \nsegments in the congestion window are sent.\nThe constraint above limits the amount of unacknowledged data at the sender \nand therefore indirectly limits the sender\u2019s send rate. To see this, consider a connec -\ntion for which loss and packet transmission delays are negligible. Then, roughly, at \nthe beginning of every RTT, the constraint permits the sender to send cwnd  bytes of \ndata into the connection; at the end of the RTT the sender receives acknowledgments \nfor the data. Thus the sender\u2019s send rate is roughly cwnd/RTT bytes/sec. By adjusting \nthe value of cwnd , the sender can therefore adjust the rate at which it sends data into \nits", "doc_id": "f4ef81c2-9b05-4f10-8e89-77e6c59ad74e", "embedding": null, "doc_hash": "2ea728f4dde3fa1a57f4b2fb6fd1c1c88466fdd05026ba18ca091bfd363c614b", "extra_info": null, "node_info": {"start": 857249, "end": 860854}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "5bc1c6f9-3622-436d-9fce-b879a860f4a4", "3": "38b2bc5f-6107-48c5-9abf-3e207d112c19"}}, "__type__": "1"}, "38b2bc5f-6107-48c5-9abf-3e207d112c19": {"__data__": {"text": "the sender always has data to send, i.e., that all \nsegments in the congestion window are sent.\nThe constraint above limits the amount of unacknowledged data at the sender \nand therefore indirectly limits the sender\u2019s send rate. To see this, consider a connec -\ntion for which loss and packet transmission delays are negligible. Then, roughly, at \nthe beginning of every RTT, the constraint permits the sender to send cwnd  bytes of \ndata into the connection; at the end of the RTT the sender receives acknowledgments \nfor the data. Thus the sender\u2019s send rate is roughly cwnd/RTT bytes/sec. By adjusting \nthe value of cwnd , the sender can therefore adjust the rate at which it sends data into \nits connection.\nLet\u2019s next consider how a TCP sender perceives that there is congestion on the \npath between itself and the destination. Let us define a \u201closs event\u201d at a TCP sender \nas the occurrence of either a timeout or the receipt of three duplicate ACKs from the \nreceiver. (Recall our discussion in Section 3.5.4 of the timeout event in Figure 3.33 \nand the subsequent modification to include fast retransmit on receipt of three dupli -\ncate ACKs.) When there is excessive congestion, then one (or more) router buffers \nalong the path overflows, causing a datagram (containing a TCP segment) to be \ndropped. The dropped datagram, in turn, results in a loss event at the sender\u2014either \na timeout or the receipt of three duplicate ACKs\u2014which is taken by the sender to be \nan indication of congestion on the sender-to-receiver path.\nHaving considered how congestion is detected, let\u2019s next consider the more opti -\nmistic case when the network is congestion-free, that is, when a loss event doesn\u2019t \noccur. In this case, acknowledgments for previously unacknowledged segments \nwill be received at the TCP sender. As we\u2019ll see, TCP will take the arrival of these \nacknowledgments as an indication that all is well\u2014that segments being transmitted \ninto the network are being successfully delivered to the destination\u2014and will use \nacknowledgments to increase its congestion window size (and hence its transmis -\nsion rate). Note that if acknowledgments arrive at a relatively slow rate (e.g., if the \nend-end path has high delay or contains a low-bandwidth link), then the congestion \nwindow will be increased at a relatively slow rate. On the other hand, if acknowl -\nedgments arrive at a high rate, then the congestion window will be increased more \nquickly. Because TCP uses acknowledgments to trigger (or clock) its increase in \ncongestion window size, TCP is said to be self-clocking .\n3.7  \u2022  TCP CONGESTION CONTROL      299\nGiven the mechanism  of adjusting the value of cwnd  to control the sending rate, \nthe critical question remains: How  should a TCP sender determine the rate at which it \nshould send? If TCP senders collectively send too fast, they can congest the network, \nleading to the type of congestion collapse that we saw in Figure 3.48. Indeed, the ver -\nsion of TCP that we\u2019ll study shortly was developed in response to observed Internet \ncongestion collapse [Jacobson 1988] under earlier versions of TCP. However, if TCP \nsenders are too cautious and send too slowly, they could under utilize the bandwidth \nin the network; that is, the TCP senders could send at a higher rate without congest -\ning the network. How then do the TCP senders determine their sending rates such \nthat they don\u2019t congest the network but at the same time make use of all the avail -\nable bandwidth? Are TCP senders explicitly coordinated, or is there a distributed \napproach in which the TCP senders can set their sending rates based only on local", "doc_id": "38b2bc5f-6107-48c5-9abf-3e207d112c19", "embedding": null, "doc_hash": "e88de3ff5e32dbfb3ff8b39c98096808b0b479ae27e5001a3513f0642e28c1e0", "extra_info": null, "node_info": {"start": 860836, "end": 864484}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "f4ef81c2-9b05-4f10-8e89-77e6c59ad74e", "3": "79749186-56a1-458e-8206-56eceece27a6"}}, "__type__": "1"}, "79749186-56a1-458e-8206-56eceece27a6": {"__data__": {"text": "the type of congestion collapse that we saw in Figure 3.48. Indeed, the ver -\nsion of TCP that we\u2019ll study shortly was developed in response to observed Internet \ncongestion collapse [Jacobson 1988] under earlier versions of TCP. However, if TCP \nsenders are too cautious and send too slowly, they could under utilize the bandwidth \nin the network; that is, the TCP senders could send at a higher rate without congest -\ning the network. How then do the TCP senders determine their sending rates such \nthat they don\u2019t congest the network but at the same time make use of all the avail -\nable bandwidth? Are TCP senders explicitly coordinated, or is there a distributed \napproach in which the TCP senders can set their sending rates based only on local \ninformation? TCP answers these questions using the following guiding principles:\n\u2022 A lost segment implies congestion, and hence, the TCP sender\u2019s rate should be \ndecreased when a segment is lost.  Recall from our discussion in Section 3.5.4, \nthat a timeout event or the receipt of four acknowledgments for a given segment \n(one original ACK and then three duplicate ACKs) is interpreted as an implicit \n\u201closs event\u201d indication of the segment following the quadruply ACKed segment, \ntriggering a retransmission of the lost segment. From a congestion-control stand -\npoint, the question is how the TCP sender should decrease its congestion window \nsize, and hence its sending rate, in response to this inferred loss event.\n\u2022 An acknowledged segment indicates that the network is delivering the sender\u2019s \nsegments to the receiver, and hence, the sender\u2019s rate can be increased when an \nACK arrives for a previously unacknowledged segment.  The arrival of acknowl -\nedgments is taken as an implicit indication that all is well\u2014segments are being \nsuccessfully delivered from sender to receiver, and the network is thus not con -\ngested. The congestion window size can thus be increased.\n\u2022 Bandwidth probing . Given ACKs indicating a congestion-free source-to-destina -\ntion path and loss events indicating a congested path, TCP\u2019s strategy for adjusting \nits transmission rate is to increase its rate in response to arriving ACKs until a loss \nevent occurs, at which point, the transmission rate is decreased. The TCP sender \nthus increases its transmission rate to probe for the rate that at which congestion \nonset begins, backs off from that rate, and then to begins probing again to see \nif the congestion onset rate has changed. The TCP sender\u2019s behavior is perhaps \nanalogous to the child who requests (and gets) more and more goodies until finally \nhe/she is finally told \u201cNo!\u201d, backs off a bit, but then begins making requests again \nshortly afterwards. Note that there is no explicit signaling of congestion state by \nthe network\u2014ACKs and loss events serve as implicit signals\u2014and that each TCP \nsender acts on local information asynchronously from other TCP senders.\nGiven this overview of TCP congestion control, we\u2019re now in a position to consider the \ndetails of the celebrated TCP congestion-control algorithm , which was first described \n300     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nin [Jacobson 1988] and is standardized in [RFC 5681]. The algorithm has three major \ncomponents: (1) slow start, (2) congestion avoidance, and (3) fast recovery. Slow start \nand congestion avoidance are mandatory components of TCP, differing in how they \nincrease the size of cwnd  in response to received ACKs. We\u2019ll see shortly that slow \nstart increases the size of cwnd  more rapidly (despite its name!) than congestion avoid -\nance. Fast recovery is recommended, but not required, for TCP senders.\nSlow Start\nWhen a TCP connection", "doc_id": "79749186-56a1-458e-8206-56eceece27a6", "embedding": null, "doc_hash": "8bcb9278e61e24651bf2cffc37984bd87741ec7de50006e5fcbdc428964eba30", "extra_info": null, "node_info": {"start": 864444, "end": 868121}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "38b2bc5f-6107-48c5-9abf-3e207d112c19", "3": "20e23f9c-25a1-43cd-944d-5f2cd5d2c9dd"}}, "__type__": "1"}, "20e23f9c-25a1-43cd-944d-5f2cd5d2c9dd": {"__data__": {"text": "of the celebrated TCP congestion-control algorithm , which was first described \n300     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nin [Jacobson 1988] and is standardized in [RFC 5681]. The algorithm has three major \ncomponents: (1) slow start, (2) congestion avoidance, and (3) fast recovery. Slow start \nand congestion avoidance are mandatory components of TCP, differing in how they \nincrease the size of cwnd  in response to received ACKs. We\u2019ll see shortly that slow \nstart increases the size of cwnd  more rapidly (despite its name!) than congestion avoid -\nance. Fast recovery is recommended, but not required, for TCP senders.\nSlow Start\nWhen a TCP connection begins, the value of cwnd  is typically initialized to a small \nvalue of 1 MSS [RFC 3390], resulting in an initial sending rate of roughly MSS/\nRTT. For example, if MSS = 500 bytes and RTT = 200 msec, the resulting initial \nsending rate is only about 20 kbps. Since the available bandwidth to the TCP sender \nmay be much larger than MSS/RTT, the TCP sender would like to find the amount of \navailable bandwidth quickly. Thus, in the slow-start  state, the value of cwnd  begins \nat 1 MSS and increases by 1 MSS every time a transmitted segment is first acknowl -\nedged. In the example of Figure 3.50, TCP sends the first segment into the network \nHost A Host B\none segment\ntwo segments\nfour segmentsRTT\nTime Time\nFigure 3.50  \u2666 TCP slow start\n3.7  \u2022  TCP CONGESTION CONTROL      301\nand waits for an acknowledgment. When this acknowledgment arrives, the TCP \nsender increases the congestion window by one MSS and sends out two maximum-\nsized segments. These segments are then acknowledged, with the sender increasing \nthe congestion window by 1 MSS for each of the acknowledged segments, giving a \ncongestion window of 4 MSS, and so on. This process results in a doubling of the \nsending rate every RTT. Thus, the TCP send rate starts slow but grows exponentially \nduring the slow start phase.\nBut when should this exponential growth end? Slow start provides several \nanswers to this question. First, if there is a loss event (i.e., congestion) indicated \nby a timeout, the TCP sender sets the value of cwnd  to 1 and begins the slow start \nprocess anew. It also sets the value of a second state variable, ssthresh  (shorthand \nfor \u201cslow start threshold\u201d) to cwnd/2 \u2014half of the value of the congestion window \nvalue when congestion was detected. The second way in which slow start may end \nis directly tied to the value of ssthresh . Since ssthresh  is half the value of \ncwnd  when congestion was last detected, it might be a bit reckless to keep doubling \ncwnd  when it reaches or surpasses the value of ssthresh . Thus, when the value of \ncwnd  equals ssthresh , slow start ends and TCP transitions into congestion avoid -\nance mode. As we\u2019ll see, TCP increases cwnd  more cautiously when in congestion-\navoidance mode. The final way in which slow start can end is if three duplicate \nACKs are detected, in which case TCP performs a fast retransmit (see Section 3.5.4) \nand enters the fast recovery state, as discussed below. TCP\u2019s behavior in slow start \nis summarized in the FSM description of TCP congestion control in Figure 3.51. The \nslow-start algorithm traces it roots to [Jacobson 1988]; an approach similar to slow \nstart was also proposed independently in [Jain 1986].\nCongestion Avoidance\nOn entry to the congestion-avoidance state, the value of cwnd  is approximately half \nits value when congestion was last", "doc_id": "20e23f9c-25a1-43cd-944d-5f2cd5d2c9dd", "embedding": null, "doc_hash": "d990e7515731a10d5457235993c90390fd1f77e98e7fa4b2348ff44d1af5c0bc", "extra_info": null, "node_info": {"start": 868194, "end": 871676}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "79749186-56a1-458e-8206-56eceece27a6", "3": "6af50f47-0e94-4fa8-a380-1f85f00a7cec"}}, "__type__": "1"}, "6af50f47-0e94-4fa8-a380-1f85f00a7cec": {"__data__": {"text": "mode. As we\u2019ll see, TCP increases cwnd  more cautiously when in congestion-\navoidance mode. The final way in which slow start can end is if three duplicate \nACKs are detected, in which case TCP performs a fast retransmit (see Section 3.5.4) \nand enters the fast recovery state, as discussed below. TCP\u2019s behavior in slow start \nis summarized in the FSM description of TCP congestion control in Figure 3.51. The \nslow-start algorithm traces it roots to [Jacobson 1988]; an approach similar to slow \nstart was also proposed independently in [Jain 1986].\nCongestion Avoidance\nOn entry to the congestion-avoidance state, the value of cwnd  is approximately half \nits value when congestion was last encountered\u2014congestion could be just around the \ncorner! Thus, rather than doubling the value of cwnd  every RTT, TCP adopts a more \nconservative approach and increases the value of cwnd  by just a single MSS every \nRTT [RFC 5681]. This can be accomplished in several ways. A common approach \nis for the TCP sender to increase cwnd  by MSS bytes (MSS/ cwnd ) whenever a new \nacknowledgment arrives. For example, if MSS is 1,460 bytes and cwnd  is 14,600 \nbytes, then 10 segments are being sent within an RTT. Each arriving ACK (assuming \none ACK per segment) increases the congestion window size by 1/10 MSS, and thus, \nthe value of the congestion window will have increased by one MSS after ACKs \nwhen all 10 segments have been received.\nBut when should congestion avoidance\u2019s linear increase (of 1 MSS per RTT) \nend? TCP\u2019s congestion-avoidance algorithm behaves the same when a timeout occurs. \nAs in the case of slow start: The value of cwnd  is set to 1 MSS, and the value of \nssthresh  is updated to half the value of cwnd  when the loss event occurred. Recall, \nhowever, that a loss event also can be triggered by a triple duplicate ACK event.  \n302     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nIn this case, the network is continuing to deliver segments from sender to receiver (as \nindicated by the receipt of duplicate ACKs). So TCP\u2019s behavior to this type of loss \nevent should be less drastic than with a timeout-indicated loss: TCP halves the value \nof cwnd  (adding in 3 MSS for good measure to account for the triple duplicate ACKs \nreceived) and records the value of ssthresh  to be half the value of cwnd  when the \ntriple duplicate ACKs were received. The fast-recovery state is then entered.\nFast Recovery\nIn fast recovery, the value of cwnd  is increased by 1 MSS for every duplicate \nACK received for the missing segment that caused TCP to enter the fast-recovery \nstate. Eventually, when an ACK arrives for the missing segment, TCP enters the  Slow\nstartduplicate ACK\ndupACKcount++\nduplicate ACK\ndupACKcount++timeout\nssthresh =cwnd/2\ncwnd=1 MSS\ndupACKcount=0cwnd=1 MSS\nssthresh =64 KB\ndupACKcount=0\ntimeout\nssthresh=cwnd/2\ncwnd=1\ndupACKcount=0timeout\nssthresh=cwnd/2\ncwnd=1 MSS\ndupACKcount=0cwnd /H11350ssthresh\nCongestion\navoidance\nFast\nrecoverynew ACK\ncwnd=cwnd+MSS \u2022(MSS/cwnd)\ndupACKcount=0\ntransmit new segment(s), as allowe dnew ACK\ncwnd=cwnd+MSS\ndupACKcount=0\ntransmit new segment(s), as allowed\nretransmit missing segment\nretransmit missing", "doc_id": "6af50f47-0e94-4fa8-a380-1f85f00a7cec", "embedding": null, "doc_hash": "648f9c3a3ab964536e088a5ec8a76c0dfc48e10ed9175100c4f3498fbcd4953e", "extra_info": null, "node_info": {"start": 871644, "end": 874798}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "20e23f9c-25a1-43cd-944d-5f2cd5d2c9dd", "3": "566e6c97-202b-429f-b6b9-74da4ea70483"}}, "__type__": "1"}, "566e6c97-202b-429f-b6b9-74da4ea70483": {"__data__": {"text": "MSS\ndupACKcount=0cwnd=1 MSS\nssthresh =64 KB\ndupACKcount=0\ntimeout\nssthresh=cwnd/2\ncwnd=1\ndupACKcount=0timeout\nssthresh=cwnd/2\ncwnd=1 MSS\ndupACKcount=0cwnd /H11350ssthresh\nCongestion\navoidance\nFast\nrecoverynew ACK\ncwnd=cwnd+MSS \u2022(MSS/cwnd)\ndupACKcount=0\ntransmit new segment(s), as allowe dnew ACK\ncwnd=cwnd+MSS\ndupACKcount=0\ntransmit new segment(s), as allowed\nretransmit missing segment\nretransmit missing segment dupACKcount==3\nssthresh=cwnd/2\ncwnd=ssthresh+3 \u2022MSS\nretransmit missing segment\nduplicate ACK\ncwnd=cwnd+MSS\ntransmit new segment(s), as alloweddupACKcount==3\nssthresh=cwnd/2\ncwnd=ssthresh+3 \u2022MSS\nretransmit missing segmentretransmit missing segment\nnew ACK\ncwnd=ssthresh\ndupACKcount=0/H9011/H9011\nFigure 3.51  \u2666 FSM description of TCP congestion control\nVideoNote\nExamining the behavior \nof TCP\n3.7  \u2022  TCP CONGESTION CONTROL      303\ncongestion-avoidance state after deflating cwnd . If a timeout event occurs, fast \nrecovery transitions to the slow-start state after performing the same actions as in \nslow start and congestion avoidance: The value of cwnd  is set to 1 MSS, and the \nvalue of ssthresh  is set to half the value of cwnd  when the loss event occurred.TCP SPLITTING: OPTIMIZING THE PERFORMANCE OF CLOUD SERVICES\nFor cloud services such as search, e-mail, and social networks, it is desirable to provide a \nhigh-level of responsiveness, ideally giving users the illusion that the services are running \nwithin their own end systems (including their smartphones). This can be a major challenge, \nas users are often located far away from the data centers responsible for serving the \ndynamic content associated with the cloud services. Indeed, if the end system is far from \na data center, then the RTT will be large, potentially leading to poor response time perfor -\nmance due to TCP slow start.\nAs a case study, consider the delay in receiving a response for a search query. \nTypically, the server requires three TCP windows during slow start to deliver the response \n[Pathak 2010]. Thus the time from when an end system initiates a TCP connection until the \ntime when it receives the last packet of the response is roughly 4 #RTT (one RTT to set up \nthe TCP connection plus three RTTs for the three windows of data) plus the processing time \nin the data center. These RTT delays can lead to a noticeable delay in returning search \nresults for a significant fraction of queries. Moreover, there can be significant packet loss \nin access networks, leading to TCP retransmissions and even larger delays.\nOne way to mitigate this problem and improve user-perceived performance is to  \n(1) deploy front-end servers closer to the users, and (2) utilize TCP splitting  by break -\ning the TCP connection at the front-end server. With TCP splitting, the client establishes \na TCP connection to the nearby front-end, and the front-end maintains a persistent TCP \nconnection to the data center with a very large TCP congestion window [Tariq 2008, \nPathak 2010, Chen 2011]. With this approach, the response time roughly becomes \n4#RTTFE+RTTBE+processing time, where RTTFE is the round-trip time between client and \nfront-end server, and RTTBE is the round-trip time between the front-end server and the data \ncenter (back-end server). If the front-end server is close to client, then this response time \napproximately becomes RTT plus processing", "doc_id": "566e6c97-202b-429f-b6b9-74da4ea70483", "embedding": null, "doc_hash": "a6238d86db7969a328ebdccd2181fbb688f34281dfc42c6db570447d015814d6", "extra_info": null, "node_info": {"start": 874997, "end": 878359}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "6af50f47-0e94-4fa8-a380-1f85f00a7cec", "3": "9cc31a30-f666-4eed-8745-b1314b348632"}}, "__type__": "1"}, "9cc31a30-f666-4eed-8745-b1314b348632": {"__data__": {"text": "servers closer to the users, and (2) utilize TCP splitting  by break -\ning the TCP connection at the front-end server. With TCP splitting, the client establishes \na TCP connection to the nearby front-end, and the front-end maintains a persistent TCP \nconnection to the data center with a very large TCP congestion window [Tariq 2008, \nPathak 2010, Chen 2011]. With this approach, the response time roughly becomes \n4#RTTFE+RTTBE+processing time, where RTTFE is the round-trip time between client and \nfront-end server, and RTTBE is the round-trip time between the front-end server and the data \ncenter (back-end server). If the front-end server is close to client, then this response time \napproximately becomes RTT plus processing time, since RTTFE is negligibly small and RTTBE \nis approximately RTT. In summary, TCP splitting can reduce the networking delay roughly \nfrom 4#RTT to RTT, significantly improving user-perceived performance, particularly for \nusers who are far from the nearest data center. TCP splitting also helps reduce TCP  \nretransmission delays caused by losses in access networks. Google and Akamai have \nmade extensive use of their CDN servers in access networks (recall our discussion in \nSection 2.6 ) to perform TCP splitting for the cloud services they support [Chen 2011].PRINCIPLES IN PRACTICE\n\n304     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nFast recovery is a recommended, but not required, component of TCP [RFC \n5681]. It is interesting that an early version of TCP, known as TCP Tahoe , uncon -\nditionally cut its congestion window to 1 MSS and entered the slow-start phase after \neither a timeout-indicated or triple-duplicate-ACK-indicated loss event. The newer \nversion of TCP, TCP Reno , incorporated fast recovery.\nFigure 3. 52 illustrates the evolution of TCP\u2019s congestion window for both Reno \nand Tahoe. In this figure, the threshold is initially equal to 8 MSS. For the first \neight transmission rounds, Tahoe and Reno take identical actions. The congestion \nwindow climbs exponentially fast during slow start and hits the threshold at the fourth \nround of transmission. The congestion window then climbs linearly until a triple \nduplicate- ACK event occurs, just after transmission round 8. Note that the congestion \nwindow is 12 # MSS when this loss event occurs. The value of ssthresh  is then set \nto 0.5 # cwnd  = 6 # MSS. Under TCP Reno, the congestion window is set to cwnd  =  \n9 # MSS and then grows linearly. Under TCP Tahoe, the congestion window is set to \n1 MSS and grows exponentially until it reaches the value of ssthresh , at which \npoint it grows linearly.\nFigure 3. 51 presents the complete FSM description of TCP\u2019s congestion-control \nalgorithms\u2014slow start, congestion avoidance, and fast recovery. The figure also \nindicates where transmission of new segments or retransmitted segments can occur. \nAlthough it is important to distinguish between TCP error control/retransmission and \nTCP congestion control, it\u2019s also important to appreciate how these two aspects of \nTCP are inextricably linked.\nTCP Congestion Control: Retrospective\nHaving delved into the details of slow start, congestion avoidance, and fast recovery,  \nit\u2019s worthwhile to now step back and view the forest from the trees. Ignoring the \n0\n102 34 56 78\nTransmission roundTCP T ahoessthresh\nssthreshCongestion window\n(in segments)\n910111 21 31415246810121416\nTCP Reno\nFigure 3.52  \u2666 Evolution of TCP\u2019s congestion window (Tahoe and Reno)\n3.7  \u2022  TCP CONGESTION CONTROL      305\ninitial", "doc_id": "9cc31a30-f666-4eed-8745-b1314b348632", "embedding": null, "doc_hash": "6a81893796962efec39b2dbced485ba1d4554648364bd3f3597867aa458e6727", "extra_info": null, "node_info": {"start": 878127, "end": 881637}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "566e6c97-202b-429f-b6b9-74da4ea70483", "3": "209b3d4a-23ec-4e3c-9f22-67450e00dd5d"}}, "__type__": "1"}, "209b3d4a-23ec-4e3c-9f22-67450e00dd5d": {"__data__": {"text": "error control/retransmission and \nTCP congestion control, it\u2019s also important to appreciate how these two aspects of \nTCP are inextricably linked.\nTCP Congestion Control: Retrospective\nHaving delved into the details of slow start, congestion avoidance, and fast recovery,  \nit\u2019s worthwhile to now step back and view the forest from the trees. Ignoring the \n0\n102 34 56 78\nTransmission roundTCP T ahoessthresh\nssthreshCongestion window\n(in segments)\n910111 21 31415246810121416\nTCP Reno\nFigure 3.52  \u2666 Evolution of TCP\u2019s congestion window (Tahoe and Reno)\n3.7  \u2022  TCP CONGESTION CONTROL      305\ninitial slow-start period when a connection begins and assuming that losses are indi -\ncated by triple duplicate ACKs rather than timeouts, TCP\u2019s congestion control con -\nsists of linear (additive) increase in cwnd  of 1 MSS per RTT and then a halving \n(multiplicative decrease) of cwnd  on a triple duplicate-ACK event. For this reason, \nTCP congestion control is often referred to as an additive-increase, multiplicative-\ndecrease (AIMD)  form of congestion control. AIMD congestion control gives rise \nto the \u201csaw tooth\u201d behavior shown in Figure 3.53, which also nicely illustrates our \nearlier intuition of TCP \u201cprobing\u201d for bandwidth\u2014TCP linearly increases its con -\ngestion window size (and hence its transmission rate) until a triple duplicate-ACK \nevent occurs. It then decreases its congestion window size by a factor of two but \nthen again begins increasing it linearly, probing to see if there is additional available \nbandwidth.\nAs noted previously, many TCP implementations use the Reno algorithm  \n[Padhye 2001]. Many variations of the Reno algorithm have been proposed [RFC \n3782; RFC 2018]. The TCP Vegas algorithm [Brakmo 1995; Ahn 1995] attempts to \navoid congestion while maintaining good throughput. The basic idea of Vegas is to \n(1) detect congestion in the routers between source and destination before  packet loss \noccurs, and (2) lower the rate linearly when this imminent packet loss is detected. \nImminent packet loss is predicted by observing the RTT. The longer the RTT of the \npackets, the greater the congestion in the routers. As of late 2015, the Ubuntu Linux \nimplementation of TCP provided slowstart, congestion avoidance, fast recovery, fast \nretransmit, and SACK, by default; alternative congestion control algorithms, such as \nTCP Vegas and BIC [Xu 2004], are also provided. For a survey of the many flavors \nof TCP, see [Afanasyev 2010].\nTCP\u2019s AIMD algorithm was developed based on a tremendous amount of \nengineering insight and experimentation with congestion control in operational  24 K\n16 K\n8 K\nTimeCongestion window\nFigure 3.53  \u2666 Additive-increase, multiplicative-decrease congestion control\n306     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nnetworks. Ten years after TCP\u2019s development, theoretical analyses showed that \nTCP\u2019s congestion-control algorithm serves as a distributed asynchronous-optimization \nalgorithm that results in several important aspects of user and network performance \nbeing simultaneously optimized [Kelly 1998]. A rich theory of congestion control \nhas since been developed [Srikant 2004].\nMacroscopic Description of TCP Throughput\nGiven the saw-toothed behavior of TCP, it\u2019s natural to consider what the average \nthroughput (that is, the average rate) of a long-lived TCP connection might be. In this \nanalysis we\u2019ll ignore the slow-start phases that occur after timeout events. (These", "doc_id": "209b3d4a-23ec-4e3c-9f22-67450e00dd5d", "embedding": null, "doc_hash": "06f081827f72489e155d445c8ac695725f47a1ff7eb13433ac6bf38af6bf4a10", "extra_info": null, "node_info": {"start": 881740, "end": 885184}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "9cc31a30-f666-4eed-8745-b1314b348632", "3": "69cfc77f-e887-4033-85ac-83a15e173791"}}, "__type__": "1"}, "69cfc77f-e887-4033-85ac-83a15e173791": {"__data__": {"text": "congestion control\n306     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nnetworks. Ten years after TCP\u2019s development, theoretical analyses showed that \nTCP\u2019s congestion-control algorithm serves as a distributed asynchronous-optimization \nalgorithm that results in several important aspects of user and network performance \nbeing simultaneously optimized [Kelly 1998]. A rich theory of congestion control \nhas since been developed [Srikant 2004].\nMacroscopic Description of TCP Throughput\nGiven the saw-toothed behavior of TCP, it\u2019s natural to consider what the average \nthroughput (that is, the average rate) of a long-lived TCP connection might be. In this \nanalysis we\u2019ll ignore the slow-start phases that occur after timeout events. (These \nphases are typically very short, since the sender grows out of the phase exponentially \nfast.) During a particular round-trip interval, the rate at which TCP sends data is a \nfunction of the congestion window and the current RTT. When the window size is w \nbytes and the current round-trip time is RTT second s, then TCP\u2019s transmission rate is \nroughly w/RTT.  TCP then probes for additional bandwidth by increasing w by 1 MSS \neach RTT until a loss event occurs. Denote by W the value of w when a loss event \noccurs. Assuming that RTT and W are approximately constant over the duration of \nthe connection, the TCP transmission rate ranges from W/(2 \u00b7 RTT) to W/RTT .\nThese assumptions lead to a highly simplified macroscopic model for the steady-\nstate behavior of TCP. The network drops a packet from the connection when the rate \nincreases to W/RTT;  the rate is then cut in half and then increases by MSS/ RTT every \nRTT until it again reaches W/RTT . This process repeats itself over and over again. \nBecause TCP\u2019s throughput (that is, rate) increases linearly between the two extreme \nvalues, we have\naverage throughput of a connection =0.75#W\nRTT\nUsing this highly idealized model for the steady-state dynamics of TCP, we \ncan also derive an interesting expression that relates a connection\u2019s loss rate to its \navailable bandwidth [Mahdavi 1997]. This derivation is outlined in the homework \nproblems. A more sophisticated model that has been found empirically to agree with \nmeasured data is [Padhye 2000].\nTCP Over High-Bandwidth Paths\nIt is important to realize that TCP congestion control has evolved over the years and \nindeed continues to evolve. For a summary of current TCP variants and discussion \nof TCP evolution, see [Floyd 2001, RFC 5681, Afanasyev 2010]. What was good for \nthe Internet when the bulk of the TCP connections carried SMTP, FTP, and Telnet \ntraffic is not necessarily good for today\u2019s HTTP-dominated Internet or for a future \nInternet with services that are still undreamed of.\n3.7  \u2022  TCP CONGESTION CONTROL      307\nThe need for continued evolution of TCP can be illustrated by considering the \nhigh-speed TCP connections that are needed for grid- and cloud-computing appli -\ncations. For example, consider a TCP connection with 1,500-byte segments and a  \n100 ms RTT, and suppose we want to send data through this connection at 10 Gbps. \nFollowing [RFC 3649], we note that using the TCP throughput formula above, in \norder to achieve a 10 Gbps throughput, the average congestion window size would \nneed to be 83,333 segments. That\u2019s a lot of segments, leading us to be rather con -\ncerned that one of these 83,333 in-flight segments might be lost. What would happen \nin the case of a loss? Or, put another way, what fraction of the transmitted segments \ncould be lost that would allow the TCP congestion-control algorithm specified in \nFigure 3. 51 still to achieve the desired 10 Gbps rate? In the homework questions for \nthis chapter, you are led through the", "doc_id": "69cfc77f-e887-4033-85ac-83a15e173791", "embedding": null, "doc_hash": "d2d5b8975a115a5a61dd1ebe6573d184e2548212e5ff470dc4b4044182ad2dbb", "extra_info": null, "node_info": {"start": 885073, "end": 888802}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "209b3d4a-23ec-4e3c-9f22-67450e00dd5d", "3": "e308e76c-a428-45d6-8367-b5cfd8ff0c96"}}, "__type__": "1"}, "e308e76c-a428-45d6-8367-b5cfd8ff0c96": {"__data__": {"text": "connection with 1,500-byte segments and a  \n100 ms RTT, and suppose we want to send data through this connection at 10 Gbps. \nFollowing [RFC 3649], we note that using the TCP throughput formula above, in \norder to achieve a 10 Gbps throughput, the average congestion window size would \nneed to be 83,333 segments. That\u2019s a lot of segments, leading us to be rather con -\ncerned that one of these 83,333 in-flight segments might be lost. What would happen \nin the case of a loss? Or, put another way, what fraction of the transmitted segments \ncould be lost that would allow the TCP congestion-control algorithm specified in \nFigure 3. 51 still to achieve the desired 10 Gbps rate? In the homework questions for \nthis chapter, you are led through the derivation of a formula relating the throughput \nof a TCP connection as a function of the loss rate ( L), the round-trip time ( RTT), and \nthe maximum segment size (MSS):\naverage throughput of a connection =1.22#MSS\nRTT 2L\nUsing this formula, we can see that in order to achieve a throughput of 10 Gbps, \ntoday\u2019s TCP congestion-control algorithm can only tolerate a segment loss probabil -\nity of 2 \u00b7 10\u201310 (or equivalently, one loss event for every 5,000,000,000 segments)\u2014a \nvery low rate. This observation has led a number of researchers to investigate new \nversions of TCP that are specifically designed for such high-speed environments; see \n[Jin 2004; Kelly 2003; Ha 2008; RFC 7323] for discussions of these efforts.\n3.7.1  Fairness\nConsider K TCP connections, each with a different end-to-end path, but all pass -\ning through a bottleneck link with transmission rate R bps. (By bottleneck link , we \nmean that for each connection, all the other links along the connection\u2019s path are not \ncongested and have abundant transmission capacity as compared with the transmis -\nsion capacity of the bottleneck link.) Suppose each connection is transferring a large \nfile and there is no UDP traffic passing through the bottleneck link. A congestion-\ncontrol mechanism is said to be fair if the average transmission rate of each connec -\ntion is approximately R/K;  that is, each connection gets an equal share of the link  \nbandwidth.\nIs TCP\u2019s AIMD algorithm fair, particularly given that different TCP connec -\ntions may start at different times and thus may have different window sizes at a given \npoint in time? [Chiu 1989] provides an elegant and intuitive explanation of why TCP \ncongestion control converges to provide an equal share of a bottleneck link\u2019s band -\nwidth among competing TCP connections.\nLet\u2019s consider the simple case of two TCP connections sharing a single link \nwith transmission rate R, as shown in Figure 3.54. Assume that the two connections \n308     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nhave the same MSS and RTT (so that if they have the same congestion window size, \nthen they have the same throughput), that they have a large amount of data to send, \nand that no other TCP connections or UDP datagrams traverse this shared link. Also, \nignore the slow-start phase of TCP and assume the TCP connections are operating in \nCA mode (AIMD) at all times.\nFigure 3. 55 plots the throughput realized by the two TCP connections. If TCP is \nto share the link bandwidth equally between the two connections, then the realized \nthroughput should fall along the 45-degree arrow (equal bandwidth share) emanating \nfrom the origin. Ideally, the sum of the two throughputs should equal R. (Certainly, \neach connection receiving an equal, but zero, share of the link capacity is not a desir -\nable situation!) So the goal should be to have the achieved throughputs fall some -\nwhere near the intersection of the equal bandwidth share line and the full bandwidth \nutilization line in Figure 3.55.\nSuppose that the TCP window sizes", "doc_id": "e308e76c-a428-45d6-8367-b5cfd8ff0c96", "embedding": null, "doc_hash": "af201021ed9dd37019ba3a4c1bf2ddf31d1e1a6b37da637f7f2dfad7fdc3d2f4", "extra_info": null, "node_info": {"start": 888813, "end": 892599}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "69cfc77f-e887-4033-85ac-83a15e173791", "3": "5691ceb5-2e3b-44d9-a5bf-6cdd8d6a6730"}}, "__type__": "1"}, "5691ceb5-2e3b-44d9-a5bf-6cdd8d6a6730": {"__data__": {"text": "the slow-start phase of TCP and assume the TCP connections are operating in \nCA mode (AIMD) at all times.\nFigure 3. 55 plots the throughput realized by the two TCP connections. If TCP is \nto share the link bandwidth equally between the two connections, then the realized \nthroughput should fall along the 45-degree arrow (equal bandwidth share) emanating \nfrom the origin. Ideally, the sum of the two throughputs should equal R. (Certainly, \neach connection receiving an equal, but zero, share of the link capacity is not a desir -\nable situation!) So the goal should be to have the achieved throughputs fall some -\nwhere near the intersection of the equal bandwidth share line and the full bandwidth \nutilization line in Figure 3.55.\nSuppose that the TCP window sizes are such that at a given point in time, con -\nnections 1 and 2 realize throughputs indicated by point A in Figure 3.55. Because the \namount of link bandwidth jointly consumed by the two connections is less than R, no \nloss will occur, and both connections will increase their window by 1 MSS per RTT \nas a result of TCP\u2019s congestion-avoidance algorithm. Thus, the joint throughput of \nthe two connections proceeds along a 45-degree line (equal increase for both connec -\ntions) starting from point A. Eventually, the link bandwidth jointly consumed by the \ntwo connections will be greater than R, and eventually packet loss will occur. Sup -\npose that connections 1 and 2 experience packet loss when they realize throughputs \nindicated by point B. Connections 1 and 2 then decrease their windows by a factor of \ntwo. The resulting throughputs realized are thus at point C, halfway along a vector \nstarting at B and ending at the origin. Because the joint bandwidth use is less than R \nat point C, the two connections again increase their throughputs along a 45-degree \nline starting from C. Eventually, loss will again occur, for example, at point D, and \nthe two connections again decrease their window sizes by a factor of two, and so on. \nYou should convince yourself that the bandwidth realized by the two connections \neventually fluctuates along the equal bandwidth share line. You should also convince TCP connection 2\nTCP connection 1Bottleneck\nrouter capacity R\nFigure 3.54  \u2666 Two TCP connections sharing a single bottleneck link\n3.7  \u2022  TCP CONGESTION CONTROL      309\nyourself that the two connections will converge to this behavior regardless of where \nthey are in the two-dimensional space! Although a number of idealized assumptions \nlie behind this scenario, it still provides an intuitive feel for why TCP results in an \nequal sharing of bandwidth among connections.\nIn our idealized scenario, we assumed that only TCP connections traverse the \nbottleneck link, that the connections have the same RTT value, and that only a single \nTCP connection is associated with a host-destination pair. In practice, these condi -\ntions are typically not met, and client-server applications can thus obtain very une -\nqual portions of link bandwidth. In particular, it has been shown that when multiple \nconnections share a common bottleneck, those sessions with a smaller RTT are able \nto grab the available bandwidth at that link more quickly as it becomes free (that is, \nopen their congestion windows faster) and thus will enjoy higher throughput than \nthose connections with larger RTTs [Lakshman 1997].\nFairness and UDP\nWe have just seen how TCP congestion control regulates an application\u2019s trans -\nmission rate via the congestion window mechanism. Many multimedia applications, \nsuch as Internet phone and video conferencing, often do not run over TCP for this \nvery reason\u2014they do not want their transmission rate throttled, even if the network \nis very congested. Instead, these applications prefer to run over UDP, which does not R\nREqual\nbandwidth\nshare\nConnection 1 throughputConnection 2 throughputD\nB\nC\nAFull bandwidth\nutilization line\nFigure 3.55  \u2666 Throughput realized by TCP", "doc_id": "5691ceb5-2e3b-44d9-a5bf-6cdd8d6a6730", "embedding": null, "doc_hash": "f253176cf3d6f90e121de32f09e58c738224fdc39a15b675ddb53d58a0c74860", "extra_info": null, "node_info": {"start": 892575, "end": 896538}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "e308e76c-a428-45d6-8367-b5cfd8ff0c96", "3": "c60ced93-4d86-485f-8dad-5bb39e79b1b7"}}, "__type__": "1"}, "c60ced93-4d86-485f-8dad-5bb39e79b1b7": {"__data__": {"text": "as it becomes free (that is, \nopen their congestion windows faster) and thus will enjoy higher throughput than \nthose connections with larger RTTs [Lakshman 1997].\nFairness and UDP\nWe have just seen how TCP congestion control regulates an application\u2019s trans -\nmission rate via the congestion window mechanism. Many multimedia applications, \nsuch as Internet phone and video conferencing, often do not run over TCP for this \nvery reason\u2014they do not want their transmission rate throttled, even if the network \nis very congested. Instead, these applications prefer to run over UDP, which does not R\nREqual\nbandwidth\nshare\nConnection 1 throughputConnection 2 throughputD\nB\nC\nAFull bandwidth\nutilization line\nFigure 3.55  \u2666 Throughput realized by TCP connections 1 and 2\n310     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nhave built-in congestion control. When running over UDP, applications can pump \ntheir audio and video into the network at a constant rate and occasionally lose pack -\nets, rather than reduce their rates to \u201cfair\u201d levels at times of congestion and not lose \nany packets. From the perspective of TCP, the multimedia applications running over \nUDP are not being fair\u2014they do not cooperate with the other connections nor adjust \ntheir transmission rates appropriately. Because TCP congestion control will decrease \nits transmission rate in the face of increasing congestion (loss), while UDP sources \nneed not, it is possible for UDP sources to crowd out TCP traffic. An area of research \ntoday is thus the development of congestion-control mechanisms for the Internet that \nprevent UDP traffic from bringing the Internet\u2019s throughput to a grinding halt [Floyd \n1999; Floyd 2000; Kohler 2006; RFC 4340].\nFairness and Parallel TCP Connections\nBut even if we could force UDP traffic to behave fairly, the fairness problem would \nstill not be completely solved. This is because there is nothing to stop a TCP-based \napplication from using multiple parallel connections. For example, Web browsers \noften use multiple parallel TCP connections to transfer the multiple objects within \na Web page. (The exact number of multiple connections is configurable in most \nbrowsers.) When an application uses multiple parallel connections, it gets a larger \nfraction of the bandwidth in a congested link. As an example, consider a link of rate \nR supporting nine ongoing client-server applications, with each of the applications \nusing one TCP connection. If a new application comes along and also uses one TCP \nconnection, then each application gets approximately the same transmission rate of \nR/10. But if this new application instead uses 11 parallel TCP connections, then the \nnew application gets an unfair allocation of more than R/2. Because Web traffic is so \npervasive in the Internet, multiple parallel connections are not uncommon.\n3.7.2   Explicit Congestion Notification (ECN):  \nNetwork-assisted Congestion Control\nSince the initial standardization of slow start and congestion avoidance in the late \n1980\u2019s [RFC 1122], TCP has implemented the form of end-end congestion control \nthat we studied in Section 3.7.1: a TCP sender receives no explicit congestion indica -\ntions from the network layer, and instead infers congestion through observed packet \nloss. More recently, extensions to both IP and TCP [RFC 3168] have been proposed, \nimplemented, and deployed that allow the network to explicitly signal congestion \nto a TCP sender and receiver. This form of network-assisted congestion control is \nknown as Explicit Congestion Notification . As shown in Figure 5.56, the TCP and \nIP protocols are involved.\nAt the network layer, two bits (with four possible values, overall) in the Type \nof Service field of the IP datagram header (which we\u2019ll discuss in Section 4.3 ) are \nused for ECN. One setting of the ECN bits is used by a router to indicate that it (the \n3.7", "doc_id": "c60ced93-4d86-485f-8dad-5bb39e79b1b7", "embedding": null, "doc_hash": "c3e8f02f640d9989262c38520896a9b6c224c1e12d6ebc623ce2546b075ac001", "extra_info": null, "node_info": {"start": 896539, "end": 900412}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "5691ceb5-2e3b-44d9-a5bf-6cdd8d6a6730", "3": "0d46923b-91aa-4910-9546-bba412e3be4b"}}, "__type__": "1"}, "0d46923b-91aa-4910-9546-bba412e3be4b": {"__data__": {"text": "indica -\ntions from the network layer, and instead infers congestion through observed packet \nloss. More recently, extensions to both IP and TCP [RFC 3168] have been proposed, \nimplemented, and deployed that allow the network to explicitly signal congestion \nto a TCP sender and receiver. This form of network-assisted congestion control is \nknown as Explicit Congestion Notification . As shown in Figure 5.56, the TCP and \nIP protocols are involved.\nAt the network layer, two bits (with four possible values, overall) in the Type \nof Service field of the IP datagram header (which we\u2019ll discuss in Section 4.3 ) are \nused for ECN. One setting of the ECN bits is used by a router to indicate that it (the \n3.7  \u2022  TCP CONGESTION CONTROL      311\nrouter) is experiencing congestion. This congestion indication is then carried in the \nmarked IP datagram to the destination host, which then informs the sending host, \nas shown in Figure 3.56. RFC 3168 does not provide a definition of when a router \nis congested; that decision is a configuration choice made possible by the router \nvendor, and decided by the network operator. However, RFC 3168 does recommend \nthat an ECN congestion indication be set only in the face of persistent congestion. A \nsecond setting of the ECN bits is used by the sending host to inform routers that the \nsender and receiver are ECN-capable, and thus capable of taking action in response \nto ECN-indicated network congestion.\nAs shown in Figure 3.56, when the TCP in the receiving host receives an ECN \ncongestion indication via a received datagram, the TCP in the receiving host informs \nthe TCP in the sending host of the congestion indication by setting the ECE (Explicit \nCongestion Notification Echo) bit (see Figure 3.29) in a receiver-to-sender TCP \nACK segment. The TCP sender, in turn, reacts to an ACK with an ECE congestion \nindication by halving the congestion window, as it would react to a lost segment \nusing fast retransmit, and sets the CWR (Congestion Window Reduced) bit in the \nheader of the next transmitted TCP sender-to-receiver segment.\nOther transport-layer protocols besides TCP may also make use of network-\nlayer-signaled ECN. The Datagram Congestion Control Protocol (DCCP) [RFC \n4340] provides a low-overhead, congestion-controlled UDP-like unreliable service \nthat utilizes ECN. DCTCP (Data Center TCP) [Alizadeh 2010], a version of TCP \ndesigned specifically for data center networks, also makes use of ECN.ECN Echo = 1Host A Host B\nECN = 11ECN Echo bit set in \nreceiver-to-sender\nTCP ACK segmen t\nECN bits set in IP\ndatagram heade r\nat congested route r\nFigure 3.56  \u2666  Explicit Congestion Notification: network-assisted  \ncongestion control\n312     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\n3.8 Summary\nWe began this chapter by studying the services that a transport-layer protocol can \nprovide to network applications. At one extreme, the transport-layer protocol can be \nvery simple and offer a no-frills service to applications, providing only a multiplexing/\ndemultiplexing function for communicating processes. The Internet\u2019s UDP protocol is \nan example of such a no-frills transport-layer protocol. At the other extreme, a transport-  \nlayer protocol can provide a variety of guarantees to applications, such as reliable deliv -\nery of data, delay guarantees, and bandwidth guarantees. Nevertheless, the services \nthat a transport protocol can provide are often constrained by the service model of the \nunderlying network-layer protocol. If the network-layer protocol cannot provide delay \nor", "doc_id": "0d46923b-91aa-4910-9546-bba412e3be4b", "embedding": null, "doc_hash": "3f1eab121acd98f934d57b17df6277c874d64f6b549d9dddf62238f8461bf7e6", "extra_info": null, "node_info": {"start": 900465, "end": 904016}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "c60ced93-4d86-485f-8dad-5bb39e79b1b7", "3": "0ad9a354-f821-40f0-9eb3-da2381e3aaf1"}}, "__type__": "1"}, "0ad9a354-f821-40f0-9eb3-da2381e3aaf1": {"__data__": {"text": "studying the services that a transport-layer protocol can \nprovide to network applications. At one extreme, the transport-layer protocol can be \nvery simple and offer a no-frills service to applications, providing only a multiplexing/\ndemultiplexing function for communicating processes. The Internet\u2019s UDP protocol is \nan example of such a no-frills transport-layer protocol. At the other extreme, a transport-  \nlayer protocol can provide a variety of guarantees to applications, such as reliable deliv -\nery of data, delay guarantees, and bandwidth guarantees. Nevertheless, the services \nthat a transport protocol can provide are often constrained by the service model of the \nunderlying network-layer protocol. If the network-layer protocol cannot provide delay \nor bandwidth guarantees to transport-layer segments, then the transport-layer protocol \ncannot provide delay or bandwidth guarantees for the messages sent between processes.\nWe learned in Section 3.4 that a transport-layer protocol can provide reliable \ndata transfer even if the underlying network layer is unreliable. We saw that provid-\ning reliable data transfer has many subtle points, but that the task can be accom -\nplished by carefully combining acknowledgments, timers, retransmissions, and \nsequence numbers.\nAlthough we covered reliable data transfer in this chapter, we should keep in \nmind that reliable data transfer can be provided by link-, network-, transport-, or \napplication-layer protocols. Any of the upper four layers of the protocol stack can \nimplement acknowledgments, timers, retransmissions, and sequence numbers and \nprovide reliable data transfer to the layer above. In fact, over the years, engineers \nand computer scientists have independently designed and implemented link-, net -\nwork-, transport-, and application-layer protocols that provide reliable data transfer \n(although many of these protocols have quietly disappeared).\nIn Section 3.5, we took a close look at TCP, the Internet\u2019s connection-oriented and \nreliable transport-layer protocol. We learned that TCP is complex, involving connec -\ntion management, flow control, and round-trip time estimation, as well as reliable data \ntransfer. In fact, TCP is actually more complex than our description\u2014we intentionally \ndid not discuss a variety of TCP patches, fixes, and improvements that are widely \nimplemented in various versions of TCP. All of this complexity, however, is hidden \nfrom the network application. If a client on one host wants to send data reliably to a \nserver on another host, it simply opens a TCP socket to the server and pumps data into \nthat socket. The client-server application is blissfully unaware of TCP\u2019s complexity.\nIn Section 3.6, we examined congestion control from a broad perspective, and \nin Section 3.7, we showed how TCP implements congestion control. We learned that \ncongestion control is imperative for the well-being of the network. Without conges -\ntion control, a network can easily become gridlocked, with little or no data being \ntransported end-to-end. In Section 3.7 we learned that TCP implements an end-to-\nend congestion-control mechanism that additively increases its transmission rate \nwhen the TCP connection\u2019s path is judged to be congestion-free, and multiplicatively \n3.8  \u2022  SUMMARY      313\ndecreases its transmission rate when loss occurs. This mechanism also strives to give \neach TCP connection passing through a congested link an equal share of the link \nbandwidth. We also examined in some depth the impact of TCP connection estab -\nlishment and slow start on latency. We observed that in many important scenarios, \nconnection establishment and slow start significantly contribute to end-to-end delay. \nWe emphasize once more that while TCP congestion control has evolved over the \nyears, it remains an area of intensive research and will likely continue to evolve in \nthe upcoming years.\nOur discussion of specific Internet transport protocols", "doc_id": "0ad9a354-f821-40f0-9eb3-da2381e3aaf1", "embedding": null, "doc_hash": "495a0b20d62ac2ef650afac88d85ef21882614a0f1e6558f00368ba64508feb8", "extra_info": null, "node_info": {"start": 903946, "end": 907915}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "0d46923b-91aa-4910-9546-bba412e3be4b", "3": "d89866f8-a218-484b-a7c8-7cd464db4727"}}, "__type__": "1"}, "d89866f8-a218-484b-a7c8-7cd464db4727": {"__data__": {"text": "rate \nwhen the TCP connection\u2019s path is judged to be congestion-free, and multiplicatively \n3.8  \u2022  SUMMARY      313\ndecreases its transmission rate when loss occurs. This mechanism also strives to give \neach TCP connection passing through a congested link an equal share of the link \nbandwidth. We also examined in some depth the impact of TCP connection estab -\nlishment and slow start on latency. We observed that in many important scenarios, \nconnection establishment and slow start significantly contribute to end-to-end delay. \nWe emphasize once more that while TCP congestion control has evolved over the \nyears, it remains an area of intensive research and will likely continue to evolve in \nthe upcoming years.\nOur discussion of specific Internet transport protocols in this chapter has focused \non UDP and TCP\u2014the two \u201cwork horses\u201d of the Internet transport layer. However, \ntwo decades of experience with these two protocols has identified circumstances in \nwhich neither is ideally suited. Researchers have thus been busy developing addi -\ntional transport-layer protocols, several of which are now IETF proposed standards.\nThe Datagram Congestion Control Protocol (DCCP) [RFC 4340] provides a low-\noverhead, message-oriented, UDP-like unreliable service, but with an application-  \nselected form of congestion control that is compatible with TCP. If reliable or  \nsemi-reliable data transfer is needed by an application, then this would be performed \nwithin the application itself, perhaps using the mechanisms we have studied in  \nSection 3. 4. DCCP is envisioned for use in applications such as streaming media \n(see Chapter 9 ) that can exploit the tradeoff between timeliness and reliability of data \ndelivery, but that want to be responsive to network congestion.\nGoogle\u2019s QUIC (Quick UDP Internet Connections) protocol [Iyengar 2016], \nimplemented in Google\u2019s Chromium browser, provides reliability via retransmission \nas well as error correction, fast-connection setup, and a rate-based congestion control \nalgorithm that aims to be TCP friendly\u2014all implemented as an application-level pro -\ntocol on top of UDP. In early 2015, Google reported that roughly half of all requests \nfrom Chrome to Google servers are served over QUIC.\nDCTCP (Data Center TCP) [Alizadeh 2010] is a version of TCP designed spe -\ncifically for data center networks, and uses ECN to better support the mix of short- \nand long-lived flows that characterize data center workloads.\nThe Stream Control Transmission Protocol (SCTP) [RFC 4960, RFC 3286] is \na reliable, message-oriented protocol that allows several different application-level \n\u201cstreams\u201d to be multiplexed through a single SCTP connection (an approach known \nas \u201cmulti-streaming\u201d). From a reliability standpoint, the different streams within the \nconnection are handled separately, so that packet loss in one stream does not affect \nthe delivery of data in other streams. QUIC provides similar multi-stream semantics. \nSCTP also allows data to be transferred over two outgoing paths when a host is con -\nnected to two or more networks, optional delivery of out-of-order data, and a number \nof other features. SCTP\u2019s flow- and congestion-control algorithms are essentially the \nsame as in TCP.\nThe TCP-Friendly Rate Control (TFRC) protocol [RFC 5348] is a congestion-\ncontrol protocol rather than a full-fledged transport-layer protocol. It specifies a \n314     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\ncongestion-control mechanism that could be used in another transport protocol such \nas DCCP (indeed one of the two application-selectable protocols available in DCCP \nis TFRC). The goal of TFRC is to smooth out the \u201csaw tooth\u201d behavior (see Fig-\nure 3.53) in TCP congestion control, while", "doc_id": "d89866f8-a218-484b-a7c8-7cd464db4727", "embedding": null, "doc_hash": "da484f3f3e2d3b9ca6024c06766015146289dd1b8288ac9d83c9062f7a98524a", "extra_info": null, "node_info": {"start": 907926, "end": 911664}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "0ad9a354-f821-40f0-9eb3-da2381e3aaf1", "3": "c99a48cd-4f68-42b4-b37b-602cdad9f878"}}, "__type__": "1"}, "c99a48cd-4f68-42b4-b37b-602cdad9f878": {"__data__": {"text": "data, and a number \nof other features. SCTP\u2019s flow- and congestion-control algorithms are essentially the \nsame as in TCP.\nThe TCP-Friendly Rate Control (TFRC) protocol [RFC 5348] is a congestion-\ncontrol protocol rather than a full-fledged transport-layer protocol. It specifies a \n314     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\ncongestion-control mechanism that could be used in another transport protocol such \nas DCCP (indeed one of the two application-selectable protocols available in DCCP \nis TFRC). The goal of TFRC is to smooth out the \u201csaw tooth\u201d behavior (see Fig-\nure 3.53) in TCP congestion control, while maintaining a long-term sending rate that \nis \u201creasonably\u201d close to that of TCP. With a smoother sending rate than TCP, TFRC \nis well-suited for multimedia applications such as IP telephony or streaming media \nwhere such a smooth rate is important. TFRC is an \u201cequation-based\u201d protocol that \nuses the measured packet loss rate as input to an equation [Padhye 2000] that esti -\nmates what TCP\u2019s throughput would be if a TCP session experiences that loss rate. \nThis rate is then taken as TFRC\u2019s target sending rate.\nOnly the future will tell whether DCCP, SCTP, QUIC, or TFRC will see wide -\nspread deployment. While these protocols clearly provide enhanced capabilities \nover TCP and UDP, TCP and UDP have proven themselves \u201cgood enough\u201d over the \nyears. Whether \u201cbetter\u201d wins out over \u201cgood enough\u201d will depend on a complex mix \nof technical, social, and business considerations.\nIn Chapter 1, we said that a computer network can be partitioned into the \u201cnet -\nwork edge\u201d and the \u201cnetwork core.\u201d The network edge covers everything that hap -\npens in the end systems. Having now covered the application layer and the transport \nlayer, our discussion of the network edge is complete. It is time to explore the net -\nwork core! This journey begins in the next two chapters, where we\u2019ll study the net -\nwork layer, and continues into Chapter 6, where we\u2019ll study the link layer.\nHomework Problems and Questions\nChapter 3 Review Questions\nSECTIONS 3.1\u20133.3 \n R1. Suppose the network layer provides the following service. The network \nlayer in the source host accepts a segment of maximum size 1,200 bytes and \na destination host address from the transport layer. The network layer then \nguarantees to deliver the segment to the transport layer at the destination \nhost. Suppose many network application processes can be running at the \ndestination host.\na. Design the simplest possible transport-layer protocol that will get applica-\ntion data to the desired process at the destination host. Assume the operat-\ning system in the destination host has assigned a 4-byte port number to \neach running application process.\nb. Modify this protocol so that it provides a \u201creturn address\u201d to the destina-\ntion process.\nc. In your protocols, does the transport layer \u201chave to do anything\u201d in the \ncore of the computer network?\nHOMEWORK PROBLEMS AND QUESTIONS      315\n R2. Consider a planet where everyone belongs to a family of six, every family \nlives in its own house, each house has a unique address, and each person \nin a given house has a unique name. Suppose this planet has a mail service \nthat delivers letters from source house to destination house. The mail service \nrequires that (1) the letter be in an envelope, and that (2) the address of the \ndestination house (and nothing more) be clearly written on the envelope. Sup -\npose each family has a delegate family member who collects and distributes \nletters for the other family members. The letters do not necessarily provide \nany indication of the recipients of the letters.\na. Using the solution to Problem R1 above as inspiration, describe a", "doc_id": "c99a48cd-4f68-42b4-b37b-602cdad9f878", "embedding": null, "doc_hash": "abb6ad1bc99831390e0b2d0845771a27c6968ae29297138f6d6a17851ccaa1cf", "extra_info": null, "node_info": {"start": 911799, "end": 915507}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "d89866f8-a218-484b-a7c8-7cd464db4727", "3": "d984b954-3e42-48aa-85be-b89a079c9950"}}, "__type__": "1"}, "d984b954-3e42-48aa-85be-b89a079c9950": {"__data__": {"text": "network?\nHOMEWORK PROBLEMS AND QUESTIONS      315\n R2. Consider a planet where everyone belongs to a family of six, every family \nlives in its own house, each house has a unique address, and each person \nin a given house has a unique name. Suppose this planet has a mail service \nthat delivers letters from source house to destination house. The mail service \nrequires that (1) the letter be in an envelope, and that (2) the address of the \ndestination house (and nothing more) be clearly written on the envelope. Sup -\npose each family has a delegate family member who collects and distributes \nletters for the other family members. The letters do not necessarily provide \nany indication of the recipients of the letters.\na. Using the solution to Problem R1 above as inspiration, describe a protocol \nthat the delegates can use to deliver letters from a sending family member \nto a receiving family member.\nb. In your protocol, does the mail service ever have to open the envelope and \nexamine the letter in order to provide its service?\n R3. How is a UDP socket fully identified? What about a TCP socket? What is the \ndifference between the full identification of both sockets?\n R4. Describe why an application developer might choose to run an application \nover UDP rather than TCP.\n R5. Why is it that voice and video traffic is often sent over TCP rather than UDP \nin today\u2019s Internet? ( Hint: The answer we are looking for has nothing to do \nwith TCP\u2019s congestion-control mechanism.)\n R6. Is it possible for an application to enjoy reliable data transfer even when the \napplication runs over UDP? If so, how?\n R7. Suppose a process in Host C has a UDP socket with port number 6789. \nSuppose both Host A and Host B each send a UDP segment to Host C with \ndestination port number 6789. Will both of these segments be directed to the \nsame socket at Host C? If so, how will the process at Host C know that these \ntwo segments originated from two different hosts?\n R8. Suppose that a Web server runs in Host C on port 80. Suppose this Web \nserver uses persistent connections, and is currently receiving requests from \ntwo different Hosts, A and B. Are all of the requests being sent through the \nsame socket at Host C? If they are being passed through different sockets, do \nboth of the sockets have port 80? Discuss and explain.\nSECTION 3.4\n R9. In our rdt protocols, why did we need to introduce sequence numbers?\n R10. In our rdt protocols, why did we need to introduce timers?\n316     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\n R11. Suppose that the roundtrip delay between sender and receiver is constant and \nknown to the sender. Would a timer still be necessary in protocol rdt 3.0 , \nassuming that packets can be lost? Explain.\n R12. Visit the Go-Back-N Java applet at the companion Web site.\na. Have the source send five packets, and then pause the animation before \nany of the five packets reach the destination. Then kill the first packet and \nresume the animation. Describe what happens.\nb. Repeat the experiment, but now let the first packet reach the destination \nand kill the first acknowledgment. Describe again what happens.\nc. Finally, try sending six packets. What happens?\n R13. Repeat R12, but now with the Selective Repeat Java applet. How are Selec-\ntive Repeat and Go-Back-N different?\nSECTION 3.5\n R14. True or false?\na. Host A is sending Host B a large file over a TCP connection. Assume Host \nB has no data to send Host A. Host B will not send acknowledgments to \nHost A because Host B cannot piggyback the acknowledgments on data.\nb. The size of the TCP rwnd  never changes throughout the duration of the \nconnection.\nc. Suppose Host A is sending Host B a large file over a TCP connection. The \nnumber of", "doc_id": "d984b954-3e42-48aa-85be-b89a079c9950", "embedding": null, "doc_hash": "d3e53532c466f36500327706286fbf47a7e72ac59fb2f37921fac7889f4e21fc", "extra_info": null, "node_info": {"start": 915371, "end": 919095}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "c99a48cd-4f68-42b4-b37b-602cdad9f878", "3": "126a91e8-d4ea-4828-b7e4-7e19ee30a263"}}, "__type__": "1"}, "126a91e8-d4ea-4828-b7e4-7e19ee30a263": {"__data__": {"text": "reach the destination \nand kill the first acknowledgment. Describe again what happens.\nc. Finally, try sending six packets. What happens?\n R13. Repeat R12, but now with the Selective Repeat Java applet. How are Selec-\ntive Repeat and Go-Back-N different?\nSECTION 3.5\n R14. True or false?\na. Host A is sending Host B a large file over a TCP connection. Assume Host \nB has no data to send Host A. Host B will not send acknowledgments to \nHost A because Host B cannot piggyback the acknowledgments on data.\nb. The size of the TCP rwnd  never changes throughout the duration of the \nconnection.\nc. Suppose Host A is sending Host B a large file over a TCP connection. The \nnumber of unacknowledged bytes that A sends cannot exceed the size of \nthe receive buffer.\nd. Suppose Host A is sending a large file to Host B over a TCP connection. \nIf the sequence number for a segment of this connection is m, then the \nsequence number for the subsequent segment will necessarily be m+1.\ne. The TCP segment has a field in its header for rwnd .\nf. Suppose that the last SampleRTT  in a TCP connection is equal to 1 sec. \nThe current value of TimeoutInterval  for the connection will neces-\nsarily be \u00da 1 sec.\ng. Suppose Host A sends one segment with sequence number 38 and 4 \nbytes of data over a TCP connection to Host B. In this same segment the \nacknowledgment number is necessarily 42.\n R15. Suppose Host A sends two TCP segments back to back to Host B over a \nTCP connection. The first segment has sequence number 90; the second has \nsequence number 110.\na. How much data is in the first segment?\nb. Suppose that the first segment is lost but the second segment arrives at \nB. In the acknowledgment that Host B sends to Host A, what will be the \nacknowledgment number?\nPROBLEMS      317\n R16. Consider the Telnet example discussed in Section 3.5. A few seconds after \nthe user types the letter \u2018C,\u2019 the user types the letter \u2018R.\u2019 After typing the let-\nter \u2018R,\u2019 how many segments are sent, and what is put in the sequence number \nand acknowledgment fields of the segments?\nSECTION 3.7\n R17. Consider two hosts, Host A and Host B, transmitting a large file to Server C over \na bottleneck link with a rate of R kbps. To transfer the file, the hosts use TCP \nwith the same parameters (including MSS and RTT) and start their transmissions \nat the same time. Host A uses a single TCP connection for the entire file, while \nHost B uses 9 simultaneous TCP connections, each for a portion (i.e., a chunk ) of \nthe file. What is the overall transmission rate achieved by each host at the begin -\nning of the file transfer? ( Hint:  the overall transmission rate of a host is the sum \nof the transmission rates of its TCP connections.) Is this situation fair?\n R18. True or false? Consider congestion control in TCP. When the timer expires at \nthe sender, the value of ssthresh  is set to one half of its previous value.\n R19. According to the discussion of TCP splitting in the sidebar in Section 3.7, \nthe response time with TCP splitting is approximately 4 3 RTTFE 1 RTTBE 1 \nprocessing time, as opposed to 4 3 RTT 1 processing time when a direct \nconnection is used. Assume that RTT BE is 0.5 3 RTT. For what values of \nRTTFE does TCP splitting have a shorter delay than a direct connection?\nProblems\n P1. Suppose Client A requests a web page from Server S through HTTP and its \nsocket is associated with port 33000.\na. What are the source and destination ports for the segments sent from A to S?\nb. What are the source and destination ports for the segments sent from S to A?\nc. Can Client A contact to Server S using UDP as the transport", "doc_id": "126a91e8-d4ea-4828-b7e4-7e19ee30a263", "embedding": null, "doc_hash": "c30af52c661440d739ee5f8c8591839e447d580c97d547c8c5aff34cdaf206af", "extra_info": null, "node_info": {"start": 919189, "end": 922812}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "d984b954-3e42-48aa-85be-b89a079c9950", "3": "38ae37e7-0a78-495c-944f-b8ce44169678"}}, "__type__": "1"}, "38ae37e7-0a78-495c-944f-b8ce44169678": {"__data__": {"text": "previous value.\n R19. According to the discussion of TCP splitting in the sidebar in Section 3.7, \nthe response time with TCP splitting is approximately 4 3 RTTFE 1 RTTBE 1 \nprocessing time, as opposed to 4 3 RTT 1 processing time when a direct \nconnection is used. Assume that RTT BE is 0.5 3 RTT. For what values of \nRTTFE does TCP splitting have a shorter delay than a direct connection?\nProblems\n P1. Suppose Client A requests a web page from Server S through HTTP and its \nsocket is associated with port 33000.\na. What are the source and destination ports for the segments sent from A to S?\nb. What are the source and destination ports for the segments sent from S to A?\nc. Can Client A contact to Server S using UDP as the transport protocol?\nd. Can Client A request multiple resources in a single TCP connection?\n P2. Consider Figure 3.5. What are the source and destination port values in the seg -\nments flowing from the server back to the clients\u2019 processes? What are the IP \naddresses in the network-layer datagrams carrying the transport-layer segments?\n P3. UDP and TCP use 1s complement for their checksums. Suppose you have \nthe following three 8-bit bytes: 01010011, 01100110, 01110100. What is the \n1s complement of the sum of these 8-bit bytes? (Note that although UDP and \nTCP use 16-bit words in computing the checksum, for this problem you are \nbeing asked to consider 8-bit sums.) Show all work. Why is it that UDP takes \nthe 1s complement of the sum; that is, why not just use the sum? With the 1s \ncomplement scheme, how does the receiver detect errors? Is it possible that a \n1-bit error will go undetected? How about a 2-bit error?\n318     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\n P4. Assume that a host receives a UDP segment with 01011101 11110010 (we \nseparated the values of each byte with a space for clarity) as the checksum. \nThe host adds the 16-bit words over all necessary fields excluding the check-\nsum and obtains the value 00110010 00001101. Is the segment considered \ncorrectly received or not? What does the receiver do?\n P5. Suppose that the UDP receiver computes the Internet checksum for the \nreceived UDP segment and finds that it matches the value carried in the \nchecksum field. Can the receiver be absolutely certain that no bit errors have \noccurred? Explain.\n P6. Consider our motivation for correcting protocol rdt2.1 . Show that the \nreceiver, shown in Figure 3.57, when operating with the sender shown in \nFigure 3.11, can lead the sender and receiver to enter into a deadlock state, \nwhere each is waiting for an event that will never occur.\n P7. In protocol rdt3.0 , the ACK packets flowing from the receiver to the \nsender do not have sequence numbers (although they do have an ACK field \nthat contains the sequence number of the packet they are acknowledging). \nWhy is it that our ACK packets do not require sequence numbers?\nWait for\n0 from\nbelowrdt_rcv(rcvpkt)&&\n(corrupt(rcvpkt)||\nhas_seq0(rcvpkt)))\ncompute chksum\nmake_pkt(sndpkt,NAK,chksum)\nudt_send(sndpkt)rdt_rcv(rcvpkt)&&\n(corrupt(rcvpkt)||\nhas_seq1(rcvpkt)))\ncompute chksum\nmake_pkt(sndpkt,NAK,chksum)\nudt_send(sndpkt) rdt_rvc(rcvpkt)&&notcorrupt(rcvpkt)\n&&has_seq1(rcvpkt)\nextract(rcvpkt,data)\ndeliver_data(data)\ncompute", "doc_id": "38ae37e7-0a78-495c-944f-b8ce44169678", "embedding": null, "doc_hash": "d53291c5c4a2c01852c2aad383acceaff29d855b579d16f80fc939988e4a7ef5", "extra_info": null, "node_info": {"start": 922771, "end": 926002}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "126a91e8-d4ea-4828-b7e4-7e19ee30a263", "3": "299a5c5e-8ddf-40d3-a5b5-008163fa92c8"}}, "__type__": "1"}, "299a5c5e-8ddf-40d3-a5b5-008163fa92c8": {"__data__": {"text": "packets do not require sequence numbers?\nWait for\n0 from\nbelowrdt_rcv(rcvpkt)&&\n(corrupt(rcvpkt)||\nhas_seq0(rcvpkt)))\ncompute chksum\nmake_pkt(sndpkt,NAK,chksum)\nudt_send(sndpkt)rdt_rcv(rcvpkt)&&\n(corrupt(rcvpkt)||\nhas_seq1(rcvpkt)))\ncompute chksum\nmake_pkt(sndpkt,NAK,chksum)\nudt_send(sndpkt) rdt_rvc(rcvpkt)&&notcorrupt(rcvpkt)\n&&has_seq1(rcvpkt)\nextract(rcvpkt,data)\ndeliver_data(data)\ncompute chksum\nmake_pkt(sendpkt,ACK,chksum)\nudt_send(sndpkt)rdt_rvc(rcvpkt)&&notcorrupt(rcvpkt)\n&& has_seq0(rcvpkt)\nextract(rcvpkt,data)\ndeliver_data(data)\ncompute chksum\nmake_pkt(sendpkt,ACK,chksum)\nudt_send(sndpkt)\nWait for\n1 from\nbelow\nFigure 3.57  \u2666 An incorrect receiver for protocol rdt 2.1\nPROBLEMS      319\n P8. Draw the FSM for the receiver side of protocol rdt3.0 .\n P9. Give a trace of the operation of protocol rdt3.0  when data packets and \nacknowledgment packets are garbled. Your trace should be similar to that \nused in Figure 3.16.\n P10. Consider a channel that can lose packets but has a maximum delay that is \nknown. Modify protocol rdt2.1  to include sender timeout and retransmit. \nInformally argue why your protocol can communicate correctly over this \nchannel.\n P11. Consider the rdt2.2  receiver in Figure 3.14, and the creation of a new \npacket in the self-transition (i.e., the transition from the state back to \nitself) in the Wait-for-0-from-below and the Wait-for-1-from-below states: \nsndpkt=make_pkt(ACK,1,checksum)  and sndpkt=make_\npkt(ACK,0,checksum) . Would the protocol work correctly if this action \nwere removed from the self-transition in the Wait-for-1-from-below state? \nJustify your answer. What if this event were removed from the self-transition \nin the Wait-for-0-from-below state? [ Hint: In this latter case, consider what \nwould happen if the first sender-to-receiver packet were corrupted.]\n P12. The sender side of rdt3.0  simply ignores (that is, takes no action on)  \nall received packets that are either in error or have the wrong value in the \nacknum  field of an acknowledgment packet. Suppose that in such circum-\nstances, rdt3.0  were simply to retransmit the current data packet. Would \nthe protocol still work? ( Hint: Consider what would happen if there were \nonly bit errors; there are no packet losses but premature timeouts can occur. \nConsider how many times the nth packet is sent, in the limit as n approaches \ninfinity.)\n P13. Assume Host A is streaming a video from Server B using UDP. Also \nassume that the network suddenly becomes very congested while Host A is \nseeing the video. Is there any way to handle this situation with UDP? What \nabout with TCP? Is there any other option?\n P14. Consider a stop-and-wait data-transfer protocol that provides error checking \nand retransmissions but uses only negative acknowledgments. Assume that \nnegative acknowledgments are never corrupted. Would such a protocol work \nover a channel with bit errors? What about over a lossy channel with bit \nerrors?\n320     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT", "doc_id": "299a5c5e-8ddf-40d3-a5b5-008163fa92c8", "embedding": null, "doc_hash": "ffd3ff6981acde88bf4c487bbde88747856dd16c3a1e9771c7761d0558d7c33a", "extra_info": null, "node_info": {"start": 926223, "end": 929210}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "38ae37e7-0a78-495c-944f-b8ce44169678", "3": "6d46c645-fdaa-4da6-9841-897de9859677"}}, "__type__": "1"}, "6d46c645-fdaa-4da6-9841-897de9859677": {"__data__": {"text": "losses but premature timeouts can occur. \nConsider how many times the nth packet is sent, in the limit as n approaches \ninfinity.)\n P13. Assume Host A is streaming a video from Server B using UDP. Also \nassume that the network suddenly becomes very congested while Host A is \nseeing the video. Is there any way to handle this situation with UDP? What \nabout with TCP? Is there any other option?\n P14. Consider a stop-and-wait data-transfer protocol that provides error checking \nand retransmissions but uses only negative acknowledgments. Assume that \nnegative acknowledgments are never corrupted. Would such a protocol work \nover a channel with bit errors? What about over a lossy channel with bit \nerrors?\n320     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\n P15. Consider the cross-country example shown in Figure 3.17. How big would \nthe window size have to be for the channel utilization to be greater than 98 \npercent? Suppose that the size of a packet is 1,500 bytes, including both \nheader fields and data.\n P16. Suppose an application uses rdt 3.0  as its transport layer protocol. As the \nstop-and-wait protocol has very low channel utilization (shown in the cross-\ncountry example), the designers of this application let the receiver keep send-\ning back a number (more than two) of alternating ACK 0 and ACK 1 even if \nthe corresponding data have not arrived at the receiver. Would this applica-\ntion design increase the channel utilization? Why? Are there any potential \nproblems with this approach? Explain.\n P17. Consider two network entities, A and B, which are connected by a perfect \nbi-directional channel (i.e., any message sent will be received correctly; the \nchannel will not corrupt, lose, or re-order packets). A and B are to deliver \ndata messages to each other in an alternating manner: First, A must deliver \na message to B, then B must deliver a message to A, then A must deliver a \nmessage to B and so on. If an entity is in a state where it should not attempt \nto deliver a message to the other side, and there is an event like rdt_\nsend(data)  call from above that attempts to pass data down for transmis-\nsion to the other side, this call from above can simply be ignored with a call \nto rdt_unable_to_send(data) , which informs the higher layer that it \nis currently not able to send data. [Note: This simplifying assumption is made \nso you don\u2019t have to worry about buffering data.]\n  Draw a FSM specification for this protocol (one FSM for A, and one FSM \nfor B!). Note that you do not have to worry about a reliability mechanism \nhere; the main point of this question is to create a FSM specification that \nreflects the synchronized behavior of the two entities. You should use the \nfollowing events and actions that have the same meaning as protocol rdt1.0 in \nFigure 3.9: rdt_send(data), packet = make_pkt(data) , udt_\nsend(packet), rdt_rcv(packet) , extract (packet,data), \ndeliver_data(data) . Make sure your protocol reflects the strict alter-\nnation of sending between A and B. Also, make sure to indicate the initial \nstates for A and B in your FSM descriptions.\n P18. In the generic SR protocol that we studied in Section 3.4.4, the sender \ntransmits a message as soon as it is available (if it is in the window) without \nwaiting for an acknowledgment. Suppose now that we want an SR protocol \nthat sends messages two at a time. That is, the sender will send a pair of mes-\nsages and will send the next pair of messages only when it knows that both \nmessages in the first pair have been received correctly.\n  Suppose that the channel may lose messages but will not corrupt or reorder \nmessages. Design an error-control protocol for the unidirectional reliable \nPROBLEMS      321\ntransfer", "doc_id": "6d46c645-fdaa-4da6-9841-897de9859677", "embedding": null, "doc_hash": "0273c7b6abd2daa2d1e93207b5b040f6c5d03bfc8a11fb303678c61e1521e523", "extra_info": null, "node_info": {"start": 928976, "end": 932696}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "299a5c5e-8ddf-40d3-a5b5-008163fa92c8", "3": "73345b68-6741-4278-8537-c7920f963797"}}, "__type__": "1"}, "73345b68-6741-4278-8537-c7920f963797": {"__data__": {"text": "A and B. Also, make sure to indicate the initial \nstates for A and B in your FSM descriptions.\n P18. In the generic SR protocol that we studied in Section 3.4.4, the sender \ntransmits a message as soon as it is available (if it is in the window) without \nwaiting for an acknowledgment. Suppose now that we want an SR protocol \nthat sends messages two at a time. That is, the sender will send a pair of mes-\nsages and will send the next pair of messages only when it knows that both \nmessages in the first pair have been received correctly.\n  Suppose that the channel may lose messages but will not corrupt or reorder \nmessages. Design an error-control protocol for the unidirectional reliable \nPROBLEMS      321\ntransfer of messages. Give an FSM description of the sender and receiver. \nDescribe the format of the packets sent between sender and receiver, and vice \nversa. If you use any procedure calls other than those in Section 3.4  \n(for example, udt_send() , start_timer() , rdt_rcv() , and so on), \nclearly state their actions. Give an example (a timeline trace of sender and \nreceiver) showing how your protocol recovers from a lost packet.\n P19. Suppose Host A and Host B use a GBN protocol with window size N 5\u00a03 \nand a long-enough range of sequence numbers. Assume Host A sends six \napplication messages to Host B and that all messages are correctly received, \nexcept for the first acknowledgment and the fifth data segment. Draw a \ntiming diagram (similar to Figure 3.22), showing the data segments and the \nacknowledgments sent along with the corresponding sequence and acknowl-\nedge numbers, respectively.\n P20. Consider a scenario in which Host A and Host B want to send messages to \nHost C. Hosts A and C are connected by a channel that can lose and corrupt \n(but not reorder) messages. Hosts B and C are connected by another channel \n(independent of the channel connecting A and C) with the same properties. \nThe transport layer at Host C should alternate in delivering messages from  \nA and B to the layer above (that is, it should first deliver the data from a packet \nfrom A, then the data from a packet from B, and so on). Design a stop-and-\nwait-like error-control protocol for reliably transferring packets from A and \nB to C, with alternating delivery at C as described above. Give FSM descrip-\ntions of A and C. ( Hint:  The FSM for B should be essentially the same as  \nfor A.) Also, give a description of the packet format(s) used.\n P21. Suppose we have two network entities, A and B. B has a supply of data mes-\nsages that will be sent to A according to the following conventions. When A \ngets a request from the layer above to get the next data (D) message from B, \nA must send a request (R) message to B on the A-to-B channel. Only when B \nreceives an R message can it send a data (D) message back to A on the B-to-\nA channel. A should deliver exactly one copy of each D message to the layer \nabove. R messages can be lost (but not corrupted) in the A-to-B channel; D \nmessages, once sent, are always delivered correctly. The delay along both \nchannels is unknown and variable.\n  Design (give an FSM description of) a protocol that incorporates the appro-\npriate mechanisms to compensate for the loss-prone A-to-B channel and \nimplements message passing to the layer above at entity A, as discussed \nabove. Use only those mechanisms that are absolutely necessary.\n322     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\n P22. Consider the GBN protocol with a sender window size of 4 and a sequence \nnumber range of 1,024. Suppose that at time t, the next in-order packet \nthat the receiver is expecting has a sequence number of k. Assume that the \nmedium", "doc_id": "73345b68-6741-4278-8537-c7920f963797", "embedding": null, "doc_hash": "ab30e2dee0a22ed1e859f06dabd001de73e5e0419c08ce346e4708a6630c4036", "extra_info": null, "node_info": {"start": 932727, "end": 936396}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "6d46c645-fdaa-4da6-9841-897de9859677", "3": "c3423cc3-a14a-4281-9220-c4efa6a9a751"}}, "__type__": "1"}, "c3423cc3-a14a-4281-9220-c4efa6a9a751": {"__data__": {"text": "in the A-to-B channel; D \nmessages, once sent, are always delivered correctly. The delay along both \nchannels is unknown and variable.\n  Design (give an FSM description of) a protocol that incorporates the appro-\npriate mechanisms to compensate for the loss-prone A-to-B channel and \nimplements message passing to the layer above at entity A, as discussed \nabove. Use only those mechanisms that are absolutely necessary.\n322     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\n P22. Consider the GBN protocol with a sender window size of 4 and a sequence \nnumber range of 1,024. Suppose that at time t, the next in-order packet \nthat the receiver is expecting has a sequence number of k. Assume that the \nmedium does not reorder messages. Answer the following questions:\na. What are the possible sets of sequence numbers inside the sender\u2019s  \nwindow at time t? Justify your answer.\nb. What are all possible values of the ACK field in all possible messages \ncurrently propagating back to the sender at time t? Justify your answer.\n P23. Give one example where buffering out-of-order segments would significantly \nimprove the throughput of a GBN protocol.\n P24. Consider a scenario where Host A, Host B, and Host C are connected as \na ring (i.e., Host A to Host B, Host B to Host C, and Host C to Host A). \nAssume that Host A and Host C run protocol rdt3.0 , while Host B simply \nrelays all messages received from Host A to Host C. Does this arrangement \nenable reliable delivery of messages from Host A to Host C? Can Host B tell \nif a certain message has been correctly received by Host A?\n P25. Consider the Telnet case study in Section 3.5.2. Assume a Telnet session is \nalready active between Host A and Server S. The user at Host A then types \nthe word \u201cHello.\u201d\na. How many TCP segments will be created at the transport layer of Host A?\nb. Is there any guarantee that each segment will be sent into the TCP connec-\ntion as soon as it is created?\nc. Does TCP provide any mechanism that can be useful for an interactive \nTelnet session?\nd. Would UDP offer a viable alternative to TCP for Telnet sessions over a \nreliable channel?\n P26. Consider transferring an enormous file of L bytes from Host A to Host B. \nAssume an MSS of 536 bytes.\na. What is the maximum value of L such that TCP sequence numbers are not \nexhausted? Recall that the TCP sequence number field has 4 bytes.\nb. For the L you obtain in (a), find how long it takes to transmit the file. \nAssume that a total of 66 bytes of transport, network, and data-link header \nare added to each segment before the resulting packet is sent out over a \n155 Mbps link. Ignore flow control and congestion control so A can pump \nout the segments back to back and continuously.\n P27. Host A and B are communicating over a TCP connection, and Host B has \nalready received from A all bytes up through byte 126. Suppose Host A  \nthen sends two segments to Host B back-to-back. The first and second  \nPROBLEMS      323\nsegments contain 80 and 40 bytes of data, respectively. In the first segment, \nthe sequence number is 127, the source port number is 302, and the des-\ntination port number is 80. Host B sends an acknowledgment whenever it \nreceives a segment from Host A.\na. In the second segment sent from Host A to B, what are the sequence num-\nber, source port number, and destination port number?\nb. If the first segment arrives before the second segment, in the acknowledg-\nment of the first arriving segment, what is the acknowledgment number, \nthe source port number, and the destination port number?\nc. If the second segment arrives before the first segment, in the acknowledg-\nment of the first arriving", "doc_id": "c3423cc3-a14a-4281-9220-c4efa6a9a751", "embedding": null, "doc_hash": "2aa9ebdf7ba035718b226569430eaa964b0be245cceebc45608133292d5e1bbf", "extra_info": null, "node_info": {"start": 936407, "end": 940054}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "73345b68-6741-4278-8537-c7920f963797", "3": "e0da86f9-d39d-4b5c-9183-73170d372ff6"}}, "__type__": "1"}, "e0da86f9-d39d-4b5c-9183-73170d372ff6": {"__data__": {"text": "     323\nsegments contain 80 and 40 bytes of data, respectively. In the first segment, \nthe sequence number is 127, the source port number is 302, and the des-\ntination port number is 80. Host B sends an acknowledgment whenever it \nreceives a segment from Host A.\na. In the second segment sent from Host A to B, what are the sequence num-\nber, source port number, and destination port number?\nb. If the first segment arrives before the second segment, in the acknowledg-\nment of the first arriving segment, what is the acknowledgment number, \nthe source port number, and the destination port number?\nc. If the second segment arrives before the first segment, in the acknowledg-\nment of the first arriving segment, what is the acknowledgment number?\nd. Suppose the two segments sent by A arrive in order at B. The first \nacknowledgment is lost and the second acknowledgment arrives after the \nfirst timeout interval. Draw a timing diagram, showing these segments \nand all other segments and acknowledgments sent. (Assume there is no \nadditional packet loss.) For each segment in your figure, provide the \nsequence number and the number of bytes of data; for each acknowledg-\nment that you add, provide the acknowledgment number.\n P28. Host A and B are directly connected with a 100 Mbps link. There is one TCP \nconnection between the two hosts, and Host A is sending to Host B an enor-\nmous file over this connection. Host A can send its application data into its \nTCP socket at a rate as high as 120 Mbps but Host B can read out of its TCP \nreceive buffer at a maximum rate of 50 Mbps. Describe the effect of TCP \nflow control.\n P29. SYN cookies were discussed in Section 3.5.6.\na. Why is it necessary for the server to use a special initial sequence number \nin the SYNACK?\nb. Suppose an attacker knows that a target host uses SYN cookies. Can the \nattacker create half-open or fully open connections by simply sending an \nACK packet to the target? Why or why not?\nc. Suppose an attacker collects a large amount of initial sequence numbers sent \nby the server. Can the attacker cause the server to create many fully open \nconnections by sending ACKs with those initial sequence numbers? Why?\n P30. Consider the network shown in Scenario 2 in Section 3.6.1. Suppose both \nsending hosts A and B have some fixed timeout values.\na. Argue that increasing the size of the finite buffer of the router might pos-\nsibly decrease the throughput ( lout).\nb. Now suppose both hosts dynamically adjust their timeout values (like \nwhat TCP does) based on the buffering delay at the router. Would increas-\ning the buffer size help to increase the throughput? Why?\n324     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\n P31. Suppose that the five measured SampleRTT  values (see Section 3.5.3) \nare 106 ms, 120 ms, 140 ms, 90 ms, and 115 ms. Compute the Estimat-\nedRTT  after each of these SampleRTT values is obtained, using a value of \n\u03b1=0.125 and assuming that the value of EstimatedRTT  was 100 ms \njust before the first of these five samples were obtained. Compute also the \nDevRTT  after each sample is obtained, assuming a value of \u03b2=0.25 and \nassuming the value of DevRTT  was 5 ms just before the first of these five \nsamples was obtained. Last, compute the TCP TimeoutInterval  after \neach of these samples is obtained.\n P32. Consider the TCP procedure for estimating RTT. Suppose that \u03b1=0.1. Let \nSampleRTT1 be the most recent sample RTT, let SampleRTT2 be the next \nmost recent sample RTT, and so on.\na. For a given TCP connection, suppose four acknowledgments have  \nbeen returned with corresponding sample RTTs: SampleRTT4,  \nSampleRTT3,", "doc_id": "e0da86f9-d39d-4b5c-9183-73170d372ff6", "embedding": null, "doc_hash": "427cc54a7cbe87adade5355f18a00fabca454618d64dd81fa0ea73676e6f097c", "extra_info": null, "node_info": {"start": 940048, "end": 943670}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "c3423cc3-a14a-4281-9220-c4efa6a9a751", "3": "6bbe1c81-d960-4a06-86bc-bb5049d1a4b9"}}, "__type__": "1"}, "6bbe1c81-d960-4a06-86bc-bb5049d1a4b9": {"__data__": {"text": "value of EstimatedRTT  was 100 ms \njust before the first of these five samples were obtained. Compute also the \nDevRTT  after each sample is obtained, assuming a value of \u03b2=0.25 and \nassuming the value of DevRTT  was 5 ms just before the first of these five \nsamples was obtained. Last, compute the TCP TimeoutInterval  after \neach of these samples is obtained.\n P32. Consider the TCP procedure for estimating RTT. Suppose that \u03b1=0.1. Let \nSampleRTT1 be the most recent sample RTT, let SampleRTT2 be the next \nmost recent sample RTT, and so on.\na. For a given TCP connection, suppose four acknowledgments have  \nbeen returned with corresponding sample RTTs: SampleRTT4,  \nSampleRTT3, SampleRTT2, and SampleRTT1. Express  \nEstimatedRTT  in terms of the four sample RTTs.\nb. Generalize your formula for n sample RTTs.\nc. For the formula in part (b) let n approach infinity. Comment on why this \naveraging procedure is called an exponential moving average.\n P33. In Section 3.5.3, we discussed TCP\u2019s estimation of RTT. Why do you think \nTCP avoids measuring the SampleRTT  for retransmitted segments?\n P34. What is the relationship between the variable SendBase  in Section 3.5.4 \nand the variable LastByteRcvd  in Section 3.5.5?\n P35. What is the relationship between the variable LastByteRcvd  in Section \n3.5.5 and the variable y in Section 3.5.4?\n P36. In Section 3.5.4, we saw that TCP waits until it has received three dupli-\ncate ACKs before performing a fast retransmit. Why do you think the TCP \ndesigners chose not to perform a fast retransmit after the first duplicate ACK \nfor a segment is received?\n P37. Compare GBN, SR, and TCP (no delayed ACK). Assume that the timeout \nvalues for all three protocols are sufficiently long such that 5 consecutive \ndata segments and their corresponding ACKs can be received (if not lost in \nthe channel) by the receiving host (Host B) and the sending host (Host A) \nrespectively. Suppose Host A sends 5 data segments to Host B, and the 2nd \nsegment (sent from A) is lost. In the end, all 5 data segments have been cor-\nrectly received by Host B.\na. How many segments has Host A sent in total and how many ACKs has \nHost B sent in total? What are their sequence numbers? Answer this  \nquestion for all three protocols.\nPROBLEMS      325\nb. If the timeout values for all three protocol are much longer than 5 RTT, \nthen which protocol successfully delivers all five data segments in short-\nest time interval?\n P38. In our description of TCP in Figure 3.53, the value of the threshold,  \nssthresh , is set as ssthresh=cwnd/2  in several places and \nssthresh  value is referred to as being set to half the window size when a \nloss event occurred. Must the rate at which the sender is sending when the \nloss event occurred be approximately equal to cwnd  segments per RTT? \nExplain your answer. If your answer is no, can you suggest a different  \nmanner in which ssthresh  should be set?\n P39. Consider Figure 3.46(b). If l\u2032in increases beyond R/2, can lout increase \nbeyond R/3? Explain. Now consider Figure 3.46(c). If l\u2032in increases beyond \nR/2, can lout increase beyond R/4 under the assumption that a packet will be \nforwarded twice on average from the router to the receiver? Explain.\n P40. Consider Figure 3.58. Assuming TCP Reno is the protocol experiencing the \nbehavior shown above, answer the following questions. In all cases, you \nshould provide a short discussion justifying your answer.\na. Identify the intervals of time when TCP slow start", "doc_id": "6bbe1c81-d960-4a06-86bc-bb5049d1a4b9", "embedding": null, "doc_hash": "d36cb5cd2411c429f9bdbe1dc4f966f4176223c7dd5cc9d90a95a7468b4c5209", "extra_info": null, "node_info": {"start": 943689, "end": 947185}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "e0da86f9-d39d-4b5c-9183-73170d372ff6", "3": "72e4c9a5-fae7-4bae-8713-9493c1351f48"}}, "__type__": "1"}, "72e4c9a5-fae7-4bae-8713-9493c1351f48": {"__data__": {"text": "\nExplain your answer. If your answer is no, can you suggest a different  \nmanner in which ssthresh  should be set?\n P39. Consider Figure 3.46(b). If l\u2032in increases beyond R/2, can lout increase \nbeyond R/3? Explain. Now consider Figure 3.46(c). If l\u2032in increases beyond \nR/2, can lout increase beyond R/4 under the assumption that a packet will be \nforwarded twice on average from the router to the receiver? Explain.\n P40. Consider Figure 3.58. Assuming TCP Reno is the protocol experiencing the \nbehavior shown above, answer the following questions. In all cases, you \nshould provide a short discussion justifying your answer.\na. Identify the intervals of time when TCP slow start is operating.\nb. Identify the intervals of time when TCP congestion avoidance is operating.\nc. After the 16th transmission round, is segment loss detected by a triple \nduplicate ACK or by a timeout?\nd. After the 22nd transmission round, is segment loss detected by a triple \nduplicate ACK or by a timeout?VideoNote\nExamining the behavior \nof TCP\n0\n02 46 81 012\nTransmission round14 16 18 20 22 24 26510152025Congestion window size (segments)30354045\nFigure 3.58  \u2666 TCP window size as a function of time\n326     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\ne. What is the initial value of ssthresh  at the first transmission round?\nf. What is the value of ssthresh  at the 18th transmission round?\ng. What is the value of ssthresh  at the 24th transmission round?\nh. During what transmission round is the 70th segment sent?\ni. Assuming a packet loss is detected after the 26th round by the receipt of \na triple duplicate ACK, what will be the values of the congestion window \nsize and of ssthresh ?\nj. Suppose TCP Tahoe is used (instead of TCP Reno), and assume that triple \nduplicate ACKs are received at the 16th round. What are the ssthresh  \nand the congestion window size at the 19th round?\nk. Again suppose TCP Tahoe is used, and there is a timeout event at  \n22nd round. How many packets have been sent out from 17th round till \n22nd round, inclusive?\n P41. Refer to Figure 3.55, which illustrates the convergence of TCP\u2019s AIMD \nalgorithm. Suppose that instead of a multiplicative decrease, TCP decreased \nthe window size by a constant amount. Would the resulting AIAD algorithm \nconverge to an equal share algorithm? Justify your answer using a diagram \nsimilar to Figure 3.55.\n P42. In Section 3.5.4, we discussed the doubling of the timeout interval after a \ntimeout event. This mechanism is a form of congestion control. Why does \nTCP need a window-based congestion-control mechanism (as studied in  \nSection 3.7) in addition to this doubling-timeout-interval mechanism?\n P43. Host A is sending an enormous file to Host B over a TCP connection. Over \nthis connection there is never any packet loss and the timers never expire. \nDenote the transmission rate of the link connecting Host A to the Internet by \nR bps. Suppose that the process in Host A is capable of sending data into its \nTCP socket at a rate S bps, where S=10#R. Further suppose that the TCP \nreceive buffer is large enough to hold the entire file, and the send buffer can \nhold only one percent of the file. What would prevent the process in Host \nA from continuously passing data to its TCP socket at rate S bps? TCP flow \ncontrol? TCP congestion control? Or something else? Elaborate.\n P44. Consider sending a large file from a host to another over a TCP connection \nthat has no loss.\na. Suppose TCP uses AIMD for its congestion control without slow start. \nAssuming", "doc_id": "72e4c9a5-fae7-4bae-8713-9493c1351f48", "embedding": null, "doc_hash": "34545c8918a72271ed2076b3671708d59a034811d4a2ad9c2662732ca40c60ba", "extra_info": null, "node_info": {"start": 947182, "end": 950697}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "6bbe1c81-d960-4a06-86bc-bb5049d1a4b9", "3": "545d9a93-adf3-442e-8290-eab87eff28bd"}}, "__type__": "1"}, "545d9a93-adf3-442e-8290-eab87eff28bd": {"__data__": {"text": "never any packet loss and the timers never expire. \nDenote the transmission rate of the link connecting Host A to the Internet by \nR bps. Suppose that the process in Host A is capable of sending data into its \nTCP socket at a rate S bps, where S=10#R. Further suppose that the TCP \nreceive buffer is large enough to hold the entire file, and the send buffer can \nhold only one percent of the file. What would prevent the process in Host \nA from continuously passing data to its TCP socket at rate S bps? TCP flow \ncontrol? TCP congestion control? Or something else? Elaborate.\n P44. Consider sending a large file from a host to another over a TCP connection \nthat has no loss.\na. Suppose TCP uses AIMD for its congestion control without slow start. \nAssuming cwnd  increases by 1 MSS every time a batch of ACKs is \nreceived and assuming approximately constant round-trip times, how long \ndoes it take for cwnd  increase from 6 MSS to 12 MSS (assuming no loss \nevents)?\nb. What is the average throughout (in terms of MSS and RTT) for this con-\nnection up through time =6 RTT?\nPROBLEMS      327\n P45. Recall the macroscopic description of TCP throughput. In the period of time \nfrom when the connection\u2019s rate varies from W/(2 \u00b7 RTT) to W/RTT , only one \npacket is lost (at the very end of the period).\na. Show that the loss rate (fraction of packets lost) is equal to\nL=loss rate=1\n3\n8 W2+3\n4 W\nb. Use the result above to show that if a connection has loss rate L, then its \naverage rate is approximately given by\n\u22481.22#MSS\nRTT 2L\n P46. Consider that only a single TCP (Reno) connection uses one 10Mbps link \nwhich does not buffer any data. Suppose that this link is the only congested \nlink between the sending and receiving hosts. Assume that the TCP sender \nhas a huge file to send to the receiver, and the receiver\u2019s receive buffer \nis much larger than the congestion window. We also make the following \nassumptions: each TCP segment size is 1,500 bytes; the two-way propagation \ndelay of this connection is 150 msec; and this TCP connection is always in \ncongestion avoidance phase, that is, ignore slow start.\na. What is the maximum window size (in segments) that this TCP connec-\ntion can achieve?\nb. What is the average window size (in segments) and average throughput \n(in bps) of this TCP connection?\nc. How long would it take for this TCP connection to reach its maximum \nwindow again after recovering from a packet loss?\n P47. Consider the scenario described in the previous problem. Suppose that the \n10Mbps link can buffer a finite number of segments. Argue that in order for \nthe link to always be busy sending data, we would like to choose a buffer size \nthat is at least the product of the link speed C and the two-way propagation \ndelay between the sender and the receiver.\n P48. Repeat Problem 46, but replacing the 10 Mbps link with a 10 Gbps link. Note \nthat in your answer to part c, you will realize that it takes a very long time for \nthe congestion window size to reach its maximum window size after recover-\ning from a packet loss. Sketch a solution to solve this problem.\n P49. Let T (measured by RTT) denote the time interval that a TCP connection \ntakes to increase its congestion window size from W/2 to W, where W is the \nmaximum congestion window size. Argue that T is a function of TCP\u2019s  \naverage throughput.\n328     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\n P50. Consider a simplified TCP\u2019s AIMD algorithm where the congestion window \nsize is measured in number of segments, not in bytes. In additive increase, the \ncongestion window size increases by one segment in each RTT. In", "doc_id": "545d9a93-adf3-442e-8290-eab87eff28bd", "embedding": null, "doc_hash": "5978969a7ef2c9f1041fbad9499ec2207437553f8fd603753d961f520b007424", "extra_info": null, "node_info": {"start": 950648, "end": 954253}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "72e4c9a5-fae7-4bae-8713-9493c1351f48", "3": "5d5cd856-6cb5-4895-aed2-f45453fc5a6f"}}, "__type__": "1"}, "5d5cd856-6cb5-4895-aed2-f45453fc5a6f": {"__data__": {"text": "\nthe congestion window size to reach its maximum window size after recover-\ning from a packet loss. Sketch a solution to solve this problem.\n P49. Let T (measured by RTT) denote the time interval that a TCP connection \ntakes to increase its congestion window size from W/2 to W, where W is the \nmaximum congestion window size. Argue that T is a function of TCP\u2019s  \naverage throughput.\n328     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\n P50. Consider a simplified TCP\u2019s AIMD algorithm where the congestion window \nsize is measured in number of segments, not in bytes. In additive increase, the \ncongestion window size increases by one segment in each RTT. In multipli-\ncative decrease, the congestion window size decreases by half (if the result \nis not an integer, round down to the nearest integer). Suppose that two TCP \nconnections, C1 and C2, share a single congested link of speed 30 segments \nper second. Assume that both C1 and C2 are in the congestion avoidance \nphase. Connection C1\u2019s RTT is 50 msec and connection C2\u2019s RTT is 100 \nmsec. Assume that when the data rate in the link exceeds the link\u2019s speed, all \nTCP connections experience data segment loss.\na. If both C1 and C2 at time t0 have a congestion window of 10 segments, \nwhat are their congestion window sizes after 1000 msec?\nb. In the long run, will these two connections get the same share of the band-\nwidth of the congested link? Explain.\n P51. Consider the network described in the previous problem. Now suppose that \nthe two TCP connections, C1 and C2, have the same RTT of 100 msec.  \nSuppose that at time t0, C1\u2019s congestion window size is 15 segments but C2\u2019s \ncongestion window size is 10 segments.\na. What are their congestion window sizes after 2200 msec?\nb. In the long run, will these two connections get about the same share of the \nbandwidth of the congested link?\nc. We say that two connections are synchronized, if both connections reach \ntheir maximum window sizes at the same time and reach their minimum \nwindow sizes at the same time. In the long run, will these two connec-\ntions get synchronized eventually? If so, what are their maximum window \nsizes?\nd. Will this synchronization help to improve the utilization of the shared \nlink? Why? Sketch some idea to break this synchronization.\n P52. Consider a modification to TCP\u2019s congestion control algorithm. Instead of \nadditive increase, we can use multiplicative increase. A TCP sender increases \nits window size by a small positive constant a (06a61) whenever it \nreceives a valid ACK. Find the functional relationship between loss rate L \nand maximum congestion window W. Argue that for this modified TCP, \nregardless of TCP\u2019s average throughput, a TCP connection always spends the \nsame amount of time to increase its congestion window size from W/2 to W.\n P53. In our discussion of TCP futures in Section 3.7, we noted that to achieve a \nthroughput of 10 Gbps, TCP could only tolerate a segment loss probability of \n2#10-10 (or equivalently, one loss event for every 5,000,000,000 segments). \nShow the derivation for the values of 2#10-10 (1 out of 5,000,000) for the \nRTT and MSS values given in Section 3.7. If TCP needed to support a 100 \nGbps connection, what would the tolerable loss be?\nPROGRAMMING ASSIGNMENTS      329\n P54. In our discussion of TCP congestion control in Section 3.7, we implicitly \nassumed that the TCP sender always had data to send. Consider now the case \nthat the TCP sender sends a large amount of data and then goes idle (since it \nhas", "doc_id": "5d5cd856-6cb5-4895-aed2-f45453fc5a6f", "embedding": null, "doc_hash": "becbfba897e9bde7658bef509e6471dfddc94be0d9883f12b46e52d2376d64e5", "extra_info": null, "node_info": {"start": 954341, "end": 957847}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "545d9a93-adf3-442e-8290-eab87eff28bd", "3": "cd5a65d1-ae7b-4b5b-9516-95f8edeac4e4"}}, "__type__": "1"}, "cd5a65d1-ae7b-4b5b-9516-95f8edeac4e4": {"__data__": {"text": "to achieve a \nthroughput of 10 Gbps, TCP could only tolerate a segment loss probability of \n2#10-10 (or equivalently, one loss event for every 5,000,000,000 segments). \nShow the derivation for the values of 2#10-10 (1 out of 5,000,000) for the \nRTT and MSS values given in Section 3.7. If TCP needed to support a 100 \nGbps connection, what would the tolerable loss be?\nPROGRAMMING ASSIGNMENTS      329\n P54. In our discussion of TCP congestion control in Section 3.7, we implicitly \nassumed that the TCP sender always had data to send. Consider now the case \nthat the TCP sender sends a large amount of data and then goes idle (since it \nhas no more data to send) at t1. TCP remains idle for a relatively long period \nof time and then wants to send more data at t2. What are the advantages and \ndisadvantages of having TCP use the cwnd  and ssthresh  values from t1 \nwhen starting to send data at t2? What alternative would you recommend? \nWhy?\n P55. In this problem we investigate whether either UDP or TCP provides a degree \nof end-point authentication.\na. Consider a server that receives a request within a UDP packet and \nresponds to that request within a UDP packet (for example, as done by a \nDNS server). If a client with IP address X spoofs its address with address \nY, where will the server send its response?\nb. Suppose a server receives a SYN with IP source address Y, and after \nresponding with a SYNACK, receives an ACK with IP source address Y \nwith the correct acknowledgment number. Assuming the server chooses a \nrandom initial sequence number and there is no \u201cman-in-the-middle,\u201d can \nthe server be certain that the client is indeed at Y (and not at some other \naddress X that is spoofing Y)?\n P56. In this problem, we consider the delay introduced by the TCP slow-start \nphase. Consider a client and a Web server directly connected by one link of \nrate R. Suppose the client wants to retrieve an object whose size is exactly \nequal to 15 S, where S is the maximum segment size (MSS). Denote the \nround-trip time between client and server as RTT (assumed to be constant). \nIgnoring protocol headers, determine the time to retrieve the object (includ-\ning TCP connection establishment) when\na. 4 S/R7S/R+RTT72S/R\nb. S/R+RTT74 S/R\nc. S/R7RTT.\nProgramming Assignments\nImplementing a Reliable Transport Protocol\nIn this laboratory programming assignment, you will be writing the sending and \nreceiving transport-level code for implementing a simple reliable data transfer pro -\ntocol. There are two versions of this lab, the alternating-bit-protocol version and the \nGBN version. This lab should be fun\u2014your implementation will differ very little \nfrom what would be required in a real-world situation.\n330     CHAPTER 3 \u2002\u2002\u2022 \u2002\u2002 TRANSPORT LAYER\nSince you probably don\u2019t have standalone machines (with an OS that you can \nmodify), your code will have to execute in a simulated hardware/software environ -\nment. However, the programming interface provided to your routines\u2014the code that \nwould call your entities from above and from below\u2014is very close to what is done \nin an actual UNIX environment. (Indeed, the software interfaces described in this \nprogramming assignment are much more realistic than the infinite loop senders and \nreceivers that many texts describe.) Stopping and starting timers are also simulated, \nand timer interrupts will cause your timer handling routine to be activated.\nThe full lab assignment, as well as code you will need to compile with your own \ncode, are available at this book\u2019s Web site: www.pearsonglobaleditions.com/kurose.\nWireshark Lab: Exploring TCP\nIn this lab, you\u2019ll", "doc_id": "cd5a65d1-ae7b-4b5b-9516-95f8edeac4e4", "embedding": null, "doc_hash": "a7aed0d87214d70b85345f8035d993af6e8dfb24e6ad7fa6af107b8e7dd5f294", "extra_info": null, "node_info": {"start": 957856, "end": 961479}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "5d5cd856-6cb5-4895-aed2-f45453fc5a6f", "3": "7f713e36-c731-497c-a4df-399052e5a916"}}, "__type__": "1"}, "7f713e36-c731-497c-a4df-399052e5a916": {"__data__": {"text": "code will have to execute in a simulated hardware/software environ -\nment. However, the programming interface provided to your routines\u2014the code that \nwould call your entities from above and from below\u2014is very close to what is done \nin an actual UNIX environment. (Indeed, the software interfaces described in this \nprogramming assignment are much more realistic than the infinite loop senders and \nreceivers that many texts describe.) Stopping and starting timers are also simulated, \nand timer interrupts will cause your timer handling routine to be activated.\nThe full lab assignment, as well as code you will need to compile with your own \ncode, are available at this book\u2019s Web site: www.pearsonglobaleditions.com/kurose.\nWireshark Lab: Exploring TCP\nIn this lab, you\u2019ll use your Web browser to access a file from a Web server. As in \nearlier Wireshark labs, you\u2019ll use Wireshark to capture the packets arriving at your \ncomputer. Unlike earlier labs, you\u2019ll also be able to download a Wireshark-readable \npacket trace from the Web server from which you downloaded the file. In this server \ntrace, you\u2019ll find the packets that were generated by your own access of the Web \nserver. You\u2019ll analyze the client- and server-side traces to explore aspects of TCP. \nIn particular, you\u2019ll evaluate the performance of the TCP connection between your \ncomputer and the Web server. You\u2019ll trace TCP\u2019s window behavior, and infer packet \nloss, retransmission, flow control and congestion control behavior, and estimated \nroundtrip time.\nAs is the case with all Wireshark labs, the full description of this lab is available \nat this book\u2019s Web site, www.pearsonglobaleditions.com/kurose.\nWireshark Lab: Exploring UDP\nIn this short lab, you\u2019ll do a packet capture and analysis of your favorite application \nthat uses UDP (for example, DNS or a multimedia application such as Skype). As \nwe learned in Section 3.3, UDP is a simple, no-frills transport protocol. In this lab, \nyou\u2019ll investigate the header fields in the UDP segment as well as the checksum \ncalculation.\nAs is the case with all Wireshark labs, the full description of this lab is available \nat this book\u2019s Web site, www.pearsonglobaleditions.com/kurose.\n331Please describe one or two of the most exciting projects you have worked on during your \ncareer. What were the biggest challenges?\nSchool teaches us lots of ways to find answers. In every interesting problem I\u2019ve worked \non, the challenge has been finding the right question. When Mike Karels and I started look -\ning at TCP congestion, we spent months staring at protocol and packet traces asking \u201cWhy \nis it failing?\u201d. One day in Mike\u2019s office, one of us said \u201cThe reason I can\u2019t figure out why \nit fails is because I don\u2019t understand how it ever worked to begin with.\u201d That turned out to \nbe the right question and it forced us to figure out the \u201cack clocking\u201d that makes TCP work. \nAfter that, the rest was easy.\nMore generally, where do you see the future of networking and the Internet?\nFor most people, the Web is the Internet. Networking geeks smile politely since we know \nthe Web is an application running over the Internet but what if they\u2019re right? The Internet \nis about enabling conversations between pairs of hosts. The Web is about distributed infor -\nmation production and consumption. \u201cInformation propagation\u201d is a very general view of \ncommunication of which \u201cpairwise conversation\u201d is a tiny subset. We need to move into the \nlarger tent. Networking today deals with broadcast media (radios, PONs, etc.) by pretending \nit\u2019s a point-to-point wire. That\u2019s massively inefficient. Terabits-per-second of data are being \nexchanged all over the World via thumb drives or smart phones but we", "doc_id": "7f713e36-c731-497c-a4df-399052e5a916", "embedding": null, "doc_hash": "bf3a48ea73de86a3024e0e5117f868327fb50ca6b63a3b78463fdf73d3381a40", "extra_info": null, "node_info": {"start": 961346, "end": 965063}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "cd5a65d1-ae7b-4b5b-9516-95f8edeac4e4", "3": "b8d7710e-0499-4372-9806-39b78584a36f"}}, "__type__": "1"}, "b8d7710e-0499-4372-9806-39b78584a36f": {"__data__": {"text": "the future of networking and the Internet?\nFor most people, the Web is the Internet. Networking geeks smile politely since we know \nthe Web is an application running over the Internet but what if they\u2019re right? The Internet \nis about enabling conversations between pairs of hosts. The Web is about distributed infor -\nmation production and consumption. \u201cInformation propagation\u201d is a very general view of \ncommunication of which \u201cpairwise conversation\u201d is a tiny subset. We need to move into the \nlarger tent. Networking today deals with broadcast media (radios, PONs, etc.) by pretending \nit\u2019s a point-to-point wire. That\u2019s massively inefficient. Terabits-per-second of data are being \nexchanged all over the World via thumb drives or smart phones but we don\u2019t know how to \ntreat that as \u201cnetworking\u201d. ISPs are busily setting up caches and CDNs to scalably distribute \nvideo and audio. Caching is a necessary part of the solution but there\u2019s no part of today\u2019s \nnetworking\u2014from Information, Queuing or Traffic Theory down to the Internet protocol Van Jacobson works at Google and was previously a Research \nFellow at PARC. Prior to that, he was co-founder and Chief Scientist \nof Packet Design. Before that, he was Chief Scientist at Cisco. \nBefore joining Cisco, he was head of the Network Research \nGroup at Lawrence Berkeley National Laboratory and taught at UC \nBerkeley and Stanford. Van received the ACM SIGCOMM Award \nin 2001 for outstanding lifetime contribution to the field of commu -\nnication networks and the IEEE Kobayashi Award in 2002 for \u201ccon -\ntributing to the understanding of network congestion and developing \ncongestion control mechanisms that enabled the successful scaling \nof the Internet\u201d. He was elected to the U.S. National Academy of \nEngineering in 2004.Van JacobsonAN INTERVIEW WITH...\n\n332specs\u2014that tells us how to engineer and deploy it. I think and hope that over the next few \nyears, networking will evolve to embrace the much larger vision of communication that \nunderlies the Web.\nWhat people inspired you professionally?\nWhen I was in grad school, Richard Feynman visited and gave a colloquium. He talked \nabout a piece of Quantum theory that I\u2019d been struggling with all semester and his explana -\ntion was so simple and lucid that what had been incomprehensible gibberish to me became \nobvious and inevitable. That ability to see and convey the simplicity that underlies our  \ncomplex world seems to me a rare and wonderful gift.\nWhat are your recommendations for students who want careers in computer science and \nnetworking?\nIt\u2019s a wonderful field\u2014computers and networking have probably had more impact on society \nthan any invention since the book. Networking is fundamentally about connecting stuff, and \nstudying it helps you make intellectual connections: Ant foraging & Bee dances demonstrate \nprotocol design better than RFCs, traffic jams or people leaving a packed stadium are the \nessence of congestion, and students finding flights back to school in a post-Thanksgiving  \nblizzard are the core of dynamic routing. If you\u2019re interested in lots of stuff and want to \nhave an impact, it\u2019s hard to imagine a better field.\n333We learned in the previous chapter that the transport layer provides various forms \nof process-to-process communication by relying on the network layer\u2019s host-to-host \ncommunication service. We also learned that the transport layer does so without any \nknowledge about how the network layer actually implements this service. So perhaps \nyou\u2019re now wondering, what\u2019s under the hood of the host-to-host communication \nservice, what makes it tick?\nIn this chapter and the next, we\u2019ll learn exactly how the network layer can pro -\nvide its host-to-host communication service. We\u2019ll see that unlike the transport and \napplication layers, there is a piece of the network layer in each and every host and \nrouter", "doc_id": "b8d7710e-0499-4372-9806-39b78584a36f", "embedding": null, "doc_hash": "3bce52b13d706bbb8f2015a958e5bc680070f6e61a03da366cc66a9d30574acf", "extra_info": null, "node_info": {"start": 965086, "end": 968965}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "7f713e36-c731-497c-a4df-399052e5a916", "3": "8b8670c3-8a78-4629-811c-2da6f95a09b7"}}, "__type__": "1"}, "8b8670c3-8a78-4629-811c-2da6f95a09b7": {"__data__": {"text": "of stuff and want to \nhave an impact, it\u2019s hard to imagine a better field.\n333We learned in the previous chapter that the transport layer provides various forms \nof process-to-process communication by relying on the network layer\u2019s host-to-host \ncommunication service. We also learned that the transport layer does so without any \nknowledge about how the network layer actually implements this service. So perhaps \nyou\u2019re now wondering, what\u2019s under the hood of the host-to-host communication \nservice, what makes it tick?\nIn this chapter and the next, we\u2019ll learn exactly how the network layer can pro -\nvide its host-to-host communication service. We\u2019ll see that unlike the transport and \napplication layers, there is a piece of the network layer in each and every host and \nrouter in the network.  Because of this, network-layer protocols are among the most \nchallenging (and therefore among the most interesting!) in the protocol stack.\nSince the network layer is arguably the most complex layer in the protocol \nstack, we\u2019ll have a lot of ground to cover here. Indeed, there is so much to cover \nthat we cover the network layer in two chapters. We\u2019ll see that the network layer \ncan be decomposed into two interacting parts, the data plane  and the control plane . \nIn Chapter 4, we\u2019ll  first cover the data plane functions of the network layer\u2014the \nper-router  functions in the network layer that determine how a datagram (that is, a \nnetwork-layer packet) arriving on one of a router\u2019s input links is forwarded to one \nof that router\u2019s output links. We\u2019ll cover both traditional IP forwarding (where for -\nwarding is based on a datagram\u2019s destination address) and generalized forwarding \n(where forwarding and other functions may be performed using values in several \ndifferent fields in the datagram\u2019s header). We\u2019ll study the IPv4 and IPv6 protocols \nand addressing in detail. In Chapter 5, we\u2019ll cover the control plane functions of \nthe network layer\u2014the network-wide  logic that controls how a datagram is routed 4CHAPTER\nThe Network \nLayer: Data \nPlane\n\n334     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\namong routers along an end-to-end path from the source host to the destination host. \nWe\u2019ll cover routing algorithms, as well as routing protocols, such as OSPF and BGP, \nthat are in widespread use in today\u2019s Internet. Traditionally, these control-plane rout -\ning protocols and data-plane forwarding functions have been implemented together, \nmonolithically, within a router. Software-defined networking (SDN) explicitly sepa -\nrates the data plane and control plane by implementing these control plane functions \nas a separate service, typically in a remote \u201ccontroller.\u201d We\u2019ll also cover SDN con -\ntrollers in Chapter 5.\nThis distinction between data-plane and control-plane functions in the network \nlayer is an important concept to keep in mind as you learn about the network layer \u2014\nit will help structure your thinking about the network layer and reflects a modern \nview of the network layer\u2019s role in computer networking.\n4.1 Overview of Network Layer\nFigure 4. 1 shows a simple network with two hosts, H1 and H2, and several routers on \nthe path between H1 and H2. Let\u2019s suppose that H1 is sending information to H2, and \nconsider the role of the network layer in these hosts and in the intervening routers. The \nnetwork layer in H1 takes segments from the transport layer in H1, encapsulates each \nsegment into a datagram, and then sends the datagrams to its nearby router, R1. At the \nreceiving host, H2, the network layer receives the datagrams from its nearby router \nR2, extracts the transport-layer segments, and delivers the segments up to the transport \nlayer at H2. The primary data-plane role of each router is to forward datagrams from \nits input links to its output", "doc_id": "8b8670c3-8a78-4629-811c-2da6f95a09b7", "embedding": null, "doc_hash": "5f4537920cfb33190e204eaa3524a39d9b5fc9bf3399e78ad9a7f28d2932b973", "extra_info": null, "node_info": {"start": 968943, "end": 972751}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "b8d7710e-0499-4372-9806-39b78584a36f", "3": "5d3d18de-8f40-48ce-b6a5-cdddc3e676c7"}}, "__type__": "1"}, "5d3d18de-8f40-48ce-b6a5-cdddc3e676c7": {"__data__": {"text": "network with two hosts, H1 and H2, and several routers on \nthe path between H1 and H2. Let\u2019s suppose that H1 is sending information to H2, and \nconsider the role of the network layer in these hosts and in the intervening routers. The \nnetwork layer in H1 takes segments from the transport layer in H1, encapsulates each \nsegment into a datagram, and then sends the datagrams to its nearby router, R1. At the \nreceiving host, H2, the network layer receives the datagrams from its nearby router \nR2, extracts the transport-layer segments, and delivers the segments up to the transport \nlayer at H2. The primary data-plane role of each router is to forward datagrams from \nits input links to its output links; the primary role of the network control plane is to \ncoordinate these local, per-router forwarding actions so that datagrams are ultimately \ntransferred end-to-end, along paths of routers between source and destination hosts. \nNote that the routers in Figure 4.1 are shown with a truncated protocol stack, that is, \nwith no upper layers above the network layer, because routers do not run application-  \nand transport-layer protocols such as those we examined in Chapters 2 and 3 .\n4.1.1  Forwarding and Routing: The Data and  \nControl Planes\nThe primary role of the network layer is deceptively simple\u2014to move packets from \na sending host to a receiving host. To do so, two important network-layer functions \ncan be identified:\n\u2022 Forwarding.  When a packet arrives at a router\u2019s input link, the router must move \nthe packet to the appropriate output link. For example, a packet arriving from \nHost H1 to Router R1 in Figure 4.1 must be forwarded to the next router on \na path to H2. As we will see, forwarding is but one function (albeit the most  \n4.1  \u2022  OVERVIEW OF NETWORK LAYER      335\nData link\nPhysicalNetworkData link\nPhysicalNetwork\nEnd system H1National or\nGlobal ISP\nMobile Network\nLocal or\nRegional ISP\nEnterprise NetworkHome Network\nEnd system H2\nData link\nPhysicalApplication\nTransport\nNetworkRouter R2\nData link\nPhysicalNetworkData link\nPhysicalNetworkData link\nPhysicalNetworkRouter R1\nData link\nPhysicalApplication\nTransport\nNetwork\nFigure 4.1  \u2666 The network layer\n336     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\ncommon and important one!) implemented in the data plane. In the more general \ncase, which we\u2019ll cover in Section 4.4, a packet might also be blocked from exit -\ning a router (e.g., if the packet originated at a known malicious sending host, or if \nthe packet were destined to a forbidden destination host), or might be duplicated \nand sent over multiple outgoing links.\n\u2022 Routing.  The network layer must determine the route or path taken by packets as \nthey flow from a sender to a receiver. The algorithms that calculate these paths \nare referred to as routing algorithms . A routing algorithm would determine, for \nexample, the path along which packets flow from H1 to H2 in Figure 4.1. Routing \nis implemented in the control plane of the network layer.\nThe terms forwarding  and routing  are often used interchangeably by authors dis -\ncussing the network layer. We\u2019ll use these terms much more precisely in this book.  \nForwarding  refers to the router-local action of transferring a packet from an input \nlink interface to the appropriate output link interface. Forwarding takes place at very \nshort timescales (typically a few nanoseconds), and thus is typically implemented in \nhardware. Routing  refers to the network-wide process that determines the end-to-end \npaths that packets take from source to destination. Routing takes place on much longer \ntimescales (typically seconds), and as we will see is often implemented in software. \nUsing our  driving", "doc_id": "5d3d18de-8f40-48ce-b6a5-cdddc3e676c7", "embedding": null, "doc_hash": "eab24a04e734c1243c186819f029fae6c5a2ff11b3d1cfee1dc5c953e38c82fd", "extra_info": null, "node_info": {"start": 972835, "end": 976546}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "8b8670c3-8a78-4629-811c-2da6f95a09b7", "3": "0d97bbcc-292f-4730-865c-eb8ab986d5f9"}}, "__type__": "1"}, "0d97bbcc-292f-4730-865c-eb8ab986d5f9": {"__data__": {"text": "Figure 4.1. Routing \nis implemented in the control plane of the network layer.\nThe terms forwarding  and routing  are often used interchangeably by authors dis -\ncussing the network layer. We\u2019ll use these terms much more precisely in this book.  \nForwarding  refers to the router-local action of transferring a packet from an input \nlink interface to the appropriate output link interface. Forwarding takes place at very \nshort timescales (typically a few nanoseconds), and thus is typically implemented in \nhardware. Routing  refers to the network-wide process that determines the end-to-end \npaths that packets take from source to destination. Routing takes place on much longer \ntimescales (typically seconds), and as we will see is often implemented in software. \nUsing our  driving analogy, consider the trip from Pennsylvania to Florida undertaken \nby our traveler back in Section 1.3.1. During this trip, our driver passes through many \ninterchanges en route to Florida. We can think of forwarding as the process of getting \nthrough a single interchange: A car enters the interchange from one road and deter -\nmines which road it should take to leave the interchange. We can think of routing as \nthe process of planning the trip from Pennsylvania to Florida: Before embarking on \nthe trip, the driver has consulted a map and chosen one of many paths possible, with \neach path consisting of a series of road segments connected at interchanges.\nA key element in every network router is its forwarding table . A router forwards \na packet by examining the value of one or more fields in the arriving packet\u2019s header, \nand then using these header values to index into its forwarding table. The value stored \nin the forwarding table entry for those values indicates the outgoing link interface at \nthat router to which that packet is to be forwarded. For example, in Figure 4.2, a packet \nwith header field value of 0110 arrives to a router. The router indexes into its forward -\ning table and determines that the output link interface for this packet is interface 2. \nThe router then internally forwards the packet to interface 2. In Section 4.2, we\u2019ll look \ninside a router and examine the forwarding function in much greater detail. Forward -\ning is the key function performed by the data-plane functionality of the network layer.\nControl Plane: The Traditional Approach \nBut now you are undoubtedly wondering how a router\u2019s forwarding tables are con -\nfigured in the first place. This is a crucial issue, one that exposes the important inter -\nplay between forwarding (in data plane) and routing (in control plane). As shown  \n4.1  \u2022  OVERVIEW OF NETWORK LAYER      337\nin Figure 4.2, the routing algorithm determines the contents of the routers\u2019 forward -\ning tables. In this example, a routing algorithm runs in each and every router and \nboth forwarding and routing functions are contained within a router. As we\u2019ll see in \nSections  5.3 and 5.4, the routing algorithm function in one router communicates with \nthe routing algorithm function in other routers to compute the values for its forward -\ning table. How is this communication performed? By exchanging routing messages \ncontaining routing information according to a routing protocol! We\u2019ll cover routing \nalgorithms and protocols in Sections 5.2 through 5.4.\nThe distinct and different purposes of the forwarding and routing functions can \nbe further illustrated by considering the hypothetical (and unrealistic, but technically \nfeasible) case of a network in which all forwarding tables are configured directly by \nhuman network operators physically present at the routers. In this case, no routing \nprotocols would be required! Of course, the human operators would need to interact \nwith each other to ensure that the forwarding tables were configured in such a way \nthat packets reached their intended destinations. It\u2019s also likely that human configu -\nration would be more error-prone and much slower to respond to changes in the net -\nwork topology", "doc_id": "0d97bbcc-292f-4730-865c-eb8ab986d5f9", "embedding": null, "doc_hash": "5b97f552a5ebc28b9be5c88e0bb8cc06a41f8dcb97a590dddeff560615fd9f4d", "extra_info": null, "node_info": {"start": 976463, "end": 980485}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "5d3d18de-8f40-48ce-b6a5-cdddc3e676c7", "3": "c4a06991-1558-4572-9922-3598d3d4c6cb"}}, "__type__": "1"}, "c4a06991-1558-4572-9922-3598d3d4c6cb": {"__data__": {"text": "protocol! We\u2019ll cover routing \nalgorithms and protocols in Sections 5.2 through 5.4.\nThe distinct and different purposes of the forwarding and routing functions can \nbe further illustrated by considering the hypothetical (and unrealistic, but technically \nfeasible) case of a network in which all forwarding tables are configured directly by \nhuman network operators physically present at the routers. In this case, no routing \nprotocols would be required! Of course, the human operators would need to interact \nwith each other to ensure that the forwarding tables were configured in such a way \nthat packets reached their intended destinations. It\u2019s also likely that human configu -\nration would be more error-prone and much slower to respond to changes in the net -\nwork topology than a routing protocol. We\u2019re thus fortunate that all networks have \nboth a forwarding and a routing function!0110Local forwarding\ntable\nheader\n0100\n0110\n0111\n10013\n2\n2\n1outputContr ol plane\nData planeRouting\nAlgorithm\nValues in arriving\npacket\u2019s header\n1\n23\nFigure 4.2  \u2666 Routing algorithms determine values in forward tables\n338     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\nControl Plane: The SDN Approach \nThe approach to implementing routing functionality shown in Figure 4.2\u2014with each \nrouter having a routing component that communicates with the routing component of \nother routers\u2014has been the traditional approach adopted by routing vendors in their \nproducts, at least until recently. Our observation that humans could manually configure \nforwarding tables does suggest, however, that there may be other ways for control-\nplane functionality to determine the contents of the data-plane forwarding tables.\nFigure 4. 3 shows an alternate approach in which a physically separate (from the \nrouters), remote controller computes and distributes the forwarding tables to be used \nby each and every router.  Note that the data plane components of Figures 4.2 and 4.3 \nare identical. In Figure 4.3, however, control-plane routing functionality is separated \n0110Local forwarding\ntable\nheader\n0100\n0110\n0111\n10013\n2\n2\n1outputRemote Controller\nValues in arriving\npacket\u2019s header\n1\n23Contr ol plane\nData plane\nFigure 4.3  \u2666  A remote controller determines and distributes values in \n forwarding tables\n4.1  \u2022  OVERVIEW OF NETWORK LAYER      339\nfrom the physical router\u2014the routing device performs forwarding only, while the \nremote controller computes and distributes forwarding tables. The remote controller \nmight be implemented in a remote data center with high reliability and redundancy, \nand might be managed by the ISP or some third party. How might the routers and \nthe remote controller communicate? By exchanging messages containing forwarding \ntables and other pieces of routing information. The control-plane approach shown \nin Figure 4.3 is at the heart of software-defined networking (SDN) , where the net -\nwork is \u201csoftware-defined\u201d because the controller that computes forwarding tables \nand interacts with routers is implemented in software. Increasingly, these software \nimplementations are also open, i.e., similar to Linux OS code, the code is publically \navailable, allowing ISPs (and networking researchers and students!) to innovate and \npropose changes to the software that controls network-layer functionality. We will \ncover the SDN control plane in Section 5.5.\n4.1.2  Network Service Model\nBefore delving into the network layer\u2019s data plane, let\u2019s wrap up our introduction \nby taking the broader view and consider the different types of service that might be \noffered by the network layer. When the transport layer at a sending host transmits a \npacket into the network (that is, passes it down to the network layer at the sending \nhost), can the transport layer rely on the network layer to deliver the packet to the \ndestination? When multiple", "doc_id": "c4a06991-1558-4572-9922-3598d3d4c6cb", "embedding": null, "doc_hash": "9510688b0b8edf08f7d255c58f72cc688114d2510fee8d4aa0e1467130270168", "extra_info": null, "node_info": {"start": 980486, "end": 984348}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "0d97bbcc-292f-4730-865c-eb8ab986d5f9", "3": "827b5ff6-f395-49d5-9292-75f5f93517f1"}}, "__type__": "1"}, "827b5ff6-f395-49d5-9292-75f5f93517f1": {"__data__": {"text": "these software \nimplementations are also open, i.e., similar to Linux OS code, the code is publically \navailable, allowing ISPs (and networking researchers and students!) to innovate and \npropose changes to the software that controls network-layer functionality. We will \ncover the SDN control plane in Section 5.5.\n4.1.2  Network Service Model\nBefore delving into the network layer\u2019s data plane, let\u2019s wrap up our introduction \nby taking the broader view and consider the different types of service that might be \noffered by the network layer. When the transport layer at a sending host transmits a \npacket into the network (that is, passes it down to the network layer at the sending \nhost), can the transport layer rely on the network layer to deliver the packet to the \ndestination? When multiple packets are sent, will they be delivered to the transport \nlayer in the receiving host in the order in which they were sent? Will the amount \nof time between the sending of two sequential packet transmissions be the same \nas the amount of time between their reception? Will the network provide any feed -\nback about congestion in the network? The answers to these questions and others \nare determined by the service model provided by the network layer. The network \nservice model  defines the characteristics of end-to-end delivery of packets between \nsending and receiving hosts.\nLet\u2019s now consider some possible services that the network layer could provide. \nThese services could include:\n\u2022 Guaranteed delivery . This service guarantees that a packet sent by a source host \nwill eventually arrive at the destination host.\n\u2022 Guaranteed delivery with bounded delay . This service not only guarantees \ndelivery of the packet, but delivery within a specified host-to-host delay bound  \n(for example, within 100 msec).\n\u2022 In-order packet delivery . This service guarantees that packets arrive at the desti -\nnation in the order that they were sent.\n\u2022 Guaranteed minimal bandwidth . This network-layer service emulates the behav -\nior of a transmission link of a specified bit rate (for example, 1 Mbps) between \nsending and receiving hosts. As long as the sending host transmits bits (as part \n340     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\nof packets) at a rate below the specified bit rate, then all packets are eventually \ndelivered to the destination host.\n\u2022 Security . The network layer could encrypt all datagrams at the source and decrypt them \nat the destination, thereby providing confidentiality to all transport-layer segments.\nThis is only a partial list of services that a network layer could provide\u2014there are \ncountless variations possible.\nThe Internet\u2019s network layer provides a single service, known as best-effort \nservice . With best-effort service, packets are neither guaranteed to be received in the \norder in which they were sent, nor is their eventual delivery even guaranteed. There \nis no guarantee on the end-to-end delay nor is there a minimal bandwidth guaran -\ntee. It might appear that best-effort service  is a euphemism for no service at all \u2014a \nnetwork that delivered no packets to the destination would satisfy the definition of  \nbest-effort delivery service! Other network architectures have defined and imple -\nmented service models that go beyond the Internet\u2019s best-effort service. For example, \nthe ATM network architecture [MFA Forum 2016, Black 1995] provides for guaran -\nteed in-order delay, bounded delay, and guaranteed minimal bandwidth. There have \nalso been proposed service model extensions to the Internet architecture; for exam -\nple, the Intserv architecture [RFC 1633] aims to provide end-end delay guarantees \nand congestion-free communication. Interestingly, in spite of these well-developed \nalternatives, the Internet\u2019s basic best-effort service model combined with adequate \nbandwidth provisioning have arguably proven to be more than \u201cgood enough\u201d to \nenable an amazing range of applications, including streaming video services such", "doc_id": "827b5ff6-f395-49d5-9292-75f5f93517f1", "embedding": null, "doc_hash": "04dc41319935bbfb283f255950fad5cd2791ae0d76e2f20de4e1aa929a7d4940", "extra_info": null, "node_info": {"start": 984339, "end": 988339}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "c4a06991-1558-4572-9922-3598d3d4c6cb", "3": "59f776ba-1f3b-499f-9681-4d1d7f2c6b77"}}, "__type__": "1"}, "59f776ba-1f3b-499f-9681-4d1d7f2c6b77": {"__data__": {"text": "have defined and imple -\nmented service models that go beyond the Internet\u2019s best-effort service. For example, \nthe ATM network architecture [MFA Forum 2016, Black 1995] provides for guaran -\nteed in-order delay, bounded delay, and guaranteed minimal bandwidth. There have \nalso been proposed service model extensions to the Internet architecture; for exam -\nple, the Intserv architecture [RFC 1633] aims to provide end-end delay guarantees \nand congestion-free communication. Interestingly, in spite of these well-developed \nalternatives, the Internet\u2019s basic best-effort service model combined with adequate \nbandwidth provisioning have arguably proven to be more than \u201cgood enough\u201d to \nenable an amazing range of applications, including streaming video services such \nas Netflix and voice-and-video-over-IP, real-time conferencing applications such as \nSkype and Facetime.\nAn Overview of Chapter 4\nHaving now provided an overview of the network layer, we\u2019ll cover the data-plane  \ncomponent of the network layer in the following sections in this chapter. In Section \n4.2, we\u2019ll dive down into the internal hardware operations of a router, including input \nand output packet processing, the router\u2019s internal switching mechanism, and packet \nqueueing and scheduling. In Section 4.3, we\u2019ll take a look at traditional IP forward -\ning, in which packets are forwarded to output ports based on their destination IP \naddresses. We\u2019ll encounter IP addressing, the celebrated IPv4 and IPv6 protocols and \nmore. In Section 4.4, we\u2019ll cover more generalized forwarding, where packets may \nbe forwarded to output ports based on a large number of header values (i.e., not only \nbased on destination IP address). Packets may be blocked or duplicated at the router, \nor may have certain header field values rewritten\u2014all under software control. This \nmore generalized form of packet forwarding is a key component of a modern network \ndata plane, including the data plane in software-defined networks (SDN).\nWe mention here in passing that the terms forwarding  and switching  are often \nused interchangeably by computer-networking researchers and practitioners; we\u2019ll \n4.2  \u2022  WHAT\u2019S INSIDE A ROUTER?      341\nuse both terms interchangeably in this textbook as well. While we\u2019re on the topic \nof terminology, it\u2019s also worth mentioning two other terms that are often used \ninterchangeably, but that we will use more carefully. We\u2019ll reserve the term packet \nswitch  to mean a general packet-switching device that transfers a packet from input \nlink interface to output link interface, according to values in a packet\u2019s header fields. \nSome packet switches, called link-layer switches  (examined in Chapter 6 ), base \ntheir forwarding decision on values in the fields of the link-layer frame; switches \nare thus referred to as link-layer (layer 2) devices. Other packet switches, called \nrouters , base their forwarding decision on header field values in the network-layer \ndatagram. Routers are thus network-layer (layer 3) devices. (To fully appreciate this \nimportant distinction, you might want to review Section 1.5.2, where we discuss \nnetwork-layer datagrams and link-layer frames and their relationship.) Since our \nfocus in this chapter is on the network layer, we\u2019ll mostly use the term router  in \nplace of packet switch .\n4.2 What\u2019s Inside a Router?\nNow that we\u2019ve overviewed the data and control planes within the network layer, the \nimportant distinction between forwarding and routing, and the services and functions of \nthe network layer, let\u2019s turn our attention to its forwarding function\u2014the actual transfer \nof packets from a router\u2019s incoming links to the appropriate outgoing links at that router.\nA high-level view of a generic router architecture is shown in Figure 4.4. Four \nrouter components can be identified:\nInput port Output port\nInput port Output", "doc_id": "59f776ba-1f3b-499f-9681-4d1d7f2c6b77", "embedding": null, "doc_hash": "8c9a00379ce4ca1e5e86ea633da645a3316781d861bfe1c7f2c635062d750c50", "extra_info": null, "node_info": {"start": 988349, "end": 992215}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "827b5ff6-f395-49d5-9292-75f5f93517f1", "3": "c3e0600d-38a2-4c7d-a118-e62221d603c8"}}, "__type__": "1"}, "c3e0600d-38a2-4c7d-a118-e62221d603c8": {"__data__": {"text": "Section 1.5.2, where we discuss \nnetwork-layer datagrams and link-layer frames and their relationship.) Since our \nfocus in this chapter is on the network layer, we\u2019ll mostly use the term router  in \nplace of packet switch .\n4.2 What\u2019s Inside a Router?\nNow that we\u2019ve overviewed the data and control planes within the network layer, the \nimportant distinction between forwarding and routing, and the services and functions of \nthe network layer, let\u2019s turn our attention to its forwarding function\u2014the actual transfer \nof packets from a router\u2019s incoming links to the appropriate outgoing links at that router.\nA high-level view of a generic router architecture is shown in Figure 4.4. Four \nrouter components can be identified:\nInput port Output port\nInput port Output portRouting\nprocessorRouting, management\ncontrol plane (software)\nForwarding\ndata plane (hardware)\nSwitch\nfabric\nFigure 4.4  \u2666 Router architecture\n342     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\n\u2022 Input ports.  An input port  performs several key functions. It performs the physi -\ncal layer function of terminating an incoming physical link at a router; this is \nshown in the leftmost box of an input port and the rightmost box of an output \nport in Figure 4.4. An input port also performs link-layer functions needed to \ninteroperate with the link layer at the other side of the incoming link; this is \nrepresented by the middle boxes in the input and output ports. Perhaps most cru -\ncially, a lookup function is also performed at the input port; this will occur in the \nrightmost box of the input port. It is here that the forwarding table is consulted \nto determine the router output port to which an arriving packet will be forwarded \nvia the switching fabric. Control packets (for example, packets carrying routing \nprotocol information) are forwarded from an input port to the routing processor. \nNote that the term \u201cport\u201d here\u2014referring to the physical input and output router \ninterfaces\u2014is distinctly different from the software ports associated with network \napplications and sockets discussed in Chapters 2 and 3. In practice, the number of \nports supported by a router can range from a relatively small number in enterprise \nrouters, to hundreds of 10 Gbps ports in a router at an ISP\u2019s edge, where the num -\nber of incoming lines tends to be the greatest. The Juniper MX2020, edge router, \nfor example, supports up to 960 10 Gbps Ethernet ports, with an overall router \nsystem capacity of 80 Tbps [Juniper MX 2020 2016].\n\u2022 Switching fabric.  The switching fabric connects the router\u2019s input ports to its \noutput ports. This switching fabric is completely contained within the router\u2014a \nnetwork inside of a network router!\n\u2022 Output ports.  An output port  stores packets received from the switching fabric \nand transmits these packets on the outgoing link by performing the necessary \nlink-layer and physical-layer functions. When a link is bidirectional (that is, car -\nries traffic in both directions), an output port will typically be paired with the \ninput port for that link on the same line card.\n\u2022 Routing processor.  The routing processor performs control-plane functions. In tra -\nditional routers, it executes the routing protocols (which we\u2019ll study in Sections \n5.3 and 5.4), maintains routing tables and attached link state information, and com -\nputes the forwarding table for the router. In SDN routers, the routing processor is \nresponsible for communicating with the remote controller in order to (among other \nactivities) receive forwarding table entries computed by the remote controller, and \ninstall these entries in the router\u2019s input ports. The routing processor also performs \nthe network management functions that we\u2019ll study in Section 5.7 .\nA router\u2019s input ports, output ports, and switching fabric are almost always \nimplemented in hardware, as shown in Figure 4.4. To appreciate why a hardware", "doc_id": "c3e0600d-38a2-4c7d-a118-e62221d603c8", "embedding": null, "doc_hash": "8ceb7a9a1e3de799e8370987f16ab43098facf6b89047695430ce8ad9f527685", "extra_info": null, "node_info": {"start": 992228, "end": 996142}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "59f776ba-1f3b-499f-9681-4d1d7f2c6b77", "3": "1e576e40-ff8e-439e-a7eb-53a8932d4f64"}}, "__type__": "1"}, "1e576e40-ff8e-439e-a7eb-53a8932d4f64": {"__data__": {"text": "functions. In tra -\nditional routers, it executes the routing protocols (which we\u2019ll study in Sections \n5.3 and 5.4), maintains routing tables and attached link state information, and com -\nputes the forwarding table for the router. In SDN routers, the routing processor is \nresponsible for communicating with the remote controller in order to (among other \nactivities) receive forwarding table entries computed by the remote controller, and \ninstall these entries in the router\u2019s input ports. The routing processor also performs \nthe network management functions that we\u2019ll study in Section 5.7 .\nA router\u2019s input ports, output ports, and switching fabric are almost always \nimplemented in hardware, as shown in Figure 4.4. To appreciate why a hardware \nimplementation is needed, consider that with a 10 Gbps input link and a 64-byte IP \ndatagram, the input port has only 51.2 ns to process the datagram before another \ndatagram may arrive. If N ports are combined on a line card (as is often done in \npractice), the datagram-processing pipeline must operate N times faster\u2014far too \n4.2  \u2022  WHAT\u2019S INSIDE A ROUTER?      343\nfast for software implementation. Forwarding hardware can be implemented either \nusing a router vendor\u2019s own hardware designs, or constructed using purchased  \nmerchant-silicon chips (e.g., as sold by companies such as Intel and Broadcom).\nWhile the data plane operates at the nanosecond time scale, a router\u2019s control \nfunctions\u2014executing the routing protocols, responding to attached links that go up \nor down, communicating with the remote controller (in the SDN case) and perform -\ning management functions\u2014operate at the millisecond or second timescale. These \ncontrol plane  functions are thus usually implemented in software and execute on the \nrouting processor (typically a traditional CPU).\nBefore delving into the details of router internals, let\u2019s return to our analogy \nfrom the beginning of this chapter, where packet forwarding was compared to cars \nentering and leaving an interchange. Let\u2019s suppose that the interchange is a rounda -\nbout, and that as a car enters the roundabout, a bit of processing is required. Let\u2019s \nconsider what information is required for this processing:\n\u2022 Destination-based forwarding . Suppose the car stops at an entry station and indi -\ncates its final destination (not at the local roundabout, but the ultimate destination \nof its journey). An attendant at the entry station looks up the final destination, \ndetermines the roundabout exit that leads to that final destination, and tells the \ndriver which roundabout exit to take.\n\u2022 Generalized forwarding . The attendant could also determine the car\u2019s exit ramp on \nthe basis of many other factors besides the destination. For example, the selected \nexit ramp might depend on the car\u2019s origin, for example the state that issued the \ncar\u2019s license plate. Cars from a certain set of states might be directed to use one exit \nramp (that leads to the destination via a slow road), while cars from other states \nmight be directed to use a different exit ramp (that leads to the destination via super -\nhighway). The same decision might be made based on the model, make and year \nof the car. Or a car not deemed roadworthy might be blocked and not be allowed to \npass through the roundabout. In the case of generalized forwarding, any number of \nfactors may contribute to the attendant\u2019s choice of the exit ramp for a given car.\nOnce the car enters the roundabout (which may be filled with other cars entering \nfrom other input roads and heading to other roundabout exits), it eventually leaves at \nthe prescribed roundabout exit ramp, where it may encounter other cars leaving the \nroundabout at that exit.\nWe can easily recognize the principal router components in Figure 4.4 in this \nanalogy\u2014the entry road and entry station correspond to the input port (with a lookup \nfunction to determine to local outgoing port); the roundabout", "doc_id": "1e576e40-ff8e-439e-a7eb-53a8932d4f64", "embedding": null, "doc_hash": "70d61ea24ff130d565bd0892373847d1008518fcb01d3abaad30886940310ab4", "extra_info": null, "node_info": {"start": 996155, "end": 1000105}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "c3e0600d-38a2-4c7d-a118-e62221d603c8", "3": "9672ebcb-dfe8-486c-af7a-3a0ff4c5a94f"}}, "__type__": "1"}, "9672ebcb-dfe8-486c-af7a-3a0ff4c5a94f": {"__data__": {"text": "might be made based on the model, make and year \nof the car. Or a car not deemed roadworthy might be blocked and not be allowed to \npass through the roundabout. In the case of generalized forwarding, any number of \nfactors may contribute to the attendant\u2019s choice of the exit ramp for a given car.\nOnce the car enters the roundabout (which may be filled with other cars entering \nfrom other input roads and heading to other roundabout exits), it eventually leaves at \nthe prescribed roundabout exit ramp, where it may encounter other cars leaving the \nroundabout at that exit.\nWe can easily recognize the principal router components in Figure 4.4 in this \nanalogy\u2014the entry road and entry station correspond to the input port (with a lookup \nfunction to determine to local outgoing port); the roundabout corresponds to the \nswitch fabric; and the roundabout exit road corresponds to the output port. With this \nanalogy, it\u2019s instructive to consider where bottlenecks might occur. What happens if \ncars arrive blazingly fast (for example, the roundabout is in Germany or Italy!) but \nthe station attendant is slow? How fast must the attendant work to ensure there\u2019s no \nbackup on an entry road? Even with a blazingly fast attendant, what happens if cars \n344     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\ntraverse the roundabout slowly\u2014can backups still occur? And what happens if most \nof the cars entering at all of the roundabout\u2019s entrance ramps all want to leave the \nroundabout at the same exit ramp\u2014can backups occur at the exit ramp or elsewhere? \nHow should the roundabout operate if we want to assign priorities to different cars, \nor block certain cars from entering the roundabout in the first place? These are all \nanalogous to critical questions faced by router and switch designers.\nIn the following subsections, we\u2019ll look at router functions in more detail. [Iyer \n2008, Chao 2001; Chuang 2005; Turner 1988; McKeown 1997a; Partridge 1998; Sopra -\nnos 2011] provide a discussion of specific router architectures. For concreteness and \nsimplicity, we\u2019ll initially assume in this section that forwarding decisions are based only \non the packet\u2019s destination address, rather than on a generalized set of packet header \nfields. We will cover the case of more generalized packet forwarding in Section 4.4.\n4.2.1  Input Port Processing and Destination-Based Forwarding\nA more detailed view of input processing is shown in Figure 4.5. As just discussed, \nthe input port\u2019s line-termination function and link-layer processing implement the \nphysical and link layers for that individual input link. The lookup performed in the \ninput port is central to the router\u2019s operation\u2014it is here that the router uses the for -\nwarding table to look up the output port to which an arriving packet will be forwarded \nvia the switching fabric. The forwarding table is either computed and updated by the \nrouting processor (using a routing protocol to interact with the routing processors in \nother network routers) or is received from a remote SDN controller. The forwarding \ntable is copied from the routing processor to the line cards over a separate bus (e.g., \na PCI bus) indicated by the dashed line from the routing processor to the input line \ncards in Figure 4.4. With such a shadow copy at each line card, forwarding decisions \ncan be made locally, at each input port, without invoking the centralized routing pro -\ncessor on a per-packet basis and thus avoiding a centralized processing bottleneck.\nLet\u2019s now consider the \u201csimplest\u201d case that the output port to which an incoming \npacket is to be switched is based on the packet\u2019s destination address. In the case of \n32-bit IP addresses, a brute-force implementation of the forwarding table would have \none entry for every possible destination address. Since there are more than 4 billion \npossible addresses, this option is totally out of", "doc_id": "9672ebcb-dfe8-486c-af7a-3a0ff4c5a94f", "embedding": null, "doc_hash": "49e83a8223a55491283fd19140d2a5134c2eed2b77127572745106187749ae55", "extra_info": null, "node_info": {"start": 1000077, "end": 1003975}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "1e576e40-ff8e-439e-a7eb-53a8932d4f64", "3": "ecaa4fae-b4d9-4cc0-8621-3b650661a078"}}, "__type__": "1"}, "ecaa4fae-b4d9-4cc0-8621-3b650661a078": {"__data__": {"text": "a separate bus (e.g., \na PCI bus) indicated by the dashed line from the routing processor to the input line \ncards in Figure 4.4. With such a shadow copy at each line card, forwarding decisions \ncan be made locally, at each input port, without invoking the centralized routing pro -\ncessor on a per-packet basis and thus avoiding a centralized processing bottleneck.\nLet\u2019s now consider the \u201csimplest\u201d case that the output port to which an incoming \npacket is to be switched is based on the packet\u2019s destination address. In the case of \n32-bit IP addresses, a brute-force implementation of the forwarding table would have \none entry for every possible destination address. Since there are more than 4 billion \npossible addresses, this option is totally out of the question.\nLine\nterminationData link\nprocessing\n(protocol,\ndecapsulation)Lookup, fowarding,\nqueuing Switch\nfabric\nFigure 4.5  \u2666 Input port processing\n4.2  \u2022  WHAT\u2019S INSIDE A ROUTER?      345\nAs an example of how this issue of scale can be handled, let\u2019s suppose that our \nrouter has four links, numbered 0 through 3, and that packets are to be forwarded to \nthe link interfaces as follows:\n Destination Address Range Link Interface\n 11001000 00010111 00010000 00000000 \n through 0\n 11001000 00010111 00010111 11111111 \n 11001000 00010111 00011000 00000000 \n through 1\n 11001000 00010111 00011000 11111111 \n 11001000 00010111 00011001 00000000 \n through 2\n 11001000 00010111 00011111 11111111 \n Otherwise 3\nClearly, for this example, it is not necessary to have 4 billion entries in the router\u2019s \nforwarding table. We could, for example, have the following forwarding table with \njust four entries:\n Prefix Link Interface\n 11001000 00010111 00010 0\n 11001000 00010111 00011000 1\n 11001000 00010111 00011 2\n Otherwise 3\nWith this style of forwarding table, the router matches a prefix  of the packet\u2019s des -\ntination address with the entries in the table; if there\u2019s a match, the router forwards \nthe packet to a link associated with the match. For example, suppose the packet\u2019s \ndestination address is 11001000 00010111 00010110 10100001 ; because \nthe 21-bit prefix of this address matches the first entry in the table, the router forwards \nthe packet to link interface 0. If a prefix doesn\u2019t match any of the first three entries, \nthen the router forwards the packet to the default interface 3. Although this sounds \nsimple enough, there\u2019s a very important subtlety here. You may have noticed that it is \npossible for a destination address to match more than one entry. For example, the first \n24 bits of the address 11001000 00010111 00011000 10101010  match the \nsecond entry in the table, and the first 21 bits of the address match the third entry in the \ntable. When there are multiple matches, the router uses the longest prefix matching \nrule; that is, it finds the longest matching entry in the table and forwards the packet to \nthe link interface associated with the longest prefix match. We\u2019ll see exactly why this \n346     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\nlongest prefix-matching rule is used when we study Internet addressing in more detail \nin Section 4.3.\nGiven the existence of a forwarding table, lookup is conceptually simple\u2014 \nhardware logic just searches through the forwarding table looking for the longest \nprefix match. But at Gigabit transmission rates, this lookup must be performed in \nnanoseconds (recall our earlier example of a 10 Gbps link and a 64-byte IP data -\ngram). Thus, not only must lookup be performed in hardware, but techniques beyond \na simple linear search through a large table are needed; surveys of fast lookup algo -\nrithms can be found in [Gupta 2001, Ruiz-Sanchez 2001]. Special attention must \nalso be paid to memory access times, resulting in designs with embedded", "doc_id": "ecaa4fae-b4d9-4cc0-8621-3b650661a078", "embedding": null, "doc_hash": "21f9a7a306562fdf29d819e539f0d07d1ec115a9a71224d9b68157cc1d2fe6f9", "extra_info": null, "node_info": {"start": 1004011, "end": 1007801}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "9672ebcb-dfe8-486c-af7a-3a0ff4c5a94f", "3": "aaf28708-06d6-4be0-b118-e2156134aa9e"}}, "__type__": "1"}, "aaf28708-06d6-4be0-b118-e2156134aa9e": {"__data__": {"text": "DATA PLANE\nlongest prefix-matching rule is used when we study Internet addressing in more detail \nin Section 4.3.\nGiven the existence of a forwarding table, lookup is conceptually simple\u2014 \nhardware logic just searches through the forwarding table looking for the longest \nprefix match. But at Gigabit transmission rates, this lookup must be performed in \nnanoseconds (recall our earlier example of a 10 Gbps link and a 64-byte IP data -\ngram). Thus, not only must lookup be performed in hardware, but techniques beyond \na simple linear search through a large table are needed; surveys of fast lookup algo -\nrithms can be found in [Gupta 2001, Ruiz-Sanchez 2001]. Special attention must \nalso be paid to memory access times, resulting in designs with embedded on-chip \nDRAM and faster SRAM (used as a DRAM cache) memories. In practice, Ternary \nContent Addressable Memories (TCAMs) are also often used for lookup [Yu 2004]. \nWith a TCAM, a 32-bit IP address is presented to the memory, which returns the \ncontent of the forwarding table entry for that address in essentially constant time. \nThe Cisco Catalyst 6500 and 7600 Series routers and switches can hold upwards of \na million TCAM forwarding table entries [Cisco TCAM 2014].\nOnce a packet\u2019s output port has been determined via the lookup, the packet \ncan be sent into the switching fabric. In some designs, a packet may be temporarily \nblocked from entering the switching fabric if packets from other input ports are cur -\nrently using the fabric. A blocked packet will be queued at the input port and then \nscheduled to cross the fabric at a later point in time. We\u2019ll take a closer look at the \nblocking, queuing, and scheduling of packets (at both input ports and output ports) \nshortly. Although \u201clookup\u201d is arguably the most important action in input port pro -\ncessing, many other actions must be taken: (1) physical- and link-layer processing \nmust occur, as discussed previously; (2) the packet\u2019s version number, checksum and \ntime-to-live field\u2014all of which we\u2019ll study in Section 4.3\u2014must be checked and the \nlatter two fields rewritten; and (3) counters used for network management (such as \nthe number of IP datagrams received) must be updated.\nLet\u2019s close our discussion of input port processing by noting that the input port \nsteps of looking up a destination IP address (\u201cmatch\u201d) and then sending the packet \ninto the switching fabric to the specified output port (\u201caction\u201d) is a specific case of a \nmore general \u201cmatch plus action\u201d abstraction that is performed in many networked \ndevices, not just routers. In link-layer switches (covered in Chapter 6) , link-layer \ndestination addresses are looked up and several actions may be taken in addition to \nsending the frame into the switching fabric towards the output port. In firewalls (cov-\nered in Chapter 8 )\u2014devices that filter out selected incoming packets\u2014an incom -\ning packet whose header matches a given criteria (e.g., a combination of source/\ndestination IP addresses and transport-layer port numbers) may be dropped (action). \nIn a network address translator (NAT, covered in Section 4.3), an incoming packet \nwhose transport-layer port number matches a given value will have its port number \nrewritten before forwarding (action). Indeed, the \u201cmatch plus action\u201d abstraction is \nboth powerful and prevalent in network devices today, and is central to the notion of \ngeneralized forwarding that we\u2019ll study in Section 4.4.\n4.2  \u2022  WHAT\u2019S INSIDE A ROUTER?      347\n4.2.2  Switching\nThe switching fabric is at the very heart of a router, as it is through this fabric that \nthe packets are actually switched (that is, forwarded) from an input port to an output \nport. Switching can be accomplished in a number of ways, as shown in Figure", "doc_id": "aaf28708-06d6-4be0-b118-e2156134aa9e", "embedding": null, "doc_hash": "626037e933bab7fa0597be49c6b14967b8907fecb8292e28d7a2b31e2a0afdff", "extra_info": null, "node_info": {"start": 1007797, "end": 1011563}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "ecaa4fae-b4d9-4cc0-8621-3b650661a078", "3": "b0ce2b34-3d08-4b41-ba76-6b5161df15b8"}}, "__type__": "1"}, "b0ce2b34-3d08-4b41-ba76-6b5161df15b8": {"__data__": {"text": "\nIn a network address translator (NAT, covered in Section 4.3), an incoming packet \nwhose transport-layer port number matches a given value will have its port number \nrewritten before forwarding (action). Indeed, the \u201cmatch plus action\u201d abstraction is \nboth powerful and prevalent in network devices today, and is central to the notion of \ngeneralized forwarding that we\u2019ll study in Section 4.4.\n4.2  \u2022  WHAT\u2019S INSIDE A ROUTER?      347\n4.2.2  Switching\nThe switching fabric is at the very heart of a router, as it is through this fabric that \nthe packets are actually switched (that is, forwarded) from an input port to an output \nport. Switching can be accomplished in a number of ways, as shown in Figure 4.6:\n\u2022 Switching via memory.  The simplest, earliest routers were traditional computers, \nwith switching between input and output ports being done under direct control of \nthe CPU (routing processor). Input and output ports functioned as traditional I/O \ndevices in a traditional operating system. An input port with an arriving packet \nfirst signaled the routing processor via an interrupt. The packet was then copied \nfrom the input port into processor memory. The routing processor then extracted \nthe destination address from the header, looked up the appropriate output port \nin the forwarding table, and copied the packet to the output port\u2019s buffers. In \nthis scenario, if the memory bandwidth is such that a maximum of B packets per \nsecond can be written into, or read from, memory, then the overall forwarding \nthroughput (the total rate at which packets are transferred from input ports to out -\nput ports) must be less than B/2. Note also that two packets cannot be forwarded \nMemory\nA\nB\nCX\nY\nZMemory\nKey:\nInput port Output portA\nXY ZB\nCCrossbar\nA\nB\nCX\nY\nZBus\nFigure 4.6  \u2666 Three switching techniques\n348     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\nat the same time, even if they have different destination ports, since only one \nmemory read/write can be done at a time over the shared system bus.\n Some modern routers switch via memory. A major difference from early routers, \nhowever, is that the lookup of the destination address and the storing of the packet \ninto the appropriate memory location are performed by processing on the input line \ncards. In some ways, routers that switch via memory look very much like shared-\nmemory multiprocessors, with the processing on a line card switching (writing) \npackets into the memory of the appropriate output port. Cisco\u2019s Catalyst 8500 \nseries switches [Cisco 8500 2016] internally switches packets via a shared memory.\n\u2022 Switching via a bus.  In this approach, an input port transfers a packet directly to the \noutput port over a shared bus, without intervention by the routing processor. This is \ntypically done by having the input port pre-pend a switch-internal label (header) to \nthe packet indicating the local output port to which this packet is being transferred \nand transmitting the packet onto the bus. All output ports receive the packet, but \nonly the port that matches the label will keep the packet. The label is then removed \nat the output port, as this label is only used within the switch to cross the bus. If mul -\ntiple packets arrive to the router at the same time, each at a different input port, all \nbut one must wait since only one packet can cross the bus at a time. Because every \npacket must cross the single bus, the switching speed of the router is limited to the \nbus speed; in our roundabout analogy, this is as if the roundabout could only contain \none car at a time. Nonetheless, switching via a bus is often sufficient for routers that \noperate in small local area and enterprise networks. The Cisco 6500 router [Cisco \n6500 2016] internally switches packets over a 32-Gbps-backplane bus.\n\u2022 Switching via an interconnection network.  One way to overcome the bandwidth \nlimitation of a single, shared bus is to", "doc_id": "b0ce2b34-3d08-4b41-ba76-6b5161df15b8", "embedding": null, "doc_hash": "0744b73633b187cd375791268b9e1dfe1efb9194abf9bbe7ab22170a3066cc57", "extra_info": null, "node_info": {"start": 1011617, "end": 1015538}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "aaf28708-06d6-4be0-b118-e2156134aa9e", "3": "219762ca-7a5f-484a-90d3-1ca926f93e6b"}}, "__type__": "1"}, "219762ca-7a5f-484a-90d3-1ca926f93e6b": {"__data__": {"text": "this label is only used within the switch to cross the bus. If mul -\ntiple packets arrive to the router at the same time, each at a different input port, all \nbut one must wait since only one packet can cross the bus at a time. Because every \npacket must cross the single bus, the switching speed of the router is limited to the \nbus speed; in our roundabout analogy, this is as if the roundabout could only contain \none car at a time. Nonetheless, switching via a bus is often sufficient for routers that \noperate in small local area and enterprise networks. The Cisco 6500 router [Cisco \n6500 2016] internally switches packets over a 32-Gbps-backplane bus.\n\u2022 Switching via an interconnection network.  One way to overcome the bandwidth \nlimitation of a single, shared bus is to use a more sophisticated interconnection net -\nwork, such as those that have been used in the past to interconnect processors in a \nmultiprocessor computer architecture. A crossbar switch is an interconnection net -\nwork consisting of 2 N buses that connect N input ports to N output ports, as shown \nin Figure 4.6. Each vertical bus intersects each horizontal bus at a crosspoint, \nwhich can be opened or closed at any time by the switch fabric controller (whose \nlogic is part of the switching fabric itself). When a packet arrives from port A and \nneeds to be forwarded to port Y, the switch controller closes the crosspoint at the \nintersection of busses A and Y, and port A then sends the packet onto its bus, which \nis picked up (only) by bus Y. Note that a packet from port B can be forwarded to \nport X at the same time, since the A-to-Y and B-to-X packets use different input \nand output busses. Thus, unlike the previous two switching approaches, cross -\nbar switches are capable of forwarding multiple packets in parallel. A crossbar \nswitch is non-blocking \u2014a packet being forwarded to an output port will not be \nblocked from reaching that output port as long as no other packet is currently being \nforwarded to that output port. However, if two packets from two different input \nports are destined to that same output port, then one will have to wait at the input, \nsince only one packet can be sent over any given bus at a time. Cisco 12000 series \n4.2  \u2022  WHAT\u2019S INSIDE A ROUTER?      349\nswitches [Cisco 12000 2016] use a crossbar switching network; the Cisco 7600 \nseries can be configured to use either a bus or crossbar switch [Cisco 7600 2016].\n More sophisticated interconnection networks use multiple stages of switching \nelements to allow packets from different input ports to proceed towards the same \noutput port at the same time through the multi-stage switching fabric. See [Tobagi \n1990] for a survey of switch architectures. The Cisco CRS employs a three-stage \nnon-blocking switching strategy. A router\u2019s switching capacity can also be scaled \nby running multiple switching fabrics in parallel. In this approach, input ports \nand output ports are connected to N switching fabrics that operate in parallel. An \ninput port breaks a packet into K smaller chunks, and sends (\u201csprays\u201d) the chunks \nthrough K of these N switching fabrics to the selected output port, which reas -\nsembles the K chunks back into the original packet.\n4.2.3  Output Port Processing\nOutput port processing, shown in Figure 4.7, takes packets that have been stored \nin the output port\u2019s memory and transmits them over the output link. This includes \nselecting and de-queueing packets for transmission, and performing the needed link-\nlayer and physical-layer transmission functions.\n4.2.4  Where Does Queuing Occur?\nIf we consider input and output port functionality and the configurations shown  \nin Figure 4.6, it\u2019s clear that packet queues may form at both the input ports and the \noutput ports, just as we identified cases where cars may wait at the inputs and out -\nputs of the traffic intersection in our roundabout", "doc_id": "219762ca-7a5f-484a-90d3-1ca926f93e6b", "embedding": null, "doc_hash": "1e0ff10eccf962463cfcd2775681ab04106d141f84585d5f7e0a9a3371b73d64", "extra_info": null, "node_info": {"start": 1015483, "end": 1019387}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "b0ce2b34-3d08-4b41-ba76-6b5161df15b8", "3": "11b436fd-c937-472d-9d72-cf7e5cb98311"}}, "__type__": "1"}, "11b436fd-c937-472d-9d72-cf7e5cb98311": {"__data__": {"text": "switching fabrics to the selected output port, which reas -\nsembles the K chunks back into the original packet.\n4.2.3  Output Port Processing\nOutput port processing, shown in Figure 4.7, takes packets that have been stored \nin the output port\u2019s memory and transmits them over the output link. This includes \nselecting and de-queueing packets for transmission, and performing the needed link-\nlayer and physical-layer transmission functions.\n4.2.4  Where Does Queuing Occur?\nIf we consider input and output port functionality and the configurations shown  \nin Figure 4.6, it\u2019s clear that packet queues may form at both the input ports and the \noutput ports, just as we identified cases where cars may wait at the inputs and out -\nputs of the traffic intersection in our roundabout analogy. The location and extent of \nqueueing (either at the input port queues or the output port queues) will depend on \nthe traffic load, the relative speed of the switching fabric, and the line speed. Let\u2019s \nnow consider these queues in a bit more detail, since as these queues grow large, the \nrouter\u2019s memory can eventually be exhausted and packet loss  will occur when no \nmemory is available to store arriving packets. Recall that in our earlier  discussions, \nwe said that packets were \u201clost within the network\u201d or \u201cdropped at a router.\u201d It is here, \nat these queues within a router, where such packets are actually dropped and lost.\nLine\nterminationData link\nprocessing\n(protocol,\nencapsulation)Queuing (buf fer\nmanagement) Switch\nfabric\nFigure 4.7  \u2666 Output port processing\n350     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\nSuppose that the input and output line speeds (transmission rates) all have an \nidentical transmission rate of Rline packets per second, and that there are N input ports \nand N output ports. To further simplify the discussion, let\u2019s assume that all packets \nhave the same fixed length, and that packets arrive to input ports in a synchronous \nmanner. That is, the time to send a packet on any link is equal to the time to receive a \npacket on any link, and during such an interval of time, either zero or one packets can \narrive on an input link. Define the switching fabric transfer rate Rswitch as the rate at \nwhich packets can be moved from input port to output port. If Rswitch is N times faster \nthan Rline, then only negligible queuing will occur at the input ports. This is because \neven in the worst case, where all N input lines are receiving packets, and all packets \nare to be forwarded to the same output port, each batch of N packets (one packet per \ninput port) can be cleared through the switch fabric before the next batch arrives.\nInput Queueing\nBut what happens if the switch fabric is not fast enough (relative to the input line \nspeeds) to transfer all arriving packets through the fabric without delay? In this case, \npacket queuing can also occur at the input ports, as packets must join input port \nqueues to wait their turn to be transferred through the switching fabric to the output \nport. To illustrate an important consequence of this queuing, consider a crossbar \nswitching fabric and suppose that (1) all link speeds are identical, (2) that one packet \ncan be transferred from any one input port to a given output port in the same amount \nof time it takes for a packet to be received on an input link, and (3) packets are moved \nfrom a given input queue to their desired output queue in an FCFS manner. Multiple \npackets can be transferred in parallel, as long as their output ports are different. How -\never, if two packets at the front of two input queues are destined for the same output \nqueue, then one of the packets will be blocked and must wait at the input queue\u2014the \nswitching fabric can transfer only one packet to a given output port at a time.\nFigure 4. 8 shows an example in which two packets (darkly shaded) at the front", "doc_id": "11b436fd-c937-472d-9d72-cf7e5cb98311", "embedding": null, "doc_hash": "b26d44b2b6f090becaa65958b56e3b2bf31ff45b4773cd7d0faa3ff886a63e43", "extra_info": null, "node_info": {"start": 1019372, "end": 1023257}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "219762ca-7a5f-484a-90d3-1ca926f93e6b", "3": "22480b80-5645-4fdb-875b-1cdbf1a7e6f8"}}, "__type__": "1"}, "22480b80-5645-4fdb-875b-1cdbf1a7e6f8": {"__data__": {"text": "fabric and suppose that (1) all link speeds are identical, (2) that one packet \ncan be transferred from any one input port to a given output port in the same amount \nof time it takes for a packet to be received on an input link, and (3) packets are moved \nfrom a given input queue to their desired output queue in an FCFS manner. Multiple \npackets can be transferred in parallel, as long as their output ports are different. How -\never, if two packets at the front of two input queues are destined for the same output \nqueue, then one of the packets will be blocked and must wait at the input queue\u2014the \nswitching fabric can transfer only one packet to a given output port at a time.\nFigure 4. 8 shows an example in which two packets (darkly shaded) at the front \nof their input queues are destined for the same upper-right output port. Suppose that \nthe switch fabric chooses to transfer the packet from the front of the upper-left queue. \nIn this case, the darkly shaded packet in the lower-left queue must wait. But not only \nmust this darkly shaded packet wait, so too must the lightly shaded packet that is \nqueued behind that packet in the lower-left queue, even though there is no conten -\ntion for the middle-right output port (the destination for the lightly shaded packet). \nThis phenomenon is known as head-of-the-line (HOL) blocking  in an input-queued \nswitch\u2014a queued packet in an input queue must wait for transfer through the fabric \n(even though its output port is free) because it is blocked by another packet at the \nhead of the line. [Karol 1987] shows that due to HOL blocking, the input queue will \ngrow to unbounded length (informally, this is equivalent to saying that significant \npacket loss will occur) under certain assumptions as soon as the packet arrival rate \non the input links reaches only 58 percent of their capacity. A number of solutions to \nHOL blocking are discussed in [McKeown 1997].\n4.2  \u2022  WHAT\u2019S INSIDE A ROUTER?      351\nOutput Queueing\nLet\u2019s next consider whether queueing can occur at a switch\u2019s output ports. Suppose \nthat Rswitch is again N times faster than Rline and that packets arriving at each of the N \ninput ports are destined to the same output port. In this case, in the time it takes to send a  \nsingle packet onto the outgoing link, N new packets will arrive at this output port \n(one from each of the N input ports). Since the output port can transmit only a single \npacket in a unit of time (the packet transmission time), the N arriving packets will \nhave to queue (wait) for transmission over the outgoing link. Then N more packets \ncan possibly arrive in the time it takes to transmit just one of the N packets that had \njust previously been queued. And so on. Thus, packet queues can form at the output \nports even when the switching fabric is N times faster than the port line speeds. \nEventually, the number of queued packets can grow large enough to exhaust avail -\nable memory at the output port.Switch\nfabricOutput port contention at time t\u2014\none dark packet can be transferred\nLight blue packet experiences HOL blocking\nSwitch\nfabric\nKey:\ndestined for upper output \nportdestined for middle output \nportdestined for lower output \nport\nFigure 4.8  \u2666 HOL blocking at and input-queued switch\n352     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\nWhen there is not enough memory to buffer an incoming packet, a decision must \nbe made to either drop the arriving packet (a policy known as drop-tail ) or remove \none or more already-queued packets to make room for the newly arrived packet. In \nsome cases, it may be advantageous to drop (or mark the header of) a packet before  \nthe buffer is full in order to provide a congestion signal to the sender. A number of \nproactive packet-dropping and -marking policies (which collectively have become", "doc_id": "22480b80-5645-4fdb-875b-1cdbf1a7e6f8", "embedding": null, "doc_hash": "3890010a8dbfe83fd1ec8499cabbd41f4ac282c5e4cc7f1ed04cc261531366a8", "extra_info": null, "node_info": {"start": 1023296, "end": 1027108}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "11b436fd-c937-472d-9d72-cf7e5cb98311", "3": "115b6a8d-ac5e-4d72-bdb2-1d3890429963"}}, "__type__": "1"}, "115b6a8d-ac5e-4d72-bdb2-1d3890429963": {"__data__": {"text": "for upper output \nportdestined for middle output \nportdestined for lower output \nport\nFigure 4.8  \u2666 HOL blocking at and input-queued switch\n352     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\nWhen there is not enough memory to buffer an incoming packet, a decision must \nbe made to either drop the arriving packet (a policy known as drop-tail ) or remove \none or more already-queued packets to make room for the newly arrived packet. In \nsome cases, it may be advantageous to drop (or mark the header of) a packet before  \nthe buffer is full in order to provide a congestion signal to the sender. A number of \nproactive packet-dropping and -marking policies (which collectively have become \nknown as active queue management (AQM)  algorithms) have been proposed and \nanalyzed [Labrador 1999, Hollot 2002]. One of the most widely studied and imple -\nmented AQM algorithms is the Random Early Detection (RED)  algorithm [Chris -\ntiansen 2001; Floyd 2016].\nOutput port queuing is illustrated in Figure 4.9. At time t, a packet has arrived \nat each of the incoming input ports, each destined for the uppermost outgoing port. \nAssuming identical line speeds and a switch operating at three times the line speed, one \ntime unit later (that is, in the time needed to receive or send a packet), all three original \npackets have been transferred to the outgoing port and are queued awaiting transmis -\nsion. In the next time unit, one of these three packets will have been transmitted over the \noutgoing link. In our example, two new packets have arrived at the incoming side of the \nswitch; one of these packets is destined for this uppermost output port. A consequence Switch\nfabricOutput port contention at time t\nOne packet time later\nSwitch\nfabric\nFigure 4.9  \u2666 Output port queueing\n4.2  \u2022  WHAT\u2019S INSIDE A ROUTER?      353\nof such queuing is that a packet scheduler  at the output port must choose one packet, \namong those queued, for transmission\u2014a topic we\u2019ll cover in the following section.\nGiven that router buffers are needed to absorb the fluctuations in traffic load, a \nnatural question to ask is how much  buffering is required. For many years, the rule of \nthumb [RFC 3439] for buffer sizing was that the amount of buffering (B) should be \nequal to an average round-trip time ( RTT, say 250 msec) times the link capacity (C). \nThis result is based on an analysis of the queueing dynamics of a relatively small num -\nber of TCP flows [Villamizar 1994]. Thus, a 10 Gbps link with an RTT of 250 msec \nwould need an amount of buffering equal to B 5 RTT  \u00b7 C 5 2.5 Gbits of buffers. More \nrecent theoretical and experimental efforts [Appenzeller 2004], however, suggest that \nwhen there are a large number of TCP flows ( N) passing through a link, the amount of \nbuffering needed is B=RTI#C>1N. With a large number of flows typically pass -\ning through large backbone router links (see, e.g., [Fraleigh 2003]), the value of N can \nbe large, with the decrease in needed buffer size becoming quite significant. [Appen -\nzeller 2004; Wischik 2005; Beheshti 2008] provide very readable discussions of the \nbuffer-sizing problem from a theoretical, implementation, and operational standpoint.\n4.2.5  Packet Scheduling\nLet\u2019s now return to the question of determining the order in which queued packets are \ntransmitted over an outgoing link. Since you yourself have undoubtedly had to wait in \nlong lines on many occasions and observed how waiting customers are served, you\u2019re \nno doubt familiar with many of the queueing disciplines commonly used in routers. \nThere is first-come-first-served (FCFS, also known as first-in-first-out, FIFO). The \nBritish are famous", "doc_id": "115b6a8d-ac5e-4d72-bdb2-1d3890429963", "embedding": null, "doc_hash": "5d6b7b36379da61c93ca06350e7def33cd044e3158281a9b72070108971d09d8", "extra_info": null, "node_info": {"start": 1027157, "end": 1030820}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "22480b80-5645-4fdb-875b-1cdbf1a7e6f8", "3": "f6870ec9-720c-437d-95db-1142d778d376"}}, "__type__": "1"}, "f6870ec9-720c-437d-95db-1142d778d376": {"__data__": {"text": "\nbe large, with the decrease in needed buffer size becoming quite significant. [Appen -\nzeller 2004; Wischik 2005; Beheshti 2008] provide very readable discussions of the \nbuffer-sizing problem from a theoretical, implementation, and operational standpoint.\n4.2.5  Packet Scheduling\nLet\u2019s now return to the question of determining the order in which queued packets are \ntransmitted over an outgoing link. Since you yourself have undoubtedly had to wait in \nlong lines on many occasions and observed how waiting customers are served, you\u2019re \nno doubt familiar with many of the queueing disciplines commonly used in routers. \nThere is first-come-first-served (FCFS, also known as first-in-first-out, FIFO). The \nBritish are famous for patient and orderly FCFS queueing at bus stops and in the mar -\nketplace (\u201cOh, are you queueing?\u201d). Other countries operate on a priority basis, with \none class of waiting customers given priority service over other waiting customers. \nThere is also round-robin queueing, where customers are again divided into classes \n(as in priority queueing) but each class of customer is given service in turn.\nFirst-in-First-Out (FIFO)\nFigure 4. 10 shows the queuing model abstraction for the FIFO link-scheduling dis -\ncipline. Packets arriving at the link output queue wait for transmission if the link is \ncurrently busy transmitting another packet. If there is not sufficient buffering space \nto hold the arriving packet, the queue\u2019s packet-discarding policy then determines \nwhether the packet will be dropped (lost) or whether other packets will be removed \nfrom the queue to make space for the arriving packet, as discussed above. In our  \ndiscussion below, we\u2019ll ignore packet discard. When a packet is completely transmit -\nted over the outgoing link (that is, receives service) it is removed from the queue.\nThe FIFO (also known as first-come-first-served, or FCFS) scheduling discipline \nselects packets for link transmission in the same order in which they arrived at the \noutput link queue. We\u2019re all familiar with FIFO queuing from service centers, where \n354     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\narriving customers join the back of the single waiting line, remain in order, and are \nthen served when they reach the front of the line. Figure 4.11 shows the FIFO queue in \noperation. Packet arrivals are indicated by numbered arrows above the upper timeline, \nwith the number indicating the order in which the packet arrived. Individual packet \ndepartures are shown below the lower timeline. The time that a packet spends in service \n(being transmitted) is indicated by the shaded rectangle between the two timelines. In \nour examples here, let\u2019s assume that each packet takes three units of time to be transmit -\nted. Under the FIFO discipline, packets leave in the same order in which they arrived. \nNote that after the departure of packet 4, the link remains idle (since packets 1 through \n4 have been transmitted and removed from the queue) until the arrival of packet 5.\nPriority Queuing\nUnder priority queuing, packets arriving at the output link are classified into prior -\nity classes upon arrival at the queue, as shown in Figure 4.12. In practice, a net -\nwork operator may configure a queue so that packets carrying network management \ninformation (e.g., as indicated by the source or destination TCP/UDP port number) \nreceive priority over user traffic; additionally, real-time voice-over-IP packets might \nreceive priority over non-real traffic such as SMTP or IMAP e-mail packets. Each ArrivalsDeparturesQueue\n(waiting area)\nLink\n(server)\nFigure 4.10  \u2666 FIFO queueing abstraction\nTimeArrivals\nDeparturesPacket\nin service\nTime1\n1 2 3 4 52 3\n1t = 0 t", "doc_id": "f6870ec9-720c-437d-95db-1142d778d376", "embedding": null, "doc_hash": "029fc6084176d0dea953dd6206bc758ad22a17a75ffd49cfbb3c04aaf4e69241", "extra_info": null, "node_info": {"start": 1030769, "end": 1034480}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "115b6a8d-ac5e-4d72-bdb2-1d3890429963", "3": "11516d1a-cd40-4b79-aed8-9e36a487984b"}}, "__type__": "1"}, "11516d1a-cd40-4b79-aed8-9e36a487984b": {"__data__": {"text": "Queuing\nUnder priority queuing, packets arriving at the output link are classified into prior -\nity classes upon arrival at the queue, as shown in Figure 4.12. In practice, a net -\nwork operator may configure a queue so that packets carrying network management \ninformation (e.g., as indicated by the source or destination TCP/UDP port number) \nreceive priority over user traffic; additionally, real-time voice-over-IP packets might \nreceive priority over non-real traffic such as SMTP or IMAP e-mail packets. Each ArrivalsDeparturesQueue\n(waiting area)\nLink\n(server)\nFigure 4.10  \u2666 FIFO queueing abstraction\nTimeArrivals\nDeparturesPacket\nin service\nTime1\n1 2 3 4 52 3\n1t = 0 t = 2 t = 4 t = 6 t = 8 t = 10 t = 12 t = 14\n2 3 4 54 5\nFigure 4.11  \u2666 The FIFO queue in operation\n4.2  \u2022  WHAT\u2019S INSIDE A ROUTER?      355\npriority class typically has its own queue. When choosing a packet to transmit, the \npriority queuing discipline will transmit a packet from the highest priority class that \nhas a nonempty queue (that is, has packets waiting for transmission). The choice \namong packets in the same priority class is typically done in a FIFO manner.\nFigure 4. 13 illustrates the operation of a priority queue with two priority classes. \nPackets 1, 3, and 4 belong to the high-priority class, and packets 2 and 5 belong to \nthe low-priority class. Packet 1 arrives and, finding the link idle, begins transmission. \nDuring the transmission of packet 1, packets 2 and 3 arrive and are queued in the low- \nand high-priority queues, respectively. After the transmission of packet 1, packet 3 (a \nhigh-priority packet) is selected for transmission over packet 2 (which, even though \nit arrived earlier, is a low-priority packet). At the end of the transmission of packet \n3, packet 2 then begins transmission. Packet 4 (a high-priority packet) arrives during \nthe transmission of packet 2 (a low-priority packet). Under a non-preemptive pri -\nority queuing  discipline, the transmission of a packet is not interrupted once it has Arrivals Departures\nLow-priority queue\n(waiting area)ClassifyHigh-priority queue\n(waiting area)\nLink\n(server)\nFigure 4.12  \u2666 The priority queueing model\nArrivals\nDeparturesPacket\nin service1\n1 2 3 452 3\n145\nTime\nTime\nt = 0 t = 2 t = 4 t = 6 t = 8 t = 10 t = 12 t = 14\n2 3 4 5\nFigure 4.13  \u2666 The priority queue in operation\n356     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\nbegun. In this case, packet 4 queues for transmission and begins being transmitted \nafter the transmission of packet 2 is completed.\nRound Robin and Weighted Fair Queuing (WFQ)\nUnder the round robin queuing discipline, packets are sorted into classes as with \npriority queuing. However, rather than there being a strict service priority among \nclasses, a round robin scheduler alternates service among the classes. In the simplest \nform of round robin scheduling, a class 1 packet is transmitted, followed by a class \n2 packet, followed by a class 1 packet, followed by a class 2 packet, and so on. A \nso-called work-conserving queuing  discipline will never allow the link to remain \nidle whenever there are packets (of any class) queued for transmission. A work-\nconserving round robin discipline that looks for a packet of a given class but finds \nnone will immediately check the next class in the round robin sequence.\nFigure 4. 14 illustrates the operation of a two-class round robin queue. In this \nexample, packets 1, 2, and 4 belong to class 1, and packets 3 and 5 belong to the \nsecond class. Packet 1 begins", "doc_id": "11516d1a-cd40-4b79-aed8-9e36a487984b", "embedding": null, "doc_hash": "a3236519020e6c5f4e89f97a8a05edfaef21751583dc04fcee1631b157c6dc4c", "extra_info": null, "node_info": {"start": 1034521, "end": 1038039}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "f6870ec9-720c-437d-95db-1142d778d376", "3": "5da56061-7054-4b2c-809a-a73c3297a218"}}, "__type__": "1"}, "5da56061-7054-4b2c-809a-a73c3297a218": {"__data__": {"text": "the classes. In the simplest \nform of round robin scheduling, a class 1 packet is transmitted, followed by a class \n2 packet, followed by a class 1 packet, followed by a class 2 packet, and so on. A \nso-called work-conserving queuing  discipline will never allow the link to remain \nidle whenever there are packets (of any class) queued for transmission. A work-\nconserving round robin discipline that looks for a packet of a given class but finds \nnone will immediately check the next class in the round robin sequence.\nFigure 4. 14 illustrates the operation of a two-class round robin queue. In this \nexample, packets 1, 2, and 4 belong to class 1, and packets 3 and 5 belong to the \nsecond class. Packet 1 begins transmission immediately upon arrival at the output \nqueue. Packets 2 and 3 arrive during the transmission of packet 1 and thus queue for \ntransmission. After the transmission of packet 1, the link scheduler looks for a class 2 \npacket and thus transmits packet 3. After the transmission of packet 3, the scheduler \nlooks for a class 1 packet and thus transmits packet 2. After the transmission of packet \n2, packet 4 is the only queued packet; it is thus transmitted immediately after packet 2.\nA generalized form of round robin queuing that has been widely implemented \nin routers is the so-called weighted fair queuing (WFQ) discipline  [Demers 1990; \nParekh 1993; Cisco QoS 2016]. WFQ is illustrated in Figure 4.15. Here, arriving \npackets are classified and queued in the appropriate per-class waiting area. As in \nround robin scheduling, a WFQ scheduler will serve classes in a circular manner\u2014\nfirst serving class 1, then serving class 2, then serving class 3, and then (assuming \nthere are three classes) repeating the service pattern. WFQ is also a work-conserving Arrivals\nPacket\nin service1\n1 2 3 452 3\n1 2 3 4 545\nDeparturesTime\nTime\nt = 0 t = 2 t = 4 t = 6 t = 8 t = 10 t = 12 t = 14\nFigure 4.14  \u2666 The two-class robin queue in operation\n4.3  \u2022  THE INTERNET PROTOCOL (IP): IPV4, ADDRESSING, IPV6, AND MORE      357\nqueuing discipline and thus will immediately move on to the next class in the service \nsequence when it finds an empty class queue.\nWFQ differs from round robin in that each class may receive a differential amount \nof service in any interval of time. Specifically, each class, i, is assigned a weight, wi. \nUnder WFQ, during any interval of time during which there are class i packets to send, \nclass i will then be guaranteed to receive a fraction of service equal to wi >(gwj), where \nthe sum in the denominator is taken over all classes that also have packets queued for \ntransmission. In the worst case, even if all classes have queued packets, class i will still \nbe guaranteed to receive a fraction wi >(gwj) of the bandwidth, where in this worst \ncase the sum in the denominator is over all classes. Thus, for a link with transmission \nrate R, class i will always achieve a throughput of at least R \u00b7 wi >(gwj). Our descrip -\ntion of WFQ has been idealized, as we have not considered the fact that packets are \ndiscrete and a packet\u2019s transmission will not be interrupted to begin transmission of \nanother packet; [Demers 1990; Parekh 1993] discuss this packetization issue.\n4.3 The Internet Protocol (IP): IPv4, Addressing, \nIPv6, and More\nOur study of the network layer thus far in Chapter 4\u2014the notion of the data and con -\ntrol plane component of the network layer, our distinction between forwarding and \nrouting, the identification of various network service models, and our look inside a \nrouter\u2014have often been without reference to any specific computer network archi -\ntecture or protocol. In this section", "doc_id": "5da56061-7054-4b2c-809a-a73c3297a218", "embedding": null, "doc_hash": "7b9d6e2b30de9297e6d37e1021ac29be95d610df1cbe8fbaa71dd0b91ebb4d2a", "extra_info": null, "node_info": {"start": 1038034, "end": 1041700}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "11516d1a-cd40-4b79-aed8-9e36a487984b", "3": "76ba1bd9-2a17-4903-b90f-b17e28c7030c"}}, "__type__": "1"}, "76ba1bd9-2a17-4903-b90f-b17e28c7030c": {"__data__": {"text": "always achieve a throughput of at least R \u00b7 wi >(gwj). Our descrip -\ntion of WFQ has been idealized, as we have not considered the fact that packets are \ndiscrete and a packet\u2019s transmission will not be interrupted to begin transmission of \nanother packet; [Demers 1990; Parekh 1993] discuss this packetization issue.\n4.3 The Internet Protocol (IP): IPv4, Addressing, \nIPv6, and More\nOur study of the network layer thus far in Chapter 4\u2014the notion of the data and con -\ntrol plane component of the network layer, our distinction between forwarding and \nrouting, the identification of various network service models, and our look inside a \nrouter\u2014have often been without reference to any specific computer network archi -\ntecture or protocol. In this section we\u2019ll focus on key aspects of the network layer on \ntoday\u2019s Internet and the celebrated Internet Protocol (IP).\nThere are two versions of IP in use today. We\u2019ll first examine the widely \ndeployed IP protocol version 4, which is usually referred to simply as IPv4 [RFC Classify\nArrivals Departuresw1\nw2\nw3Link\nFigure 4.15  \u2666 Weighted fair queueing\n358     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\n791] in Section 4.3.1. We\u2019ll examine IP version 6 [RFC 2460; RFC 4291], which has \nbeen proposed to replace IPv4, in Section 4.3.5. In between, we\u2019ll primarily cover \nInternet addressing\u2014a topic that might seem rather dry and detail-oriented but we\u2019ll \nsee is crucial to understanding how the Internet\u2019s network layer works. To master IP \naddressing is to master the Internet\u2019s network layer itself!\n4.3.1  IPv4 Datagram Format\nRecall that the Internet\u2019s network-layer packet is referred to as a datagram . We begin \nour study of IP with an overview of the syntax and semantics of the IPv4 datagram. \nYou might be thinking that nothing could be drier than the syntax and semantics of a \npacket\u2019s bits. Nevertheless, the datagram plays a central role in the Internet\u2014every \nnetworking student and professional needs to see it, absorb it, and master it. (And \njust to see that protocol headers can indeed be fun to study, check out [Pomeranz \n2010]). The IPv4 datagram format is shown in Figure 4.16. The key fields in the IPv4 \ndatagram are the following:\n\u2022 Version number.  These 4 bits specify the IP protocol version of the datagram. \nBy looking at the version number, the router can determine how to interpret the \nremainder of the IP datagram. Different versions of IP use different datagram \nformats. The datagram format for IPv4 is shown in Figure 4.16. The datagram \nformat for the new version of IP (IPv6) is discussed in Section 4.3.5.Version Type of serviceHeader\nlength\nUpper-layer\nprotocol16-bit Identi \ufb01er\nTime-to-live13-bit Fragmentation of fset FlagsDatagram length (bytes)\nHeader checksum32 bits\n32-bit Source IP address\n32-bit Destination IP address\nOptions (if any)\nData\nFigure 4.16  \u2666 IPv4 datagram format\n4.3  \u2022  THE INTERNET PROTOCOL (IP): IPV4, ADDRESSING, IPV6, AND MORE      359\n\u2022 Header length.  Because an IPv4 datagram can contain a variable number of \noptions (which are included in the IPv4 datagram header), these 4 bits are needed \nto determine where in the IP datagram the payload (e.g., the transport-layer seg -\nment being encapsulated in this datagram) actually begins. Most IP datagrams do \nnot contain options, so the typical IP datagram has a 20-byte header.\n\u2022 Type of service.  The type of service (TOS) bits were included in the IPv4 header \nto allow different types of IP datagrams to be distinguished from each other. For \nexample, it might be useful", "doc_id": "76ba1bd9-2a17-4903-b90f-b17e28c7030c", "embedding": null, "doc_hash": "07c46d8c85ea769cacdc40394eb3237835a2581bbf700fe7341c75599445c242", "extra_info": null, "node_info": {"start": 1041653, "end": 1045205}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "5da56061-7054-4b2c-809a-a73c3297a218", "3": "bd4074ed-1670-4ce5-8d2b-ec5452240c98"}}, "__type__": "1"}, "bd4074ed-1670-4ce5-8d2b-ec5452240c98": {"__data__": {"text": "format\n4.3  \u2022  THE INTERNET PROTOCOL (IP): IPV4, ADDRESSING, IPV6, AND MORE      359\n\u2022 Header length.  Because an IPv4 datagram can contain a variable number of \noptions (which are included in the IPv4 datagram header), these 4 bits are needed \nto determine where in the IP datagram the payload (e.g., the transport-layer seg -\nment being encapsulated in this datagram) actually begins. Most IP datagrams do \nnot contain options, so the typical IP datagram has a 20-byte header.\n\u2022 Type of service.  The type of service (TOS) bits were included in the IPv4 header \nto allow different types of IP datagrams to be distinguished from each other. For \nexample, it might be useful to distinguish real-time datagrams (such as those used \nby an IP telephony application) from non-real-time traffic (for example, FTP). The \nspecific level of service to be provided is a policy issue determined and config -\nured by the network administrator for that router. We also learned in Section 3.7.2 \nthat two of the TOS bits are used for Explicit Congestion  Notification.\n\u2022 Datagram length.  This is the total length of the IP datagram (header plus data), \nmeasured in bytes. Since this field is 16 bits long, the theoretical maximum size of \nthe IP datagram is 65,535 bytes. However, datagrams are rarely larger than 1,500 \nbytes, which allows an IP datagram to fit in the payload field of a maximally sized \nEthernet frame.\n\u2022 Identifier, flags, fragmentation offset.  These three fields have to do with so-called \nIP fragmentation, a topic we will consider shortly. Interestingly, the new version \nof IP, IPv6, does not allow for fragmentation.\n\u2022 Time-to-live.  The time-to-live (TTL) field is included to ensure that datagrams \ndo not circulate forever (due to, for example, a long-lived routing loop) in the \nnetwork. This field is decremented by one each time the datagram is processed by \na router. If the TTL field reaches 0, a router must drop that datagram.\n\u2022 Protocol.  This field is typically used only when an IP datagram reaches its final \ndestination. The value of this field indicates the specific transport-layer protocol \nto which the data portion of this IP datagram should be passed. For example, a \nvalue of 6 indicates that the data portion is passed to TCP, while a value of 17 indi -\ncates that the data is passed to UDP. For a list of all possible values, see [IANA \nProtocol Numbers 2016]. Note that the protocol number in the IP datagram has \na role that is analogous to the role of the port number field in the transport-layer \nsegment. The protocol number is the glue that binds the network and transport \nlayers together, whereas the port number is the glue that binds the transport and \napplication layers together. We\u2019ll see in Chapter 6 that the link-layer frame also \nhas a special field that binds the link layer to the network layer.\n\u2022 Header checksum.  The header checksum aids a router in detecting bit errors in \na received IP datagram. The header checksum is computed by treating each 2 \nbytes in the header as a number and summing these numbers using 1s complement \narithmetic. As discussed in Section 3.3, the 1s complement of this sum, known \nas the Internet checksum, is stored in the checksum field. A router computes the \nheader checksum for each received IP datagram and detects an error condition if \n360     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\nthe checksum carried in the datagram header does not equal the computed check -\nsum. Routers typically discard datagrams for which an error has been detected. \nNote that the checksum must be recomputed and stored again at each router, since \nthe TTL field, and possibly the options field as well, will change. An interesting \ndiscussion of fast algorithms for computing the Internet", "doc_id": "bd4074ed-1670-4ce5-8d2b-ec5452240c98", "embedding": null, "doc_hash": "7c41405027c0587c4bebf1d5036034654e89e00f7847ef357b77ec6c099ced59", "extra_info": null, "node_info": {"start": 1045288, "end": 1049057}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "76ba1bd9-2a17-4903-b90f-b17e28c7030c", "3": "9612aa85-3bf6-4dda-abcb-7702e75b17cf"}}, "__type__": "1"}, "9612aa85-3bf6-4dda-abcb-7702e75b17cf": {"__data__": {"text": "in the header as a number and summing these numbers using 1s complement \narithmetic. As discussed in Section 3.3, the 1s complement of this sum, known \nas the Internet checksum, is stored in the checksum field. A router computes the \nheader checksum for each received IP datagram and detects an error condition if \n360     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\nthe checksum carried in the datagram header does not equal the computed check -\nsum. Routers typically discard datagrams for which an error has been detected. \nNote that the checksum must be recomputed and stored again at each router, since \nthe TTL field, and possibly the options field as well, will change. An interesting \ndiscussion of fast algorithms for computing the Internet checksum is [RFC 1071]. \nA question often asked at this point is, why does TCP/IP perform error checking at \nboth the transport and network layers? There are several reasons for this repetition. \nFirst, note that only the IP header is checksummed at the IP layer, while the TCP/\nUDP checksum is computed over the entire TCP/UDP segment. Second, TCP/\nUDP and IP do not necessarily both have to belong to the same protocol stack. \nTCP can, in principle, run over a different network-layer protocol (for example, \nATM) [Black 1995]) and IP can carry data that will not be passed to TCP/UDP.\n\u2022 Source and destination IP addresses.  When a source creates a datagram, it inserts \nits IP address into the source IP address field and inserts the address of the ulti -\nmate destination into the destination IP address field. Often the source host deter -\nmines the destination address via a DNS lookup, as discussed in Chapter 2. We\u2019ll \ndiscuss IP addressing in detail in Section 4.3.3.\n\u2022 Options.  The options fields allow an IP header to be extended. Header options \nwere meant to be used rarely\u2014hence the decision to save overhead by not includ -\ning the information in options fields in every datagram header. However, the \nmere existence of options does complicate matters\u2014since datagram headers can \nbe of variable length, one cannot determine a priori where the data field will start. \nAlso, since some datagrams may require options processing and others may not, \nthe amount of time needed to process an IP datagram at a router can vary greatly. \nThese considerations become particularly important for IP processing in high-\nperformance routers and hosts. For these reasons and others, IP options were not \nincluded in the IPv6 header, as discussed in Section 4.3.5.\n\u2022 Data (payload).  Finally, we come to the last and most important field\u2014the raison \nd\u2019etre  for the datagram in the first place! In most circumstances, the data field of \nthe IP datagram contains the transport-layer segment (TCP or UDP) to be deliv -\nered to the destination. However, the data field can carry other types of data, such \nas ICMP messages (discussed in Section 5.6).\nNote that an IP datagram has a total of 20 bytes of header (assuming no options). \nIf the datagram carries a TCP segment, then each (non-fragmented) datagram carries \na total of 40 bytes of header (20 bytes of IP header plus 20 bytes of TCP header) \nalong with the application-layer message.\n4.3.2  IPv4 Datagram Fragmentation\nWe\u2019ll see in Chapter 6 that not all link-layer protocols can carry network-layer \npackets of the same size. Some protocols can carry big datagrams, whereas other \n4.3  \u2022  THE INTERNET PROTOCOL (IP): IPV4, ADDRESSING, IPV6, AND MORE      361\n protocols can carry only little datagrams. For example, Ethernet frames can carry up to \n1,500 bytes of data, whereas frames for some wide-area links can carry no more than \n576 bytes. The maximum amount of data that a link-layer frame can carry is called \nthe maximum transmission unit (MTU)", "doc_id": "9612aa85-3bf6-4dda-abcb-7702e75b17cf", "embedding": null, "doc_hash": "6cce3eb53672bf7ba51c34cdec6740f954a2ad8ef067314d3c85c6d2ab11a461", "extra_info": null, "node_info": {"start": 1048989, "end": 1052752}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "bd4074ed-1670-4ce5-8d2b-ec5452240c98", "3": "8cceb003-3862-4c3b-b211-1d4347328ed6"}}, "__type__": "1"}, "8cceb003-3862-4c3b-b211-1d4347328ed6": {"__data__": {"text": "total of 40 bytes of header (20 bytes of IP header plus 20 bytes of TCP header) \nalong with the application-layer message.\n4.3.2  IPv4 Datagram Fragmentation\nWe\u2019ll see in Chapter 6 that not all link-layer protocols can carry network-layer \npackets of the same size. Some protocols can carry big datagrams, whereas other \n4.3  \u2022  THE INTERNET PROTOCOL (IP): IPV4, ADDRESSING, IPV6, AND MORE      361\n protocols can carry only little datagrams. For example, Ethernet frames can carry up to \n1,500 bytes of data, whereas frames for some wide-area links can carry no more than \n576 bytes. The maximum amount of data that a link-layer frame can carry is called \nthe maximum transmission unit (MTU) . Because each IP datagram is encapsulated \nwithin the link-layer frame for transport from one router to the next router, the MTU \nof the link-layer protocol places a hard limit on the length of an IP datagram. Having \na hard limit on the size of an IP datagram is not much of a problem. What is a prob -\nlem is that each of the links along the route between sender and destination can use \ndifferent link-layer protocols, and each of these protocols can have different MTUs.\nTo understand the forwarding issue better, imagine that you are a router that inter -\nconnects several links, each running different link-layer protocols with different MTUs. \nSuppose you receive an IP datagram from one link. You check your forwarding table to \ndetermine the outgoing link, and this outgoing link has an MTU that is smaller than the \nlength of the IP datagram. Time to panic\u2014how are you going to squeeze this oversized \nIP datagram into the payload field of the link-layer frame? The solution is to fragment \nthe payload in the IP datagram into two or more smaller IP datagrams, encapsulate each \nof these smaller IP datagrams in a separate link-layer frame; and send these frames over \nthe outgoing link. Each of these smaller datagrams is referred to as a fragment .\nFragments need to be reassembled before they reach the transport layer at the \ndestination. Indeed, both TCP and UDP are expecting to receive complete, unfrag -\nmented segments from the network layer. The designers of IPv4 felt that reassem -\nbling datagrams in the routers would introduce significant complication into the \nprotocol and put a damper on router performance. (If you were a router, would you \nwant to be reassembling fragments on top of everything else you had to do?) Sticking \nto the principle of keeping the network core simple, the designers of IPv4 decided to \nput the job of datagram reassembly in the end systems rather than in network routers.\nWhen a destination host receives a series of datagrams from the same source, it \nneeds to determine whether any of these datagrams are fragments of some original, \nlarger datagram. If some datagrams are fragments, it must further determine when \nit has received the last fragment and how the fragments it has received should be \npieced back together to form the original datagram. To allow the destination host \nto perform these reassembly tasks, the designers of IP (version 4) put identification, \nflag, and fragmentation offset  fields in the IP datagram header. When a datagram is \ncreated, the sending host stamps the datagram with an identification number as well \nas source and destination addresses. Typically, the sending host increments the iden -\ntification number for each datagram it sends. When a router needs to fragment a data -\ngram, each resulting datagram (that is, fragment) is stamped with the source address, \ndestination address, and identification number of the original datagram. When the \ndestination receives a series of datagrams from the same sending host, it can examine \nthe identification numbers of the datagrams to determine which of the datagrams are \nactually fragments of the same larger datagram. Because IP is an unreliable service, \none or more of the fragments", "doc_id": "8cceb003-3862-4c3b-b211-1d4347328ed6", "embedding": null, "doc_hash": "2fbce9fe9da2e9a2e87160342401bf87fa6c0d87b6a8aebbd4c6efdc07df2f05", "extra_info": null, "node_info": {"start": 1052805, "end": 1056728}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "9612aa85-3bf6-4dda-abcb-7702e75b17cf", "3": "20e90c1f-df2d-4b82-b2e4-2467fe9cfbaa"}}, "__type__": "1"}, "20e90c1f-df2d-4b82-b2e4-2467fe9cfbaa": {"__data__": {"text": "and fragmentation offset  fields in the IP datagram header. When a datagram is \ncreated, the sending host stamps the datagram with an identification number as well \nas source and destination addresses. Typically, the sending host increments the iden -\ntification number for each datagram it sends. When a router needs to fragment a data -\ngram, each resulting datagram (that is, fragment) is stamped with the source address, \ndestination address, and identification number of the original datagram. When the \ndestination receives a series of datagrams from the same sending host, it can examine \nthe identification numbers of the datagrams to determine which of the datagrams are \nactually fragments of the same larger datagram. Because IP is an unreliable service, \none or more of the fragments may never arrive at the destination. For this reason, in \norder for the destination host to be absolutely sure it has received the last fragment of \n362     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\nthe original datagram, the last fragment has a flag bit set to 0, whereas all the other \nfragments have this flag bit set to 1. Also, in order for the destination host to deter -\nmine whether a fragment is missing (and also to be able to reassemble the fragments \nin their proper order), the offset field is used to specify where the fragment fits within \nthe original IP datagram.\nFigure 4. 17 illustrates an example. A datagram of 4,000 bytes (20 bytes of IP \nheader plus 3,980 bytes of IP payload) arrives at a router and must be forwarded \nto a link with an MTU of 1,500 bytes. This implies that the 3,980 data bytes in the \noriginal datagram must be allocated to three separate fragments (each of which is \nalso an IP datagram). \nThe online material for this book, and the problems at the end of this chapter will \nallow you to explore fragmentation in more detail. Also, on this book\u2019s Web site, we \nprovide a Java applet that generates fragments. You provide the incoming datagram \nsize, the MTU, and the incoming datagram identification. The applet automatically \ngenerates the fragments for you. See http://www.pearsonglobaleditions.com/kurose.\n4.3.3  IPv4 Addressing\nWe now turn our attention to IPv4 addressing. Although you may be thinking that \naddressing must be a straightforward topic, hopefully by the end of this section you\u2019ll Fragmentation:\nIn: one large datagram (4,000 bytes)\nOut: 3 smaller datagrams\nReassembly:\nIn: 3 smaller datagrams\nOut: one large datagram (4,000 bytes)Link MTU: 1,500 bytes\nFigure 4.17  \u2666 IP fragmentation and reassembly\n4.3  \u2022  THE INTERNET PROTOCOL (IP): IPV4, ADDRESSING, IPV6, AND MORE      363\nbe convinced that Internet addressing is not only a juicy, subtle, and interesting topic \nbut also one that is of central importance to the Internet. An excellent treatment of \nIPv4 addressing can be found in the first chapter in [Stewart 1999].\nBefore discussing IP addressing, however, we\u2019ll need to say a few words about \nhow hosts and routers are connected into the Internet. A host typically has only a \nsingle link into the network; when IP in the host wants to send a datagram, it does \nso over this link. The boundary between the host and the physical link is called \nan interface . Now consider a router and its interfaces. Because a router\u2019s job is to \nreceive a datagram on one link and forward the datagram on some other link, a router \nnecessarily has two or more links to which it is connected. The boundary between the \nrouter and any one of its links is also called an interface. A router thus has multiple \ninterfaces, one for each of its links. Because every host and router is capable of send -\ning and receiving IP datagrams, IP requires each host and router interface to have \nits own IP address. Thus,", "doc_id": "20e90c1f-df2d-4b82-b2e4-2467fe9cfbaa", "embedding": null, "doc_hash": "6f45e831d668571d46d3bb50a46ebeb2f762e201498e9ed9199d3cb79cc08cfb", "extra_info": null, "node_info": {"start": 1056631, "end": 1060397}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "8cceb003-3862-4c3b-b211-1d4347328ed6", "3": "b7b5769d-f51a-451a-a979-6a919ad90171"}}, "__type__": "1"}, "b7b5769d-f51a-451a-a979-6a919ad90171": {"__data__": {"text": "few words about \nhow hosts and routers are connected into the Internet. A host typically has only a \nsingle link into the network; when IP in the host wants to send a datagram, it does \nso over this link. The boundary between the host and the physical link is called \nan interface . Now consider a router and its interfaces. Because a router\u2019s job is to \nreceive a datagram on one link and forward the datagram on some other link, a router \nnecessarily has two or more links to which it is connected. The boundary between the \nrouter and any one of its links is also called an interface. A router thus has multiple \ninterfaces, one for each of its links. Because every host and router is capable of send -\ning and receiving IP datagrams, IP requires each host and router interface to have \nits own IP address. Thus, an IP address is technically associated with an interface, \nrather than with the host or router containing that interface.\nEach IP address is 32 bits long (equivalently, 4 bytes), and there are thus a total \nof 232 (or approximately 4 billion) possible IP addresses. These addresses are typically \nwritten in so-called dotted-decimal notation , in which each byte of the address is \nwritten in its decimal form and is separated by a period (dot) from other bytes in the \naddress. For example, consider the IP address 193.32.216.9. The 193 is the decimal \nequivalent of the first 8 bits of the address; the 32 is the decimal equivalent of the sec -\nond 8 bits of the address, and so on. Thus, the address 193.32.216.9 in binary notation is\n11000001 00100000 11011000 00001001\nEach interface on every host and router in the global Internet must have an IP address \nthat is globally unique (except for interfaces behind NATs, as discussed in Section \n4.3.4). These addresses cannot be chosen in a willy-nilly manner, however. A portion \nof an interface\u2019s IP address will be determined by the subnet to which it is connected.\nFigure 4. 18 provides an example of IP addressing and interfaces. In this figure, \none router (with three interfaces) is used to interconnect seven hosts. Take a close \nlook at the IP addresses assigned to the host and router interfaces, as there are sev -\neral things to notice. The three hosts in the upper-left portion of Figure 4.18, and \nthe router interface to which they are connected, all have an IP address of the form \n223.1.1.xxx. That is, they all have the same leftmost 24 bits in their IP address. These \nfour interfaces are also interconnected to each other by a network that contains no \nrouters . This network could be interconnected by an Ethernet LAN, in which case \nthe interfaces would be interconnected by an Ethernet switch (as we\u2019ll discuss in \nChapter 6 ), or by a wireless access point (as we\u2019ll discuss in Chapter 7 ). We\u2019ll repre -\nsent this routerless network connecting these hosts as a cloud for now, and dive into \nthe internals of such networks in Chapters 6 and 7.\nIn IP terms, this network interconnecting three host interfaces and one router \ninterface forms a subnet  [RFC 950]. (A subnet is also called an IP network  or simply \n364     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\na network  in the Internet literature.) IP addressing assigns an address to this subnet: \n223.1.1.0/24, where the /24 (\u201cslash-24\u201d) notation, sometimes known as a subnet \nmask , indicates that the leftmost 24 bits of the 32-bit quantity define the subnet \naddress. The 223.1.1.0/24 subnet thus consists of the three host interfaces (223.1.1.1, \n223.1.1.2, and 223.1.1.3) and one router interface (223.1.1.4). Any additional hosts \nattached to the 223.1.1.0/24 subnet would be required  to have an address of the form \n223.1.1.xxx. There are two additional subnets shown in Figure 4.18: the", "doc_id": "b7b5769d-f51a-451a-a979-6a919ad90171", "embedding": null, "doc_hash": "1a197b90cdc3e65f874deb88333ebbb51237c39f4cdaa7900454db11a69ffe2b", "extra_info": null, "node_info": {"start": 1060403, "end": 1064151}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "20e90c1f-df2d-4b82-b2e4-2467fe9cfbaa", "3": "b4057fa5-dc97-4d60-acb2-14d4f86ac475"}}, "__type__": "1"}, "b4057fa5-dc97-4d60-acb2-14d4f86ac475": {"__data__": {"text": "network  in the Internet literature.) IP addressing assigns an address to this subnet: \n223.1.1.0/24, where the /24 (\u201cslash-24\u201d) notation, sometimes known as a subnet \nmask , indicates that the leftmost 24 bits of the 32-bit quantity define the subnet \naddress. The 223.1.1.0/24 subnet thus consists of the three host interfaces (223.1.1.1, \n223.1.1.2, and 223.1.1.3) and one router interface (223.1.1.4). Any additional hosts \nattached to the 223.1.1.0/24 subnet would be required  to have an address of the form \n223.1.1.xxx. There are two additional subnets shown in Figure 4.18: the 223.1.2.0/24 \nnetwork and the 223.1.3.0/24 subnet. Figure 4.19 illustrates the three IP subnets pre -\nsent in Figure 4.18.\nThe IP definition of a subnet is not restricted to Ethernet segments that connect \nmultiple hosts to a router interface. To get some insight here, consider Figure 4.20, \nwhich shows three routers that are interconnected with each other by point-to-point \nlinks. Each router has three interfaces, one for each point-to-point link and one for \nthe broadcast link that directly connects the router to a pair of hosts. What subnets \nare present here? Three subnets, 223.1.1.0/24, 223.1.2.0/24, and 223.1.3.0/24, are \nsimilar to the subnets we encountered in Figure 4.18. But note that there are three \nadditional subnets in this example as well: one subnet, 223.1.9.0/24, for the inter -\nfaces that connect routers R1 and R2; another subnet, 223.1.8.0/24, for the interfaces \nthat connect routers R2 and R3; and a third subnet, 223.1.7.0/24, for the interfaces \nthat connect routers R3 and R1. For a general interconnected system of routers and \nhosts, we can use the following recipe to define the subnets in the system:223.1.1.1\n223.1.2.1\n223.1.2.2223.1.1.2223.1.1.4 223.1.2.9\n223.1.3.27\n223.1.1.3\n223.1.3.1 223.1.3.2\nFigure 4.18  \u2666 Interface addresses and subnets\n4.3  \u2022  THE INTERNET PROTOCOL (IP): IPV4, ADDRESSING, IPV6, AND MORE      365\nTo determine the subnets, detach each interface from its host or router, creating \nislands of isolated networks, with interfaces terminating the end points of the \nisolated networks. Each of these isolated networks is called a subnet .\nIf we apply this procedure to the interconnected system in Figure 4.20, we get six \nislands or subnets.\nFrom the discussion above, it\u2019s clear that an organization (such as a company or \nacademic institution) with multiple Ethernet segments and point-to-point links will \nhave multiple subnets, with all of the devices on a given subnet having the same subnet \naddress. In principle, the different subnets could have quite different subnet addresses. \nIn practice, however, their subnet addresses often have much in common. To understand \nwhy, let\u2019s next turn our attention to how addressing is handled in the global Internet.\nThe Internet\u2019s address assignment strategy is known as Classless Interdomain \nRouting (CIDR \u2014pronounced cider ) [RFC 4632]. CIDR generalizes the notion of \nsubnet addressing. As with subnet addressing, the 32-bit IP address is divided into \ntwo parts and again has the dotted-decimal form a.b.c.d/x , where x indicates the \nnumber of bits in the first part of the address.\nThe x most significant bits of an address of the form a.b.c.d/x  constitute the", "doc_id": "b4057fa5-dc97-4d60-acb2-14d4f86ac475", "embedding": null, "doc_hash": "08f0f3b7e619d97dc8c6ba0c70ff4fac7cedb2011441ea94348abfcd31f5ab59", "extra_info": null, "node_info": {"start": 1064322, "end": 1067587}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "b7b5769d-f51a-451a-a979-6a919ad90171", "3": "4da1ef5c-84cf-46ef-8fea-86d31d5ac5df"}}, "__type__": "1"}, "4da1ef5c-84cf-46ef-8fea-86d31d5ac5df": {"__data__": {"text": "subnet \naddress. In principle, the different subnets could have quite different subnet addresses. \nIn practice, however, their subnet addresses often have much in common. To understand \nwhy, let\u2019s next turn our attention to how addressing is handled in the global Internet.\nThe Internet\u2019s address assignment strategy is known as Classless Interdomain \nRouting (CIDR \u2014pronounced cider ) [RFC 4632]. CIDR generalizes the notion of \nsubnet addressing. As with subnet addressing, the 32-bit IP address is divided into \ntwo parts and again has the dotted-decimal form a.b.c.d/x , where x indicates the \nnumber of bits in the first part of the address.\nThe x most significant bits of an address of the form a.b.c.d/x  constitute the \nnetwork portion of the IP address, and are often referred to as the prefix  (or network \nprefix ) of the address. An organization is typically assigned a block of contiguous \naddresses, that is, a range of addresses with a common prefix (see the Principles in \nPractice feature). In this case, the IP addresses of devices within the organization \nwill share the common prefix. When we cover the Internet\u2019s BGP routing protocol in 223.1.1.0/24\n223.1.2.0/24\n223.1.3.0/24\nFigure 4.19  \u2666 Subnet addresses\n366     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\nSection 5.4 , we\u2019ll  see that only these x leading prefix bits are considered by routers \noutside the organization\u2019s network. That is, when a router outside the organization \nforwards a datagram whose destination address is inside the organization, only the \nleading x bits of the address need be considered. This considerably reduces the size \nof the forwarding table in these routers, since a single  entry of the form a.b.c.d/x  will \nbe sufficient to forward packets to any destination within the organization.\nThe remaining 32- x bits of an address can be thought of as distinguishing among the \ndevices within  the organization, all of which have the same network prefix. These are \nthe bits that will be considered when forwarding packets at routers within  the organiza -\ntion. These lower-order bits may (or may not) have an additional subnetting structure, \nsuch as that discussed above. For example, suppose the first 21 bits of the CIDRized \naddress a.b.c.d/21 specify the organization\u2019s network prefix and are common to the IP \naddresses of all devices in that organization. The remaining 11 bits then identify the \nspecific hosts in the organization. The organization\u2019s internal structure might be such \nthat these 11 rightmost bits are used for subnetting within the organization, as discussed \nabove. For example, a.b.c.d/24 might refer to a specific subnet within the organization.\nBefore CIDR was adopted, the network portions of an IP address were constrained \nto be 8, 16, or 24 bits in length, an addressing scheme known as classful addressing , 223.1.8.1 223.1.8.0223.1.9.1 223.1.7.1\n223.1.2.6\n223.1.2.1 223.1.2.2 223.1.3.1 223.1.3.2223.1.1.3\n223.1.7.0 223.1.9.2\n223.1.3.27223.1.1.1 223.1.1.4\nR1\nR2 R3\nFigure 4.20  \u2666 Three routers interconnecting six subnets\n4.3  \u2022  THE INTERNET PROTOCOL (IP): IPV4, ADDRESSING, IPV6, AND MORE      367\nsince subnets with 8-, 16-, and 24-bit subnet addresses were known as class A, B, and \nC networks, respectively. The requirement that the subnet portion of an IP address be \nexactly 1, 2, or 3 bytes long turned out to be problematic for supporting the rapidly \ngrowing number of organizations with small and", "doc_id": "4da1ef5c-84cf-46ef-8fea-86d31d5ac5df", "embedding": null, "doc_hash": "aee34b6b8f372c36d355acca784d29a71c7b9a3b9352fe06caabde5912dba886", "extra_info": null, "node_info": {"start": 1067471, "end": 1070921}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "b4057fa5-dc97-4d60-acb2-14d4f86ac475", "3": "5dbccfce-7e9a-4e60-8b9a-9bcf9b0ef73c"}}, "__type__": "1"}, "5dbccfce-7e9a-4e60-8b9a-9bcf9b0ef73c": {"__data__": {"text": "223.1.3.1 223.1.3.2223.1.1.3\n223.1.7.0 223.1.9.2\n223.1.3.27223.1.1.1 223.1.1.4\nR1\nR2 R3\nFigure 4.20  \u2666 Three routers interconnecting six subnets\n4.3  \u2022  THE INTERNET PROTOCOL (IP): IPV4, ADDRESSING, IPV6, AND MORE      367\nsince subnets with 8-, 16-, and 24-bit subnet addresses were known as class A, B, and \nC networks, respectively. The requirement that the subnet portion of an IP address be \nexactly 1, 2, or 3 bytes long turned out to be problematic for supporting the rapidly \ngrowing number of organizations with small and medium-sized subnets. A class C (/24) \nsubnet could accommodate only up to 28 2 2 5 254 hosts (two of the 28 5 256 addresses \nare reserved for special use)\u2014too small for many organizations. However, a class B \n(/16) subnet, which supports up to 65,634 hosts, was too large. Under classful address -\ning, an organization with, say, 2,000 hosts was typically allocated a class B (/16) subnet \naddress. This led to a rapid depletion of the class B address space and poor utilization of \nthe assigned address space. For example, the organization that used a class B address for \nits 2,000 hosts was allocated enough of the address space for up to 65,534 interfaces\u2014\nleaving more than 63,000 addresses that could not be used by other organizations.\nThis example of an ISP that connects eight organizations to the Internet nicely illustrates \nhow carefully allocated CIDRized addresses facilitate routing. Suppose, as shown in Figure \n4.21, that the ISP (which we\u2019ll call Fly-By-Night-ISP) advertises to the outside world that it \nshould be sent any datagrams whose first 20 address bits match 200.23.16.0/20. The \nrest of the world need not know that within the address block 200.23.16.0/20 there are \nin fact eight other organizations, each with its own subnets. This ability to use a single \nprefix to advertise multiple networks is often referred to as address aggregation  (also \nroute aggregation  or route summarization ).\nAddress aggregation works extremely well when addresses are allocated in blocks \nto ISPs and then from ISPs to client organizations. But what happens when addresses \nare not allocated in such a hierarchical manner? What would happen, for example, if \nFly-By-Night-ISP acquires ISPs-R-Us and then has Organization 1 connect to the Internet \nthrough its subsidiary ISPs-R-Us? As shown in Figure 4.21, the subsidiary ISPs-R-Us owns \nthe address block 199.31.0.0/16, but Organization 1\u2019s IP addresses are unfortunately \noutside of this address block. What should be done here? Certainly, Organization 1 could \nrenumber all of its routers and hosts to have addresses within the ISPs-R-Us address block. \nBut this is a costly solution, and Organization 1 might well be reassigned to another \nsubsidiary in the future. The solution typically adopted is for Organization 1 to keep its \nIP addresses in 200.23.18.0/23. In this case, as shown in Figure 4.22, Fly-By-Night-ISP \ncontinues to advertise the address block 200.23.16.0/20 and ISPs-R-Us continues to \nadvertise 199.31.0.0/16. However, ISPs-R-Us now also advertises the block of addresses \nfor Organization 1, 200.23.18.0/23. When other routers in the larger Internet see the \naddress blocks 200.23.16.0/20 (from Fly-By-Night-ISP) and 200.23.18.0/23 (from ISPs-\nR-Us) and want to route to an address in the block 200.23.18.0/23, they will use longest \nprefix matching  (see Section", "doc_id": "5dbccfce-7e9a-4e60-8b9a-9bcf9b0ef73c", "embedding": null, "doc_hash": "8fb559f08fde56af317bd04c0bca462aeb639f96d6ab245fb029f2c8af33ecb2", "extra_info": null, "node_info": {"start": 1071088, "end": 1074473}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "4da1ef5c-84cf-46ef-8fea-86d31d5ac5df", "3": "d2e55835-7d0c-4be8-8f00-5e765743ca8e"}}, "__type__": "1"}, "d2e55835-7d0c-4be8-8f00-5e765743ca8e": {"__data__": {"text": "1 to keep its \nIP addresses in 200.23.18.0/23. In this case, as shown in Figure 4.22, Fly-By-Night-ISP \ncontinues to advertise the address block 200.23.16.0/20 and ISPs-R-Us continues to \nadvertise 199.31.0.0/16. However, ISPs-R-Us now also advertises the block of addresses \nfor Organization 1, 200.23.18.0/23. When other routers in the larger Internet see the \naddress blocks 200.23.16.0/20 (from Fly-By-Night-ISP) and 200.23.18.0/23 (from ISPs-\nR-Us) and want to route to an address in the block 200.23.18.0/23, they will use longest \nprefix matching  (see Section 4.2.1), and route toward ISPs-R-Us, as it advertises the long -\nest (i.e., most-specific) address prefix that matches the destination address.PRINCIPLES IN PRACTICE\n\n368     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\nOrganization 0\n200.23.16.0/23\nOrganization 1\nFly-By-Night-ISP\u201cSend me anything\n  with addresses\n  beginning\n  200.23.16.0/20\u201d\nISPs-R-Us200.23.18.0/23\nOrganization 2\n200.23.20.0/23\nOrganization 7\n200.23.30.0/23Internet\n\u201cSend me anything\n  with addresses\n  beginning\n  199.31.0.0/16\u201d\nFigure 4.21  \u2666 Hierarchical addressing and route aggregation\nOrganization 0\n200.23.16.0/23\nOrganization 2\nFly-By-Night-ISP\u201cSend me anything\n  with addresses\n  beginning\n  200.23.16.0/20\u201d\nISPs-R-Us200.23.20.0/23\nOrganization 7\n200.23.30.0/23\nOrganization 1\n200.23.18.0/23Internet\u201cSend me anything\n  with addresses\n  beginning\n  199.31.0.0/16 or\n  200.23.18.0/23\u201d\nFigure 4.22  \u2666 ISPs-R-Us has a more specific route to Organization 1\n4.3  \u2022  THE INTERNET PROTOCOL (IP): IPV4, ADDRESSING, IPV6, AND MORE      369\nWe would be remiss if we did not mention yet another type of IP address, the IP \nbroadcast address 255.255.255.255. When a host sends a datagram with destination \naddress 255.255.255.255, the message is delivered to all hosts on the same subnet. \nRouters optionally forward the message into neighboring subnets as well (although \nthey usually don\u2019t).\nHaving now studied IP addressing in detail, we need to know how hosts and \nsubnets get their addresses in the first place. Let\u2019s begin by looking at how an organi -\nzation gets a block of addresses for its devices, and then look at how a device (such \nas a host) is assigned an address from within the organization\u2019s block of addresses.\nObtaining a Block of Addresses\nIn order to obtain a block of IP addresses for use within an organization\u2019s subnet, \na network administrator might first contact its ISP, which would provide addresses \nfrom a larger block of addresses that had already been allocated to the ISP. For \nexample, the ISP may itself have been allocated the address block 200.23.16.0/20. \nThe ISP, in turn, could divide its address block into eight equal-sized contiguous \naddress blocks and give one of these address blocks out to each of up to eight organi -\nzations that are supported by this ISP, as shown below. (We have underlined the \nsubnet part of these addresses for your convenience.)\nISP\u2019s block:     200.23.16.0/20     11001000 00010111 00010000 00000000\nOrganization 0  ", "doc_id": "d2e55835-7d0c-4be8-8f00-5e765743ca8e", "embedding": null, "doc_hash": "6ff181394eb1c89ec34ee3ee7fd04c4ad59fb72fcdd37f9810a868f02febc806", "extra_info": null, "node_info": {"start": 1074435, "end": 1077463}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "5dbccfce-7e9a-4e60-8b9a-9bcf9b0ef73c", "3": "9c1d5bd4-f21a-4832-a1a0-67bcfda576bf"}}, "__type__": "1"}, "9c1d5bd4-f21a-4832-a1a0-67bcfda576bf": {"__data__": {"text": "a block of IP addresses for use within an organization\u2019s subnet, \na network administrator might first contact its ISP, which would provide addresses \nfrom a larger block of addresses that had already been allocated to the ISP. For \nexample, the ISP may itself have been allocated the address block 200.23.16.0/20. \nThe ISP, in turn, could divide its address block into eight equal-sized contiguous \naddress blocks and give one of these address blocks out to each of up to eight organi -\nzations that are supported by this ISP, as shown below. (We have underlined the \nsubnet part of these addresses for your convenience.)\nISP\u2019s block:     200.23.16.0/20     11001000 00010111 00010000 00000000\nOrganization 0   200.23.16.0/23     11001000 00010111 00010000 00000000\nOrganization 1   200.23.18.0/23     11001000 00010111 00010010 00000000\nOrganization 2   200.23.20.0/23     11001000 00010111 00010100 00000000\n\u00a0\u00a0\u00a0\u00a0\u2026\u00a0\u00a0 \u2026\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0                 \u00a0\u00a0\u00a0\u2026\nOrganization 7   200.23.30.0/23     11001000 00010111 00011110 00000000\nWhile obtaining a set of addresses from an ISP is one way to get a block of \naddresses, it is not the only way. Clearly, there must also be a way for the ISP itself \nto get a block of addresses. Is there a global authority that has ultimate responsibil -\nity for managing the IP address space and allocating address blocks to ISPs and \nother organizations? Indeed there is! IP addresses are managed under the authority \nof the Internet Corporation for Assigned Names and Numbers (ICANN) [ICANN \n2016], based on guidelines set forth in [RFC 7020]. The role of the nonprofit ICANN \norganization [NTIA 1998] is not only to allocate IP addresses, but also to manage \nthe DNS root servers. It also has the very contentious job of assigning domain names \nand resolving domain name disputes. The ICANN allocates addresses to regional \nInternet registries (for example, ARIN, RIPE, APNIC, and LACNIC, which together \nform the Address Supporting Organization of ICANN [ASO-ICANN 2016]), and \nhandle the allocation/management of addresses within their regions.\n370     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\nObtaining a Host Address: The Dynamic Host Configuration Protocol\nOnce an organization has obtained a block of addresses, it can assign individual \nIP addresses to the host and router interfaces in its organization. A system admin -\nistrator will typically manually configure the IP addresses into the router (often \nremotely, with a network management tool). Host addresses can also be config -\nured manually, but typically this is done using the Dynamic Host Configuration \nProtocol (DHCP)  [RFC 2131]. DHCP allows a host to obtain (be allocated) an \nIP address automatically. A network administrator can configure DHCP so that a \ngiven host receives the same IP address each time it connects to the network, or a \nhost may be assigned a temporary IP address  that will be different each time the \nhost connects to the network. In addition to host IP address assignment, DHCP also \nallows a host to learn additional information, such as its subnet mask, the address \nof its first-hop router (often called the default gateway), and the address of its local \nDNS server.\nBecause of DHCP\u2019s ability to automate the network-related aspects of connect -\ning a host into a network, it is often referred to as a plug-and-play  or zeroconf  \n(zero-configuration) protocol. This capability makes it very attractive to the network \nadministrator who would otherwise have to perform these tasks manually! DHCP \nis also enjoying widespread use in residential Internet access networks, enterprise \nnetworks, and in wireless LANs, where hosts join and leave the network frequently. \nConsider,", "doc_id": "9c1d5bd4-f21a-4832-a1a0-67bcfda576bf", "embedding": null, "doc_hash": "63daa02d578c55a5a941e013a0805d7c244499b35b216ac7e2624fe5271cfd02", "extra_info": null, "node_info": {"start": 1077359, "end": 1081077}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "d2e55835-7d0c-4be8-8f00-5e765743ca8e", "3": "c43bcf01-2bd1-4c22-9ebf-74f46ac0f91e"}}, "__type__": "1"}, "c43bcf01-2bd1-4c22-9ebf-74f46ac0f91e": {"__data__": {"text": "\nhost connects to the network. In addition to host IP address assignment, DHCP also \nallows a host to learn additional information, such as its subnet mask, the address \nof its first-hop router (often called the default gateway), and the address of its local \nDNS server.\nBecause of DHCP\u2019s ability to automate the network-related aspects of connect -\ning a host into a network, it is often referred to as a plug-and-play  or zeroconf  \n(zero-configuration) protocol. This capability makes it very attractive to the network \nadministrator who would otherwise have to perform these tasks manually! DHCP \nis also enjoying widespread use in residential Internet access networks, enterprise \nnetworks, and in wireless LANs, where hosts join and leave the network frequently. \nConsider, for example, the student who carries a laptop from a dormitory room to \na library to a classroom. It is likely that in each location, the student will be con -\nnecting into a new subnet and hence will need a new IP address at each location. \nDHCP is ideally suited to this situation, as there are many users coming and going, \nand addresses are needed for only a limited amount of time. The value of DHCP\u2019s \nplug-and-play capability is clear, since it\u2019s unimaginable that a system administrator \nwould be able to reconfigure laptops at each location, and few students (except those \ntaking a computer networking class!) would have the expertise to configure their \nlaptops manually.\nDHCP is a client-server protocol. A client is typically a newly arriving host \nwanting to obtain network configuration information, including an IP address for \nitself. In the simplest case, each subnet (in the addressing sense of Figure 4.20) will \nhave a DHCP server. If no server is present on the subnet, a DHCP relay agent (typi -\ncally a router) that knows the address of a DHCP server for that network is needed. \nFigure 4. 23 shows a DHCP server attached to subnet 223.1.2/24, with the router \nserving as the relay agent for arriving clients attached to subnets 223.1.1/24 and \n223.1.3/24. In our discussion below, we\u2019ll assume that a DHCP server is available \non the subnet.\nFor a newly arriving host, the DHCP protocol is a four-step process, as shown in \nFigure 4. 24 for the network setting shown in Figure 4.23. In this figure, yiaddr  (as \nin \u201cyour Internet address\u201d) indicates the address being allocated to the newly arriving \nclient. The four steps are:\n4.3  \u2022  THE INTERNET PROTOCOL (IP): IPV4, ADDRESSING, IPV6, AND MORE      371\n\u2022 DHCP server discovery.  The first task of a newly arriving host is to find a DHCP \nserver with which to interact. This is done using a DHCP discover message , \nwhich a client sends within a UDP packet to port 67. The UDP packet is encap -\nsulated in an IP datagram. But to whom should this datagram be sent? The host \ndoesn\u2019t even know the IP address of the network to which it is attaching, much \nless the address of a DHCP server for this network. Given this, the DHCP client \ncreates an IP datagram containing its DHCP discover message along with the \nbroadcast destination IP address of 255.255.255.255 and a \u201cthis host\u201d source IP \naddress of 0.0.0.0. The DHCP client passes the IP datagram to the link layer, \nwhich then broadcasts this frame to all nodes attached to the subnet (we will cover \nthe details of link-layer broadcasting in Section 6.4).\n\u2022 DHCP server offer(s).  A DHCP server receiving a DHCP discover message \nresponds to the client with a DHCP offer message  that is broadcast to all nodes \non the subnet, again using the IP broadcast address of 255.255.255.255. (You \nmight want to think about why this server reply must also be broadcast). Since \nseveral", "doc_id": "c43bcf01-2bd1-4c22-9ebf-74f46ac0f91e", "embedding": null, "doc_hash": "e23e55a24ce74e962126e8f415508ffe25764f6aa4547897c65cc7e30675c7b1", "extra_info": null, "node_info": {"start": 1081009, "end": 1084701}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "9c1d5bd4-f21a-4832-a1a0-67bcfda576bf", "3": "a944ee64-2904-4841-a43d-196e590f2792"}}, "__type__": "1"}, "a944ee64-2904-4841-a43d-196e590f2792": {"__data__": {"text": "Given this, the DHCP client \ncreates an IP datagram containing its DHCP discover message along with the \nbroadcast destination IP address of 255.255.255.255 and a \u201cthis host\u201d source IP \naddress of 0.0.0.0. The DHCP client passes the IP datagram to the link layer, \nwhich then broadcasts this frame to all nodes attached to the subnet (we will cover \nthe details of link-layer broadcasting in Section 6.4).\n\u2022 DHCP server offer(s).  A DHCP server receiving a DHCP discover message \nresponds to the client with a DHCP offer message  that is broadcast to all nodes \non the subnet, again using the IP broadcast address of 255.255.255.255. (You \nmight want to think about why this server reply must also be broadcast). Since \nseveral DHCP servers can be present on the subnet, the client may find itself in \nthe enviable position of being able to choose from among several offers. Each 223.1.1.1\n223.1.1.2223.1.1.4 223.1.2.9\n223.1.3.27\n223.1.1.3\n223.1.3.1 223.1.3.2223.1.2.1223.1.2.5\n223.1.2.2Arriving\nDHCP\nclientDHCP\nserver\nFigure 4.23  \u2666 DHCP client and server\n372     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\nserver offer message contains the transaction ID of the received discover mes -\nsage, the proposed IP address for the client, the network mask, and an IP address \nlease time \u2014the amount of time for which the IP address will be valid. It is com -\nmon for the server to set the lease time to several hours or days [Droms 2002].\n\u2022 DHCP request. The newly arriving client will choose from among one or more \nserver offers and respond to its selected offer with a DHCP request message , \nechoing back the configuration parameters.\n\u2022 DHCP ACK.  The server responds to the DHCP request message with a DHCP \nACK message , confirming the requested parameters.DHCP server:\n223.1.2.5Arriving client\nDHCP discover\nTime Timesrc: 0.0.0.0, 68\ndest: 255.255.255.255,67\nDHCPDISCOVER\nyiaddr: 0.0.0.0\ntransaction ID: 654\nsrc: 223.1.2.5, 67\ndest: 255.255.255.255,68\nDHCPOFFER\nyiaddrr: 223.1.2.4\ntransaction ID: 654\nDHCP server ID: 223.1.2.5\nLifetime: 3600 secsDHCP of fer\nsrc: 223.1.2.5, 67\ndest: 255.255.255.255,68\nDHCPACK\nyiaddrr: 223.1.2.4\ntransaction ID: 655\nDHCP server ID: 223.1.2.5\nLifetime: 3600 secsDHCP ACKsrc: 0.0.0.0, 68\ndest: 255.255.255.255, 67\nDHCPREQUEST\nyiaddrr: 223.1.2.4\ntransaction ID: 655\nDHCP server ID: 223.1.2.5\nLifetime: 3600 secsDHCP request\nFigure 4.24  \u2666 DHCP client-server interaction\n4.3  \u2022  THE INTERNET PROTOCOL (IP): IPV4, ADDRESSING, IPV6, AND MORE      373\nOnce the client receives the DHCP ACK, the interaction is complete and the \nclient can use the DHCP-allocated IP address for the lease duration. Since a client \nmay want to use its address beyond the lease\u2019s expiration, DHCP also provides a \nmechanism that allows a client to renew its lease on an IP address.\nFrom a mobility aspect, DHCP does have one very significant shortcoming. \nSince a new IP address is obtained from DHCP each time a node connects to a new \nsubnet, a TCP connection to a remote application cannot be maintained as a mobile \nnode moves between subnets. In Chapter 6, we will", "doc_id": "a944ee64-2904-4841-a43d-196e590f2792", "embedding": null, "doc_hash": "ed60d87bbda73cdb1781633b72d57c4c4699e142034cf338c22daf672b49903f", "extra_info": null, "node_info": {"start": 1084756, "end": 1087837}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "c43bcf01-2bd1-4c22-9ebf-74f46ac0f91e", "3": "248f0479-4a06-4e9a-972c-d0205e2df956"}}, "__type__": "1"}, "248f0479-4a06-4e9a-972c-d0205e2df956": {"__data__": {"text": "\u2666 DHCP client-server interaction\n4.3  \u2022  THE INTERNET PROTOCOL (IP): IPV4, ADDRESSING, IPV6, AND MORE      373\nOnce the client receives the DHCP ACK, the interaction is complete and the \nclient can use the DHCP-allocated IP address for the lease duration. Since a client \nmay want to use its address beyond the lease\u2019s expiration, DHCP also provides a \nmechanism that allows a client to renew its lease on an IP address.\nFrom a mobility aspect, DHCP does have one very significant shortcoming. \nSince a new IP address is obtained from DHCP each time a node connects to a new \nsubnet, a TCP connection to a remote application cannot be maintained as a mobile \nnode moves between subnets. In Chapter 6, we will examine mobile IP\u2014an exten -\nsion to the IP infrastructure that allows a mobile node to use a single permanent \naddress as it moves between subnets. Additional details about DHCP can be found in \n[Droms 2002] and [dhc 2016]. An open source reference implementation of DHCP \nis available from the Internet Systems Consortium [ISC 2016].\n4.3.4  Network Address Translation (NAT)\nGiven our discussion about Internet addresses and the IPv4 datagram format, we\u2019re \nnow well aware that every IP-capable device needs an IP address. With the prolif -\neration of small office, home office (SOHO) subnets, this would seem to imply that \nwhenever a SOHO wants to install a LAN to connect multiple machines, a range of \naddresses would need to be allocated by the ISP to cover all of the SOHO\u2019s IP devices \n(including phones, tablets, gaming devices, IP TVs, printers and more). If the subnet \ngrew bigger, a larger block of addresses would have to be allocated. But what if the \nISP had already allocated the contiguous portions of the SOHO network\u2019s current \naddress range? And what typical homeowner wants (or should need) to know how \nto manage IP addresses in the first place? Fortunately, there is a simpler approach \nto address allocation that has found increasingly widespread use in such scenarios: \nnetwork address translation (NAT)  [RFC 2663; RFC 3022; Huston 2004, Zhang \n2007; Cisco NAT 2016].\nFigure 4. 25 shows the operation of a NAT-enabled router. The NAT-enabled \nrouter, residing in the home, has an interface that is part of the home network on \nthe right of Figure 4.25. Addressing within the home network is exactly as we have \nseen above\u2014all four interfaces in the home network have the same subnet address \nof 10.0.0/24. The address space 10.0.0.0/8 is one of three portions of the IP address \nspace that is reserved in [RFC 1918] for a private network  or a realm with private \naddresses , such as the home network in Figure 4.25. A realm with private addresses \nrefers to a network whose addresses only have meaning to devices within that net -\nwork. To see why this is important, consider the fact that there are hundreds of thou -\nsands of home networks, many using the same address space, 10.0.0.0/24. Devices \nwithin a given home network can send packets to each other using 10.0.0.0/24 \naddressing. However, packets forwarded beyond  the home network into the larger \nglobal Internet clearly cannot use these addresses (as either a source or a destina -\ntion address) because there are hundreds of thousands of networks using this block \nof addresses. That is, the 10.0.0.0/24 addresses can only have meaning within the \n374     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\ngiven home network. But if private addresses only have meaning within a given \nnetwork, how is addressing handled when packets are sent to or received from the \nglobal Internet, where addresses are necessarily unique? The answer lies in under -\nstanding NAT.\nThe NAT-enabled router does not look like a router to the outside world. Instead \nthe NAT router behaves to the outside world as a", "doc_id": "248f0479-4a06-4e9a-972c-d0205e2df956", "embedding": null, "doc_hash": "3b83a7bd5fe8a140e22a109bdda6691487edccf7a3c3efe36058a4137fca15e6", "extra_info": null, "node_info": {"start": 1087861, "end": 1091655}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "a944ee64-2904-4841-a43d-196e590f2792", "3": "556f31d9-9cdd-40a8-bf87-da8068cd9695"}}, "__type__": "1"}, "556f31d9-9cdd-40a8-bf87-da8068cd9695": {"__data__": {"text": "However, packets forwarded beyond  the home network into the larger \nglobal Internet clearly cannot use these addresses (as either a source or a destina -\ntion address) because there are hundreds of thousands of networks using this block \nof addresses. That is, the 10.0.0.0/24 addresses can only have meaning within the \n374     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\ngiven home network. But if private addresses only have meaning within a given \nnetwork, how is addressing handled when packets are sent to or received from the \nglobal Internet, where addresses are necessarily unique? The answer lies in under -\nstanding NAT.\nThe NAT-enabled router does not look like a router to the outside world. Instead \nthe NAT router behaves to the outside world as a single  device with a single  IP \naddress. In Figure 4.25, all traffic leaving the home router for the larger Internet has \na source IP address of 138.76.29.7, and all traffic entering the home router must have \na destination address of 138.76.29.7. In essence, the NAT-enabled router is hiding \nthe details of the home network from the outside world. (As an aside, you might \nwonder where the home network computers get their addresses and where the router \ngets its single IP address. Often, the answer is the same\u2014DHCP! The router gets its \naddress from the ISP\u2019s DHCP server, and the router runs a DHCP server to provide \naddresses to computers within the NAT-DHCP-router-controlled home network\u2019s \naddress space.)\nIf all datagrams arriving at the NAT router from the WAN have the same desti -\nnation IP address (specifically, that of the WAN-side interface of the NAT router), \nthen how does the router know the internal host to which it should forward a given \ndatagram? The trick is to use a NAT translation table  at the NAT router, and to \ninclude port numbers as well as IP addresses in the table entries.3210.0.0.1\n138.76.29.710.0.0.410.0.0.2\n10.0.0.3NAT translation tabl e\nWAN sid e\n138.76.29.7, 5001LAN side\n10.0.0.1, 3345\n. . ..  . .\nS = 138.76.29.7, 5001\nD = 128.119.40.186, 80 1\n4\nS = 128.119.40.186, 80\nD = 138.76.29.7, 5001S = 128.119.40.186, 80\nD = 10.0.0.1, 3345 S = 10.0.0.1, 3345\nD = 128.119.40.186, 80\nFigure 4.25  \u2666 Network address translation\n4.3  \u2022  THE INTERNET PROTOCOL (IP): IPV4, ADDRESSING, IPV6, AND MORE      375\nConsider the example in Figure 4.25. Suppose a user sitting in a home net -\nwork behind host 10.0.0.1 requests a Web page on some Web server (port 80) \nwith IP address 128.119.40.186. The host 10.0.0.1 assigns the (arbitrary) source \nport number 3345 and sends the datagram into the LAN. The NAT router receives \nthe datagram, generates a new source port number 5001 for the datagram, replaces \nthe source IP address with its WAN-side IP address 138.76.29.7, and replaces the \noriginal source port number 3345 with the new source port number 5001. When \ngenerating a new source port number, the NAT router can select any source port \nnumber that is not currently in the NAT translation table. (Note that because a port \nnumber field is 16 bits long, the NAT protocol can support over 60,000 simul -\ntaneous connections with a single WAN-side IP address for the router!) NAT \nin the router also adds an entry to its NAT translation table. The Web server, \nblissfully unaware that the arriving datagram containing the HTTP request has \nbeen manipulated by the NAT router, responds with a datagram whose destination \naddress is the", "doc_id": "556f31d9-9cdd-40a8-bf87-da8068cd9695", "embedding": null, "doc_hash": "4215484413e0a0a2dd8eac302bc8bf63472a634cb3c9edfd09ddc86309681a92", "extra_info": null, "node_info": {"start": 1091601, "end": 1095042}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "248f0479-4a06-4e9a-972c-d0205e2df956", "3": "409f5922-38da-4c2f-a88b-98c877882b39"}}, "__type__": "1"}, "409f5922-38da-4c2f-a88b-98c877882b39": {"__data__": {"text": "datagram, generates a new source port number 5001 for the datagram, replaces \nthe source IP address with its WAN-side IP address 138.76.29.7, and replaces the \noriginal source port number 3345 with the new source port number 5001. When \ngenerating a new source port number, the NAT router can select any source port \nnumber that is not currently in the NAT translation table. (Note that because a port \nnumber field is 16 bits long, the NAT protocol can support over 60,000 simul -\ntaneous connections with a single WAN-side IP address for the router!) NAT \nin the router also adds an entry to its NAT translation table. The Web server, \nblissfully unaware that the arriving datagram containing the HTTP request has \nbeen manipulated by the NAT router, responds with a datagram whose destination \naddress is the IP address of the NAT router, and whose destination port number is \n5001. When this datagram arrives at the NAT router, the router indexes the NAT \ntranslation table using the destination IP address and destination port number to \nobtain the appropriate IP address (10.0.0.1) and destination port number (3345) \nfor the browser in the home network. The router then rewrites the datagram\u2019s \ndestination address and destination port number, and forwards the datagram into \nthe home network.\nNAT has enjoyed widespread deployment in recent years. But NAT is not with -\nout detractors. First, one might argue that, port numbers are meant to be used for \naddressing processes, not for addressing hosts. This violation can indeed cause prob -\nlems for servers running on the home network, since, as we have seen in Chapter 2 , \nserver processes wait for incoming requests at well-known port numbers and peers in \na P2P protocol need to accept incoming connections when acting as servers. Techni -\ncal solutions to these problems include NAT traversal  tools [RFC 5389] and Uni -\nversal Plug and Play (UPnP), a protocol that allows a host to discover and configure \na nearby NAT [UPnP Forum 2016].\nMore \u201cphilosophical\u201d arguments have also been raised against NAT by archi -\ntectural purists. Here, the concern is that routers are meant to be layer 3 (i.e., net -\nwork-layer) devices, and should process packets only up to the network layer. NAT \nviolates this principle that hosts should be talking directly with each other, without \ninterfering nodes modifying IP addresses, much less port numbers. But like it or not, \nNAT has not become an important component of the Internet, as have other so-called \nmiddleboxes  [Sekar 2011] that operate at the network layer but have functions that \nare quite different from routers. Middleboxes do not perform traditional datagram \nforwarding, but instead perform functions such as NAT, load balancing of traffic \nflows, traffic firewalling (see accompanying sidebar), and more. The generalized \nforwarding paradigm that we\u2019ll study shortly in Section 4.4 allows a number of these \nmiddlebox functions, as well as traditional router forwarding, to be accomplished in \na common, integrated manner.\n376     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\n4.3.5  IPv6\nIn the early 1990s, the Internet Engineering Task Force began an effort to develop a \nsuccessor to the IPv4 protocol. A prime motivation for this effort was the realization \nthat the 32-bit IPv4 address space was beginning to be used up, with new subnets INSPECTING DATAGRAMS: FIREWALLS AND INTRUSION DETECTION  \nSYSTEMS\nSuppose you are assigned the task of administering a home, departmental, university, or \ncorporate network. Attackers, knowing the IP address range of your network, can easily \nsend IP datagrams to addresses in your range. These datagrams can do all kinds of devi -\nous things, including mapping your network with ping sweeps and port scans, crashing \nvulnerable hosts with malformed packets, scanning for open", "doc_id": "409f5922-38da-4c2f-a88b-98c877882b39", "embedding": null, "doc_hash": "37621a7f91b81a0bc8c9fbf1cf25524674d53a2cf886477e6ab370f19baa3d5d", "extra_info": null, "node_info": {"start": 1095004, "end": 1098845}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "556f31d9-9cdd-40a8-bf87-da8068cd9695", "3": "5932e59c-e582-4605-a425-ed388e650145"}}, "__type__": "1"}, "5932e59c-e582-4605-a425-ed388e650145": {"__data__": {"text": "the early 1990s, the Internet Engineering Task Force began an effort to develop a \nsuccessor to the IPv4 protocol. A prime motivation for this effort was the realization \nthat the 32-bit IPv4 address space was beginning to be used up, with new subnets INSPECTING DATAGRAMS: FIREWALLS AND INTRUSION DETECTION  \nSYSTEMS\nSuppose you are assigned the task of administering a home, departmental, university, or \ncorporate network. Attackers, knowing the IP address range of your network, can easily \nsend IP datagrams to addresses in your range. These datagrams can do all kinds of devi -\nous things, including mapping your network with ping sweeps and port scans, crashing \nvulnerable hosts with malformed packets, scanning for open TCP/UDP ports on servers \nin your network, and infecting hosts by including malware in the packets. As the network \nadministrator, what are you going to do about all those bad guys out there, each capable \nof sending malicious packets into your network? Two popular defense mechanisms to mali -\ncious packet attacks are firewalls and intrusion detection systems (IDSs).\nAs a network administrator, you may first try installing a firewall between your network \nand the Internet. (Most access routers today have firewall capability.) Firewalls inspect the \ndatagram and segment header fields, denying suspicious datagrams entry into the internal \nnetwork. For example, a firewall may be configured to block all ICMP echo request pack -\nets (see Section 5.6 ), thereby preventing an attacker from doing a traditional port scan \nacross your IP address range. Firewalls can also block packets based on source and des -\ntination IP addresses and port numbers. Additionally, firewalls can be configured to track \nTCP connections, granting entry only to datagrams that belong to approved connections.\nAdditional protection can be provided with an IDS. An IDS, typically situated at the \nnetwork boundary, performs \u201cdeep packet inspection,\u201d examining not only header fields \nbut also the payloads in the datagram (including application-layer data). An IDS has a \ndatabase of packet signatures that are known to be part of attacks. This database is auto -\nmatically updated as new attacks are discovered. As packets pass through the IDS, the \nIDS attempts to match header fields and payloads to the signatures in its signature data -\nbase. If such a match is found, an alert is created. An intrusion prevention system (IPS) is \nsimilar to an IDS, except that it actually blocks packets in addition to creating alerts. In \nChapter 8, we\u2019ll explore firewalls and IDSs in more detail.\nCan firewalls and IDSs fully shield your network from all attacks? The answer is clearly \nno, as attackers continually find new attacks for which signatures are not yet available. \nBut firewalls and traditional signature-based IDSs are useful in protecting your network \nfrom known attacks.FOCUS ON SECURITY\n\n4.3  \u2022  THE INTERNET PROTOCOL (IP): IPV4, ADDRESSING, IPV6, AND MORE      377\nand IP nodes being attached to the Internet (and being allocated unique IP addresses) \nat a breathtaking rate. To respond to this need for a large IP address space, a new \nIP protocol, IPv6, was developed. The designers of IPv6 also took this opportunity \nto tweak and augment other aspects of IPv4, based on the accumulated operational \nexperience with IPv4.\nThe point in time when IPv4 addresses would be completely allocated (and \nhence no new networks could attach to the Internet) was the subject of considerable \ndebate. The estimates of the two leaders of the IETF\u2019s Address Lifetime Expec -\ntations working group were that addresses would become exhausted in 2008 and \n2018, respectively [Solensky 1996]. In February 2011, IANA allocated out the last \nremaining pool of unassigned IPv4 addresses to a regional registry. While these reg -\nistries still have available IPv4 addresses within their pool, once these addresses are", "doc_id": "5932e59c-e582-4605-a425-ed388e650145", "embedding": null, "doc_hash": "06fb6e84d642fa2611aaacd4cef79675271cff84842a7225ee3d37706ddd4df7", "extra_info": null, "node_info": {"start": 1098908, "end": 1102829}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "409f5922-38da-4c2f-a88b-98c877882b39", "3": "812c5ac3-184d-4bf2-817d-243b9493c6b9"}}, "__type__": "1"}, "812c5ac3-184d-4bf2-817d-243b9493c6b9": {"__data__": {"text": "protocol, IPv6, was developed. The designers of IPv6 also took this opportunity \nto tweak and augment other aspects of IPv4, based on the accumulated operational \nexperience with IPv4.\nThe point in time when IPv4 addresses would be completely allocated (and \nhence no new networks could attach to the Internet) was the subject of considerable \ndebate. The estimates of the two leaders of the IETF\u2019s Address Lifetime Expec -\ntations working group were that addresses would become exhausted in 2008 and \n2018, respectively [Solensky 1996]. In February 2011, IANA allocated out the last \nremaining pool of unassigned IPv4 addresses to a regional registry. While these reg -\nistries still have available IPv4 addresses within their pool, once these addresses are \nexhausted, there are no more available address blocks that can be allocated from a \ncentral pool [Huston 2011a]. A recent survey of IPv4 address-space exhaustion, and \nthe steps taken to prolong the life of the address space is [Richter 2015].\nAlthough the mid-1990s estimates of IPv4 address depletion suggested that \na considerable amount of time might be left until the IPv4 address space was \nexhausted, it was realized that considerable time would be needed to deploy a new \ntechnology on such an extensive scale, and so the process to develop IP version 6 \n(IPv6) [RFC 2460] was begun [RFC 1752]. (An often-asked question is what hap -\npened to IPv5? It was initially envisioned that the ST-2 protocol would become \nIPv5, but ST-2 was later dropped.) An excellent source of information about IPv6 \nis [Huitema 1998].\nIPv6 Datagram Format\nThe format of the IPv6 datagram is shown in Figure 4.26. The most important \nchanges introduced in IPv6 are evident in the datagram format:\n\u2022 Expanded addressing capabilities.  IPv6 increases the size of the IP address from \n32 to 128 bits. This ensures that the world won\u2019t run out of IP addresses. Now, \nevery grain of sand on the planet can be IP-addressable. In addition to unicast and \nmulticast addresses, IPv6 has introduced a new type of address, called an anycast \naddress , that allows a datagram to be delivered to any one of a group of hosts. \n(This feature could be used, for example, to send an HTTP GET to the nearest of \na number of mirror sites that contain a given document.)\n\u2022 A streamlined 40-byte header.  As discussed below, a number of IPv4 fields have \nbeen dropped or made optional. The resulting 40-byte fixed-length header allows \nfor faster processing of the IP datagram by a router. A new encoding of options \nallows for more flexible options processing.\n\u2022 Flow labeling.  IPv6 has an elusive definition of a flow. RFC 2460 states that this \nallows \u201clabeling of packets belonging to particular flows for which the sender \n378     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\nrequests special handling, such as a non-default quality of service or real-time \nservice.\u201d For example, audio and video transmission might likely be treated as \na flow. On the other hand, the more traditional applications, such as file transfer \nand e-mail, might not be treated as flows. It is possible that the traffic carried by a \nhigh-priority user (for example, someone paying for better service for their traffic)  \nmight also be treated as a flow. What is clear, however, is that the designers of \nIPv6 foresaw the eventual need to be able to differentiate among the flows, even \nif the exact meaning of a flow had yet to be determined.\nAs noted above, a comparison of Figure 4.26 with Figure 4.16 reveals the sim -\npler, more streamlined structure of the IPv6 datagram. The following fields are \ndefined in IPv6:\n\u2022 Version.  This 4-bit field identifies the IP version number. Not surprisingly, IPv6 \ncarries a value of 6 in this field. Note that putting a 4", "doc_id": "812c5ac3-184d-4bf2-817d-243b9493c6b9", "embedding": null, "doc_hash": "ac23bcb10437e7756ef131e80fa9d81e4b1d84af29bcdc82144f7b6b828622c8", "extra_info": null, "node_info": {"start": 1102803, "end": 1106580}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "5932e59c-e582-4605-a425-ed388e650145", "3": "ff884cde-19af-46c7-8573-45ffe6430d74"}}, "__type__": "1"}, "ff884cde-19af-46c7-8573-45ffe6430d74": {"__data__": {"text": "as file transfer \nand e-mail, might not be treated as flows. It is possible that the traffic carried by a \nhigh-priority user (for example, someone paying for better service for their traffic)  \nmight also be treated as a flow. What is clear, however, is that the designers of \nIPv6 foresaw the eventual need to be able to differentiate among the flows, even \nif the exact meaning of a flow had yet to be determined.\nAs noted above, a comparison of Figure 4.26 with Figure 4.16 reveals the sim -\npler, more streamlined structure of the IPv6 datagram. The following fields are \ndefined in IPv6:\n\u2022 Version.  This 4-bit field identifies the IP version number. Not surprisingly, IPv6 \ncarries a value of 6 in this field. Note that putting a 4 in this field does not create \na valid IPv4 datagram. (If it did, life would be a lot simpler\u2014see the discussion \nbelow regarding the transition from IPv4 to IPv6.)\n\u2022 Traffic class.  The 8-bit traffic class field, like the TOS field in IPv4, can be used \nto give priority to certain datagrams within a flow, or it can be used to give pri -\nority to datagrams from certain applications (for example, voice-over-IP) over \ndatagrams from other applications (for example, SMTP e-mail).\n\u2022 Flow label.  As discussed above, this 20-bit field is used to identify a flow of datagrams.\n\u2022 Payload length.  This 16-bit value is treated as an unsigned integer giving the \nnumber of bytes in the IPv6 datagram following the fixed-length, 40-byte data -\ngram header.Version Traf\ufb01c class\nPayload length Next hdr Hop limitFlow label32 bits\nSource address\n(128 bits)\nDestination address\n(128 bits)\nData\nFigure 4.26  \u2666 IPv6 datagram format\n4.3  \u2022  THE INTERNET PROTOCOL (IP): IPV4, ADDRESSING, IPV6, AND MORE      379\n\u2022 Next header.  This field identifies the protocol to which the contents (data field) of \nthis datagram will be delivered (for example, to TCP or UDP). The field uses the \nsame values as the protocol field in the IPv4 header.\n\u2022 Hop limit.  The contents of this field are decremented by one by each router \nthat forwards the datagram. If the hop limit count reaches zero, the datagram is \n discarded.\n\u2022 Source and destination addresses.  The various formats of the IPv6 128-bit address \nare described in RFC 4291.\n\u2022 Data.  This is the payload portion of the IPv6 datagram. When the datagram \nreaches its destination, the payload will be removed from the IP datagram and \npassed on to the protocol specified in the next header field.\nThe discussion above identified the purpose of the fields that are included in the \nIPv6 datagram. Comparing the IPv6 datagram format in Figure 4.26 with the IPv4 \ndatagram format that we saw in Figure 4.16, we notice that several fields appearing \nin the IPv4 datagram are no longer present in the IPv6 datagram:\n\u2022 Fragmentation/reassembly.  IPv6 does not allow for fragmentation and reassem -\nbly at intermediate routers; these operations can be performed only by the source \nand destination. If an IPv6 datagram received by a router is too large to be for -\nwarded over the outgoing link, the router simply drops the datagram and sends a \n\u201cPacket Too Big\u201d ICMP error message (see Section 5.6 ) back to the sender. The \nsender can then resend the data, using a smaller IP datagram size. Fragmentation \nand reassembly is a time-consuming operation; removing this functionality from \nthe routers and placing it squarely in the end systems considerably speeds up IP \nforwarding within the network.\n\u2022 Header checksum.  Because the transport-layer (for example, TCP and UDP) and \nlink-layer (for example, Ethernet) protocols in the Internet layers perform check -\nsumming, the", "doc_id": "ff884cde-19af-46c7-8573-45ffe6430d74", "embedding": null, "doc_hash": "17dcd0ab1276283a55dfe311416712a335af2d735ecc21241fa03fc822956e08", "extra_info": null, "node_info": {"start": 1106614, "end": 1110257}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "812c5ac3-184d-4bf2-817d-243b9493c6b9", "3": "8b9f12dc-9d81-48b8-acf6-ce3168fb8498"}}, "__type__": "1"}, "8b9f12dc-9d81-48b8-acf6-ce3168fb8498": {"__data__": {"text": "can be performed only by the source \nand destination. If an IPv6 datagram received by a router is too large to be for -\nwarded over the outgoing link, the router simply drops the datagram and sends a \n\u201cPacket Too Big\u201d ICMP error message (see Section 5.6 ) back to the sender. The \nsender can then resend the data, using a smaller IP datagram size. Fragmentation \nand reassembly is a time-consuming operation; removing this functionality from \nthe routers and placing it squarely in the end systems considerably speeds up IP \nforwarding within the network.\n\u2022 Header checksum.  Because the transport-layer (for example, TCP and UDP) and \nlink-layer (for example, Ethernet) protocols in the Internet layers perform check -\nsumming, the designers of IP probably felt that this functionality was sufficiently \nredundant in the network layer that it could be removed. Once again, fast pro -\ncessing of IP packets was a central concern. Recall from our discussion of IPv4 \nin Section 4.3.1 that since the IPv4 header contains a TTL field (similar to the \nhop limit field in IPv6), the IPv4 header checksum needed to be recomputed at \nevery router. As with fragmentation and reassembly, this too was a costly opera -\ntion in IPv4.\n\u2022 Options.  An options field is no longer a part of the standard IP header. How -\never, it has not gone away. Instead, the options field is one of the possible next \nheaders pointed to from within the IPv6 header. That is, just as TCP or UDP \nprotocol headers can be the next header within an IP packet, so too can an \noptions field. The removal of the options field results in a fixed-length, 40-byte \nIP header.\n380     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\nTransitioning from IPv4 to IPv6\nNow that we have seen the technical details of IPv6, let us consider a very practi -\ncal matter: How will the public Internet, which is based on IPv4, be transitioned to \nIPv6? The problem is that while new IPv6-capable systems can be made backward-\ncompatible, that is, can send, route, and receive IPv4 datagrams, already deployed \nIPv4-capable systems are not capable of handling IPv6 datagrams. Several options \nare possible [Huston 2011b, RFC 4213].\nOne option would be to declare a flag day\u2014a given time and date when all \nInternet machines would be turned off and upgraded from IPv4 to IPv6. The last \nmajor technology transition (from using NCP to using TCP for reliable transport \nservice) occurred almost 35 years ago. Even back then [RFC 801], when the Internet \nwas tiny and still being administered by a small number of \u201cwizards,\u201d it was real -\nized that such a flag day was not possible. A flag day involving billions of devices \nis even more unthinkable today.\nThe approach to IPv4-to-IPv6 transition that has been most widely adopted in \npractice involves tunneling  [RFC 4213]. The basic idea behind tunneling \u2014a key \nconcept with applications in many other scenarios beyond IPv4-to-IPv6 transition, \nincluding wide use in the all-IP cellular networks that we\u2019ll cover in Chapter 7 \u2014is \nthe following. Suppose two IPv6 nodes (in this example, B and E in Figure 4.27) \nwant to interoperate using IPv6 datagrams but are connected to each other by inter -\nvening IPv4 routers. We refer to the intervening set of IPv4 routers between two \nIPv6 routers as a tunnel , as illustrated in Figure 4.27. With tunneling, the IPv6 node \non the sending side of the tunnel (in this example, B) takes the entire  IPv6 datagram \nand puts it in the data (payload) field of an IPv4 datagram. This IPv4 datagram is \nthen addressed to the", "doc_id": "8b9f12dc-9d81-48b8-acf6-ce3168fb8498", "embedding": null, "doc_hash": "4d123f97da374af99c264d79af7e9a26226aa164dd55a66ea0b2b5103b0da839", "extra_info": null, "node_info": {"start": 1110253, "end": 1113811}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "ff884cde-19af-46c7-8573-45ffe6430d74", "3": "cf1a7251-aff1-499d-851c-bd2588abf6f2"}}, "__type__": "1"}, "cf1a7251-aff1-499d-851c-bd2588abf6f2": {"__data__": {"text": "transition, \nincluding wide use in the all-IP cellular networks that we\u2019ll cover in Chapter 7 \u2014is \nthe following. Suppose two IPv6 nodes (in this example, B and E in Figure 4.27) \nwant to interoperate using IPv6 datagrams but are connected to each other by inter -\nvening IPv4 routers. We refer to the intervening set of IPv4 routers between two \nIPv6 routers as a tunnel , as illustrated in Figure 4.27. With tunneling, the IPv6 node \non the sending side of the tunnel (in this example, B) takes the entire  IPv6 datagram \nand puts it in the data (payload) field of an IPv4 datagram. This IPv4 datagram is \nthen addressed to the IPv6 node on the receiving side of the tunnel (in this exam -\nple, E) and sent to the first node in the tunnel (in this example, C). The intervening \nIPv4 routers in the tunnel route this IPv4 datagram among themselves, just as they \nwould any other datagram, blissfully unaware that the IPv4 datagram itself con -\ntains a complete IPv6 datagram. The IPv6 node on the receiving side of the tunnel \neventually receives the IPv4 datagram (it is the destination of the IPv4 datagram!), \ndetermines that the IPv4 datagram contains an IPv6 datagram (by observing that \nthe protocol number field in the IPv4 datagram is 41 [RFC 4213], indicating that \nthe IPv4 payload is a IPv6 datagram), extracts the IPv6 datagram, and then routes \nthe IPv6 datagram exactly as it would if it had received the IPv6 datagram from a \ndirectly connected IPv6 neighbor.\nWe end this section by noting that while the adoption of IPv6 was initially slow \nto take off [Lawton 2001; Huston 2008b], momentum has been building. NIST \n[NIST IPv6 2015] reports that more than a third of US government second-level \ndomains are IPv6-enabled. On the client side, Google reports that only about 8 per -\ncent of the clients accessing Google services do so via IPv6 [Google IPv6 2015]. But \nother recent measurements [Czyz 2014] indicate that IPv6 adoption is accelerating. \nThe proliferation of devices such as IP-enabled phones and other portable devices \n4.3  \u2022  THE INTERNET PROTOCOL (IP): IPV4, ADDRESSING, IPV6, AND MORE      381\nprovides an additional push for more widespread deployment of IPv6. Europe\u2019s \nThird Generation Partnership Program [3GPP 2016] has specified IPv6 as the stand -\nard addressing scheme for mobile multimedia.\nOne important lesson that we can learn from the IPv6 experience is that it is enor -\nmously difficult to change network-layer protocols. Since the early 1990s, numerous \nnew network-layer protocols have been trumpeted as the next major revolution for \nthe Internet, but most of these protocols have had limited penetration to date. These \nprotocols include IPv6, multicast protocols, and resource reservation protocols; a \ndiscussion of these latter two protocols can be found in the online supplement to \nthis text. Indeed, introducing new protocols into the network layer is like replac -\ning the foundation of a house\u2014it is difficult to do without tearing the whole house \ndown or at least temporarily relocating the house\u2019s residents. On the other hand, the \nInternet has witnessed rapid deployment of new protocols at the application layer. \nThe classic examples, of course, are the Web, instant messaging, streaming media, \ndistributed games, and various forms of social media. Introducing new application-\nlayer protocols is like adding a new layer of paint to a house\u2014it is relatively easy to \ndo, and if you choose an attractive color, others in the neighborhood will copy you. A B C D E FIPv6\nA to B:", "doc_id": "cf1a7251-aff1-499d-851c-bd2588abf6f2", "embedding": null, "doc_hash": "89029140ce33d25ce35a6a3dc9f61414fa34f8c1aa0c9c1270408cd05f5e8c95", "extra_info": null, "node_info": {"start": 1113909, "end": 1117453}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "8b9f12dc-9d81-48b8-acf6-ce3168fb8498", "3": "b379d463-bd9f-4646-bd6d-4b7f317fafea"}}, "__type__": "1"}, "b379d463-bd9f-4646-bd6d-4b7f317fafea": {"__data__": {"text": "can be found in the online supplement to \nthis text. Indeed, introducing new protocols into the network layer is like replac -\ning the foundation of a house\u2014it is difficult to do without tearing the whole house \ndown or at least temporarily relocating the house\u2019s residents. On the other hand, the \nInternet has witnessed rapid deployment of new protocols at the application layer. \nThe classic examples, of course, are the Web, instant messaging, streaming media, \ndistributed games, and various forms of social media. Introducing new application-\nlayer protocols is like adding a new layer of paint to a house\u2014it is relatively easy to \ndo, and if you choose an attractive color, others in the neighborhood will copy you. A B C D E FIPv6\nA to B: IPv6Physical view\nB to C: IPv4\n(encapsulating IPv6)D to E: IPv4\n(encapsulating IPv6)E to F: IPv6IPv6 IPv4 IPv4 IPv6 IPv6\nFlow: X\nSource: A\nDest: F\ndataSource: B\nDest: ESource: B\nDest: EA B E FIPv6Logical view\nIPv6\nTunnelIPv6 IPv6\nFlow: X\nSource: A\nDest: F\ndataFlow: X\nSource: A\nDest: F\ndataFlow: X\nSource: A\nDest: F\ndata\nFigure 4.27  \u2666 Tunneling\n382     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\nIn summary, in the future we can certainly expect to see changes in the Internet\u2019s \nnetwork layer, but these changes will likely occur on a time scale that is much slower \nthan the changes that will occur at the application layer.\n4.4 Generalized Forwarding and SDN\nIn Section 4.2.1, we noted that an Internet router\u2019s forwarding decision has tradition -\nally been based solely on a packet\u2019s destination address. In the previous section, \nhowever, we\u2019ve also seen that there has been a proliferation of middleboxes that \nperform many layer-3 functions. NAT boxes rewrite header IP addresses and port \nnumbers; firewalls block traffic based on  header-field values or redirect packets for \nadditional processing, such as deep packet inspection (DPI). Load-balancers forward \npackets requesting a given service (e.g., an HTTP request) to one of a set of a set of \nservers that provide that service. [RFC 3234] lists a number of common middlebox \nfunctions.\nThis proliferation of middleboxes, layer-2 switches, and layer-3 routers [Qazi \n2013]\u2014each with its own specialized hardware, software and management inter -\nfaces\u2014has undoubtedly resulted in costly headaches for many network operators. \nHowever, recent advances in software-defined networking have promised, and are \nnow delivering, a unified approach towards providing many of these network-layer \nfunctions, and certain link-layer functions as well, in a modern, elegant, and inte -\ngrated manner.\nRecall that Section 4.2.1 characterized destination-based forwarding as the two \nsteps of looking up a destination IP address (\u201cmatch\u201d), then sending the packet into \nthe switching fabric to the specified output port (\u201caction\u201d). Let\u2019s now consider a \nsignificantly more general \u201cmatch-plus-action\u201d paradigm, where the \u201cmatch\u201d can \nbe made over multiple header fields associated with different protocols at differ -\nent layers in the protocol stack. The \u201caction\u201d can include forwarding the packet to \none or more output ports (as in destination-based forwarding), load balancing pack -\nets across multiple outgoing interfaces that lead to a service (as in load balancing), \nrewriting header values (as in NAT), purposefully blocking/dropping a packet (as in \na firewall), sending a packet to a special server for further processing and action (as \nin DPI), and more.\nIn generalized forwarding, a match-plus-action table generalizes the", "doc_id": "b379d463-bd9f-4646-bd6d-4b7f317fafea", "embedding": null, "doc_hash": "99383c96d03e3b42bf8e9fd432ca6d3005d4499afac33a5fb5449a2f254e45ee", "extra_info": null, "node_info": {"start": 1117349, "end": 1120887}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "cf1a7251-aff1-499d-851c-bd2588abf6f2", "3": "6b7c1e5f-5a5e-46ac-8cca-6b398ccbecb8"}}, "__type__": "1"}, "6b7c1e5f-5a5e-46ac-8cca-6b398ccbecb8": {"__data__": {"text": "fabric to the specified output port (\u201caction\u201d). Let\u2019s now consider a \nsignificantly more general \u201cmatch-plus-action\u201d paradigm, where the \u201cmatch\u201d can \nbe made over multiple header fields associated with different protocols at differ -\nent layers in the protocol stack. The \u201caction\u201d can include forwarding the packet to \none or more output ports (as in destination-based forwarding), load balancing pack -\nets across multiple outgoing interfaces that lead to a service (as in load balancing), \nrewriting header values (as in NAT), purposefully blocking/dropping a packet (as in \na firewall), sending a packet to a special server for further processing and action (as \nin DPI), and more.\nIn generalized forwarding, a match-plus-action table generalizes the notion of \nthe destination-based forwarding table that we encountered in Section 4.2.1. Because \nforwarding decisions may be made using network-layer and/or link-layer source \nand destination addresses, the forwarding devices shown in Figure 4.28 are more \naccurately described as \u201cpacket switches\u201d rather than layer 3 \u201crouters\u201d or layer 2 \n\u201cswitches.\u201d Thus, in the remainder of this section, and in Section 5.5 , we\u2019ll refer \n4.4  \u2022  GENERALIZED FORWARDING AND SDN      383\nto these devices as packet switches, adopting the terminology that is gaining wide -\nspread adoption in SDN literature.\nFigure 4.28 shows a match-plus-action table in each packet switch, with the \ntable being computed, installed, and updated by a remote controller. We note that \nwhile it is possible for the control components at the individual packet switch to \ninteract with each other (e.g., in a manner similar to that in Figure 4.2), in practice \ngeneralized match-plus-action capabilities are implemented via a remote controller \nthat computes, installs, and updates these tables. You might take a minute to compare \nFigures 4.2, 4.3 and 4.28\u2014what similarities and differences do you notice between \ndestination-based forwarding shown in Figure 4.2 and 4.3, and generalized forward -\ning shown in Figure 4.28?1101 0100Remote Controller\nValues in arriving\npacket\u2019s header\n1\n23Local \ufb02ow table\n...\n...\n...\n......\n...\n...\n......\n...\n...\n...Header sCounters Action sContr ol plane\nData plane\nFigure 4.28  \u2666  Generalized forwarding: Each packet switch contains a match-plus-action  \ntable that is computed and distributed by a remote controller\n384     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\nOur following discussion of generalized forwarding will be based on OpenFlow \n[McKeown 2008, OpenFlow 2009, Casado 2014, Tourrilhes 2014]\u2014a highly vis -\nible and successful standard that has pioneered the notion of the match-plus-action \nforwarding abstraction and controllers, as well as the SDN revolution more gener -\nally [Feamster 2013]. We\u2019ll primarily consider OpenFlow 1.0, which introduced key \nSDN abstractions and functionality in a particularly clear and concise manner. Later \nversions of OpenFlow introduced additional capabilities as a result of experience \ngained through implementation and use; current and earlier versions of the Open -\nFlow standard can be found at [ONF 2016].\nEach entry in the match-plus-action forwarding table, known as a flow table  in \nOpenFlow, includes:\n\u2022 A set of header field values  to which an incoming packet will be matched. As in \nthe case of destination-based forwarding, hardware-based matching is most rap -\nidly performed in TCAM memory, with more than a million destination address \nentries being possible [Bosshart 2013]. A packet that matches no flow table entry \ncan be dropped or sent to the remote controller for more processing. In practice, \na flow table may be implemented by multiple flow tables for performance or cost \nreasons [Bosshart 2013], but we\u2019ll focus here on the abstraction", "doc_id": "6b7c1e5f-5a5e-46ac-8cca-6b398ccbecb8", "embedding": null, "doc_hash": "c0280836676570f0b39cb5ce685d8d5ee7d539454dba33c81d81990312843f45", "extra_info": null, "node_info": {"start": 1120867, "end": 1124647}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "b379d463-bd9f-4646-bd6d-4b7f317fafea", "3": "129fd2b5-7303-4ef2-8e88-4023188b95f1"}}, "__type__": "1"}, "129fd2b5-7303-4ef2-8e88-4023188b95f1": {"__data__": {"text": "a result of experience \ngained through implementation and use; current and earlier versions of the Open -\nFlow standard can be found at [ONF 2016].\nEach entry in the match-plus-action forwarding table, known as a flow table  in \nOpenFlow, includes:\n\u2022 A set of header field values  to which an incoming packet will be matched. As in \nthe case of destination-based forwarding, hardware-based matching is most rap -\nidly performed in TCAM memory, with more than a million destination address \nentries being possible [Bosshart 2013]. A packet that matches no flow table entry \ncan be dropped or sent to the remote controller for more processing. In practice, \na flow table may be implemented by multiple flow tables for performance or cost \nreasons [Bosshart 2013], but we\u2019ll focus here on the abstraction of a single flow \ntable.\n\u2022 A set of counters  that are updated as packets are matched to flow table entries. \nThese counters might include the number of packets that have been matched by \nthat table entry, and the time since the table entry was last updated.\n\u2022 A set of actions to be taken  when a packet matches a flow table entry. These \nactions might be to forward the packet to a given output port, to drop the packet, \nmakes copies of the packet and sent them to multiple output ports, and/or to \nrewrite selected header fields.\nWe\u2019ll explore matching and actions in more detail in Sections 4.4.1 and 4.4.2, \nrespectively. We\u2019ll then study how the network-wide collection of per-packet switch \nmatching rules can be used to implement a wide range of functions including routing, \nlayer-2 switching, firewalling, load-balancing, virtual networks, and more in Sec -\ntion\u00a04.4.3. In closing, we note that the flow table is essentially an API, the abstrac -\ntion through which an individual packet switch\u2019s behavior can be programmed; \nwe\u2019ll see in Section 4.4.3 that network-wide behaviors can similarly be programmed \nby appropriately programming/configuring these tables in a collection  of network \npacket switches [Casado 2014].\n4.4.1 Match\nFigure 4.29 shows the eleven packet-header fields and the incoming port ID \nthat can be matched in an OpenFlow 1.0 match-plus-action rule. Recall from \n4.4  \u2022  GENERALIZED FORWARDING AND SDN      385\nSection 1.5.2 that a link-layer (layer 2) frame arriving to a packet switch will \ncontain a network-layer (layer 3) datagram as its payload, which in turn will typi -\ncally contain a transport-layer (layer 4) segment. The first observation we make \nis that OpenFlow\u2019s match abstraction allows for a match to be made on selected \nfields from three  layers of protocol headers (thus rather brazenly defying the lay -\nering principle we studied in Section 1.5 ). Since we\u2019ve not yet covered the link \nlayer, suffice it to say that the source and destination MAC addresses shown in \nFigure 4.29 are the link-layer addresses associated with the frame\u2019s sending and \nreceiving interfaces; by forwarding on the basis of Ethernet addresses rather than \nIP addresses, we can see that an OpenFlow-enabled device can equally perform \nas a router (layer-3 device) forwarding datagrams as well as a switch (layer-2 \ndevice) forwarding frames. The Ethernet type field corresponds to the upper layer \nprotocol (e.g., IP) to which the frame\u2019s payload will be de-multiplexed, and the \nVLAN fields are concerned with so-called virtual local area networks that we\u2019ll \nstudy in Chapter 6. The set of twelve values that can be matched in the OpenFlow \n1.0 specification has grown to 41 values in more recent OpenFlow specifications \n[Bosshart 2014].\nThe ingress port refers to the input port at the packet switch on which a packet \nis received. The packet\u2019s IP source address, IP destination address, IP protocol field, \nand IP type of service fields were discussed earlier in", "doc_id": "129fd2b5-7303-4ef2-8e88-4023188b95f1", "embedding": null, "doc_hash": "8c2528640a3e7aa7a34998cd76effd3a5ff8aaf7bcdb87ed45256c41042572ec", "extra_info": null, "node_info": {"start": 1124619, "end": 1128422}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "6b7c1e5f-5a5e-46ac-8cca-6b398ccbecb8", "3": "60578cc4-704c-4ca6-8f55-4bf201db7097"}}, "__type__": "1"}, "60578cc4-704c-4ca6-8f55-4bf201db7097": {"__data__": {"text": "perform \nas a router (layer-3 device) forwarding datagrams as well as a switch (layer-2 \ndevice) forwarding frames. The Ethernet type field corresponds to the upper layer \nprotocol (e.g., IP) to which the frame\u2019s payload will be de-multiplexed, and the \nVLAN fields are concerned with so-called virtual local area networks that we\u2019ll \nstudy in Chapter 6. The set of twelve values that can be matched in the OpenFlow \n1.0 specification has grown to 41 values in more recent OpenFlow specifications \n[Bosshart 2014].\nThe ingress port refers to the input port at the packet switch on which a packet \nis received. The packet\u2019s IP source address, IP destination address, IP protocol field, \nand IP type of service fields were discussed earlier in Section 4.3.1. The transport-layer \nsource and destination port number fields can also be matched.\nFlow table entries may also have wildcards. For example, an IP address of \n128.119.*.* in a flow table will match the corresponding address field of any data -\ngram that has 128.119 as the first 16 bits of its address. Each flow table entry also has \nan associated priority. If a packet matches multiple flow table entries, the selected \nmatch and corresponding action will be that of the highest priority entry with which \nthe packet matches.\nLastly, we observe that not all fields in an IP header can be matched. For exam -\nple OpenFlow does not allow matching on the basis of TTL field or datagram length \nfield. Why are some fields allowed for matching, while others are not? Undoubtedly, \nthe answer has to do with the tradeoff between functionality and complexity. The \n\u201cart\u201d in choosing an abstraction is to provide for enough functionality to accomplish \na task (in this case to implement, configure, and manage a wide range of network-\nlayer functions that had previously been implemented through an assortment of Ingress\nPortSrc\nMACDst\nMACEth\nTypeVLAN\nIDVLAN\nPriIP Src IP DstIP\nProtoIP\nTOSTCP/UDP\nSrc PortTCP/UDP\nDst Port\nTransport layer Network layer Link layer\nFigure 4.29  \u2666 Packet matching fields, OpenFlow 1.0 flow table\n386     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\nnetwork-layer devices), without over-burdening the abstraction with so much detail \nand generality that it becomes bloated and unusable. Butler Lampson has famously \nnoted [Lampson 1983]:\nDo one thing at a time, and do it well. An interface should capture the minimum \nessentials of an abstraction. Don\u2019t generalize; generalizations are generally \nwrong.\nGiven OpenFlow\u2019s success, one can surmise that its designers indeed chose their \nabstraction well. Additional details of OpenFlow matching can be found in [Open -\nFlow 2009, ONF 2016].\n4.4.2  Action\nAs shown in Figure 4.28, each flow table entry has a list of zero or more actions \nthat determine the processing that is to be applied to a packet that matches a flow \ntable entry. If there are multiple actions, they are performed in the order specified \nin the list.\nAmong the most important possible actions are:\n\u2022 Forwarding.  An incoming packet may be forwarded to a particular physical out -\nput port, broadcast over all ports (except the port on which it arrived) or multi -\ncast over a selected set of ports. The packet may be encapsulated and sent to the \nremote controller for this device. That controller then may (or may not) take some \naction on that packet, including installing new flow table entries, and may return \nthe packet to the device for forwarding under the updated set of flow table rules.\n\u2022 Dropping.  A flow table entry with no action indicates that a matched packet \nshould be dropped.\n\u2022 Modify-field.  The values in ten packet header fields (all layer 2, 3, and 4 fields \nshown in Figure 4.29 except the IP Protocol field) may be re-written before the \npacket is forwarded to the chosen output", "doc_id": "60578cc4-704c-4ca6-8f55-4bf201db7097", "embedding": null, "doc_hash": "6c63663d921be7d0fe995b035dcaa4973fc12cf6855a7057e699a03bbb2cb594", "extra_info": null, "node_info": {"start": 1128473, "end": 1132281}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "129fd2b5-7303-4ef2-8e88-4023188b95f1", "3": "e99503c1-6258-418f-b37c-33300194f0ff"}}, "__type__": "1"}, "e99503c1-6258-418f-b37c-33300194f0ff": {"__data__": {"text": " An incoming packet may be forwarded to a particular physical out -\nput port, broadcast over all ports (except the port on which it arrived) or multi -\ncast over a selected set of ports. The packet may be encapsulated and sent to the \nremote controller for this device. That controller then may (or may not) take some \naction on that packet, including installing new flow table entries, and may return \nthe packet to the device for forwarding under the updated set of flow table rules.\n\u2022 Dropping.  A flow table entry with no action indicates that a matched packet \nshould be dropped.\n\u2022 Modify-field.  The values in ten packet header fields (all layer 2, 3, and 4 fields \nshown in Figure 4.29 except the IP Protocol field) may be re-written before the \npacket is forwarded to the chosen output port.\n4.4.3  OpenFlow Examples of Match-plus-action in Action\nHaving now considered both the match and action components of generalized \nforwarding, let\u2019s put these ideas together in the context of the sample network \nshown in Figure 4.30. The network has 6 hosts (h1, h2, h3, h4, h5 and h6) and \nthree packet switches (s1, s2 and s3), each with four local interfaces (numbered \n1 through 4). We\u2019ll consider a number of network-wide behaviors that we\u2019d like \nto implement, and the flow table entries in s1, s2 and s3 needed to implement this \nbehavior.\n4.4  \u2022  GENERALIZED FORWARDING AND SDN      387\nA First Example: Simple Forwarding\nAs a very simple example, suppose that the desired forwarding behavior is that  \npackets from h5 or h6 destined to h3 or h4 are to be forwarded from s3 to s1, and then \nfrom s1 to s2 (thus completely avoiding the use of the link between s3 and s2). The \nflow table entry in s1 would be:\ns1 Flow Table (Example 1)\nMatch Action\nIngress Port = 1 ; IP Src = 10.3.*.* ; IP Dst = 10.2.*.* Forward(4)\n\u2026 \u2026\nOf course, we\u2019ll also need a flow table entry in s3 so that datagrams sent from \nh5 or h6 are forwarded to s1 over outgoing interface 3:\ns3 Flow Table (Example 1)\nMatch Action\nIP Src = 10.3.*.* ; IP Dst = 10.2.*.* Forward(3)\n\u2026 \u20261\n4\ns3s3\ns1s2\n231\n234Host h6\n10.3.0.6OpenFlow controller\nHost h5\n10.3.0.5\nHost h1\n10.1.0.1Host h2\n10.1.0.2Host h3\n10.2.0.3Host h4\n10.2.0.4\n1\n4\n23\nFigure 4.30  \u2666  OpenFlow match-plus-action network with three packet \nswitches, 6 hosts, and an OpenFlow controller\n388     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\nLastly, we\u2019ll also need a flow table entry in s2 to complete this first example, so \nthat datagrams arriving from s1 are forwarded to their destination, either host h3 or h4:\ns2 Flow Table (Example 1)\nMatch Action\nIngress port = 2 ; IP Dst = 10.2.0.3 Forward(3)\nIngress port = 2 ; IP Dst = 10.2.0.4 Forward(4)\n\u2026 \u2026\nA Second Example: Load Balancing\nAs a second example, let\u2019s consider a load-balancing scenario, where datagrams from \nh3 destined to 10.1.*.* are to be forwarded over the direct link between s2 and s1, while \ndatagrams from h4 destined to 10.1.*.* are to be forwarded over the link between s2 \nand s3 (and then from s3 to s1). Note that this behavior couldn\u2019t be achieved with IP\u2019s \ndestination-based forwarding. In this case, the flow table in s2 would be:\ns2 Flow Table (Example 2)\nMatch Action\nIngress", "doc_id": "e99503c1-6258-418f-b37c-33300194f0ff", "embedding": null, "doc_hash": "16a20afc4d270ee92380d3d77fb11094cb431fe1059e596f6acb519bdedbb775", "extra_info": null, "node_info": {"start": 1132250, "end": 1135441}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "60578cc4-704c-4ca6-8f55-4bf201db7097", "3": "53759cbd-2dda-443a-850f-7bff5abcaa6b"}}, "__type__": "1"}, "53759cbd-2dda-443a-850f-7bff5abcaa6b": {"__data__": {"text": "port = 2 ; IP Dst = 10.2.0.3 Forward(3)\nIngress port = 2 ; IP Dst = 10.2.0.4 Forward(4)\n\u2026 \u2026\nA Second Example: Load Balancing\nAs a second example, let\u2019s consider a load-balancing scenario, where datagrams from \nh3 destined to 10.1.*.* are to be forwarded over the direct link between s2 and s1, while \ndatagrams from h4 destined to 10.1.*.* are to be forwarded over the link between s2 \nand s3 (and then from s3 to s1). Note that this behavior couldn\u2019t be achieved with IP\u2019s \ndestination-based forwarding. In this case, the flow table in s2 would be:\ns2 Flow Table (Example 2)\nMatch Action\nIngress port = 3; IP Dst = 10.1.*.* Forward(2)\nIngress port = 4; IP Dst = 10.1.*.* Forward(1)\n\u2026 \u2026\nFlow table entries are also needed at s1 to forward the datagrams received from \ns2 to either h1 or h2; and flow table entries are needed at s3 to forward datagrams \nreceived on interface 4 from s2 over interface 3 towards s1. See if you can figure out \nthese flow table entries at s1 and s3.\nA Third Example: Firewalling\nAs a third example, let\u2019s consider a firewall scenario in which s2 wants only to \nreceive (on any of its interfaces) traffic sent from hosts attached to s3.\ns2 Flow Table (Example 3)\nMatch Action\nIP Src = 10.3.*.* IP Dst = 10.2.0.3 Forward(3)\nIP Src = 10.3.*.* IP Dst = 10.2.0.4 Forward(4)\n\u2026 \u2026\nHOMEWORK PROBLEMS AND QUESTIONS      389\nIf there were no other entries in s2\u2019s flow table, then only traffic from 10.3.*.* would \nbe forwarded to the hosts attached to s2.\nAlthough we\u2019ve only considered a few basic scenarios here, the versatility and \nadvantages of generalized forwarding are hopefully apparent. In homework prob -\nlems, we\u2019ll explore how flow tables can be used to create many different logical \nbehaviors, including virtual networks\u2014two or more logically separate networks \n(each with their own independent and distinct forwarding behavior)\u2014that use the \nsame  physical set of packet switches and links. In Section 5.5, we\u2019ll return to flow \ntables when we study the SDN controllers that compute and distribute the flow tables, \nand the protocol used for communicating between a packet switch and its controller.\n4.5 Summary\nIn this chapter we\u2019ve covered the data plane  functions of the network layer\u2014the per-\nrouter  functions that determine how packets arriving on one of a router\u2019s input links \nare forwarded to one of that router\u2019s output links. We began by taking a detailed look \nat the internal operations of a router, studying input and output port functionality and \ndestination-based forwarding, a router\u2019s internal switching mechanism, packet queue \nmanagement and more. We covered both traditional IP forwarding (where forward -\ning is based on a datagram\u2019s destination address) and generalized forwarding (where \nforwarding and other functions may be performed using values in several different \nfields in the datagram\u2019s header) and seen the versatility of the latter approach. \u00a0We \nalso studied the IPv4 and IPv6 protocols in detail, and Internet addressing, which we \nfound to be much deeper, subtler, and more interesting than we might have expected.\nWith our newfound understanding of the network-layer\u2019s data plane, we\u2019re now \nready to dive into the network layer\u2019s control plane in Chapter 5!\nHomework Problems and Questions\nChapter 4 Review Questions\nSECTION 4.1\n R1. Let\u2019s review some of the terminology used in this textbook. Recall that the \nname of a transport-layer packet is segment  and that the name of a link-layer \npacket is frame", "doc_id": "53759cbd-2dda-443a-850f-7bff5abcaa6b", "embedding": null, "doc_hash": "0eb24819bf0d6505a44cec386bc9ff4552df0fd4c716bd0f3dc575808fe5399f", "extra_info": null, "node_info": {"start": 1135600, "end": 1139084}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "e99503c1-6258-418f-b37c-33300194f0ff", "3": "49e40527-d8ee-4e4e-9f4d-035ab994fbee"}}, "__type__": "1"}, "49e40527-d8ee-4e4e-9f4d-035ab994fbee": {"__data__": {"text": "\nforwarding and other functions may be performed using values in several different \nfields in the datagram\u2019s header) and seen the versatility of the latter approach. \u00a0We \nalso studied the IPv4 and IPv6 protocols in detail, and Internet addressing, which we \nfound to be much deeper, subtler, and more interesting than we might have expected.\nWith our newfound understanding of the network-layer\u2019s data plane, we\u2019re now \nready to dive into the network layer\u2019s control plane in Chapter 5!\nHomework Problems and Questions\nChapter 4 Review Questions\nSECTION 4.1\n R1. Let\u2019s review some of the terminology used in this textbook. Recall that the \nname of a transport-layer packet is segment  and that the name of a link-layer \npacket is frame . What is the name of a network-layer packet? Recall that both \nrouters and link-layer switches are called packet switches . What is the funda-\nmental difference between a router and link-layer switch?\n R2. We noted that network layer functionality can be broadly divided into  \ndata plane functionality and control plane functionality. What are the main \nfunctions of the data plane? Of the control plane?\n390     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\n R3. We made a distinction between the forwarding function and the routing func-\ntion performed in the network layer. What are the key differences between \nrouting and forwarding?\n R4. What is the role of the forwarding table within a router?\n R5. We said that a network layer\u2019s service model \u201cdefines the characteristics of \nend-to-end transport of packets between sending and receiving hosts.\u201d What is \nthe service model of the Internet\u2019s network layer? What guarantees are made by \nthe Internet\u2019s service model regarding the host-to-host delivery of datagrams?\nSECTION 4.2\n R6. In Section 4.2, we saw that a router typically consists of input ports, output \nports, a switching fabric and a routing processor. Which of these are imple-\nmented in hardware and which are implemented in software? Why? Return-\ning to the notion of the network layer\u2019s data plane and control plane, which \nare implemented in hardware and which are implemented in software? Why?\n R7. What does each input port of a high speed router store to facilitate fast for-\nwarding decisions?\n R8. What is meant by destination-based forwarding? How does this differ from \ngeneralized forwarding (assuming you\u2019ve read Section 4.4, which of the two \napproaches are adopted by Software-Defined Networking)?\n R9. Suppose that an arriving packet matches two or more entries in a router\u2019s \nforwarding table. With traditional destination-based forwarding, what rule \ndoes a router apply to determine which of these rules should be applied to \ndetermine the output port to which the arriving packet should be switched?\n R10. Switching in a router forwards data from an input port to an output port. \nWhat is the advantage of switching via an interconnection network over \nswitching via memory and switching via bus?\n R11. What is the role of a packet scheduler  at the output port of a router?\n R12. What is a drop-tail policy? What are AQM algorithms? Which is the most \nwidely studied and implemented AQM algorithm? How does it work?\n R13. What is HOL blocking? Does it occur in input ports or output ports?\n R14. In Section 4.2, we studied FIFO, Priority, Round Robin (RR), and Weighted \nFair Queueing (WFQ) packet scheduling disciplines? Which of these queueing \ndisciplines ensure that all packets depart in the order in which they arrived?\n R15. Give an example showing why a network operator might want one class of \npackets to be given priority over another class of packets.\n R16. What is an essential different between RR and WFQ packet scheduling? Is \nthere a case (", "doc_id": "49e40527-d8ee-4e4e-9f4d-035ab994fbee", "embedding": null, "doc_hash": "c468848e1fbf3dc0a6d581583cb38a9084cace744d230a924a99c7acec17ca8e", "extra_info": null, "node_info": {"start": 1138961, "end": 1142697}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "53759cbd-2dda-443a-850f-7bff5abcaa6b", "3": "f96b1224-440e-43e3-86db-02b1b2094b19"}}, "__type__": "1"}, "f96b1224-440e-43e3-86db-02b1b2094b19": {"__data__": {"text": "of a router?\n R12. What is a drop-tail policy? What are AQM algorithms? Which is the most \nwidely studied and implemented AQM algorithm? How does it work?\n R13. What is HOL blocking? Does it occur in input ports or output ports?\n R14. In Section 4.2, we studied FIFO, Priority, Round Robin (RR), and Weighted \nFair Queueing (WFQ) packet scheduling disciplines? Which of these queueing \ndisciplines ensure that all packets depart in the order in which they arrived?\n R15. Give an example showing why a network operator might want one class of \npackets to be given priority over another class of packets.\n R16. What is an essential different between RR and WFQ packet scheduling? Is \nthere a case ( Hint:  Consider the WFQ weights) where RR and WFQ will \nbehave exactly the same?\nHOMEWORK PROBLEMS AND QUESTIONS      391\nSECTION 4.3\n R17. Suppose Host A sends Host B a TCP segment encapsulated in an IP data-\ngram. When Host B receives the datagram, how does the network layer in \nHost B know it should pass the segment (that is, the payload of the datagram) \nto TCP rather than to UDP or to some other upper-layer protocol?\n R18. What field in the IP header can be used to ensure that a packet is forwarded \nthrough no more than N routers?\n R19. Recall that we saw the Internet checksum being used in both transport-layer \nsegment (in UDP and TCP headers, Figures 3.7 and 3.29 respectively) and in \nnetwork-layer datagrams (IP header, Figure 4.16). Now consider a transport \nlayer segment encapsulated in an IP datagram. Are the checksums in the seg-\nment header and datagram header computed over any common bytes in the IP \ndatagram? Explain your answer.\n R20. When a large datagram is fragmented into multiple smaller datagrams, where \nare these smaller datagrams reassembled into a single larger datagram?\n R21. A router has eight interfaces. How many IP addresses will it have?\n R22. What is the 32-bit binary equivalent of the IP address 202.3.14.25?\n R23. Visit a host that uses DHCP to obtain its IP address, network mask, default \nrouter, and IP address of its local DNS server. List these values.\n R24. Suppose there are four routers between a source host and a destination host. \nIgnoring fragmentation, an IP datagram sent from the source host to the \ndestination host will travel over how many interfaces? How many forward -\ning tables will be indexed to move the datagram from the source to the \ndestination?\n R25. Suppose an application generates chunks of 40 bytes of data every 20 msec, \nand each chunk gets encapsulated in a TCP segment and then an IP datagram. \nWhat percentage of each datagram will be overhead, and what percentage \nwill be application data?\n R26. Suppose you purchase a wireless router and connect it to your cable modem. \nAlso suppose that your ISP dynamically assigns your connected device (that \nis, your wireless router) one IP address. Also suppose that you have five PCs \nat home that use 802.11 to wirelessly connect to your wireless router. How \nare IP addresses assigned to the five PCs? Does the wireless router use NAT? \nWhy or why not?\n R27. What is meant by the term \u201croute aggregation\u201d? Why is it useful for a router \nto perform route aggregation?\n R28. What is meant by a \u201cplug-and-play\u201d or \u201czeroconf\u201d protocol?\n R29. What is a private network address? Should a datagram with a private network \naddress ever be present in the larger public Internet? Explain.\n392     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\n R30. Compare and contrast the IPv4 and the IPv6 header fields. Do they have any \nfields in common?\n R31. It", "doc_id": "f96b1224-440e-43e3-86db-02b1b2094b19", "embedding": null, "doc_hash": "0bcf2ec9a451febb24e6ef132c04755fc74256b7645adfcdcfa3843c09d45db3", "extra_info": null, "node_info": {"start": 1142740, "end": 1146313}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "49e40527-d8ee-4e4e-9f4d-035ab994fbee", "3": "b1a31f8f-4b84-46d5-b006-8f268500012d"}}, "__type__": "1"}, "b1a31f8f-4b84-46d5-b006-8f268500012d": {"__data__": {"text": "wirelessly connect to your wireless router. How \nare IP addresses assigned to the five PCs? Does the wireless router use NAT? \nWhy or why not?\n R27. What is meant by the term \u201croute aggregation\u201d? Why is it useful for a router \nto perform route aggregation?\n R28. What is meant by a \u201cplug-and-play\u201d or \u201czeroconf\u201d protocol?\n R29. What is a private network address? Should a datagram with a private network \naddress ever be present in the larger public Internet? Explain.\n392     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\n R30. Compare and contrast the IPv4 and the IPv6 header fields. Do they have any \nfields in common?\n R31. It has been said that when IPv6 tunnels through IPv4 routers, IPv6 treats the \nIPv4 tunnels as link-layer protocols. Do you agree with this statement? Why \nor why not?\nSECTION 4.4\n R32. How does generalized forwarding differ from destination-based \n forwarding?\n R33. What is the difference between a forwarding table that we encountered in \ndestination-based forwarding in Section 4.1 and OpenFlow\u2019s flow table that \nwe encountered in Section 4.4?\n R34. What is meant by the \u201cmatch plus action\u201d operation of a router or switch? In \nthe case of destination-based forwarding packet switch, what is matched and \nwhat is the action taken? In the case of an SDN, name three fields that can be \nmatched, and three actions that can be taken. \n R35. Name three header fields in an IP datagram that can be \u201cmatched\u201d in Open-\nFlow 1.0 generalized forwarding. What are three IP datagram header fields \nthat cannot  be \u201cmatched\u201d in OpenFlow?\nProblems\n P1. Consider the network below.\na. Show the forwarding table in router A, such that all traffic destined to host \nH3 is forwarded through interface 3.\nb. Can you write down a forwarding table in router A, such that all traffic \nfrom H1 destined to host H3 is forwarded through interface 3, while all \ntraffic from H2 destined to host H3 is forwarded through interface 4? \n(Hint:  This is a trick question.)\nB\nA13\n242\nD1\n23\nH3H1\nH21\n12\nC\nPROBLEMS      393\n P2. Suppose two packets arrive to two different input ports of a router at exactly \nthe same time. Also suppose there are no other packets anywhere in the \nrouter.\na. Suppose the two packets are to be forwarded to two different output ports. \nIs it possible to forward the two packets through the switch fabric at the \nsame time when the fabric uses a shared bus?\nb. Suppose the two packets are to be forwarded to two different output ports. \nIs it possible to forward the two packets through the switch fabric at the \nsame time when the fabric uses switching via memory?\nc. Suppose the two packets are to be forwarded to the same output port. Is it \npossible to forward the two packets through the switch fabric at the same \ntime when the fabric uses a crossbar?\n P3. In Section 4.2, we noted that the maximum queuing delay is (n\u20131)D  if the \nswitching fabric is n times faster than the input line rates. Suppose that all \npackets are of the same length, n packets arrive at the same time to the n \ninput ports, and all n packets want to be forwarded to different output ports. \nWhat is the maximum delay for a packet for the (a) memory, (b) bus, and  \n(c) crossbar switching fabrics?\n P4. Consider the switch shown below. Suppose that all datagrams have the same \nfixed length, that the switch operates in a slotted, synchronous manner, \nand that in one time slot a datagram can be transferred from an input port \nto an output port. The switch fabric is a crossbar so that at most one data -\ngram can be transferred to a given", "doc_id": "b1a31f8f-4b84-46d5-b006-8f268500012d", "embedding": null, "doc_hash": "5a8ced200a8b0694d5608d34f10495e8498fabe7554f81e9e31122816d20232f", "extra_info": null, "node_info": {"start": 1146372, "end": 1149927}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "f96b1224-440e-43e3-86db-02b1b2094b19", "3": "a893787f-f92f-4e73-8329-9e632c9b992c"}}, "__type__": "1"}, "a893787f-f92f-4e73-8329-9e632c9b992c": {"__data__": {"text": "that the maximum queuing delay is (n\u20131)D  if the \nswitching fabric is n times faster than the input line rates. Suppose that all \npackets are of the same length, n packets arrive at the same time to the n \ninput ports, and all n packets want to be forwarded to different output ports. \nWhat is the maximum delay for a packet for the (a) memory, (b) bus, and  \n(c) crossbar switching fabrics?\n P4. Consider the switch shown below. Suppose that all datagrams have the same \nfixed length, that the switch operates in a slotted, synchronous manner, \nand that in one time slot a datagram can be transferred from an input port \nto an output port. The switch fabric is a crossbar so that at most one data -\ngram can be transferred to a given output port in a time slot, but different \noutput ports can receive datagrams from different input ports in a single \ntime slot. What is the minimal number of time slots needed to transfer \nthe packets shown from input ports to their output ports, assuming any \ninput queue scheduling order you want (i.e., it need not have HOL block -\ning)? What is the largest number of slots needed, assuming the worst-case \nscheduling order you can devise, assuming that a non-empty input queue is \nnever idle?\nXYSwitch\nfabricOutput port X\nOutput port Y\nOutput port ZX\nYZ\n394     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\n P5. Consider a datagram network using 32-bit host addresses. Suppose a router \nhas four links, numbered 0 through 3, and packets are to be forwarded to the \nlink interfaces as follows:\n Destination Address Range Link Interface\n 11100000 00000000 00000000 00000000\n through 0\n 11100000 00000000 11111111 11111111\n 11100000 00000001 00000000 00000000\n through 1\n 11100000 00000001 11111111 11111111\n 11100000 00000010 00000000 00000000\n through 2\n 11100001 11111111 11111111 11111111\n otherwise 3\na. Provide a forwarding table that has five entries, uses longest prefix match-\ning, and forwards packets to the correct link interfaces.\nb. Describe how your forwarding table determines the appropriate link inter-\nface for datagrams with destination addresses:\n 11111000 10010001 01010001 01010101\n 11100000 00000000 11000011 00111100\n 11100001 10000000 00010001 01110111\n P6. Consider a datagram network using 8-bit host addresses. Suppose a router \nuses longest prefix matching and has the following forwarding table:\nPrefix Match Interface\n 00 0\n 01 1\n100 2\notherwise 3\n  For each of the four interfaces, give the associated range of destination host \naddresses and the number of addresses in the range.\nPROBLEMS      395\n P7. Consider a datagram network using 8-bit host addresses. Suppose a router \nuses longest prefix matching and has the following forwarding table:\nPrefix Match Interface\n 11 0\n101 1\n100 2\notherwise 3\n  For each of the four interfaces, give the associated range of destination host \naddresses and the number of addresses in the range.\n P8. Consider a router that interconnects three subnets: Subnet 1, Subnet 2, and  \nSubnet 3. Suppose all of the interfaces in each of these three subnets are \nrequired to have the prefix 223.1.17/24. Also suppose that Subnet 1 is required \nto support up to 62 interfaces, Subnet 2 is to support up to 106\u00a0interfaces, and \nSubnet 3 is to support up to 15 interfaces. Provide three network addresses \n(of the form a.b.c.d/x) that satisfy these constraints.\n P9. Suppose there are 35 hosts in a subnet. What should the IP address structure \nlook like?\n P10. What is the problem of NAT in P2P applications? How can it be avoided? Is \nthere a special name for this solution?\n P11. Consider a subnet with prefix 192.168.56.128/26. Give an example of one \nIP address (of form xxx.xxx.xxx.xxx) that can be assigned to this network.", "doc_id": "a893787f-f92f-4e73-8329-9e632c9b992c", "embedding": null, "doc_hash": "9a054b34c9cbcd72d618672438e6f65ca565f34e9b4859e52f5f52848bddd1b4", "extra_info": null, "node_info": {"start": 1149850, "end": 1153579}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "b1a31f8f-4b84-46d5-b006-8f268500012d", "3": "1471d869-01b7-4e61-b385-d176f1aeaaae"}}, "__type__": "1"}, "1471d869-01b7-4e61-b385-d176f1aeaaae": {"__data__": {"text": "\nrequired to have the prefix 223.1.17/24. Also suppose that Subnet 1 is required \nto support up to 62 interfaces, Subnet 2 is to support up to 106\u00a0interfaces, and \nSubnet 3 is to support up to 15 interfaces. Provide three network addresses \n(of the form a.b.c.d/x) that satisfy these constraints.\n P9. Suppose there are 35 hosts in a subnet. What should the IP address structure \nlook like?\n P10. What is the problem of NAT in P2P applications? How can it be avoided? Is \nthere a special name for this solution?\n P11. Consider a subnet with prefix 192.168.56.128/26. Give an example of one \nIP address (of form xxx.xxx.xxx.xxx) that can be assigned to this network. \nSuppose an ISP owns the block of addresses of the form 192.168.56.32/26. \nSuppose it wants to create four subnets from this block, with each block \nhaving the same number of IP addresses. What are the prefixes (of form \na.b.c.d/x) for the four subnets?\n P12. Consider the topology shown in Figure 4.20. Denote the three subnets with \nhosts (starting clockwise at 12:00) as Networks A, B, and C. Denote the  \nsubnets without hosts as Networks D, E, and F.\na. Assign network addresses to each of these six subnets, with the following \nconstraints: All addresses must be allocated from 214.97.254/23; Subnet A \nshould have enough addresses to support 250 interfaces; Subnet B should \nhave enough addresses to support 120 interfaces; and Subnet C should \n396     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\nhave enough addresses to support 120 interfaces. Of course, subnets D, E \nand F should each be able to support two interfaces. For each subnet, the \nassignment should take the form a.b.c.d/x or a.b.c.d/x \u2013 e.f.g.h/y.\nb. Using your answer to part (a), provide the forwarding tables (using long-\nest prefix matching) for each of the three routers.\n P13. IPsec has been designed to be backward compatible with IPv4 and IPv6. In \nparticular, in order to reap the benefits of IPsec, we don\u2019t need to replace the \nprotocol stacks in all the routers and hosts in the Internet. For example, using \nthe transport mode (one of two IPsec \u201cmodes\u201d), if two hosts want to securely \ncommunicate, IPsec needs to be available only in those two hosts. Discuss \nthe services provided by an IPsec session.\n P14. Consider sending a 1,600-byte datagram into a link that has an MTU of \n500 bytes. Suppose the original datagram is stamped with the identification \nnumber 291. How many fragments are generated? What are the values in the \nvarious fields in the IP datagram(s) generated related to fragmentation?\n P15. Suppose datagrams are limited to 1,500 bytes (including header) between \nsource Host A and destination Host B. Assuming a 20-byte IP header, how \nmany datagrams would be required to send an MP3 consisting of 5 million \nbytes? Explain how you computed your answer.\n P16. Consider the network setup in Figure 4.25. Suppose that the ISP instead \nassigns the router the address 24.34.112.235 and that the network address  \nof the home network is 192.168.1/24.\na. Assign addresses to all interfaces in the home network.\nb. Suppose each host has two ongoing TCP connections, all to port 80 at \nhost 128.119.40.86. Provide the six corresponding entries in the NAT \ntranslation table.\n P17. Suppose you are interested in detecting the number of hosts behind a NAT. \nYou observe that the IP layer stamps an identification number sequentially on \neach IP packet. The identification number of the first IP packet generated by \na host is a random number, and the identification numbers of the", "doc_id": "1471d869-01b7-4e61-b385-d176f1aeaaae", "embedding": null, "doc_hash": "285895afd5b033b94a2befb364505d1edc92f37fa65fb59d6ed7f959d10524c5", "extra_info": null, "node_info": {"start": 1153626, "end": 1157172}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "a893787f-f92f-4e73-8329-9e632c9b992c", "3": "dcf44d07-ee10-4727-8a40-887ea679802e"}}, "__type__": "1"}, "dcf44d07-ee10-4727-8a40-887ea679802e": {"__data__": {"text": "you computed your answer.\n P16. Consider the network setup in Figure 4.25. Suppose that the ISP instead \nassigns the router the address 24.34.112.235 and that the network address  \nof the home network is 192.168.1/24.\na. Assign addresses to all interfaces in the home network.\nb. Suppose each host has two ongoing TCP connections, all to port 80 at \nhost 128.119.40.86. Provide the six corresponding entries in the NAT \ntranslation table.\n P17. Suppose you are interested in detecting the number of hosts behind a NAT. \nYou observe that the IP layer stamps an identification number sequentially on \neach IP packet. The identification number of the first IP packet generated by \na host is a random number, and the identification numbers of the subsequent \nIP packets are sequentially assigned. Assume all IP packets generated by \nhosts behind the NAT are sent to the outside world.\na. Based on this observation, and assuming you can sniff all packets sent by \nthe NAT to the outside, can you outline a simple technique that detects the \nnumber of unique hosts behind a NAT? Justify your answer.\nb. If the identification numbers are not sequentially assigned but randomly \nassigned, would your technique work? Justify your answer.\n P18. In this problem we\u2019ll explore the impact of NATs on P2P applications. \nSuppose a peer with username Arnold discovers through querying that a \npeer with username Bernard has a file it wants to download. Also suppose \nPROBLEMS      397\nthat Bernard and Arnold are both behind a NAT. Try to devise a technique \nthat will allow Arnold to establish a TCP connection with Bernard without \napplication-specific NAT configuration. If you have difficulty devising such \na technique, discuss why.\n P19. Consider the SDN OpenFlow network shown in Figure 4.30. Suppose that \nthe desired forwarding behavior for datagrams arriving at s2 is as follows:\n\u2022 any datagrams arriving on input port 1 from hosts h5 or h6 that are des-\ntined to hosts h1 or h2 should be forwarded over output port 2;\n\u2022 any datagrams arriving on input port 2 from hosts h1 or h2 that are des-\ntined to hosts h5 or h6 should be forwarded over output port 1;\n\u2022 any arriving datagrams on input ports 1 or 2 and destined to hosts h3 or h4 \nshould be delivered to the host specified;\n\u2022 hosts h3 and h4 should be able to send datagrams to each other.\nSpecify the flow table entries in s2 that implement this forwarding behavior.\n P20. Consider again the SDN OpenFlow network shown in Figure 4.30. Suppose \nthat the desired forwarding behavior for datagrams arriving from hosts h3 or \nh4 at s2 is as follows:\n\u2022 any datagrams arriving from host h3 and destined for h1, h2, h5 or h6 \nshould be forwarded in a clockwise direction in the network;\n\u2022 any datagrams arriving from host h4 and destined for h1, h2, h5 or h6 \nshould be forwarded in a counter-clockwise direction in the network.\nSpecify the flow table entries in s2 that implement this forwarding behavior.\n P21. Consider again the scenario from P19 above. Give the flow tables entries at \npacket switches s1 and s3, such that any arriving datagrams with a source \naddress of h3 or h4 are routed to the destination hosts specified in the desti-\nnation address field in the IP datagram. ( Hint:  Your forwarding table rules \nshould include the cases that an arriving datagram is destined for a directly \nattached host or should be forwarded to a neighboring router for eventual \nhost delivery there.)\n P22. Consider again the SDN OpenFlow network shown in Figure 4.30. Suppose \nwe want switch s2 to function as a firewall. Specify the flow table in s2 that \nimplements the following firewall behaviors (specify a different flow table \nfor each of", "doc_id": "dcf44d07-ee10-4727-8a40-887ea679802e", "embedding": null, "doc_hash": "fdfb9e58a8916d9cb35f1b886e924c41335b37e62b663bb762bb02648e6d2c39", "extra_info": null, "node_info": {"start": 1157103, "end": 1160792}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "1471d869-01b7-4e61-b385-d176f1aeaaae", "3": "df9867de-8d7a-4f4c-991f-baa6e6371e16"}}, "__type__": "1"}, "df9867de-8d7a-4f4c-991f-baa6e6371e16": {"__data__": {"text": "P21. Consider again the scenario from P19 above. Give the flow tables entries at \npacket switches s1 and s3, such that any arriving datagrams with a source \naddress of h3 or h4 are routed to the destination hosts specified in the desti-\nnation address field in the IP datagram. ( Hint:  Your forwarding table rules \nshould include the cases that an arriving datagram is destined for a directly \nattached host or should be forwarded to a neighboring router for eventual \nhost delivery there.)\n P22. Consider again the SDN OpenFlow network shown in Figure 4.30. Suppose \nwe want switch s2 to function as a firewall. Specify the flow table in s2 that \nimplements the following firewall behaviors (specify a different flow table \nfor each of the four firewalling behaviors below) for delivery of datagrams \ndestined to h3 and h4. You do not need to specify the forwarding behavior in \ns2 that forwards traffic to other routers.\n\u2022 Only traffic arriving from hosts h1 and h6 should be delivered to hosts h3 \nor h4 (i.e., that arriving traffic from hosts h2 and h5 is blocked).\n\u2022 Only TCP traffic is allowed to be delivered to hosts h3 or h4 (i.e., that \nUDP traffic is blocked).\n398     CHAPTER 4 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: DATA PLANE\n\u2022 Only traffic destined to h3 is to be delivered (i.e., all traffic to h4 is \nblocked).\n\u2022 Only UDP traffic from h1 and destined to h3 is to be delivered. All other \ntraffic is blocked.\nWireshark Lab\nIn the Web site for this textbook, www.pearsonglobaleditions.com/kurose, you\u2019ll \nfind a Wireshark lab assignment that examines the operation of the IP protocol, and \nthe IP datagram format in particular.\n399What brought you to specialize in networking?\nI was working as a programmer at UCLA in the late 1960s. My job was supported by \nthe US Defense Advanced Research Projects Agency (called ARPA then, called DARPA \nnow). I was working in the laboratory of Professor Leonard Kleinrock on the Network \nMeasurement Center of the newly created ARPAnet. The first node of the ARPAnet was \ninstalled at UCLA on September 1, 1969. I was responsible for programming a computer \nthat was used to capture performance information about the ARPAnet and to report this \ninformation back for comparison with mathematical models and predictions of the perfor -\nmance of the network.\nSeveral of the other graduate students and I were made responsible for working on \nthe so-called host-level protocols of the ARPAnet\u2014the procedures and formats that would \nallow many different kinds of computers on the network to interact with each other. It \nwas a fascinating exploration into a new world (for me) of distributed computing and \ncommunication.\nDid you imagine that IP would become as pervasive as it is today when you first designed \nthe protocol?\nWhen Bob Kahn and I first worked on this in 1973, I think we were mostly very focused on \nthe central question: How can we make heterogeneous packet networks interoperate with \none another, assuming we cannot actually change the networks themselves? We hoped that \nwe could find a way to permit an arbitrary collection of packet-switched networks to be \ninterconnected in a transparent fashion, so that host computers could communicate end-to-end \nwithout having to do any translations in between. I think we knew that we were dealing Vinton G. Cerf is Vice President and Chief Internet Evangelist for \nGoogle. He served for over 16 years at MCI in various positions, \nending up his tenure there as Senior Vice President for Technology \nStrategy. He is widely known as the co-designer of the TCP/IP  \nprotocols and the architecture of the Internet. During his time from 1976  \nto 1982 at the US Department of Defense Advanced Research \nProjects Agency (DARPA), he played a key role leading the develop -\nment of Internet and", "doc_id": "df9867de-8d7a-4f4c-991f-baa6e6371e16", "embedding": null, "doc_hash": "e7c6c3d25fa595e6ec5f6b67990b27a796daa4e0db32e1f3691d8c2b606534ab", "extra_info": null, "node_info": {"start": 1160802, "end": 1164588}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "dcf44d07-ee10-4727-8a40-887ea679802e", "3": "2b9784d4-7b3d-47cc-868e-78d8cc839596"}}, "__type__": "1"}, "2b9784d4-7b3d-47cc-868e-78d8cc839596": {"__data__": {"text": "networks themselves? We hoped that \nwe could find a way to permit an arbitrary collection of packet-switched networks to be \ninterconnected in a transparent fashion, so that host computers could communicate end-to-end \nwithout having to do any translations in between. I think we knew that we were dealing Vinton G. Cerf is Vice President and Chief Internet Evangelist for \nGoogle. He served for over 16 years at MCI in various positions, \nending up his tenure there as Senior Vice President for Technology \nStrategy. He is widely known as the co-designer of the TCP/IP  \nprotocols and the architecture of the Internet. During his time from 1976  \nto 1982 at the US Department of Defense Advanced Research \nProjects Agency (DARPA), he played a key role leading the develop -\nment of Internet and Internet-related data packet and security  \ntechniques. He received the US Presidential Medal of Freedom in \n2005 and the US National Medal of Technology in 1997. He \nholds a BS in Mathematics from Stanford University and an MS and \nPhD in computer science from UCLA.\nVinton G. CerfAN INTERVIEW WITH\u2026\n400with powerful and expandable technology, but I doubt we had a clear image of what the \nworld would be like with hundreds of millions of computers all interlinked on the Internet.\nWhat do you now envision for the future of networking and the Internet? What major \nchallenges/obstacles do you think lie ahead in their development?\nI believe the Internet itself and networks in general will continue to proliferate. Already \nthere is convincing evidence that there will be billions of Internet-enabled devices on the \nInternet, including appliances like cell phones, refrigerators, personal digital assistants, home \nservers, televisions, as well as the usual array of laptops, servers, and so on. Big challenges \ninclude support for mobility, battery life, capacity of the access links to the network, and abil -\nity to scale the optical core of the network up in an unlimited fashion. Designing an interplan -\netary extension of the Internet is a project in which I am deeply engaged at the Jet Propulsion \nLaboratory. We will need to cut over from IPv4 [32-bit addresses] to IPv6 [128 bits].  \nThe list is long!\nWho has inspired you professionally?\nMy colleague Bob Kahn; my thesis advisor, Gerald Estrin; my best friend, Steve Crocker \n(we met in high school and he introduced me to computers in 1960!); and the thousands of \nengineers who continue to evolve the Internet today.\nDo you have any advice for students entering the networking/Internet field?\nThink outside the limitations of existing systems\u2014imagine what might be possible; but then \ndo the hard work of figuring out how to get there from the current state of affairs. Dare to \ndream: A half dozen colleagues and I at the Jet Propulsion Laboratory have been working \non the design of an interplanetary extension of the terrestrial Internet. It may take decades \nto implement this, mission by mission, but to paraphrase: \u201cA man\u2019s reach should exceed his \ngrasp, or what are the heavens for?\u201d\n401In this chapter, we\u2019ll complete our journey through the network layer by covering the \ncontrol-plane  component of the network layer\u2014the network-wide  logic that con -\ntrols not only how a datagram is forwarded among routers along an end-to-end path \nfrom the source host to the destination host, but also how network-layer components \nand services are configured and managed. In Section 5.2, we\u2019ll cover traditional \nrouting algorithms for computing least cost paths in a graph; these algorithms are the \nbasis for two widely deployed Internet routing protocols: OSPF and BGP, that we\u2019ll \ncover in Sections 5.3 and 5.4, respectively. As we\u2019ll see, OSPF is a routing protocol \nthat operates within a single ISP\u2019s network. BGP is a routing protocol that serves to \ninterconnect all of the networks in the Internet; BGP is thus often referred to as the", "doc_id": "2b9784d4-7b3d-47cc-868e-78d8cc839596", "embedding": null, "doc_hash": "29df6bb31a7e1c73d8a6b43d31b30561d106e95ae7e1333d4da833286f0a093d", "extra_info": null, "node_info": {"start": 1164539, "end": 1168447}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "df9867de-8d7a-4f4c-991f-baa6e6371e16", "3": "f65596f9-f47e-4cf1-a8e2-f0a40e4ac25a"}}, "__type__": "1"}, "f65596f9-f47e-4cf1-a8e2-f0a40e4ac25a": {"__data__": {"text": "that con -\ntrols not only how a datagram is forwarded among routers along an end-to-end path \nfrom the source host to the destination host, but also how network-layer components \nand services are configured and managed. In Section 5.2, we\u2019ll cover traditional \nrouting algorithms for computing least cost paths in a graph; these algorithms are the \nbasis for two widely deployed Internet routing protocols: OSPF and BGP, that we\u2019ll \ncover in Sections 5.3 and 5.4, respectively. As we\u2019ll see, OSPF is a routing protocol \nthat operates within a single ISP\u2019s network. BGP is a routing protocol that serves to \ninterconnect all of the networks in the Internet; BGP is thus often referred to as the \n\u201cglue\u201d that holds the Internet together. Traditionally, control-plane routing protocols \nhave been implemented together with data-plane forwarding functions, monolithi -\ncally, within a router. As we learned in the introduction to Chapter 4, software-\ndefined  networking (SDN) makes a clear separation between the data and control \nplanes, implementing control-plane functions in a separate \u201ccontroller\u201d service that \nis distinct, and remote, from the forwarding components of the routers it controls. \nWe\u2019ll cover SDN controllers in Section 5.5.\nIn Sections 5.6 and 5.7 we\u2019ll cover some of the nuts and bolts of managing an \nIP network: ICMP (the Internet Control Message Protocol) and SNMP (the Simple \nNetwork Management Protocol).5CHAPTER \nThe Network \nLayer: Control \nPlane\n\n402     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\n5.1 Introduction\nLet\u2019s quickly set the context for our study of the network control plane by recall -\ning Figures 4.2 and 4.3. There, we saw that the forwarding table (in the case of \n destination-based forwarding) and the flow table (in the case of generalized forward -\ning) were the principal elements that linked the network layer\u2019s data and control \nplanes. We learned that these tables specify the local data-plane forwarding behavior \nof a router. We saw that in the case of generalized forwarding, the actions taken (Sec-\ntion 4.4.2 ) could include not only forwarding a packet to a router\u2019s output port, but \nalso dropping a packet, replicating a packet, and/or rewriting layer 2, 3 or 4 packet-\nheader fields.\nIn this chapter, we\u2019ll study how those forwarding and flow tables are computed, \nmaintained and installed. In our introduction to the network layer in Section 4.1, we \nlearned that there are two possible approaches for doing so.\n\u2022 Per-router control . Figure 5.1 illustrates the case where a routing algorithm runs \nin each and every router; both a forwarding and a routing function are contained \nContr ol plane\nData planeRouting\nAlgorithm\nForwarding\nTable\nFigure 5.1  \u2666  Per-router control: Individual routing algorithm components \ninteract in the control plane\n5.1  \u2022  INTRODUCTION      403\nwithin each router. Each router has a routing component that communicates with \nthe routing components in other routers to compute the values for its forwarding \ntable. This per-router control approach has been used in the Internet for decades. \nThe OSPF and BGP protocols that we\u2019ll study in Sections 5.3 and 5.4 are based \non this per-router approach to control.\n\u2022 Logically centralized control . Figure 5.2 illustrates the case in which a logically \ncentralized controller computes and distributes the forwarding tables to be used \nby each and every router. As we saw in Section 4.4, the  generalized match-plus-\naction abstraction allows the router to perform traditional IP forwarding as well \nas a rich set of other functions (load sharing, firewalling, and NAT) that had been \npreviously implemented in separate", "doc_id": "f65596f9-f47e-4cf1-a8e2-f0a40e4ac25a", "embedding": null, "doc_hash": "53d155aa036b160627aeb2f2f4401939f083046fa2c4262a50e27f77797edef1", "extra_info": null, "node_info": {"start": 1168532, "end": 1172198}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "2b9784d4-7b3d-47cc-868e-78d8cc839596", "3": "ecd771e5-136b-436b-beaa-c3a8cb5ec32e"}}, "__type__": "1"}, "ecd771e5-136b-436b-beaa-c3a8cb5ec32e": {"__data__": {"text": "component that communicates with \nthe routing components in other routers to compute the values for its forwarding \ntable. This per-router control approach has been used in the Internet for decades. \nThe OSPF and BGP protocols that we\u2019ll study in Sections 5.3 and 5.4 are based \non this per-router approach to control.\n\u2022 Logically centralized control . Figure 5.2 illustrates the case in which a logically \ncentralized controller computes and distributes the forwarding tables to be used \nby each and every router. As we saw in Section 4.4, the  generalized match-plus-\naction abstraction allows the router to perform traditional IP forwarding as well \nas a rich set of other functions (load sharing, firewalling, and NAT) that had been \npreviously implemented in separate middleboxes.\nLogically centralized routing controller\nContr ol plane\nData plane\nControl\nAgent (CA)\nCACA\nCACA\nFigure 5.2  \u2666  Logically centralized control: A distinct, typically remote,  \ncontroller interacts with local control agents (CAs)\n404     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\nThe controller interacts with a control agent (CA) in each of the routers via a \nwell-defined protocol to configure and manage that router\u2019s flow table. Typically, \nthe CA has minimum functionality; its job is to communicate with the controller, \nand to do as the controller commands. Unlike the routing algorithms in Figure \n5.1, the CAs do not directly interact with each other nor do they actively take part \nin computing the forwarding table. This is a key distinction between per-router \ncontrol and logically centralized control.\nBy \u201clogically centralized\u201d control [Levin 2012] we mean that the routing \ncontrol service is accessed as if it were a single central service point, even though \nthe service is likely to be implemented via multiple servers for fault-tolerance, \nand performance scalability reasons. As we will see in Section 5.5, SDN adopts \nthis notion of a logically centralized controller\u2014an approach that is finding \nincreased use in production deployments. Google uses SDN to control the rout -\ners in its internal B4 global wide-area network that interconnects its data centers  \n[Jain 2013]. SWAN [Hong 2013], from Microsoft Research, uses a logically cen -\ntralized controller to manage routing and forwarding between a wide area network \nand a data center network. China Telecom and China Unicom are using SDN both \nwithin data centers and between data centers [Li 2015]. AT&T has noted [AT&T \n2013] that it \u201csupports many SDN capabilities and independently defined, propri -\netary mechanisms that fall under the SDN architectural framework.\u201d\n5.2 Routing Algorithms\nIn this section we\u2019ll study routing algorithms , whose goal is to determine good \npaths (equivalently, routes), from senders to receivers, through the network of \nrouters. Typically, a \u201cgood\u201d path is one that has the least cost. We\u2019ll see that in \npractice, however, real-world concerns such as policy issues (for example, a rule \nsuch as \u201crouter x, belonging to organization Y, should not forward any packets \noriginating from the network owned by organization Z \u201d) also come into play. We \nnote that whether the network control plane adopts a per-router control approach \nor a logically centralized approach, there must always be a well-defined sequence \nof routers that a packet will cross in traveling from sending to receiving host. Thus, \nthe routing algorithms that compute these paths are of fundamental importance, \nand another candidate for our top-10 list of fundamentally important networking \nconcepts.\nA graph is used to formulate routing problems. Recall that a graph  G=(N, E) \nis a set N of nodes and a collection E of edges, where each edge is a pair of nodes \nfrom N. In the context of network-layer routing, the nodes in the graph represent", "doc_id": "ecd771e5-136b-436b-beaa-c3a8cb5ec32e", "embedding": null, "doc_hash": "3f932ceda974ccdd8d1fca305101f6182d9dfa44e9f9810c1babd786e18bd011", "extra_info": null, "node_info": {"start": 1172126, "end": 1175950}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "f65596f9-f47e-4cf1-a8e2-f0a40e4ac25a", "3": "1f199d48-f5be-43c1-95a9-2e5ff06e1c33"}}, "__type__": "1"}, "1f199d48-f5be-43c1-95a9-2e5ff06e1c33": {"__data__": {"text": "not forward any packets \noriginating from the network owned by organization Z \u201d) also come into play. We \nnote that whether the network control plane adopts a per-router control approach \nor a logically centralized approach, there must always be a well-defined sequence \nof routers that a packet will cross in traveling from sending to receiving host. Thus, \nthe routing algorithms that compute these paths are of fundamental importance, \nand another candidate for our top-10 list of fundamentally important networking \nconcepts.\nA graph is used to formulate routing problems. Recall that a graph  G=(N, E) \nis a set N of nodes and a collection E of edges, where each edge is a pair of nodes \nfrom N. In the context of network-layer routing, the nodes in the graph represent \n5.2  \u2022  ROUTING ALGORITHMS      405\nrouters\u2014the points at which packet-forwarding decisions are made\u2014and the edges \nconnecting these nodes represent the physical links between these routers. Such \na graph abstraction of a computer network is shown in Figure 5.3. To view some \ngraphs representing real network maps, see [Dodge 2016, Cheswick 2000]; for \na discussion of how well different graph-based models model the Internet, see  \n[Zegura 1997, Faloutsos 1999, Li 2004].\nAs shown in Figure 5.3, an edge also has a value representing its cost. Typically, \nan edge\u2019s cost may reflect the physical length of the corresponding link (for example, \na transoceanic link might have a higher cost than a short-haul terrestrial link), the link \nspeed, or the monetary cost associated with a link. For our purposes, we\u2019ll simply \ntake the edge costs as a given and won\u2019t worry about how they are determined. For \nany edge (x, y) in E, we denote c(x, y) as the cost of the edge between nodes x and y. \nIf the pair (x, y) does not belong to E, we set c(x, y)=\u221e. Also, we\u2019ll only consider \nundirected graphs (i.e., graphs whose edges do not have a direction) in our discussion \nhere, so that edge (x, y) is the same as edge (y, x) and that c(x, y)=c(y, x); however, \nthe algorithms we\u2019ll study can be easily extended to the case of directed links with a \ndifferent cost in each direction. Also, a node y is said to be a neighbor  of node x if \n(x, y) belongs to E.\nGiven that costs are assigned to the various edges in the graph abstraction, \na natural goal of a routing algorithm is to identify the least costly paths between \nsources and destinations. To make this problem more precise, recall that a path  \nin a graph G=(N, E) is a sequence of nodes (x1, x2, g, xp) such that each \nof the pairs (x1, x2), (x2, x3), g, (xp-1, xp) are edges in E. The cost of a path \n(x1, x2, g, xp) is simply the sum of all the edge costs along the path, that is, xyv35\n25\n231\n12\n1u zw\nFigure 5.3  \u2666 Abstract graph model of a computer network\n406     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\nc(x1, x2)+c(x2, x3) + g+ c(xp-1, xp). Given any two nodes x and y, there are typi -\ncally many paths between the two nodes, with each path having a cost. One or more \nof these paths is a least-cost path . The least-cost problem is therefore clear: Find a \npath between the source and destination that has least cost. In Figure 5.3, for exam -\nple, the least-cost path between source node u and destination node w is (u, x, y, w) \nwith a path cost of 3. Note that if all edges in the graph have the same", "doc_id": "1f199d48-f5be-43c1-95a9-2e5ff06e1c33", "embedding": null, "doc_hash": "1c2375d50a863919d92f3f6a8bc7d202295ab91b8cdfa8d7935d772019f2697d", "extra_info": null, "node_info": {"start": 1175957, "end": 1179310}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "ecd771e5-136b-436b-beaa-c3a8cb5ec32e", "3": "4014b4ef-b022-48df-87a8-99dc4457d400"}}, "__type__": "1"}, "4014b4ef-b022-48df-87a8-99dc4457d400": {"__data__": {"text": " \u2666 Abstract graph model of a computer network\n406     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\nc(x1, x2)+c(x2, x3) + g+ c(xp-1, xp). Given any two nodes x and y, there are typi -\ncally many paths between the two nodes, with each path having a cost. One or more \nof these paths is a least-cost path . The least-cost problem is therefore clear: Find a \npath between the source and destination that has least cost. In Figure 5.3, for exam -\nple, the least-cost path between source node u and destination node w is (u, x, y, w) \nwith a path cost of 3. Note that if all edges in the graph have the same cost, the least-\ncost path is also the shortest path  (that is, the path with the smallest number of links \nbetween the source and the destination).\nAs a simple exercise, try finding the least-cost path from node u to z in \nFigure 5.3 and reflect for a moment on how you calculated that path. If you are \nlike most people, you found the path from u to z by examining Figure 5.3, tracing \na few routes from u to z, and somehow convincing yourself that the path you had \nchosen had the least cost among all possible paths. (Did you check all of the 17 pos -\nsible paths between u and z? Probably not!) Such a calculation is an example of a \ncentralized routing algorithm\u2014the routing algorithm was run in one location, your \nbrain, with complete information about the network. Broadly, one way in which \nwe can classify routing algorithms is according to whether they are centralized or \ndecentralized.\n\u2022 A centralized routing algorithm  computes the least-cost path between a source \nand destination using complete, global knowledge about the network. That is, the \nalgorithm takes the connectivity between all nodes and all link costs as inputs. \nThis then requires that the algorithm somehow obtain this information before \nactually performing the calculation. The calculation itself can be run at one site \n(e.g., a logically centralized controller as in Figure 5.2) or could be replicated in \nthe routing component of each and every router (e.g., as in Figure 5.1 ). The key \ndistinguishing feature here, however, is that the algorithm has complete informa -\ntion about connectivity and link costs. Algorithms with global state information \nare often referred to as link-state (LS) algorithms , since the algorithm must \nbe aware of the cost of each link in the network. We\u2019ll study LS algorithms in  \nSection 5.2.1.\n\u2022 In a decentralized routing algorithm , the calculation of the least-cost path is \ncarried out in an iterative, distributed manner by the routers. No node has com -\nplete information about the costs of all network links. Instead, each node begins \nwith only the knowledge of the costs of its own directly attached links. Then, \nthrough an iterative process of calculation and exchange of information with its \nneighboring nodes, a node gradually calculates the least-cost path to a destination \nor set of destinations. The decentralized routing algorithm we\u2019ll study below in  \nSection 5. 2.2 is called a distance-vector (DV) algorithm, because each node main -\ntains a vector of estimates of the costs (distances) to all other nodes in the net -\nwork. Such decentralized algorithms, with interactive message exchange between \n5.2  \u2022  ROUTING ALGORITHMS      407\nneighboring routers is perhaps more naturally suited to control planes where the \nrouters interact directly with each other, as in Figure 5.1.\nA second broad way to classify routing algorithms is according to whether they \nare static or dynamic. In static routing algorithms , routes change very slowly over \ntime, often as a result of human intervention (for example, a human manually editing \na link costs). Dynamic routing algorithms  change", "doc_id": "4014b4ef-b022-48df-87a8-99dc4457d400", "embedding": null, "doc_hash": "7c7203d17dee06709a9b96d4ee68714ff9ea477d78f1e833a5b3d1fdf759726d", "extra_info": null, "node_info": {"start": 1179470, "end": 1183204}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "1f199d48-f5be-43c1-95a9-2e5ff06e1c33", "3": "55453d2a-be54-4259-926b-e13d941f7f63"}}, "__type__": "1"}, "55453d2a-be54-4259-926b-e13d941f7f63": {"__data__": {"text": "5. 2.2 is called a distance-vector (DV) algorithm, because each node main -\ntains a vector of estimates of the costs (distances) to all other nodes in the net -\nwork. Such decentralized algorithms, with interactive message exchange between \n5.2  \u2022  ROUTING ALGORITHMS      407\nneighboring routers is perhaps more naturally suited to control planes where the \nrouters interact directly with each other, as in Figure 5.1.\nA second broad way to classify routing algorithms is according to whether they \nare static or dynamic. In static routing algorithms , routes change very slowly over \ntime, often as a result of human intervention (for example, a human manually editing \na link costs). Dynamic routing algorithms  change the routing paths as the network \ntraffic loads or topology change. A dynamic algorithm can be run either periodically \nor in direct response to topology or link cost changes. While dynamic algorithms \nare more responsive to network changes, they are also more susceptible to problems \nsuch as routing loops and route oscillation.\nA third way to classify routing algorithms is according to whether they are load-\nsensitive or load-insensitive. In a load-sensitive algorithm , link costs vary dynami -\ncally to reflect the current level of congestion in the underlying link. If a high cost \nis associated with a link that is currently congested, a routing algorithm will tend \nto choose routes around such a congested link. While early ARPAnet routing algo -\nrithms were load-sensitive [McQuillan 1980], a number of difficulties were encoun -\ntered [Huitema 1998]. Today\u2019s Internet routing algorithms (such as RIP, OSPF, and \nBGP) are load-insensitive , as a link\u2019s cost does not explicitly reflect its current (or \nrecent past) level of congestion.\n5.2.1  The Link-State (LS) Routing Algorithm\nRecall that in a link-state algorithm, the network topology and all link costs are \nknown, that is, available as input to the LS algorithm. In practice this is accom -\nplished by having each node broadcast link-state packets to all other nodes in \nthe network, with each link-state packet containing the identities and costs of \nits attached links. In practice (for example, with the Internet\u2019s OSPF routing \nprotocol, discussed in Section 5.3) this is often accomplished by a link-state \nbroadcast  algorithm  [Perlman 1999]. The result of the nodes\u2019 broadcast is that \nall nodes have an identical and complete view of the network. Each node can \nthen run the LS algorithm and compute the same set of least-cost paths as every \nother node.\nThe link-state routing algorithm we present below is known as Dijkstra\u2019s \nalgorithm , named after its inventor. A closely related algorithm is Prim\u2019s algo -\nrithm; see [Cormen 2001] for a general discussion of graph algorithms. Dijkstra\u2019s \nalgorithm computes the least-cost path from one node (the source, which we will \nrefer to as u) to all other nodes in the network. Dijkstra\u2019s algorithm is iterative and \nhas the property that after the kth iteration of the algorithm, the least-cost paths \nare known to k destination nodes, and among the least-cost paths to all destination \n408     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\nnodes, these k paths will have the k smallest costs. Let us define the following \nnotation:\n\u2022 D(v): cost of the least-cost path from the source node to destination v as of this \niteration of the algorithm.\n\u2022 p(v): previous node (neighbor of v) along the current least-cost path from the \nsource to v.\n\u2022 N\u2032: subset of nodes; v is in N\u2032 if the least-cost path from the source to v is defini -\ntively known.\nThe centralized", "doc_id": "55453d2a-be54-4259-926b-e13d941f7f63", "embedding": null, "doc_hash": "2ff54d8e6909342bbcced7317706f617e4cce3af969eea00ac91811a420f274c", "extra_info": null, "node_info": {"start": 1183089, "end": 1186705}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "4014b4ef-b022-48df-87a8-99dc4457d400", "3": "5b261188-8ad8-41ab-b827-541dfaf2b0c8"}}, "__type__": "1"}, "5b261188-8ad8-41ab-b827-541dfaf2b0c8": {"__data__": {"text": "the kth iteration of the algorithm, the least-cost paths \nare known to k destination nodes, and among the least-cost paths to all destination \n408     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\nnodes, these k paths will have the k smallest costs. Let us define the following \nnotation:\n\u2022 D(v): cost of the least-cost path from the source node to destination v as of this \niteration of the algorithm.\n\u2022 p(v): previous node (neighbor of v) along the current least-cost path from the \nsource to v.\n\u2022 N\u2032: subset of nodes; v is in N\u2032 if the least-cost path from the source to v is defini -\ntively known.\nThe centralized routing algorithm consists of an initialization step followed by \na loop. The number of times the loop is executed is equal to the number of nodes in \nthe network. Upon termination, the algorithm will have calculated the shortest paths \nfrom the source node u to every other node in the network.\nLink-State (LS) Algorithm for Source Node u\n1  Initialization:  \n2   N\u2019 = {u}\n3   for all nodes v\n4     if v is a neighbor of u\n5       then D(v) = c(u,v)\n6     else D(v) = \u221e\n7\n8  Loop\n9   \ufb01nd w not in N\u2019 such that D(w) is a minimum\n10  add w to N\u2019\n11  update D(v) for each neighbor v of w and not in N\u2019:\n12        D(v) = min(D(v), D(w)+ c(w,v) )\n13   /* new cost to v is either old cost to v or known\n14    least path cost to w plus cost from w to v */\n15 until N\u2019= N\nAs an example, let\u2019s consider the network in Figure 5.3 and compute the least-\ncost paths from u to all possible destinations. A tabular summary of the algorithm\u2019s \ncomputation is shown in Table 5.1, where each line in the table gives the values of \nthe algorithm\u2019s variables at the end of the iteration. Let\u2019s consider the few first steps \nin detail.\n\u2022 In the initialization step, the currently known least-cost paths from u to its directly \nattached neighbors, v, x, and w, are initialized to 2, 1, and 5, respectively. Note in \n5.2  \u2022  ROUTING ALGORITHMS      409\nparticular that the cost to w is set to 5 (even though we will soon see that a lesser-cost  \npath does indeed exist) since this is the cost of the direct (one hop) link from u to \nw. The costs to y and z are set to infinity because they are not directly connected \nto u.\n\u2022 In the first iteration, we look among those nodes not yet added to the set N\u2032 and \nfind that node with the least cost as of the end of the previous iteration. That node \nis x, with a cost of 1, and thus x is added to the set N\u2032. Line 12 of the LS algorithm \nis then performed to update D(v) for all nodes v, yielding the results shown in the \nsecond line (Step 1) in Table 5.1. The cost of the path to v is unchanged. The cost \nof the path to w (which was 5 at the end of the initialization) through node x is \nfound to have a cost of 4. Hence this lower-cost path is selected and w\u2019s predeces -\nsor along the shortest path from u is set to x. Similarly, the cost to y (through x) is \ncomputed to be 2, and the table is updated accordingly.\n\u2022 In the second iteration, nodes v and y are found to have the least-cost paths (2), \nand we break the tie arbitrarily and add y to the set N\u2032 so that N\u2032 now contains u, \nx, and y. The cost to the remaining nodes not yet", "doc_id": "5b261188-8ad8-41ab-b827-541dfaf2b0c8", "embedding": null, "doc_hash": "246c23a9b62d10ff6cb163f35a94c62ce5c8aa5c3b1ecfc4e5a2611eaeabc0f8", "extra_info": null, "node_info": {"start": 1186798, "end": 1189986}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "55453d2a-be54-4259-926b-e13d941f7f63", "3": "ce2db4ea-900e-444f-9e10-a50d0c799362"}}, "__type__": "1"}, "ce2db4ea-900e-444f-9e10-a50d0c799362": {"__data__": {"text": "for all nodes v, yielding the results shown in the \nsecond line (Step 1) in Table 5.1. The cost of the path to v is unchanged. The cost \nof the path to w (which was 5 at the end of the initialization) through node x is \nfound to have a cost of 4. Hence this lower-cost path is selected and w\u2019s predeces -\nsor along the shortest path from u is set to x. Similarly, the cost to y (through x) is \ncomputed to be 2, and the table is updated accordingly.\n\u2022 In the second iteration, nodes v and y are found to have the least-cost paths (2), \nand we break the tie arbitrarily and add y to the set N\u2032 so that N\u2032 now contains u, \nx, and y. The cost to the remaining nodes not yet in N\u2032, that is, nodes v, w, and z, \nare updated via line 12 of the LS algorithm, yielding the results shown in the third \nrow in Table 5.1.\n\u2022 And so on . . . \nWhen the LS algorithm terminates, we have, for each node, its predecessor \nalong the least-cost path from the source node. For each predecessor, we also have its \npredecessor, and so in this manner we can construct the entire path from the source to \nall destinations. The forwarding table in a node, say node u, can then be constructed \nfrom this information by storing, for each destination, the next-hop node on the least-\ncost path from u to the destination. Figure 5.4 shows the resulting least-cost paths \nand forwarding table in u for the network in Figure 5.3.Table 5.1  \u2666 Running the link-state algorithm on the network in Figure 5.3step N\u2019 D (v), p (v) D (w), p (w) D (x), p (x) D (y), p (y) D (z), p (z)\n0 u 2, u 5, u 1,u \u221e \u221e\n1 ux 2, u 4, x 2, x \u221e\n2 uxy 2, u 3, y 4, y\n3 uxyv 3, y 4, y\n4 uxyvw 4, y\n5 uxyvwz\n410     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\nWhat is the computational complexity of this algorithm? That is, given n nodes \n(not counting the source), how much computation must be done in the worst case to \nfind the least-cost paths from the source to all destinations? In the first iteration, we \nneed to search through all n nodes to determine the node, w, not in N\u2032 that has the \nminimum cost. In the second iteration, we need to check n-1 nodes to determine \nthe minimum cost; in the third iteration n-2 nodes, and so on. Overall, the total \nnumber of nodes we need to search through over all the iterations is n(n+1)/2, and \nthus we say that the preceding implementation of the LS algorithm has worst-case \ncomplexity of order n squared: O(n2). (A more sophisticated implementation of this \nalgorithm, using a data structure known as a heap, can find the minimum in line 9 in \nlogarithmic rather than linear time, thus reducing the complexity.)\nBefore completing our discussion of the LS algorithm, let us consider a pathol -\nogy that can arise. Figure 5.5 shows a simple network topology where link costs are \nequal to the load carried on the link, for example, reflecting the delay that would \nbe experienced. In this example, link costs are not symmetric; that is, c(u,v) equals \nc(v,u) only if the load carried on both directions on the link ( u,v) is the same. In this \nexample, node z originates a unit of traffic destined for w, node x also originates a \nunit of traffic destined for w, and node y injects an amount of traffic equal to e, also \ndestined for w. The initial routing is shown in Figure 5.5(a) with the link costs cor -\nresponding to the amount of traffic carried.\nWhen", "doc_id": "ce2db4ea-900e-444f-9e10-a50d0c799362", "embedding": null, "doc_hash": "d26b839f1450e5f43c29fddbeec4803e114cbbddee93883c78c9b676def930b9", "extra_info": null, "node_info": {"start": 1189965, "end": 1193322}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "5b261188-8ad8-41ab-b827-541dfaf2b0c8", "3": "fb1336ce-f866-4763-9845-80450b88bff2"}}, "__type__": "1"}, "fb1336ce-f866-4763-9845-80450b88bff2": {"__data__": {"text": "let us consider a pathol -\nogy that can arise. Figure 5.5 shows a simple network topology where link costs are \nequal to the load carried on the link, for example, reflecting the delay that would \nbe experienced. In this example, link costs are not symmetric; that is, c(u,v) equals \nc(v,u) only if the load carried on both directions on the link ( u,v) is the same. In this \nexample, node z originates a unit of traffic destined for w, node x also originates a \nunit of traffic destined for w, and node y injects an amount of traffic equal to e, also \ndestined for w. The initial routing is shown in Figure 5.5(a) with the link costs cor -\nresponding to the amount of traffic carried.\nWhen the LS algorithm is next run, node y determines (based on the link costs \nshown in Figure 5.5(a)) that the clockwise path to w has a cost of 1, while the coun -\nterclockwise path to w (which it had been using) has a cost of 1+e. Hence y\u2019s least-\ncost path to w is now clockwise. Similarly, x determines that its new least-cost path to \nw is also clockwise, resulting in costs shown in Figure 5.5(b). When the LS algorithm \nis run next, nodes x, y, and z all detect a zero-cost path to w in the counterclockwise \ndirection, and all route their traffic to the counterclockwise routes. The next time the \nLS algorithm is run, x, y, and z all then route their traffic to the clockwise routes.\nWhat can be done to prevent such oscillations (which can occur in any algo -\nrithm, not just an LS algorithm, that uses a congestion or delay-based link metric)? \nOne solution would be to mandate that link costs not depend on the amount of traffic Destination Link\nv\nw\nx\ny\nz(u, v)\n(u, x)\n(u, x)\n(u, x)\n(u, x) x yv\nu zw\nFigure 5.4  \u2666 Least cost path and forwarding table for node u\n5.2  \u2022  ROUTING ALGORITHMS      411\ncarried\u2014an unacceptable solution since one goal of routing is to avoid highly con -\ngested (for example, high-delay) links. Another solution is to ensure that not all rout -\ners run the LS algorithm at the same time. This seems a more reasonable solution, \nsince we would hope that even if routers ran the LS algorithm with the same perio -\ndicity, the execution instance of the algorithm would not be the same at each node. \nInterestingly, researchers have found that routers in the Internet can self-synchronize \namong themselves [Floyd Synchronization 1994]. That is, even though they initially \nexecute the algorithm with the same period but at different instants of time, the algo -\nrithm execution instance can eventually become, and remain, synchronized at the \nrouters. One way to avoid such self-synchronization is for each router to randomize \nthe time it sends out a link advertisement.\nHaving studied the LS algorithm, let\u2019s consider the other major routing algo -\nrithm that is used in practice today\u2014the distance-vector routing algorithm.w\nyz x1\n00\n0 e1 + e\n1\na.  Initial r outing1\new\nyz x2 + e\n1 + e1\n0 00\nb.  x, y detect better path\n     to w, clockwise\nw\nyz x0\n00\n1 1 + e2+ e\nc.  x, y, z detect better path\n     to w, counterclockwisew\nyz x2 + e\n1 + e1\n000\nd.  x, y, z, detect better path\n     to w, clockwise11\ne\n11\ne11\ne\nFigure 5.5  \u2666 Oscillations with congestion-sensitive routing\n412     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER:", "doc_id": "fb1336ce-f866-4763-9845-80450b88bff2", "embedding": null, "doc_hash": "7180ca4b5f746e891e10e2e16e06d6a0849a7560102082296a61962f994001b7", "extra_info": null, "node_info": {"start": 1193291, "end": 1196532}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "ce2db4ea-900e-444f-9e10-a50d0c799362", "3": "71fa8a5f-ce00-48c8-b413-b598a721c697"}}, "__type__": "1"}, "71fa8a5f-ce00-48c8-b413-b598a721c697": {"__data__": {"text": "distance-vector routing algorithm.w\nyz x1\n00\n0 e1 + e\n1\na.  Initial r outing1\new\nyz x2 + e\n1 + e1\n0 00\nb.  x, y detect better path\n     to w, clockwise\nw\nyz x0\n00\n1 1 + e2+ e\nc.  x, y, z detect better path\n     to w, counterclockwisew\nyz x2 + e\n1 + e1\n000\nd.  x, y, z, detect better path\n     to w, clockwise11\ne\n11\ne11\ne\nFigure 5.5  \u2666 Oscillations with congestion-sensitive routing\n412     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\n5.2.2  The Distance-Vector (DV) Routing Algorithm\nWhereas the LS algorithm is an algorithm using global information, the distance-\nvector (DV)  algorithm is iterative, asynchronous, and distributed. It is distributed  in \nthat each node receives some information from one or more of its directly attached  \nneighbors, performs a calculation, and then distributes the results of its calculation \nback to its neighbors. It is iterative  in that this process continues on until no more \ninformation is exchanged between neighbors. (Interestingly, the algorithm is also \nself-terminating\u2014there is no signal that the computation should stop; it just stops.) \nThe algorithm is asynchronous  in that it does not require all of the nodes to operate in \nlockstep with each other. We\u2019ll see that an asynchronous, iterative, self-terminating, \ndistributed algorithm is much more interesting and fun than a centralized algorithm!\nBefore we present the DV algorithm, it will prove beneficial to discuss an impor -\ntant relationship that exists among the costs of the least-cost paths. Let dx(y) be the \ncost of the least-cost path from node x to node y. Then the least costs are related by \nthe celebrated Bellman-Ford equation, namely,\n dx(y)=min v5c(x, v)+dv( y)6, (5.1)\nwhere the minv in the equation is taken over all of x\u2019s neighbors. The Bellman-\nFord equation is rather intuitive. Indeed, after traveling from x to v, if we then take \nthe least-cost path from v to y, the path cost will be c(x, v)+dv(y). Since we must \nbegin by traveling to some neighbor v, the least cost from x to y is the minimum of \nc(x, v)+dv(y) taken over all neighbors v.\nBut for those who might be skeptical about the validity of the equation, let\u2019s \ncheck it for source node u and destination node z in Figure 5.3. The source node u \nhas three neighbors: nodes v, x, and w. By walking along various paths in the graph, \nit is easy to see that dv(z)=5, dx(z)=3, and dw(z)=3. Plugging these values into \nEquation 5. 1, along with the costs c(u, v)=2, c(u, x)=1, and c(u, w)=5, gives \ndu(z)=min52+5, 5+3, 1+36=4, which is obviously true and which is \nexactly what the Dijskstra algorithm gave us for the same network. This quick veri -\nfication should help relieve any skepticism you may have.\nThe Bellman-Ford equation is not just an intellectual curiosity. It actually has signif -\nicant practical importance: the solution to the Bellman-Ford equation provides the entries \nin node x\u2019s forwarding table. To see this, let v* be any neighboring node that achieves \nthe minimum in Equation 5.1. Then, if node x wants to send a packet to node y along a \nleast-cost path, it should first forward the packet to node v*. Thus, node x\u2019s forwarding \ntable would", "doc_id": "71fa8a5f-ce00-48c8-b413-b598a721c697", "embedding": null, "doc_hash": "695bf9486b9677bee166f013e008d62a78ac9fe29cc3973b22db55a006173fbf", "extra_info": null, "node_info": {"start": 1196758, "end": 1199921}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "fb1336ce-f866-4763-9845-80450b88bff2", "3": "ebca192e-3d6c-4242-b273-79c7d148ae4a"}}, "__type__": "1"}, "ebca192e-3d6c-4242-b273-79c7d148ae4a": {"__data__": {"text": "\ndu(z)=min52+5, 5+3, 1+36=4, which is obviously true and which is \nexactly what the Dijskstra algorithm gave us for the same network. This quick veri -\nfication should help relieve any skepticism you may have.\nThe Bellman-Ford equation is not just an intellectual curiosity. It actually has signif -\nicant practical importance: the solution to the Bellman-Ford equation provides the entries \nin node x\u2019s forwarding table. To see this, let v* be any neighboring node that achieves \nthe minimum in Equation 5.1. Then, if node x wants to send a packet to node y along a \nleast-cost path, it should first forward the packet to node v*. Thus, node x\u2019s forwarding \ntable would specify node v* as the next-hop router for the ultimate destination y. Another \nimportant practical contribution of the Bellman-Ford equation is that it suggests the form \nof the neighbor-to-neighbor communication that will take place in the DV algorithm.\nThe basic idea is as follows. Each node x begins with Dx(y), an estimate of the cost \nof the least-cost path from itself to node y, for all nodes, y, in N. Let Dx=[Dx(y): y in N] \nbe node x\u2019s distance vector, which is the vector of cost estimates from x to all other nodes, \ny, in N. With the DV algorithm, each node x maintains the following routing information:\n5.2  \u2022  ROUTING ALGORITHMS      413\n\u2022 For each neighbor v, the cost c(x,v) from x to directly attached neighbor, v\n\u2022 Node x\u2019s distance vector, that is, Dx=[Dx(y): y in N], containing x\u2019s estimate of \nits cost to all destinations, y, in N\n\u2022 The distance vectors of each of its neighbors, that is, Dv=[Dv(y): y in N] for \neach neighbor v of x\nIn the distributed, asynchronous algorithm, from time to time, each node sends a \ncopy of its distance vector to each of its neighbors. When a node x receives a new \ndistance vector from any of its neighbors w, it saves w\u2019s distance vector, and then \nuses the Bellman-Ford equation to update its own distance vector as follows:\nDx(y)=min v5c(x, v)+Dv(y)6 for each node y in N\nIf node x\u2019s distance vector has changed as a result of this update step, node x will then \nsend its updated distance vector to each of its neighbors, which can in turn update \ntheir own distance vectors. Miraculously enough, as long as all the nodes continue \nto exchange their distance vectors in an asynchronous fashion, each cost estimate \nDx(y) converges to dx(y), the actual cost of the least-cost path from node x to node y \n[Bertsekas 1991]!\nDistance-Vector (DV) Algorithm\nAt each node, x:\n1  Initialization:\n2    for all destinations y in N:\n3       Dx(y)= c(x,y)/* if y is not a neighbor then c(x,y)= \u221e */\n4    for each neighbor w\n5       Dw(y) = ? for all destinations y in N\n6    for each neighbor w\n7       send distance vector  Dx = [Dx(y): y in N] to w\n8\n9  loop \n10    wait  (until I see a link cost change to some neighbor w or\n11            until I receive a distance vector from some neighbor w)\n12\n13    for each y in N:\n14        Dx(y) = minv{c(x,v) + Dv(y)}\n15\n16 if Dx(y) changed for any destination y\n17       send distance vector Dx  =", "doc_id": "ebca192e-3d6c-4242-b273-79c7d148ae4a", "embedding": null, "doc_hash": "7e3361f12a2077b9a3743ba5630bdec65f16cb38bb63d5e3dcbbbe310628d48e", "extra_info": null, "node_info": {"start": 1199701, "end": 1202768}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "71fa8a5f-ce00-48c8-b413-b598a721c697", "3": "06cd562f-d684-40b3-82dc-2b060aa5a408"}}, "__type__": "1"}, "06cd562f-d684-40b3-82dc-2b060aa5a408": {"__data__": {"text": "   for each neighbor w\n5       Dw(y) = ? for all destinations y in N\n6    for each neighbor w\n7       send distance vector  Dx = [Dx(y): y in N] to w\n8\n9  loop \n10    wait  (until I see a link cost change to some neighbor w or\n11            until I receive a distance vector from some neighbor w)\n12\n13    for each y in N:\n14        Dx(y) = minv{c(x,v) + Dv(y)}\n15\n16 if Dx(y) changed for any destination y\n17       send distance vector Dx  = [Dx(y): y in N] to all neighbors\n18\n19 forever \n414     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\nIn the DV algorithm, a node x updates its distance-vector estimate when it either \nsees a cost change in one of its directly attached links or receives a distance-vector \nupdate from some neighbor. But to update its own forwarding table for a given des -\ntination y, what node x really needs to know is not the shortest-path distance to y but \ninstead the neighboring node v*(y) that is the next-hop router along the shortest path \nto y. As you might expect, the next-hop router v*(y) is the neighbor v that achieves \nthe minimum in Line 14 of the DV algorithm. (If there are multiple neighbors v that \nachieve the minimum, then v*(y) can be any of the minimizing neighbors.) Thus, \nin Lines 13\u201314, for each destination y, node x also determines v*(y) and updates its \nforwarding table for destination y.\nRecall that the LS algorithm is a centralized algorithm in the sense that it \nrequires each node to first obtain a complete map of the network before running the \nDijkstra algorithm. The DV algorithm is decentralized  and does not use such global \ninformation. Indeed, the only information a node will have is the costs of the links \nto its directly attached neighbors and information it receives from these neighbors. \nEach node waits for an update from any neighbor (Lines 10\u201311), calculates its new \ndistance vector when receiving an update (Line 14), and distributes its new distance \nvector to its neighbors (Lines 16\u201317). DV-like algorithms are used in many routing \nprotocols in practice, including the Internet\u2019s RIP and BGP, ISO IDRP, Novell IPX, \nand the original ARPAnet.\nFigure 5. 6 illustrates the operation of the DV algorithm for the simple three-\nnode network shown at the top of the figure. The operation of the algorithm is illus -\ntrated in a synchronous manner, where all nodes simultaneously receive distance \nvectors from their neighbors, compute their new distance vectors, and inform their \nneighbors if their distance vectors have changed. After studying this example, you \nshould convince yourself that the algorithm operates correctly in an asynchronous \nmanner as well, with node computations and update generation/reception occurring \nat any time.\nThe leftmost column of the figure displays three initial routing tables  for each \nof the three nodes. For example, the table in the upper-left corner is node x\u2019s ini -\ntial routing table. Within a specific routing table, each row is a distance vector\u2014  \nspecifically, each node\u2019s routing table includes its own distance vector and that \nof each of its neighbors. Thus, the first row in node x\u2019s initial routing table is \nDx=[Dx(x), Dx(y), Dx(z)]=[0, 2, 7].  The second and third rows in this table are \nthe most recently received distance vectors from nodes y and z, respectively. Because \nat initialization node x has not received anything from node y or z, the entries in  \nthe second", "doc_id": "06cd562f-d684-40b3-82dc-2b060aa5a408", "embedding": null, "doc_hash": "db4f7b175643c65fa615a9b8c24eb3ef841b3cc3dbb21cff2778966468def798", "extra_info": null, "node_info": {"start": 1203015, "end": 1206433}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "ebca192e-3d6c-4242-b273-79c7d148ae4a", "3": "a8e78090-d76e-4018-ad44-c6eabd808186"}}, "__type__": "1"}, "a8e78090-d76e-4018-ad44-c6eabd808186": {"__data__": {"text": "occurring \nat any time.\nThe leftmost column of the figure displays three initial routing tables  for each \nof the three nodes. For example, the table in the upper-left corner is node x\u2019s ini -\ntial routing table. Within a specific routing table, each row is a distance vector\u2014  \nspecifically, each node\u2019s routing table includes its own distance vector and that \nof each of its neighbors. Thus, the first row in node x\u2019s initial routing table is \nDx=[Dx(x), Dx(y), Dx(z)]=[0, 2, 7].  The second and third rows in this table are \nthe most recently received distance vectors from nodes y and z, respectively. Because \nat initialization node x has not received anything from node y or z, the entries in  \nthe second and third rows are initialized to infinity.\nAfter initialization, each node sends its distance vector to each of its two neigh -\nbors. This is illustrated in Figure 5.6 by the arrows from the first column of tables \nto the second column of tables. For example, node x sends its distance vector Dx = \n[0, 2, 7] to both nodes y and z. After receiving the updates, each node recomputes its \nown distance vector. For example, node x computes\n5.2  \u2022  ROUTING ALGORITHMS      415\n Dx(x)=0\n Dx(y)=min5c(x,y)+Dy(y), c(x,z)+Dz(y)6=min52+0, 7+16=2\n Dx(z)=min5c(x,y)+Dy(z), c(x,z)+Dz(z)6=min52+1, 7+06=3\nThe second column therefore displays, for each node, the node\u2019s new distance vector \nalong with distance vectors just received from its neighbors. Note, for example, that \nNode y tableNode x table\n0 2 7x y z\n` ` `\n` ` `\nTime721y\nx z\nNode z table\nfromcost to\nx\ny\nz0 2 3x y z\n2 0 1\n7 1 0fromcost to\nx\ny\nz0 2 3x y z\n2 0 1\n3 1 0fromcost to\nx\ny\nz\n2 0 1x y z\n` ` `\n` ` `fromcost to\nx\ny\nz0 2 7x y z\n2 0 1\n7 1 0fromcost to\nx\ny\nz0 2 3x y z\n2 0 1\n3 1 0fromcost to\nx\ny\nz\n7 1 0x y z\n` ` `\n` ` `fromcost to\nx\ny\nz0 2 7x y z\n2 0 1\n3 1 0fromcost to\nx\ny\nz0 2 3x y z\n2 0 1\n3 1 0fromcost to\nx\ny\nz\nFigure 5.6  \u2666 Distance-vector (DV) algorithm in operation\n416     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\nnode x\u2019s estimate for the least cost to node z, Dx(z), has changed from 7 to 3. Also \nnote that for node x, neighboring node y achieves the minimum in line 14 of the DV \nalgorithm; thus at this stage of the algorithm, we have at node x that v*(y)=y and \nv*(z)=y.\nAfter the nodes recompute their distance vectors, they again send their updated \ndistance vectors to their neighbors (if there has been a change). This is illustrated in \nFigure 5. 6 by the arrows from the second column of tables to the third column of \ntables. Note that only nodes x and z send updates: node y\u2019s distance vector didn\u2019t \nchange so node y doesn\u2019t send an update. After receiving the updates, the nodes then \nrecompute their distance vectors and update their routing tables, which are shown in \nthe third column.\nThe process of receiving updated distance vectors from neighbors, recomputing \nrouting table entries, and informing neighbors of changed costs of the least-cost path \nto a destination continues until", "doc_id": "a8e78090-d76e-4018-ad44-c6eabd808186", "embedding": null, "doc_hash": "da81998546eddfb7c65220b0814622b040e1f380984fa4cd6cd2e53c5712e238", "extra_info": null, "node_info": {"start": 1206161, "end": 1209150}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "06cd562f-d684-40b3-82dc-2b060aa5a408", "3": "da92c9c6-cd83-4c94-bc2f-5357b56f70ea"}}, "__type__": "1"}, "da92c9c6-cd83-4c94-bc2f-5357b56f70ea": {"__data__": {"text": "and \nv*(z)=y.\nAfter the nodes recompute their distance vectors, they again send their updated \ndistance vectors to their neighbors (if there has been a change). This is illustrated in \nFigure 5. 6 by the arrows from the second column of tables to the third column of \ntables. Note that only nodes x and z send updates: node y\u2019s distance vector didn\u2019t \nchange so node y doesn\u2019t send an update. After receiving the updates, the nodes then \nrecompute their distance vectors and update their routing tables, which are shown in \nthe third column.\nThe process of receiving updated distance vectors from neighbors, recomputing \nrouting table entries, and informing neighbors of changed costs of the least-cost path \nto a destination continues until no update messages are sent. At this point, since no \nupdate messages are sent, no further routing table calculations will occur and the \nalgorithm will enter a quiescent state; that is, all nodes will be performing the wait in \nLines 10\u201311 of the DV algorithm. The algorithm remains in the quiescent state until \na link cost changes, as discussed next.\nDistance-Vector Algorithm: Link-Cost Changes and Link Failure\nWhen a node running the DV algorithm detects a change in the link cost from \nitself to a neighbor (Lines 10\u201311), it updates its distance vector (Lines 13\u201314) and, \nif there\u2019s a change in the cost of the least-cost path, informs its neighbors (Lines \n16\u201317) of its new distance vector. Figure 5.7(a) illustrates a scenario where the link \ncost from y to x changes from 4 to 1. We focus here only on y\u2019 and z\u2019s distance table \nentries to destination x. The DV algorithm causes the following sequence of events \nto occur:\n\u2022 At time t0, y detects the link-cost change (the cost has changed from 4 to 1), \nupdates its distance vector, and informs its neighbors of this change since its dis -\ntance vector has changed.\n\u2022 At time t1, z receives the update from y and updates its table. It computes a new \nleast cost to x (it has decreased from a cost of 5 to a cost of 2) and sends its new \ndistance vector to its neighbors.\n\u2022 At time t2, y receives z\u2019s update and updates its distance table. y\u2019s least costs do \nnot change and hence y does not send any message to z. The algorithm comes to \na quiescent state.\nThus, only two iterations are required for the DV algorithm to reach a quiescent  \nstate. The good news about the decreased cost between x and y has propagated \nquickly through the network.\n5.2  \u2022  ROUTING ALGORITHMS      417\nLet\u2019s now consider what can happen when a link cost increases.  Suppose that \nthe link cost between x and y increases from 4 to 60, as shown in Figure 5.7(b).\n 1. Before the link cost changes, Dy(x)=4, Dy(z)=1, Dz(y)=1, and Dz(x)=5. \nAt time t0, y detects the link-cost change (the cost has changed from 4 to 60). y \ncomputes its new minimum-cost path to x to have a cost of\nDy(x)=min5c(y,x)+Dx(x), c(y,z)+Dz(x)6=min560+0, 1+56=6\n  Of course, with our global view of the network, we can see that this new cost via \nz is wrong.  But the only information node y has is that its direct cost to x is 60 \nand that z has last told y that z could get to x with a cost of 5. So in order to get \nto x, y would now route through z, fully expecting that z will be able to get to x \nwith a cost of 5. As of t1 we have a routing loop \u2014in order to get to x, y routes \nthrough z, and z routes through y. A routing loop is like a black hole\u2014a", "doc_id": "da92c9c6-cd83-4c94-bc2f-5357b56f70ea", "embedding": null, "doc_hash": "616eba615b9e6fd92fbcbefa85e5a07131bf7687b6bcc3338689e1650fd04e3e", "extra_info": null, "node_info": {"start": 1209116, "end": 1212530}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "a8e78090-d76e-4018-ad44-c6eabd808186", "3": "21fce722-6ee1-4f45-b562-4d63c2c7ea2b"}}, "__type__": "1"}, "21fce722-6ee1-4f45-b562-4d63c2c7ea2b": {"__data__": {"text": "its new minimum-cost path to x to have a cost of\nDy(x)=min5c(y,x)+Dx(x), c(y,z)+Dz(x)6=min560+0, 1+56=6\n  Of course, with our global view of the network, we can see that this new cost via \nz is wrong.  But the only information node y has is that its direct cost to x is 60 \nand that z has last told y that z could get to x with a cost of 5. So in order to get \nto x, y would now route through z, fully expecting that z will be able to get to x \nwith a cost of 5. As of t1 we have a routing loop \u2014in order to get to x, y routes \nthrough z, and z routes through y. A routing loop is like a black hole\u2014a packet \ndestined for x arriving at y or z as of t1 will bounce back and forth between these \ntwo nodes forever (or until the forwarding tables are changed).\n 2. Since node y has computed a new minimum cost to x, it informs z of its new \ndistance vector at time t1.\n 3. Sometime after t1, z receives y\u2019s new distance vector, which indicates that y\u2019s \nminimum cost to x is 6. z knows it can get to y with a cost of 1 and hence com -\nputes a new least cost to x of Dz(x)=min550+0,1+66=7. Since z\u2019s \nleast cost to x has increased, it then informs y of its new distance vector at t2.\n 4. In a similar manner, after receiving z\u2019s new distance vector, y determines \nDy(x)=8 and sends z its distance vector. z then determines Dz(x)=9 and \nsends y its distance vector, and so on.\nHow long will the process continue? You should convince yourself that the loop will \npersist for 44 iterations (message exchanges between y and z)\u2014until z eventually \ncomputes the cost of its path via y to be greater than 50. At this point, z will (finally!) \ndetermine that its least-cost path to x is via its direct connection to x. y will then 5041 60\n1y\nx\na. b.z5041y\nx z\nFigure 5.7  \u2666 Changes in link cost\n418     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\nroute to x via z. The result of the bad news about the increase in link cost has indeed  \ntraveled slowly! What would have happened if the link cost c(y, x) had changed from \n4 to 10,000 and the cost c(z, x) had been 9,999? Because of such scenarios, the prob -\nlem we have seen is sometimes referred to as the count-to-infinity  problem.\nDistance-Vector Algorithm: Adding Poisoned Reverse\nThe specific looping scenario just described can be avoided using a technique known \nas poisoned reverse.  The idea is simple\u2014if z routes through y to get to destination x, \nthen z will advertise to y that its distance to x is infinity, that is, z will advertise to y \nthat Dz(x)=\u221e (even though z knows Dz(x)=5 in truth). z will continue telling this \nlittle white lie to y as long as it routes to x via y. Since y believes that z has no path \nto x, y will never attempt to route to x via z, as long as z continues to route to x via y \n(and lies about doing so).\nLet\u2019s now see how poisoned reverse solves the particular looping problem we \nencountered before in Figure 5.5(b). As a result of the poisoned reverse, y\u2019s distance \ntable indicates Dz(x)=\u221e. When the cost of the (x, y) link changes from 4 to 60 at \ntime t0, y updates its table and continues to route directly to x, albeit at a higher cost \nof 60, and informs z of its new cost to x, that is, Dy(x) = 60. After receiving the \nupdate at t1, z immediately shifts its route to", "doc_id": "21fce722-6ee1-4f45-b562-4d63c2c7ea2b", "embedding": null, "doc_hash": "0cd84e90b0c77891f10917f899834d4106d1346901583745a57d2b67134d8f0e", "extra_info": null, "node_info": {"start": 1212683, "end": 1215949}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "da92c9c6-cd83-4c94-bc2f-5357b56f70ea", "3": "1977f293-ae63-43de-9303-a53039269190"}}, "__type__": "1"}, "1977f293-ae63-43de-9303-a53039269190": {"__data__": {"text": "to x via y. Since y believes that z has no path \nto x, y will never attempt to route to x via z, as long as z continues to route to x via y \n(and lies about doing so).\nLet\u2019s now see how poisoned reverse solves the particular looping problem we \nencountered before in Figure 5.5(b). As a result of the poisoned reverse, y\u2019s distance \ntable indicates Dz(x)=\u221e. When the cost of the (x, y) link changes from 4 to 60 at \ntime t0, y updates its table and continues to route directly to x, albeit at a higher cost \nof 60, and informs z of its new cost to x, that is, Dy(x) = 60. After receiving the \nupdate at t1, z immediately shifts its route to x to be via the direct ( z, x) link at a cost \nof 50. Since this is a new least-cost path to x, and since the path no longer passes \nthrough y, z now informs y that Dz(x)=50 at t2. After receiving the update from \nz, y updates its distance table with Dy(x)=51. Also, since z is now on y\u2019s least-\ncost path to x, y poisons the reverse path from z to x by informing z at time t3 that \nDy(x)=\u221e (even though y knows that Dy(x)=51 in truth).\nDoes poisoned reverse solve the general count-to-infinity problem? It does not. \nYou should convince yourself that loops involving three or more nodes (rather than \nsimply two immediately neighboring nodes) will not be detected by the poisoned \nreverse technique.\nA Comparison of LS and DV Routing Algorithms\nThe DV and LS algorithms take complementary approaches toward computing rout -\ning. In the DV algorithm, each node talks to only its directly connected neighbors, \nbut it provides its neighbors with least-cost estimates from itself to all the nodes \n(that it knows about) in the network. The LS algorithm requires global information. \nConsequently, when implemented in each and every router, e.g., as in Figure 4.2 and \n5.1, each node would need to communicate with all other nodes (via broadcast), but \nit tells them only the costs of its directly connected links. Let\u2019s conclude our study \nof LS and DV algorithms with a quick comparison of some of their attributes. Recall \nthat N is the set of nodes (routers) and E is the set of edges (links).\n\u2022 Message complexity.  We have seen that LS requires each node to know the cost \nof each link in the network. This requires O(|N| |E|) messages to be sent. Also, \n5.3  \u2022  INTRA-AS ROUTING IN THE INTERNET: OSPF      419\nwhenever a link cost changes, the new link cost must be sent to all nodes. The DV \nalgorithm requires message exchanges between directly connected neighbors at \neach iteration. We have seen that the time needed for the algorithm to converge \ncan depend on many factors. When link costs change, the DV algorithm will \npropagate the results of the changed link cost only if the new link cost results in a \nchanged least-cost path for one of the nodes attached to that link.\n\u2022 Speed of convergence.  We have seen that our implementation of LS is an O(|N|2) \nalgorithm requiring O(|N| |E|)) messages. The DV algorithm can converge slowly \nand can have routing loops while the algorithm is converging. DV also suffers \nfrom the count-to-infinity problem.\n\u2022 Robustness.  What can happen if a router fails, misbehaves, or is sabotaged? \nUnder LS, a router could broadcast an incorrect cost for one of its attached links \n(but no others). A node could also corrupt or drop any packets it received as part \nof an LS broadcast. But an LS node is computing only its own forwarding tables; \nother nodes are performing similar", "doc_id": "1977f293-ae63-43de-9303-a53039269190", "embedding": null, "doc_hash": "1f48cd3730214648baf24aa0a8930a31c64a846432cc8743aee98eabc37c74fd", "extra_info": null, "node_info": {"start": 1215909, "end": 1219377}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "21fce722-6ee1-4f45-b562-4d63c2c7ea2b", "3": "6f81abfc-cbc2-4a0a-a9d4-d0a924372457"}}, "__type__": "1"}, "6f81abfc-cbc2-4a0a-a9d4-d0a924372457": {"__data__": {"text": "of the nodes attached to that link.\n\u2022 Speed of convergence.  We have seen that our implementation of LS is an O(|N|2) \nalgorithm requiring O(|N| |E|)) messages. The DV algorithm can converge slowly \nand can have routing loops while the algorithm is converging. DV also suffers \nfrom the count-to-infinity problem.\n\u2022 Robustness.  What can happen if a router fails, misbehaves, or is sabotaged? \nUnder LS, a router could broadcast an incorrect cost for one of its attached links \n(but no others). A node could also corrupt or drop any packets it received as part \nof an LS broadcast. But an LS node is computing only its own forwarding tables; \nother nodes are performing similar calculations for themselves. This means route \ncalculations are somewhat separated under LS, providing a degree of robustness. \nUnder DV, a node can advertise incorrect least-cost paths to any or all destina -\ntions. (Indeed, in 1997, a malfunctioning router in a small ISP provided national \nbackbone routers with erroneous routing information. This caused other routers \nto flood the malfunctioning router with traffic and caused large portions of the \nInternet to become disconnected for up to several hours [Neumann 1997].) More \ngenerally, we note that, at each iteration, a node\u2019s calculation in DV is passed on \nto its neighbor and then indirectly to its neighbor\u2019s neighbor on the next iteration. \nIn this sense, an incorrect node calculation can be diffused through the entire \nnetwork under DV.\nIn the end, neither algorithm is an obvious winner over the other; indeed, both algo -\nrithms are used in the Internet.\n5.3 Intra-AS Routing in the Internet: OSPF\nIn our study of routing algorithms so far, we\u2019ve viewed the network simply as a \ncollection of interconnected routers. One router was indistinguishable from another \nin the sense that all routers executed the same routing algorithm to compute routing \npaths through the entire network. In practice, this model and its view of a homog -\nenous set of routers all executing the same routing algorithm is simplistic for two \nimportant reasons:\n\u2022 Scale.  As the number of routers becomes large, the overhead involved in communi -\ncating, computing, and storing routing information becomes prohibitive. Today\u2019s \nInternet consists of hundreds of millions of routers. Storing routing information  \n420     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\nfor possible destinations at each of these routers would clearly require enormous \namounts of memory. The overhead required to broadcast connectivity and link \ncost updates among all of the routers would be huge! A distance-vector algorithm \nthat iterated among such a large number of routers would surely never converge. \nClearly, something must be done to reduce the complexity of route computation \nin a network as large as the Internet.\n\u2022 Administrative autonomy.  As described in Section 1.3, the Internet is a network \nof ISPs, with each ISP consisting of its own network of routers. An ISP generally \ndesires to operate its network as it pleases (for example, to run whatever rout -\ning algorithm it chooses within its network) or to hide aspects of its network\u2019s \ninternal organization from the outside. Ideally, an organization should be able to \noperate and administer its network as it wishes, while still being able to connect \nits network to other outside networks.\nBoth of these problems can be solved by organizing routers into autonomous \n systems (ASs) , with each AS consisting of a group of routers that are under the same \nadministrative control. Often the routers in an ISP, and the links that interconnect \nthem, constitute a single AS. Some ISPs, however, partition their network into multi -\nple ASs. In particular, some tier-1 ISPs use one gigantic", "doc_id": "6f81abfc-cbc2-4a0a-a9d4-d0a924372457", "embedding": null, "doc_hash": "b76707769e21ed090c6388be9527c61757e5765893b0d2439a93e71b09d69019", "extra_info": null, "node_info": {"start": 1219327, "end": 1223094}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "1977f293-ae63-43de-9303-a53039269190", "3": "95dc9d08-7ec6-407d-82c9-a0de285dc48d"}}, "__type__": "1"}, "95dc9d08-7ec6-407d-82c9-a0de285dc48d": {"__data__": {"text": "An ISP generally \ndesires to operate its network as it pleases (for example, to run whatever rout -\ning algorithm it chooses within its network) or to hide aspects of its network\u2019s \ninternal organization from the outside. Ideally, an organization should be able to \noperate and administer its network as it wishes, while still being able to connect \nits network to other outside networks.\nBoth of these problems can be solved by organizing routers into autonomous \n systems (ASs) , with each AS consisting of a group of routers that are under the same \nadministrative control. Often the routers in an ISP, and the links that interconnect \nthem, constitute a single AS. Some ISPs, however, partition their network into multi -\nple ASs. In particular, some tier-1 ISPs use one gigantic AS for their entire network, \nwhereas others break up their ISP into tens of interconnected ASs. An autonomous \nsystem is identified by its globally unique autonomous system number (ASN) [RFC \n1930]. AS numbers, like IP addresses, are assigned by ICANN regional registries \n[ICANN 2016].\nRouters within the same AS all run the same routing algorithm and have infor -\nmation about each other. The routing algorithm  running within an autonomous sys -\ntem is called an intra-autonomous system routing  protocol .\nOpen Shortest Path First (OSPF) \nOSPF routing and its closely related cousin, IS-IS, are widely used for intra-AS \nrouting in the Internet. The Open in OSPF indicates that the routing protocol speci -\nfication is publicly available (for example, as opposed to Cisco\u2019s EIGRP protocol, \nwhich was only recently became open [Savage 2015], after roughly 20 years as a \nCisco-proprietary protocol). The most recent version of OSPF, version 2, is defined \nin [RFC 2328], a public document.\nOSPF is a link-state protocol that uses flooding of link-state information \nand a Dijkstra\u2019s least-cost path algorithm. With OSPF, each router constructs \na complete topological map (that is, a graph) of the entire autonomous system. \nEach router then locally runs Dijkstra\u2019s shortest-path algorithm to determine a \nshortest-path tree to all subnets , with itself as the root node. Individual link costs \nare configured by the network administrator (see sidebar, Principles and Practice: \nSetting OSPF Weights). The administrator might choose to set all link costs to 1, \n5.3  \u2022  INTRA-AS ROUTING IN THE INTERNET: OSPF      421\nthus achieving minimum-hop routing, or might choose to set the link weights to \nbe inversely proportional to link capacity in order to discourage traffic from using \nlow-bandwidth links. OSPF does not mandate a policy for how link weights are \nset (that is the job of the  network administrator), but instead provides the mecha -\nnisms (protocol) for determining least-cost path routing for the given set of link \nweights.\nWith OSPF, a router broadcasts routing information to all other routers in the \nautonomous system, not just to its neighboring routers. A router broadcasts link-state \ninformation whenever there is a change in a link\u2019s state (for example, a change in \ncost or a change in up/down status). It also broadcasts a link\u2019s state periodically (at \nleast once every 30 minutes), even if the link\u2019s state has not changed. RFC 2328 \nnotes that \u201cthis periodic updating of link state advertisements adds robustness to the \nlink state algorithm.\u201d OSPF advertisements are contained in OSPF messages that are SETTING OSPF LINK WEIGHTS\nOur discussion of link-state routing has implicitly assumed that link weights are set, a \nrouting algorithm such as OSPF is run, and traffic flows according to the routing tables \ncomputed by the LS algorithm. In terms of cause and effect, the link weights are given (i.e., \nthey come first) and result (via Dijkstra\u2019s", "doc_id": "95dc9d08-7ec6-407d-82c9-a0de285dc48d", "embedding": null, "doc_hash": "f381870ccaeac5c199dd46f759bbb97334695264249ddc83e3cbac288fa399f4", "extra_info": null, "node_info": {"start": 1223003, "end": 1226771}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "6f81abfc-cbc2-4a0a-a9d4-d0a924372457", "3": "9c620293-22e4-46a0-b215-fa20fb929542"}}, "__type__": "1"}, "9c620293-22e4-46a0-b215-fa20fb929542": {"__data__": {"text": "a link\u2019s state (for example, a change in \ncost or a change in up/down status). It also broadcasts a link\u2019s state periodically (at \nleast once every 30 minutes), even if the link\u2019s state has not changed. RFC 2328 \nnotes that \u201cthis periodic updating of link state advertisements adds robustness to the \nlink state algorithm.\u201d OSPF advertisements are contained in OSPF messages that are SETTING OSPF LINK WEIGHTS\nOur discussion of link-state routing has implicitly assumed that link weights are set, a \nrouting algorithm such as OSPF is run, and traffic flows according to the routing tables \ncomputed by the LS algorithm. In terms of cause and effect, the link weights are given (i.e., \nthey come first) and result (via Dijkstra\u2019s algorithm) in routing paths that minimize overall \ncost. In this viewpoint, link weights reflect the cost of using a link (e.g., if link weights are \ninversely proportional to capacity, then the use of high-capacity links would have smaller \nweight and thus be more attractive from a routing standpoint) and Dijsktra\u2019s algorithm \nserves to minimize overall cost.\nIn practice, the cause and effect relationship between link weights and routing paths \nmay be reversed, with network operators configuring link weights in order to obtain rout -\ning paths that achieve certain traffic engineering goals [Fortz 2000, Fortz 2002]. For \nexample, suppose a network operator has an estimate of traffic flow entering the network \nat each ingress point and destined for each egress point. The operator may then want \nto put in place a specific routing of ingress-to-egress flows that minimizes the maximum \nutilization over all of the network\u2019s links. But with a routing algorithm such as OSPF, the \noperator\u2019s main \u201cknobs\u201d for tuning the routing of flows through the network are the link \nweights. Thus, in order to achieve the goal of minimizing the maximum link utilization, the \noperator must find the set of link weights that achieves this goal. This is a reversal of the \ncause and effect relationship\u2014the desired routing of flows is known, and the OSPF link \nweights must be found such that the OSPF routing algorithm results in this desired routing \nof flows.PRINCIPLES IN PRACTICE\n\n422     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\ncarried directly by IP, with an upper-layer protocol of 89 for OSPF. Thus, the OSPF \nprotocol must itself implement functionality such as reliable message transfer and \nlink-state broadcast. The OSPF protocol also checks that links are operational (via a \nHELLO message that is sent to an attached neighbor) and allows an OSPF router to \nobtain a neighboring router\u2019s database of network-wide link state.\nSome of the advances embodied in OSPF include the following:\n\u2022 Security.  Exchanges between OSPF routers (for example, link-state updates) can \nbe authenticated. With authentication, only trusted routers can participate in the \nOSPF protocol within an AS, thus preventing malicious intruders (or networking \nstudents taking their newfound knowledge out for a joyride) from injecting incor -\nrect information into router tables. By default, OSPF packets between routers are \nnot authenticated and could be forged. Two types of authentication can be con -\nfigured\u2014simple and MD5 (see Chapter 8 for a discussion on MD5 and authenti -\ncation in general). With simple authentication, the same password is configured \non each router. When a router sends an OSPF packet, it includes the password in \nplaintext. Clearly, simple authentication is not very secure. MD5 authentication is \nbased on shared secret keys that are configured in all the routers. For each OSPF \npacket that it sends, the router computes the MD5 hash of the content of the OSPF \npacket appended with the secret key. (See the discussion of message authentica -\ntion codes in Chapter 8 .) Then the router includes the resulting hash value in the \nOSPF", "doc_id": "9c620293-22e4-46a0-b215-fa20fb929542", "embedding": null, "doc_hash": "a8d4d81f800d4240b0f320a7ac25a51453f617028af624d572da7aff2299e8ca", "extra_info": null, "node_info": {"start": 1226818, "end": 1230703}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "95dc9d08-7ec6-407d-82c9-a0de285dc48d", "3": "b232ce0d-fc44-44cc-acb2-e4b51841f290"}}, "__type__": "1"}, "b232ce0d-fc44-44cc-acb2-e4b51841f290": {"__data__": {"text": "tables. By default, OSPF packets between routers are \nnot authenticated and could be forged. Two types of authentication can be con -\nfigured\u2014simple and MD5 (see Chapter 8 for a discussion on MD5 and authenti -\ncation in general). With simple authentication, the same password is configured \non each router. When a router sends an OSPF packet, it includes the password in \nplaintext. Clearly, simple authentication is not very secure. MD5 authentication is \nbased on shared secret keys that are configured in all the routers. For each OSPF \npacket that it sends, the router computes the MD5 hash of the content of the OSPF \npacket appended with the secret key. (See the discussion of message authentica -\ntion codes in Chapter 8 .) Then the router includes the resulting hash value in the \nOSPF packet. The receiving router, using the preconfigured secret key, will com -\npute an MD5 hash of the packet and compare it with the hash value that the packet \ncarries, thus verifying the packet\u2019s authenticity. Sequence numbers are also used \nwith MD5 authentication to protect against replay attacks.\n\u2022 Multiple same-cost paths.  When multiple paths to a destination have the same \ncost, OSPF allows multiple paths to be used (that is, a single path need not be \nchosen for carrying all traffic when multiple equal-cost paths exist).\n\u2022 Integrated support for unicast and multicast routing.  Multicast OSPF (MOSPF) \n[RFC 1584] provides simple extensions to OSPF to provide for multicast routing. \nMOSPF uses the existing OSPF link database and adds a new type of link-state \nadvertisement to the existing OSPF link-state broadcast mechanism.\n\u2022 Support for hierarchy within a single AS.  An OSPF autonomous system can \nbe configured hierarchically into areas. Each area runs its own OSPF link-state \nrouting algorithm, with each router in an area broadcasting its link state to all \nother routers in that area. Within each area, one or more area border routers are \nresponsible for routing packets outside the area. Lastly, exactly one OSPF area \nin the AS is configured to be the backbone area. The primary role of the back -\nbone area is to route traffic between the other areas in the AS. The backbone \nalways contains all area border routers in the AS and may contain non-border \nrouters as well. Inter-area routing within the AS requires that the packet be first \n5.4  \u2022  ROUTING AMONG THE ISPS: BGP      423\nrouted to an area border router (intra-area routing), then routed through the back -\nbone to the area border router that is in the destination area, and then routed to \nthe final destination.\nOSPF is a relatively complex protocol, and our coverage here has been necessar -\nily brief; [Huitema 1998; Moy 1998; RFC 2328] provide additional details.\n5.4 Routing Among the ISPs: BGP\nWe just learned that OSPF is an example of an intra-AS routing protocol. When \nrouting a packet between a source and destination within the same AS, the route the \npacket follows is entirely determined by the intra-AS routing protocol. However, to \nroute a packet across multiple ASs, say from a smartphone in Timbuktu to a server \nin a datacenter in Silicon Valley, we need an inter-autonomous system routing \nprotocol . Since an inter-AS routing protocol involves coordination among multiple \nASs, communicating ASs must run the same inter-AS routing protocol. In fact, in the \nInternet, all ASs run the same inter-AS routing protocol, called the Border Gateway \nProtocol, more commonly known as BGP  [RFC 4271; Stewart 1999].\nBGP is arguably the most important of all the Internet protocols (the only other \ncontender would be the IP protocol that we studied in Section 4.3 ), as it is the pro -\ntocol that glues the thousands of ISPs in the Internet together. As we will soon see, \nBGP is a decentralized and asynchronous", "doc_id": "b232ce0d-fc44-44cc-acb2-e4b51841f290", "embedding": null, "doc_hash": "45facab2ceaca36ab6347dbb1567836485d3ed7927db4bc0fe7c7c9403d566d4", "extra_info": null, "node_info": {"start": 1230650, "end": 1234462}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "9c620293-22e4-46a0-b215-fa20fb929542", "3": "c6752815-236e-4a24-bf8a-b881af2b4106"}}, "__type__": "1"}, "c6752815-236e-4a24-bf8a-b881af2b4106": {"__data__": {"text": "a smartphone in Timbuktu to a server \nin a datacenter in Silicon Valley, we need an inter-autonomous system routing \nprotocol . Since an inter-AS routing protocol involves coordination among multiple \nASs, communicating ASs must run the same inter-AS routing protocol. In fact, in the \nInternet, all ASs run the same inter-AS routing protocol, called the Border Gateway \nProtocol, more commonly known as BGP  [RFC 4271; Stewart 1999].\nBGP is arguably the most important of all the Internet protocols (the only other \ncontender would be the IP protocol that we studied in Section 4.3 ), as it is the pro -\ntocol that glues the thousands of ISPs in the Internet together. As we will soon see, \nBGP is a decentralized and asynchronous protocol in the vein of distance-vector \nrouting described in Section 5.2.2. Although BGP is a complex and challenging pro -\ntocol, to understand the Internet on a deep level, we need to become familiar with \nits underpinnings and operation. The time we devote to learning BGP will be well \nworth the effort.\n5.4.1  The Role of BGP\nTo understand the responsibilities of BGP, consider an AS and an arbitrary router \nin that AS. Recall that every router has a forwarding table, which plays the central \nrole in the process of forwarding arriving packets to outbound router links. As we \nhave learned, for destinations that are within the same AS, the entries in the router\u2019s \nforwarding table are determined by the AS\u2019s intra-AS routing protocol. But what \nabout destinations that are outside of the AS? This is precisely where BGP comes to \nthe rescue.\nIn BGP, packets are not routed to a specific destination address, but instead to \nCIDRized prefixes, with each prefix representing a subnet or a collection of subnets. \nIn the world of BGP, a destination may take the form 138.16.68/22, which for this \n424     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\nexample includes 1,024 IP addresses. Thus, a router\u2019s forwarding table will have \nentries of the form ( x, I), where x is a prefix (such as 138.16.68/22) and I is an inter -\nface number for one of the router\u2019s interfaces.\nAs an inter-AS routing protocol, BGP provides each router a means to:\n 1. Obtain prefix reachability information from neighboring ASs.  In particular, \nBGP allows each subnet to advertise its existence to the rest of the Internet. A \nsubnet screams, \u201cI exist and I am here,\u201d and BGP makes sure that all the rout -\ners in the Internet know about this subnet. If it weren\u2019t for BGP, each subnet \nwould be an isolated island\u2014alone, unknown and unreachable by the rest of the \nInternet.\n 2. Determine the \u201cbest\u201d routes to the prefixes.  A router may learn about two or \nmore different routes to a specific prefix. To determine the best route, the router \nwill locally run a BGP route-selection procedure (using the prefix reachability \ninformation it obtained via neighboring routers). The best route will be deter -\nmined based on policy as well as the reachability information.\nLet us now delve into how BGP carries out these two tasks.\n5.4.2  Advertising BGP Route Information\nConsider the network shown in Figure 5.8. As we can see, this simple network has \nthree autonomous systems: AS1, AS2, and AS3. As shown, AS3 includes a subnet \nwith prefix x. For each AS, each router is either a gateway router  or an internal \nrouter . A gateway router is a router on the edge of an AS that directly connects to \none or more routers in other ASs. An internal router  connects only to hosts and \nrouters within its own AS. In AS1, for example, router 1c is a gateway", "doc_id": "c6752815-236e-4a24-bf8a-b881af2b4106", "embedding": null, "doc_hash": "47436f5823daa52143376c06bdcac56c8c3c133c933e292719575f0a12e46ad0", "extra_info": null, "node_info": {"start": 1234516, "end": 1238090}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "b232ce0d-fc44-44cc-acb2-e4b51841f290", "3": "93077e6d-0807-4f30-8372-d631d59f1251"}}, "__type__": "1"}, "93077e6d-0807-4f30-8372-d631d59f1251": {"__data__": {"text": "neighboring routers). The best route will be deter -\nmined based on policy as well as the reachability information.\nLet us now delve into how BGP carries out these two tasks.\n5.4.2  Advertising BGP Route Information\nConsider the network shown in Figure 5.8. As we can see, this simple network has \nthree autonomous systems: AS1, AS2, and AS3. As shown, AS3 includes a subnet \nwith prefix x. For each AS, each router is either a gateway router  or an internal \nrouter . A gateway router is a router on the edge of an AS that directly connects to \none or more routers in other ASs. An internal router  connects only to hosts and \nrouters within its own AS. In AS1, for example, router 1c is a gateway router; routers \n1a, 1b, and 1d are internal routers.\nLet\u2019s consider the task of advertising reachability information for prefix x to \nall of the routers shown in Figure 5.8. At a high level, this is straightforward. First, \nAS3 sends a BGP message to AS2, saying that x exists and is in AS3; let\u2019s denote \nthis message as \u201cAS3 x\u201d. Then AS2 sends a BGP message to AS1, saying that x \nexists and that you can get to x by first passing through AS2 and then going to AS3; \nlet\u2019s denote that message as \u201cAS2 AS3 x\u201d. In this manner, each of the autonomous \nsystems will not only learn about the existence of x, but also learn about a path of \nautonomous systems that leads to x. \nAlthough the discussion in the above paragraph about advertising BGP reacha -\nbility information should get the general idea across, it is not precise in the sense that \nautonomous systems do not actually send messages to each other, but instead routers \ndo. To understand this, let\u2019s now re-examine the example in Figure 5.8. In BGP, \n5.4  \u2022  ROUTING AMONG THE ISPS: BGP      425\npairs of routers exchange routing information over semi-permanent TCP connections \nusing port 179. Each such TCP connection, along with all the BGP messages sent \nover the connection, is called a BGP connection . Furthermore, a BGP connection \nthat spans two ASs is called an external BGP (eBGP)  connection, and a BGP ses -\nsion between routers in the same AS is called an internal BGP (iBGP)  connection. \nExamples of BGP connections for the network in Figure 5.8 are shown in Figure 5.9. \nThere is typically one eBGP connection for each link that directly connects gateway \nrouters in different ASs; thus, in Figure 5.9, there is an eBGP connection between \ngateway routers 1c and 2a and an eBGP connection between gateway routers 2c  \nand 3a.\nThere are also iBGP connections between routers within each of the ASs. In \nparticular, Figure 5.9 displays a common configuration of one BGP connection for \neach pair of routers internal to an AS, creating a mesh of TCP connections within \neach AS. In Figure 5.9, the eBGP connections are shown with the long dashes; the \niBGP connections are shown with the short dashes. Note that iBGP connections do \nnot always correspond to physical links.\nIn order to propagate the reachability information, both iBGP and eBGP ses -\nsions are used. Consider again advertising the reachability information for prefix x \nto all routers in AS1 and AS2. In this process, gateway router 3a first sends an eBGP \nmessage \u201cAS3 x\u201d to gateway router 2c. Gateway router 2c then sends the iBGP \nmessage \u201cAS3 x\u201d to all of the other routers in AS2, including to gateway router 2a. \nGateway router 2a then sends the eBGP message \u201cAS2 AS3 x\u201d to gateway router 1c. 2b\n2d2a 2c\nAS21b\n1d1a", "doc_id": "93077e6d-0807-4f30-8372-d631d59f1251", "embedding": null, "doc_hash": "c825bf8cd7ac42d582e580b7fb2db4e80900aa8a988a9d84a01efb399090566f", "extra_info": null, "node_info": {"start": 1238129, "end": 1241589}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "c6752815-236e-4a24-bf8a-b881af2b4106", "3": "c520cb25-2157-4332-b8d8-7764e565eb07"}}, "__type__": "1"}, "c520cb25-2157-4332-b8d8-7764e565eb07": {"__data__": {"text": "are shown with the short dashes. Note that iBGP connections do \nnot always correspond to physical links.\nIn order to propagate the reachability information, both iBGP and eBGP ses -\nsions are used. Consider again advertising the reachability information for prefix x \nto all routers in AS1 and AS2. In this process, gateway router 3a first sends an eBGP \nmessage \u201cAS3 x\u201d to gateway router 2c. Gateway router 2c then sends the iBGP \nmessage \u201cAS3 x\u201d to all of the other routers in AS2, including to gateway router 2a. \nGateway router 2a then sends the eBGP message \u201cAS2 AS3 x\u201d to gateway router 1c. 2b\n2d2a 2c\nAS21b\n1d1a 1c\nAS13b\n3d3a 3c\nAS3X\nFigure 5.8  \u2666  Network with three autonomous systems. AS3 includes a  \nsubnet with prefix x\n426     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\nFinally, gateway router 1c uses iBGP to send the message \u201cAS2 AS3 x\u201d to all the \nrouters in AS1. After this process is complete, each router in AS1 and AS2 is aware \nof the existence of x and is also aware of an AS path that leads to x.\nOf course, in a real network, from a given router there may be many different \npaths to a given destination, each through a different sequence of ASs. For example, \nconsider the network in Figure 5.10, which is the original network in Figure 5.8, with \nan additional physical link from router 1d to router 3d. In this case, there are two \npaths from AS1 to x: the path \u201cAS2 AS3 x\u201d via router 1c; and the new path \u201cAS3 x\u201d \nvia the router 1d.\n5.4.3  Determining the Best Routes\nAs we have just learned, there may be many paths from a given router to a destina -\ntion subnet. In fact, in the Internet, routers often receive reachability information \nabout dozens of different possible paths. How does a router choose among these \npaths (and then configure its forwarding table accordingly)?\nBefore addressing this critical question, we need to introduce a little more \nBGP terminology. When a router advertises a prefix across a BGP connection, it \nincludes with the prefix several BGP attributes . In BGP jargon, a prefix along with \nits attributes is called a route . Two of the more important attributes are AS-PATH \nand NEXT-HOP. The AS-PATH attribute contains the list of ASs through which the eBGPKey:\niBGP2b\n2d2a 2c\nAS21b\n1d1a 1c\nAS13b\n3d3a 3c\nAS3X\nFigure 5.9  \u2666 eBGP and iBGP connections\n5.4  \u2022  ROUTING AMONG THE ISPS: BGP      427\nadvertisement has passed, as we\u2019ve seen in our examples above. To generate the AS-\nPATH value, when a prefix is passed to an AS, the AS adds its ASN to the existing \nlist in the AS-PATH. For example, in Figure 5.10, there are two routes from AS1 \nto subnet x: one which uses the AS-PATH \u201cAS2 AS3\u201d; and another that uses the \nAS-PATH \u201cA3\u201d. BGP routers also use the AS-PATH attribute to detect and prevent \nlooping advertisements; specifically, if a router sees that its own AS is contained in \nthe path list, it will reject the advertisement.\nProviding the critical link between the inter-AS and intra-AS routing protocols, \nthe NEXT-HOP attribute has a subtle but important use. The NEXT-HOP is the IP \naddress of the router interface that begins the AS-PATH . To gain insight into this \nattribute, let\u2019s again refer to Figure 5.10. As indicated in Figure 5.10, the NEXT-\nHOP attribute for the", "doc_id": "c520cb25-2157-4332-b8d8-7764e565eb07", "embedding": null, "doc_hash": "ce3bd6e60f3d3e70955d944be638464d9af8447fe8388120d65929a4c866d0b7", "extra_info": null, "node_info": {"start": 1241648, "end": 1244907}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "93077e6d-0807-4f30-8372-d631d59f1251", "3": "bb53949d-4ddb-4384-a1e6-eefbb628acf1"}}, "__type__": "1"}, "bb53949d-4ddb-4384-a1e6-eefbb628acf1": {"__data__": {"text": "are two routes from AS1 \nto subnet x: one which uses the AS-PATH \u201cAS2 AS3\u201d; and another that uses the \nAS-PATH \u201cA3\u201d. BGP routers also use the AS-PATH attribute to detect and prevent \nlooping advertisements; specifically, if a router sees that its own AS is contained in \nthe path list, it will reject the advertisement.\nProviding the critical link between the inter-AS and intra-AS routing protocols, \nthe NEXT-HOP attribute has a subtle but important use. The NEXT-HOP is the IP \naddress of the router interface that begins the AS-PATH . To gain insight into this \nattribute, let\u2019s again refer to Figure 5.10. As indicated in Figure 5.10, the NEXT-\nHOP attribute for the route \u201cAS2 AS3 x\u201d from AS1 to x that passes through AS2 \nis the IP address of the left interface on router 2a. The NEXT-HOP attribute for the \nroute \u201cAS3 x\u201d from AS1 to x that bypasses AS2 is the IP address of the leftmost \ninterface of router 3d. In summary, in this toy example, each router in AS1 becomes \naware of two BGP routes to prefix x:\nIP address of leftmost interface for router 2a; AS2 AS3; x\nIP address of leftmost interface of router 3d; AS3; x\nHere, each BGP route is written as a list with three components: NEXT-HOP; AS-\nPATH; destination prefix. In practice, a BGP route includes additional attributes, \nwhich we will ignore for the time being. Note that the NEXT-HOP attribute is an IP NEXT-HOP\nNEXT-HOP2b\n2d2a 2c\nAS21b\n1d1a 1c\nAS13b\n3d3a 3c\nAS3X\nFigure 5.10  \u2666  Network augmented with peering link between AS1  \nand AS3\n428     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\naddress of a router that does not belong to AS1; however, the subnet that contains \nthis IP address directly attaches to AS1.\nHot Potato Routing\nWe are now finally  in position to talk about BGP routing algorithms in a precise \nmanner. We will begin with one of the simplest routing algorithms, namely, hot \npotato routing .\nConsider router 1b in the network in Figure 5.10. As just described, this router \nwill learn about two possible BGP routes to prefix x. In hot potato routing, the route \nchosen (from among all  possible routes) is that route with the least cost to the NEXT-\nHOP router beginning that route. In this example, router 1b will consult its intra-AS \nrouting information to find the least-cost intra-AS path to NEXT-HOP router 2a and \nthe least-cost intra-AS path to NEXT-HOP router 3d, and then select the route with \nthe smallest of these least-cost paths. For example, suppose that cost is defined as the \nnumber of links traversed. Then the least cost from router 1b to router 2a is 2, the least \ncost from router 1b to router 2d is 3, and router 2a would therefore be selected. Router \n1b would then consult its forwarding table (configured by its intra-AS algorithm) and \nfind the interface I that is on the least-cost path to router 2a. It then adds ( x, I) to its \nforwarding table.\nThe steps for adding an outside-AS prefix in a router\u2019s forwarding table for hot \npotato routing are summarized in Figure 5.11. It is important to note that when add -\ning an outside-AS prefix into a forwarding table, both the inter-AS routing protocol \n(BGP) and the intra-AS routing protocol (e.g., OSPF) are used.\nThe idea behind hot-potato routing is for router 1b to get packets out of its \nAS", "doc_id": "bb53949d-4ddb-4384-a1e6-eefbb628acf1", "embedding": null, "doc_hash": "a45a4fbbfefeff83563266d02cea2d7e56c4f951ae1d943abbdec595808c59f4", "extra_info": null, "node_info": {"start": 1244862, "end": 1248140}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "c520cb25-2157-4332-b8d8-7764e565eb07", "3": "cb3ab435-cd83-45af-bf99-b2b22de2638d"}}, "__type__": "1"}, "cb3ab435-cd83-45af-bf99-b2b22de2638d": {"__data__": {"text": "router 2d is 3, and router 2a would therefore be selected. Router \n1b would then consult its forwarding table (configured by its intra-AS algorithm) and \nfind the interface I that is on the least-cost path to router 2a. It then adds ( x, I) to its \nforwarding table.\nThe steps for adding an outside-AS prefix in a router\u2019s forwarding table for hot \npotato routing are summarized in Figure 5.11. It is important to note that when add -\ning an outside-AS prefix into a forwarding table, both the inter-AS routing protocol \n(BGP) and the intra-AS routing protocol (e.g., OSPF) are used.\nThe idea behind hot-potato routing is for router 1b to get packets out of its \nAS as quickly as possible (more specifically, with the least cost possible) without \nworrying about the cost of the remaining portions of the path outside of its AS to \nthe destination. In the name \u201chot potato routing,\u201d a packet is analogous to a hot \npotato that is burning in your hands. Because it is burning hot, you want to pass it \noff to another person (another AS) as quickly as possible. Hot potato routing is thus \nLearn from inter-AS\nprotocol that subnet\nx is reachable via\nmultiple gateways.Use routing info from\nintra-AS protocol to\ndetermine costs of\nleast-cost paths to\neach of the gateways.Hot potato routing:\nChoose the gateway\nthat has the\nsmallest least cost.Determine from\nforwarding table the\ninterface I that leads\nto least-cost gateway.\nEnter (x,I) in\nforwarding table.\nFigure 5.11  \u2666  Steps in adding outside-AS destination in a router\u2019s \n forwarding table\n5.4  \u2022  ROUTING AMONG THE ISPS: BGP      429\na selfish  algorithm\u2014it tries to reduce the cost in its own AS while ignoring the other \ncomponents of the end-to-end costs outside its AS. Note that with hot potato routing, \ntwo routers in the same AS may choose two different AS paths to the same prefix. \nFor example, we just saw that router 1b would send packets through AS2 to reach  \nx. However, router 1d would bypass AS2 and send packets directly to AS3 to reach x.\nRoute-Selection Algorithm\nIn practice, BGP uses an algorithm that is more complicated than hot potato routing, \nbut nevertheless incorporates hot potato routing. For any given destination prefix, the \ninput into BGP\u2019s route-selection algorithm is the set of all routes to that prefix that have \nbeen learned and accepted by the router. If there is only one such route, then BGP obvi -\nously selects that route. If there are two or more routes to the same prefix, then BGP \nsequentially invokes the following elimination rules until one route remains:\n 1. A route is assigned a local preference  value as one of its attributes (in addition \nto the AS-PATH and NEXT-HOP attributes). The local preference of a route \ncould have been set by the router or could have been learned from another router \nin the same AS. The value of the local preference attribute is a policy decision \nthat is left entirely up to the AS\u2019s network administrator. (We will shortly dis -\ncuss BGP policy issues in some detail.) The routes with the highest local prefer -\nence values are selected.\n 2. From the remaining routes (all with the same highest local preference value), \nthe route with the shortest AS-PATH is selected. If this rule were the only rule \nfor route selection, then BGP would be using a DV algorithm for path determi -\nnation, where the distance metric uses the number of AS hops rather than the \nnumber of router hops.\n 3. From the remaining routes (all with the same highest local preference value and \nthe same AS-PATH length), hot potato routing is used, that is, the route with the \nclosest NEXT-HOP", "doc_id": "cb3ab435-cd83-45af-bf99-b2b22de2638d", "embedding": null, "doc_hash": "fdda4895be2aeddb15c60f5c4c24dc138b20a633635d014b699f855d8838841c", "extra_info": null, "node_info": {"start": 1248150, "end": 1251762}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "bb53949d-4ddb-4384-a1e6-eefbb628acf1", "3": "484996ef-8748-415e-a429-4cccfd7ee5bb"}}, "__type__": "1"}, "484996ef-8748-415e-a429-4cccfd7ee5bb": {"__data__": {"text": "attribute is a policy decision \nthat is left entirely up to the AS\u2019s network administrator. (We will shortly dis -\ncuss BGP policy issues in some detail.) The routes with the highest local prefer -\nence values are selected.\n 2. From the remaining routes (all with the same highest local preference value), \nthe route with the shortest AS-PATH is selected. If this rule were the only rule \nfor route selection, then BGP would be using a DV algorithm for path determi -\nnation, where the distance metric uses the number of AS hops rather than the \nnumber of router hops.\n 3. From the remaining routes (all with the same highest local preference value and \nthe same AS-PATH length), hot potato routing is used, that is, the route with the \nclosest NEXT-HOP router is selected.\n 4. If more than one route still remains, the router uses BGP identifiers to select the \nroute; see [Stewart 1999].\nAs an example, let\u2019s again consider router 1b in Figure 5.10. Recall that there \nare exactly two BGP routes to prefix x, one that passes through AS2 and one that \nbypasses AS2. Also recall that if hot potato routing on its own were used, then BGP \nwould route packets through AS2 to prefix x. But in the above route-selection algo -\nrithm, rule 2 is applied before rule 3, causing BGP to select the route that bypasses \nAS2, since that route has a shorter AS PATH. So we see that with the above route-\nselection algorithm, BGP is no longer a selfish algorithm\u2014it first looks for routes \nwith short AS paths (thereby likely reducing end-to-end delay).\nAs noted above, BGP is the de facto  standard for inter-AS routing for the \nInternet. To see the contents of various BGP routing tables (large!) extracted from \n430     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\nrouters in tier-1 ISPs, see http://www.routeviews.org. BGP routing tables often \ncontain over half a million routes (that is, prefixes and corresponding attributes). \nStatistics about the size and characteristics of BGP routing tables are presented in \n[Potaroo 2016].\n5.4.4  IP-Anycast\nIn addition to being the Internet\u2019s inter-AS routing protocol, BGP is often used to \nimplement the IP-anycast service [RFC 1546, RFC 7094], which is commonly used \nin DNS. To motivate IP-anycast, consider that in many applications, we are inter -\nested in (1) replicating the same content on different servers in many different dis -\npersed geographical locations, and (2) having each user access the content from the \nserver that is closest. For example, a CDN may replicate videos and other objects on \nservers in different countries. Similarly, the DNS system can replicate DNS records \non DNS servers throughout the world. When a user wants to access this replicated \ncontent, it is desirable to point the user to the \u201cnearest\u201d server with the replicated \ncontent. BGP\u2019s route-selection algorithm provides an easy and natural mechanism \nfor doing so.\nTo make our discussion concrete, let\u2019s describe how a CDN might use IP- \nanycast. As shown in Figure 5.12, during the IP-anycast configuration stage, the \nCDN company assigns the same  IP address to each of its servers, and uses stand -\nard BGP to advertise this IP address from each of the servers. When a BGP router \nreceives multiple route advertisements for this IP address, it treats these advertise -\nments as providing different paths to the same physical location (when, in fact, \nthe advertisements are for different paths to different physical locations). When \nconfiguring its routing table, each router will locally use the BGP route-selec -\ntion algorithm to pick the \u201cbest\u201d (for example, closest, as determined by AS-hop \ncounts) route to that IP", "doc_id": "484996ef-8748-415e-a429-4cccfd7ee5bb", "embedding": null, "doc_hash": "342bba3de1047640ebd411bf0ca38575bf9b9a93aa6a57f71b83b02da448273d", "extra_info": null, "node_info": {"start": 1251689, "end": 1255351}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "cb3ab435-cd83-45af-bf99-b2b22de2638d", "3": "1f45241e-f900-447a-8f75-78b81115075b"}}, "__type__": "1"}, "1f45241e-f900-447a-8f75-78b81115075b": {"__data__": {"text": "let\u2019s describe how a CDN might use IP- \nanycast. As shown in Figure 5.12, during the IP-anycast configuration stage, the \nCDN company assigns the same  IP address to each of its servers, and uses stand -\nard BGP to advertise this IP address from each of the servers. When a BGP router \nreceives multiple route advertisements for this IP address, it treats these advertise -\nments as providing different paths to the same physical location (when, in fact, \nthe advertisements are for different paths to different physical locations). When \nconfiguring its routing table, each router will locally use the BGP route-selec -\ntion algorithm to pick the \u201cbest\u201d (for example, closest, as determined by AS-hop \ncounts) route to that IP address. For example, if one BGP route (corresponding to \none location) is only one AS hop away from the router, and all other BGP routes \n(corresponding to other locations) are two or more AS hops away, then the BGP \nrouter would choose to route packets to the location that is one hop away. After \nthis initial BGP address-advertisement phase, the CDN can do its main job of dis -\ntributing content. When a client requests the video, the CDN returns to the client \nthe common IP address used by the geographically dispersed servers, no matter \nwhere the client is located. When the client sends a request to that IP address, \nInternet routers then forward the request packet to the \u201cclosest\u201d server, as defined \nby the BGP route-selection algorithm.\nAlthough the above CDN example nicely illustrates how IP-anycast can be \nused, in practice CDNs generally choose not to use IP-anycast because BGP routing \nchanges can result in different packets of the same TCP connection arriving at dif -\nferent instances of the Web server. But IP-anycast is extensively used by the DNS \nsystem to direct DNS queries to the closest root DNS server. Recall from Section \n2.4, there are currently 13 IP addresses for root DNS servers. But corresponding \n5.4  \u2022  ROUTING AMONG THE ISPS: BGP      431\nto each of these addresses, there are multiple DNS root servers, with some of these \naddresses having over 100 DNS root servers scattered over all corners of the world. \nWhen a DNS query is sent to one of these 13 IP addresses, IP anycast is used to route \nthe query to the nearest of the DNS root servers that is responsible for that address. \n5.4.5  Routing Policy\nWhen a router selects a route to a destination, the AS routing policy can trump all \nother considerations, such as shortest AS path or hot potato routing. Indeed, in the \nroute-selection algorithm, routes are first selected according to the local-preference \nattribute, whose value is fixed by the policy of the local AS.\nLet\u2019s illustrate some of the basic concepts of BGP routing policy with a simple \nexample. Figure 5.13 shows six interconnected autonomous systems: A, B, C, W, X, \nand Y. It is important to note that A, B, C, W, X, and Y are ASs, not routers. Let\u2019s AS1AS33b3c\n3a\n1a1c\n1b\n1dAS2AS4\n2a2c4a 4c4b\nAdvertise\n212.21.21.21\nCDN Server BCDN Server AAdvertise\n212.21.21.21Receive BGP \nadvertisements for\n212.21.21.21 from\nAS1 and from AS4.\nForward toward\nServer B since it is\ncloser.2b\nFigure 5.12  \u2666 Using IP-anycast to bring users to the closest CDN server\n432     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\nassume that autonomous systems W, X, and Y are access ISPs and that A, B, and C \nare backbone provider networks. We\u2019ll also assume that A, B, and C, directly send \ntraffic", "doc_id": "1f45241e-f900-447a-8f75-78b81115075b", "embedding": null, "doc_hash": "87b8fcd6ddbb10f8dbd359825bec7d6e72647dd0585ac9a810d3b254d671b27f", "extra_info": null, "node_info": {"start": 1255368, "end": 1258846}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "484996ef-8748-415e-a429-4cccfd7ee5bb", "3": "1d31a4f9-34ad-4f47-814e-7a2020d31637"}}, "__type__": "1"}, "1d31a4f9-34ad-4f47-814e-7a2020d31637": {"__data__": {"text": "4c4b\nAdvertise\n212.21.21.21\nCDN Server BCDN Server AAdvertise\n212.21.21.21Receive BGP \nadvertisements for\n212.21.21.21 from\nAS1 and from AS4.\nForward toward\nServer B since it is\ncloser.2b\nFigure 5.12  \u2666 Using IP-anycast to bring users to the closest CDN server\n432     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\nassume that autonomous systems W, X, and Y are access ISPs and that A, B, and C \nare backbone provider networks. We\u2019ll also assume that A, B, and C, directly send \ntraffic to each other, and provide full BGP information to their customer networks. \nAll traffic entering an ISP access network must be destined for that network, and  \nall traffic leaving an ISP access network must have originated in that network.  \nW and Y are clearly access ISPs. X is a multi-homed access ISP , since it is con -\nnected to the rest of the network via two different providers (a scenario that is becom -\ning increasingly common in practice). However, like W and Y, X itself must be the \nsource/destination of all traffic leaving/entering X. But how will this stub network \nbehavior be implemented and enforced? How will X be prevented from forwarding \ntraffic between B and C? This can easily be accomplished by controlling the manner \nin which BGP routes are advertised. In particular X will function as an access ISP \nnetwork if it advertises (to its neighbors B and C) that it has no paths to any other \ndestinations except itself. That is, even though X may know of a path, say XCY, that \nreaches network Y, it will not advertise this path to B. Since B is unaware that X has \na path to Y, B would never forward traffic destined to Y (or C) via X. This simple \nexample illustrates how a selective route advertisement policy can be used to imple -\nment customer/provider routing relationships.\nLet\u2019s next focus on a provider network, say AS B. Suppose that B has learned \n(from A) that A has a path AW to W. B can thus install the route AW into its routing \ninformation base. Clearly, B also wants to advertise the path BAW to its customer, \nX, so that X knows that it can route to W via B. But should B advertise the path \nBAW to C? If it does so, then C could route traffic to W via BAW. If A, B, and C are \nall backbone providers, than B might rightly feel that it should not have to shoulder \nthe burden (and cost!) of carrying transit traffic between A and C. B might rightly \nfeel that it is A\u2019s and C\u2019s job (and cost!) to make sure that C can route to/from A\u2019s \ncustomers via a direct connection between A and C. There are currently no official \nstandards that govern how backbone ISPs route among themselves. However, a rule \nof thumb followed by commercial ISPs is that any traffic flowing across an ISP\u2019s \nbackbone network must have either a source or a destination (or both) in a network \nthat is a customer of that ISP; otherwise the traffic would be getting a free ride on the \nISP\u2019s network. Individual peering agreements (that would govern questions such as A WX\nYBKey:\nProvider\nnetwork\nCustomer\nnetworkC\nFigure 5.13  \u2666 A simple BGP policy scenario\n5.4  \u2022  ROUTING AMONG THE ISPS: BGP      433\nthose raised above) are typically negotiated between pairs of ISPs and are often con -\nfidential; [Huston 1999a] provides an interesting discussion of peering agreements. \nFor a detailed description of how routing policy reflects commercial relationships \namong ISPs, see [Gao 2001; Dmitiropoulos 2007]. For a discussion of BGP routing \npolices from an ISP standpoint, see [Caesar 2005b].WHY ARE", "doc_id": "1d31a4f9-34ad-4f47-814e-7a2020d31637", "embedding": null, "doc_hash": "614ea89403e99310b543ccf9676755e0de8719310ed99c7e02e1557a333feb06", "extra_info": null, "node_info": {"start": 1259040, "end": 1262550}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "1f45241e-f900-447a-8f75-78b81115075b", "3": "69ccd261-28dd-48b0-8fa6-66338bbfd9ae"}}, "__type__": "1"}, "69ccd261-28dd-48b0-8fa6-66338bbfd9ae": {"__data__": {"text": "that ISP; otherwise the traffic would be getting a free ride on the \nISP\u2019s network. Individual peering agreements (that would govern questions such as A WX\nYBKey:\nProvider\nnetwork\nCustomer\nnetworkC\nFigure 5.13  \u2666 A simple BGP policy scenario\n5.4  \u2022  ROUTING AMONG THE ISPS: BGP      433\nthose raised above) are typically negotiated between pairs of ISPs and are often con -\nfidential; [Huston 1999a] provides an interesting discussion of peering agreements. \nFor a detailed description of how routing policy reflects commercial relationships \namong ISPs, see [Gao 2001; Dmitiropoulos 2007]. For a discussion of BGP routing \npolices from an ISP standpoint, see [Caesar 2005b].WHY ARE THERE DIFFERENT INTER-AS AND INTRA-AS ROUTING \nPROTOCOLS?\nHaving now studied the details of specific inter-AS and intra-AS routing protocols deployed \nin today\u2019s Internet, let\u2019s conclude by considering perhaps the most fundamental question \nwe could ask about these protocols in the first place (hopefully, you have been wondering \nthis all along, and have not lost the forest for the trees!): Why are different inter-AS and \nintra-AS routing protocols used?\nThe answer to this question gets at the heart of the differences between the goals of \nrouting within an AS and among ASs:\n\u2022\tPolicy.  Among ASs, policy issues dominate. It may well be important that traffic origi -\nnating in a given AS not be able to pass through another specific AS. Similarly, a \ngiven AS may well want to control what transit traffic it carries between other ASs. We \nhave seen that BGP carries path attributes and provides for controlled distribution of \nrouting information so that such policy-based routing decisions can be made. Within \nan AS, everything is nominally under the same administrative control, and thus policy \nissues play a much less important role in choosing routes within the AS.\n\u2022\tScale.  The ability of a routing algorithm and its data structures to scale to handle \nrouting to/among large numbers of networks is a critical issue in inter-AS routing. \nWithin an AS, scalability is less of a concern. For one thing, if a single ISP becomes \ntoo large, it is always possible to divide it into two ASs and perform inter-AS routing \nbetween the two new ASs. (Recall that OSPF allows such a hierarchy to be built by \nsplitting an AS into areas.)\n\u2022\tPerformance.  Because inter-AS routing is so policy oriented, the quality (for example, \nperformance) of the routes used is often of secondary concern (that is, a longer or \nmore costly route that satisfies certain policy criteria may well be taken over a route \nthat is shorter but does not meet that criteria). Indeed, we saw that among ASs, there \nis not even the notion of cost (other than AS hop count) associated with routes. Within \na single AS, however, such policy concerns are of less importance, allowing routing to \nfocus more on the level of performance realized on a route.PRINCIPLES IN PRACTICE\n\n434     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\nThis completes our brief introduction to BGP. Understanding BGP is important \nbecause it plays a central role in the Internet. We encourage you to see the references \n[Griffin 2012; Stewart 1999; Labovitz 1997; Halabi 2000; Huitema 1998; Gao 2001; \nFeamster 2004; Caesar 2005b; Li 2007] to learn more about BGP.\n5.4.6   Putting the Pieces Together: Obtaining  \nInternet Presence\nAlthough this subsection is not about BGP per se , it brings together many of the \nprotocols and concepts we\u2019ve seen thus far, including IP addressing, DNS, and BGP.\nSuppose you have just created a small company that has a number of servers, \nincluding a public Web server that describes your company\u2019s products and services, \na mail server from which your employees", "doc_id": "69ccd261-28dd-48b0-8fa6-66338bbfd9ae", "embedding": null, "doc_hash": "b119e434443f57a59879e293cd7eaef9eabc47246d26a570f33441da78317f3e", "extra_info": null, "node_info": {"start": 1262389, "end": 1266131}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "1d31a4f9-34ad-4f47-814e-7a2020d31637", "3": "8695c84e-c92f-414b-ae33-8981af4f2769"}}, "__type__": "1"}, "8695c84e-c92f-414b-ae33-8981af4f2769": {"__data__": {"text": "completes our brief introduction to BGP. Understanding BGP is important \nbecause it plays a central role in the Internet. We encourage you to see the references \n[Griffin 2012; Stewart 1999; Labovitz 1997; Halabi 2000; Huitema 1998; Gao 2001; \nFeamster 2004; Caesar 2005b; Li 2007] to learn more about BGP.\n5.4.6   Putting the Pieces Together: Obtaining  \nInternet Presence\nAlthough this subsection is not about BGP per se , it brings together many of the \nprotocols and concepts we\u2019ve seen thus far, including IP addressing, DNS, and BGP.\nSuppose you have just created a small company that has a number of servers, \nincluding a public Web server that describes your company\u2019s products and services, \na mail server from which your employees obtain their e-mail messages, and a DNS \nserver. Naturally, you would like the entire world to be able to visit your Web site in \norder to learn about your exciting products and services. Moreover, you would like your \nemployees to be able to send and receive e-mail to potential customers throughout the \nworld.\nTo meet these goals, you first need to obtain Internet connectivity, which is \ndone by contracting with, and connecting to, a local ISP. Your company will have \na gateway router, which will be connected to a router in your local ISP. This con -\nnection might be a DSL connection through the existing telephone infrastructure, a \nleased line to the ISP\u2019s router, or one of the many other access solutions described in \nChapter 1. Your local ISP will also provide you with an IP address range, e.g., a /24 \naddress range consisting of 256 addresses. Once you have your physical connectivity \nand your IP address range, you will assign one of the IP addresses (in your address \nrange) to your Web server, one to your mail server, one to your DNS server, one to \nyour gateway router, and other IP addresses to other servers and networking devices \nin your company\u2019s network.\nIn addition to contracting with an ISP, you will also need to contract with an \nInternet registrar to obtain a domain name for your company, as described in Chapter \n2. For example, if your company\u2019s name is, say, Xanadu Inc., you will naturally try \nto obtain the domain name xanadu.com. Your company must also obtain presence \nin the DNS system. Specifically, because outsiders will want to contact your DNS \nserver to obtain the IP addresses of your servers, you will also need to provide your \nregistrar with the IP address of your DNS server. Your registrar will then put an \nentry for your DNS server (domain name and corresponding IP address) in the .com \ntop-level-domain servers, as described in Chapter 2. After this step is completed, any \nuser who knows your domain name (e.g., xanadu.com) will be able to obtain the IP \naddress of your DNS server via the DNS system.\nSo that people can discover the IP addresses of your Web server, in your DNS \nserver you will need to include entries that map the host name of your Web server \n(e.g., www.xanadu.com) to its IP address. You will want to have similar entries for \n5.5  \u2022  THE SDN CONTROL PLANE      435\nother publicly available servers in your company, including your mail server. In this \nmanner, if Alice wants to browse your Web server, the DNS system will contact your \nDNS server, find the IP address of your Web server, and give it to Alice. Alice can \nthen establish a TCP connection directly with your Web server.\nHowever, there still remains one other necessary and crucial step to allow out -\nsiders from around the world to access your Web server. Consider what happens \nwhen Alice, who knows the IP address of your Web server, sends an IP datagram \n(e.g., a TCP SYN segment) to that IP address. This datagram will be routed through \nthe Internet, visiting a series of routers in many different ASs, and eventually reach \nyour Web server. When any one of the routers receives the datagram,", "doc_id": "8695c84e-c92f-414b-ae33-8981af4f2769", "embedding": null, "doc_hash": "ad20db7c2049148b57cd6b73e2ea5b9c2f43e46998a88af7cf3e19e2f7967f4d", "extra_info": null, "node_info": {"start": 1266089, "end": 1269976}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "69ccd261-28dd-48b0-8fa6-66338bbfd9ae", "3": "e98cd12f-077b-4574-9203-27a5c9d890b2"}}, "__type__": "1"}, "e98cd12f-077b-4574-9203-27a5c9d890b2": {"__data__": {"text": "publicly available servers in your company, including your mail server. In this \nmanner, if Alice wants to browse your Web server, the DNS system will contact your \nDNS server, find the IP address of your Web server, and give it to Alice. Alice can \nthen establish a TCP connection directly with your Web server.\nHowever, there still remains one other necessary and crucial step to allow out -\nsiders from around the world to access your Web server. Consider what happens \nwhen Alice, who knows the IP address of your Web server, sends an IP datagram \n(e.g., a TCP SYN segment) to that IP address. This datagram will be routed through \nthe Internet, visiting a series of routers in many different ASs, and eventually reach \nyour Web server. When any one of the routers receives the datagram, it is going \nto look for an entry in its forwarding table to determine on which outgoing port it \nshould forward the datagram. Therefore, each of the routers needs to know about the \nexistence of your company\u2019s /24 prefix (or some aggregate entry). How does a router \nbecome aware of your company\u2019s prefix? As we have just seen, it becomes aware of \nit from BGP! Specifically, when your company contracts with a local ISP and gets \nassigned a prefix (i.e., an address range), your local ISP will use BGP to advertise \nyour prefix to the ISPs to which it connects. Those ISPs will then, in turn, use BGP \nto propagate the advertisement. Eventually, all Internet routers will know about your \nprefix (or about some aggregate that includes your prefix) and thus be able to appro -\npriately forward datagrams destined to your Web and mail servers.\n5.5 The SDN Control Plane\nIn this section, we\u2019ll dive into the SDN control plane\u2014the network-wide logic that \ncontrols packet forwarding among a network\u2019s SDN-enabled devices, as well as the \nconfiguration and management of these devices and their services. Our study here \nbuilds on our earlier discussion of generalized SDN forwarding in Section 4.4, so you \nmight want to first review that section, as well as Section 5.1  of this chapter, before \ncontinuing on.  As in Section 4.4, we\u2019ll again  adopt the terminology used in the SDN \nliterature and refer to the network\u2019s forwarding devices as \u201cpacket switches\u201d (or just \nswitches, with \u201cpacket\u201d being understood), since forwarding decisions can be made \non the basis of network-layer source/destination addresses, link-layer source/destina -\ntion addresses, as well as many other values in transport-, network-, and link-layer \npacket-header fields.\nFour key characteristics of an SDN architecture can be identified [Kreutz 2015]:\n\u2022 Flow-based forwarding.  Packet forwarding by SDN-controlled switches can be \nbased on any number of header field values in the transport-layer, network-layer, \nor link-layer header. We saw in Section 4.4 that the OpenFlow1.0 abstraction \nallows forwarding based on eleven different header field values. This contrasts \n436     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\nsharply with the traditional approach to router-based forwarding that we studied \nin Sections 5.2\u20135. 4, where forwarding of IP datagrams was based solely on a \ndatagram\u2019s destination IP address. Recall from Figure 5.2 that packet forwarding \nrules are specified in a switch\u2019s flow table; it is the job of the SDN control plane \nto compute, manage and install flow table entries in all of the network\u2019s switches.\n\u2022 Separation of data plane and control plane.  This separation is shown clearly \nin Figures 5.2 and 5.14. The data plane consists of the network\u2019s switches\u2014  \nrelatively simple (but fast) devices that execute the \u201cmatch plus action\u201d rules in \ntheir flow tables. The control plane consists of servers and software that deter -\nmine and manage the switches\u2019 flow tables.\n\u2022 Network control functions: external to data-plane", "doc_id": "e98cd12f-077b-4574-9203-27a5c9d890b2", "embedding": null, "doc_hash": "7435d173c61a74e32daea39054a4c8aab70fd80ee7371e0a08fe314e8ddd66a1", "extra_info": null, "node_info": {"start": 1269942, "end": 1273775}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "8695c84e-c92f-414b-ae33-8981af4f2769", "3": "1cb74a30-b7ea-4fd2-92cf-c3642eaf6d4b"}}, "__type__": "1"}, "1cb74a30-b7ea-4fd2-92cf-c3642eaf6d4b": {"__data__": {"text": "4, where forwarding of IP datagrams was based solely on a \ndatagram\u2019s destination IP address. Recall from Figure 5.2 that packet forwarding \nrules are specified in a switch\u2019s flow table; it is the job of the SDN control plane \nto compute, manage and install flow table entries in all of the network\u2019s switches.\n\u2022 Separation of data plane and control plane.  This separation is shown clearly \nin Figures 5.2 and 5.14. The data plane consists of the network\u2019s switches\u2014  \nrelatively simple (but fast) devices that execute the \u201cmatch plus action\u201d rules in \ntheir flow tables. The control plane consists of servers and software that deter -\nmine and manage the switches\u2019 flow tables.\n\u2022 Network control functions: external to data-plane switches.  Given that the \u201cS\u201d in \nSDN is for \u201csoftware,\u201d it\u2019s perhaps not surprising that the SDN control plane is \nimplemented in software. Unlike traditional routers, however, this software exe -\ncutes on servers that are both distinct and remote from the network\u2019s switches. As \nshown in Figure 5.14, the control plane itself consists of two components\u2014an SDN \ncontroller (or network operating system [Gude 2008]) and a set of network-control \napplications. The controller maintains accurate network state information (e.g., the \nstate of remote links, switches, and hosts); provides this information to the network-\ncontrol applications running in the control plane; and provides the means through \nwhich these applications can monitor, program, and control the underlying network \ndevices. Although the controller in Figure 5.14 is shown as a single central server, \nin practice the controller is only logically centralized; it is typically implemented on \nseveral servers that provide coordinated, scalable performance and high availability.\n\u2022 A programmable network.  The network is programmable through the network-\ncontrol applications running in the control plane. These applications represent \nthe \u201cbrains\u201d of the SDN control plane, using the APIs provided by the SDN \ncontroller to specify and control the data plane in the network devices. For exam -\nple, a routing network-control application might determine the end-end paths \nbetween sources and destinations (e.g., by executing Dijkstra\u2019s algorithm using \nthe node-state and link-state information maintained by the SDN controller). \nAnother network application might perform access control, i.e., determine which \npackets are to be blocked at a switch, as in our third example in Section 4.4.3 . \nYet another application might forward packets in a manner that performs server \nload balancing (the second example we considered in Section 4.4.3 ).\nFrom this discussion, we can see that SDN represents a significant \u201cunbundling\u201d \nof network functionality\u2014data plane switches, SDN controllers, and network-control  \napplications are separate entities that may each be provided by different vendors \nand organizations. This contrasts with the pre-SDN model in which a switch/router \n(together with its embedded control plane software and protocol implementations) \nwas monolithic, vertically integrated, and sold by a single vendor. This unbundling \n5.5  \u2022  THE SDN CONTROL PLANE      437\nof network functionality in SDN has been likened to the earlier evolution from main -\nframe computers (where hardware, system software, and applications were provided \nby a single vendor) to personal computers (with their separate hardware, operating \nsystems, and applications). The unbundling of computing hardware, system soft -\nware, and applications has arguably led to a rich, open ecosystem driven by innova -\ntion in all three of these areas; one hope for SDN is that it too will lead to a such rich \ninnovation.\nGiven our understanding of the SDN architecture of Figure 5.14, many questions \nnaturally arise. How and where are the flow tables actually computed? How are these \ntables updated in response to events at SDN-controlled devices (e.g., an attached link", "doc_id": "1cb74a30-b7ea-4fd2-92cf-c3642eaf6d4b", "embedding": null, "doc_hash": "f4c105d9bd3196745ab575e209f22e6d12d6f7f9804525ba571b830c17c8f81b", "extra_info": null, "node_info": {"start": 1273820, "end": 1277776}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "e98cd12f-077b-4574-9203-27a5c9d890b2", "3": "dd98e63c-8594-496c-80c0-7420cbc7bdcf"}}, "__type__": "1"}, "dd98e63c-8594-496c-80c0-7420cbc7bdcf": {"__data__": {"text": "network functionality in SDN has been likened to the earlier evolution from main -\nframe computers (where hardware, system software, and applications were provided \nby a single vendor) to personal computers (with their separate hardware, operating \nsystems, and applications). The unbundling of computing hardware, system soft -\nware, and applications has arguably led to a rich, open ecosystem driven by innova -\ntion in all three of these areas; one hope for SDN is that it too will lead to a such rich \ninnovation.\nGiven our understanding of the SDN architecture of Figure 5.14, many questions \nnaturally arise. How and where are the flow tables actually computed? How are these \ntables updated in response to events at SDN-controlled devices (e.g., an attached link \ngoing up/down)? And how are the flow table entries at multiple switches coordinated \nin such a way as to result in orchestrated and consistent network-wide functionality \n(e.g., end-to-end paths for forwarding packets from sources to destinations, or coor -\ndinated distributed firewalls)? It is the role of the SDN control plane to provide these, \nand many other, capabilities.\nRoutingNetwork-contr ol Applications\nContr ol\nplane\nData\nplane\nSDN-Contr olled SwitchesAccess\nControlLoad\nBalancer\nNorthbound\nAPI\nSouthbound\nAPISDN Controller\n(network operating system)\nFigure 5.14  \u2666  Components of the SDN architecture: SDN-controlled \nswitches, the SDN controller, network-control applications\n438     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\n5.5.2   The SDN Control Plane: SDN Controller and  \nSDN Network-control Applications\nLet\u2019s begin our discussion of the SDN control plane in the abstract, by consider -\ning the generic capabilities that the control plane must provide. As we\u2019ll see, this \nabstract, \u201cfirst principles\u201d approach will lead us to an overall architecture that reflects \nhow SDN control planes have been implemented in practice.\nAs noted above, the SDN control plane divides broadly into two components\u2014\nthe SDN controller and the SDN network-control applications. Let\u2019s explore the \ncontroller first. Many SDN controllers have been developed since the earliest SDN \ncontroller [Gude 2008]; see [Kreutz 2015] for an extremely thorough and up-to-date \nsurvey. Figure 5.15 provides a more detailed view of a generic SDN controller. A \ncontroller\u2019s functionality can be broadly organized into three layers. Let\u2019s consider \nthese layers in an uncharacteristically bottom-up fashion:\n\u2022 A communication layer: communicating between the SDN controller and con -\ntrolled network devices.  Clearly, if an SDN controller is going to control the \noperation of a remote SDN-enabled switch, host, or other device, a protocol is \nneeded to transfer information between the controller and that device. In addition, \na device must be able to communicate locally-observed events to the controller  \n(e.g., a message indicating that an attached link has gone up or down, that a \ndevice has just joined the network, or a heartbeat indicating that a device is up and \noperational). These events provide the SDN controller with an up-to-date view \nof the network\u2019s state. This protocol constitutes the lowest layer of the controller \narchitecture, as shown in Figure 5.15. The communication between the controller \nand the controlled devices cross what has come to be known as the controller\u2019s \n\u201csouthbound\u201d interface. In Section 5.5.2, we\u2019ll study OpenFlow\u2014a specific pro-\ntocol that provides this communication functionality. OpenFlow is implemented \nin most, if not all, SDN controllers.\n\u2022 A network-wide state-management layer.  The ultimate control decisions made by \nthe SDN control plane\u2014e.g., configuring flow tables in all switches to achieve \nthe desired end-end forwarding, to implement load balancing, or to implement a \nparticular firewalling", "doc_id": "dd98e63c-8594-496c-80c0-7420cbc7bdcf", "embedding": null, "doc_hash": "145bafda228c77b6a2b04681c5beffa1556b222f9182621c18509203d3312270", "extra_info": null, "node_info": {"start": 1277739, "end": 1281570}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "1cb74a30-b7ea-4fd2-92cf-c3642eaf6d4b", "3": "8cda39b2-223a-4407-9371-cf8bca6abc30"}}, "__type__": "1"}, "8cda39b2-223a-4407-9371-cf8bca6abc30": {"__data__": {"text": "provide the SDN controller with an up-to-date view \nof the network\u2019s state. This protocol constitutes the lowest layer of the controller \narchitecture, as shown in Figure 5.15. The communication between the controller \nand the controlled devices cross what has come to be known as the controller\u2019s \n\u201csouthbound\u201d interface. In Section 5.5.2, we\u2019ll study OpenFlow\u2014a specific pro-\ntocol that provides this communication functionality. OpenFlow is implemented \nin most, if not all, SDN controllers.\n\u2022 A network-wide state-management layer.  The ultimate control decisions made by \nthe SDN control plane\u2014e.g., configuring flow tables in all switches to achieve \nthe desired end-end forwarding, to implement load balancing, or to implement a \nparticular firewalling capability\u2014will require that the controller have up-to-date \ninformation about state of the networks\u2019 hosts, links, switches, and other SDN-\ncontrolled devices. A switch\u2019s flow table contains counters whose values might \nalso be profitably used by network-control applications; these values should thus \nbe available to the applications. Since the ultimate aim of the control plane is to \ndetermine flow tables for the various controlled devices, a controller might also \nmaintain a copy of these tables. These pieces of information all constitute exam -\nples of the network-wide \u201cstate\u201d maintained by the SDN controller.\n\u2022 The interface to the network-control application layer.  The controller interacts \nwith network-control applications through its \u201cnorthbound\u201d interface. This API \n5.5  \u2022  THE SDN CONTROL PLANE      439\nallows network-control applications to read/write network state and flow tables \nwithin the state-management layer. Applications can register to be notified when \nstate-change events occur, so that they can take actions in response to network \nevent notifications sent from SDN-controlled devices. Different types of APIs \nmay be provided; we\u2019ll see that two popular SDN controllers communicate with \ntheir applications using a REST [Fielding 2000] request-response interface.\nWe have noted several times that an SDN controller can be considered to be \n \u201clogically centralized,\u201d i.e., that the controller may be viewed externally (e.g., from the \npoint of view of SDN-controlled devices and external network-control applications) \nRoutingAccess\nControlLoad\nBalancer\nInterface, abstractions for  network control apps\nNetwork\ngraphRESTful\nAPIIntent\nCommunication to/from controlled devicesNetwork-wide distributed, robust state management\nLink-state\ninfoHost infoSwitch\ninfoStatisticsFlow\ntables\nOpenFlow SNM PSDN Contr ollerNorthbound\nAPI\nSouthbound\nAPI\nFigure 5.15  \u2666 Components of an SDN controller\n440     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\nas a single, monolithic service. However, these services and the databases used to \nhold state information are implemented in practice by a distributed  set of servers \nfor fault tolerance, high availability, or for performance reasons. With controller \nfunctions being implemented by a set of servers, the semantics of the controller\u2019s \ninternal operations (e.g., maintaining logical time ordering of events, consistency, \nconsensus, and more) must be considered [Panda 2013]. Such concerns are com -\nmon across many different distributed systems; see [Lamport 1989, Lampson 1996] \nfor elegant solutions to these challenges. Modern controllers such as OpenDaylight \n[OpenDaylight Lithium 2016] and ONOS [ONOS 2016] (see sidebar) have placed \nconsiderable emphasis on architecting a logically centralized but physically distrib -\nuted controller platform that provides scalable services and high availability to the \ncontrolled devices and network-control applications alike.\nThe architecture depicted in Figure 5.15 closely resembles the architecture of the \noriginally proposed NOX controller in 2008 [Gude 2008], as well as that of today\u2019s \nOpenDaylight [OpenDaylight Lithium 2016] and ONOS [ONOS 2016]", "doc_id": "8cda39b2-223a-4407-9371-cf8bca6abc30", "embedding": null, "doc_hash": "e8af63e92fa4c8259f748db331d06d4641ee729cf8fe2f654f204aa4f7bf4b45", "extra_info": null, "node_info": {"start": 1281570, "end": 1285519}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "dd98e63c-8594-496c-80c0-7420cbc7bdcf", "3": "e0302406-d5a4-4f74-86a3-29f2dad630ca"}}, "__type__": "1"}, "e0302406-d5a4-4f74-86a3-29f2dad630ca": {"__data__": {"text": "must be considered [Panda 2013]. Such concerns are com -\nmon across many different distributed systems; see [Lamport 1989, Lampson 1996] \nfor elegant solutions to these challenges. Modern controllers such as OpenDaylight \n[OpenDaylight Lithium 2016] and ONOS [ONOS 2016] (see sidebar) have placed \nconsiderable emphasis on architecting a logically centralized but physically distrib -\nuted controller platform that provides scalable services and high availability to the \ncontrolled devices and network-control applications alike.\nThe architecture depicted in Figure 5.15 closely resembles the architecture of the \noriginally proposed NOX controller in 2008 [Gude 2008], as well as that of today\u2019s \nOpenDaylight [OpenDaylight Lithium 2016] and ONOS [ONOS 2016] SDN control -\nlers (see sidebar). We\u2019ll cover an example of controller operation in Section 5.5.3. \nFirst, however, let\u2019s examine the OpenFlow protocol, which lies in the controller\u2019s \ncommunication layer.\n5.5.2  OpenFlow Protocol\nThe OpenFlow protocol [OpenFlow 2009, ONF 2016] operates between an SDN \ncontroller and an SDN-controlled switch or other device implementing the Open -\nFlow API that we studied earlier in Section 4.4. The OpenFlow protocol operates \nover TCP, with a default port number of 6653.\nAmong the important messages flowing from the controller to the controlled \nswitch are the following:\n\u2022 Configuration.  This message allows the controller to query and set a switch\u2019s \nconfiguration parameters.\n\u2022 Modify-State.  This message is used by a controller to add/delete or modify entries \nin the switch\u2019s flow table, and to set switch port properties.\n\u2022 Read-State.  This message is used by a controller to collect statistics and counter \nvalues from the switch\u2019s flow table and ports.\n\u2022 Send-Packet.  This message is used by the controller to send a specific packet out \nof a specified port at the controlled switch. The message itself contains the packet \nto be sent in its payload.\nAmong the messages flowing from the SDN-controlled switch to the controller \nare the following:\n\u2022 Flow-Removed.  This message informs the controller that a flow table entry has \nbeen removed, for example by a timeout or as the result of a received modify-state  \nmessage.\n5.5  \u2022  THE SDN CONTROL PLANE      441\n\u2022 Port-status.  This message is used by a switch to inform the controller of a change \nin port status.\n\u2022 Packet-in.  Recall from Section 4.4 that a packet arriving at a switch port and not \nmatching any flow table entry is sent to the controller for additional processing. \nMatched packets may also be sent to the controller, as an action to be taken on a \nmatch. The packet-in  message is used to send such packets to the controller.\nAdditional OpenFlow messages are defined in [OpenFlow 2009, ONF 2016].\nGOOGLE\u2019S SOFTWARE-DEFINED GLOBAL NETWORK\nRecall from the case study in Section 2.6 that Google deploys a dedicated wide-area \nnetwork (WAN) that interconnects its data centers and server clusters (in IXPs and ISPs). \nThis network, called B4, has a Google-designed SDN control plane built on OpenFlow. \nGoogle\u2019s network is able to drive WAN links at near 70% utilization over the long run  \n(a two to three fold increase over typical link utilizations) and split application flows among \nmultiple paths based on application priority and existing flow demands [Jain 2013].\nThe Google B4 network is particularly it well-suited for SDN: (i) Google controls all \ndevices from the edge servers in IXPs and ISPs to routers in their network core; (ii) the \nmost bandwidth-intensive applications are large-scale data copies between sites that can \ndefer to higher-priority interactive applications during times of resource congestion;  \n(iii) with only a few dozen data centers being connected, centralized control is feasible.\nGoogle\u2019s B4 network uses custom-built switches, each implementing a slightly", "doc_id": "e0302406-d5a4-4f74-86a3-29f2dad630ca", "embedding": null, "doc_hash": "855995e8ff778357476142d3882476cb3078299d67b2f9c7bb6d681765cdf889", "extra_info": null, "node_info": {"start": 1285514, "end": 1289391}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "8cda39b2-223a-4407-9371-cf8bca6abc30", "3": "1e3c7aad-3d88-4727-973d-da4a9336e256"}}, "__type__": "1"}, "1e3c7aad-3d88-4727-973d-da4a9336e256": {"__data__": {"text": "\nGoogle\u2019s network is able to drive WAN links at near 70% utilization over the long run  \n(a two to three fold increase over typical link utilizations) and split application flows among \nmultiple paths based on application priority and existing flow demands [Jain 2013].\nThe Google B4 network is particularly it well-suited for SDN: (i) Google controls all \ndevices from the edge servers in IXPs and ISPs to routers in their network core; (ii) the \nmost bandwidth-intensive applications are large-scale data copies between sites that can \ndefer to higher-priority interactive applications during times of resource congestion;  \n(iii) with only a few dozen data centers being connected, centralized control is feasible.\nGoogle\u2019s B4 network uses custom-built switches, each implementing a slightly extended ver -\nsion of OpenFlow, with a local Open Flow Agent (OFA) that is similar in spirit to the control \nagent we encountered in Figure 5.2. Each OFA in turn connects to an Open Flow Controller \n(OFC) in the network control server (NCS), using a separate \u201cout of band\u201d network, distinct \nfrom the network that carries data-center traffic between data centers. The OFC thus provides \nthe services used by the NCS to communicate with its controlled switches, similar in spirit to \nthe lowest layer in the SDN architecture shown in Figure 5.15. In B4, the OFC also performs \nstate management functions, keeping node and link status in a Network Information Base \n(NIB). Google\u2019s implementation of the OFC is based on the ONIX SDN controller [Koponen \n2010]. Two routing protocols, BGP (for routing between the data centers) and IS-IS (a close \nrelative of OSPF, for routing within a data center), are implemented. Paxos [Chandra 2007] is \nused to execute hot replicas of NCS components to protect against failure.\nA traffic engineering network-control application, sitting logically above the set of \nnetwork control servers, interacts with these servers to provide global, network-wide band -\nwidth provisioning for groups of application flows. With B4, SDN made an important \nleap forward into the operational networks of a global network provider. See [Jain 2013] \nfor a detailed description of B4.PRINCIPLES IN PRACTICE\n\n442     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\n5.5.3  Data and Control Plane Interaction: An Example\nIn order to solidify our understanding of the interaction between SDN-controlled \nswitches and the SDN controller, let\u2019s consider the example shown in Figure 5.16, \nin which Dijkstra\u2019s algorithm (which we studied in Section 5.2) is used to determine \nshortest path routes. The SDN scenario in Figure 5.16 has two important differ -\nences from the earlier per-router-control scenario of Sections 5.2.1 and 5.3, where \n Dijkstra\u2019s algorithm was implemented in each and every router and link-state updates \nwere flooded among all network routers:\n\u2022 Dijkstra\u2019s algorithm is executed as a separate application, outside of the packet \nswitches.\n\u2022 Packet switches send link updates to the SDN controller and not to each other.\nIn this example, let\u2019s assume that the link between switch s1 and s2 goes \ndown; that shortest path routing is implemented, and consequently and that incom -\ning and outgoing flow forwarding rules at s1, s3, and s4 are affected, but that s2\u2019s \nFigure 5.16  \u2666 SDN controller scenario: Link-state changeNetwork\ngraphRESTful\nAPIIntent\nStatisticsFlow\ntables\nOpenFlow SNM PDijkstra\u2019 s link-stat e\nRouting\n4\n3\n2\n15\ns1s2\ns3s46Link-state\ninfoHost infoSwitch\ninfo\n5.5  \u2022  THE SDN CONTROL PLANE      443\noperation is unchanged. Let\u2019s also assume that OpenFlow is used as the communi", "doc_id": "1e3c7aad-3d88-4727-973d-da4a9336e256", "embedding": null, "doc_hash": "aa12f17397c45334a50c76e5c1d4d60b3e0b8b8f246116f4c56ddadb02d57293", "extra_info": null, "node_info": {"start": 1289374, "end": 1293000}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "e0302406-d5a4-4f74-86a3-29f2dad630ca", "3": "79bec56c-18ff-42f5-b02a-4bb31fc7d7b0"}}, "__type__": "1"}, "79bec56c-18ff-42f5-b02a-4bb31fc7d7b0": {"__data__": {"text": "each other.\nIn this example, let\u2019s assume that the link between switch s1 and s2 goes \ndown; that shortest path routing is implemented, and consequently and that incom -\ning and outgoing flow forwarding rules at s1, s3, and s4 are affected, but that s2\u2019s \nFigure 5.16  \u2666 SDN controller scenario: Link-state changeNetwork\ngraphRESTful\nAPIIntent\nStatisticsFlow\ntables\nOpenFlow SNM PDijkstra\u2019 s link-stat e\nRouting\n4\n3\n2\n15\ns1s2\ns3s46Link-state\ninfoHost infoSwitch\ninfo\n5.5  \u2022  THE SDN CONTROL PLANE      443\noperation is unchanged. Let\u2019s also assume that OpenFlow is used as the communi -\ncation layer protocol, and that the control plane performs no other function other \nthan link-state routing.\n 1. Switch s1, experiencing a link failure between itself and s2, notifies the SDN \ncontroller of the link-state change using the OpenFlow port-status  message.\n 2. The SDN controller receives the OpenFlow message indicating the link-state \nchange, and notifies the link-state manager, which updates a link-state  database.\n 3. The network-control application that implements Dijkstra\u2019s link-state routing \nhas previously registered to be notified when link state changes. That applica -\ntion receives the notification of the link-state change.\n 4. The link-state routing application interacts with the link-state manager to get \nupdated link state; it might also consult other components in the state- management \nlayer. It then computes the new least-cost paths.\n 5. The link-state routing application then interacts with the flow table manager, \nwhich determines the flow tables to be updated.\n 6. The flow table manager then uses the OpenFlow protocol to update flow table \nentries at affected switches\u2014s1 (which will now route packets destined to s2 via s4), \ns2 (which will now begin receiving packets from s1 via intermediate switch s4), and \ns4 (which must now forward packets from s1 destined to s2).\nThis example is simple but illustrates how the SDN control plane provides control-\nplane services (in this case network-layer routing) that had been previously imple -\nmented with per-router control exercised in each and every network router. One can \nnow easily appreciate how an SDN-enabled ISP could easily switch from least-cost \npath routing to a more hand-tailored approach to routing. Indeed, since the controller \ncan tailor the flow tables as it pleases, it can implement any form of forwarding that \nit pleases\u2014simply by changing its application-control software. This ease of change \nshould be contrasted to the case of a traditional per-router control plane, where soft-\nware in all routers (which might be provided to the ISP by multiple independent \nvendors) must be changed.\n5.5.4  SDN: Past and Future\nAlthough the intense interest in SDN is a relatively recent phenomenon, the techni -\ncal roots of SDN, and the separation of the data and control planes in particular, go \nback considerably further. In 2004, [Feamster 2004, Lakshman 2004, RFC 3746] all \nargued for the separation of the network\u2019s data and control planes. [van der Merwe \n1998] describes a control framework for ATM networks [Black 1995] with multiple \ncontrollers, each controlling a number of ATM switches. The Ethane project [Casado \n2007] pioneered the notion of a network of simple flow-based Ethernet switches with \nmatch-plus-action flow tables, a centralized controller that managed flow admission \n444     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\nand routing, and the forwarding of unmatched packets from the switch to the control -\nler. A network of more than 300 Ethane switches was operational in 2007. Ethane \nquickly evolved into the OpenFlow project, and the rest (as the saying goes)", "doc_id": "79bec56c-18ff-42f5-b02a-4bb31fc7d7b0", "embedding": null, "doc_hash": "538d08e7d646127696fc302db6b15411b1dfc639bc17015f9b6ea456cd90aab8", "extra_info": null, "node_info": {"start": 1293175, "end": 1296873}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "1e3c7aad-3d88-4727-973d-da4a9336e256", "3": "8972270e-9951-4658-a166-da16910bf9f9"}}, "__type__": "1"}, "8972270e-9951-4658-a166-da16910bf9f9": {"__data__": {"text": "all \nargued for the separation of the network\u2019s data and control planes. [van der Merwe \n1998] describes a control framework for ATM networks [Black 1995] with multiple \ncontrollers, each controlling a number of ATM switches. The Ethane project [Casado \n2007] pioneered the notion of a network of simple flow-based Ethernet switches with \nmatch-plus-action flow tables, a centralized controller that managed flow admission \n444     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\nand routing, and the forwarding of unmatched packets from the switch to the control -\nler. A network of more than 300 Ethane switches was operational in 2007. Ethane \nquickly evolved into the OpenFlow project, and the rest (as the saying goes) is history!\nNumerous research efforts are aimed at developing future SDN architectures \nand capabilities. As we have seen, the SDN revolution is leading to the disruptive \nreplacement of dedicated monolithic switches and routers (with both data and con -\ntrol planes) by simple commodity switching hardware and a sophisticated software \ncontrol plane. A generalization of SDN known as network functions virtualization \n(NFV) similarly aims at disruptive replacement of sophisticated middleboxes (such \nas middleboxes with dedicated hardware and proprietary software for media caching/\nservice) with simple commodity servers, switching, and storage [Gember-Jacobson \n2014]. A second area of important research seeks to extend SDN concepts from the \nintra-AS setting to the inter-AS setting [Gupta 2014].\nSDN CONTROLLER CASE STUDIES: THE OPENDAYLIGHT  \nAND ONOS CONTROLLERS\nIn the earliest days of SDN, there was a single SDN protocol (OpenFlow [McKeown 2008; \nOpenFlow 2009]) and a single SDN controller (NOX [Gude 2008]). Since then, the num -\nber of SDN controllers in particular has grown significantly [Kreutz 2015]. Some SDN \ncontrollers are company-specific and proprietary, e.g., ONIX [Koponen 2010], Juniper \nNetworks Contrail [Juniper Contrail 2016], and Google\u2019s controller [Jain 2013] for its  \nB4 wide-area network. But many more controllers are open-source and implemented in a \nvariety of programming languages [Erickson 2013]. Most recently, the OpenDaylight  \ncontroller [OpenDaylight Lithium 2016] and the ONOS controller [ONOS 2016] have \nfound considerable industry support. They are both open-source and are being developed \nin partnership with the Linux Foundation.\nThe OpenDaylight Controller\nFigure 5. 17 presents a simplified view of the OpenDaylight Lithium SDN controller platform \n[OpenDaylight Lithium 2016]. ODL\u2019s main set of controller components correspond closely \nto those we developed in Figure 5.15.\nNetwork-Service Applications  are the applications that determine how data-plane for -\nwarding and other services, such as firewalling and load balancing, are accomplished in \nthe controlled switches. Unlike the canonical controller in Figure 5.15, the ODL controller \nhas two interfaces through which applications may communicate with native controller \nservices and each other: external applications communicate with controller modules using \na REST request-response API running over HTTP. Internal applications communicate with \neach other via the Service Abstraction Layer (SAL). The choice as to whether a control -\nler application is implemented externally or internally is up to the application designer; PRINCIPLES IN PRACTICE\n\n5.5  \u2022  THE SDN CONTROL PLANE      445\nFigure 5.17  \u2666 The OpenDaylight controllerREST APITraf\ufb01c\nEngineering\nService Abstraction Layer (SAL)\nOpenFlow 1.0 SNMP OVSDBAccess\nControlNetwork service\nappsBasic Network Service Functions\nTopology\nmanagerSwitch\nmanagerStats\nmanager\nForwarding\nmanagerHost\nmanager\nNetwork\nService Apps\nODL\nController\nthe particular configuration of applications shown in Figure 5.17 is only meant as an \n", "doc_id": "8972270e-9951-4658-a166-da16910bf9f9", "embedding": null, "doc_hash": "9626e270d0e6c259c371b050655334a7c445888931f65b5fd7285b37151389fe", "extra_info": null, "node_info": {"start": 1296766, "end": 1300589}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "79bec56c-18ff-42f5-b02a-4bb31fc7d7b0", "3": "6ab4a37c-63d6-465f-b705-125540012e29"}}, "__type__": "1"}, "6ab4a37c-63d6-465f-b705-125540012e29": {"__data__": {"text": "\na REST request-response API running over HTTP. Internal applications communicate with \neach other via the Service Abstraction Layer (SAL). The choice as to whether a control -\nler application is implemented externally or internally is up to the application designer; PRINCIPLES IN PRACTICE\n\n5.5  \u2022  THE SDN CONTROL PLANE      445\nFigure 5.17  \u2666 The OpenDaylight controllerREST APITraf\ufb01c\nEngineering\nService Abstraction Layer (SAL)\nOpenFlow 1.0 SNMP OVSDBAccess\nControlNetwork service\nappsBasic Network Service Functions\nTopology\nmanagerSwitch\nmanagerStats\nmanager\nForwarding\nmanagerHost\nmanager\nNetwork\nService Apps\nODL\nController\nthe particular configuration of applications shown in Figure 5.17 is only meant as an \n example.\nODL\u2019s Basic Network-Service Functions  are at the heart of the controller, and they \ncorrespond closely to the network-wide state management capabilities that we encoun -\ntered in Figure 5.15. The SAL is the controller\u2019s nerve center, allowing controller \n components and applications to invoke each other\u2019s services and to subscribe to events \nthey generate. It also provides a uniform abstract interface to the specific underlying \ncommunications protocols  in the communication layer, including OpenFlow and SNMP \n(the Simple Network Management Protocol\u2014a network management protocol that we \nwill cover in Section 5.7). OVSDB is a protocol used to manage data center switching, \nan important application area for SDN technology. We\u2019ll introduce data center network -\ning in Chapter 6 .\n446     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\nThe ONOS Controller\nFigure 5. 18 presents a simplified view of the ONOS controller ONOS 2016]. Similar \nto the canonical controller in Figure 5.15, three layers can be identified in the ONOS \n controller:\n\u2022\tNorthbound abstractions and protocols.  A unique feature of ONOS is its intent \nframework, which allows an application to request a high-level service (e.g., to setup \na connection between host A and Host B, or conversely to not allow Host A and host \nB to communicate) without having to know the details of how this service is performed. \nState information is provided to network-control applications across the northbound API \neither synchronously (via query) or asynchronously (via listener callbacks, e.g., when \nnetwork state changes).\n\u2022\tDistributed core.  The state of the network\u2019s links, hosts, and devices is maintained \nin ONOS\u2019s distributed core. ONOS is deployed as a service on a set of intercon -\nnected servers, with each server running an identical copy of the ONOS software; an \nincreased number of servers offers an increased service capacity. The ONOS core Figure 5.18  \u2666 ONOS controller architectureIntent REST   API\nHosts Paths\nTopolog y\nDevices LinksFlow rules\nStatistics\nDevice Link Host Flow Packet\nOpenFlow Netconf OVSDB\nNetwork\ncontr ol app s\nNorthbound\nabstractions,\nprotocols\nONOS\ndistributed\ncore\nSouthbound\nabstractions,\nprotocols\n5.6  \u2022  ICMP: THE INTERNET CONTROL MESSAGE PROTOCOL      447\n5.6 ICMP: The Internet Control Message Protocol\nThe Internet Control Message Protocol (ICMP), specified in [RFC 792], is used by \nhosts and routers to communicate network-layer information to each other. The most \ntypical use of ICMP is for error reporting. For example, when running an HTTP \nsession, you may have encountered an error message such as \u201cDestination network \nunreachable.\u201d This message had its origins in ICMP. At some point, an IP router was \nunable to find a path to the host specified in your HTTP request. That router created \nand sent an ICMP message to your host indicating the error.\nICMP is often considered part of IP, but architecturally it lies just above IP, as \nICMP messages are carried inside IP datagrams. That is, ICMP messages are carried \nas IP payload,", "doc_id": "6ab4a37c-63d6-465f-b705-125540012e29", "embedding": null, "doc_hash": "1ee8812a75e4c39b17b46ed4d262c36c2e552048d683cd9c558c16079accb9b1", "extra_info": null, "node_info": {"start": 1300567, "end": 1304360}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "8972270e-9951-4658-a166-da16910bf9f9", "3": "00ab1247-1fc9-412a-8864-f894db4cee60"}}, "__type__": "1"}, "00ab1247-1fc9-412a-8864-f894db4cee60": {"__data__": {"text": "ICMP: The Internet Control Message Protocol\nThe Internet Control Message Protocol (ICMP), specified in [RFC 792], is used by \nhosts and routers to communicate network-layer information to each other. The most \ntypical use of ICMP is for error reporting. For example, when running an HTTP \nsession, you may have encountered an error message such as \u201cDestination network \nunreachable.\u201d This message had its origins in ICMP. At some point, an IP router was \nunable to find a path to the host specified in your HTTP request. That router created \nand sent an ICMP message to your host indicating the error.\nICMP is often considered part of IP, but architecturally it lies just above IP, as \nICMP messages are carried inside IP datagrams. That is, ICMP messages are carried \nas IP payload, just as TCP or UDP segments are carried as IP payload. Similarly, \nwhen a host receives an IP datagram with ICMP specified as the upper-layer protocol \n(an upper-layer protocol number of 1), it demultiplexes the datagram\u2019s contents to \nICMP, just as it would demultiplex a datagram\u2019s content to TCP or UDP.\nICMP messages have a type and a code field, and contain the header and the first \n8 bytes of the IP datagram that caused the ICMP message to be generated in the first \nplace (so that the sender can determine the datagram that caused the error). Selected \nICMP message types are shown in Figure 5.19. Note that ICMP messages are used \nnot only for signaling error conditions.\nThe well-known ping program sends an ICMP type 8 code 0 message to the \nspecified host. The destination host, seeing the echo request, sends back a type 0 \ncode 0 ICMP echo reply. Most TCP/IP implementations support the ping server \ndirectly in the operating system; that is, the server is not a process. Chapter 11 of \n[Stevens 1990] provides the source code for the ping client program. Note that the \nclient program needs to be able to instruct the operating system to generate an ICMP \nmessage of type 8 code 0.\nAnother interesting ICMP message is the source quench message. This message \nis seldom used in practice. Its original purpose was to perform congestion control\u2014to  \nallow a congested router to send an ICMP source quench message to a host to force provides the mechanisms for service replication and coordination among instances, \nproviding the applications above and the network devices below with the abstraction \nof logically centralized core services.\n\u2022\tSouthbound abstractions and protocols.  The southbound abstractions mask the hetero -\ngeneity of the underlying hosts, links, switches, and protocols, allowing the distributed \ncore to be both device and protocol agnostic. Because of this abstraction, the south -\nbound interface below the distributed core is logically higher than in our canonical \ncontroller in Figure 5.14 or the ODL controller in Figure 5.17.\n448     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\nthat host to reduce its transmission rate. We have seen in Chapter 3 that TCP has its \nown congestion-control mechanism that operates at the transport layer, without the \nuse of network-layer feedback such as the ICMP source quench message.\nIn Chapter 1 we introduced the Traceroute program, which allows us to trace a \nroute from a host to any other host in the world.  Interestingly, Traceroute is imple -\nmented with ICMP messages. To determine the names and addresses of the routers \nbetween source and destination, Traceroute in the source sends a series of ordinary IP \ndatagrams to the destination. Each of these datagrams carries a UDP segment with an \nunlikely UDP port number. The first of these datagrams has a TTL of 1, the second of 2, \nthe third of 3, and so on. The source also starts timers for each of the datagrams. When \nthe nth datagram arrives at the nth router, the nth router observes that the TTL of the \ndatagram has just expired. According to the rules of the IP", "doc_id": "00ab1247-1fc9-412a-8864-f894db4cee60", "embedding": null, "doc_hash": "0825c9774d91f51f1bf15a8280608fa7cc99c7fb2016d76118d617a338bccc91", "extra_info": null, "node_info": {"start": 1304338, "end": 1308237}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "6ab4a37c-63d6-465f-b705-125540012e29", "3": "f899621d-48f3-4348-8b03-cf8a57f88ac4"}}, "__type__": "1"}, "f899621d-48f3-4348-8b03-cf8a57f88ac4": {"__data__": {"text": "introduced the Traceroute program, which allows us to trace a \nroute from a host to any other host in the world.  Interestingly, Traceroute is imple -\nmented with ICMP messages. To determine the names and addresses of the routers \nbetween source and destination, Traceroute in the source sends a series of ordinary IP \ndatagrams to the destination. Each of these datagrams carries a UDP segment with an \nunlikely UDP port number. The first of these datagrams has a TTL of 1, the second of 2, \nthe third of 3, and so on. The source also starts timers for each of the datagrams. When \nthe nth datagram arrives at the nth router, the nth router observes that the TTL of the \ndatagram has just expired. According to the rules of the IP protocol, the router discards \nthe datagram and sends an ICMP warning message to the source (type 11 code 0). This \nwarning message includes the name of the router and its IP address. When this ICMP \nmessage arrives back at the source, the source obtains the round-trip time from the \ntimer and the name and IP address of the nth router from the ICMP message.\nHow does a Traceroute source know when to stop sending UDP segments? \nRecall that the source increments the TTL field for each datagram it sends. Thus, one \nof the datagrams will eventually make it all the way to the destination host. Because \nthis datagram contains a UDP segment with an unlikely port number, the destination Figure 5.19  \u2666 ICMP message typesICMP Type Code Description\n0\n3\n3\n3\n3\n3\n3\n4\n8\n9\n10\n11\n120\n0\n1\n2\n3\n6\n7\n0\n0\n0\n0\n0\n0echo reply (to ping)\ndestination network unreachable\ndestination host unreachable\ndestination protocol unreachable\ndestination port unreachable\ndestination network unknown\ndestination host unknown\nsource quench (congestion control)\necho request\nrouter advertisement\nrouter discovery\nTTL expired\nIP header bad\n5.7  \u2022  NETWORK MANAGEMENT AND SNMP      449\nhost sends a port unreachable ICMP message (type 3 code 3) back to the source. \nWhen the source host receives this particular ICMP message, it knows it does not \nneed to send additional probe packets. (The standard Traceroute program actually \nsends sets of three packets with the same TTL; thus the Traceroute output provides \nthree results for each TTL.)\nIn this manner, the source host learns the number and the identities of routers \nthat lie between it and the destination host and the round-trip time between the two \nhosts. Note that the Traceroute client program must be able to instruct the operating \nsystem to generate UDP datagrams with specific TTL values and must also be able to \nbe notified by its operating system when ICMP messages arrive. Now that you under -\nstand how Traceroute works, you may want to go back and play with it some more.\nA new version of ICMP has been defined for IPv6 in RFC 4443. In addition to \nreorganizing the existing ICMP type and code definitions, ICMPv6 also added new \ntypes and codes required by the new IPv6 functionality. These include the \u201cPacket \nToo Big\u201d type and an \u201cunrecognized IPv6 options\u201d error code.\n5.7 Network Management and SNMP\nHaving now made our way to the end of our study of the network layer, with only \nthe link-layer before us, we\u2019re well aware that a network consists of many com -\nplex, interacting pieces of hardware and software\u2014from the links, switches, routers, \nhosts, and other devices that comprise the physical components of the network to \nthe many protocols that control and coordinate these devices. When hundreds or \nthousands of such components are brought together by an organization to form a \nnetwork, the job of the network administrator to keep the network \u201cup and running\u201d \nis surely a challenge. We saw in Section 5.5 that the logically centralized controller \ncan help with this process in an SDN context. But the", "doc_id": "f899621d-48f3-4348-8b03-cf8a57f88ac4", "embedding": null, "doc_hash": "949e29c3ad3b0064f74c3a02d5bda22738fb51074804be0bc99c51a226693b71", "extra_info": null, "node_info": {"start": 1308293, "end": 1312087}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "00ab1247-1fc9-412a-8864-f894db4cee60", "3": "39c53241-670b-470d-9663-1cc2e9a446a2"}}, "__type__": "1"}, "39c53241-670b-470d-9663-1cc2e9a446a2": {"__data__": {"text": "and an \u201cunrecognized IPv6 options\u201d error code.\n5.7 Network Management and SNMP\nHaving now made our way to the end of our study of the network layer, with only \nthe link-layer before us, we\u2019re well aware that a network consists of many com -\nplex, interacting pieces of hardware and software\u2014from the links, switches, routers, \nhosts, and other devices that comprise the physical components of the network to \nthe many protocols that control and coordinate these devices. When hundreds or \nthousands of such components are brought together by an organization to form a \nnetwork, the job of the network administrator to keep the network \u201cup and running\u201d \nis surely a challenge. We saw in Section 5.5 that the logically centralized controller \ncan help with this process in an SDN context. But the challenge of network manage -\nment has been around long before SDN, with a rich set of network management tools \nand approaches that help the network administrator monitor, manage, and control the \nnetwork. We\u2019ll study these tools and techniques in this section.\nAn often-asked question is \u201cWhat is network management?\u201d A well-conceived, \nsingle-sentence (albeit a rather long run-on sentence) definition of network manage -\nment from [Saydam 1996] is:\nNetwork management includes the deployment, integration, and coordination of \nthe hardware, software, and human elements to monitor, test, poll, configure, ana -\nlyze, evaluate, and control the network and element resources to meet the real-time, \noperational performance, and Quality of Service requirements at a reasonable cost.\nGiven this broad definition, we\u2019ll cover only the rudiments of network man -\nagement in this section\u2014the architecture, protocols, and information base used by \n450     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\na network administrator in performing their task. We\u2019ll not cover the administrator\u2019s \ndecision-making processes, where topics such as fault identification [Labovitz 1997; \nSteinder 2002; Feamster 2005; Wu 2005; Teixeira 2006], anomaly detection [Lakhina \n2005; Barford 2009], network design/engineering to meet contracted Service Level \nAgreements (SLA\u2019s) [Huston 1999a], and more come into consideration. Our focus \nis thus purposefully narrow; the interested reader should consult these references, the \nexcellent network-management text by Subramanian [Subramanian 2000], and the \nmore detailed treatment of network management available on the Web site for this text.\n5.7.1  The Network Management Framework\nFigure 5.20 shows the key components of network management:\n\u2022 The managing server  is an application, typically with a human in the loop, run -\nning in a centralized network management station in the network operations center \n(NOC). The managing server is the locus of activity for network management; it \ncontrols the collection, processing, analysis, and/or display of network management \ninformation. It is here that actions are initiated to control network behavior and here \nthat the human network administrator interacts with the network\u2019s devices.\n\u2022 A managed device  is a piece of network equipment (including its software) that \nresides on a managed network. A managed device might be a host, router, switch, \nmiddlebox, modem, thermometer, or other network-connected device. There may \nbe several so-called managed objects  within a managed device. These managed \nobjects are the actual pieces of hardware within the managed device (for example, \na network interface card is but one component of a host or router), and configura -\ntion parameters for these hardware and software components (for example, an \nintra-AS routing protocol such as OSPF).\n\u2022 Each managed object within a managed device associated information that is collected \ninto a Management Information Base (MIB) ; we\u2019ll see that the values of these \npieces of information are available to (and in many cases able to be set by) the man -\naging server. A MIB object might be a counter, such as the number of IP datagrams \ndiscarded at a router due to errors in an IP datagram header, or the number of UDP \nsegments received at a host; descriptive information such", "doc_id": "39c53241-670b-470d-9663-1cc2e9a446a2", "embedding": null, "doc_hash": "6059a2ac629f6d3f4f53ddc9da1be946dddf91602bccdfb92449487694a03b1c", "extra_info": null, "node_info": {"start": 1312023, "end": 1316170}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "f899621d-48f3-4348-8b03-cf8a57f88ac4", "3": "9dda46c4-158b-40e2-a359-358aaf944998"}}, "__type__": "1"}, "9dda46c4-158b-40e2-a359-358aaf944998": {"__data__": {"text": "\nbe several so-called managed objects  within a managed device. These managed \nobjects are the actual pieces of hardware within the managed device (for example, \na network interface card is but one component of a host or router), and configura -\ntion parameters for these hardware and software components (for example, an \nintra-AS routing protocol such as OSPF).\n\u2022 Each managed object within a managed device associated information that is collected \ninto a Management Information Base (MIB) ; we\u2019ll see that the values of these \npieces of information are available to (and in many cases able to be set by) the man -\naging server. A MIB object might be a counter, such as the number of IP datagrams \ndiscarded at a router due to errors in an IP datagram header, or the number of UDP \nsegments received at a host; descriptive information such as the version of the soft -\nware running on a DNS server; status information such as whether a particular device \nis functioning correctly; or protocol-specific information such as a routing path to a \ndestination. MIB objects are specified in a data description language known as SMI \n(Structure of Management Information) [RFC 2578; RFC 2579; RFC 2580]. A formal \ndefinition language is used to ensure that the syntax and semantics of the network \nmanagement data are well defined and unambiguous. Related MIB objects are gath -\nered into MIB modules. As of mid-2015, there were nearly 400 MIB modules defined \nby RFCs, and a much larger number of vendor-specific (private) MIB modules.\n\u2022 Also resident in each managed device is a network management agent , a pro -\ncess running in the managed device that communicates with the managing server, \n5.7  \u2022  NETWORK MANAGEMENT AND SNMP      451\ntaking local actions at the managed device under the command and control of the \nmanaging server. The network management agent is similar to the routing agent \nthat we saw in Figure 5.2.\n\u2022 The final component of a network management framework is the network \n management protocol . The protocol runs between the managing server and the \nmanaged devices, allowing the managing server to query the status of managed \ndevices and indirectly take actions at these devices via its agents. Agents can use \nthe network management protocol to inform the managing server of exceptional \nevents (for example, component failures or violation of performance thresholds). \nIt\u2019s important to note that the network management protocol does not itself man -\nage the network. Instead, it provides capabilities that a network administrator can \nuse to manage (\u201cmonitor, test, poll, configure, analyze, evaluate, and control\u201d) the \nnetwork. This is a subtle, but important, distinction. In the following section, we\u2019ll \ncover the Internet\u2019s SNMP (Simple Network Management Protocol)  protocol.Figure 5.20  \u2666  Elements of network management: Managing server, \n managed devices, MIB data, remote agents, SNMPManaging server\nAgentAgent\nManaged\ndeviceManaged\ndeviceManaged\ndevice\nManaged\ndeviceAgent MIB data\nMIB data\nAgent MIB data MIB data\nSNMP\nprotocolKey:Agent MIB data\nManaged\ndevice\n452     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\n5.7.2  The Simple Network Management Protocol (SNMP)\nThe Simple Network Management Protocol  version 2 (SNMPv2) [RFC 3416] \nis an application-layer protocol used to convey network-management control and \ninformation messages between a managing server and an agent executing on behalf \nof that managing server. The most common usage of SNMP is in a request-response \nmode in which an SNMP managing server sends a request to an SNMP agent, who \nreceives the request, performs some action, and sends a reply to the request. Typi -\ncally, a request will be used to query (retrieve) or modify (set) MIB object values \nassociated with a managed device. A second common usage of SNMP is for an agent \nto send an unsolicited message, known as a trap message, to a managing server. Trap \nmessages are used to notify a managing server of an exceptional situation (e.g., a \nlink interface going up or down)", "doc_id": "9dda46c4-158b-40e2-a359-358aaf944998", "embedding": null, "doc_hash": "864c8ffed052954c0ac1b6e3e3930404df73371826a81e8cf3b1132000c22375", "extra_info": null, "node_info": {"start": 1316135, "end": 1320191}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "39c53241-670b-470d-9663-1cc2e9a446a2", "3": "1335ac7c-95c0-4974-9e7c-56f962ccd283"}}, "__type__": "1"}, "1335ac7c-95c0-4974-9e7c-56f962ccd283": {"__data__": {"text": "3416] \nis an application-layer protocol used to convey network-management control and \ninformation messages between a managing server and an agent executing on behalf \nof that managing server. The most common usage of SNMP is in a request-response \nmode in which an SNMP managing server sends a request to an SNMP agent, who \nreceives the request, performs some action, and sends a reply to the request. Typi -\ncally, a request will be used to query (retrieve) or modify (set) MIB object values \nassociated with a managed device. A second common usage of SNMP is for an agent \nto send an unsolicited message, known as a trap message, to a managing server. Trap \nmessages are used to notify a managing server of an exceptional situation (e.g., a \nlink interface going up or down) that has resulted in changes to MIB object values.\nSNMPv2 defines seven types of messages, known generically as protocol data \nunits\u2014PDUs\u2014as shown in Table 5.2 and described below. The format of the PDU \nis shown in Figure 5.21.\n\u2022 The GetRequest , GetNextRequest,  and GetBulkRequest  PDUs are \nall sent from a managing server to an agent to request the value of one or more MIB \nobjects at the agent\u2019s managed device. The MIB objects whose values are being \nTable 5.2  \u2666 SNMPv2 PDU typesSNMPv2 PDU Type Sender-receiver Description\nGetRequest manager-to-agent get value of one or more MIB object instances\nGetNextRequest manager-to-agent get value of next MIB object instance in list or table\nGetBulkRequest manager-to-agent get values in large block of data, for example, values \nin a large table\nInformRequest manager-to-manager inform remote managing entity of MIB values remote \nto its access\nSetRequest manager-to-agent set value of one or more MIB object instances\nResponse agent-to-manager or generated in response to \nmanager-to-manager  GetRequest,  \n GetNextRequest,  \n GetBulkRequest,  \n SetRequest PDU, or  \n InformRequest\nSNMPv2-Trap agent-to-manager inform manager of an exceptional event #\n5.7  \u2022  NETWORK MANAGEMENT AND SNMP      453\nrequested are specified in the variable binding portion of the PDU.  GetRequest , \nGetNextRequest , and GetBulkRequest  differ in the granularity of their \ndata requests. GetRequest  can request an arbitrary set of MIB values; multiple \nGetNextRequest s can be used to sequence through a list or table of MIB \nobjects; GetBulkRequest  allows a large block of data to be returned, avoiding \nthe overhead incurred if multiple GetRequest  or  GetNextRequest  mes -\nsages were to be sent. In all three cases, the agent responds with a Response \nPDU containing the object identifiers and their associated values.\n\u2022 The SetRequest  PDU is used by a managing server to set the value of one or \nmore MIB objects in a managed device. An agent replies with a Response  PDU \nwith the \u201cnoError\u201d error status to confirm that the value has indeed been set.\n\u2022 The InformRequest  PDU is used by a managing server to notify another \nmanaging server of MIB information that is remote to the receiving server.\n\u2022 The Response PDU  is typically sent from a managed device to the managing server \nin response to a request message from that server, returning the requested information.\n\u2022 The final type of SNMPv2 PDU is the trap message. Trap messages are generated \nasynchronously; that is, they are not generated in response to a received request but \nrather in response to an event for which the managing server requires notification. \nRFC 3418 defines well-known trap types that include a cold or warm start by a \ndevice, a link going up or down, the loss of a neighbor, or an authentication failure \nevent. A received trap request has no required response from a managing server.\nGiven the request-response nature of SNMP, it is worth noting here that although \nSNMP PDUs can be carried via many different transport protocols, the SNMP PDU \nis typically carried in the payload of a UDP datagram. Indeed, RFC 3417", "doc_id": "1335ac7c-95c0-4974-9e7c-56f962ccd283", "embedding": null, "doc_hash": "fb639f112dc95d8c8e939d54cb597c72613eb3f5dc5116bc0b47d23f50da3476", "extra_info": null, "node_info": {"start": 1320246, "end": 1324169}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "9dda46c4-158b-40e2-a359-358aaf944998", "3": "cd0815d8-60a3-4b90-9540-74c3aee760ce"}}, "__type__": "1"}, "cd0815d8-60a3-4b90-9540-74c3aee760ce": {"__data__": {"text": "response to a request message from that server, returning the requested information.\n\u2022 The final type of SNMPv2 PDU is the trap message. Trap messages are generated \nasynchronously; that is, they are not generated in response to a received request but \nrather in response to an event for which the managing server requires notification. \nRFC 3418 defines well-known trap types that include a cold or warm start by a \ndevice, a link going up or down, the loss of a neighbor, or an authentication failure \nevent. A received trap request has no required response from a managing server.\nGiven the request-response nature of SNMP, it is worth noting here that although \nSNMP PDUs can be carried via many different transport protocols, the SNMP PDU \nis typically carried in the payload of a UDP datagram. Indeed, RFC 3417 states Figure 5.21  \u2666 SNMP PDU formatPDU\ntype\n(0\u20133)Request\nIdError\nStatus\n(0\u20135)Error\nIndexName\nValue NameName Value\nPDU\nType\n(4)EnterpriseAgent\nAddrTrap\nType\n(0\u20137)Speci\ufb01c\ncodeTime\nstampValueGet/set header\nTrap header Trap information\nSNMP PDUVariables to get/set\n454     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\nthat UDP is \u201cthe  preferred transport mapping.\u201d However, since UDP is an unreli -\nable transport protocol, there is no guarantee that a request, or its response, will be \nreceived at the intended destination. The request ID field of the PDU (see Figure \n5.21) is used by the managing server to number its requests to an agent; the agent\u2019s \nresponse takes its request ID from that of the received request. Thus, the request ID \nfield can be used by the managing server to detect lost requests or replies. It is up to \nthe managing server to decide whether to retransmit a request if no corresponding \nresponse is received after a given amount of time. In particular, the SNMP standard \ndoes not mandate any particular procedure for retransmission, or even if retransmis-\nsion is to be done in the first place. It only requires that the managing server \u201cneeds \nto act responsibly in respect to the frequency and duration of retransmissions.\u201d This, \nof course, leads one to wonder how a \u201cresponsible\u201d protocol should act!\nSNMP has evolved through three versions. The designers of SNMPv3 have said \nthat \u201cSNMPv3 can be thought of as SNMPv2 with additional security and administra -\ntion capabilities\u201d [RFC 3410]. Certainly, there are changes in SNMPv3 over SNMPv2, \nbut nowhere are those changes more evident than in the area of administration and secu -\nrity. The central role of security in SNMPv3 was particularly important, since the lack \nof adequate security resulted in SNMP being used primarily for monitoring rather than \ncontrol (for example, SetRequest  is rarely used in SNMPv1). Once again, we see that \n security \u2014a topic we\u2019ll cover in detail in Chapter 8  \u2014 is of critical concern, but once again \na concern whose importance had been realized perhaps a bit late and only then \u201cadded on.\u201d\n5.7 Summary\nWe have now completed our two-chapter journey into the network core\u2014a jour -\nney that began with our study of the network layer\u2019s data plane in Chapter 4 and \nfinished here with our study of the network layer\u2019s control plane. We learned that \nthe control plane is the network-wide logic that controls not only how a datagram \nis forwarded among routers along an end-to-end path from the source host to the \ndestination host, but also how network-layer components and services are config -\nured and managed.\nWe learned that there are two broad approaches towards building a control \nplane: traditional per-router control  (where a routing algorithm runs in each and \nevery router and the routing component in the router communicates with the routing \ncomponents in other routers) and software-defined networking  (SDN) control (where \na logically", "doc_id": "cd0815d8-60a3-4b90-9540-74c3aee760ce", "embedding": null, "doc_hash": "3bd92de63c3ae7b16b69fc392877665c3beb13a788bcfa9da40b7995603334dc", "extra_info": null, "node_info": {"start": 1324136, "end": 1327931}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "1335ac7c-95c0-4974-9e7c-56f962ccd283", "3": "0570143b-4e01-48a8-9ca0-2ed3792f94f8"}}, "__type__": "1"}, "0570143b-4e01-48a8-9ca0-2ed3792f94f8": {"__data__": {"text": "journey into the network core\u2014a jour -\nney that began with our study of the network layer\u2019s data plane in Chapter 4 and \nfinished here with our study of the network layer\u2019s control plane. We learned that \nthe control plane is the network-wide logic that controls not only how a datagram \nis forwarded among routers along an end-to-end path from the source host to the \ndestination host, but also how network-layer components and services are config -\nured and managed.\nWe learned that there are two broad approaches towards building a control \nplane: traditional per-router control  (where a routing algorithm runs in each and \nevery router and the routing component in the router communicates with the routing \ncomponents in other routers) and software-defined networking  (SDN) control (where \na logically centralized controller computes and distributes the forwarding tables to \nbe used by each and every router). We studied two fundamental routing algorithms \nfor computing least cost paths in a graph\u2014link-state routing and distance-vector \nrouting\u2014in Section 5.2; these algorithms find application in both per-router control \nand in SDN control. These algorithms are the basis for two widely-deployed Internet \nHOMEWORK PROBLEMS AND QUESTIONS      455\nrouting protocols, OSPF and BGP, that we covered in Sections 5.3 and 5.4. We \ncovered the SDN approach to the network-layer control plane in Section 5.5, inves -\ntigating SDN network-control applications, the SDN controller, and the OpenFlow \nprotocol for communicating between the controller and SDN-controlled devices. In \nSections 5.6 and 5.7, we covered some of the nuts and bolts of managing an IP net -\nwork: ICMP (the Internet Control Message Protocol) and SNMP (the Simple Net -\nwork Management Protocol).\nHaving completed our study of the network layer, our journey now takes us \none step further down the protocol stack, namely, to the link layer. Like the network \nlayer, the link layer is part of each and every network-connected device. But we will \nsee in the next chapter that the link layer has the much more localized task of moving \npackets between nodes on the same link or LAN. Although this task may appear on \nthe surface to be rather simple compared with that of the network layer\u2019s tasks, we \nwill see that the link layer involves a number of important and fascinating issues that \ncan keep us busy for a long time.\nHomework Problems and Questions\nChapter 5 Review Questions\nSECTION 5.1\n R1. What is meant by a control plane that is based on per-router control? In such \ncases, when we say the network control and data planes are implemented \n\u201cmonolithically,\u201d what do we mean?\n R2. What is meant by a control plane that is based on logically centralized \ncontrol? In such cases, are the data plane and the control plane implemented \nwithin the same device or in separate devices? Explain.\nSECTION 5.2\n R3. Compare and contrast the properties of a centralized and a distributed routing \nalgorithm. Give an example of a routing protocol that takes a centralized and \na decentralized approach.\n R4. Compare and contrast static and dynamic routing algorithms.\n R5. What is the \u201ccount to infinity\u201d problem in distance vector routing?\n R6. How is a least cost path calculated in a decentralized routing algorithm?\nSECTIONS 5.3\u20135.4\n R7. Why are different inter-AS and intra-AS protocols used in the Internet?\n R8. True or false: When an OSPF route sends its link state information, it is sent \nonly to those nodes directly attached neighbors. Explain.\n456     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\n R9. What is meant by an area in an OSPF autonomous system? Why was the \nconcept of an area introduced?\n R10. Define and contrast the following terms: subnet, prefix , and BGP route .\n R11. How does", "doc_id": "0570143b-4e01-48a8-9ca0-2ed3792f94f8", "embedding": null, "doc_hash": "718fb2cb0bb029aec780d87c8c50558f6eb7e62f0fb91d381c4747019432a163", "extra_info": null, "node_info": {"start": 1327934, "end": 1331718}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "cd0815d8-60a3-4b90-9540-74c3aee760ce", "3": "65ca127f-71f3-4319-87b1-8da9e31bacc1"}}, "__type__": "1"}, "65ca127f-71f3-4319-87b1-8da9e31bacc1": {"__data__": {"text": "to infinity\u201d problem in distance vector routing?\n R6. How is a least cost path calculated in a decentralized routing algorithm?\nSECTIONS 5.3\u20135.4\n R7. Why are different inter-AS and intra-AS protocols used in the Internet?\n R8. True or false: When an OSPF route sends its link state information, it is sent \nonly to those nodes directly attached neighbors. Explain.\n456     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\n R9. What is meant by an area in an OSPF autonomous system? Why was the \nconcept of an area introduced?\n R10. Define and contrast the following terms: subnet, prefix , and BGP route .\n R11. How does BGP use the NEXT-HOP attribute? How does it use the AS-PATH \nattribute?\n R12. Describe how a network administrator of an upper-tier ISP can implement \npolicy when configuring BGP.\n R13. True or false: When a BGP router receives an advertised path from its neigh-\nbor, it must add its own identity to the received path and then send that new \npath on to all of its neighbors. Explain.\nSECTION 5.5\n R14. Describe the main role of the communication layer, the network-wide state- \nmanagement layer, and the network-control application layer in an SDN \ncontroller.\n R15. Suppose you wanted to implement a new routing protocol in the SDN control \nplane. At which layer would you implement that protocol? Explain.\n R16. What types of messages flow across an SDN controller\u2019s northbound and \nsouthbound APIs? Who is the recipient of these messages sent from the \ncontroller across the southbound interface, and who sends messages to the \ncontroller across the northbound interface?\n R17. Describe the purpose of two types of OpenFlow messages (of your choosing) \nthat are sent from a controlled device to the controller. Describe the purpose \nof two types of Openflow messages (of your choosing) that are send from the \ncontroller to a controlled device.\n R18. What is the purpose of the service abstraction layer in the OpenDaylight SDN \ncontroller?\nSECTIONS 5.6\u20135.7\n R19. Names four different types of ICMP messages\n R20. What two types of ICMP messages are received at the sending host executing \nthe Traceroute  program?\n R21. Define the following terms in the context of SNMP: managing server, \n managed device, network management agent and MIB.\n R22. What are the purposes of the SNMP GetRequest  and SetRequest  messages?\n R23. What is the purpose of the SNMP trap message?\nPROBLEMS      457\nProblems\n P1. Looking at Figure 5.3, enumerate the paths from y to u that do not contain \nany loops.\n P2. Repeat Problem P1 for paths from x to z, z to u, and z to w.\n P3. Consider the following network. With the indicated link costs, use Dijkstra\u2019s \nshortest-path algorithm to compute the shortest path from x to all network nodes. \nShow how the algorithm works by computing a table similar to Table 5.1. \nxvt yz\nu\nw612\n87\n8\n3\n64324\n3\n P4. Consider the network shown in Problem P3. Using Dijkstra\u2019s algorithm, and \nshowing your work using a table similar to Table 5.1, do the following:\na. Compute the shortest path from t to all network nodes.\nb. Compute the shortest path from u to all network nodes.\nc. Compute the shortest path from v to all network nodes.\nd. Compute the shortest path from w to all network nodes.\ne. Compute the shortest path from y to all network nodes.\nf. Compute the shortest path from z to all network nodes.\n P5. Consider the network shown below, and assume that each node initially \nknows the costs to each of its neighbors. Consider the distance-vector algo-\nrithm and show the distance table", "doc_id": "65ca127f-71f3-4319-87b1-8da9e31bacc1", "embedding": null, "doc_hash": "b934f75098cbb824bf986457c5fd7df09f4272e572f53606e4c7bbc991d9b816", "extra_info": null, "node_info": {"start": 1331884, "end": 1335420}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "0570143b-4e01-48a8-9ca0-2ed3792f94f8", "3": "ba5f5581-45e1-4e88-bb52-010cda0b51db"}}, "__type__": "1"}, "ba5f5581-45e1-4e88-bb52-010cda0b51db": {"__data__": {"text": "P4. Consider the network shown in Problem P3. Using Dijkstra\u2019s algorithm, and \nshowing your work using a table similar to Table 5.1, do the following:\na. Compute the shortest path from t to all network nodes.\nb. Compute the shortest path from u to all network nodes.\nc. Compute the shortest path from v to all network nodes.\nd. Compute the shortest path from w to all network nodes.\ne. Compute the shortest path from y to all network nodes.\nf. Compute the shortest path from z to all network nodes.\n P5. Consider the network shown below, and assume that each node initially \nknows the costs to each of its neighbors. Consider the distance-vector algo-\nrithm and show the distance table entries at node z.\nu\nzv\ny236\n2\n31\nxVideoNote\nDijkstra\u2019s algorithm: \ndiscussion and example\n458     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\n P6. Consider a general topology (that is, not the specific network shown above) and a \nsynchronous version of the distance-vector algorithm. Suppose that at each itera -\ntion, a node exchanges its distance vectors with its neighbors and receives their \ndistance vectors. Assuming that the algorithm begins with each node knowing \nonly the costs to its immediate neighbors, what is the maximum number of itera -\ntions required before the distributed algorithm converges? Justify your answer.\n P7. Consider the network fragment shown below. x has only two attached neigh-\nbors, w and y. w has a minimum-cost path to destination u (not shown) of 5, \nand y has a minimum-cost path to u of 6. The complete paths from w and y \nto u (and between w and y) are not shown. All link costs in the network have \nstrictly positive integer values.\nxyw\n2 2\n5\na. Give x\u2019s distance vector for destinations w, y, and u.\nb. Give a link-cost change for either c(x,w) or c(x,y) such that x will inform \nits neighbors of a new minimum-cost path to u as a result of executing the \ndistance-vector algorithm.\nc. Give a link-cost change for either c(x,w) or c(x,y) such that x will not \ninform its neighbors of a new minimum-cost path to u as a result of \nexecuting the distance-vector algorithm.\n P8. Consider the three-node topology shown in Figure 5.6. Rather than having \nthe link costs shown in Figure 5.6, the link costs are c(x,y) = 3, c(y,z) = 6, \nc(z,x) = 4. Compute the distance tables after the initialization step and after \neach iteration of a synchronous version of the distance-vector algorithm (as \nwe did in our earlier discussion of Figure 5.6).\n P9. Can the poisoned reverse  solve the general count-to-infinity problem? Justify \nyour answer.\n P10. Argue that for the distance-vector algorithm in Figure 5.6, each value in the \ndistance vector D(x) is non-increasing and will eventually stabilize in a finite \nnumber of steps.\n P11. Consider Figure 5.7. Suppose there is another router w, connected to router \ny and z. The costs of all links are given as follows: c(x,y) = 4, c(x,z) = 50, \nc(y,w) = 1, c(z,w) = 1, c(y,z) = 3. Suppose that poisoned reverse is used in \nthe distance-vector routing algorithm.\nPROBLEMS      459\na. When the distance vector routing is stabilized, router w, y, and z inform their \ndistances to x to each other. What distance values do they tell each other?\nb. Now suppose that the link cost between x and y increases to 60. Will there be \na count-to-infinity problem even if poisoned reverse is used? Why or why not?", "doc_id": "ba5f5581-45e1-4e88-bb52-010cda0b51db", "embedding": null, "doc_hash": "b1ecb72afe29c6684d21c5f1f0fa2c20876ffe1e36ade57bc0679e1bb2e475e0", "extra_info": null, "node_info": {"start": 1335364, "end": 1338737}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "65ca127f-71f3-4319-87b1-8da9e31bacc1", "3": "ff2f6b08-6786-45ed-8ba5-5e785d8bd983"}}, "__type__": "1"}, "ff2f6b08-6786-45ed-8ba5-5e785d8bd983": {"__data__": {"text": "Figure 5.7. Suppose there is another router w, connected to router \ny and z. The costs of all links are given as follows: c(x,y) = 4, c(x,z) = 50, \nc(y,w) = 1, c(z,w) = 1, c(y,z) = 3. Suppose that poisoned reverse is used in \nthe distance-vector routing algorithm.\nPROBLEMS      459\na. When the distance vector routing is stabilized, router w, y, and z inform their \ndistances to x to each other. What distance values do they tell each other?\nb. Now suppose that the link cost between x and y increases to 60. Will there be \na count-to-infinity problem even if poisoned reverse is used? Why or why not? \nIf there is a count-to-infinity problem, then how many iterations are needed for \nthe distance-vector routing to reach a stable state again? Justify your answer.\nc. How do you modify c(y,z) such that there is no count-to-infinity problem \nat all if c(y,x) changes from 4 to 60?\n P12. What is the message complexity of LS routing algorithm?\n P13. Will a BGP router always choose the loop-free route with the shortest ASpath \nlength? Justify your answer.\n P14. Consider the network shown below. Suppose AS3 and AS2 are running \nOSPF for their intra-AS routing protocol. Suppose AS1 and AS4 are running \nRIP for their intra-AS routing protocol. Suppose eBGP and iBGP are used \nfor the inter-AS routing protocol. Initially suppose there is no physical link \nbetween AS2 and AS4.\na. Router 3c learns about prefix x from which routing protocol: OSPF, RIP, \neBGP, or iBGP?\nb. Router 3a learns about x from which routing protocol?\nc. Router 1c learns about x from which routing protocol?\nd. Router 1d learns about x from which routing protocol?\nAS4\nAS3\nAS1AS2x4b\n4c4a\n3c\n3b3a\n1c\n1b\n1d1a\nI1 I22c\n2a\n2b\n460     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\n P15. Referring to the previous problem, once router 1d learns about x it will put an \nentry ( x, I) in its forwarding table.\na. Will I be equal to I1 or I2 for this entry? Explain why in one sentence.\nb. Now suppose that there is a physical link between AS2 and AS4, shown \nby the dotted line. Suppose router 1d learns that x is accessible via AS2 as \nwell as via AS3. Will I be set to I1 or I2? Explain why in one sentence.\nc. Now suppose there is another AS, called AS5, which lies on the path \nbetween AS2 and AS4 (not shown in diagram). Suppose router 1d learns \nthat x is accessible via AS2 AS5 AS4 as well as via AS3 AS4. Will I be \nset to I1 or I2? Explain why in one sentence.\nP16. Consider the following network. ISP B provides national backbone service \nto regional ISP A. ISP C provides national backbone service to regional \nISP D. Each ISP consists of one AS. B and C peer with each other in two \nplaces using BGP. Consider traffic going from A to D. B would prefer \nto hand that traffic over to C on the West Coast (so that C would have \nto absorb the cost of carrying the traffic cross-country), while C would \nprefer to get the traffic via its East Coast peering point with B (so that B \nwould have carried the traffic across the country). What BGP mechanism \nmight C use, so that B would hand over A-to-D traffic at its East Coast \npeering point? To answer this question, you will need to dig into the BGP \n specification.\nISP B\nISP C\nISP", "doc_id": "ff2f6b08-6786-45ed-8ba5-5e785d8bd983", "embedding": null, "doc_hash": "93296df5cce3622ea37bdaf4fcfef2a27322ea3925748a8489c61538cb82f0e3", "extra_info": null, "node_info": {"start": 1338819, "end": 1342030}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "ba5f5581-45e1-4e88-bb52-010cda0b51db", "3": "dbab1c37-6730-4eb5-8908-996d74f384e9"}}, "__type__": "1"}, "dbab1c37-6730-4eb5-8908-996d74f384e9": {"__data__": {"text": "service \nto regional ISP A. ISP C provides national backbone service to regional \nISP D. Each ISP consists of one AS. B and C peer with each other in two \nplaces using BGP. Consider traffic going from A to D. B would prefer \nto hand that traffic over to C on the West Coast (so that C would have \nto absorb the cost of carrying the traffic cross-country), while C would \nprefer to get the traffic via its East Coast peering point with B (so that B \nwould have carried the traffic across the country). What BGP mechanism \nmight C use, so that B would hand over A-to-D traffic at its East Coast \npeering point? To answer this question, you will need to dig into the BGP \n specification.\nISP B\nISP C\nISP DISP A\nSOCKET PROGRAMMING ASSIGNMENT      461\n P17. In Figure 5.13, consider the path information that reaches stub networks W, \nX, and Y. Based on the information available at W and X, what are their \nrespective views of the network topology? Justify your answer. The topology \nview at Y is shown below.\nW\nYX\nA\nCStub network\nY\u2019s view of\nthe topology\n P18. Consider Figure 5.13. B would never forward traffic destined to Y via X based \non BGP routing. But there are some very popular applications for which data \npackets go to X first and then flow to Y. Identify one such application, and \ndescribe how data packets follow a path not given by BGP routing.\n P19. In Figure 5.13, suppose that there is another stub network V that is a cus-\ntomer of ISP A. Suppose that B and C have a peering relationship, and A is \na customer of both B and C. Suppose that A would like to have the traffic \ndestined to W to come from B only, and the traffic destined to V from either \nB or C. How should A advertise its routes to B and C? What AS routes does \nC receive?\n P20. Suppose ASs X and Z are not directly connected but instead are connected \nby AS Y. Further suppose that X has a peering agreement with Y, and that Y \nhas a peering agreement with Z. Finally, suppose that Z wants to transit all \nof Y\u2019s traffic but does not want to transit X\u2019s traffic. Does BGP allow Z to \n implement this policy?\n P21. Consider the two ways in which communication occurs between a managing \nentity and a managed device: request-response mode and trapping. What are \nthe pros and cons of these two approaches, in terms of (1) overhead, (2) noti-\nfication time when exceptional events occur, and (3) robustness with respect \nto lost messages between the managing entity and the device?\n P22. In Section 5.7 we saw that it was preferable to transport SNMP messages in \nunreliable UDP datagrams. Why do you think the designers of SNMP chose \nUDP rather than TCP as the transport protocol of choice for SNMP?\nSocket Programming Assignment\nAt the end of Chapter 2, there are four socket programming assignments. Below, \nyou will find a fifth assignment which employs ICMP, a protocol discussed in this \nchapter.\n462     CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\nAssignment 5: ICMP Ping\nPing is a popular networking application used to test from a remote location whether \na particular host is up and reachable. It is also often used to measure latency between \nthe client host and the target host. It works by sending ICMP \u201cecho request\u201d packets \n(i.e., ping packets) to the target host and listening for ICMP \u201cecho response\u201d replies \n(i.e., pong packets). Ping measures the RRT, records packet loss, and calculates a \nstatistical summary of multiple ping-pong exchanges (the minimum, mean, max, and \nstandard deviation of the round-trip times).\nIn this lab, you will write your own Ping application in Python. Your", "doc_id": "dbab1c37-6730-4eb5-8908-996d74f384e9", "embedding": null, "doc_hash": "f1ed962a0cc798ad88bfd623955c30b0d2d7b5adba5ffc3bda1ebc71d5a55255", "extra_info": null, "node_info": {"start": 1341952, "end": 1345547}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "ff2f6b08-6786-45ed-8ba5-5e785d8bd983", "3": "92bc9c97-9de1-4eb2-9085-8eb0bc067dad"}}, "__type__": "1"}, "92bc9c97-9de1-4eb2-9085-8eb0bc067dad": {"__data__": {"text": "   CHAPTER 5 \u2002\u2002\u2022 \u2002\u2002 THE NETWORK LAYER: CONTROL PLANE\nAssignment 5: ICMP Ping\nPing is a popular networking application used to test from a remote location whether \na particular host is up and reachable. It is also often used to measure latency between \nthe client host and the target host. It works by sending ICMP \u201cecho request\u201d packets \n(i.e., ping packets) to the target host and listening for ICMP \u201cecho response\u201d replies \n(i.e., pong packets). Ping measures the RRT, records packet loss, and calculates a \nstatistical summary of multiple ping-pong exchanges (the minimum, mean, max, and \nstandard deviation of the round-trip times).\nIn this lab, you will write your own Ping application in Python. Your application \nwill use ICMP. But in order to keep your program simple, you will not exactly follow \nthe official specification in RFC 1739. Note that you will only need to write the client \nside of the program, as the functionality needed on the server side is built into almost \nall operating systems. You can find full details of this assignment, as well as important \nsnippets of the Python code, at the Web site http://www.pearsonglobaleditions.com/\nkurose.\nProgramming Assignment\nIn this programming assignment, you will be writing a \u201cdistributed\u201d set of proce -\ndures that implements a distributed asynchronous distance-vector routing for the \nnetwork shown below.\nYou are to write the following routines that will \u201cexecute\u201d asynchronously \nwithin the emulated environment provided for this assignment. For node 0, you will \nwrite the routines:\n3201\n731\n21\n\u2022 rtinit0() . This routine will be called once at the beginning of the emulation. \nrtinit0()  has no arguments. It should initialize your distance table in node 0 to \nreflect the direct costs of 1, 3, and 7 to nodes 1, 2, and 3, respectively. In the \nfigure above, all links are bidirectional and the costs in both directions are identi -\ncal. After initializing the distance table and any other data structures needed by \nyour node 0 routines, it should then send its directly connected neighbors (in this \ncase, 1, 2, and 3) the cost of its minimum-cost paths to all other network nodes. \nWIRESHARK LAB      463\nThis minimum-cost information is sent to neighboring nodes in a routing update \npacket by calling the routine tolayer2(),  as described in the full assignment. The \nformat of the routing update packet is also described in the full assignment.\n\u2022 rtupdate0(struct rtpkt *rcvdpkt) . This routine will be called when node 0 receives \na routing packet that was sent to it by one of its directly connected neighbors. \nThe parameter *rcvdpkt  is a pointer to the packet that was received. rtupdate0()  \nis the \u201cheart\u201d of the distance-vector algorithm. The values it receives in a routing \nupdate packet from some other node i contain i\u2019s current shortest-path costs to \nall other network nodes. rtupdate0()  uses these received values to update its own \ndistance table (as specified by the distance-vector algorithm). If its own minimum \ncost to another node changes as a result of the update, node 0 informs its directly \nconnected neighbors of this change in minimum cost by sending them a rout -\ning packet. Recall that in the distance-vector algorithm, only directly connected \nnodes will exchange routing packets. Thus, nodes 1 and 2 will communicate with \neach other, but nodes 1 and 3 will not communicate with each other.\nSimilar routines are defined for nodes 1, 2, and 3. Thus, you will write eight pro -\ncedures in all: rtinit0(), rtinit1(), rtinit2(), rtinit3(), rtupdate0(), rtupdate1(), rtup -\ndate2(),  and rtupdate3().  These routines will together implement a distributed, \nasynchronous computation of the distance tables for the topology and costs shown in \nthe figure on the", "doc_id": "92bc9c97-9de1-4eb2-9085-8eb0bc067dad", "embedding": null, "doc_hash": "e4964c00ccb3f48545d429dce64b2ce74f51ea6f4381539b8e528d6e33dd40cc", "extra_info": null, "node_info": {"start": 1345526, "end": 1349295}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "dbab1c37-6730-4eb5-8908-996d74f384e9", "3": "128fd52d-8ca7-4947-ae3a-7338655ed629"}}, "__type__": "1"}, "128fd52d-8ca7-4947-ae3a-7338655ed629": {"__data__": {"text": "changes as a result of the update, node 0 informs its directly \nconnected neighbors of this change in minimum cost by sending them a rout -\ning packet. Recall that in the distance-vector algorithm, only directly connected \nnodes will exchange routing packets. Thus, nodes 1 and 2 will communicate with \neach other, but nodes 1 and 3 will not communicate with each other.\nSimilar routines are defined for nodes 1, 2, and 3. Thus, you will write eight pro -\ncedures in all: rtinit0(), rtinit1(), rtinit2(), rtinit3(), rtupdate0(), rtupdate1(), rtup -\ndate2(),  and rtupdate3().  These routines will together implement a distributed, \nasynchronous computation of the distance tables for the topology and costs shown in \nthe figure on the preceding page.\nYou can find the full details of the programming assignment, as well as C code \nthat you will need to create the simulated hardware/software environment, at http://\nwww.pearsonglobaleditions.com/kurose. A Java version of the assignment is also \navailable.\nWireshark Lab\nIn the Web site for this textbook, www.pearsonglobaleditions.com/kurose, you\u2019ll \nfind a Wireshark lab assignment that examines the use of the ICMP protocol in the \nping and traceroute commands.\n464Please describe one or two of the most exciting projects you have worked on during your \ncareer. What were the biggest challenges?\nWhen I was a researcher at AT&T, a group of us designed a new way to manage rout -\ning in Internet Service Provider backbone networks. Traditionally, network operators \nconfigure each router individually, and these routers run distributed protocols to compute \npaths through the network. We believed that network management would be simpler and \nmore flexible if network operators could exercise direct control over how routers forward \ntraffic based on a network-wide view of the topology and traffic. The Routing Control \nPlatform (RCP) we designed and built could compute the routes for all of AT&T\u2019s back -\nbone on a single commodity computer, and could control legacy routers without modi -\nfication. To me, this project was exciting because we had a provocative idea, a working \nsystem, and ultimately a real deployment in an operational network. Fast forward a few \nyears, and software-defined networking (SDN) has become a mainstream technology, \nand standard protocols (like OpenFlow) have made it much easier to tell the underlying \nswitches what to do.Jennifer Rexford is a Professor in the Computer Science department \nat Princeton University. Her research has the broad goal of making \ncomputer networks easier to design and manage, with particular \nemphasis on routing protocols. From 1996\u20132004, she was a mem -\nber of the Network Management and Performance department at \nAT&T Labs\u2013Research. While at AT&T, she designed techniques and \ntools for network measurement, traffic engineering, and router con -\nfiguration that were deployed in AT&T\u2019s backbone network. Jennifer \nis co-author of the book \u201cWeb Protocols and Practice: Networking \nProtocols, Caching, and Traffic Measurement,\u201d published by \nAddison-Wesley in May 2001. She served as the chair of ACM \nSIGCOMM from 2003 to 2007. She received her BSE degree in \nelectrical engineering from Princeton University in 1991, and her \nPhD degree in electrical engineering and computer science from \nthe University of Michigan in 1996. In 2004, Jennifer was the win -\nner of ACM\u2019s Grace Murray Hopper Award for outstanding young \ncomputer professional and appeared on the MIT TR-100 list of top \ninnovators under the age of 35.Jennifer RexfordAN INTERVIEW WITH\u2026\n\n465How do you think software-defined networking should evolve in the future?\nIn a major break from the past, control-plane software can be created by many different \nprogrammers, not just at companies selling network equipment. Yet, unlike the applications \nrunning on a server or a smart phone, controller apps must work together  to handle the same \ntraffic. Network operators do", "doc_id": "128fd52d-8ca7-4947-ae3a-7338655ed629", "embedding": null, "doc_hash": "d2e8a1ec06f12934df3f5d264f1cab8cc16c0f00e8de33c766e35f0700cc9df4", "extra_info": null, "node_info": {"start": 1349269, "end": 1353226}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "92bc9c97-9de1-4eb2-9085-8eb0bc067dad", "3": "e592555c-7050-4b19-9575-673751940dea"}}, "__type__": "1"}, "e592555c-7050-4b19-9575-673751940dea": {"__data__": {"text": "\nSIGCOMM from 2003 to 2007. She received her BSE degree in \nelectrical engineering from Princeton University in 1991, and her \nPhD degree in electrical engineering and computer science from \nthe University of Michigan in 1996. In 2004, Jennifer was the win -\nner of ACM\u2019s Grace Murray Hopper Award for outstanding young \ncomputer professional and appeared on the MIT TR-100 list of top \ninnovators under the age of 35.Jennifer RexfordAN INTERVIEW WITH\u2026\n\n465How do you think software-defined networking should evolve in the future?\nIn a major break from the past, control-plane software can be created by many different \nprogrammers, not just at companies selling network equipment. Yet, unlike the applications \nrunning on a server or a smart phone, controller apps must work together  to handle the same \ntraffic. Network operators do not want to perform load balancing on some traffic and rout -\ning on other traffic; instead, they want to perform load balancing and routing, together, on \nthe same traffic. Future SDN controller platforms should offer good programming abstrac -\ntions for composing  independently written multiple controller applications together. More \nbroadly, good programming abstractions can make it easier to create controller applications, \nwithout having to worry about low-level details like flow table entries, traffic counters, bit \npatterns in packet headers, and so on. Also, while an SDN controller is logically central -\nized, the network still consists of a distributed collection of devices. Future controllers \nshould offer good abstractions for updating the flow tables across the network, so apps can \nreason about what happens to packets in flight while the devices are updated. Programming \nabstractions for control-plane software is an exciting area for interdisciplinary research \nbetween computer networking, distributed systems, and programming languages, with a real \nchance for practical impact in the years ahead.\nWhere do you see the future of networking and the Internet?\nNetworking is an exciting field because the applications and the underlying technologies \nchange all the time. We are always reinventing ourselves! Who would have predicted even \nten years ago the dominance of smart phones, allowing mobile users to access existing \napplications as well as new location-based services? The emergence of cloud computing is \nfundamentally changing the relationship between users and the applications they run, and \nnetworked sensors and actuators (the \u201cInternet of Things\u201d) are enabling a wealth of new \napplications (and security vulnerabilities!). The pace of innovation is truly inspiring.\nThe underlying network is a crucial component in all of these innovations. Yet, the \nnetwork is notoriously \u201cin the way\u201d\u2014limiting performance, compromising reliability, con -\nstraining applications, and complicating the deployment and management of services. We \nshould strive to make the network of the future as invisible as the air we breathe, so it never \nstands in the way of new ideas and valuable services. To do this, we need to raise the level \nof abstraction above individual network devices and protocols (and their attendant acro -\nnyms!), so we can reason about the network and the user\u2019s high-level goals as a whole.\nWhat people inspired you professionally?\nI\u2019ve long been inspired by Sally Floyd at the International Computer Science Institute. Her \nresearch is always purposeful, focusing on the important challenges facing the Internet. She \ndigs deeply into hard questions until she understands the problem and the space of solutions \n466completely, and she devotes serious energy into \u201cmaking things happen,\u201d such as push -\ning her ideas into protocol standards and network equipment. Also, she gives back to the \ncommunity, through professional service in numerous standards and research organizations \nand by creating tools (such as the widely used ns-2 and ns-3 simulators) that enable other \nresearchers to succeed. She retired in 2009 but her influence on the field will be felt for \nyears to come.\nWhat are your recommendations for students who want careers in computer science and \nnetworking?\nNetworking is an inherently interdisciplinary field. Applying techniques from other disci -\nplines", "doc_id": "e592555c-7050-4b19-9575-673751940dea", "embedding": null, "doc_hash": "a35bfed1d558f4d885305dc8233d759835a85757586da68345574a63144866cf", "extra_info": null, "node_info": {"start": 1353139, "end": 1357404}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "128fd52d-8ca7-4947-ae3a-7338655ed629", "3": "5d8b3960-4cfe-4603-b4bb-c8300dc4ade3"}}, "__type__": "1"}, "5d8b3960-4cfe-4603-b4bb-c8300dc4ade3": {"__data__": {"text": "focusing on the important challenges facing the Internet. She \ndigs deeply into hard questions until she understands the problem and the space of solutions \n466completely, and she devotes serious energy into \u201cmaking things happen,\u201d such as push -\ning her ideas into protocol standards and network equipment. Also, she gives back to the \ncommunity, through professional service in numerous standards and research organizations \nand by creating tools (such as the widely used ns-2 and ns-3 simulators) that enable other \nresearchers to succeed. She retired in 2009 but her influence on the field will be felt for \nyears to come.\nWhat are your recommendations for students who want careers in computer science and \nnetworking?\nNetworking is an inherently interdisciplinary field. Applying techniques from other disci -\nplines breakthroughs in networking come from such diverse areas as queuing theory, game \ntheory, control theory, distributed systems, network optimization, programming languages, \nmachine learning, algorithms, data structures, and so on. I think that becoming conversant \nin a related field, or collaborating closely with experts in those fields, is a wonderful way \nto put networking on a stronger foundation, so we can learn how to build networks that are \nworthy of society\u2019s trust. Beyond the theoretical disciplines, networking is exciting because \nwe create real artifacts that real people use. Mastering how to design and build systems\u2014by \ngaining experience in operating systems, computer architecture, and so on\u2014is another fan -\ntastic way to amplify your knowledge of networking to help make the world a better place.\n467In the previous two chapters we learned that the network layer provides a commu -\nnication service between any two network hosts. Between the two hosts, datagrams \ntravel over a series of communication links, some wired and some wireless, starting \nat the source host, passing through a series of packet switches (switches and routers) \nand ending at the destination host. As we continue down the protocol stack, from \nthe network layer to the link layer, we naturally wonder how packets are sent across \nthe individual links  that make up the end-to-end communication path. How are the \nnetwork-layer datagrams encapsulated in the link-layer frames for transmission over \na single link? Are different link-layer protocols used in the different links along the \ncommunication path? How are transmission conflicts in broadcast links resolved? \nIs there addressing at the link layer and, if so, how does the link-layer addressing \noperate with the network-layer addressing we learned about in Chapter 4? And what \nexactly is the difference between a switch and a router? We\u2019ll answer these and other \nimportant questions in this chapter.\nIn discussing the link layer, we\u2019ll see that there are two fundamentally  different \ntypes of link-layer channels. The first type are broadcast channels, which connect \nmultiple hosts in wireless LANs, satellite networks, and hybrid fiber-coaxial cable \n(HFC) access networks. Since many hosts are connected to the same broadcast com -\nmunication channel, a so-called medium access protocol is needed to coordinate \nframe transmission. In some cases, a central controller may be used to coordinate 6CHAPTER\nThe Link Layer \nand LANs\n\n468     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\ntransmissions; in other cases, the hosts themselves coordinate transmissions. The \nsecond type of link-layer channel is the point-to-point communication link, such as \nthat often found between two routers connected by a long-distance link, or between \na user\u2019s office computer and the nearby Ethernet switch to which it is connected. \nCoordinating access to a point-to-point link is simpler; the reference material on this \nbook\u2019s Web site has a detailed discussion of the Point-to-Point Protocol (PPP), which \nis used in settings ranging from dial-up service over a telephone line to high-speed \npoint-to-point frame transport over fiber-optic links.\nWe\u2019ll explore several important link-layer concepts and technologies", "doc_id": "5d8b3960-4cfe-4603-b4bb-c8300dc4ade3", "embedding": null, "doc_hash": "33a3180d0be65cc52384acc0a25b9a74476edf3ed22ae83c5074390d45a9e2ab", "extra_info": null, "node_info": {"start": 1357411, "end": 1361496}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "e592555c-7050-4b19-9575-673751940dea", "3": "3596891d-49a8-4354-8885-be0a0c8488c4"}}, "__type__": "1"}, "3596891d-49a8-4354-8885-be0a0c8488c4": {"__data__": {"text": "\u2002\u2002 THE LINK LAYER AND LANS\ntransmissions; in other cases, the hosts themselves coordinate transmissions. The \nsecond type of link-layer channel is the point-to-point communication link, such as \nthat often found between two routers connected by a long-distance link, or between \na user\u2019s office computer and the nearby Ethernet switch to which it is connected. \nCoordinating access to a point-to-point link is simpler; the reference material on this \nbook\u2019s Web site has a detailed discussion of the Point-to-Point Protocol (PPP), which \nis used in settings ranging from dial-up service over a telephone line to high-speed \npoint-to-point frame transport over fiber-optic links.\nWe\u2019ll explore several important link-layer concepts and technologies in this  chapter. \nWe\u2019ll dive deeper into error detection and correction, a topic we touched on briefly \nin Chapter 3. We\u2019ll consider multiple access networks and switched LANs, including \nEthernet\u2014by far the most prevalent wired LAN technology. We\u2019ll also look at virtual \nLANs, and data center networks. Although WiFi, and more generally wireless LANs, \nare link-layer topics, we\u2019ll postpone our study of these important topics until Chapter 7 .\n6.1 Introduction to the Link Layer\nLet\u2019s begin with some important terminology. We\u2019ll find it convenient in this chapter \nto refer to any device that runs a link-layer (i.e., layer 2) protocol as a node . Nodes \ninclude hosts, routers, switches, and WiFi access points (discussed in Chapter 7 ). We \nwill also refer to the communication channels that connect adjacent nodes along the \ncommunication path as links . In order for a datagram to be transferred from source host \nto destination host, it must be moved over each of the individual links  in the end-to-\nend path. As an example, in the company network shown at the bottom of Figure 6.1, \nconsider sending a datagram from one of the wireless hosts to one of the servers. This \ndatagram will actually pass through six links: a WiFi link between sending host and \nWiFi access point, an Ethernet link between the access point and a link-layer switch; \na link between the link-layer switch and the router, a link between the two routers; an \nEthernet link between the router and a link-layer switch; and finally an Ethernet link \nbetween the switch and the server. Over a given link, a transmitting node encapsulates \nthe datagram in a link-layer frame  and transmits the frame into the link.\nIn order to gain further insight into the link layer and how it relates to the \n network layer, let\u2019s consider a transportation analogy. Consider a travel agent who \nis planning a trip for a tourist traveling from Princeton, New Jersey, to Lausanne, \nSwitzerland. The travel agent decides that it is most convenient for the tourist to take \na limousine from Princeton to JFK airport, then a plane from JFK airport to Geneva\u2019s \nairport, and finally a train from Geneva\u2019s airport to Lausanne\u2019s train station. Once \nthe travel agent makes the three reservations, it is the responsibility of the Princeton \nlimousine company to get the tourist from Princeton to JFK; it is the responsibility of \nthe airline company to get the tourist from JFK to Geneva; and it is the responsibility \n6.1  \u2022  INTRODUCTION TO THE LINK LAYER      469\nFigure 6.1  \u2666 Six link-layer hops between wireless host and serverNational or\nGlobal ISP\nMobile Network\nLocal or\nRegional ISP\nEnterprise NetworkHome Network\n470     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\nof the Swiss train service to get the tourist from Geneva to Lausanne. Each of the \nthree segments of the trip is \u201cdirect\u201d between two \u201cadjacent\u201d locations. Note that the \nthree transportation segments are managed by different companies and use entirely \ndifferent transportation modes (limousine, plane,", "doc_id": "3596891d-49a8-4354-8885-be0a0c8488c4", "embedding": null, "doc_hash": "6fc284e1900717efccd5585a583340fd309c6c71a918299b18be94223ad973cb", "extra_info": null, "node_info": {"start": 1361557, "end": 1365339}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "5d8b3960-4cfe-4603-b4bb-c8300dc4ade3", "3": "7d5ebe42-eb79-4105-86fa-a76c3891255b"}}, "__type__": "1"}, "7d5ebe42-eb79-4105-86fa-a76c3891255b": {"__data__": {"text": "the responsibility of \nthe airline company to get the tourist from JFK to Geneva; and it is the responsibility \n6.1  \u2022  INTRODUCTION TO THE LINK LAYER      469\nFigure 6.1  \u2666 Six link-layer hops between wireless host and serverNational or\nGlobal ISP\nMobile Network\nLocal or\nRegional ISP\nEnterprise NetworkHome Network\n470     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\nof the Swiss train service to get the tourist from Geneva to Lausanne. Each of the \nthree segments of the trip is \u201cdirect\u201d between two \u201cadjacent\u201d locations. Note that the \nthree transportation segments are managed by different companies and use entirely \ndifferent transportation modes (limousine, plane, and train). Although the transporta -\ntion modes are different, they each provide the basic service of moving passengers \nfrom one location to an adjacent location. In this transportation analogy, the tourist is \na datagram, each transportation segment is a link, the transportation mode is a link-\nlayer protocol, and the travel agent is a routing protocol.\n6.1.1 The Services Provided by the Link Layer\nAlthough the basic service of any link layer is to move a datagram from one node \nto an adjacent node over a single communication link, the details of the provided \nservice can vary from one link-layer protocol to the next. Possible services that can \nbe offered by a link-layer protocol include:\n\u2022 Framing.  Almost all link-layer protocols encapsulate each network-layer data -\ngram within a link-layer frame before transmission over the link. A frame consists \nof a data field, in which the network-layer datagram is inserted, and a number of \nheader fields. The structure of the frame is specified by the link-layer protocol. \nWe\u2019ll see several different frame formats when we examine specific link-layer \nprotocols in the second half of this chapter.\n\u2022 Link access.  A medium access control (MAC) protocol specifies the rules by \nwhich a frame is transmitted onto the link. For point-to-point links that have a \nsingle sender at one end of the link and a single receiver at the other end of the \nlink, the MAC protocol is simple (or nonexistent)\u2014the sender can send a frame \nwhenever the link is idle. The more interesting case is when multiple nodes share \na single broadcast link\u2014the so-called multiple access problem. Here, the MAC \nprotocol serves to coordinate the frame transmissions of the many nodes.\n\u2022 Reliable delivery.  When a link-layer protocol provides reliable delivery service, \nit guarantees to move each network-layer datagram across the link without error. \nRecall that certain transport-layer protocols (such as TCP) also provide a reliable \ndelivery service. Similar to a transport-layer reliable delivery service, a link-layer \nreliable delivery service can be achieved with acknowledgments and retransmis -\nsions (see Section 3.4 ). A link-layer reliable delivery service is often used for \nlinks that are prone to high error rates, such as a wireless link, with the goal of \ncorrecting an error locally\u2014on the link where the error occurs\u2014rather than forc -\ning an end-to-end retransmission of the data by a transport- or application-layer \nprotocol. However, link-layer reliable delivery can be considered an unnecessary \noverhead for low bit-error links, including fiber, coax, and many twisted-pair \ncopper links. For this reason, many wired link-layer protocols do not provide a \nreliable delivery service.\n6.1  \u2022  INTRODUCTION TO THE LINK LAYER      471\n\u2022 Error detection and correction.  The link-layer hardware in a receiving node can incor -\nrectly decide that a bit in a frame is zero when it was transmitted as a one, and vice \nversa. Such bit errors are introduced by signal attenuation and electromagnetic noise. \nBecause there is no need to forward a datagram that has an error, many link-layer pro -\ntocols provide a mechanism", "doc_id": "7d5ebe42-eb79-4105-86fa-a76c3891255b", "embedding": null, "doc_hash": "8bf66fa3e1678337a1721282aac400bef748acf0641c75f9c6d6ae7e297afe73", "extra_info": null, "node_info": {"start": 1365420, "end": 1369263}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "3596891d-49a8-4354-8885-be0a0c8488c4", "3": "aa1d26ec-6575-4993-98ed-8df0383ac560"}}, "__type__": "1"}, "aa1d26ec-6575-4993-98ed-8df0383ac560": {"__data__": {"text": "\nprotocol. However, link-layer reliable delivery can be considered an unnecessary \noverhead for low bit-error links, including fiber, coax, and many twisted-pair \ncopper links. For this reason, many wired link-layer protocols do not provide a \nreliable delivery service.\n6.1  \u2022  INTRODUCTION TO THE LINK LAYER      471\n\u2022 Error detection and correction.  The link-layer hardware in a receiving node can incor -\nrectly decide that a bit in a frame is zero when it was transmitted as a one, and vice \nversa. Such bit errors are introduced by signal attenuation and electromagnetic noise. \nBecause there is no need to forward a datagram that has an error, many link-layer pro -\ntocols provide a mechanism to detect such bit errors. This is done by having the trans -\nmitting node include error-detection bits in the frame, and having the receiving node \nperform an error check. Recall from Chapters 3 and 4 that the Internet\u2019s transport layer \nand network layer also provide a limited form of error detection\u2014the Internet check -\nsum. Error detection in the link layer is usually more sophisticated and is implemented \nin hardware. Error correction is similar to error detection, except that a receiver not \nonly detects when bit errors have occurred in the frame but also determines exactly \nwhere in the frame the errors have occurred (and then corrects these errors).\n6.1.2 Where Is the Link Layer Implemented?\nBefore diving into our detailed study of the link layer, let\u2019s conclude this introduction \nby considering the question of where the link layer is implemented. We\u2019ll focus here \non an end system, since we learned in Chapter 4 that the link layer is implemented in \na router\u2019s line card. Is a host\u2019s link layer implemented in hardware or software? Is it \nimplemented on a separate card or chip, and how does it interface with the rest of a \nhost\u2019s hardware and operating system components?\nFigure 6. 2 shows a typical host architecture. For the most part, the link layer is \nimplemented in a network adapter , also sometimes known as a network interface \ncard (NIC) . At the heart of the network adapter is the link-layer controller, usually a \nsingle, special-purpose chip that implements many of the link-layer services (fram -\ning, link access, error detection, and so on). Thus, much of a link-layer controller\u2019s \nfunctionality is implemented in hardware. For example, Intel\u2019s 710 adapter [Intel \n2016] implements the Ethernet protocols we\u2019ll study in Section 6.5; the Atheros \nAR5006 [Atheros 2016] controller implements the 802.11 WiFi protocols we\u2019ll \nstudy in Chapter 7 . Until the late 1990s, most network adapters were physically \nseparate cards (such as a PCMCIA card or a plug-in card fitting into a PC\u2019s PCI \ncard slot) but increasingly, network adapters are being integrated onto the host\u2019s \nmotherboard\u2014a so-called LAN-on-motherboard configuration.\nOn the sending side, the controller takes a datagram that has been created and \nstored in host memory by the higher layers of the protocol stack, encapsulates the \ndatagram in a link-layer frame (filling in the frame\u2019s various fields), and then trans -\nmits the frame into the communication link, following the link-access protocol. On \nthe receiving side, a controller receives the entire frame, and extracts the network-\nlayer datagram. If the link layer performs error detection, then it is the sending con -\ntroller that sets the error-detection bits in the frame header and it is the receiving \ncontroller that performs error detection.\nFigure 6. 2 shows a network adapter attaching to a host\u2019s bus (e.g., a PCI \nor PCI-X bus), where it looks much like any other I/O device to the other host \n472     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\ncomponents.", "doc_id": "aa1d26ec-6575-4993-98ed-8df0383ac560", "embedding": null, "doc_hash": "23a39aec5c0ded5ac9a3fb4724d9cfff48edaf719de7d62492610c47b0ce74ac", "extra_info": null, "node_info": {"start": 1369240, "end": 1372970}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "7d5ebe42-eb79-4105-86fa-a76c3891255b", "3": "2896f16f-0864-4db6-9995-81bc9f2ea82f"}}, "__type__": "1"}, "2896f16f-0864-4db6-9995-81bc9f2ea82f": {"__data__": {"text": "a link-layer frame (filling in the frame\u2019s various fields), and then trans -\nmits the frame into the communication link, following the link-access protocol. On \nthe receiving side, a controller receives the entire frame, and extracts the network-\nlayer datagram. If the link layer performs error detection, then it is the sending con -\ntroller that sets the error-detection bits in the frame header and it is the receiving \ncontroller that performs error detection.\nFigure 6. 2 shows a network adapter attaching to a host\u2019s bus (e.g., a PCI \nor PCI-X bus), where it looks much like any other I/O device to the other host \n472     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\ncomponents. Figure 6.2 also shows that while most of the link layer is imple -\nmented in hardware, part of the link layer is implemented in software that runs \non the host\u2019s CPU. The software components of the link layer implement higher-\nlevel link-layer functionality such as assembling link-layer addressing informa -\ntion and activating the controller hardware. On the receiving side, link-layer \nsoftware responds to controller interrupts (e.g., due to the receipt of one or more \nframes), handling error conditions and passing a datagram up to the network \nlayer. Thus, the link layer is a combination of hardware and software\u2014the place \nin the protocol stack where software meets hardware. [Intel 2016] provides a read -\nable overview (as well as a detailed description) of the XL710 controller from a \nsoftware-programming point of view.\n6.2 Error-Detection and -Correction Techniques\nIn the previous section, we noted that bit-level error detection and correction \u2014\ndetecting and correcting the corruption of bits in a link-layer frame sent from one \nnode to another physically connected neighboring node\u2014are two services often \n provided by the link layer. We saw in Chapter 3 that error-detection and -correction \nservices are also often offered at the transport layer as well. In this section, we\u2019ll Figure 6.2  \u2666  Network adapter: Its relationship to other host components \nand to protocol stack functionalityHost\nMemory\nHost bus\n(e.g., PCI)CPU\nController\nPhysical\ntransmissionNetwork adapterLink\nPhysicalTransport\nNetwork\nLinkApplication\n6.2  \u2022  ERROR-DETECTION AND -CORRECTION TECHNIQUES      473\nexamine a few of the simplest techniques that can be used to detect and, in some \ncases, correct such bit errors. A full treatment of the theory and implementation \nof this topic is itself the topic of many textbooks (for example, [Schwartz 1980] \nor [Bertsekas 1991]), and our treatment here is necessarily brief. Our goal here is \nto develop an intuitive feel for the capabilities that error-detection and -correction \ntechniques provide and to see how a few simple techniques work and are used in \npractice in the link layer.\nFigure 6. 3 illustrates the setting for our study. At the sending node, data, D, to \nbe protected against bit errors is augmented with error-detection and -correction bits \n(EDC ). Typically, the data to be protected includes not only the datagram passed \ndown from the network layer for transmission across the link, but also link-level \naddressing information, sequence numbers, and other fields in the link frame header. \nBoth D and EDC  are sent to the receiving node in a link-level frame. At the receiv -\ning node, a sequence of bits, D\u2032 and EDC\u2032 is received. Note that D\u2032 and EDC\u2032 may \ndiffer from the original D and EDC  as a result of in-transit bit flips.\nThe receiver\u2019s challenge is to determine whether or not D\u2032 is the same as the \noriginal D, given that it has only received D\u2032 and EDC\u2032. The exact wording of the \nreceiver\u2019s decision in Figure 6.3 (we ask whether an error is detected, not whether an \nerror has occurred!) is important. Error-detection and -correction techniques allow \nthe", "doc_id": "2896f16f-0864-4db6-9995-81bc9f2ea82f", "embedding": null, "doc_hash": "b27d73d061e915ca015742751e47581941849d6824be9614b8d9c60835d49581", "extra_info": null, "node_info": {"start": 1372988, "end": 1376804}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "aa1d26ec-6575-4993-98ed-8df0383ac560", "3": "5a95a7c1-a15d-483d-8d49-820908aac6d3"}}, "__type__": "1"}, "5a95a7c1-a15d-483d-8d49-820908aac6d3": {"__data__": {"text": "the link, but also link-level \naddressing information, sequence numbers, and other fields in the link frame header. \nBoth D and EDC  are sent to the receiving node in a link-level frame. At the receiv -\ning node, a sequence of bits, D\u2032 and EDC\u2032 is received. Note that D\u2032 and EDC\u2032 may \ndiffer from the original D and EDC  as a result of in-transit bit flips.\nThe receiver\u2019s challenge is to determine whether or not D\u2032 is the same as the \noriginal D, given that it has only received D\u2032 and EDC\u2032. The exact wording of the \nreceiver\u2019s decision in Figure 6.3 (we ask whether an error is detected, not whether an \nerror has occurred!) is important. Error-detection and -correction techniques allow \nthe receiver to sometimes, but not always , detect that bit errors have occurred. Even \nwith the use of error-detection bits there still may be undetected bit errors ; that is, \nthe receiver may be unaware that the received information contains bit errors. As a \nFigure 6.3  \u2666 Error-detection and -correction scenarioEDC' D'Detected errorDatagram\nEDC Dd data bits\nBit error-prone linkall\nbits in D'\nOK\n?NYDatagram\nHI\n474     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\nconsequence, the receiver might deliver a corrupted datagram to the network layer, \nor be unaware that the contents of a field in the frame\u2019s header has been corrupted. \nWe thus want to choose an error-detection scheme that keeps the probability of such \noccurrences small. Generally, more sophisticated error-detection and-correction \ntechniques (that is, those that have a smaller probability of allowing undetected bit \nerrors) incur a larger overhead\u2014more computation is needed to compute and trans -\nmit a larger number of error-detection and -correction bits.\nLet\u2019s now examine three techniques for detecting errors in the transmitted data\u2014\nparity checks (to illustrate the basic ideas behind error detection and correction), check -\nsumming methods (which are more typically used in the transport layer), and cyclic \nredundancy checks (which are more typically used in the link layer in an adapter).\n6.2.1 Parity Checks\nPerhaps the simplest form of error detection is the use of a single parity bit . Suppose \nthat the information to be sent, D in Figure 6.4, has d bits. In an even parity scheme, \nthe sender simply includes one additional bit and chooses its value such that the total \nnumber of 1s in the d + 1 bits (the original information plus a parity bit) is even. For \nodd parity schemes, the parity bit value is chosen such that there is an odd number \nof 1s. Figure 6.4 illustrates an even parity scheme, with the single parity bit being \nstored in a separate field.\nReceiver operation is also simple with a single parity bit. The receiver need only \ncount the number of 1s in the received d + 1 bits. If an odd number of 1-valued bits \nare found with an even parity scheme, the receiver knows that at least one bit error has \noccurred. More precisely, it knows that some odd number of bit errors have occurred.\nBut what happens if an even number of bit errors occur? You should convince \nyourself that this would result in an undetected error. If the probability of bit errors is \nsmall and errors can be assumed to occur independently from one bit to the next, the \nprobability of multiple bit errors in a packet would be extremely small. In this case, \na single parity bit might suffice. However, measurements have shown that, rather \nthan occurring independently, errors are often clustered together in \u201cbursts.\u201d Under \nburst error conditions, the probability of undetected errors in a frame protected by \nsingle-bit parity can approach 50 percent [Spragins 1991]. Clearly, a more robust \nerror-detection scheme is needed (and, fortunately, is used in practice!). But", "doc_id": "5a95a7c1-a15d-483d-8d49-820908aac6d3", "embedding": null, "doc_hash": "10a385bb816aa8f98b3d729a524c25559bc84ff6efd063e9ca22735e7356012b", "extra_info": null, "node_info": {"start": 1376799, "end": 1380547}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "2896f16f-0864-4db6-9995-81bc9f2ea82f", "3": "89d037c9-f5f5-4781-b530-51581b342e26"}}, "__type__": "1"}, "89d037c9-f5f5-4781-b530-51581b342e26": {"__data__": {"text": "of bit errors have occurred.\nBut what happens if an even number of bit errors occur? You should convince \nyourself that this would result in an undetected error. If the probability of bit errors is \nsmall and errors can be assumed to occur independently from one bit to the next, the \nprobability of multiple bit errors in a packet would be extremely small. In this case, \na single parity bit might suffice. However, measurements have shown that, rather \nthan occurring independently, errors are often clustered together in \u201cbursts.\u201d Under \nburst error conditions, the probability of undetected errors in a frame protected by \nsingle-bit parity can approach 50 percent [Spragins 1991]. Clearly, a more robust \nerror-detection scheme is needed (and, fortunately, is used in practice!). But before \nexamining error-detection schemes that are used in practice, let\u2019s consider a simple \nFigure 6.4  \u2666 One-bit even parity0111000110101011 1d data bitsParity\nbit\n6.2  \u2022  ERROR-DETECTION AND -CORRECTION TECHNIQUES      475\ngeneralization of one-bit parity that will provide us with insight into error-correction \ntechniques.\nFigure 6. 5 shows a two-dimensional generalization of the single-bit parity \nscheme. Here, the d bits in D are divided into i rows and j columns. A parity value \nis computed for each row and for each column. The resulting i + j + 1 parity bits \ncomprise the link-layer frame\u2019s error-detection bits.\nSuppose now that a single bit error occurs in the original d bits of information. \nWith this two-dimensional parity  scheme, the parity of both the column and the row \ncontaining the flipped bit will be in error. The receiver can thus not only detect  the \nfact that a single bit error has occurred, but can use the column and row indices of \nthe column and row with parity errors to actually identify the bit that was corrupted \nand correct  that error! Figure 6.5 shows an example in which the 1-valued bit in \nposition (2,2) is corrupted and switched to a 0\u2014an error that is both detectable and \ncorrectable at the receiver. Although our discussion has focused on the original d bits \nof information, a single error in the parity bits themselves is also detectable and cor -\nrectable. Two-dimensional parity can also detect (but not correct!) any combination \nof two errors in a packet. Other properties of the two-dimensional parity scheme are \nexplored in the problems at the end of the chapter.\nFigure 6.5  \u2666 Two-dimensional even parity1 0 1 0 1 1\n1 1 1 1 0 0\n0 1 1 1 0 1\n0 0 1 0 1 01 0 1 0 1 1\n1 0 1 1 0 0\n0 1 1 1 0 1\n0 0 1 0 1 0Row parity\nParity \nerror\nParity \nerrorNo errors Correctable\nsingle-bit errord1,1\nd2,1\n. . .\ndi,1\ndi+1,1. . .\n. . .\n. . .\n. . .\n. . .d1,j\nd2,j\n. . .\ndi,j\ndi+1,jd1,j+1\nd2,j+1\n. . .\ndi,j+1\ndi+1,j+1Column parity\n476     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\nThe ability of the receiver to both detect and correct errors is known as forward \nerror correction (FEC) . These techniques are commonly used in audio storage and \nplayback devices such as audio CDs. In a network setting, FEC techniques can be \nused by themselves, or in conjunction with link-layer ARQ techniques similar to \nthose we examined in Chapter 3. FEC techniques are valuable because they can \ndecrease the number of sender retransmissions required. Perhaps more important, \nthey allow for immediate correction of errors at the receiver. This avoids having to \nwait for the round-trip propagation delay needed for the sender to receive a NAK \npacket and for the retransmitted packet to", "doc_id": "89d037c9-f5f5-4781-b530-51581b342e26", "embedding": null, "doc_hash": "498a3a83f67effc63d2049cbe896ea356f9076c75c5c74f86cae37ea43eb5a6a", "extra_info": null, "node_info": {"start": 1380457, "end": 1383963}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "5a95a7c1-a15d-483d-8d49-820908aac6d3", "3": "1d2f0838-10cf-4ff5-9292-928cb222873c"}}, "__type__": "1"}, "1d2f0838-10cf-4ff5-9292-928cb222873c": {"__data__": {"text": "parity\n476     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\nThe ability of the receiver to both detect and correct errors is known as forward \nerror correction (FEC) . These techniques are commonly used in audio storage and \nplayback devices such as audio CDs. In a network setting, FEC techniques can be \nused by themselves, or in conjunction with link-layer ARQ techniques similar to \nthose we examined in Chapter 3. FEC techniques are valuable because they can \ndecrease the number of sender retransmissions required. Perhaps more important, \nthey allow for immediate correction of errors at the receiver. This avoids having to \nwait for the round-trip propagation delay needed for the sender to receive a NAK \npacket and for the retransmitted packet to propagate back to the receiver\u2014a poten -\ntially important advantage for real-time network applications [Rubenstein 1998] or \nlinks (such as deep-space links) with long propagation delays. Research examining \nthe use of FEC in error-control protocols includes [Biersack 1992; Nonnenmacher \n1998; Byers 1998; Shacham 1990].\n6.2.2 Checksumming Methods\nIn checksumming techniques, the d bits of data in Figure 6.4 are treated as a sequence \nof k-bit integers. One simple checksumming method is to simply sum these k-bit inte -\ngers and use the resulting sum as the error-detection bits. The Internet checksum  is \nbased on this approach\u2014bytes of data are treated as 16-bit integers and summed. The \n1s complement of this sum then forms the Internet checksum that is carried in the \nsegment header. As discussed in Section 3.3, the receiver checks the checksum by \ntaking the 1s complement of the sum of the received data (including the checksum) \nand checking whether the result is all 1 bits. If any of the bits are 0, an error is indi -\ncated. RFC 1071 discusses the Internet checksum algorithm and its implementation \nin detail. In the TCP and UDP protocols, the Internet checksum is computed over all \nfields (header and data fields included). In IP the checksum is computed over the IP \nheader (since the UDP or TCP segment has its own checksum). In other protocols, \nfor example, XTP [Strayer 1992], one checksum is computed over the header and \nanother checksum is computed over the entire packet.\nChecksumming methods require relatively little packet overhead. For example, \nthe checksums in TCP and UDP use only 16 bits. However, they provide relatively \nweak protection against errors as compared with cyclic redundancy check, which is \ndiscussed below and which is often used in the link layer. A natural question at this \npoint is, Why is checksumming used at the transport layer and cyclic redundancy \ncheck used at the link layer? Recall that the transport layer is typically implemented \nin software in a host as part of the host\u2019s operating system. Because transport-layer \nerror detection is implemented in software, it is important to have a simple and fast \nerror-detection scheme such as checksumming. On the other hand, error detection at \nthe link layer is implemented in dedicated hardware in adapters, which can rapidly \nperform the more complex CRC operations. Feldmeier [Feldmeier 1995] presents \nfast software implementation techniques for not only weighted checksum codes, but \nCRC (see below) and other codes as well.\n6.2  \u2022  ERROR-DETECTION AND -CORRECTION TECHNIQUES      477\n6.2.3 Cyclic Redundancy Check (CRC)\nAn error-detection technique used widely in today\u2019s computer networks is based on \ncyclic redundancy check (CRC) codes . CRC codes are also known as polynomial \ncodes , since it is possible to view the bit string to be sent as a polynomial whose \ncoefficients are the 0 and 1 values in the bit string, with operations on the bit string \ninterpreted as polynomial arithmetic.\nCRC codes operate as follows. Consider the d-bit piece", "doc_id": "1d2f0838-10cf-4ff5-9292-928cb222873c", "embedding": null, "doc_hash": "c43e4d225058ee50d0cf5c22247c25e3ea67c6b65daed7d0f2a5f1791d994b4b", "extra_info": null, "node_info": {"start": 1384001, "end": 1387822}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "89d037c9-f5f5-4781-b530-51581b342e26", "3": "34aaffd4-86b3-4456-ab7b-9ae1d263e9c4"}}, "__type__": "1"}, "34aaffd4-86b3-4456-ab7b-9ae1d263e9c4": {"__data__": {"text": "Feldmeier [Feldmeier 1995] presents \nfast software implementation techniques for not only weighted checksum codes, but \nCRC (see below) and other codes as well.\n6.2  \u2022  ERROR-DETECTION AND -CORRECTION TECHNIQUES      477\n6.2.3 Cyclic Redundancy Check (CRC)\nAn error-detection technique used widely in today\u2019s computer networks is based on \ncyclic redundancy check (CRC) codes . CRC codes are also known as polynomial \ncodes , since it is possible to view the bit string to be sent as a polynomial whose \ncoefficients are the 0 and 1 values in the bit string, with operations on the bit string \ninterpreted as polynomial arithmetic.\nCRC codes operate as follows. Consider the d-bit piece of data, D, that the send -\ning node wants to send to the receiving node. The sender and receiver must first \nagree on an r + 1 bit pattern, known as a generator , which we will denote as G. \nWe will require that the most significant (leftmost) bit of G be a 1. The key idea \nbehind CRC codes is shown in Figure 6.6. For a given piece of data, D, the sender \nwill choose r additional bits, R, and append them to D such that the resulting d + r  \nbit pattern (interpreted as a binary number) is exactly divisible by G (i.e., has no \nremainder) using modulo-2 arithmetic. The process of error checking with CRCs is \nthus simple: The receiver divides the d + r received bits by G. If the remainder is \nnonzero, the receiver knows that an error has occurred; otherwise the data is accepted \nas being correct.\nAll CRC calculations are done in modulo-2 arithmetic without carries in addi -\ntion or borrows in subtraction. This means that addition and subtraction are identical, \nand both are equivalent to the bitwise exclusive-or (XOR) of the operands. Thus, for \nexample,\n1011 XOR 0101 = 1110\n1001 XOR 1101 = 0100\nAlso, we similarly have\n1011 - 0101 = 1110\n1001 - 1101 = 0100\nMultiplication and division are the same as in base-2 arithmetic, except that any \nrequired addition or subtraction is done without carries or borrows. As in regular \nFigure 6.6  \u2666 CRCd bits r bits\nD: Data bits to be sent\nD \u2022 2r  XOR    RR: CRC bits Bit pattern\nMathematical formula\n478     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\nbinary arithmetic, multiplication by 2k left shifts a bit pattern by k places. Thus, given \nD and R, the quantity D # 2r XOR R yields the d + r bit pattern shown in Figure 6.6. \nWe\u2019ll use this algebraic characterization of the d + r bit pattern from Figure 6.6 in \nour discussion below.\nLet us now turn to the crucial question of how the sender computes R. Recall \nthat we want to find R such that there is an n such that\nD # 2r XOR R=nG\nThat is, we want to choose R such that G divides into D # 2r XOR R without \nremainder. If we XOR (that is, add modulo-2, without carry) R to both sides of the \nabove equation, we get\nD # 2r=nG XOR R\nThis equation tells us that if we divide D # 2r by G, the value of the remainder \nis precisely R. In other words, we can calculate R as\nR=remainder D#2r\nG\nFigure 6. 7 illustrates this calculation for the case of D=101110, d=6, \nG=1001,  and r=3. The 9 bits transmitted in this case are 101 110  011. \nYou should check these calculations for yourself and also check that indeed \nD # 2r=101011 # G XOR R.\nFigure 6.7  \u2666 A sample CRC calculation1 0 0 11  0 1 1 1 0 0 0 01 0 1 0 1", "doc_id": "34aaffd4-86b3-4456-ab7b-9ae1d263e9c4", "embedding": null, "doc_hash": "bab3014c9ff09d5e3dece529fadd978aebdae08383dd89f120b62a3e821dcbd5", "extra_info": null, "node_info": {"start": 1387875, "end": 1391178}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "1d2f0838-10cf-4ff5-9292-928cb222873c", "3": "63aa74c1-fd83-4623-94c0-ee61c1fe7075"}}, "__type__": "1"}, "63aa74c1-fd83-4623-94c0-ee61c1fe7075": {"__data__": {"text": "add modulo-2, without carry) R to both sides of the \nabove equation, we get\nD # 2r=nG XOR R\nThis equation tells us that if we divide D # 2r by G, the value of the remainder \nis precisely R. In other words, we can calculate R as\nR=remainder D#2r\nG\nFigure 6. 7 illustrates this calculation for the case of D=101110, d=6, \nG=1001,  and r=3. The 9 bits transmitted in this case are 101 110  011. \nYou should check these calculations for yourself and also check that indeed \nD # 2r=101011 # G XOR R.\nFigure 6.7  \u2666 A sample CRC calculation1 0 0 11  0 1 1 1 0 0 0 01 0 1 0 1 1 \n1 0 0 1 \n1 0 1\n0 0 0\n1 0 1 0\n1 0 0 1\n1 1 0\n0 0 0\n1 1 0 0\n1 0 0 1\n1 0 1 0\n1 0 0 1\n 0 1 1G\nD\nR\n6.3  \u2022  MULTIPLE ACCESS LINKS AND PROTOCOLS      479\nInternational standards have been defined for 8-, 12-, 16-, and 32-bit generators, \nG. The CRC-32 32-bit standard, which has been adopted in a number of link-level \nIEEE protocols, uses a generator of\nGCRC@32=100000100110000010001110110110111\nEach of the CRC standards can detect burst errors of fewer than r + 1 bits. (This \nmeans that all consecutive bit errors of r bits or fewer will be detected.) Furthermore, \nunder appropriate assumptions, a burst of length greater than r + 1 bits is detected \nwith probability 1-0.5r. Also, each of the CRC standards can detect any odd num -\nber of bit errors. See [Williams 1993] for a discussion of implementing CRC checks. \nThe theory behind CRC codes and even more powerful codes is beyond the scope of \nthis text. The text [Schwartz 1980] provides an excellent introduction to this topic.\n6.3 Multiple Access Links and Protocols\nIn the introduction to this chapter, we noted that there are two types of network links: \npoint-to-point links and broadcast links. A point-to-point link  consists of a single \nsender at one end of the link and a single receiver at the other end of the link. Many \nlink-layer protocols have been designed for point-to-point links; the point-to-point \nprotocol (PPP) and high-level data link control (HDLC) are two such protocols. The \nsecond type of link, a broadcast link , can have multiple sending and receiving nodes \nall connected to the same, single, shared broadcast channel. The term broadcast  is \nused here because when any one node transmits a frame, the channel broadcasts the \nframe and each of the other nodes receives a copy. Ethernet and wireless LANs are \nexamples of broadcast link-layer technologies. In this section we\u2019ll take a step back \nfrom specific link-layer protocols and first examine a problem of central importance \nto the link layer: how to coordinate the access of multiple sending and receiving \nnodes to a shared broadcast channel\u2014the multiple access problem . Broadcast chan -\nnels are often used in LANs, networks that are geographically concentrated in a \nsingle building (or on a corporate or university campus). Thus, we\u2019ll look at how \nmultiple access channels are used in LANs at the end of this section.\nWe are all familiar with the notion of broadcasting\u2014television has been using it \nsince its invention. But traditional television is a one-way broadcast (that is, one fixed \nnode transmitting to many receiving nodes), while nodes on a computer network \nbroadcast channel can both send and receive. Perhaps a more apt human analogy for \na broadcast channel is a cocktail party, where many people gather in a large room \n(the air providing the broadcast medium) to talk and listen. A second good analogy is \nsomething many readers will be familiar with\u2014a classroom\u2014where", "doc_id": "63aa74c1-fd83-4623-94c0-ee61c1fe7075", "embedding": null, "doc_hash": "8d99c1cc579d28cd67ed85e3cca35b6b5920521896f5131a82b06a69a23e8c0a", "extra_info": null, "node_info": {"start": 1391303, "end": 1394810}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "34aaffd4-86b3-4456-ab7b-9ae1d263e9c4", "3": "bdf2ef05-21a3-4ef3-8c3c-5e36294a17fb"}}, "__type__": "1"}, "bdf2ef05-21a3-4ef3-8c3c-5e36294a17fb": {"__data__": {"text": "are often used in LANs, networks that are geographically concentrated in a \nsingle building (or on a corporate or university campus). Thus, we\u2019ll look at how \nmultiple access channels are used in LANs at the end of this section.\nWe are all familiar with the notion of broadcasting\u2014television has been using it \nsince its invention. But traditional television is a one-way broadcast (that is, one fixed \nnode transmitting to many receiving nodes), while nodes on a computer network \nbroadcast channel can both send and receive. Perhaps a more apt human analogy for \na broadcast channel is a cocktail party, where many people gather in a large room \n(the air providing the broadcast medium) to talk and listen. A second good analogy is \nsomething many readers will be familiar with\u2014a classroom\u2014where teacher(s) and \nstudent(s) similarly share the same, single, broadcast medium. A central problem in \n480     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\nboth scenarios is that of determining who gets to talk (that is, transmit into the chan -\nnel) and when. As humans, we\u2019ve evolved an elaborate set of protocols for sharing \nthe broadcast channel:\n\u201cGive everyone a chance to speak.\u201d\n\u201cDon\u2019t speak until you are spoken to.\u201d\n\u201cDon\u2019t monopolize the conversation.\u201d\n\u201cRaise your hand if you have a question.\u201d\n\u201cDon\u2019t interrupt when someone is speaking.\u201d\n\u201cDon\u2019t fall asleep when someone is talking.\u201d\nComputer networks similarly have protocols\u2014so-called multiple access \n protocols \u2014by which nodes regulate their transmission into the shared broadcast \nchannel. As shown in Figure 6.8, multiple access protocols are needed in a wide \nvariety of network settings, including both wired and wireless access networks, and \nsatellite networks. Although technically each node accesses the broadcast chan -\nnel through its adapter, in this section we will refer to the node  as the sending and \nFigure 6.8  \u2666 Various multiple access channelsShar ed wir e\n(for example, cable access network)Shar ed wir eless\n(for example, WiFi)\nSatellite Cocktail partyHead\nend\n6.3  \u2022  MULTIPLE ACCESS LINKS AND PROTOCOLS      481\nreceiving device. In practice, hundreds or even thousands of nodes can directly com -\nmunicate over a broadcast channel.\nBecause all nodes are capable of transmitting frames, more than two nodes can \ntransmit frames at the same time. When this happens, all of the nodes receive multiple \nframes at the same time; that is, the transmitted frames collide  at all of the receiv -\ners. Typically, when there is a collision, none of the receiving nodes can make any \nsense of any of the frames that were transmitted; in a sense, the signals of the col -\nliding frames become inextricably tangled together. Thus, all the frames involved in \nthe collision are lost, and the broadcast channel is wasted during the collision inter -\nval. Clearly, if many nodes want to transmit frames frequently, many transmissions \nwill result in collisions, and much of the bandwidth of the broadcast channel will be \nwasted.\nIn order to ensure that the broadcast channel performs useful work when mul -\ntiple nodes are active, it is necessary to somehow coordinate the transmissions of \nthe active nodes. This coordination job is the responsibility of the multiple access \nprotocol. Over the past 40 years, thousands of papers and hundreds of PhD disserta -\ntions have been written on multiple access protocols; a comprehensive survey of the \nfirst 20 years of this body of work is [Rom 1990]. Furthermore, active research in \nmultiple access protocols continues due to the continued emergence of new types of \nlinks, particularly new wireless links.\nOver the years, dozens of multiple access protocols have been implemented in \na variety of link-layer technologies. Nevertheless, we can classify just about any \nmultiple access protocol as", "doc_id": "bdf2ef05-21a3-4ef3-8c3c-5e36294a17fb", "embedding": null, "doc_hash": "95ccda34c473611bbb35864c0d054a0e3f8bee4bf0a1f321766ad41d40d2178c", "extra_info": null, "node_info": {"start": 1394594, "end": 1398404}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "63aa74c1-fd83-4623-94c0-ee61c1fe7075", "3": "8db403b9-e197-4bf0-ae12-853933f3ca27"}}, "__type__": "1"}, "8db403b9-e197-4bf0-ae12-853933f3ca27": {"__data__": {"text": "order to ensure that the broadcast channel performs useful work when mul -\ntiple nodes are active, it is necessary to somehow coordinate the transmissions of \nthe active nodes. This coordination job is the responsibility of the multiple access \nprotocol. Over the past 40 years, thousands of papers and hundreds of PhD disserta -\ntions have been written on multiple access protocols; a comprehensive survey of the \nfirst 20 years of this body of work is [Rom 1990]. Furthermore, active research in \nmultiple access protocols continues due to the continued emergence of new types of \nlinks, particularly new wireless links.\nOver the years, dozens of multiple access protocols have been implemented in \na variety of link-layer technologies. Nevertheless, we can classify just about any \nmultiple access protocol as belonging to one of three categories: channel partition -\ning protocols , random access protocols , and taking-turns protocols . We\u2019ll cover \nthese categories of multiple access protocols in the following three subsections.\nLet\u2019s conclude this overview by noting that, ideally, a multiple access protocol \nfor a broadcast channel of rate R bits per second should have the following desirable \ncharacteristics:\n 1. When only one node has data to send, that node has a throughput of R bps.\n 2. When M nodes have data to send, each of these nodes has a throughput of R/M \nbps. This need not necessarily imply that each of the M nodes always has an \ninstantaneous rate of R/M, but rather that each node should have an average \ntransmission rate of R/M over some suitably defined interval of time.\n 3. The protocol is decentralized; that is, there is no master node that represents a \nsingle point of failure for the network.\n 4. The protocol is simple, so that it is inexpensive to implement.\n6.3.1 Channel Partitioning Protocols\nRecall from our early discussion back in Section 1.3 that time -division  multiplexing \n(TDM) and frequency-division multiplexing (FDM) are two techniques that can \n482     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\nbe used to partition a broadcast channel\u2019s bandwidth among all nodes sharing that \nchannel. As an example, suppose the channel supports N nodes and that the trans -\nmission rate of the channel is R bps. TDM divides time into time frames  and further \ndivides each time frame into N time slots . (The TDM time frame should not be \nconfused with the link-layer unit of data exchanged between sending and receiving \nadapters, which is also called a frame. In order to reduce confusion, in this subsec -\ntion we\u2019ll refer to the link-layer unit of data exchanged as a packet.) Each time slot \nis then assigned to one of the N nodes. Whenever a node has a packet to send, it \ntransmits the packet\u2019s bits during its assigned time slot in the revolving TDM frame. \nTypically, slot sizes are chosen so that a single packet can be transmitted during a \nslot time. Figure 6.9 shows a simple four-node TDM example. Returning to our \ncocktail party analogy, a TDM-regulated cocktail party would allow one partygoer \nto speak for a fixed period of time, then allow another partygoer to speak for the \nsame amount of time, and so on. Once everyone had had a chance to talk, the  pattern \nwould repeat.\nTDM is appealing because it eliminates collisions and is perfectly fair: Each \nnode gets a dedicated transmission rate of R/N bps during each frame time. However, \nit has two major drawbacks. First, a node is limited to an average rate of R/N bps \neven when it is the only node with packets to send. A second drawback is that a node \nmust always wait for its turn in the transmission sequence\u2014again, even when it is \nthe only node with a frame to send. Imagine the partygoer who is the only one with \nanything to say (and imagine that this is the even rarer circumstance where everyone Figure 6.9  \u2666 A four-node TDM and FDM", "doc_id": "8db403b9-e197-4bf0-ae12-853933f3ca27", "embedding": null, "doc_hash": "ad4a6e3518892ec6560db03e00eb12e1f2247226451d6c61d063879bc79c4a70", "extra_info": null, "node_info": {"start": 1398386, "end": 1402249}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "bdf2ef05-21a3-4ef3-8c3c-5e36294a17fb", "3": "79864a9f-fd5d-43ad-80e7-64cdc93b1eef"}}, "__type__": "1"}, "79864a9f-fd5d-43ad-80e7-64cdc93b1eef": {"__data__": {"text": "time, then allow another partygoer to speak for the \nsame amount of time, and so on. Once everyone had had a chance to talk, the  pattern \nwould repeat.\nTDM is appealing because it eliminates collisions and is perfectly fair: Each \nnode gets a dedicated transmission rate of R/N bps during each frame time. However, \nit has two major drawbacks. First, a node is limited to an average rate of R/N bps \neven when it is the only node with packets to send. A second drawback is that a node \nmust always wait for its turn in the transmission sequence\u2014again, even when it is \nthe only node with a frame to send. Imagine the partygoer who is the only one with \nanything to say (and imagine that this is the even rarer circumstance where everyone Figure 6.9  \u2666 A four-node TDM and FDM example4KHzFDM\nTDMLink\n4KHz\nSlot\nAll slots labeled \u201c2\u201d are dedicated\nto a speci\ufb01c sender -receiver pair .Frame1\n223 41 234 12 34 12 34\nKey:\n6.3  \u2022  MULTIPLE ACCESS LINKS AND PROTOCOLS      483\nwants to hear what that one person has to say). Clearly, TDM would be a poor choice \nfor a multiple access protocol for this particular party.\nWhile TDM shares the broadcast channel in time, FDM divides the R bps chan -\nnel into different frequencies (each with a bandwidth of R/N) and assigns each fre -\nquency to one of the N nodes. FDM thus creates N smaller channels of R/N bps out \nof the single, larger R bps channel. FDM shares both the advantages and drawbacks \nof TDM. It avoids collisions and divides the bandwidth fairly among the N nodes. \nHowever, FDM also shares a principal disadvantage with TDM\u2014a node is limited to \na bandwidth of R/N, even when it is the only node with packets to send.\nA third channel partitioning protocol is code division multiple access \n(CDMA) . While TDM and FDM assign time slots and frequencies, respectively, \nto the nodes, CDMA assigns a different code  to each node. Each node then uses \nits unique code to encode the data bits it sends. If the codes are chosen carefully, \nCDMA networks have the wonderful property that different nodes can transmit \nsimultaneously  and yet have their respective receivers correctly receive a send -\ner\u2019s encoded data bits (assuming the receiver knows the sender\u2019s code) in spite \nof interfering transmissions by other nodes. CDMA has been used in military \nsystems for some time (due to its anti-jamming properties) and now has wide -\nspread civilian use, particularly in cellular telephony. Because CDMA\u2019s use is so \ntightly tied to wireless channels, we\u2019ll save our discussion of the technical details \nof CDMA until Chapter 7. For now, it will suffice to know that CDMA codes, \nlike time slots in TDM and frequencies in FDM, can be allocated to the multiple \naccess channel users.\n6.3.2 Random Access Protocols\nThe second broad class of multiple access protocols are random access protocols. \nIn a random access protocol, a transmitting node always transmits at the full rate \nof the channel, namely, R bps. When there is a collision, each node involved in the \ncollision repeatedly retransmits its frame (that is, packet) until its frame gets through \nwithout a collision. But when a node experiences a collision, it doesn\u2019t necessarily \nretransmit the frame right away. Instead it waits a random delay before retrans -\nmitting the frame . Each node involved in a collision chooses independent random \ndelays. Because the random delays are independently chosen, it is possible that one \nof the nodes will pick a delay that is sufficiently less than the delays of the other col -\nliding nodes and will therefore be able to sneak its frame into the channel without a \ncollision.\nThere are dozens if not hundreds of random access protocols described in the \nliterature [Rom 1990;", "doc_id": "79864a9f-fd5d-43ad-80e7-64cdc93b1eef", "embedding": null, "doc_hash": "488546ab28c9c59cb0b3062f8baa26e1883f3b620f4984dfdba51326fe0752fa", "extra_info": null, "node_info": {"start": 1402304, "end": 1406035}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "8db403b9-e197-4bf0-ae12-853933f3ca27", "3": "3f403ce9-c6d8-45c2-969d-861f5ffc401d"}}, "__type__": "1"}, "3f403ce9-c6d8-45c2-969d-861f5ffc401d": {"__data__": {"text": "the channel, namely, R bps. When there is a collision, each node involved in the \ncollision repeatedly retransmits its frame (that is, packet) until its frame gets through \nwithout a collision. But when a node experiences a collision, it doesn\u2019t necessarily \nretransmit the frame right away. Instead it waits a random delay before retrans -\nmitting the frame . Each node involved in a collision chooses independent random \ndelays. Because the random delays are independently chosen, it is possible that one \nof the nodes will pick a delay that is sufficiently less than the delays of the other col -\nliding nodes and will therefore be able to sneak its frame into the channel without a \ncollision.\nThere are dozens if not hundreds of random access protocols described in the \nliterature [Rom 1990; Bertsekas 1991]. In this section we\u2019ll describe a few of the \nmost commonly used random access protocols\u2014the ALOHA protocols [Abram -\nson 1970; Abramson 1985; Abramson 2009] and the carrier sense multiple access \n(CSMA) protocols [Kleinrock 1975b]. Ethernet [Metcalfe 1976] is a popular and \nwidely deployed CSMA protocol.\n484     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\nSlotted ALOHA\nLet\u2019s begin our study of random access protocols with one of the simplest random \naccess protocols, the slotted ALOHA protocol. In our description of slotted ALOHA, \nwe assume the following:\n\u2022 All frames consist of exactly L bits.\n\u2022 Time is divided into slots of size L/R seconds (that is, a slot equals the time to \ntransmit one frame).\n\u2022 Nodes start to transmit frames only at the beginnings of slots.\n\u2022 The nodes are synchronized so that each node knows when the slots begin.\n\u2022 If two or more frames collide in a slot, then all the nodes detect the collision event \nbefore the slot ends.\nLet p be a probability, that is, a number between 0 and 1. The operation of slotted \nALOHA in each node is simple:\n\u2022 When the node has a fresh frame to send, it waits until the beginning of the next \nslot and transmits the entire frame in the slot.\n\u2022 If there isn\u2019t a collision, the node has successfully transmitted its frame and thus \nneed not consider retransmitting the frame. (The node can prepare a new frame \nfor transmission, if it has one.)\n\u2022 If there is a collision, the node detects the collision before the end of the slot. The \nnode retransmits its frame in each subsequent slot with probability p until the \nframe is transmitted without a collision.\nBy retransmitting with probability p, we mean that the node effectively tosses \na biased coin; the event heads corresponds to \u201cretransmit,\u201d which occurs with prob -\nability p. The event tails corresponds to \u201cskip the slot and toss the coin again in the \nnext slot\u201d; this occurs with probability (1-p). All nodes involved in the collision \ntoss their coins independently.\nSlotted ALOHA would appear to have many advantages. Unlike channel par -\ntitioning, slotted ALOHA allows a node to transmit continuously at the full rate, R, \nwhen that node is the only active node. (A node is said to be active if it has frames \nto send.) Slotted ALOHA is also highly decentralized, because each node detects \ncollisions and independently decides when to retransmit. (Slotted ALOHA does, \nhowever, require the slots to be synchronized in the nodes; shortly we\u2019ll discuss \nan unslotted version of the ALOHA protocol, as well as CSMA protocols, none of \nwhich require such synchronization.) Slotted ALOHA is also an extremely simple \nprotocol.\nSlotted ALOHA works well when there is only one active node, but how \n efficient is it when there are multiple active nodes? There are two possible efficiency \n6.3  \u2022  MULTIPLE ACCESS LINKS AND", "doc_id": "3f403ce9-c6d8-45c2-969d-861f5ffc401d", "embedding": null, "doc_hash": "f66be99be64738b117fd782947bb81f7cb5a79e3397047550c59c4f8af1a16b5", "extra_info": null, "node_info": {"start": 1406002, "end": 1409664}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "79864a9f-fd5d-43ad-80e7-64cdc93b1eef", "3": "628e8be5-cc12-408d-b5b0-82f20cf163ae"}}, "__type__": "1"}, "628e8be5-cc12-408d-b5b0-82f20cf163ae": {"__data__": {"text": "the full rate, R, \nwhen that node is the only active node. (A node is said to be active if it has frames \nto send.) Slotted ALOHA is also highly decentralized, because each node detects \ncollisions and independently decides when to retransmit. (Slotted ALOHA does, \nhowever, require the slots to be synchronized in the nodes; shortly we\u2019ll discuss \nan unslotted version of the ALOHA protocol, as well as CSMA protocols, none of \nwhich require such synchronization.) Slotted ALOHA is also an extremely simple \nprotocol.\nSlotted ALOHA works well when there is only one active node, but how \n efficient is it when there are multiple active nodes? There are two possible efficiency \n6.3  \u2022  MULTIPLE ACCESS LINKS AND PROTOCOLS      485\nconcerns here. First, as shown in Figure 6.10, when there are multiple active nodes, \na certain fraction of the slots will have collisions and will therefore be \u201cwasted.\u201d The \nsecond concern is that another fraction of the slots will be empty  because all active \nnodes refrain from transmitting as a result of the probabilistic transmission policy. \nThe only \u201cunwasted\u201d slots will be those in which exactly one node transmits. A slot \nin which exactly one node transmits is said to be a successful slot . The efficiency  of \na slotted multiple access protocol is defined to be the long-run fraction of successful \nslots in the case when there are a large number of active nodes, each always having \na large number of frames to send. Note that if no form of access control were used, \nand each node were to immediately retransmit after each collision, the efficiency \nwould be zero. Slotted ALOHA clearly increases the efficiency beyond zero, but by \nhow much?\nWe now proceed to outline the derivation of the maximum efficiency of slotted \nALOHA. To keep this derivation simple, let\u2019s modify the protocol a little and assume \nthat each node attempts to transmit a frame in each slot with probability p. (That is, \nwe assume that each node always has a frame to send and that the node transmits \nwith probability p for a fresh frame as well as for a frame that has already suffered a \ncollision.) Suppose there are N nodes. Then the probability that a given slot is a suc -\ncessful slot is the probability that one of the nodes transmits and that the remaining \nN-1 nodes do not transmit. The probability that a given node transmits is p; the \nprobability that the remaining nodes do not transmit is (1-p)N-1. Therefore the \nprobability a given node has a success is p(1-p)N-1. Because there are N nodes, \nthe probability that any one of the N nodes has a success is Np(1-p)N-1.Figure 6.10  \u2666  Nodes 1, 2, and 3 collide in the first slot. Node 2 finally \nsucceeds in the fourth slot, node 1 in the eighth slot, and \nnode 3 in the ninth slotNode 3\nKey:\nC = Collision slot\nE = Empty slot\nS = Successful slotNode 2Node 1\n2 2 21 1 1 1\n3 3 3\nTime\nCE CS EC ES S\n486     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\nThus, when there are N active nodes, the efficiency of slotted ALOHA is \nNp(1-p)N-1. To obtain the maximum  efficiency for N active nodes, we have to find the \np* that maximizes this expression. (See the homework problems for a general outline of  \nthis derivation.) And to obtain the maximum efficiency for a large number of active \nnodes, we take the limit of Np*(1-p*)N-1 as N approaches infinity. (Again, see the \nhomework problems.) After performing these calculations, we\u2019ll find that the maximum \nefficiency of the protocol is given by 1/ e = 0.37. That is, when a large number of nodes \nhave many frames to transmit, then", "doc_id": "628e8be5-cc12-408d-b5b0-82f20cf163ae", "embedding": null, "doc_hash": "d41ab0f23f67dbc2c777f6e27b6d3e23c31e515ff25f5f6d4ccb6b48372e19af", "extra_info": null, "node_info": {"start": 1409739, "end": 1413304}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "3f403ce9-c6d8-45c2-969d-861f5ffc401d", "3": "98dc066d-17be-4a7f-9348-6f5b3bef01ee"}}, "__type__": "1"}, "98dc066d-17be-4a7f-9348-6f5b3bef01ee": {"__data__": {"text": "6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\nThus, when there are N active nodes, the efficiency of slotted ALOHA is \nNp(1-p)N-1. To obtain the maximum  efficiency for N active nodes, we have to find the \np* that maximizes this expression. (See the homework problems for a general outline of  \nthis derivation.) And to obtain the maximum efficiency for a large number of active \nnodes, we take the limit of Np*(1-p*)N-1 as N approaches infinity. (Again, see the \nhomework problems.) After performing these calculations, we\u2019ll find that the maximum \nefficiency of the protocol is given by 1/ e = 0.37. That is, when a large number of nodes \nhave many frames to transmit, then (at best) only 37 percent of the slots do useful work. \nThus the effective transmission rate of the channel is not R bps but only 0.37 R bps! \nA similar analysis also shows that 37 percent of the slots go empty and 26 percent \nof slots have collisions. Imagine the poor network administrator who has purchased a \n100-Mbps slotted ALOHA system, expecting to be able to use the network to transmit \ndata among a large number of users at an aggregate rate of, say, 80 Mbps! Although the \nchannel is capable of transmitting a given frame at the full channel rate of 100 Mbps, in \nthe long run, the successful throughput of this channel will be less than 37 Mbps.\nALOHA\nThe slotted ALOHA protocol required that all nodes synchronize their transmissions \nto start at the beginning of a slot. The first ALOHA protocol [Abramson 1970] was \nactually an unslotted, fully decentralized protocol. In pure ALOHA, when a frame \nfirst arrives (that is, a network-layer datagram is passed down from the network layer \nat the sending node), the node immediately transmits the frame in its entirety into the \nbroadcast channel. If a transmitted frame experiences a collision with one or more \nother transmissions, the node will then immediately (after completely transmitting \nits collided frame) retransmit the frame with probability p. Otherwise, the node waits \nfor a frame transmission time. After this wait, it then transmits the frame with prob -\nability p, or waits (remaining idle) for another frame time with probability 1 \u2013 p.\nTo determine the maximum efficiency of pure ALOHA, we focus on an individual \nnode. We\u2019ll make the same assumptions as in our slotted ALOHA analysis and take the \nframe transmission time to be the unit of time. At any given time, the probability that a \nnode is transmitting a frame is p. Suppose this frame begins transmission at time t0. As \nshown in Figure 6.11, in order for this frame to be successfully transmitted, no other \nnodes can begin their transmission in the interval of time [t0-1, t0]. Such a transmis -\nsion would overlap with the beginning of the transmission of node i\u2019s frame. The prob -\nability that all other nodes do not begin a transmission in this interval is (1-p)N-1. \nSimilarly, no other node can begin a transmission while node i is transmitting, as such a \ntransmission would overlap with the latter part of node i\u2019s transmission. The probabil -\nity that all other nodes do not begin a transmission in this interval is also (1-p)N-1. \nThus, the probability that a given node has a successful transmission is p(1-p)2(N-1).  \nBy taking limits as in the slotted ALOHA case, we find that the maximum efficiency \nof the pure ALOHA protocol is only 1/(2 e)\u2014exactly half that of slotted ALOHA. This \nthen is the price to be paid for a fully decentralized ALOHA protocol.\n6.3  \u2022  MULTIPLE ACCESS LINKS AND PROTOCOLS      487\nCarrier Sense Multiple Access (CSMA)\nIn both slotted and pure ALOHA, a node\u2019s decision to transmit is made indepen -\ndently of the activity of the other", "doc_id": "98dc066d-17be-4a7f-9348-6f5b3bef01ee", "embedding": null, "doc_hash": "abe5267613c7dfbd57fe4baad361e7c37820ae71f3747703f9b9926e1fd29433", "extra_info": null, "node_info": {"start": 1413351, "end": 1417033}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "628e8be5-cc12-408d-b5b0-82f20cf163ae", "3": "3e3440a0-c744-4119-8e95-8c75db02eda7"}}, "__type__": "1"}, "3e3440a0-c744-4119-8e95-8c75db02eda7": {"__data__": {"text": "that all other nodes do not begin a transmission in this interval is also (1-p)N-1. \nThus, the probability that a given node has a successful transmission is p(1-p)2(N-1).  \nBy taking limits as in the slotted ALOHA case, we find that the maximum efficiency \nof the pure ALOHA protocol is only 1/(2 e)\u2014exactly half that of slotted ALOHA. This \nthen is the price to be paid for a fully decentralized ALOHA protocol.\n6.3  \u2022  MULTIPLE ACCESS LINKS AND PROTOCOLS      487\nCarrier Sense Multiple Access (CSMA)\nIn both slotted and pure ALOHA, a node\u2019s decision to transmit is made indepen -\ndently of the activity of the other nodes attached to the broadcast channel. In particu -\nlar, a node neither pays attention to whether another node happens to be transmitting \nwhen it begins to transmit, nor stops transmitting if another node begins to interfere \nwith its transmission. In our cocktail party analogy, ALOHA protocols are quite \nlike a boorish partygoer who continues to chatter away regardless of whether other \npeople are talking. As humans, we have human protocols that allow us not only to \nbehave with more civility, but also to decrease the amount of time spent \u201ccolliding\u201d \nwith each other in conversation and, consequently, to increase the amount of data we \nexchange in our conversations. Specifically, there are two important rules for polite \nhuman conversation:\n\u2022 Listen before speaking.  If someone else is speaking, wait until they are finished. \nIn the networking world, this is called carrier sensing \u2014a node listens to the \nchannel before transmitting. If a frame from another node is currently being trans -\nmitted into the channel, a node then waits until it detects no transmissions for a \nshort amount of time and then begins transmission.\n\u2022 If someone else begins talking at the same time, stop talking.  In the network -\ning world, this is called collision detection \u2014a transmitting node listens to the \nchannel while it is transmitting. If it detects that another node is transmitting an \ninterfering frame, it stops transmitting and waits a random amount of time before \nrepeating the sense-and-transmit-when-idle cycle.\nThese two rules are embodied in the family of carrier sense multiple access \n(CSMA)  and CSMA with collision detection (CSMA/CD)  protocols [Kleinrock \n1975b; Metcalfe 1976; Lam 1980; Rom 1990]. Many variations on CSMA and Figure 6.11  \u2666 Interfering transmissions in pure ALOHATimeWill overlap\nwith start of \ni\u2019s frame\nt0 \u2013 1 t0 t0 + 1Will overlap\nwith end of \ni\u2019s frame\nNode i frame\n488     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\nCSMA/CD have been proposed. Here, we\u2019ll consider a few of the most important, \nand fundamental, characteristics of CSMA and CSMA/CD.\nThe first question that you might ask about CSMA is why, if all nodes perform \ncarrier sensing, do collisions occur in the first place? After all, a node will refrain \nfrom transmitting whenever it senses that another node is transmitting. The answer \nto the question can best be illustrated using space-time diagrams [Molle 1987]. \n Figure 6.12 shows a space-time diagram of four nodes (A, B, C, D) attached to a \nlinear broadcast bus. The horizontal axis shows the position of each node in space; \nthe vertical axis represents time.\nAt time t0, node B senses the channel is idle, as no other nodes are currently trans -\nmitting. Node B thus begins transmitting, with its bits propagating in both directions \nalong the broadcast medium. The downward propagation of B\u2019s bits in Figure 6.12 \nwith increasing time indicates that a nonzero amount of time is needed for B\u2019s bits \nactually to propagate (albeit at near the speed of light) along the", "doc_id": "3e3440a0-c744-4119-8e95-8c75db02eda7", "embedding": null, "doc_hash": "edbb24b7918d55076757a4c8f66a3f2ea7e7e06daa3e51dd0315a26a6e3fc303", "extra_info": null, "node_info": {"start": 1417072, "end": 1420728}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "98dc066d-17be-4a7f-9348-6f5b3bef01ee", "3": "b27cc8a9-c505-4146-9236-1eeaa2ceabe5"}}, "__type__": "1"}, "b27cc8a9-c505-4146-9236-1eeaa2ceabe5": {"__data__": {"text": "it senses that another node is transmitting. The answer \nto the question can best be illustrated using space-time diagrams [Molle 1987]. \n Figure 6.12 shows a space-time diagram of four nodes (A, B, C, D) attached to a \nlinear broadcast bus. The horizontal axis shows the position of each node in space; \nthe vertical axis represents time.\nAt time t0, node B senses the channel is idle, as no other nodes are currently trans -\nmitting. Node B thus begins transmitting, with its bits propagating in both directions \nalong the broadcast medium. The downward propagation of B\u2019s bits in Figure 6.12 \nwith increasing time indicates that a nonzero amount of time is needed for B\u2019s bits \nactually to propagate (albeit at near the speed of light) along the broadcast medium. At \ntime t1 (t17t0), node D has a frame to send. Although node B is currently transmit -\nting at time t1, the bits being transmitted by B have yet to reach D, and thus D senses NORM ABRAMSON AND ALOHANET\nNorm Abramson, a PhD engineer, had a passion for surfing and an interest in \npacket switching. This combination of interests brought him to the University of \nHawaii in 1969. Hawaii consists of many mountainous islands, making it difficult \nto install and operate land-based networks. When not surfing, Abramson thought \nabout how to design a network that does packet switching over radio. The network \nhe designed had one central host and several secondary nodes scattered over the \nHawaiian Islands. The network had two channels, each using a different frequency \nband. The downlink channel broadcasted packets from the central host to the sec -\nondary hosts; and the upstream channel sent packets from the secondary hosts to \nthe central host. In addition to sending informational packets, the central host also \nsent on the downstream channel an acknowledgment for each packet successfully \nreceived from the secondary hosts.\nBecause the secondary hosts transmitted packets in a decentralized fashion, col -\nlisions on the upstream channel inevitably occurred. This observation led Abramson \nto devise the pure ALOHA protocol, as described in this chapter. In 1970, with \ncontinued funding from ARPA, Abramson connected his ALOHAnet to the ARPAnet. \nAbramson\u2019s work is important not only because it was the first example of a radio \npacket network, but also because it inspired Bob Metcalfe. A few years later, \nMetcalfe modified the ALOHA protocol to create the CSMA/CD protocol and the \nEthernet LAN.CASE HISTORY\n\n6.3  \u2022  MULTIPLE ACCESS LINKS AND PROTOCOLS      489\nthe channel idle at t1. In accordance with the CSMA protocol, D thus begins transmit -\nting its frame. A short time later, B\u2019s transmission begins to interfere with D\u2019s trans -\nmission at D. From Figure 6.12, it is evident that the end-to-end channel propagation \ndelay  of a broadcast channel\u2014the time it takes for a signal to propagate from one of \nthe nodes to another\u2014will play a crucial role in determining its performance. The \nlonger this propagation delay, the larger the chance that a carrier-sensing node is not \nyet able to sense a transmission that has already begun at another node in the network.\nCarrier Sense Multiple Access with Collision Dection (CSMA/CD)\nIn Figure 6.12, nodes do not perform collision detection; both B and D continue to \ntransmit their frames in their entirety even though a collision has occurred. When a \nnode performs collision detection, it ceases transmission as soon as it detects a col -\nlision. Figure 6.13 shows the same scenario as in Figure 6.12, except that the two Figure 6.12  \u2666  Space-time diagram of two CSMA nodes with colliding \ntransmissionsA\nTime TimeSpace\nt0\nt1BC D\n490     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND", "doc_id": "b27cc8a9-c505-4146-9236-1eeaa2ceabe5", "embedding": null, "doc_hash": "00276ed67bc601dba0aa6d941a0b5372cb22f2fe8cbb11ca4950bf561ae6d81f", "extra_info": null, "node_info": {"start": 1420616, "end": 1424327}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "3e3440a0-c744-4119-8e95-8c75db02eda7", "3": "c96ae6f2-43a6-47f3-ae9e-b623906602a2"}}, "__type__": "1"}, "c96ae6f2-43a6-47f3-ae9e-b623906602a2": {"__data__": {"text": "carrier-sensing node is not \nyet able to sense a transmission that has already begun at another node in the network.\nCarrier Sense Multiple Access with Collision Dection (CSMA/CD)\nIn Figure 6.12, nodes do not perform collision detection; both B and D continue to \ntransmit their frames in their entirety even though a collision has occurred. When a \nnode performs collision detection, it ceases transmission as soon as it detects a col -\nlision. Figure 6.13 shows the same scenario as in Figure 6.12, except that the two Figure 6.12  \u2666  Space-time diagram of two CSMA nodes with colliding \ntransmissionsA\nTime TimeSpace\nt0\nt1BC D\n490     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\nnodes each abort their transmission a short time after detecting a collision. Clearly, \nadding collision detection to a multiple access protocol will help protocol perfor -\nmance by not transmitting a useless, damaged (by interference with a frame from \nanother node) frame in its entirety.\nBefore analyzing the CSMA/CD protocol, let us now summarize its operation \nfrom the perspective of an adapter (in a node) attached to a broadcast channel:\n 1. The adapter obtains a datagram from the network layer, prepares a link-layer \nframe, and puts the frame adapter buffer.\n 2. If the adapter senses that the channel is idle (that is, there is no signal energy \nentering the adapter from the channel), it starts to transmit the frame. If, on the \nother hand, the adapter senses that the channel is busy, it waits until it senses \nno signal energy and then starts to transmit the frame.\n 3. While transmitting, the adapter monitors for the presence of signal energy \ncoming from other adapters using the broadcast channel.Figure 6.13  \u2666 CSMA with collision detectionA\nTime TimeCollision\ndetect/abort\ntimeSpace\nt0\nt1BC D\n6.3  \u2022  MULTIPLE ACCESS LINKS AND PROTOCOLS      491\n 4. If the adapter transmits the entire frame without detecting signal energy from \nother adapters, the adapter is finished with the frame. If, on the other hand, the \nadapter detects signal energy from other adapters while transmitting, it aborts \nthe transmission (that is, it stops transmitting its frame).\n 5. After aborting, the adapter waits a random amount of time and then returns to \nstep 2.\nThe need to wait a random (rather than fixed) amount of time is hopefully clear\u2014if \ntwo nodes transmitted frames at the same time and then both waited the same fixed \namount of time, they\u2019d continue colliding forever. But what is a good interval of \ntime from which to choose the random backoff time? If the interval is large and the \nnumber of colliding nodes is small, nodes are likely to wait a large amount of time \n(with the channel remaining idle) before repeating the sense-and-transmit-when-\nidle step. On the other hand, if the interval is small and the number of colliding \nnodes is large, it\u2019s likely that the chosen random values will be nearly the same, \nand transmitting nodes will again collide. What we\u2019d like is an interval that is short \nwhen the number of colliding nodes is small, and long when the number of colliding \nnodes is large.\nThe binary exponential backoff  algorithm, used in Ethernet as well as in DOC -\nSIS cable network multiple access protocols [DOCSIS 2011], elegantly solves this \nproblem. Specifically, when transmitting a frame that has already experienced n col-\nlisions, a node chooses the value of K at random from {0,1,2, . . . . 2n-1}. Thus, \nthe more collisions experienced by a frame, the larger the interval from which K \nis chosen. For Ethernet, the actual amount of time a node waits is K #512 bit times \n(i.e., K times the amount of time needed to send 512 bits into the", "doc_id": "c96ae6f2-43a6-47f3-ae9e-b623906602a2", "embedding": null, "doc_hash": "20a76649c905938a34e4162f171ba28b0a0e7b32e5bf7d62fe3109e31f4c6887", "extra_info": null, "node_info": {"start": 1424389, "end": 1428057}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "b27cc8a9-c505-4146-9236-1eeaa2ceabe5", "3": "6ef389a8-9402-40b7-bdb4-d9664371361f"}}, "__type__": "1"}, "6ef389a8-9402-40b7-bdb4-d9664371361f": {"__data__": {"text": "What we\u2019d like is an interval that is short \nwhen the number of colliding nodes is small, and long when the number of colliding \nnodes is large.\nThe binary exponential backoff  algorithm, used in Ethernet as well as in DOC -\nSIS cable network multiple access protocols [DOCSIS 2011], elegantly solves this \nproblem. Specifically, when transmitting a frame that has already experienced n col-\nlisions, a node chooses the value of K at random from {0,1,2, . . . . 2n-1}. Thus, \nthe more collisions experienced by a frame, the larger the interval from which K \nis chosen. For Ethernet, the actual amount of time a node waits is K #512 bit times \n(i.e., K times the amount of time needed to send 512 bits into the Ethernet) and the \nmaximum value that n can take is capped at 10.\nLet\u2019s look at an example. Suppose that a node attempts to transmit a frame for \nthe first time and while transmitting it detects a collision. The node then chooses  \nK = 0 with probability 0.5 or chooses K=1 with probability 0.5. If the node \nchooses K = 0, then it immediately begins sensing the channel. If the node chooses \nK = 1, it waits 512 bit times (e.g., 5.12 microseconds for a 100 Mbps Ethernet) \nbefore beginning the sense-and-transmit-when-idle cycle. After a second collision, \nK is chosen with equal probability from {0,1,2,3}. After three collisions, K is cho -\nsen with equal probability from {0,1,2,3,4,5,6,7}. After 10 or more collisions, K is \nchosen with equal probability from {0,1,2,\u2026, 1023}. Thus, the size of the sets from \nwhich K is chosen grows exponentially with the number of collisions; for this reason \nthis algorithm is referred to as binary exponential backoff.\nWe also note here that each time a node prepares a new frame for transmission, \nit runs the CSMA/CD algorithm, not taking into account any collisions that may \nhave occurred in the recent past. So it is possible that a node with a new frame will \nimmediately be able to sneak in a successful transmission while several other nodes \nare in the exponential backoff state.\n492     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\nCSMA/CD Efficiency\nWhen only one node has a frame to send, the node can transmit at the full channel \nrate (e.g., for Ethernet typical rates are 10 Mbps, 100 Mbps, or 1 Gbps). However, if \nmany nodes have frames to transmit, the effective transmission rate of the channel \ncan be much less. We define the efficiency of CSMA/CD  to be the long-run fraction \nof time during which frames are being transmitted on the channel without collisions \nwhen there is a large number of active nodes, with each node having a large number \nof frames to send. In order to present a closed-form approximation of the efficiency \nof Ethernet, let dprop denote the maximum time it takes signal energy to propagate \nbetween any two adapters. Let dtrans be the time to transmit a maximum-size frame \n(approximately 1.2 msecs for a 10 Mbps Ethernet). A derivation of the efficiency of \nCSMA/CD is beyond the scope of this book (see [Lam 1980] and [Bertsekas 1991]). \nHere we simply state the following approximation:\nEfficiency =1\n1+5dprop>dtrans\nWe see from this formula that as dprop approaches 0, the efficiency approaches 1. \nThis matches our intuition that if the propagation delay is zero, colliding nodes will \nabort immediately without wasting the channel. Also, as dtrans becomes very large, \nefficiency approaches 1. This is also intuitive because when a frame grabs the chan-\nnel, it will hold on to the channel for a very long time; thus, the channel will be doing \nproductive work most of the time.\n6.3.3 Taking-Turns Protocols\nRecall that two", "doc_id": "6ef389a8-9402-40b7-bdb4-d9664371361f", "embedding": null, "doc_hash": "47666c94eba0fed707fe65998c72fb87ee05691b735a0d3c906ccfb17636b1e2", "extra_info": null, "node_info": {"start": 1428035, "end": 1431660}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "c96ae6f2-43a6-47f3-ae9e-b623906602a2", "3": "a466cb63-55bb-4671-b966-83f6910e0579"}}, "__type__": "1"}, "a466cb63-55bb-4671-b966-83f6910e0579": {"__data__": {"text": "Mbps Ethernet). A derivation of the efficiency of \nCSMA/CD is beyond the scope of this book (see [Lam 1980] and [Bertsekas 1991]). \nHere we simply state the following approximation:\nEfficiency =1\n1+5dprop>dtrans\nWe see from this formula that as dprop approaches 0, the efficiency approaches 1. \nThis matches our intuition that if the propagation delay is zero, colliding nodes will \nabort immediately without wasting the channel. Also, as dtrans becomes very large, \nefficiency approaches 1. This is also intuitive because when a frame grabs the chan-\nnel, it will hold on to the channel for a very long time; thus, the channel will be doing \nproductive work most of the time.\n6.3.3 Taking-Turns Protocols\nRecall that two desirable properties of a multiple access protocol are (1) when only \none node is active, the active node has a throughput of R bps, and (2) when M nodes \nare active, then each active node has a throughput of nearly R/M bps. The ALOHA \nand CSMA protocols have this first property but not the second. This has motivated \nresearchers to create another class of protocols\u2014the taking-turns protocols . As with \nrandom access protocols, there are dozens of taking-turns protocols, and each one of \nthese protocols has many variations. We\u2019ll discuss two of the more important protocols \nhere. The first one is the polling protocol . The polling protocol requires one of the \nnodes to be designated as a master node. The master node polls  each of the nodes in \na round-robin fashion. In particular, the master node first sends a message to node 1, \nsaying that it (node 1) can transmit up to some maximum number of frames. After node \n1 transmits some frames, the master node tells node 2 it (node 2) can transmit up to the \nmaximum number of frames. (The master node can determine when a node has finished \nsending its frames by observing the lack of a signal on the channel.) The procedure con -\ntinues in this manner, with the master node polling each of the nodes in a cyclic manner.\nThe polling protocol eliminates the collisions and empty slots that plague ran -\ndom access protocols. This allows polling to achieve a much higher efficiency. But \n6.3  \u2022  MULTIPLE ACCESS LINKS AND PROTOCOLS      493\nit also has a few drawbacks. The first drawback is that the protocol introduces a \npolling delay\u2014the amount of time required to notify a node that it can transmit. If, \nfor example, only one node is active, then the node will transmit at a rate less than \nR bps, as the master node must poll each of the inactive nodes in turn each time the \nactive node has sent its maximum number of frames. The second drawback, which is \npotentially more serious, is that if the master node fails, the entire channel becomes \ninoperative. The 802.15 protocol and the Bluetooth protocol we will study in Sec -\ntion\u00a06.3 are examples of polling protocols.\nThe second taking-turns protocol is the token-passing protocol . In this pro -\ntocol there is no master node. A small, special-purpose frame known as a token  is \nexchanged among the nodes in some fixed order. For example, node 1 might always \nsend the token to node 2, node 2 might always send the token to node 3, and node N \nmight always send the token to node 1. When a node receives a token, it holds onto \nthe token only if it has some frames to transmit; otherwise, it immediately forwards \nthe token to the next node. If a node does have frames to transmit when it receives \nthe token, it sends up to a maximum number of frames and then forwards the token to \nthe next node. Token passing is decentralized and highly efficient. But it has its prob -\nlems as well. For example, the failure of one node can crash the entire channel. Or if \na node accidentally neglects to release the token, then some recovery procedure must \nbe invoked to", "doc_id": "a466cb63-55bb-4671-b966-83f6910e0579", "embedding": null, "doc_hash": "1d05fabb59f0f945ce867fd092364b59449c26ddf07c9ac331c50aafd7279dbe", "extra_info": null, "node_info": {"start": 1431635, "end": 1435441}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "6ef389a8-9402-40b7-bdb4-d9664371361f", "3": "4044f40e-3f00-42aa-8151-cb01883c0f7d"}}, "__type__": "1"}, "4044f40e-3f00-42aa-8151-cb01883c0f7d": {"__data__": {"text": "among the nodes in some fixed order. For example, node 1 might always \nsend the token to node 2, node 2 might always send the token to node 3, and node N \nmight always send the token to node 1. When a node receives a token, it holds onto \nthe token only if it has some frames to transmit; otherwise, it immediately forwards \nthe token to the next node. If a node does have frames to transmit when it receives \nthe token, it sends up to a maximum number of frames and then forwards the token to \nthe next node. Token passing is decentralized and highly efficient. But it has its prob -\nlems as well. For example, the failure of one node can crash the entire channel. Or if \na node accidentally neglects to release the token, then some recovery procedure must \nbe invoked to get the token back in circulation. Over the years many token-passing \nprotocols have been developed, including the fiber distributed data interface (FDDI) \nprotocol [Jain 1994] and the IEEE 802.5 token ring protocol [IEEE 802.5 2012], and \neach one had to address these as well as other sticky issues.\n6.3.4  DOCSIS: The Link-Layer Protocol for Cable  \nInternet Access\nIn the previous three subsections, we\u2019ve learned about three broad classes of mul -\ntiple access protocols: channel partitioning protocols, random access protocols, and \ntaking turns protocols. A cable access network will make for an excellent case study \nhere, as we\u2019ll find aspects of each  of these three classes of multiple access protocols \nwith the cable access network!\nRecall from Section 1.2.1 that a cable access network typically connects several \nthousand residential cable modems to a cable modem termination system (CMTS) \nat the cable network headend. The Data-Over-Cable Service Interface Specifica -\ntions (DOCSIS) [DOCSIS 2011] specifies the cable data network architecture and \nits protocols. DOCSIS uses FDM to divide the downstream (CMTS to modem) and \nupstream (modem to CMTS) network segments into multiple frequency channels. \nEach downstream channel is 6 MHz wide, with a maximum throughput of approxi -\nmately 40 Mbps per channel (although this data rate is seldom seen at a cable modem \nin practice); each upstream channel has a maximum channel width of 6.4 MHz, and \na maximum upstream throughput of approximately 30 Mbps. Each upstream and \n494     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\ndownstream channel is a broadcast channel. Frames transmitted on the downstream \nchannel by the CMTS are received by all cable modems receiving that channel; since \nthere is just a single CMTS transmitting into the downstream channel, however, there \nis no multiple access problem. The upstream direction, however, is more interesting \nand technically challenging, since multiple cable modems share the same upstream \nchannel (frequency) to the CMTS, and thus collisions can potentially occur.\nAs illustrated in Figure 6.14, each upstream channel is divided into intervals \nof time (TDM-like), each containing a sequence of mini-slots during which cable \nmodems can transmit to the CMTS. The CMTS explicitly grants permission to indi -\nvidual cable modems to transmit during specific mini-slots. The CMTS accomplishes \nthis by sending a control message known as a MAP message on a downstream chan -\nnel to specify which cable modem (with data to send) can transmit during which \nmini-slot for the interval of time specified in the control message. Since mini-slots \nare explicitly allocated to cable modems, the CMTS can ensure there are no colliding \ntransmissions during a mini-slot.\nBut how does the CMTS know which cable modems have data to send in the \nfirst place? This is accomplished by having cable modems send mini-slot-request \nframes to the CMTS during a special set of interval mini-slots that are dedicated for \nthis purpose, as shown in Figure 6.14. These mini-slot-request frames are transmit", "doc_id": "4044f40e-3f00-42aa-8151-cb01883c0f7d", "embedding": null, "doc_hash": "9dbcc49cf4069d402b4281bc311fc71039c1c381597022bc9bb0b005fc908a88", "extra_info": null, "node_info": {"start": 1435425, "end": 1439294}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "a466cb63-55bb-4671-b966-83f6910e0579", "3": "2678f70b-631b-4b0b-ab93-4afb5d8c9c90"}}, "__type__": "1"}, "2678f70b-631b-4b0b-ab93-4afb5d8c9c90": {"__data__": {"text": "cable modems to transmit during specific mini-slots. The CMTS accomplishes \nthis by sending a control message known as a MAP message on a downstream chan -\nnel to specify which cable modem (with data to send) can transmit during which \nmini-slot for the interval of time specified in the control message. Since mini-slots \nare explicitly allocated to cable modems, the CMTS can ensure there are no colliding \ntransmissions during a mini-slot.\nBut how does the CMTS know which cable modems have data to send in the \nfirst place? This is accomplished by having cable modems send mini-slot-request \nframes to the CMTS during a special set of interval mini-slots that are dedicated for \nthis purpose, as shown in Figure 6.14. These mini-slot-request frames are transmit -\nted in a random access manner and so may collide with each other. A cable modem \ncan neither sense whether the upstream channel is busy nor detect collisions. Instead, \nthe cable modem infers that its mini-slot-request frame experienced a collision if it \ndoes not receive a response to the requested allocation in the next downstream con -\ntrol message. When a collision is inferred, a cable modem uses binary exponential Figure 6.14  \u2666  Upstream and downstream channels between CMTS and \ncable modemsResidences with\ncable modems\nMinislots\ncontaining\nminislot\nrequest framesAssigned minislots\ncontaining cable\nmodem upstream\ndata framesCable head endMAP frame for \ninterval [t1,t2]\nCMTSDownstream channel i\nUpstream channel j\nt1 t2\n6.4  \u2022  SWITCHED LOCAL AREA NETWORKS      495\nbackoff to defer the retransmission of its mini-slot-request frame to a future time \nslot. When there is little traffic on the upstream channel, a cable modem may actually \ntransmit data frames during slots nominally assigned for mini-slot-request frames \n(and thus avoid having to wait for a mini-slot assignment).\nA cable access network thus serves as a terrific example of multiple access pro -\ntocols in action\u2014FDM, TDM, random access, and centrally allocated time slots all \nwithin one network!\n6.4 Switched Local Area Networks\nHaving covered broadcast networks and multiple access protocols in the previous \nsection, let\u2019s turn our attention next to switched local networks. Figure 6.15 shows \na switched local network connecting three departments, two servers and a router \nwith four switches. Because these switches operate at the link layer, they switch \nlink-layer frames (rather than network-layer datagrams), don\u2019t recognize network-\nlayer addresses, and don\u2019t use routing algorithms like RIP or OSPF to determine \nFigure 6.15  \u2666 An institutional network connected together by four switchesMail\nserverTo external\ninternet\n1 Gbps\n1\n2 34561 Gbps\n1 Gbps\nElectrical Engineering Computer Science100 Mbps\n(\ufb01ber)100 Mbps\n(\ufb01ber)100 Mbps\n(\ufb01ber)\nMixture of 10 Mbps,\n100 Mbps, 1 Gbps,\nCat 5 cableWeb\nserver\nComputer Engineering\n496     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\npaths through the network of layer-2 switches. Instead of using IP addresses, we will \nsoon see that they use link-layer addresses to forward link-layer frames through the \nnetwork of switches. We\u2019ll begin our study of switched LANs by first covering link-\nlayer addressing (Section 6.4.1). We then examine the celebrated Ethernet protocol \n(Section 6. 5.2). After examining link-layer addressing and Ethernet, we\u2019ll look at \nhow link-layer switches operate (Section 6.4.3), and then see (Section 6.4.4) how \nthese switches are often used to build large-scale LANs.\n6.4.1 Link-Layer Addressing and ARP\nHosts and routers have link-layer addresses. Now you might find this surprising, \nrecalling from Chapter 4 that", "doc_id": "2678f70b-631b-4b0b-ab93-4afb5d8c9c90", "embedding": null, "doc_hash": "8ba5698a030d1a14cb545fd9f09b33b888c64efa33f1aab443ad83dfbc53756f", "extra_info": null, "node_info": {"start": 1439279, "end": 1442917}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "4044f40e-3f00-42aa-8151-cb01883c0f7d", "3": "fa05fbab-4f5c-47a4-bf52-55e190234d96"}}, "__type__": "1"}, "fa05fbab-4f5c-47a4-bf52-55e190234d96": {"__data__": {"text": "the network of layer-2 switches. Instead of using IP addresses, we will \nsoon see that they use link-layer addresses to forward link-layer frames through the \nnetwork of switches. We\u2019ll begin our study of switched LANs by first covering link-\nlayer addressing (Section 6.4.1). We then examine the celebrated Ethernet protocol \n(Section 6. 5.2). After examining link-layer addressing and Ethernet, we\u2019ll look at \nhow link-layer switches operate (Section 6.4.3), and then see (Section 6.4.4) how \nthese switches are often used to build large-scale LANs.\n6.4.1 Link-Layer Addressing and ARP\nHosts and routers have link-layer addresses. Now you might find this surprising, \nrecalling from Chapter 4 that hosts and routers have network-layer addresses as well. \nYou might be asking, why in the world do we need to have addresses at both the \nnetwork and link layers? In addition to describing the syntax and function of the \nlink-layer addresses, in this section we hope to shed some light on why the two lay -\ners of addresses are useful and, in fact, indispensable. We\u2019ll also cover the Address \nResolution Protocol (ARP), which provides a mechanism to translate IP addresses to \nlink-layer addresses.\nMAC Addresses\nIn truth, it is not hosts and routers that have link-layer addresses but rather their \nadapters (that is, network interfaces) that have link-layer addresses. A host or router \nwith multiple network interfaces will thus have multiple link-layer addresses associ -\nated with it, just as it would also have multiple IP addresses associated with it. It's \nimportant to note, however, that link-layer switches do not have link-layer addresses \nassociated with their interfaces that connect to hosts and routers. This is because the \njob of the link-layer switch is to carry datagrams between hosts and routers; a switch \ndoes this job transparently, that is, without the host or router having to explicitly \naddress the frame to the intervening switch. This is illustrated in Figure 6.16. A link-\nlayer address is variously called a LAN address , a physical address , or a MAC \naddress . Because MAC address seems to be the most popular term, we\u2019ll henceforth \nrefer to link-layer addresses as MAC addresses. For most LANs (including Ethernet \nand 802.11 wireless LANs), the MAC address is 6 bytes long, giving 248 possi -\nble MAC addresses. As shown in Figure 6.16, these 6-byte addresses are typically \nexpressed in hexadecimal notation, with each byte of the address expressed as a pair \nof hexadecimal numbers. Although MAC addresses were designed to be permanent, \nit is now possible to change an adapter\u2019s MAC address via software. For the rest of \nthis section, however, we\u2019ll assume that an adapter\u2019s MAC address is fixed.\nOne interesting property of MAC addresses is that no two adapters have the \nsame address. This might seem surprising given that adapters are manufactured in \nmany countries by many companies. How does a company manufacturing adapters in \nTaiwan make sure that it is using different addresses from a company manufacturing \n6.4  \u2022  SWITCHED LOCAL AREA NETWORKS      497\nadapters in Belgium? The answer is that the IEEE manages the MAC address space. \nIn particular, when a company wants to manufacture adapters, it purchases a chunk \nof the address space consisting of 224 addresses for a nominal fee. IEEE allocates the \nchunk of 224 addresses by fixing the first 24 bits of a MAC address and letting the \ncompany create unique combinations of the last 24 bits for each adapter.\nAn adapter\u2019s MAC address has a flat structure (as opposed to a hierarchical \nstructure) and doesn\u2019t change no matter where the adapter goes. A laptop with an \nEthernet interface always has the same MAC address, no matter where the computer \ngoes. A smartphone with an 802.11 interface always has the same MAC address, no \nmatter where the smartphone goes. Recall", "doc_id": "fa05fbab-4f5c-47a4-bf52-55e190234d96", "embedding": null, "doc_hash": "43839ba4c7fee5a1f17f3bb5f723713065348c14a51f2d2f014ab5d25bcceb4f", "extra_info": null, "node_info": {"start": 1442964, "end": 1446843}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "2678f70b-631b-4b0b-ab93-4afb5d8c9c90", "3": "1679f3a5-8a0d-4e37-b3af-ddb564d4ec43"}}, "__type__": "1"}, "1679f3a5-8a0d-4e37-b3af-ddb564d4ec43": {"__data__": {"text": "in Belgium? The answer is that the IEEE manages the MAC address space. \nIn particular, when a company wants to manufacture adapters, it purchases a chunk \nof the address space consisting of 224 addresses for a nominal fee. IEEE allocates the \nchunk of 224 addresses by fixing the first 24 bits of a MAC address and letting the \ncompany create unique combinations of the last 24 bits for each adapter.\nAn adapter\u2019s MAC address has a flat structure (as opposed to a hierarchical \nstructure) and doesn\u2019t change no matter where the adapter goes. A laptop with an \nEthernet interface always has the same MAC address, no matter where the computer \ngoes. A smartphone with an 802.11 interface always has the same MAC address, no \nmatter where the smartphone goes. Recall that, in contrast, IP addresses have a hier -\narchical structure (that is, a network part and a host part), and a host\u2019s IP addresses \nneeds to be changed when the host moves, i.e., changes the network to which it is \nattached. An adapter\u2019s MAC address is analogous to a person\u2019s social security num -\nber, which also has a flat addressing structure and which doesn\u2019t change no matter \nwhere the person goes. An IP address is analogous to a person\u2019s postal address, \nwhich is hierarchical and which must be changed whenever a person moves. Just as a \nperson may find it useful to have both a postal address and a social security number, \nit is useful for a host and router interfaces to have both a network-layer address and \na MAC address.\nWhen an adapter wants to send a frame to some destination adapter, the sending \nadapter inserts the destination adapter\u2019s MAC address into the frame and then sends the \nframe into the LAN. As we will soon see, a switch occasionally broadcasts an incom -\ning frame onto all of its interfaces. We\u2019ll see in Chapter 7 that 802.11 also broadcasts \nframes. Thus, an adapter may receive a frame that isn\u2019t addressed to it. Thus, when \nan adapter receives a frame, it will check to see whether the destination MAC address Figure 6.16  \u2666  Each interface connected to a LAN has a unique MAC \naddress88-B2-2F-54-1A-0F 5C-66-AB-90-75-B11A-23-F9-CD-06-9B\n49-BD-D2-C7-56-2A\n498     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\nin the frame matches its own MAC address. If there is a match, the adapter extracts \nthe enclosed datagram and passes the datagram up the protocol stack. If there isn\u2019t a \nmatch, the adapter discards the frame, without passing the network-layer datagram up. \nThus, the destination only will be interrupted when the frame is received.\nHowever, sometimes a sending adapter does want all the other adapters on the \nLAN to receive and process  the frame it is about to send. In this case, the sending \nadapter inserts a special MAC broadcast address  into the destination address field \nof the frame. For LANs that use 6-byte addresses (such as Ethernet and 802.11), the \nbroadcast address is a string of 48 consecutive 1s (that is, FF-FF-FF-FF-FF-FF in \nhexadecimal notation).\nAddress Resolution Protocol (ARP)\nBecause there are both network-layer addresses (for example, Internet IP addresses) \nand link-layer addresses (that is, MAC addresses), there is a need to translate between \nthem. For the Internet, this is the job of the Address Resolution Protocol (ARP)  \n[RFC 826].\nTo understand the need for a protocol such as ARP, consider the network \nshown in Figure 6.17. In this simple example, each host and router has a single IP \naddress and single MAC address. As usual, IP addresses are shown in dotted-decimal \nKEEPING THE LAYERS INDEPENDENT\nThere are several reasons why hosts and router interfaces have MAC addresses in \n", "doc_id": "1679f3a5-8a0d-4e37-b3af-ddb564d4ec43", "embedding": null, "doc_hash": "0e3239b304fa9720b7a6973f28ef802a846d4523230718cf58a278891cd81ce0", "extra_info": null, "node_info": {"start": 1446807, "end": 1450451}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "fa05fbab-4f5c-47a4-bf52-55e190234d96", "3": "dd8eaec3-d0d2-4bb6-8785-efbf48e0213f"}}, "__type__": "1"}, "dd8eaec3-d0d2-4bb6-8785-efbf48e0213f": {"__data__": {"text": "consecutive 1s (that is, FF-FF-FF-FF-FF-FF in \nhexadecimal notation).\nAddress Resolution Protocol (ARP)\nBecause there are both network-layer addresses (for example, Internet IP addresses) \nand link-layer addresses (that is, MAC addresses), there is a need to translate between \nthem. For the Internet, this is the job of the Address Resolution Protocol (ARP)  \n[RFC 826].\nTo understand the need for a protocol such as ARP, consider the network \nshown in Figure 6.17. In this simple example, each host and router has a single IP \naddress and single MAC address. As usual, IP addresses are shown in dotted-decimal \nKEEPING THE LAYERS INDEPENDENT\nThere are several reasons why hosts and router interfaces have MAC addresses in \n addition to network-layer addresses. First, LANs are designed for arbitrary network-layer \nprotocols, not just for IP and the Internet. If adapters were assigned IP addresses rather \nthan \u201cneutral\u201d MAC addresses, then adapters would not easily be able to support other \nnetwork-layer protocols (for example, IPX or DECnet). Second, if adapters were to use \nnetwork-layer addresses instead of MAC addresses, the network-layer address would have \nto be stored in the adapter RAM and reconfigured every time the adapter was moved (or \npowered up). Another option is to not use any addresses in the adapters and have each \nadapter pass the data (typically, an IP datagram) of each frame it receives up the protocol \nstack. The network layer could then check for a matching network-layer address. One \nproblem with this option is that the host would be interrupted by every frame sent on the \nLAN, including by frames that were destined for other hosts on the same broadcast LAN. \nIn summary, in order for the layers to be largely independent building blocks in a network \narchitecture, different layers need to have their own addressing scheme. We have now \nseen three types of addresses: host names for the application layer, IP addresses for the \nnetwork layer, and MAC addresses for the link layer.PRINCIPLES IN PRACTICE\n\n6.4  \u2022  SWITCHED LOCAL AREA NETWORKS      499\nnotation and MAC addresses are shown in hexadecimal notation. For the purposes of \nthis discussion, we will assume in this section that the switch broadcasts all frames; \nthat is, whenever a switch receives a frame on one interface, it forwards the frame \non all of its other interfaces. In the next section, we will provide a more accurate \nexplanation of how switches operate.\nNow suppose that the host with IP address 222.222.222.220 wants to send an IP \ndatagram to host 222.222.222.222. In this example, both the source and destination \nare in the same subnet, in the addressing sense of Section 4.3.3. To send a datagram, \nthe source must give its adapter not only the IP datagram but also the MAC address \nfor destination 222.222.222.222. The sending adapter will then construct a link-layer \nframe containing the destination\u2019s MAC address and send the frame into the LAN.\nThe important question addressed in this section is, How does the sending host \ndetermine the MAC address for the destination host with IP address 222.222.222.222? \nAs you might have guessed, it uses ARP. An ARP module in the sending host takes \nany IP address on the same LAN as input, and returns the corresponding MAC \naddress. In the example at hand, sending host 222.222.222.220 provides its ARP \nmodule the IP address 222.222.222.222, and the ARP module returns the corre -\nsponding MAC address 49-BD-D2-C7-56-2A.\nSo we see that ARP resolves an IP address to a MAC address. In many ways \nit is analogous to DNS (studied in Section 2.5 ), which resolves host names to IP \naddresses. However, one important difference between the two resolvers is that DNS \nresolves host names for hosts anywhere in the Internet, whereas ARP resolves IP \naddresses only for hosts and router interfaces on the same subnet.", "doc_id": "dd8eaec3-d0d2-4bb6-8785-efbf48e0213f", "embedding": null, "doc_hash": "6ff96f76c90d4d0986c22b4ea1cab797b1eead26dde5990cb8a444fe9a4cbf02", "extra_info": null, "node_info": {"start": 1450471, "end": 1454352}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "1679f3a5-8a0d-4e37-b3af-ddb564d4ec43", "3": "ccff84ae-75ed-4b64-9a9c-e95bf3be21e8"}}, "__type__": "1"}, "ccff84ae-75ed-4b64-9a9c-e95bf3be21e8": {"__data__": {"text": "uses ARP. An ARP module in the sending host takes \nany IP address on the same LAN as input, and returns the corresponding MAC \naddress. In the example at hand, sending host 222.222.222.220 provides its ARP \nmodule the IP address 222.222.222.222, and the ARP module returns the corre -\nsponding MAC address 49-BD-D2-C7-56-2A.\nSo we see that ARP resolves an IP address to a MAC address. In many ways \nit is analogous to DNS (studied in Section 2.5 ), which resolves host names to IP \naddresses. However, one important difference between the two resolvers is that DNS \nresolves host names for hosts anywhere in the Internet, whereas ARP resolves IP \naddresses only for hosts and router interfaces on the same subnet. If a node in Cali -\nfornia were to try to use ARP to resolve the IP address for a node in Mississippi, ARP \nwould return with an error.Figure 6.17  \u2666  Each interface on a LAN has an IP address and a MAC \naddressIP:222.222.222.221IP:222.222.222.220\nIP:222.222.222.223\nIP:222.222.222.2225C-66-AB-90-75-B11A-23-F9-CD-06-9B\n49-BD-D2-C7-56-2A88-B2-2F-54-1A-0F\nABC\n500     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\nNow that we have explained what ARP does, let\u2019s look at how it works. Each host \nand router has an ARP table  in its memory, which contains mappings of IP addresses \nto MAC addresses. Figure 6.18 shows what an ARP table in host 222.222.222.220 \nmight look like. The ARP table also contains a time-to-live (TTL) value, which indi -\ncates when each mapping will be deleted from the table. Note that a table does not \nnecessarily contain an entry for every host and router on the subnet; some may have \nnever been entered into the table, and others may have expired. A typical expiration \ntime for an entry is 20 minutes from when an entry is placed in an ARP table.\nNow suppose that host 222.222.222.220 wants to send a datagram that is IP-\naddressed to another host or router on that subnet. The sending host needs to obtain the \nMAC address of the destination given the IP address. This task is easy if the sender\u2019s \nARP table has an entry for the destination node. But what if the ARP table doesn\u2019t cur -\nrently have an entry for the destination? In particular, suppose 222.222.222.220 wants \nto send a datagram to 222.222.222.222. In this case, the sender uses the ARP protocol \nto resolve the address. First, the sender constructs a special packet called an ARP \npacket . An ARP packet has several fields, including the sending and receiving IP and \nMAC addresses. Both ARP query and response packets have the same format. The pur -\npose of the ARP query packet is to query all the other hosts and routers on the subnet \nto determine the MAC address corresponding to the IP address that is being resolved.\nReturning to our example, 222.222.222.220 passes an ARP query packet to \nthe adapter along with an indication that the adapter should send the packet to the \nMAC broadcast address, namely, FF-FF-FF-FF-FF-FF. The adapter encapsulates the \nARP packet in a link-layer frame, uses the broadcast address for the frame\u2019s destina -\ntion address, and transmits the frame into the subnet. Recalling our social security \n number/postal address analogy, an ARP query is equivalent to a person shouting out \nin a crowded room of cubicles in some company (say, AnyCorp): \u201cWhat is the social \nsecurity number of the person whose postal address is Cubicle 13, Room 112, Any -\nCorp, Palo Alto, California?\u201d The frame containing the ARP query is received by all \nthe other adapters", "doc_id": "ccff84ae-75ed-4b64-9a9c-e95bf3be21e8", "embedding": null, "doc_hash": "ea16d7825a51ebf93d1555a82e282c1a44e71b07615ce23e6d688998d0aad75d", "extra_info": null, "node_info": {"start": 1454374, "end": 1457869}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "dd8eaec3-d0d2-4bb6-8785-efbf48e0213f", "3": "0fb6b0db-2775-4c6e-9eb1-581434266f01"}}, "__type__": "1"}, "0fb6b0db-2775-4c6e-9eb1-581434266f01": {"__data__": {"text": "passes an ARP query packet to \nthe adapter along with an indication that the adapter should send the packet to the \nMAC broadcast address, namely, FF-FF-FF-FF-FF-FF. The adapter encapsulates the \nARP packet in a link-layer frame, uses the broadcast address for the frame\u2019s destina -\ntion address, and transmits the frame into the subnet. Recalling our social security \n number/postal address analogy, an ARP query is equivalent to a person shouting out \nin a crowded room of cubicles in some company (say, AnyCorp): \u201cWhat is the social \nsecurity number of the person whose postal address is Cubicle 13, Room 112, Any -\nCorp, Palo Alto, California?\u201d The frame containing the ARP query is received by all \nthe other adapters on the subnet, and (because of the broadcast address) each adapter \npasses the ARP packet within the frame up to its ARP module. Each of these ARP \nmodules checks to see if its IP address matches the destination IP address in the ARP \npacket. The one with a match sends back to the querying host a response ARP packet \nwith the desired mapping. The querying host 222.222.222.220 can then update its \nARP table and send its IP datagram, encapsulated in a link-layer frame whose desti-\nnation MAC is that of the host or router responding to the earlier ARP query.Figure 6.18  \u2666 A possible ARP table in 222.222.222.220IP Address MAC Addres sT TL\n222.222.222.221 88-B2-2F-54-1A-0F 13:45:00\n222.222.222.223 5C-66-AB-90-75-B 11 3:52:00\n6.4  \u2022  SWITCHED LOCAL AREA NETWORKS      501\nThere are a couple of interesting things to note about the ARP protocol. First, \nthe query ARP message is sent within a broadcast frame, whereas the response \nARP message is sent within a standard frame. Before reading on you should think \nabout why this is so. Second, ARP is plug-and-play; that is, an ARP table gets built \n automatically\u2014it doesn\u2019t have to be configured by a system administrator. And if a \nhost becomes disconnected from the subnet, its entry is eventually deleted from the \nother ARP tables in the subnet.\nStudents often wonder if ARP is a link-layer protocol or a network-layer proto -\ncol. As we\u2019ve seen, an ARP packet is encapsulated within a link-layer frame and thus \nlies architecturally above the link layer. However, an ARP packet has fields contain -\ning link-layer addresses and thus is arguably a link-layer protocol, but it also contains \nnetwork-layer addresses and thus is also arguably a network-layer protocol. In the \nend, ARP is probably best considered a protocol that straddles the boundary between \nthe link and network layers\u2014not fitting neatly into the simple layered protocol stack \nwe studied in Chapter 1. Such are the complexities of real-world protocols!\nSending a Datagram off the Subnet\nIt should now be clear how ARP operates when a host wants to send a datagram to \nanother host on the same subnet.  But now let\u2019s look at the more complicated situ -\nation when a host on a subnet wants to send a network-layer datagram to a host off \nthe subnet  (that is, across a router onto another subnet). Let\u2019s discuss this issue in \nthe context of Figure 6.19, which shows a simple network consisting of two subnets \ninterconnected by a router.\nThere are several interesting things to note about Figure 6.19. Each host has \nexactly one IP address and one adapter. But, as discussed in Chapter 4 , a router has \nan IP address for each  of its interfaces. For each router interface there is also an ARP \nmodule (in the router) and an adapter. Because the router in Figure 6.19 has two \ninterfaces, it has two IP addresses, two ARP modules, and two adapters. Of course, \neach adapter in the network has its own MAC address.\nFigure 6.19  \u2666 Two subnets interconnected by a", "doc_id": "0fb6b0db-2775-4c6e-9eb1-581434266f01", "embedding": null, "doc_hash": "55bbcce9a62a7994fdcc35881260c21170690497b70b0268e504266feaa1ea04", "extra_info": null, "node_info": {"start": 1457859, "end": 1461569}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "ccff84ae-75ed-4b64-9a9c-e95bf3be21e8", "3": "9b1848fd-dff1-47b8-9b1c-71f02bbe2c6c"}}, "__type__": "1"}, "9b1848fd-dff1-47b8-9b1c-71f02bbe2c6c": {"__data__": {"text": "datagram to a host off \nthe subnet  (that is, across a router onto another subnet). Let\u2019s discuss this issue in \nthe context of Figure 6.19, which shows a simple network consisting of two subnets \ninterconnected by a router.\nThere are several interesting things to note about Figure 6.19. Each host has \nexactly one IP address and one adapter. But, as discussed in Chapter 4 , a router has \nan IP address for each  of its interfaces. For each router interface there is also an ARP \nmodule (in the router) and an adapter. Because the router in Figure 6.19 has two \ninterfaces, it has two IP addresses, two ARP modules, and two adapters. Of course, \neach adapter in the network has its own MAC address.\nFigure 6.19  \u2666 Two subnets interconnected by a routerIP:111.111.111.110 IP:111.111.111.111\nIP:111.111.111.112IP:222.222.222.221\nIP:222.222.222.22274-29-9C-E8-FF-55\nCC-49-DE-D0-AB-7DE6-E9-00-17-BB-4B\n1A-23-F9-CD-06-9B\nIP:222.222.222.22088-B2-2F-54-1A-0F\n49-BD-D2-C7-56-2A\n502     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\nAlso note that Subnet 1 has the network address 111.111.111/24 and that Subnet 2  \nhas the network address 222.222.222/24. Thus all of the interfaces connected to Sub -\nnet 1 have addresses of the form 111.111.111.xxx and all of the interfaces connected \nto Subnet 2 have addresses of the form 222.222.222.xxx.\nNow let\u2019s examine how a host on Subnet 1 would send a datagram to a host \non Subnet 2. Specifically, suppose that host 111.111.111.111 wants to send an IP \ndatagram to a host 222.222.222.222. The sending host passes the datagram to its \nadapter, as usual. But the sending host must also indicate to its adapter an appro -\npriate destination MAC address. What MAC address should the adapter use? One \nmight be tempted to guess that the appropriate MAC address is that of the adapter for \nhost 222.222.222.222, namely, 49-BD-D2-C7-56-2A. This guess, however, would \nbe wrong! If the sending adapter were to use that MAC address, then none of the \n adapters on Subnet 1 would bother to pass the IP datagram up to its network layer, \nsince the frame\u2019s destination address would not match the MAC address of any \nadapter on Subnet 1. The datagram would just die and go to datagram heaven.\nIf we look carefully at Figure 6.19, we see that in order for a datagram to go from \n111.111.111.111 to a host on Subnet 2, the datagram must first be sent to the router \ninterface 111.111.111.110, which is the IP address of the first-hop router on the \npath to the final destination. Thus, the appropriate MAC address for the frame is the \naddress of the adapter for router interface 111.111.111.110, namely, E6-E9-00-17-\nBB-4B. How does the sending host acquire the MAC address for 111.111.111.110? \nBy using ARP, of course! Once the sending adapter has this MAC address, it cre -\nates a frame (containing the datagram addressed to 222.222.222.222) and sends the \nframe into Subnet 1. The router adapter on Subnet 1 sees that the link-layer frame \nis addressed to it, and therefore passes the frame to the network layer of the router. \nHooray\u2014the IP datagram has successfully been moved from source host to the \nrouter! But we are not finished. We still have to move the datagram from the router \nto the destination. The router now has to determine the correct interface on which the \ndatagram is to", "doc_id": "9b1848fd-dff1-47b8-9b1c-71f02bbe2c6c", "embedding": null, "doc_hash": "e680350551b73ed7455445c6affcd4cd6e4525fc3ebe36d0426efe871de95b0b", "extra_info": null, "node_info": {"start": 1461561, "end": 1464878}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "0fb6b0db-2775-4c6e-9eb1-581434266f01", "3": "359864b1-ee8c-490c-9183-79b2b4b1d321"}}, "__type__": "1"}, "359864b1-ee8c-490c-9183-79b2b4b1d321": {"__data__": {"text": "namely, E6-E9-00-17-\nBB-4B. How does the sending host acquire the MAC address for 111.111.111.110? \nBy using ARP, of course! Once the sending adapter has this MAC address, it cre -\nates a frame (containing the datagram addressed to 222.222.222.222) and sends the \nframe into Subnet 1. The router adapter on Subnet 1 sees that the link-layer frame \nis addressed to it, and therefore passes the frame to the network layer of the router. \nHooray\u2014the IP datagram has successfully been moved from source host to the \nrouter! But we are not finished. We still have to move the datagram from the router \nto the destination. The router now has to determine the correct interface on which the \ndatagram is to be forwarded. As discussed in Chapter 4, this is done by consulting a \nforwarding table in the router. The forwarding table tells the router that the datagram \nis to be forwarded via router interface 222.222.222.220. This interface then passes \nthe datagram to its adapter, which encapsulates the datagram in a new frame and \nsends the frame into Subnet 2. This time, the destination MAC address of the frame \nis indeed the MAC address of the ultimate destination. And how does the router \nobtain this destination MAC address? From ARP, of course!\nARP for Ethernet is defined in RFC 826. A nice introduction to ARP is given in \nthe TCP/IP tutorial, RFC 1180. We\u2019ll explore ARP in more detail in the homework \nproblems.\n6.4.2 Ethernet\nEthernet has pretty much taken over the wired LAN market. In the 1980s and the \nearly 1990s, Ethernet faced many challenges from other LAN technologies,  including \n6.4  \u2022  SWITCHED LOCAL AREA NETWORKS      503\ntoken ring, FDDI, and ATM. Some of these other technologies succeeded in captur -\ning a part of the LAN market for a few years. But since its invention in the mid-\n1970s, Ethernet has continued to evolve and grow and has held on to its dominant \nposition. Today, Ethernet is by far the most prevalent wired LAN technology, and it \nis likely to remain so for the foreseeable future. One might say that Ethernet has been \nto local area networking what the Internet has been to global networking.\nThere are many reasons for Ethernet\u2019s success. First, Ethernet was the first \nwidely deployed high-speed LAN. Because it was deployed early, network admin -\nistrators became intimately familiar with Ethernet\u2014its wonders and its quirks\u2014and \nwere reluctant to switch over to other LAN technologies when they came on the \nscene. Second, token ring, FDDI, and ATM were more complex and expensive than \nEthernet, which further discouraged network administrators from switching over. \nThird, the most compelling reason to switch to another LAN technology (such as \nFDDI or ATM) was usually the higher data rate of the new technology; however, \nEthernet always fought back, producing versions that operated at equal data rates \nor higher. Switched Ethernet was also introduced in the early 1990s, which further \nincreased its effective data rates. Finally, because Ethernet has been so popular, Eth -\nernet hardware (in particular, adapters and switches) has become a commodity and \nis remarkably cheap.\nThe original Ethernet LAN was invented in the mid-1970s by Bob Metcalfe \nand David Boggs. The original Ethernet LAN used a coaxial bus to interconnect the \nnodes. Bus topologies for Ethernet actually persisted throughout the 1980s and into \nthe mid-1990s. Ethernet with a bus topology is a broadcast LAN\u2014all transmitted \nframes travel to and are processed by all adapters connected to the bus. Recall that \nwe covered Ethernet\u2019s CSMA/CD multiple access protocol with binary exponential \nbackoff in Section 6.3.2.\nBy the late 1990s, most companies and universities had replaced their LANs \nwith", "doc_id": "359864b1-ee8c-490c-9183-79b2b4b1d321", "embedding": null, "doc_hash": "c9d0f7bad396e36d17d0d7196162870a173a428097192169ac4acc98e1285716", "extra_info": null, "node_info": {"start": 1464911, "end": 1468640}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "9b1848fd-dff1-47b8-9b1c-71f02bbe2c6c", "3": "c84269f6-2282-44f7-ad07-5eaa60951235"}}, "__type__": "1"}, "c84269f6-2282-44f7-ad07-5eaa60951235": {"__data__": {"text": "Eth -\nernet hardware (in particular, adapters and switches) has become a commodity and \nis remarkably cheap.\nThe original Ethernet LAN was invented in the mid-1970s by Bob Metcalfe \nand David Boggs. The original Ethernet LAN used a coaxial bus to interconnect the \nnodes. Bus topologies for Ethernet actually persisted throughout the 1980s and into \nthe mid-1990s. Ethernet with a bus topology is a broadcast LAN\u2014all transmitted \nframes travel to and are processed by all adapters connected to the bus. Recall that \nwe covered Ethernet\u2019s CSMA/CD multiple access protocol with binary exponential \nbackoff in Section 6.3.2.\nBy the late 1990s, most companies and universities had replaced their LANs \nwith Ethernet installations using a hub-based star topology. In such an installation \nthe hosts (and routers) are directly connected to a hub with twisted-pair copper wire. \nA hub is a physical-layer device that acts on individual bits rather than frames. \nWhen a bit, representing a zero or a one, arrives from one interface, the hub sim -\nply re-creates the bit, boosts its energy strength, and transmits the bit onto all the \nother interfaces. Thus, Ethernet with a hub-based star topology is also a broadcast \nLAN\u2014whenever a hub receives a bit from one of its interfaces, it sends a copy out \non all of its other interfaces. In particular, if a hub receives frames from two different \ninterfaces at the same time, a collision occurs and the nodes that created the frames \nmust retransmit.\nIn the early 2000s Ethernet experienced yet another major evolutionary change. \nEthernet installations continued to use a star topology, but the hub at the center was \nreplaced with a switch . We\u2019ll be examining switched Ethernet in depth later in this \nchapter. For now, we only mention that a switch is not only \u201ccollision-less\u201d but is \nalso a bona-fide store-and-forward packet switch; but unlike routers, which operate \nup through layer 3, a switch operates only up through layer 2.\n504     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\nEthernet Frame Structure\nWe can learn a lot about Ethernet by examining the Ethernet frame, which is shown \nin Figure 6.20. To give this discussion about Ethernet frames a tangible context, \nlet\u2019s consider sending an IP datagram from one host to another host, with both \nhosts on the same Ethernet LAN (for example, the Ethernet LAN in Figure\u00a0 6.17.) \n(Although the payload of our Ethernet frame is an IP datagram, we note that an \nEthernet frame can carry other network-layer packets as well.) Let the sending \nadapter, adapter A, have the MAC address AA-AA-AA-AA-AA-AA and the \nreceiving adapter, adapter B, have the MAC address BB-BB-BB-BB-BB-BB. The \nsending adapter encapsulates the IP datagram within an Ethernet frame and passes \nthe frame to the physical layer. The receiving adapter receives the frame from the \nphysical layer, extracts the IP datagram, and passes the IP datagram to the network \nlayer. In this context, let\u2019s now examine the six fields of the Ethernet frame, as \nshown in Figure 6.20.\n\u2022 Data field (46 to 1,500 bytes).  This field carries the IP datagram. The maxi -\nmum transmission unit (MTU) of Ethernet is 1,500 bytes. This means that if the \nIP datagram exceeds 1,500 bytes, then the host has to fragment the datagram , \nas discussed in Section 4.3.2. The minimum size of the data field is 46 bytes. \nThis means that if the IP datagram is less than 46 bytes, the data field has to be \n\u201cstuffed\u201d to fill it out to 46 bytes. When stuffing is used, the data passed to the \nnetwork layer contains the stuffing as well as an IP datagram. The network layer", "doc_id": "c84269f6-2282-44f7-ad07-5eaa60951235", "embedding": null, "doc_hash": "1ccca3ca148ec49976dce1e629adbd1f149e86b2ce01de3afbc00c8149fa9ad6", "extra_info": null, "node_info": {"start": 1468627, "end": 1472236}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "359864b1-ee8c-490c-9183-79b2b4b1d321", "3": "34d2673a-8782-4373-b7c5-31a1ea164786"}}, "__type__": "1"}, "34d2673a-8782-4373-b7c5-31a1ea164786": {"__data__": {"text": "\nlayer. In this context, let\u2019s now examine the six fields of the Ethernet frame, as \nshown in Figure 6.20.\n\u2022 Data field (46 to 1,500 bytes).  This field carries the IP datagram. The maxi -\nmum transmission unit (MTU) of Ethernet is 1,500 bytes. This means that if the \nIP datagram exceeds 1,500 bytes, then the host has to fragment the datagram , \nas discussed in Section 4.3.2. The minimum size of the data field is 46 bytes. \nThis means that if the IP datagram is less than 46 bytes, the data field has to be \n\u201cstuffed\u201d to fill it out to 46 bytes. When stuffing is used, the data passed to the \nnetwork layer contains the stuffing as well as an IP datagram. The network layer \nuses the length field in the IP datagram header to remove the stuffing.\n\u2022 Destination address (6 bytes).  This field contains the MAC address of the \ndestination adapter, BB-BB-BB-BB-BB-BB. When adapter B receives an Eth -\nernet frame whose destination address is either BB-BB-BB-BB-BB-BB or the \nMAC broadcast address, it passes the contents of the frame\u2019s data field to the \nnetwork layer; if it receives a frame with any other MAC address, it discards \nthe frame.\n\u2022 Source address (6 bytes).  This field contains the MAC address of the adapter that \ntransmits the frame onto the LAN, in this example, AA-AA-AA-AA-AA-AA.\n\u2022 Type field (2 bytes).  The type field permits Ethernet to multiplex network-layer \nprotocols. To understand this, we need to keep in mind that hosts can use other \nnetwork-layer protocols besides IP. In fact, a given host may support multi -\nple network-layer protocols using different protocols for different applications. Figure 6.20  \u2666 Ethernet frame structurePreamble CRCDest.\naddressSource\naddress\nTypeData\n6.4  \u2022  SWITCHED LOCAL AREA NETWORKS      505\nFor this reason, when the Ethernet frame arrives at adapter B, adapter B needs \nto know to which network-layer protocol it should pass (that is, demultiplex) \nthe contents of the data field. IP and other network-layer protocols (for exam -\nple, Novell IPX or AppleTalk) each have their own, standardized type number. \nFurthermore, the ARP protocol (discussed in the previous section) has its own \ntype number, and if the arriving frame contains an ARP packet (i.e., has a type \nfield of 0806 hexadecimal), the ARP packet will be demultiplexed up to the \nARP protocol. Note that the type field is analogous to the protocol field in the \nnetwork-layer datagram and the port-number fields in the transport-layer seg -\nment; all of these fields serve to glue a protocol at one layer to a protocol at the \nlayer above.\n\u2022 Cyclic redundancy check (CRC) (4 bytes).  As discussed in Section 6.2.3, the pur -\npose of the CRC field is to allow the receiving adapter, adapter B, to detect bit \nerrors in the frame.\n\u2022 Preamble (8 bytes).  The Ethernet frame begins with an 8-byte preamble field. \nEach of the first 7 bytes of the preamble has a value of 10101010; the last byte \nis 10101011. The first 7 bytes of the preamble serve to \u201cwake up\u201d the receiv -\ning adapters and to synchronize their clocks to that of the sender\u2019s clock. Why \nshould the clocks be out of synchronization? Keep in mind that adapter A aims \nto transmit the frame at 10 Mbps, 100 Mbps, or 1 Gbps, depending on the type \nof Ethernet LAN. However, because nothing is absolutely perfect, adapter A will \nnot transmit the frame at exactly the target rate; there will always be some drift \nfrom the target rate, a drift which is not known a priori  by the other adapters on \nthe LAN. A receiving adapter can", "doc_id": "34d2673a-8782-4373-b7c5-31a1ea164786", "embedding": null, "doc_hash": "f6a2731c13df87eb2626456fc1842a65e7d88b60239e9d2775aa11ea412830dc", "extra_info": null, "node_info": {"start": 1472282, "end": 1475809}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "c84269f6-2282-44f7-ad07-5eaa60951235", "3": "2f34f22b-77d3-44b1-9ac1-9a4496bce79e"}}, "__type__": "1"}, "2f34f22b-77d3-44b1-9ac1-9a4496bce79e": {"__data__": {"text": "8-byte preamble field. \nEach of the first 7 bytes of the preamble has a value of 10101010; the last byte \nis 10101011. The first 7 bytes of the preamble serve to \u201cwake up\u201d the receiv -\ning adapters and to synchronize their clocks to that of the sender\u2019s clock. Why \nshould the clocks be out of synchronization? Keep in mind that adapter A aims \nto transmit the frame at 10 Mbps, 100 Mbps, or 1 Gbps, depending on the type \nof Ethernet LAN. However, because nothing is absolutely perfect, adapter A will \nnot transmit the frame at exactly the target rate; there will always be some drift \nfrom the target rate, a drift which is not known a priori  by the other adapters on \nthe LAN. A receiving adapter can lock onto adapter A\u2019s clock simply by locking \nonto the bits in the first 7 bytes of the preamble. The last 2 bits of the eighth byte \nof the preamble (the first two consecutive 1s) alert adapter B that the \u201cimportant \nstuff\u201d is about to come.\nAll of the Ethernet technologies provide connectionless service to the network \nlayer. That is, when adapter A wants to send a datagram to adapter B, adapter A \nencapsulates the datagram in an Ethernet frame and sends the frame into the LAN, \nwithout first handshaking with adapter B. This layer-2 connectionless service is anal -\nogous to IP\u2019s layer-3 datagram service and UDP\u2019s layer-4 connectionless service.\nEthernet technologies provide an unreliable service to the network layer. Spe -\ncifically, when adapter B receives a frame from adapter A, it runs the frame through \na CRC check, but neither sends an acknowledgment when a frame passes the CRC \ncheck nor sends a negative acknowledgment when a frame fails the CRC check. \nWhen a frame fails the CRC check, adapter B simply discards the frame. Thus, \nadapter A has no idea whether its transmitted frame reached adapter B and passed \nthe CRC check. This lack of reliable transport (at the link layer) helps to make Eth -\nernet simple and cheap. But it also means that the stream of datagrams passed to the \nnetwork layer can have gaps.\n506     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\nIf there are gaps due to discarded Ethernet frames, does the application at \nHost B see gaps as well? As we learned in Chapter 3, this depends on whether \nthe application is using UDP or TCP. If the application is using UDP, then the \napplication in Host B will indeed see gaps in the data. On the other hand, if the \napplication is using TCP, then TCP in Host B will not acknowledge the data \ncontained in discarded frames, causing TCP in Host A to retransmit. Note that \nwhen TCP retransmits data, the data will eventually return to the Ethernet adapter \nat which it was discarded. Thus, in this sense, Ethernet does retransmit data, \nalthough Ethernet is unaware of whether it is transmitting a brand-new datagram \nwith brand-new data, or a datagram that contains data that has already been trans -\nmitted at least once.\nEthernet Technologies\nIn our discussion above, we\u2019ve referred to Ethernet as if it were a single protocol \nstandard. But in fact, Ethernet comes in many  different flavors, with somewhat bewil -\ndering acronyms such as 10BASE-T, 10BASE-2, 100BASE-T, 1000BASE-LX, BOB METCALFE AND ETHERNET\nAs a PhD student at Harvard University in the early 1970s, Bob Metcalfe worked \non the ARPAnet at MIT. During his studies, he also became exposed to Abramson\u2019s \nwork on ALOHA and random access protocols. After completing his PhD and just \nbefore beginning a job at Xerox Palo Alto Research Center (Xerox PARC), he vis -\nited Abramson and his University", "doc_id": "2f34f22b-77d3-44b1-9ac1-9a4496bce79e", "embedding": null, "doc_hash": "c35ab78a32ad362395226f80e2a234ca50b06e620f72721e725eb18de8673e53", "extra_info": null, "node_info": {"start": 1475786, "end": 1479345}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "34d2673a-8782-4373-b7c5-31a1ea164786", "3": "40658619-ddb6-4cdc-b27e-607ef48154a9"}}, "__type__": "1"}, "40658619-ddb6-4cdc-b27e-607ef48154a9": {"__data__": {"text": "our discussion above, we\u2019ve referred to Ethernet as if it were a single protocol \nstandard. But in fact, Ethernet comes in many  different flavors, with somewhat bewil -\ndering acronyms such as 10BASE-T, 10BASE-2, 100BASE-T, 1000BASE-LX, BOB METCALFE AND ETHERNET\nAs a PhD student at Harvard University in the early 1970s, Bob Metcalfe worked \non the ARPAnet at MIT. During his studies, he also became exposed to Abramson\u2019s \nwork on ALOHA and random access protocols. After completing his PhD and just \nbefore beginning a job at Xerox Palo Alto Research Center (Xerox PARC), he vis -\nited Abramson and his University of Hawaii colleagues for three months, getting a \nfirsthand look at ALOHAnet. At Xerox PARC, Metcalfe became exposed to Alto com -\nputers, which in many ways were the forerunners of the personal computers of the \n1980s. Metcalfe saw the need to network these computers in an inexpensive man -\nner. So armed with his knowledge about ARPAnet, ALOHAnet, and random access \nprotocols, Metcalfe\u2014along with colleague David Boggs\u2014invented Ethernet.\nMetcalfe and Boggs\u2019s original Ethernet ran at 2.94 Mbps and linked up to 256 \nhosts separated by up to one mile. Metcalfe and Boggs succeeded at getting most of \nthe researchers at Xerox PARC to communicate through their Alto computers. Metcalfe \nthen forged an alliance between Xerox, Digital, and Intel to establish Ethernet as a \n10 Mbps Ethernet standard, ratified by the IEEE. Xerox did not show much interest in \ncommercializing Ethernet. In 1979, Metcalfe formed his own company, 3Com, which \ndeveloped and commercialized networking technology, including Ethernet technol -\nogy. In particular, 3Com developed and marketed Ethernet cards in the early 1980s \nfor the immensely popular IBM PCs.CASE HISTORY\n\n6.4  \u2022  SWITCHED LOCAL AREA NETWORKS      507\n10GBASE-T and 40GBASE-T. These and many other Ethernet technologies have \nbeen standardized over the years by the IEEE 802.3 CSMA/CD (Ethernet) working \ngroup [IEEE 802.3 2012]. While these acronyms may appear bewildering, there is \nactually considerable order here. The first part of the acronym refers to the speed of \nthe standard: 10, 100, 1000, or 10G, for 10 Megabit (per second), 100 Megabit, Giga -\nbit, 10 Gigabit and 40 Gigibit Ethernet, respectively. \u201cBASE\u201d refers to baseband \nEthernet, meaning that the physical media only carries Ethernet traffic; almost all of \nthe 802.3 standards are for baseband Ethernet. The final part of the acronym refers to \nthe physical media itself; Ethernet is both a link-layer and a physical-layer specifica -\ntion and is carried over a variety of physical media including coaxial cable, copper \nwire, and fiber. Generally, a \u201cT\u201d refers to twisted-pair copper wires.\nHistorically, an Ethernet was initially conceived of as a segment of coaxial cable. \nThe early 10BASE-2 and 10BASE-5 standards specify 10 Mbps Ethernet over two \ntypes of coaxial cable, each limited in length to 500 meters. Longer runs could be \nobtained by using a repeater \u2014a physical-layer device that receives a signal on the \ninput side, and regenerates the signal on the output side. A coaxial cable corresponds \nnicely to our view of Ethernet as a broadcast medium\u2014all frames transmitted by one \ninterface are received at other interfaces, and Ethernet\u2019s CDMA/CD protocol nicely \nsolves the multiple access problem. Nodes simply attach to the cable, and voila , we \nhave", "doc_id": "40658619-ddb6-4cdc-b27e-607ef48154a9", "embedding": null, "doc_hash": "36219b5dea6967d1ea8686e6a9d640671f8318f79e17dd9ded83b3a251cd8632", "extra_info": null, "node_info": {"start": 1479404, "end": 1482810}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "2f34f22b-77d3-44b1-9ac1-9a4496bce79e", "3": "e8d5e261-d39b-4f61-950e-dd7e29d16458"}}, "__type__": "1"}, "e8d5e261-d39b-4f61-950e-dd7e29d16458": {"__data__": {"text": "copper wires.\nHistorically, an Ethernet was initially conceived of as a segment of coaxial cable. \nThe early 10BASE-2 and 10BASE-5 standards specify 10 Mbps Ethernet over two \ntypes of coaxial cable, each limited in length to 500 meters. Longer runs could be \nobtained by using a repeater \u2014a physical-layer device that receives a signal on the \ninput side, and regenerates the signal on the output side. A coaxial cable corresponds \nnicely to our view of Ethernet as a broadcast medium\u2014all frames transmitted by one \ninterface are received at other interfaces, and Ethernet\u2019s CDMA/CD protocol nicely \nsolves the multiple access problem. Nodes simply attach to the cable, and voila , we \nhave a local area network!\nEthernet has passed through a series of evolutionary steps over the years, and \ntoday\u2019s Ethernet is very different from the original bus-topology designs using coax -\nial cable. In most installations today, nodes are connected to a switch via point-to-\npoint segments made of twisted-pair copper wires or fiber-optic cables, as shown in \nFigures 6.15\u20136.17.\nIn the mid-1990s, Ethernet was standardized at 100 Mbps, 10 times faster than \n10 Mbps Ethernet. The original Ethernet MAC protocol and frame format were pre -\nserved, but higher-speed physical layers were defined for copper wire (100BASE-T) \nand fiber (100BASE-FX, 100BASE-SX, 100BASE-BX). Figure 6.21 shows these \ndifferent standards and the common Ethernet MAC protocol and frame format. \n100 Mbps Ethernet is limited to a 100-meter distance over twisted pair, and to \nPhysicalTransport\nNetwork\nLinkApplication\n100BASE-TX\n100BASE-T4100BASE-T2MAC protocol\nand frame format\n100BASE-SX100BASE-FX\n100BASE-BX\nFigure 6.21  \u2666  100 Mbps Ethernet standards: A common link layer, \n different physical layers\n508     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\nseveral kilometers over fiber, allowing Ethernet switches in different buildings to \nbe connected.\nGigabit Ethernet is an extension to the highly successful 10 Mbps and 100 Mbps \nEthernet standards. Offering a raw data rate of 40,000 Mbps, 40 Gigabit Ethernet \nmaintains full compatibility with the huge installed base of Ethernet equipment. The \nstandard for Gigabit Ethernet, referred to as IEEE 802.3z, does the following:\n\u2022 Uses the standard Ethernet frame format (Figure 6.20) and is backward com -\npatible with 10BASE-T and 100BASE-T technologies. This allows for easy \nintegration of Gigabit Ethernet with the existing installed base of Ethernet \nequipment.\n\u2022 Allows for point-to-point links as well as shared broadcast channels. Point-to-\npoint links use switches while broadcast channels use hubs, as described earlier. \nIn Gigabit Ethernet jargon, hubs are called buffered distributors .\n\u2022 Uses CSMA/CD for shared broadcast channels. In order to have acceptable effi -\nciency, the maximum distance between nodes must be severely restricted.\n\u2022 Allows for full-duplex operation at 40 Gbps in both directions for point-to-point \nchannels.\nInitially operating over optical fiber, Gigabit Ethernet is now able to run over cat -\negory 5 UTP cabling.\nLet\u2019s conclude our discussion of Ethernet technology by posing a question \nthat may have begun troubling you. In the days of bus topologies and hub-based \nstar topologies, Ethernet was clearly a broadcast link (as defined in Section 6.3) in \nwhich frame collisions occurred when nodes transmitted at the same time. To deal \nwith these collisions, the Ethernet standard included the CSMA/CD protocol, which \nis particularly effective for a wired broadcast LAN spanning a small geographical \nregion. But", "doc_id": "e8d5e261-d39b-4f61-950e-dd7e29d16458", "embedding": null, "doc_hash": "63d38a1084cfbffc27e0a568934733171042f38fb2dd61feefe1ee6b0aef5c14", "extra_info": null, "node_info": {"start": 1482747, "end": 1486323}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "40658619-ddb6-4cdc-b27e-607ef48154a9", "3": "6dedc4b1-6b39-4242-b676-cd93d754394b"}}, "__type__": "1"}, "6dedc4b1-6b39-4242-b676-cd93d754394b": {"__data__": {"text": "the maximum distance between nodes must be severely restricted.\n\u2022 Allows for full-duplex operation at 40 Gbps in both directions for point-to-point \nchannels.\nInitially operating over optical fiber, Gigabit Ethernet is now able to run over cat -\negory 5 UTP cabling.\nLet\u2019s conclude our discussion of Ethernet technology by posing a question \nthat may have begun troubling you. In the days of bus topologies and hub-based \nstar topologies, Ethernet was clearly a broadcast link (as defined in Section 6.3) in \nwhich frame collisions occurred when nodes transmitted at the same time. To deal \nwith these collisions, the Ethernet standard included the CSMA/CD protocol, which \nis particularly effective for a wired broadcast LAN spanning a small geographical \nregion. But if the prevalent use of Ethernet today is a switch-based star topology, \nusing store-and-forward packet switching, is there really a need anymore for an Eth -\nernet MAC protocol? As we\u2019ll see shortly, a switch coordinates its transmissions \nand never forwards more than one frame onto the same interface at any time. Fur -\nthermore, modern switches are full-duplex, so that a switch and a node can each \nsend frames to each other at the same time without interference. In other words, in \na switch-based Ethernet LAN there are no collisions and, therefore, there is no need \nfor a MAC protocol!\nAs we\u2019ve seen, today\u2019s Ethernets are very different from the original Ethernet \nconceived by Metcalfe and Boggs more than 30 years ago\u2014speeds have increased \nby three orders of magnitude, Ethernet frames are carried over a variety of media, \nswitched-Ethernets have become dominant, and now even the MAC protocol is often \nunnecessary! Is all of this really  still Ethernet? The answer, of course, is \u201cyes, by \ndefinition.\u201d It is interesting to note, however, that through all of these changes, there \n6.4  \u2022  SWITCHED LOCAL AREA NETWORKS      509\nhas indeed been one enduring constant that has remained unchanged over 30 years\u2014\nEthernet\u2019s frame format. Perhaps this then is the one true and timeless centerpiece of \nthe Ethernet standard.\n6.4.3 Link-Layer Switches\nUp until this point, we have been purposefully vague about what a switch actually \ndoes and how it works. The role of the switch is to receive incoming link-layer \nframes and forward them onto outgoing links; we\u2019ll study this forwarding function \nin detail in this subsection. We\u2019ll see that the switch itself is transparent  to the \nhosts and routers in the subnet; that is, a host/router addresses a frame to another \nhost/router (rather than addressing the frame to the switch) and happily sends the \nframe into the LAN, unaware that a switch will be receiving the frame and forward -\ning it. The rate at which frames arrive to any one of the switch\u2019s output interfaces \nmay temporarily exceed the link capacity of that interface. To accommodate this \nproblem, switch output interfaces have buffers, in much the same way that router \noutput interfaces have buffers for datagrams. Let\u2019s now take a closer look at how \nswitches operate.\nForwarding and Filtering\nFiltering  is the switch function that determines whether a frame should be for -\nwarded to some interface or should just be dropped. Forwarding  is the switch \nfunction that determines the interfaces to which a frame should be directed, and \nthen moves the frame to those interfaces. Switch filtering and forwarding are done \nwith a switch table . The switch table contains entries for some, but not necessar -\nily all, of the hosts and routers on a LAN. An entry in the switch table contains (1) \na MAC address, (2) the switch interface that leads toward that MAC address, and \n(3) the time at which the entry was placed in the table. An example switch table  \nfor the uppermost switch in Figure 6.15 is shown in Figure 6.22. This description \nof frame forwarding may sound similar to", "doc_id": "6dedc4b1-6b39-4242-b676-cd93d754394b", "embedding": null, "doc_hash": "1852f4acbad5dc855944ffbd5dab0dfb1c6deb35f097ed891aaf013990b9612c", "extra_info": null, "node_info": {"start": 1486252, "end": 1490131}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "e8d5e261-d39b-4f61-950e-dd7e29d16458", "3": "e65c9712-f26b-4c89-8fcc-4e3ce2e91970"}}, "__type__": "1"}, "e65c9712-f26b-4c89-8fcc-4e3ce2e91970": {"__data__": {"text": "and Filtering\nFiltering  is the switch function that determines whether a frame should be for -\nwarded to some interface or should just be dropped. Forwarding  is the switch \nfunction that determines the interfaces to which a frame should be directed, and \nthen moves the frame to those interfaces. Switch filtering and forwarding are done \nwith a switch table . The switch table contains entries for some, but not necessar -\nily all, of the hosts and routers on a LAN. An entry in the switch table contains (1) \na MAC address, (2) the switch interface that leads toward that MAC address, and \n(3) the time at which the entry was placed in the table. An example switch table  \nfor the uppermost switch in Figure 6.15 is shown in Figure 6.22. This description \nof frame forwarding may sound similar to our discussion of datagram forwarding \nFigure 6.22  \u2666  Portion of a switch table for the uppermost switch in  \nFigure 6.15Time Interface Address\n62-FE-F7-11-89-A3 1 9:32\n7C-BA-B2-B4-91-1 03 9:36\n.... .... ....\n510     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\nin Chapter 4 . Indeed, in our discussion of generalized forwarding in Section 4.4 , \nwe learned that many modern packet switches can be configured to forward on the \nbasis of layer-2 destination MAC addresses (i.e., function as a layer-2 switch) or \nlayer-3 IP destination addresses (i.e., function as a layer-3 router). Nonetheless,  \nwe\u2019ll make the important distinction that switches forward packets based on MAC \naddresses rather than on IP addresses. We will also see that a traditional (i.e., in a \nnon-SDN context) switch table is constructed in a very different manner from a \nrouter\u2019s forwarding table.\nTo understand how switch filtering and forwarding work, suppose a frame with \ndestination address DD-DD-DD-DD-DD-DD arrives at the switch on interface x. \nThe switch indexes its table with the MAC address DD-DD-DD-DD-DD-DD. There \nare three possible cases:\n\u2022 There is no entry in the table for DD-DD-DD-DD-DD-DD. In this case, the switch \nforwards copies of the frame to the output buffers preceding all interfaces except \nfor interface x. In other words, if there is no entry for the destination address, the \nswitch broadcasts the frame.\n\u2022 There is an entry in the table, associating DD-DD-DD-DD-DD-DD with interface \nx. In this case, the frame is coming from a LAN segment that contains adapter \nDD-DD-DD-DD-DD-DD. There being no need to forward the frame to any of \nthe other interfaces, the switch performs the filtering function by discarding the \nframe.\n\u2022 There is an entry in the table, associating DD-DD-DD-DD-DD-DD with interface \ny/uni2260.alt1x. In this case, the frame needs to be forwarded to the LAN segment attached \nto interface y. The switch performs its forwarding function by putting the frame \nin an output buffer that precedes interface y.\nLet\u2019s walk through these rules for the uppermost switch in Figure 6.15 and its \nswitch table in Figure 6.22. Suppose that a frame with destination address 62-FE-\nF7-11-89-A3 arrives at the switch from interface 1. The switch examines its table \nand sees that the destination is on the LAN segment connected to interface 1 (that \nis, Electrical Engineering). This means that the frame has already been broadcast on \nthe LAN segment that contains the destination. The switch therefore filters (that is, \ndiscards) the frame. Now suppose a frame with the same destination address arrives \nfrom interface 2. The switch again examines its table and sees that the destination \nis in the direction of interface 1; it therefore forwards the frame to the output buffer \npreceding interface 1. It should be clear from this example that as long as the switch \ntable is complete and accurate, the switch forwards frames toward destinations \nwithout", "doc_id": "e65c9712-f26b-4c89-8fcc-4e3ce2e91970", "embedding": null, "doc_hash": "4c27552c468e36986858ea93c1b0f3663c485321dc5f2994fd7e36ae4489a9ea", "extra_info": null, "node_info": {"start": 1490125, "end": 1493895}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "6dedc4b1-6b39-4242-b676-cd93d754394b", "3": "edb88a85-760f-486c-bbb0-0f8c50b8b76e"}}, "__type__": "1"}, "edb88a85-760f-486c-bbb0-0f8c50b8b76e": {"__data__": {"text": "that a frame with destination address 62-FE-\nF7-11-89-A3 arrives at the switch from interface 1. The switch examines its table \nand sees that the destination is on the LAN segment connected to interface 1 (that \nis, Electrical Engineering). This means that the frame has already been broadcast on \nthe LAN segment that contains the destination. The switch therefore filters (that is, \ndiscards) the frame. Now suppose a frame with the same destination address arrives \nfrom interface 2. The switch again examines its table and sees that the destination \nis in the direction of interface 1; it therefore forwards the frame to the output buffer \npreceding interface 1. It should be clear from this example that as long as the switch \ntable is complete and accurate, the switch forwards frames toward destinations \nwithout any broadcasting.\nIn this sense, a switch is \u201csmarter\u201d than a hub. But how does this switch table get \nconfigured in the first place? Are there link-layer equivalents to network-layer rout -\ning protocols? Or must an overworked manager manually configure the switch table?\n6.4  \u2022  SWITCHED LOCAL AREA NETWORKS      511\nSelf-Learning\nA switch has the wonderful property (particularly for the already-overworked network \nadministrator) that its table is built automatically, dynamically, and autonomously\u2014\nwithout any intervention from a network administrator or from a configuration pro -\ntocol. In other words, switches are self-learning . This capability is accomplished as \nfollows:\n 1. The switch table is initially empty.\n 2. For each incoming frame received on an interface, the switch stores in its table \n(1) the MAC address in the frame\u2019s source address field , (2) the interface from \nwhich the frame arrived, and (3) the current time. In this manner the switch \nrecords in its table the LAN segment on which the sender resides. If every \nhost in the LAN eventually sends a frame, then every host will eventually get \nrecorded in the table.\n 3. The switch deletes an address in the table if no frames are received with that \naddress as the source address after some period of time (the aging time ). In \nthis manner, if a PC is replaced by another PC (with a different adapter), the \nMAC address of the original PC will eventually be purged from the switch \ntable.\nLet\u2019s walk through the self-learning property for the uppermost switch in Fig -\nure\u00a06. 15 and its corresponding switch table in Figure 6.22. Suppose at time 9:39 a \nframe with source address 01-12-23-34-45-56 arrives from interface 2. Suppose that \nthis address is not in the switch table. Then the switch adds a new entry to the table, \nas shown in Figure 6.23.\nContinuing with this same example, suppose that the aging time for this switch \nis 60 minutes, and no frames with source address 62-FE-F7-11-89-A3 arrive to the \nswitch between 9:32 and 10:32. Then at time 10:32, the switch removes this address \nfrom its table.\nFigure 6.23  \u2666  Switch learns about the location of an adapter with address \n01-12-23-34-45-56Address Interface Time\n01-12-23-34-45-56 2 9:39\n62-FE-F7-11-89-A3 1 9:32\n7C-BA-B2-B4-91-10 3 9:36\n.... .... ....\n512     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\nSwitches are plug-and-play devices  because they require no intervention \nfrom a network administrator or user. A network administrator wanting to install \na switch need do nothing more than connect the LAN segments to the switch \ninterfaces. The administrator need not configure the switch tables at the time of \ninstallation or when a host is removed from one of the LAN segments. Switches \nare also full-duplex, meaning any switch interface can send and receive at the \nsame time.\nProperties of Link-Layer Switching\nHaving described the basic operation of a link-layer switch, let\u2019s now consider their \nfeatures and properties. We can", "doc_id": "edb88a85-760f-486c-bbb0-0f8c50b8b76e", "embedding": null, "doc_hash": "cf6cd2b55557cb1cda3808cecd2e7a1b325943ffd9a398af6e589ccf1ecc351c", "extra_info": null, "node_info": {"start": 1493868, "end": 1497680}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "e65c9712-f26b-4c89-8fcc-4e3ce2e91970", "3": "48867ffd-5ec6-4e2e-88ae-082f01349b86"}}, "__type__": "1"}, "48867ffd-5ec6-4e2e-88ae-082f01349b86": {"__data__": {"text": "9:32\n7C-BA-B2-B4-91-10 3 9:36\n.... .... ....\n512     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\nSwitches are plug-and-play devices  because they require no intervention \nfrom a network administrator or user. A network administrator wanting to install \na switch need do nothing more than connect the LAN segments to the switch \ninterfaces. The administrator need not configure the switch tables at the time of \ninstallation or when a host is removed from one of the LAN segments. Switches \nare also full-duplex, meaning any switch interface can send and receive at the \nsame time.\nProperties of Link-Layer Switching\nHaving described the basic operation of a link-layer switch, let\u2019s now consider their \nfeatures and properties. We can identify several advantages of using switches, rather \nthan broadcast links such as buses or hub-based star topologies:\n\u2022 Elimination of collisions . In a LAN built from switches (and without hubs), there \nis no wasted bandwidth due to collisions! The switches buffer frames and never \ntransmit more than one frame on a segment at any one time. As with a router, the \nmaximum aggregate throughput of a switch is the sum of all the switch interface \nrates. Thus, switches provide a significant performance improvement over LANs \nwith broadcast links.\n\u2022 Heterogeneous links . Because a switch isolates one link from another, the differ-\nent links in the LAN can operate at different speeds and can run over different \nmedia. For example, the uppermost switch in Figure 6.15 might have three1 Gbps \n1000BASE-T copper links, two 100 Mbps 100BASE-FX fiber links, and one \n100BASE-T copper link. Thus, a switch is ideal for mixing legacy equipment \nwith new equipment.\n\u2022 Management . In addition to providing enhanced security (see sidebar on Focus on \nSecurity), a switch also eases network management. For example, if an adapter \nmalfunctions and continually sends Ethernet frames (called a jabbering adapter), \na switch can detect the problem and internally disconnect the malfunctioning \nadapter. With this feature, the network administrator need not get out of bed and \ndrive back to work in order to correct the problem. Similarly, a cable cut discon -\nnects only that host that was using the cut cable to connect to the switch. In the \ndays of coaxial cable, many a network manager spent hours \u201cwalking the line\u201d (or \nmore accurately, \u201ccrawling the floor\u201d) to find the cable break that brought down \nthe entire network. Switches also gather statistics on bandwidth usage, collision \nrates, and traffic types, and make this information available to the network man -\nager. This information can be used to debug and correct problems, and to plan \nhow the LAN should evolve in the future. Researchers are exploring adding yet \nmore management functionality into Ethernet LANs in prototype deployments \n[Casado 2007; Koponen 2011].\n6.4  \u2022  SWITCHED LOCAL AREA NETWORKS      513\nSwitches Versus Routers\nAs we learned in Chapter 4, routers are store-and-forward packet switches that for -\nward packets using network-layer addresses. Although a switch is also a store-and-\nforward packet switch, it is fundamentally different from a router in that it forwards \npackets using MAC addresses. Whereas a router is a layer-3 packet switch, a switch \nis a layer-2 packet switch. Recall, however, that we learned in Section 4.4 that mod -\nern switches using the \u201cmatch plus action\u201d operation can be used to forward a layer-2 \nframe based on the frame's destination MAC address, as well as a layer-3 datagram \nusing the datagram's destination IP address. Indeed, we saw that switches using the \nOpenFlow standard can perform generalized packet forwarding based on any of \neleven different frame, datagram, and transport-layer header fields.\nEven though switches and routers are fundamentally different, network admin -\nistrators must often choose between them when installing an interconnection device. \nFor example, for the network", "doc_id": "48867ffd-5ec6-4e2e-88ae-082f01349b86", "embedding": null, "doc_hash": "6886b5cf5d3ea3339576879c82d136272762d567e0c7efacee1b7bc8ff76ac62", "extra_info": null, "node_info": {"start": 1497753, "end": 1501703}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "edb88a85-760f-486c-bbb0-0f8c50b8b76e", "3": "e027283d-e8e1-47f5-8a5a-8a87196fc7dd"}}, "__type__": "1"}, "e027283d-e8e1-47f5-8a5a-8a87196fc7dd": {"__data__": {"text": "different from a router in that it forwards \npackets using MAC addresses. Whereas a router is a layer-3 packet switch, a switch \nis a layer-2 packet switch. Recall, however, that we learned in Section 4.4 that mod -\nern switches using the \u201cmatch plus action\u201d operation can be used to forward a layer-2 \nframe based on the frame's destination MAC address, as well as a layer-3 datagram \nusing the datagram's destination IP address. Indeed, we saw that switches using the \nOpenFlow standard can perform generalized packet forwarding based on any of \neleven different frame, datagram, and transport-layer header fields.\nEven though switches and routers are fundamentally different, network admin -\nistrators must often choose between them when installing an interconnection device. \nFor example, for the network in Figure 6.15, the network administrator could just as \neasily have used a router instead of a switch to connect the department LANs, servers, \nand internet gateway router. Indeed, a router would permit interdepartmental commu -\nnication without creating collisions. Given that both switches and routers are candi -\ndates for interconnection devices, what are the pros and cons of the two approaches?SNIFFING A SWITCHED LAN: SWITCH POISONING\nWhen a host is connected to a switch, it typically only receives frames that are intended \nfor it. For example, consider a switched LAN in Figure 6.17. When host A sends a frame \nto host B, and there is an entry for host B in the switch table, then the switch will forward \nthe frame only to host B. If host C happens to be running a sniffer, host C will not be able \nto sniff this A-to-B frame. Thus, in a switched-LAN environment (in contrast to a broadcast \nlink environment such as 802.11 LANs or hub\u2013based Ethernet LANs), it is more difficult \nfor an attacker to sniff frames. However , because the switch broadcasts frames that have \ndestination addresses that are not in the switch table, the sniffer at C can still sniff some \nframes that are not intended for C. Furthermore, a sniffer will be able sniff all Ethernet \nbroadcast frames with broadcast destination address FF\u2013FF\u2013FF\u2013FF\u2013FF\u2013FF. A well-known \nattack against a switch, called switch poisoning , is to send tons of packets to the \nswitch with many different bogus source MAC addresses, thereby filling the switch table \nwith bogus entries and leaving no room for the MAC addresses of the legitimate hosts. \nThis causes the switch to broadcast most frames, which can then be picked up by the \nsniffer [Skoudis 2006]. As this attack is rather involved even for a sophisticated attacker, \nswitches are significantly less vulnerable to sniffing than are hubs and wireless LANs.FOCUS ON SECURITY\n\n514     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\nFirst consider the pros and cons of switches. As mentioned above, switches are \nplug-and-play, a property that is cherished by all the overworked network adminis -\ntrators of the world. Switches can also have relatively high filtering and forwarding \nrates\u2014as shown in Figure 6.24, switches have to process frames only up through \nlayer 2, whereas routers have to process datagrams up through layer 3. On the other \nhand, to prevent the cycling of broadcast frames, the active topology of a switched \nnetwork is restricted to a spanning tree. Also, a large switched network would require \nlarge ARP tables in the hosts and routers and would generate substantial ARP traffic \nand processing. Furthermore, switches are susceptible to broadcast storms\u2014if one \nhost goes haywire and transmits an endless stream of Ethernet broadcast frames, the \nswitches will forward all of these frames, causing the entire network to collapse.\nNow consider the pros and cons of routers. Because network addressing is often \nhierarchical (and not flat, as is MAC addressing), packets do not normally cycle \nthrough routers even when the network has redundant paths. (However, packets can \ncycle when router", "doc_id": "e027283d-e8e1-47f5-8a5a-8a87196fc7dd", "embedding": null, "doc_hash": "40361b1637847acae44cfbc583ae679e066ff59643a794a41da23da1b3fec6dd", "extra_info": null, "node_info": {"start": 1501635, "end": 1505581}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "48867ffd-5ec6-4e2e-88ae-082f01349b86", "3": "35366f03-fae4-410d-ac6e-69cec9a64594"}}, "__type__": "1"}, "35366f03-fae4-410d-ac6e-69cec9a64594": {"__data__": {"text": "up through layer 3. On the other \nhand, to prevent the cycling of broadcast frames, the active topology of a switched \nnetwork is restricted to a spanning tree. Also, a large switched network would require \nlarge ARP tables in the hosts and routers and would generate substantial ARP traffic \nand processing. Furthermore, switches are susceptible to broadcast storms\u2014if one \nhost goes haywire and transmits an endless stream of Ethernet broadcast frames, the \nswitches will forward all of these frames, causing the entire network to collapse.\nNow consider the pros and cons of routers. Because network addressing is often \nhierarchical (and not flat, as is MAC addressing), packets do not normally cycle \nthrough routers even when the network has redundant paths. (However, packets can \ncycle when router tables are misconfigured; but as we learned in Chapter 4, IP uses \na special datagram header field to limit the cycling.) Thus, packets are not restricted \nto a spanning tree and can use the best path between source and destination. Because \nrouters do not have the spanning tree restriction, they have allowed the Internet to be \nbuilt with a rich topology that includes, for example, multiple active links between \nEurope and North America. Another feature of routers is that they provide firewall \nprotection against layer-2 broadcast storms. Perhaps the most significant drawback \nof routers, though, is that they are not plug-and-play\u2014they and the hosts that connect \nto them need their IP addresses to be configured. Also, routers often have a larger \nper-packet processing time than switches, because they have to process up through \nthe layer-3 fields. Finally, there are two different ways to pronounce the word router , \neither as \u201crootor\u201d or as \u201crowter,\u201d and people waste a lot of time arguing over the \nproper pronunciation [Perlman 1999].\nGiven that both switches and routers have their pros and cons (as summarized in \nTable 6. 1), when should an institutional network (for example, a university campus Figure 6.24  \u2666 Packet processing in switches, routers, and hostsHost\nApplicationHost\nTransport\nNetwork\nLink\nPhysicalLink\nPhysicalNetworkSwitch Router\nLink\nPhysicalApplication\nTransport\nNetwork\nLink\nPhysical\n6.4  \u2022  SWITCHED LOCAL AREA NETWORKS      515\nnetwork or a corporate campus network) use switches, and when should it use rout -\ners? Typically, small networks consisting of a few hundred hosts have a few LAN \nsegments. Switches suffice for these small networks, as they localize traffic and \nincrease aggregate throughput without requiring any configuration of IP addresses. \nBut larger networks consisting of thousands of hosts typically include routers within \nthe network (in addition to switches). The routers provide a more robust isolation of \ntraffic, control broadcast storms, and use more \u201cintelligent\u201d routes among the hosts \nin the network.\nFor more discussion of the pros and cons of switched versus routed networks, \nas well as a discussion of how switched LAN technology can be extended to accom -\nmodate two orders of magnitude more hosts than today\u2019s Ethernets, see [Meyers \n2004; Kim 2008].\n6.4.4 Virtual Local Area Networks (VLANs)\nIn our earlier discussion of Figure 6.15, we noted that modern institutional LANs \nare often configured hierarchically, with each workgroup (department) having its \nown switched LAN connected to the switched LANs of other groups via a switch \nhierarchy. While such a configuration works well in an ideal world, the real world \nis often far from ideal. Three drawbacks can be identified in the configuration in \nFigure 6.15:\n\u2022 Lack of traffic isolation.  Although the hierarchy localizes group traffic to within \na single switch, broadcast traffic (e.g., frames carrying ARP and DHCP mes -\nsages or frames whose destination has not yet been learned by a self-learning \nswitch) must still traverse the entire institutional network. Limiting the scope of \nsuch broadcast traffic would improve LAN performance. Perhaps more impor", "doc_id": "35366f03-fae4-410d-ac6e-69cec9a64594", "embedding": null, "doc_hash": "b86470644e0a47fbfb5d1e7393229d24954a3086d5cfa5e4faf7870774f06271", "extra_info": null, "node_info": {"start": 1505588, "end": 1509593}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "e027283d-e8e1-47f5-8a5a-8a87196fc7dd", "3": "b6f5e7fb-39af-4871-80ca-80e92e154510"}}, "__type__": "1"}, "b6f5e7fb-39af-4871-80ca-80e92e154510": {"__data__": {"text": "discussion of Figure 6.15, we noted that modern institutional LANs \nare often configured hierarchically, with each workgroup (department) having its \nown switched LAN connected to the switched LANs of other groups via a switch \nhierarchy. While such a configuration works well in an ideal world, the real world \nis often far from ideal. Three drawbacks can be identified in the configuration in \nFigure 6.15:\n\u2022 Lack of traffic isolation.  Although the hierarchy localizes group traffic to within \na single switch, broadcast traffic (e.g., frames carrying ARP and DHCP mes -\nsages or frames whose destination has not yet been learned by a self-learning \nswitch) must still traverse the entire institutional network. Limiting the scope of \nsuch broadcast traffic would improve LAN performance. Perhaps more impor -\ntantly, it also may be desirable to limit LAN broadcast traffic for security/privacy \nreasons. For example, if one group contains the company\u2019s executive manage -\nment team and another group contains disgruntled employees running Wireshark \npacket sniffers, the network manager may well prefer that the executives\u2019 traffic \nnever even reaches employee hosts. This type of isolation could be provided by Table 6.1  \u2666  Comparison of the typical features of popular interconnection \ndevicesHubs Routers Switches\nTraffic isolation No Yes Yes\nPlug and play Yes No Yes\nOptimal routing No Yes No\n516     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\nreplacing the center switch in Figure 6.15 with a router. We\u2019ll see shortly that this \nisolation also can be achieved via a switched (layer 2) solution.\n\u2022 Inefficient use of switches.  If instead of three groups, the institution had 10 \ngroups, then 10 first-level switches would be required. If each group were \nsmall, say less than 10 people, then a single 96-port switch would likely be large \nenough to accommodate everyone, but this single switch would not provide \ntraffic isolation.\n\u2022 Managing users.  If an employee moves between groups, the physical cabling \nmust be changed to connect the employee to a different switch in Figure 6.15. \nEmployees belonging to two groups make the problem even harder.\nFortunately, each of these difficulties can be handled by a switch that supports \nvirtual local area networks  (VLANs ). As the name suggests, a switch that sup -\nports VLANs allows multiple virtual  local area networks to be defined over a sin -\ngle physical  local area network infrastructure. Hosts within a VLAN communicate \nwith each other as if they (and no other hosts) were connected to the switch. In a \nport-based VLAN, the switch\u2019s ports (interfaces) are divided into groups by the \nnetwork manager. Each group constitutes a VLAN, with the ports in each VLAN \nforming a broadcast domain (i.e., broadcast traffic from one port can only reach \nother ports in the group). Figure 6.25 shows a single switch with 16 ports. Ports 2 \nto 8 belong to the EE VLAN, while ports 9 to 15 belong to the CS VLAN (ports 1 \nand 16 are unassigned). This VLAN solves all of the difficulties noted above\u2014EE \nand CS VLAN frames are isolated from each other, the two switches in Figure 6.15 \nhave been replaced by a single switch, and if the user at switch port 8 joins the CS \nDepartment, the network operator simply reconfigures the VLAN software so that \nport 8 is now associated with the CS VLAN. One can easily imagine how the VLAN \nswitch is configured and operates\u2014the network manager declares a port to belong \nFigure 6.25  \u2666 A single switch with two configured VLANs1\nElectrical Engineering\n(VLAN ports 2\u20138)Computer Science\n(VLAN ports 9\u201315)91 5\n24 81 01 6\n6.4  \u2022  SWITCHED LOCAL AREA NETWORKS      517\nto a given VLAN (with undeclared ports belonging to a default VLAN) using switch \nmanagement software, a table of port-to-VLAN mappings is maintained within the \nswitch;", "doc_id": "b6f5e7fb-39af-4871-80ca-80e92e154510", "embedding": null, "doc_hash": "ed39c5c2c82a3a4236f164d2d14335ff9bcd3187f76b7c688051684b60ccb61d", "extra_info": null, "node_info": {"start": 1509587, "end": 1513419}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "35366f03-fae4-410d-ac6e-69cec9a64594", "3": "30b7fd33-547e-441e-8b3d-bd315c7d3c99"}}, "__type__": "1"}, "30b7fd33-547e-441e-8b3d-bd315c7d3c99": {"__data__": {"text": "been replaced by a single switch, and if the user at switch port 8 joins the CS \nDepartment, the network operator simply reconfigures the VLAN software so that \nport 8 is now associated with the CS VLAN. One can easily imagine how the VLAN \nswitch is configured and operates\u2014the network manager declares a port to belong \nFigure 6.25  \u2666 A single switch with two configured VLANs1\nElectrical Engineering\n(VLAN ports 2\u20138)Computer Science\n(VLAN ports 9\u201315)91 5\n24 81 01 6\n6.4  \u2022  SWITCHED LOCAL AREA NETWORKS      517\nto a given VLAN (with undeclared ports belonging to a default VLAN) using switch \nmanagement software, a table of port-to-VLAN mappings is maintained within the \nswitch; and switch hardware only delivers frames between ports belonging to the \nsame VLAN.\nBut by completely isolating the two VLANs, we have introduced a new dif -\nficulty! How can traffic from the EE Department be sent to the CS Department? \nOne way to handle this would be to connect a VLAN switch port (e.g., port 1 in Fig -\nure\u00a06. 25) to an external router and configure that port to belong both the EE and CS \nVLANs. In this case, even though the EE and CS departments share the same physi -\ncal switch, the logical configuration would look as if the EE and CS departments \nhad separate switches connected via a router. An IP datagram going from the EE to \nthe CS department would first cross the EE VLAN to reach the router and then be \nforwarded by the router back over the CS VLAN to the CS host. Fortunately, switch \nvendors make such configurations easy for the network manager by building a single \ndevice that contains both a VLAN switch and a router, so a separate external router \nis not needed. A homework problem at the end of the chapter explores this scenario \nin more detail.\nReturning again to Figure 6.15, let\u2019s now suppose that rather than having a sepa -\nrate Computer Engineering department, some EE and CS faculty are housed in a \nseparate building, where (of course!) they need network access, and (of course!) \nthey\u2019d like to be part of their department\u2019s VLAN. Figure 6.26 shows a second 8-port \nswitch, where the switch ports have been defined as belonging to the EE or the \nCS VLAN, as needed. But how should these two switches be interconnected? One \neasy solution would be to define a port belonging to the CS VLAN on each switch \n(similarly for the EE VLAN) and to connect these ports to each other, as shown in \nFigure\u00a06. 26(a). This solution doesn\u2019t scale, however, since N VLANS would require \nN ports on each switch simply to interconnect the two switches.\nA more scalable approach to interconnecting VLAN switches is known as \nVLAN trunking . In the VLAN trunking approach shown in Figure 6.26(b), a spe -\ncial port on each switch (port 16 on the left switch and port 1 on the right switch) is \nconfigured as a trunk port to interconnect the two VLAN switches. The trunk port \nbelongs to all VLANs, and frames sent to any VLAN are forwarded over the trunk \nlink to the other switch. But this raises yet another question: How does a switch know \nthat a frame arriving on a trunk port belongs to a particular VLAN? The IEEE has \ndefined an extended Ethernet frame format, 802.1Q, for frames crossing a VLAN \ntrunk. As shown in Figure 6.27, the 802.1Q frame consists of the standard Ethernet \nframe with a four-byte VLAN tag  added into the header that carries the identity of \nthe VLAN to which the frame belongs. The VLAN tag is added into a frame by the \nswitch at the sending side of a VLAN trunk, parsed, and removed by the switch at \nthe receiving side of the trunk. The VLAN tag itself consists of a 2-byte Tag Protocol \nIdentifier (TPID) field (with a fixed hexadecimal value of 81-00), a", "doc_id": "30b7fd33-547e-441e-8b3d-bd315c7d3c99", "embedding": null, "doc_hash": "1d1e038339a103b34868acfd34595e23bf85452140068af7dd1cd7c4dae6925a", "extra_info": null, "node_info": {"start": 1513537, "end": 1517247}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "b6f5e7fb-39af-4871-80ca-80e92e154510", "3": "9ecfa0cf-c386-4a24-966a-ac55779dbae0"}}, "__type__": "1"}, "9ecfa0cf-c386-4a24-966a-ac55779dbae0": {"__data__": {"text": "question: How does a switch know \nthat a frame arriving on a trunk port belongs to a particular VLAN? The IEEE has \ndefined an extended Ethernet frame format, 802.1Q, for frames crossing a VLAN \ntrunk. As shown in Figure 6.27, the 802.1Q frame consists of the standard Ethernet \nframe with a four-byte VLAN tag  added into the header that carries the identity of \nthe VLAN to which the frame belongs. The VLAN tag is added into a frame by the \nswitch at the sending side of a VLAN trunk, parsed, and removed by the switch at \nthe receiving side of the trunk. The VLAN tag itself consists of a 2-byte Tag Protocol \nIdentifier (TPID) field (with a fixed hexadecimal value of 81-00), a 2-byte Tag Con -\ntrol Information field that contains a 12-bit VLAN identifier field, and a 3-bit priority \nfield that is similar in intent to the IP datagram TOS field.\n518     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\nFigure 6.26  \u2666  Connecting two VLAN switches with two VLANs:  \n(a) two cables (b) trunked1\n161\n8\n1\nElectrical Engineering\n(VLAN ports 2\u20138)\nb.a.\nElectrical Engineering\n(VLAN ports 2, 3, 6)Trunk\nlink\nComputer Science\n(VLAN ports 9\u201315)91 5\n24 81 01 61\n23\n45\n687\nComputer Science\n(VLAN ports 4, 5, 7)\nFigure 6.27  \u2666  Original Ethernet frame (top), 802.1Q-tagged Ethernet \nVLAN frame (below)Preamble CRCDest.\naddressSource\naddressType\nData\nPreamble CRC'Dest.\naddressSource\naddressType\nTag Control Information\nTag Protocol Identi\ufb01erRecomputed\nCRTData\n6.5  \u2022  LINK VIRTUALIZATION: A NETWORK AS A LINK LAYER      519\nIn this discussion, we\u2019ve only briefly touched on VLANs and have focused on port-\nbased VLANs. We should also mention that VLANs can be defined in several other \nways. In MAC-based VLANs, the network manager specifies the set of MAC addresses \nthat belong to each VLAN; whenever a device attaches to a port, the port is connected \ninto the appropriate VLAN based on the MAC address of the device. VLANs can also \nbe defined based on network-layer protocols (e.g., IPv4, IPv6, or Appletalk) and other \ncriteria. It is also possible for VLANs to be extended across IP routers, allowing islands \nof LANs to be connected together to form a single VLAN that could span the globe  \n[Yu 2011]. See the 802.1Q standard [IEEE 802.1q 2005] for more details.\n6.5 Link Virtualization: A Network as a Link \nLayer\nBecause this chapter concerns link-layer protocols, and given that we\u2019re now nearing \nthe chapter\u2019s end, let\u2019s reflect on how our understanding of the term link has evolved. \nWe began this chapter by viewing the link as a physical wire connecting two com -\nmunicating hosts. In studying multiple access protocols, we saw that multiple hosts \ncould be connected by a shared wire and that the \u201cwire\u201d connecting the hosts could \nbe radio spectra or other media. This led us to consider the link a bit more abstractly \nas a channel, rather than as a wire. In our study of Ethernet LANs (Figure 6.15) \nwe saw that the interconnecting media could actually be a rather complex switched \ninfrastructure. Throughout this evolution, however, the hosts themselves maintained \nthe view that the interconnecting medium was simply a link-layer channel connect -\ning two or more hosts. We saw, for example, that an Ethernet host can be blissfully \nunaware of whether it is connected to other LAN hosts by a single short LAN seg -\nment (Figure 6.17) or by a geographically dispersed switched LAN (Figure", "doc_id": "9ecfa0cf-c386-4a24-966a-ac55779dbae0", "embedding": null, "doc_hash": "2669f60c1db7399f9e270149e510cfe10f3f0d123c15e5ddd06ebceeba4b5bdb", "extra_info": null, "node_info": {"start": 1517259, "end": 1520657}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "30b7fd33-547e-441e-8b3d-bd315c7d3c99", "3": "05976454-c5fb-4282-acbb-e2f5edb17ac2"}}, "__type__": "1"}, "05976454-c5fb-4282-acbb-e2f5edb17ac2": {"__data__": {"text": "we saw that multiple hosts \ncould be connected by a shared wire and that the \u201cwire\u201d connecting the hosts could \nbe radio spectra or other media. This led us to consider the link a bit more abstractly \nas a channel, rather than as a wire. In our study of Ethernet LANs (Figure 6.15) \nwe saw that the interconnecting media could actually be a rather complex switched \ninfrastructure. Throughout this evolution, however, the hosts themselves maintained \nthe view that the interconnecting medium was simply a link-layer channel connect -\ning two or more hosts. We saw, for example, that an Ethernet host can be blissfully \nunaware of whether it is connected to other LAN hosts by a single short LAN seg -\nment (Figure 6.17) or by a geographically dispersed switched LAN (Figure 6.15) or \nby a VLAN (Figure 6.26).\nIn the case of a dialup modem connection between two hosts, the link connect -\ning the two hosts is actually the telephone network\u2014a logically separate, global tel -\necommunications network with its own switches, links, and protocol stacks for data \ntransfer and signaling. From the Internet link-layer point of view, however, the dial-\nup connection through the telephone network is viewed as a simple \u201cwire.\u201d In this \nsense, the Internet virtualizes the telephone network, viewing the telephone network \nas a link-layer technology providing link-layer connectivity between two Internet \nhosts. An  overlay network similarly views the Internet as a means for providing con -\nnectivity between overlay nodes, seeking to overlay the Internet in the same way that \nthe Internet overlays the telephone network.\nIn this section, we\u2019ll consider Multiprotocol Label Switching (MPLS) net -\nworks. Unlike the circuit-switched telephone network, MPLS is a packet-switched, \n520     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\nvirtual-circuit network in its own right. It has its own packet formats and forwarding \nbehaviors. Thus, from a pedagogical viewpoint, a discussion of MPLS fits well into a \nstudy of either the network layer or the link layer. From an Internet viewpoint, how -\never, we can consider MPLS, like the telephone network and switched- Ethernets, \nas a link-layer technology that serves to interconnect IP devices. Thus, we\u2019ll con -\nsider MPLS in our discussion of the link layer. Frame-relay and ATM networks \ncan also be used to interconnect IP devices, though they represent a slightly older \n(but still deployed) technology and will not be covered here; see the very readable \nbook [Goralski 1999] for details. Our treatment of MPLS will be necessarily brief, \nas entire books could be (and have been) written on these networks. We recommend \n[Davie 2000] for details on MPLS. We\u2019ll focus here primarily on how MPLS  servers \ninterconnect to IP devices, although we\u2019ll dive a bit deeper into the underlying tech -\nnologies as well.\n6.5.1 Multiprotocol Label Switching (MPLS)\nMultiprotocol Label Switching (MPLS) evolved from a number of industry efforts \nin the mid-to-late 1990s to improve the forwarding speed of IP routers by adopting a \nkey concept from the world of virtual-circuit networks: a fixed-length label. The goal \nwas not to abandon the destination-based IP datagram-forwarding infrastructure for \none based on fixed-length labels and virtual circuits, but to augment it by selectively \nlabeling datagrams and allowing routers to forward datagrams based on fixed-length \nlabels (rather than destination IP addresses) when possible. Importantly, these tech -\nniques work hand-in-hand with IP, using IP addressing and routing. The IETF uni -\nfied these efforts in the MPLS protocol [RFC 3031, RFC 3032], effectively blending \nVC techniques into a routed datagram network.\nLet\u2019s begin our study of MPLS by considering the format of a", "doc_id": "05976454-c5fb-4282-acbb-e2f5edb17ac2", "embedding": null, "doc_hash": "3ce8b3fa6bb737304467ef4c4344eadf8e8561d9f055d8fc86c717df41402c57", "extra_info": null, "node_info": {"start": 1520573, "end": 1524339}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "9ecfa0cf-c386-4a24-966a-ac55779dbae0", "3": "d331462a-0d87-4e92-a441-c491be46c143"}}, "__type__": "1"}, "d331462a-0d87-4e92-a441-c491be46c143": {"__data__": {"text": "speed of IP routers by adopting a \nkey concept from the world of virtual-circuit networks: a fixed-length label. The goal \nwas not to abandon the destination-based IP datagram-forwarding infrastructure for \none based on fixed-length labels and virtual circuits, but to augment it by selectively \nlabeling datagrams and allowing routers to forward datagrams based on fixed-length \nlabels (rather than destination IP addresses) when possible. Importantly, these tech -\nniques work hand-in-hand with IP, using IP addressing and routing. The IETF uni -\nfied these efforts in the MPLS protocol [RFC 3031, RFC 3032], effectively blending \nVC techniques into a routed datagram network.\nLet\u2019s begin our study of MPLS by considering the format of a link-layer frame \nthat is handled by an MPLS-capable router. Figure 6.28 shows that a link-layer \nframe transmitted between MPLS-capable devices has a small MPLS header added \nbetween the layer-2 (e.g., Ethernet) header and layer-3 (i.e., IP) header. RFC 3032 \ndefines the format of the MPLS header for such links; headers are defined for ATM \nand frame-relayed networks as well in other RFCs. Among the fields in the MPLS \nPPP or Ethernet\nheaderMPLS header IP header Remainder of link-layer frame\nLabel Exp S TTL\nFigure 6.28  \u2666  MPLS header: Located between link- and network-layer \nheaders\n6.5  \u2022  LINK VIRTUALIZATION: A NETWORK AS A LINK LAYER      521\nheader are the label, 3 bits reserved for experimental use, a single S bit, which is used \nto indicate the end of a series of \u201cstacked\u201d MPLS headers (an advanced topic that \nwe\u2019ll not cover here), and a time-to-live field.\nIt\u2019s immediately evident from Figure 6.28 that an MPLS-enhanced frame can \nonly be sent between routers that are both MPLS capable (since a non-MPLS-capable \nrouter would be quite confused when it found an MPLS header where it had expected \nto find the IP header!). An MPLS-capable router is often referred to as a label-\nswitched router , since it forwards an MPLS frame by looking up the MPLS label \nin its forwarding table and then immediately passing the datagram to the appropriate \noutput interface. Thus, the MPLS-capable router need not extract the destination IP \naddress and perform a lookup of the longest prefix match in the forwarding table. But \nhow does a router know if its neighbor is indeed MPLS capable, and how does a router \nknow what label to associate with the given IP destination? To answer these questions, \nwe\u2019ll need to take a look at the interaction among a group of MPLS-capable routers.\nIn the example in Figure 6.29, routers R1 through R4 are MPLS capable. R5 \nand R6 are standard IP routers. R1 has advertised to R2 and R3 that it (R1) can route \nto destination A, and that a received frame with MPLS label 6 will be forwarded to \ndestination A. Router R3 has advertised to router R4 that it can route to destinations \nA and D, and that incoming frames with MPLS labels 10 and 12, respectively, will be \nswitched toward those destinations. Router R2 has also advertised to router R4 that \nit (R2) can reach destination A, and that a received frame with MPLS label 8 will be \nswitched toward A. Note that router R4 is now in the interesting position of having \nFigure 6.29  \u2666 MPLS-enhanced forwardingR4in\nlabelout\nlabel\n10\n12\n8A\nD\nA0\n0\n1destout\ninterface\nR6\nR5R3\nR2D\nA0\n00110\nR1in\nlabelout\nlabel\n6\n9A\nD1\n010\n12destout\ninterface\nin\nlabelout\nlabel\n\u2013A 0", "doc_id": "d331462a-0d87-4e92-a441-c491be46c143", "embedding": null, "doc_hash": "bd96f86ef43a29f2286005648432d68b73d38ed2ef357c788df3aadaad91378b", "extra_info": null, "node_info": {"start": 1524354, "end": 1527755}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "05976454-c5fb-4282-acbb-e2f5edb17ac2", "3": "b5a2cb58-09fe-48df-8472-319a94e92dc6"}}, "__type__": "1"}, "b5a2cb58-09fe-48df-8472-319a94e92dc6": {"__data__": {"text": "R4 that it can route to destinations \nA and D, and that incoming frames with MPLS labels 10 and 12, respectively, will be \nswitched toward those destinations. Router R2 has also advertised to router R4 that \nit (R2) can reach destination A, and that a received frame with MPLS label 8 will be \nswitched toward A. Note that router R4 is now in the interesting position of having \nFigure 6.29  \u2666 MPLS-enhanced forwardingR4in\nlabelout\nlabel\n10\n12\n8A\nD\nA0\n0\n1destout\ninterface\nR6\nR5R3\nR2D\nA0\n00110\nR1in\nlabelout\nlabel\n6\n9A\nD1\n010\n12destout\ninterface\nin\nlabelout\nlabel\n\u2013A 0 6destout\ninterfacein\nlabelout\nlabel\n6A 0 8destout\ninterface\n522     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\ntwo MPLS paths to reach A: via interface 0 with outbound MPLS label 10, and via \ninterface 1 with an MPLS label of 8. The broad picture painted in Figure 6.29 is \nthat IP devices R5, R6, A, and D are connected together via an MPLS infrastructure \n(MPLS-capable routers R1, R2, R3, and R4) in much the same way that a switched \nLAN or an ATM network can connect together IP devices. And like a switched \nLAN or ATM network, the MPLS-capable routers R1 through R4 do so without ever \ntouching the IP header of a packet .\nIn our discussion above, we\u2019ve not specified the specific protocol used to dis -\ntribute labels among the MPLS-capable routers, as the details of this signaling are \nwell beyond the scope of this book. We note, however, that the IETF working group \non MPLS has specified in [RFC 3468] that an extension of the RSVP protocol, \nknown as RSVP-TE [RFC 3209], will be the focus of its efforts for MPLS signaling. \nWe\u2019ve also not discussed how MPLS actually computes the paths for packets among \nMPLS capable routers, nor how it gathers link-state information (e.g., amount of link \nbandwidth unreserved by MPLS) to use in these path computations. Existing link-\nstate routing algorithms (e.g., OSPF) have been extended to flood this information to \nMPLS-capable routers. Interestingly, the actual path computation algorithms are not \nstandardized, and are currently vendor-specific.\nThus far, the emphasis of our discussion of MPLS has been on the fact that \nMPLS performs switching based on labels, without needing to consider the IP \naddress of a packet. The true advantages of MPLS and the reason for current interest \nin MPLS, however, lie not in the potential increases in switching speeds, but rather in \nthe new traffic management capabilities that MPLS enables. As noted above, R4 has \ntwo MPLS paths to A. If forwarding were performed up at the IP layer on the basis \nof IP address, the IP routing protocols we studied in Chapter 5 would specify only \na single, least-cost path to A. Thus, MPLS provides the ability to forward packets \nalong routes that would not be possible using standard IP routing protocols. This is \none simple form of traffic engineering  using MPLS [RFC 3346; RFC 3272; RFC \n2702; Xiao 2000], in which a network operator can override normal IP routing and \nforce some of the traffic headed toward a given destination along one path, and other \ntraffic destined toward the same destination along another path (whether for policy, \nperformance, or some other reason).\nIt is also possible to use MPLS for many other purposes as well. It can be used \nto perform fast restoration of MPLS forwarding paths, e.g., to reroute traffic over a \nprecomputed failover path in response to link failure [Kar 2000; Huang 2002; RFC", "doc_id": "b5a2cb58-09fe-48df-8472-319a94e92dc6", "embedding": null, "doc_hash": "4584976b3eb43343f4d865b7e76a3f6d3ba38d87aceeed301114c4e0e073ff01", "extra_info": null, "node_info": {"start": 1527892, "end": 1531331}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "d331462a-0d87-4e92-a441-c491be46c143", "3": "661dff1c-7e03-4db3-8a44-2db282d96005"}}, "__type__": "1"}, "661dff1c-7e03-4db3-8a44-2db282d96005": {"__data__": {"text": "A. Thus, MPLS provides the ability to forward packets \nalong routes that would not be possible using standard IP routing protocols. This is \none simple form of traffic engineering  using MPLS [RFC 3346; RFC 3272; RFC \n2702; Xiao 2000], in which a network operator can override normal IP routing and \nforce some of the traffic headed toward a given destination along one path, and other \ntraffic destined toward the same destination along another path (whether for policy, \nperformance, or some other reason).\nIt is also possible to use MPLS for many other purposes as well. It can be used \nto perform fast restoration of MPLS forwarding paths, e.g., to reroute traffic over a \nprecomputed failover path in response to link failure [Kar 2000; Huang 2002; RFC \n3469]. Finally, we note that MPLS can, and has, been used to implement so-called \n virtual private networks  (VPNs). In implementing a VPN for a customer, an ISP uses \nits MPLS-enabled network to connect together the customer\u2019s various networks. MPLS \ncan be used to isolate both the resources and addressing used by the customer\u2019s VPN \nfrom that of other users crossing the ISP\u2019s network; see [DeClercq 2002] for details.\nOur discussion of MPLS has been brief, and we encourage you to consult the \nreferences we\u2019ve mentioned. We note that with so many possible uses for MPLS, it \nappears that it is rapidly becoming the Swiss Army knife of Internet traffic engineering!\n6.6  \u2022  DATA CENTER NETWORKING      523\n6.6 Data Center Networking\nIn recent years, Internet companies such as Google, Microsoft, Facebook, and \n Amazon (as well as their counterparts in Asia and Europe) have built massive data \ncenters, each housing tens to hundreds of thousands of hosts, and concurrently sup -\nporting many distinct cloud applications (e.g., search, e-mail, social networking, and \ne-commerce). Each data center has its own data center network  that interconnects its \nhosts with each other and interconnects the data center with the Internet. In this sec -\ntion, we provide a brief introduction to data center networking for cloud applications.\nThe cost of a large data center is huge, exceeding $12 million per month for a \n100,000 host data center [Greenberg 2009a]. Of these costs, about 45 percent can \nbe attributed to the hosts themselves (which need to be replaced every 3\u20134 years); \n25 percent to infrastructure, including transformers, uninterruptable power supplies \n(UPS) systems, generators for long-term outages, and cooling systems; 15 percent \nfor electric utility costs for the power draw; and 15 percent for networking, including \nnetwork gear (switches, routers and load balancers), external links, and transit traf -\nfic costs. (In these percentages, costs for equipment are amortized so that a common \ncost metric is applied for one-time purchases and ongoing expenses such as power.) \nWhile networking is not the largest cost, networking innovation is the key to reduc -\ning overall cost and maximizing performance [Greenberg 2009a].\nThe worker bees in a data center are the hosts: They serve content (e.g., Web \npages and videos), store e-mails and documents, and collectively perform massively \ndistributed computations (e.g., distributed index computations for search engines). \nThe hosts in data centers, called blades  and resembling pizza boxes, are generally \ncommodity hosts that include CPU, memory, and disk storage. The hosts are stacked \nin racks, with each rack typically having 20 to 40 blades. At the top of each rack there \nis a switch, aptly named the Top of Rack (TOR) switch , that interconnects the hosts \nin the rack with each other and with other switches in the data center. Specifically, \neach host in the rack has a network interface card that connects to its TOR switch, \nand each TOR switch has additional ports that can be connected to other switches. \nToday hosts typically have", "doc_id": "661dff1c-7e03-4db3-8a44-2db282d96005", "embedding": null, "doc_hash": "63190a34fa5cf3f2eadfbb7906d6394979a51bc31289ca6d1ec3cb0ab9f90310", "extra_info": null, "node_info": {"start": 1531194, "end": 1535073}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "b5a2cb58-09fe-48df-8472-319a94e92dc6", "3": "122f857d-21fe-4280-88e2-e727f4e2edb9"}}, "__type__": "1"}, "122f857d-21fe-4280-88e2-e727f4e2edb9": {"__data__": {"text": "Web \npages and videos), store e-mails and documents, and collectively perform massively \ndistributed computations (e.g., distributed index computations for search engines). \nThe hosts in data centers, called blades  and resembling pizza boxes, are generally \ncommodity hosts that include CPU, memory, and disk storage. The hosts are stacked \nin racks, with each rack typically having 20 to 40 blades. At the top of each rack there \nis a switch, aptly named the Top of Rack (TOR) switch , that interconnects the hosts \nin the rack with each other and with other switches in the data center. Specifically, \neach host in the rack has a network interface card that connects to its TOR switch, \nand each TOR switch has additional ports that can be connected to other switches. \nToday hosts typically have 40 Gbps Ethernet connections to their TOR switches \n[Greenberg 2015]. Each host is also assigned its own data-center-internal IP address.\nThe data center network supports two types of traffic: traffic flowing between \nexternal clients and internal hosts and traffic flowing between internal hosts. To handle \nflows between external clients and internal hosts, the data center network includes one \nor more border routers , connecting the data center network to the public Internet. The \ndata center network therefore interconnects the racks with each other and connects the \nracks to the border routers. Figure 6.30 shows an example of a data center network. \nData center network design , the art of designing the interconnection network and pro -\ntocols that connect the racks with each other and with the border routers, has become \nan important branch of computer networking research in recent years [Al-Fares 2008; \nGreenberg 2009a; Greenberg 2009b; Mysore 2009; Guo 2009; Wang 2010].\n524     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\nLoad Balancing\nA cloud data center, such as a Google or Microsoft data center, provides many \napplications concurrently, such as search, e-mail, and video applications. To sup -\nport requests from external clients, each application is associated with a publicly \nvisible IP address to which clients send their requests and from which they receive \nresponses. Inside the data center, the external requests are first directed to a load \nbalancer  whose job it is to distribute requests to the hosts, balancing the load across \nthe hosts as a function of their current load. A large data center will often have sev -\neral load balancers, each one devoted to a set of specific cloud applications. Such a \nload balancer is sometimes referred to as a \u201clayer-4 switch\u201d since it makes decisions \nbased on the destination port number (layer 4) as well as destination IP address in \nthe packet. Upon receiving a request for a particular application, the load balancer \nforwards it to one of the hosts that handles the application. (A host may then invoke \nthe services of other hosts to help process the request.) When the host finishes pro -\ncessing the request, it sends its response back to the load balancer, which in turn \nrelays the response back to the external client. The load balancer not only balances Figure 6.30  \u2666 A data center network with a hierarchical topologyInternet\nA\n1234567 8CB\nServer racksTOR switchesTier-2 switchesTier-1 switchesAccess routerBorder router\nLoad\nbalancer\n6.6  \u2022  DATA CENTER NETWORKING      525\nthe work load across hosts, but also provides a NAT-like function, translating the \npublic external IP address to the internal IP address of the appropriate host, and then \ntranslating back for packets traveling in the reverse direction back to the clients. This \nprevents clients from contacting hosts directly, which has the security benefit of \nhiding the internal network structure and preventing clients from directly interacting \nwith the hosts.\nHierarchical Architecture\nFor a small data center housing only a few thousand hosts, a simple network consist -\ning of a border router, a load balancer, and a few tens of racks all interconnected by \na single Ethernet switch could possibly suffice. But to scale to", "doc_id": "122f857d-21fe-4280-88e2-e727f4e2edb9", "embedding": null, "doc_hash": "21f41eeec0a558f798de6f37633b0d28500c9f4d38ec6dff27decdf1db01e9b4", "extra_info": null, "node_info": {"start": 1535037, "end": 1539117}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "661dff1c-7e03-4db3-8a44-2db282d96005", "3": "856f14c0-8dd8-494e-bc4c-d5c1801075d1"}}, "__type__": "1"}, "856f14c0-8dd8-494e-bc4c-d5c1801075d1": {"__data__": {"text": " \u2022  DATA CENTER NETWORKING      525\nthe work load across hosts, but also provides a NAT-like function, translating the \npublic external IP address to the internal IP address of the appropriate host, and then \ntranslating back for packets traveling in the reverse direction back to the clients. This \nprevents clients from contacting hosts directly, which has the security benefit of \nhiding the internal network structure and preventing clients from directly interacting \nwith the hosts.\nHierarchical Architecture\nFor a small data center housing only a few thousand hosts, a simple network consist -\ning of a border router, a load balancer, and a few tens of racks all interconnected by \na single Ethernet switch could possibly suffice. But to scale to tens to hundreds of \nthousands of hosts, a data center often employs a hierarchy of routers and switches , \nsuch as the topology shown in Figure 6.30. At the top of the hierarchy, the border \nrouter connects to access routers (only two are shown in Figure 6.30, but there can be \nmany more). Below each access router there are three tiers of switches. Each access \nrouter connects to a top-tier switch, and each top-tier switch connects to multiple \nsecond-tier switches and a load balancer. Each second-tier switch in turn connects to \nmultiple racks via the racks\u2019 TOR switches (third-tier switches). All links typically \nuse Ethernet for their link-layer and physical-layer protocols, with a mix of copper \nand fiber cabling. With such a hierarchical design, it is possible to scale a data center \nto hundreds of thousands of hosts.\nBecause it is critical for a cloud application provider to continually provide appli -\ncations with high availability, data centers also include redundant network equip -\nment and redundant links in their designs (not shown in Figure 6.30). For example, \neach TOR switch can connect to two tier-2 switches, and each access router, tier-1 \nswitch, and tier-2 switch can be duplicated and integrated into the design [Cisco \n2012; Greenberg 2009b]. In the hierarchical design in Figure 6.30, observe that the \nhosts below each access router form a single subnet. In order to localize ARP broad -\ncast traffic, each of these subnets is further partitioned into smaller VLAN subnets, \neach comprising a few hundred hosts [Greenberg 2009a].\nAlthough the conventional hierarchical architecture just described solves the \nproblem of scale, it suffers from limited host-to-host capacity  [Greenberg 2009b]. \nTo understand this limitation, consider again Figure 6.30, and suppose each host \nconnects to its TOR switch with a 1 Gbps link, whereas the links between switches \nare 10 Gbps Ethernet links. Two hosts in the same rack can always communicate at \na full 1 Gbps, limited only by the rate of the hosts\u2019 network interface cards. How -\never, if there are many simultaneous flows in the data center network, the maximum \nrate between two hosts in different  racks can be much less. To gain insight into \nthis issue, consider a traffic pattern consisting of 40 simultaneous flows between  \n40 pairs of hosts in different racks. Specifically, suppose each of 10 hosts in rack 1 \nin Figure 6.30 sends a flow to a corresponding host in rack 5. Similarly, there are ten \nsimultaneous flows between pairs of hosts in racks 2 and 6, ten simultaneous flows  \n526     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\nbetween racks 3 and 7, and ten simultaneous flows between racks 4 and 8. If each \nflow evenly shares a link\u2019s capacity with other flows traversing that link, then the \n40 flows crossing the 10 Gbps A-to-B link (as well as the 10 Gbps B-to-C link) will \neach only receive 10 Gbps / 40 = 250 Mbps, which is significantly less than the  \n1 Gbps network interface card rate. The problem becomes even more acute for flows \nbetween hosts that need to travel higher up the", "doc_id": "856f14c0-8dd8-494e-bc4c-d5c1801075d1", "embedding": null, "doc_hash": "556b6b29ea388be15ae4aff9853d1cce1574b99ebb7e988edc991745ca470649", "extra_info": null, "node_info": {"start": 1539156, "end": 1543004}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "122f857d-21fe-4280-88e2-e727f4e2edb9", "3": "02a96dc1-30e6-45ba-ac0c-5fab4b626d24"}}, "__type__": "1"}, "02a96dc1-30e6-45ba-ac0c-5fab4b626d24": {"__data__": {"text": "sends a flow to a corresponding host in rack 5. Similarly, there are ten \nsimultaneous flows between pairs of hosts in racks 2 and 6, ten simultaneous flows  \n526     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\nbetween racks 3 and 7, and ten simultaneous flows between racks 4 and 8. If each \nflow evenly shares a link\u2019s capacity with other flows traversing that link, then the \n40 flows crossing the 10 Gbps A-to-B link (as well as the 10 Gbps B-to-C link) will \neach only receive 10 Gbps / 40 = 250 Mbps, which is significantly less than the  \n1 Gbps network interface card rate. The problem becomes even more acute for flows \nbetween hosts that need to travel higher up the hierarchy. One possible solution to \nthis limitation is to deploy higher-rate switches and routers. But this would signifi -\ncantly increase the cost of the data center, because switches and routers with high \nport speeds are very expensive.\nSupporting high-bandwidth host-to-host communication is important because a \nkey requirement in data centers is flexibility in placement of computation and ser -\nvices [Greenberg 2009b; Farrington 2010]. For example, a large-scale Internet search \nengine may run on thousands of hosts spread across multiple racks with significant \nbandwidth requirements between all pairs of hosts. Similarly, a cloud computing \nservice such as EC2 may wish to place the multiple virtual machines comprising a \ncustomer\u2019s service on the physical hosts with the most capacity irrespective of their \nlocation in the data center. If these physical hosts are spread across multiple racks, \nnetwork bottlenecks as described above may result in poor performance.\nTrends in Data Center Networking\nIn order to reduce the cost of data centers, and at the same time improve their delay \nand throughput performance, Internet cloud giants such as Google, Facebook, \n Amazon, and Microsoft are continually deploying new data center network designs. \nAlthough these designs are proprietary, many important trends can nevertheless be \nidentified.\nOne such trend is to deploy new interconnection architectures and network \nprotocols that overcome the drawbacks of the traditional hierarchical designs. One \nsuch approach is to replace the hierarchy of switches and routers with a fully con -\nnected topology  [Facebook 2014; Al-Fares 2008; Greenberg 2009b; Guo 2009], such \nas the topology shown in Figure 6.31. In this design, each tier-1 switch connects to \nall of the tier-2 switches so that (1) host-to-host traffic never has to rise above the \nswitch tiers, and (2) with n tier-1 switches, between any two tier-2 switches there are \nn disjoint paths. Such a design can significantly improve the host-to-host capacity. \nTo see this, consider again our example of 40 flows. The topology in Figure 6.31 \ncan handle such a flow pattern since there are four distinct paths between the first \ntier-2 switch and the second tier-2 switch, together providing an aggregate capacity of  \n40 Gbps between the first two tier-2 switches. Such a design not only alleviates the \nhost-to-host capacity limitation, but also creates a more flexible computation and ser -\nvice environment in which communication between any two racks not connected to \nthe same switch is logically equivalent, irrespective of their locations in the data center.\nAnother major trend is to employ shipping container\u2013based modular data cent -\ners (MDCs) [YouTube 2009; Waldrop 2007]. In an MDC, a factory builds, within a \n6.6  \u2022  DATA CENTER NETWORKING      527\nstandard 12-meter shipping container, a \u201cmini data center\u201d and ships the container \nto the data center location. Each container has up to a few thousand hosts, stacked \nin tens of racks, which are packed closely together. At the data center location, mul -\ntiple containers are interconnected with each other and also with the Internet. Once \na prefabricated container is deployed at a data center, it is often difficult to service. \nThus,", "doc_id": "02a96dc1-30e6-45ba-ac0c-5fab4b626d24", "embedding": null, "doc_hash": "5570ceec338c9cee81ccef577f59359727e599849fee32272b1dbc68395e58c9", "extra_info": null, "node_info": {"start": 1543091, "end": 1547042}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "856f14c0-8dd8-494e-bc4c-d5c1801075d1", "3": "eaf48bec-50f9-4bc4-bb03-46c16cb96d80"}}, "__type__": "1"}, "eaf48bec-50f9-4bc4-bb03-46c16cb96d80": {"__data__": {"text": "to \nthe same switch is logically equivalent, irrespective of their locations in the data center.\nAnother major trend is to employ shipping container\u2013based modular data cent -\ners (MDCs) [YouTube 2009; Waldrop 2007]. In an MDC, a factory builds, within a \n6.6  \u2022  DATA CENTER NETWORKING      527\nstandard 12-meter shipping container, a \u201cmini data center\u201d and ships the container \nto the data center location. Each container has up to a few thousand hosts, stacked \nin tens of racks, which are packed closely together. At the data center location, mul -\ntiple containers are interconnected with each other and also with the Internet. Once \na prefabricated container is deployed at a data center, it is often difficult to service. \nThus, each container is designed for graceful performance degradation: as compo -\nnents (servers and switches) fail over time, the container continues to operate but \nwith degraded performance. When many components have failed and performance \nhas dropped below a threshold, the entire container is removed and replaced with a \nfresh one.\nBuilding a data center out of containers creates new networking challenges. \nWith an MDC, there are two types of networks: the container-internal networks \nwithin each of the containers and the core network connecting each container  \n[Guo 2009; Farrington 2010]. Within each container, at the scale of up to a few \nthousand hosts, it is possible to build a fully connected network (as described above) \nusing inexpensive commodity Gigabit Ethernet switches. However, the design of the \ncore network, interconnecting hundreds to thousands of containers while providing \nhigh host-to-host bandwidth across containers for typical workloads, remains a chal -\nlenging problem. A hybrid electrical/optical switch architecture for interconnecting \nthe containers is proposed in [Farrington 2010].\nWhen using highly interconnected topologies, one of the major issues is design -\ning routing algorithms among the switches. One possibility [Greenberg 2009b] is \nto use a form of random routing. Another possibility [Guo 2009] is to deploy mul -\ntiple network interface cards in each host, connect each host to multiple low-cost \ncommodity switches, and allow the hosts themselves to intelligently route traffic \namong the switches. Variations and extensions of these approaches are currently \nbeing deployed in contemporary data centers.Figure 6.31  \u2666 Highly interconnected data network topology1234567 8Server racksTOR switchesTier-2 switchesTier-1 switches\n528     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\nAnother important trend is that large cloud providers are increasingly building \nor customizing just about everything that is in their data centers, including network \nadapters, switches routers, TORs, software, and networking protocols [Greenberg \n2015, Singh 2015]. Another trend, pioneered by Amazon, is to improve reliability \nwith \u201cavailability zones,\u201d which essentially replicate distinct data centers in different \nnearby buildings. By having the buildings nearby (a few kilometers apart), trans -\nactional data can be synchronized across the data centers in the same availability \nzone while providing fault tolerance [Amazon 2014]. Many more innovations in data \ncenter design are likely to continue to come; interested readers are encouraged to see \nthe recent papers and videos on data center network design.\n6.7 Retrospective: A Day in the Life of a Web \nPage Request\nNow that we\u2019ve covered the link layer in this chapter, and the network, transport and \napplication layers in earlier chapters, our journey down the protocol stack is com -\nplete! In the very beginning of this book (Section 1.1 ), we wrote \u201cmuch of this book \nis concerned with computer network protocols,\u201d and in the first five chapters, we\u2019ve \ncertainly seen that this is indeed the case! Before heading into the topical chapters in \nsecond part of this book, we\u2019d like to wrap up our journey down the protocol stack by \ntaking an integrated, holistic", "doc_id": "eaf48bec-50f9-4bc4-bb03-46c16cb96d80", "embedding": null, "doc_hash": "bbe2560d01af69ad9ca7ca72970a4c184575044cf3b38713994fd339d765dc98", "extra_info": null, "node_info": {"start": 1546975, "end": 1550974}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "02a96dc1-30e6-45ba-ac0c-5fab4b626d24", "3": "bc2e1947-153b-48bc-9992-94f9eb4e05ee"}}, "__type__": "1"}, "bc2e1947-153b-48bc-9992-94f9eb4e05ee": {"__data__": {"text": "in data \ncenter design are likely to continue to come; interested readers are encouraged to see \nthe recent papers and videos on data center network design.\n6.7 Retrospective: A Day in the Life of a Web \nPage Request\nNow that we\u2019ve covered the link layer in this chapter, and the network, transport and \napplication layers in earlier chapters, our journey down the protocol stack is com -\nplete! In the very beginning of this book (Section 1.1 ), we wrote \u201cmuch of this book \nis concerned with computer network protocols,\u201d and in the first five chapters, we\u2019ve \ncertainly seen that this is indeed the case! Before heading into the topical chapters in \nsecond part of this book, we\u2019d like to wrap up our journey down the protocol stack by \ntaking an integrated, holistic view of the protocols we\u2019ve learned about so far. One \nway then to take this \u201cbig picture\u201d view is to identify the many (many!) protocols \nthat are involved in satisfying even the simplest request: downloading a Web page. \nFigure 6. 32 illustrates our setting: a student, Bob, connects a laptop to his school\u2019s \nEthernet switch and downloads a Web page (say the home page of www.google  \n.com). As we now know, there\u2019s a lot going on \u201cunder the hood\u201d to satisfy this seem -\ningly simple request. A Wireshark lab at the end of this chapter examines trace files \ncontaining a number of the packets involved in similar scenarios in more detail.\n6.7.1 Getting Started: DHCP, UDP, IP, and Ethernet\nLet\u2019s suppose that Bob boots up his laptop and then connects it to an Ethernet cable \nconnected to the school\u2019s Ethernet switch, which in turn is connected to the school\u2019s \nrouter, as shown in Figure 6.32. The school\u2019s router is connected to an ISP, in this \nexample, comcast.net. In this example, comcast.net is providing the DNS service \nfor the school; thus, the DNS server resides in the Comcast network rather than the \nschool network. We\u2019ll assume that the DHCP server is running within the router, as \nis often the case.\nWhen Bob first connects his laptop to the network, he can\u2019t do anything  \n(e.g., download a Web page) without an IP address. Thus, the first network-related \n6.7  \u2022  RETROSPECTIVE: A DAY IN THE LIFE OF A WEB PAGE REQUEST      529\naction taken by Bob\u2019s laptop is to run the DHCP protocol to obtain an IP address, as \nwell as other information, from the local DHCP server:\n 1. The operating system on Bob\u2019s laptop creates a DHCP request message  \n (Section 4.3.3) and puts this message within a UDP segment  (Section 3.3) \nwith destination port 67 (DHCP server) and source port 68 (DHCP client). The \nUDP segment is then placed within an IP datagram  (Section 4.3.1) with a \nbroadcast IP destination address (255.255.255.255) and a source IP address of \n0.0.0.0, since Bob\u2019s laptop doesn\u2019t yet have an IP address.\n 2. The IP datagram containing the DHCP request message is then placed within \nan Ethernet frame  (Section 6.4.2). The Ethernet frame has a destina -\ntion MAC addresses of FF:FF:FF:FF:FF:FF so that the frame will be \nbroadcast to all devices connected to the switch (hopefully including a \nDHCP server); the frame\u2019s source MAC address is that of Bob\u2019s laptop, \n00:16:D3:23:68:8A.\n 3. The broadcast Ethernet frame containing the DHCP request is the first frame \nsent by Bob\u2019s laptop to the Ethernet switch. The switch broadcasts the \nincoming frame on all outgoing ports, including the port connected to the", "doc_id": "bc2e1947-153b-48bc-9992-94f9eb4e05ee", "embedding": null, "doc_hash": "90650a4776082153f471a7c9d6249b2ecba0c297ed8e155a688e35b5f1cfb420", "extra_info": null, "node_info": {"start": 1550948, "end": 1554357}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "eaf48bec-50f9-4bc4-bb03-46c16cb96d80", "3": "7ca3ee29-86e9-429f-90d6-f1cb956237c7"}}, "__type__": "1"}, "7ca3ee29-86e9-429f-90d6-f1cb956237c7": {"__data__": {"text": "\n0.0.0.0, since Bob\u2019s laptop doesn\u2019t yet have an IP address.\n 2. The IP datagram containing the DHCP request message is then placed within \nan Ethernet frame  (Section 6.4.2). The Ethernet frame has a destina -\ntion MAC addresses of FF:FF:FF:FF:FF:FF so that the frame will be \nbroadcast to all devices connected to the switch (hopefully including a \nDHCP server); the frame\u2019s source MAC address is that of Bob\u2019s laptop, \n00:16:D3:23:68:8A.\n 3. The broadcast Ethernet frame containing the DHCP request is the first frame \nsent by Bob\u2019s laptop to the Ethernet switch. The switch broadcasts the \nincoming frame on all outgoing ports, including the port connected to the \nrouter.00:22:6B:45:1F:1B\n68.85.2.100:16:D3:23:68:8A\n68.85.2.101comcast.net\nDNS server\n68.87.71.226\nwww.google.com\nWeb server\n64.233.169.105School network\n68.80.2.0/24\nComcast\u2019 s network\n68.80.0.0/13\nGoogle\u2019 s network\n64.233.160.0/191\u20137\n8\u20131318\u20132414\u201317\nFigure 6.32  \u2666  A day in the life of a Web page request: Network setting \nand actions\n530     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\n 4. The router receives the broadcast Ethernet frame containing the DHCP request \non its interface with MAC address 00:22:6B:45:1F:1B and the IP datagram \nis extracted from the Ethernet frame. The datagram\u2019s broadcast IP destina -\ntion address indicates that this IP datagram should be processed by upper \nlayer protocols at this node, so the datagram\u2019s payload (a UDP segment) is \nthus demultiplexed  (Section 3.2 ) up to UDP, and the DHCP request message \nis extracted from the UDP segment. The DHCP server now has the DHCP \nrequest message.\n 5. Let\u2019s suppose that the DHCP server running within the router can allocate IP \naddresses in the CIDR  (Section 4.3.3) block 68.85.2.0/24. In this example, all \nIP addresses used within the school are thus within Comcast\u2019s address block. \nLet\u2019s suppose the DHCP server allocates address 68.85.2.101 to Bob\u2019s laptop. \nThe DHCP server creates a DHCP ACK message  (Section 4.3.3) containing \nthis IP address, as well as the IP address of the DNS server (68.87.71.226), \nthe IP address for the default gateway router (68.85.2.1), and the subnet block \n(68.85.2.0/24) (equivalently, the \u201cnetwork mask\u201d). The DHCP message is \nput inside a UDP segment, which is put inside an IP datagram, which is put \ninside an Ethernet frame. The Ethernet frame has a source MAC address of the \nrouter\u2019s interface to the home network (00:22:6B:45:1F:1B) and a destination \nMAC address of Bob\u2019s laptop (00:16:D3:23:68:8A).\n 6. The Ethernet frame containing the DHCP ACK is sent (unicast) by the router \nto the switch. Because the switch is self-learning  (Section 6.4.3) and previ-\nously received an Ethernet frame (containing the DHCP request) from Bob\u2019s \nlaptop, the switch knows to forward a frame addressed to 00:16:D3:23:68:8A \nonly to the output port leading to Bob\u2019s laptop.\n 7. Bob\u2019s laptop receives the Ethernet frame containing the DHCP ACK, extracts \nthe IP datagram from the Ethernet frame, extracts the UDP segment from the \nIP datagram, and extracts the DHCP ACK message from", "doc_id": "7ca3ee29-86e9-429f-90d6-f1cb956237c7", "embedding": null, "doc_hash": "b2b48b52fcbcaed55a196c7d31b068559c67b66005ae0e21fd617250e9e62815", "extra_info": null, "node_info": {"start": 1554437, "end": 1557505}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "bc2e1947-153b-48bc-9992-94f9eb4e05ee", "3": "97f98343-e362-48d8-8958-7da7f44891b5"}}, "__type__": "1"}, "97f98343-e362-48d8-8958-7da7f44891b5": {"__data__": {"text": "\nMAC address of Bob\u2019s laptop (00:16:D3:23:68:8A).\n 6. The Ethernet frame containing the DHCP ACK is sent (unicast) by the router \nto the switch. Because the switch is self-learning  (Section 6.4.3) and previ-\nously received an Ethernet frame (containing the DHCP request) from Bob\u2019s \nlaptop, the switch knows to forward a frame addressed to 00:16:D3:23:68:8A \nonly to the output port leading to Bob\u2019s laptop.\n 7. Bob\u2019s laptop receives the Ethernet frame containing the DHCP ACK, extracts \nthe IP datagram from the Ethernet frame, extracts the UDP segment from the \nIP datagram, and extracts the DHCP ACK message from the UDP segment. \nBob\u2019s DHCP client then records its IP address and the IP address of its DNS \nserver. It also installs the address of the default gateway into its IP forward-\ning table  (Section 4.1). Bob\u2019s laptop will send all datagrams with destination \naddress outside of its subnet 68.85.2.0/24 to the default gateway. At this point, \nBob\u2019s laptop has initialized its networking components and is ready to begin \nprocessing the Web page fetch. (Note that only the last two DHCP steps of the \nfour presented in Chapter 4 are actually necessary.)\n6.7.2 Still Getting Started: DNS and ARP\nWhen Bob types the URL for www.google.com into his Web browser, he begins \nthe long chain of events that will eventually result in Google\u2019s home page being \ndisplayed by his Web browser. Bob\u2019s Web browser begins the process by creating \na TCP socket  (Section 2.7) that will be used to send the HTTP request  (Section \n2.2) to www.google.com. In order to create the socket, Bob\u2019s laptop will need to \n6.7  \u2022  RETROSPECTIVE: A DAY IN THE LIFE OF A WEB PAGE REQUEST      531\nknow the IP address of www.google.com. We learned in Section 2.5, that the  DNS \n protocol  is used to provide this name-to-IP-address translation service.\n 8. The operating system on Bob\u2019s laptop thus creates a DNS query message  \n(Section 2.5.3), putting the string \u201cwww.google.com\u201d in the question section \nof the DNS message. This DNS message is then placed within a UDP segment \nwith a destination port of 53 (DNS server). The UDP segment is then placed \nwithin an IP datagram with an IP destination address of 68.87.71.226 (the \naddress of the DNS server returned in the DHCP ACK in step 5) and a source \nIP address of 68.85.2.101.\n 9. Bob\u2019s laptop then places the datagram containing the DNS query message in \nan Ethernet frame. This frame will be sent (addressed, at the link layer) to the \ngateway router in Bob\u2019s school\u2019s network. However, even though Bob\u2019s laptop \nknows the IP address of the school\u2019s gateway router (68.85.2.1) via the DHCP \nACK message in step 5 above, it doesn\u2019t know the gateway router\u2019s MAC \naddress. In order to obtain the MAC address of the gateway router, Bob\u2019s \n laptop will need to use the ARP protocol  (Section 6.4.1).\n 10. Bob\u2019s laptop creates an ARP query  message with a target IP address of \n68.85.2.1 (the default gateway), places the ARP message within an Ethernet \nframe with a broadcast destination address (FF:FF:FF:FF:FF:FF) and sends the \nEthernet frame to the switch, which delivers the frame to all connected devices, \nincluding the gateway router.\n 11. The gateway router receives the frame containing the ARP query message on the \ninterface to the school network, and finds that the target IP address of 68.85.2.1 in \nthe ARP message matches the IP address of its interface. The gateway router thus", "doc_id": "97f98343-e362-48d8-8958-7da7f44891b5", "embedding": null, "doc_hash": "386385e33e39935aa972c46ddc2c967c434cb5129630b331ae4fef0534dd704b", "extra_info": null, "node_info": {"start": 1557547, "end": 1560981}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "7ca3ee29-86e9-429f-90d6-f1cb956237c7", "3": "dd0e7528-be46-4855-88b1-ae6e27ba61cb"}}, "__type__": "1"}, "dd0e7528-be46-4855-88b1-ae6e27ba61cb": {"__data__": {"text": "In order to obtain the MAC address of the gateway router, Bob\u2019s \n laptop will need to use the ARP protocol  (Section 6.4.1).\n 10. Bob\u2019s laptop creates an ARP query  message with a target IP address of \n68.85.2.1 (the default gateway), places the ARP message within an Ethernet \nframe with a broadcast destination address (FF:FF:FF:FF:FF:FF) and sends the \nEthernet frame to the switch, which delivers the frame to all connected devices, \nincluding the gateway router.\n 11. The gateway router receives the frame containing the ARP query message on the \ninterface to the school network, and finds that the target IP address of 68.85.2.1 in \nthe ARP message matches the IP address of its interface. The gateway router thus \nprepares an ARP reply , indicating that its MAC address of 00:22:6B:45:1F:1B \ncorresponds to IP address 68.85.2.1. It places the ARP reply message in an Eth -\nernet frame, with a destination address of 00:16:D3:23:68:8A (Bob\u2019s laptop) and \nsends the frame to the switch, which delivers the frame to Bob\u2019s laptop.\n 12. Bob\u2019s laptop receives the frame containing the ARP reply message and \nextracts the MAC address of the gateway router (00:22:6B:45:1F:1B) from the \nARP reply message.\n 13. Bob\u2019s laptop can now ( finally! ) address the Ethernet frame containing the DNS \nquery to the gateway router\u2019s MAC address. Note that the IP datagram in this frame \nhas an IP destination address of 68.87.71.226 (the DNS server), while the frame \nhas a destination address of 00:22:6B:45:1F:1B (the gateway router). Bob\u2019s laptop \nsends this frame to the switch, which delivers the frame to the gateway router.\n6.7.3 Still Getting Started: Intra-Domain Routing to the \nDNS Server\n 14. The gateway router receives the frame and extracts the IP datagram containing \nthe DNS query. The router looks up the destination address of this datagram \n532     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\n(68.87.71.226) and determines from its forwarding table that the datagram \nshould be sent to the leftmost router in the Comcast network in Figure 6.32. \nThe IP datagram is placed inside a link-layer frame appropriate for the link \nconnecting the school\u2019s router to the leftmost Comcast router and the frame is \nsent over this link.\n 15. The leftmost router in the Comcast network receives the frame, extracts the \nIP datagram, examines the datagram\u2019s destination address (68.87.71.226) and \ndetermines the outgoing interface on which to forward the datagram toward the \nDNS server from its forwarding table, which has been filled in by  Comcast\u2019s \nintra-domain protocol (such as RIP, OSPF  or IS-IS , Section 5.3) as well as the \nInternet\u2019s inter-domain protocol , BGP  (Section 5.4).\n 16. Eventually the IP datagram containing the DNS query arrives at the DNS server. \nThe DNS server extracts the DNS query message, looks up the name www  \n.google.com in its DNS database (Section 2.5 ), and finds the DNS resource \nrecord  that contains the IP address (64.233.169.105) for www.google.com. \n(assuming that it is currently cached in the DNS server). Recall that this cached \ndata originated in the authoritative DNS server  (Section  2.5.2) for googlecom. \nThe DNS server forms a DNS reply message  containing this hostname-to-IP-\naddress mapping, and places the DNS reply message in a UDP segment, and the \nsegment within an IP datagram addressed to Bob\u2019s laptop (68.85.2.101). This \ndatagram will be forwarded", "doc_id": "dd0e7528-be46-4855-88b1-ae6e27ba61cb", "embedding": null, "doc_hash": "553897e6b5c423ae37fb4c1d4150db24fdd7715b627048e4da3c64fa6667c37c", "extra_info": null, "node_info": {"start": 1560902, "end": 1564311}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "97f98343-e362-48d8-8958-7da7f44891b5", "3": "7c7c1a87-c4ed-4a3c-bb02-767537be295b"}}, "__type__": "1"}, "7c7c1a87-c4ed-4a3c-bb02-767537be295b": {"__data__": {"text": "arrives at the DNS server. \nThe DNS server extracts the DNS query message, looks up the name www  \n.google.com in its DNS database (Section 2.5 ), and finds the DNS resource \nrecord  that contains the IP address (64.233.169.105) for www.google.com. \n(assuming that it is currently cached in the DNS server). Recall that this cached \ndata originated in the authoritative DNS server  (Section  2.5.2) for googlecom. \nThe DNS server forms a DNS reply message  containing this hostname-to-IP-\naddress mapping, and places the DNS reply message in a UDP segment, and the \nsegment within an IP datagram addressed to Bob\u2019s laptop (68.85.2.101). This \ndatagram will be forwarded back through the Comcast network to the school\u2019s \nrouter and from there, via the Ethernet switch to Bob\u2019s laptop.\n 17. Bob\u2019s laptop extracts the IP address of the server www.google.com from the \nDNS message. Finally , after a lot of work, Bob\u2019s laptop is now ready to con-\ntact the www.google.com server!\n6.7.4 Web Client-Server Interaction: TCP and HTTP\n 18. Now that Bob\u2019s laptop has the IP address of www.google.com, it can create the \nTCP socket  (Section 2.7 ) that will be used to send the HTTP GET  message \n(Section 2.2.3) to www.google.com. When Bob creates the TCP socket, the \nTCP in Bob\u2019s laptop must first perform a three-way handshake  (Section 3.5.6 ) \nwith the TCP in www.google.com. Bob\u2019s laptop thus first creates a TCP SYN  \nsegment with destination port 80 (for HTTP), places the TCP segment inside an \nIP datagram with a destination IP address of 64.233.169.105 (www.google  \n.com), places the datagram inside a frame with a destination MAC address of \n00:22:6B:45:1F:1B (the gateway router) and sends the frame to the switch.\n 19. The routers in the school network, Comcast\u2019s network, and Google\u2019s network \nforward the datagram containing the TCP SYN toward www.google.com, \nusing the forwarding table in each router, as in steps 14\u201316 above. Recall that \nthe router forwarding table entries governing forwarding of packets over the \ninter-domain link between the Comcast and Google networks are determined \nby the BGP  protocol (Chapter 5).\n6.7  \u2022  RETROSPECTIVE: A DAY IN THE LIFE OF A WEB PAGE REQUEST      533\n 20. Eventually, the datagram containing the TCP SYN arrives at www.google \n.com. The TCP SYN message is extracted from the datagram and demulti-\nplexed to the welcome socket associated with port 80. A connection socket \n(Section 2.7) is created for the TCP connection between the Google HTTP \nserver and Bob\u2019s laptop. A TCP SYNACK (Section 3.5.6) segment is gener-\nated, placed inside a datagram addressed to Bob\u2019s laptop, and finally placed \ninside a link-layer frame appropriate for the link connecting www.google.com \nto its first-hop router.\n 21. The datagram containing the TCP SYNACK segment is forwarded through the \nGoogle, Comcast, and school networks, eventually arriving at the Ethernet card \nin Bob\u2019s laptop. The datagram is demultiplexed within the operating system to \nthe TCP socket created in step 18, which enters the connected state.\n 22. With the socket on Bob\u2019s laptop now ( finally! ) ready to send bytes to www \n.google.com, Bob\u2019s browser creates the HTTP GET message (Section 2.2.3) \ncontaining the URL to be fetched. The HTTP GET message is then written into \nthe socket, with the GET message becoming the payload of a TCP segment. \nThe TCP segment is placed in a datagram and sent and delivered to www", "doc_id": "7c7c1a87-c4ed-4a3c-bb02-767537be295b", "embedding": null, "doc_hash": "48724eec05b856ea2b5f6497cd8a85dd3e2dff36acc7cfbd36a431a01a3459ed", "extra_info": null, "node_info": {"start": 1564351, "end": 1567784}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "dd0e7528-be46-4855-88b1-ae6e27ba61cb", "3": "6002ad3a-8017-46a5-8a4d-9b75b984f644"}}, "__type__": "1"}, "6002ad3a-8017-46a5-8a4d-9b75b984f644": {"__data__": {"text": "\nto its first-hop router.\n 21. The datagram containing the TCP SYNACK segment is forwarded through the \nGoogle, Comcast, and school networks, eventually arriving at the Ethernet card \nin Bob\u2019s laptop. The datagram is demultiplexed within the operating system to \nthe TCP socket created in step 18, which enters the connected state.\n 22. With the socket on Bob\u2019s laptop now ( finally! ) ready to send bytes to www \n.google.com, Bob\u2019s browser creates the HTTP GET message (Section 2.2.3) \ncontaining the URL to be fetched. The HTTP GET message is then written into \nthe socket, with the GET message becoming the payload of a TCP segment. \nThe TCP segment is placed in a datagram and sent and delivered to www \n.google.com as in steps 18\u201320 above.\n 23. The HTTP server at www.google.com reads the HTTP GET message from \nthe TCP socket, creates an HTTP response  message (Section 2.2), places the \nrequested Web page content in the body of the HTTP response message, and \nsends the message into the TCP socket.\n 24. The datagram containing the HTTP reply message is forwarded through the \nGoogle, Comcast, and school networks, and arrives at Bob\u2019s laptop. Bob\u2019s \nWeb browser program reads the HTTP response from the socket, extracts \nthe html for the Web page from the body of the HTTP response, and finally \n(finally! ) displays the Web page!\nOur scenario above has covered a lot of networking ground! If you\u2019ve understood \nmost or all of the above example, then you\u2019ve also covered a lot of ground since you \nfirst read Section 1.1, where we wrote \u201cmuch of this book is concerned with computer \nnetwork protocols\u201d and you may have wondered what a protocol actually was! As \ndetailed as the above example might seem, we\u2019ve omitted a number of possible addi -\ntional protocols (e.g., NAT running in the school\u2019s gateway router, wireless access to \nthe school\u2019s network, security protocols for accessing the school network or encrypt -\ning segments or datagrams, network management protocols), and considerations \n(Web caching, the DNS hierarchy) that one would encounter in the public  Internet. \nWe\u2019ll cover a number of these topics and more in the second part of this book.\nLastly, we note that our example above was an integrated and holistic, but also \nvery \u201cnuts and bolts,\u201d view of many of the protocols that we\u2019ve studied in the first \npart of this book. The example focused more on the \u201chow\u201d than the \u201cwhy.\u201d For a \nbroader, more reflective view on the design of network protocols in general, see \n[Clark 1988, RFC 5218].\n534     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\n6.8 Summary\nIn this chapter, we\u2019ve examined the link layer\u2014its services, the principles underly -\ning its operation, and a number of important specific protocols that use these princi -\nples in implementing link-layer services.\nWe saw that the basic service of the link layer is to move a network-layer data -\ngram from one node (host, switch, router, WiFi access point) to an adjacent node. We \nsaw that all link-layer protocols operate by encapsulating a network-layer datagram \nwithin a link-layer frame before transmitting the frame over the link to the adjacent \nnode. Beyond this common framing function, however, we learned that different \nlink-layer protocols provide very different link access, delivery, and transmission \nservices. These differences are due in part to the wide variety of link types over \nwhich link-layer protocols must operate. A simple point-to-point link has a single \nsender and receiver communicating over a single \u201cwire.\u201d A multiple access link is \nshared among many senders and receivers; consequently, the link-layer protocol for \na multiple access channel has a protocol (its multiple access protocol) for coordinat -\ning link access. In the case of", "doc_id": "6002ad3a-8017-46a5-8a4d-9b75b984f644", "embedding": null, "doc_hash": "94f419a46b94e21ef26c1a767bdbe31604d99cea41e4a080de54d299aac48b3c", "extra_info": null, "node_info": {"start": 1567758, "end": 1571518}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "7c7c1a87-c4ed-4a3c-bb02-767537be295b", "3": "810876c9-2d8c-4032-b8ed-f23538566ed3"}}, "__type__": "1"}, "810876c9-2d8c-4032-b8ed-f23538566ed3": {"__data__": {"text": "an adjacent node. We \nsaw that all link-layer protocols operate by encapsulating a network-layer datagram \nwithin a link-layer frame before transmitting the frame over the link to the adjacent \nnode. Beyond this common framing function, however, we learned that different \nlink-layer protocols provide very different link access, delivery, and transmission \nservices. These differences are due in part to the wide variety of link types over \nwhich link-layer protocols must operate. A simple point-to-point link has a single \nsender and receiver communicating over a single \u201cwire.\u201d A multiple access link is \nshared among many senders and receivers; consequently, the link-layer protocol for \na multiple access channel has a protocol (its multiple access protocol) for coordinat -\ning link access. In the case of MPLS, the \u201clink\u201d connecting two adjacent nodes (for \nexample, two IP routers that are adjacent in an IP sense\u2014that they are next-hop \nIP routers toward some destination) may actually be a network  in and of itself. In \none sense, the idea of a network being considered as a link should not seem odd. A \ntelephone link connecting a home modem/computer to a remote modem/router, for \nexample, is actually a path through a sophisticated and complex telephone network.\nAmong the principles underlying link-layer communication, we examined error-\ndetection and -correction techniques, multiple access protocols, link-layer address -\ning, virtualization (VLANs), and the construction of extended switched LANs and \ndata center networks. Much of the focus today at the link layer is on these switched \nnetworks. In the case of error detection/correction, we examined how it is possible \nto add additional bits to a frame\u2019s header in order to detect, and in some cases cor -\nrect, bit-flip errors that might occur when the frame is transmitted over the link. We \ncovered simple parity and checksumming schemes, as well as the more robust cyclic \nredundancy check. We then moved on to the topic of multiple access protocols. We \nidentified and studied three broad approaches for coordinating access to a broadcast \nchannel: channel partitioning approaches (TDM, FDM), random access approaches \n(the ALOHA protocols and CSMA protocols), and taking-turns approaches (poll -\ning and token passing). We studied the cable access network and found that it \nuses many of these multiple access methods. We saw that a consequence of hav -\ning multiple nodes share a single broadcast channel was the need to provide node \naddresses at the link layer. We learned that link-layer addresses were quite different \nfrom  network-layer addresses and that, in the case of the Internet, a special proto -\ncol (ARP\u2014the Address Resolution Protocol) is used to translate between these two \nforms of addressing and studied the hugely successful Ethernet protocol in detail. We \nthen examined how nodes sharing a broadcast channel form a LAN and how multiple \nLANs can be connected together to form larger LANs\u2014all without  the intervention \nHOMEWORK PROBLEMS AND QUESTIONS      535\nof network-layer routing to interconnect these local nodes. We also learned how \n multiple virtual LANs can be created on a single physical LAN infrastructure.\nWe ended our study of the link layer by focusing on how MPLS networks pro -\nvide link-layer services when they interconnect IP routers and an overview of the \nnetwork designs for today\u2019s massive data centers. We wrapped up this chapter (and \nindeed the first five chapters) by identifying the many protocols that are needed to \nfetch a simple Web page. Having covered the link layer, our journey down the pro -\ntocol stack is now ove r! Certainly, the physical layer lies below the link layer, but \nthe details of the physical layer are probably best left for another course (for exam -\nple, in communication theory, rather than computer networking). We have, however, \ntouched upon several aspects of the physical layer in this chapter and in Chapter 1 \n(our discussion of physical media in Section 1.2).", "doc_id": "810876c9-2d8c-4032-b8ed-f23538566ed3", "embedding": null, "doc_hash": "d3ae8e8b1a0023ccc7d7c3f59bc8f67bac56beb630be30fc0c16657377de3b39", "extra_info": null, "node_info": {"start": 1571415, "end": 1575444}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "6002ad3a-8017-46a5-8a4d-9b75b984f644", "3": "751cfadd-b091-4642-b85b-19771b1dceb0"}}, "__type__": "1"}, "751cfadd-b091-4642-b85b-19771b1dceb0": {"__data__": {"text": "ended our study of the link layer by focusing on how MPLS networks pro -\nvide link-layer services when they interconnect IP routers and an overview of the \nnetwork designs for today\u2019s massive data centers. We wrapped up this chapter (and \nindeed the first five chapters) by identifying the many protocols that are needed to \nfetch a simple Web page. Having covered the link layer, our journey down the pro -\ntocol stack is now ove r! Certainly, the physical layer lies below the link layer, but \nthe details of the physical layer are probably best left for another course (for exam -\nple, in communication theory, rather than computer networking). We have, however, \ntouched upon several aspects of the physical layer in this chapter and in Chapter 1 \n(our discussion of physical media in Section 1.2). We\u2019ll consider the physical layer \nagain when we study wireless link characteristics in the next chapter.\nAlthough our journey down the protocol stack is over, our study of computer \nnetworking is not yet at an end. In the following three chapters we cover wireless \nnetworking, network security, and multimedia networking. These four topics do \nnot fit conveniently into any one layer; indeed, each topic crosscuts many layers. \nUnderstanding these topics (billed as advanced topics in some networking texts) thus \nrequires a firm foundation in all layers of the protocol stack\u2014a foundation that our \nstudy of the link layer has now completed!\nHomework Problems and Questions\nChapter 6 Review Questions\nSECTIONS 6.1\u20136.2\n R1. What is framing in link layer?\n R2. If all the links in the Internet were to provide reliable delivery service, would \nthe TCP reliable delivery service be redundant? Why or why not?\n R3. Name three error-detection strategies employed by link layer.\nSECTION 6.3\n R4. Suppose two nodes start to transmit at the same time a packet of length L \nover a broadcast channel of rate R. Denote the propagation delay between the \ntwo nodes as dprop. Will there be a collision if dprop6L/R? Why or why not?\n R5. In Section 6.3, we listed four desirable characteristics of a broadcast channel. \nWhich of these characteristics does slotted ALOHA have? Which of these \ncharacteristics does token passing have?\n536     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\n R6. In CSMA/CD, after the fifth collision, what is the probability that a node \nchooses K=4? The result K=4 corresponds to a delay of how many \n seconds on a 10 Mbps Ethernet?\n R7. While TDM and FDM assign time slots and frequencies, CDMA assigns a dif -\nferent code to each node. Explain the basic principle in which CDMA works.\n R8. Why does collision occur in CSMA, if all nodes perform carrier sensing \nbefore transmission?\nSECTION 6.4\n R9. How big is the MAC address space? The IPv4 address space? The IPv6 \naddress space?\n R10. Suppose nodes A, B, and C each attach to the same broadcast LAN (through \ntheir adapters). If A sends thousands of IP datagrams to B with each encap-\nsulating frame addressed to the MAC address of B, will C\u2019s adapter process \nthese frames? If so, will C\u2019s adapter pass the IP datagrams in these frames \nto the network layer C? How would your answers change if A sends frames \nwith the MAC broadcast address?\n R11. Why is an ARP query sent within a broadcast frame? Why is an ARP \nresponse sent within a frame with a specific destination MAC address?\n R12. For the network in Figure 6.19, the router has two ARP modules, each with its \nown ARP table. Is it possible that the same MAC address appears in both tables?\n R13. What is a hub used for?\n R14. Consider Figure 6.15. How many subnetworks are there, in the addressing \nsense of Section 4.3?\n R15. Each host and router has an ARP table in its memory. What are the contents \nof this", "doc_id": "751cfadd-b091-4642-b85b-19771b1dceb0", "embedding": null, "doc_hash": "6665cc75424a0b5304eaa62d3ddf0a7085d1669a6a2a4bdbce2bde839f92cbfd", "extra_info": null, "node_info": {"start": 1575468, "end": 1579212}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "810876c9-2d8c-4032-b8ed-f23538566ed3", "3": "3c56cde8-837d-41d3-a09e-b29ac70bc554"}}, "__type__": "1"}, "3c56cde8-837d-41d3-a09e-b29ac70bc554": {"__data__": {"text": "adapter process \nthese frames? If so, will C\u2019s adapter pass the IP datagrams in these frames \nto the network layer C? How would your answers change if A sends frames \nwith the MAC broadcast address?\n R11. Why is an ARP query sent within a broadcast frame? Why is an ARP \nresponse sent within a frame with a specific destination MAC address?\n R12. For the network in Figure 6.19, the router has two ARP modules, each with its \nown ARP table. Is it possible that the same MAC address appears in both tables?\n R13. What is a hub used for?\n R14. Consider Figure 6.15. How many subnetworks are there, in the addressing \nsense of Section 4.3?\n R15. Each host and router has an ARP table in its memory. What are the contents \nof this table?\n R16. The Ethernet frame begins with an 8-byte preamble field. The purpose of the \nfirst 7 bytes is to \u201cwake up\u201d the receiving adapters and to synchronize their \nclocks to that of the sender\u2019s clock. What are the contents of the 8 bytes? \nWhat is the purpose of the last byte?\nProblems\n P1. Suppose the information content of a packet is the bit pattern 1010 0111 0101 \n1001 and an even parity scheme is being used. What would the value of the field \ncontaining the parity bits be for the case of a two-dimensional parity scheme? \nYour answer should be such that a minimum-length checksum field is used.\n P2. Show (give an example other than the one in Figure 6.5) that two-dimen-\nsional parity checks can correct and detect a single bit error. Show (give an \nexample of) a double-bit error that can be detected but not corrected.\nPROBLEMS      537\n P3. Suppose the information portion of a packet contains six bytes consisting \nof the 8-bit unsigned binary ASCII representation of string \u201cCHKSUM\u201d; \ncompute the Internet checksum for this data.\n P4. Compute the Internet checksum for each of the following:\na. the binary representation of the numbers 1 through 6.\nb. the ASCII representation of the letters C through H (uppercase).\nc. the ASCII representation of the letters c through h (lowercase).\n P5. Consider the generator, G 5 1001, and suppose that D has the \nvalue\u00a011000111010. What is the value of R?\n P6. Rework the previous problem, but suppose that D has the value\na. 01101010101.\nb. 11111010101.\nc. 10001100001.\n P7. In this problem, we explore some of the properties of the CRC. For  \nthe  generator G (= 1001)  given in Section 6.2.3, answer the following  \nquestions.\na. Why can it detect any single bit error in data D?\nb. Can the above G detect any odd number of bit errors? Why?\n P8. In Section 6.3, we provided an outline of the derivation of the efficiency of \nslotted ALOHA. In this problem we\u2019ll complete the derivation.\na. Recall that when there are N active nodes, the efficiency of slotted \nALOHA is Np(1-p)N-1. Find the value of p that maximizes this expres-\nsion.\nb. Using the value of p found in (a), find the efficiency of slotted ALOHA \nby letting N approach infinity. Hint: (1-1/N)N approaches 1/ e as N \napproaches infinity.\n P9. Show that the maximum efficiency of pure ALOHA is 1/(2 e). Note : This \nproblem is easy if you have completed the problem above!\nP 10. Consider two nodes, A and B, that use the slotted ALOHA protocol to con-\ntend for a channel. Suppose node A has more data to transmit than node B, \nand node A\u2019s retransmission probability pA is greater than node B\u2019s retrans-\nmission probability, pB.\na. Provide a formula for node A\u2019s average throughput. What is the total \nefficiency of the protocol with", "doc_id": "3c56cde8-837d-41d3-a09e-b29ac70bc554", "embedding": null, "doc_hash": "bc5d800d9113635e938610d870b2a8d3a7c03a42e93aa3d8a06ae47262eb3256", "extra_info": null, "node_info": {"start": 1579288, "end": 1582774}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "751cfadd-b091-4642-b85b-19771b1dceb0", "3": "043e48d5-7717-415e-8efa-17c693efb4f4"}}, "__type__": "1"}, "043e48d5-7717-415e-8efa-17c693efb4f4": {"__data__": {"text": "the value of p found in (a), find the efficiency of slotted ALOHA \nby letting N approach infinity. Hint: (1-1/N)N approaches 1/ e as N \napproaches infinity.\n P9. Show that the maximum efficiency of pure ALOHA is 1/(2 e). Note : This \nproblem is easy if you have completed the problem above!\nP 10. Consider two nodes, A and B, that use the slotted ALOHA protocol to con-\ntend for a channel. Suppose node A has more data to transmit than node B, \nand node A\u2019s retransmission probability pA is greater than node B\u2019s retrans-\nmission probability, pB.\na. Provide a formula for node A\u2019s average throughput. What is the total \nefficiency of the protocol with these two nodes?\nb. If pA=2pB, is node A\u2019s average throughput twice as large as that of node \nB? Why or why not? If not, how can you choose pA and pB to make that \nhappen?\n538     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\nc. In general, suppose there are N nodes, among which node A has retrans-\nmission probability 2p and all other nodes have retransmission probability \np. Provide expressions to compute the average throughputs of node A and \nof any other node.\n P11. Suppose four active nodes\u2014nodes A, B, C and D\u2014are competing for access \nto a channel using slotted ALOHA. Assume each node has an infinite number \nof packets to send. Each node attempts to transmit in each slot with probabil-\nity p. The first slot is numbered slot 1, the second slot is numbered slot 2, and \nso on.\na. What is the probability that node A succeeds for the first time in slot 5?\nb. What is the probability that some node (either A, B, C or D) succeeds in \nslot 4?\nc. What is the probability that the first success occurs in slot 3?\nd. What is the efficiency of this four-node system?\n P12. Graph the efficiency of slotted ALOHA and pure ALOHA as a function of  \np for the following values of N:\na. N=15.\nb. N=25.\nc. N=35.\n P13. Consider a broadcast channel with N nodes and a transmission rate of R bps. \nSuppose the broadcast channel uses polling (with an additional polling node) \nfor multiple access. Suppose the amount of time from when a node completes \ntransmission until the subsequent node is permitted to transmit (that is, the \npolling delay) is dpoll. Suppose that within a polling round, a given node is \nallowed to transmit at most Q bits. What is the maximum throughput of the \nbroadcast channel?\n P14. Consider three LANs interconnected by two routers, as shown in Figure 6.33.\na. Assign IP addresses to all of the interfaces. For Subnet 1 use \naddresses of the form 192.168.1.xxx; for Subnet 2 uses addresses of \nthe form 192.168.2.xxx; and for Subnet 3 use addresses of the form \n192.168.3.xxx.\nb. Assign MAC addresses to all of the adapters.\nc. Consider sending an IP datagram from Host E to Host B. Suppose all of \nthe ARP tables are up to date. Enumerate all the steps, as done for the \nsingle-router example in Section 6.4.1.\nd. Repeat (c), now assuming that the ARP table in the sending host is empty \n(and the other tables are up to date).\n P15. Consider Figure 6.33. Now we replace the router between subnets 1 and 2 \nwith a switch S1, and label the router between subnets 2 and 3 as R1.\nPROBLEMS      539\na. Consider sending an IP datagram from Host E to Host F. Will Host E ask router \nR1 to help forward the datagram? Why? In the Ethernet frame containing the \nIP datagram, what are the source and destination IP", "doc_id": "043e48d5-7717-415e-8efa-17c693efb4f4", "embedding": null, "doc_hash": "e82005e466017afa37642320a129401fe85afa299e2130393d56d50263c36896", "extra_info": null, "node_info": {"start": 1582829, "end": 1586204}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "3c56cde8-837d-41d3-a09e-b29ac70bc554", "3": "a743a739-8538-4ee8-915d-9126c42f7bc5"}}, "__type__": "1"}, "a743a739-8538-4ee8-915d-9126c42f7bc5": {"__data__": {"text": "Consider sending an IP datagram from Host E to Host B. Suppose all of \nthe ARP tables are up to date. Enumerate all the steps, as done for the \nsingle-router example in Section 6.4.1.\nd. Repeat (c), now assuming that the ARP table in the sending host is empty \n(and the other tables are up to date).\n P15. Consider Figure 6.33. Now we replace the router between subnets 1 and 2 \nwith a switch S1, and label the router between subnets 2 and 3 as R1.\nPROBLEMS      539\na. Consider sending an IP datagram from Host E to Host F. Will Host E ask router \nR1 to help forward the datagram? Why? In the Ethernet frame containing the \nIP datagram, what are the source and destination IP and MAC addresses?\nb. Suppose E would like to send an IP datagram to B, and assume that E\u2019s \nARP cache does not contain B\u2019s MAC address. Will E perform an ARP \nquery to find B\u2019s MAC address? Why? In the Ethernet frame (containing \nthe IP datagram destined to B) that is delivered to router R1, what are the \nsource and destination IP and MAC addresses?\nc. Suppose Host A would like to send an IP datagram to Host B, and neither A\u2019s \nARP cache contains B\u2019s MAC address nor does B\u2019s ARP cache contain A\u2019s \nMAC address. Further suppose that the switch S1\u2019s forwarding table contains \nentries for Host B and router R1 only. Thus, A will broadcast an ARP request \nmessage. What actions will switch S1 perform once it receives the ARP \nrequest message? Will router R1 also receive this ARP request message? If \nso, will R1 forward the message to Subnet 3? Once Host B receives this ARP \nrequest message, it will send back to Host A an ARP response message. But \nwill it send an ARP query message to ask for A\u2019s MAC address? Why? What \nwill switch S1 do once it receives an ARP response message from Host B?\n P16. Consider the previous problem, but suppose now that the router between sub-\nnets 2 and 3 is replaced by a switch. Answer questions (a)\u2013(c) in the previous \nproblem in this new context.Figure 6.33  \u2666 Three subnets, interconnected by routersSubnet 3E\nFC\nSubnet 2DA\nB\nSubnet 1\n540     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\n P17. Recall that with the CSMA/CD protocol, the adapter waits 536K bit times \nafter a collision, where K is drawn randomly. For K 5 115, how long does \nthe adapter wait until returning to Step 2 for a 10 Mbps broadcast channel? \nFor a 100 Mbps broadcast channel?\n P18. Suppose nodes Aand B are on the same 12 Mbps broadcast channel, and the \npropagation delay between the two nodes is 316 bit times. Suppose CSMA/CD  \nand Ethernet packets are used for this broadcast channel. Suppose node A begins \ntransmitting a frame and, before it finishes, node B begins transmitting a \nframe. Can A finish transmitting before it detects that B has transmitted? \nWhy or why not? If the answer is yes, then A incorrectly believes that its \nframe was successful transmitted without a collision. Hint:  Suppose at time \nt 5 0 bits, A begins transmitting a frame. In the worst case, Atransmits a \nminimum-sized frame of 512 1 64 bit times. So A would finish transmit-\nting the frame at t 5 512 1 64 bit times. Thus, the answer is no, if B\u2019s signal \nreaches A before bit time t 5 512 1 64 bits. In the worst case, when does B\u2019s \nsignal reach A?\n P19. Suppose nodes A and B are on the same 10 Mbps broadcast channel, and the \npropagation delay between the two nodes is 245 bit times. Suppose A and \nB send Ethernet frames at the same time, the frames collide, and then A and \nB choose different values of K in the CSMA/CD algorithm. Assuming no", "doc_id": "a743a739-8538-4ee8-915d-9126c42f7bc5", "embedding": null, "doc_hash": "510af7d6079b920e9b962287aa3ed4bb4a60f44a996294865d3cb365761de4d2", "extra_info": null, "node_info": {"start": 1586197, "end": 1589731}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "043e48d5-7717-415e-8efa-17c693efb4f4", "3": "48e1478e-5125-42d7-8dea-504b4d9617c1"}}, "__type__": "1"}, "48e1478e-5125-42d7-8dea-504b4d9617c1": {"__data__": {"text": "was successful transmitted without a collision. Hint:  Suppose at time \nt 5 0 bits, A begins transmitting a frame. In the worst case, Atransmits a \nminimum-sized frame of 512 1 64 bit times. So A would finish transmit-\nting the frame at t 5 512 1 64 bit times. Thus, the answer is no, if B\u2019s signal \nreaches A before bit time t 5 512 1 64 bits. In the worst case, when does B\u2019s \nsignal reach A?\n P19. Suppose nodes A and B are on the same 10 Mbps broadcast channel, and the \npropagation delay between the two nodes is 245 bit times. Suppose A and \nB send Ethernet frames at the same time, the frames collide, and then A and \nB choose different values of K in the CSMA/CD algorithm. Assuming no \nother nodes are active, can the retransmissions from A and B collide? For our \npurposes, it suffices to work out the following example. Suppose A and B \nbegin transmission at t=0 bit times. They both detect collisions at t=245\nt bit times. Suppose KA=0 and KB=1. At what time does B schedule its \nretransmission? At what time does A begin transmission? ( Note : The nodes \nmust wait for an idle channel after returning to Step 2\u2014see protocol.) At \nwhat time does A\u2019s signal reach B? Does B refrain from transmitting at its \nscheduled time?\n P20. In this problem, you will derive the efficiency of a CSMA/CD-like multiple \naccess protocol. In this protocol, time is slotted and all adapters are synchro-\nnized to the slots. Unlike slotted ALOHA, however, the length of a slot (in \nseconds) is much less than a frame time (the time to transmit a frame). Let S \nbe the length of a slot. Suppose all frames are of constant length L=kRS,  \nwhere R is the transmission rate of the channel and k is a large integer. Sup-\npose there are N nodes, each with an infinite number of frames to send. We \nalso assume that dprop6S, so that all nodes can detect a collision before the \nend of a slot time. The protocol is as follows:\n\u2022 If, for a given slot, no node has possession of the channel, all nodes \ncontend for the channel; in particular, each node transmits in the slot with \nprobability p. If exactly one node transmits in the slot, that node takes \npossession of the channel for the subsequent k-1 slots and transmits its \nentire frame.\n\u2022 If some node has possession of the channel, all other nodes refrain \nfrom transmitting until the node that possesses the channel has finished \ntransmitting its frame. Once this node has transmitted its frame, all nodes \ncontend for the channel.\n  Note that the channel alternates between two states: the productive state, \nwhich lasts exactly k slots, and the nonproductive state, which lasts for a ran-\ndom number of slots. Clearly, the channel efficiency is the ratio of k/(k+x), \nwhere x is the expected number of consecutive unproductive slots.\na. For fixed N and p, determine the efficiency of this protocol.\nb. For fixed N, determine the p that maximizes the efficiency.\nc. Using the p (which is a function of N) found in (b), determine the effi-\nciency as N approaches infinity.\nd. Show that this efficiency approaches 1 as the frame length becomes large.\n P21. Consider Figure 6.33 in problem P14. Provide MAC addresses and IP \naddresses for the interfaces at Host A, both routers, and Host F. Suppose \nHost A sends a datagram to Host F. Give the source and destination MAC \naddresses in the frame encapsulating this IP datagram as the frame is trans-\nmitted (i) from A to the left router, (ii) from the left router to the right router, \n(iii) from the right router to F. Also give the source and destination IP \naddresses in the IP datagram encapsulated within the frame at each of these \npoints in time.\n P22. Suppose now that the leftmost router in Figure", "doc_id": "48e1478e-5125-42d7-8dea-504b4d9617c1", "embedding": null, "doc_hash": "7e3b620950727ba6927ab456dbe7728e9e0794cdf2d5d52ce021922fffd70d0a", "extra_info": null, "node_info": {"start": 1589720, "end": 1593415}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "a743a739-8538-4ee8-915d-9126c42f7bc5", "3": "0bdab582-438f-497a-ab1d-7739b6b32673"}}, "__type__": "1"}, "0bdab582-438f-497a-ab1d-7739b6b32673": {"__data__": {"text": "determine the effi-\nciency as N approaches infinity.\nd. Show that this efficiency approaches 1 as the frame length becomes large.\n P21. Consider Figure 6.33 in problem P14. Provide MAC addresses and IP \naddresses for the interfaces at Host A, both routers, and Host F. Suppose \nHost A sends a datagram to Host F. Give the source and destination MAC \naddresses in the frame encapsulating this IP datagram as the frame is trans-\nmitted (i) from A to the left router, (ii) from the left router to the right router, \n(iii) from the right router to F. Also give the source and destination IP \naddresses in the IP datagram encapsulated within the frame at each of these \npoints in time.\n P22. Suppose now that the leftmost router in Figure 6.33 is replaced by a switch. \nHosts A, B, C, and D and the right router are all star-connected into this \nswitch. Give the source and destination MAC addresses in the frame encap-\nsulating this IP datagram as the frame is transmitted (i) from A to the switch, \n(ii) from the switch to the right router, (iii) from the right router to F. Also \ngive the source and destination IP addresses in the IP datagram encapsulated \nwithin the frame at each of these points in time.\n P23. Consider Figure 5.15. Suppose that all links are 120 Mbps. What is the \nmaximum total aggregate throughput that can be achieved among 12 hosts  \n(4 in each department) and 2 servers in this network? You can assume that \nany host or server can send to any other host or server. Why?\n P24. Suppose the three departmental switches in Figure 5.15 are replaced by hubs. \nAll links are 120 Mbps. Now answer the questions posed in Problem P23.\n P25. Suppose that all the switches in Figure 5.15 are replaced by hubs. All links \nare 120 Mbps. Now answer the questions posed in Problem P23\n P26. Let\u2019s consider the operation of a learning switch in the context of a network \nin which 6 nodes labeled A through F are star connected into an Ethernet \nswitch. Suppose that (i) B sends a frame to E, (ii) E replies with a frame to B, \n(iii) A sends a frame to B, (iv) B replies with a frame to A. The switch table PROBLEMS      541\n542     CHAPTER 6 \u2002\u2002\u2022 \u2002\u2002 THE LINK LAYER AND LANS\nis initially empty. Show the state of the switch table before and after each of \nthese events. For each of these events, identify the link(s) on which the trans-\nmitted frame will be forwarded, and briefly justify your answers.\n P27. In this problem, we explore the use of small packets for Voice-over-IP appli-\ncations. One of the drawbacks of a small packet size is that a large fraction of \nlink bandwidth is consumed by overhead bytes. To this end, suppose that the \npacket consists of P bytes and 5 bytes of header.\na. Consider sending a digitally encoded voice source directly. Suppose the \nsource is encoded at a constant rate of 128 kbps. Assume each packet is \nentirely filled before the source sends the packet into the network. The \ntime required to fill a packet is the packetization delay . In terms of L, \ndetermine the packetization delay in milliseconds.\nb. Packetization delays greater than 20 msec can cause a noticeable and \nunpleasant echo. Determine the packetization delay for L=1,500  bytes \n(roughly corresponding to a maximum-sized Ethernet packet) and for \nL=50 (corresponding to an ATM packet).\nc. Calculate the store-and-forward delay at a single switch for a link rate of \nR=622 Mbps for L=1,500  bytes, and for L=50 bytes.\nd. Comment on the advantages of using a small packet size.\n P28. Consider the single switch VLAN in Figure 6.25, and assume an external \nrouter is connected to switch port 1. Assign IP", "doc_id": "0bdab582-438f-497a-ab1d-7739b6b32673", "embedding": null, "doc_hash": "e3f0ae584b70c3a48a771c71d55255547a61c80c3c577186c72ebbba45c17d97", "extra_info": null, "node_info": {"start": 1593368, "end": 1596985}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "48e1478e-5125-42d7-8dea-504b4d9617c1", "3": "a055997a-a88a-4a07-9d8f-b23ac2aac43b"}}, "__type__": "1"}, "a055997a-a88a-4a07-9d8f-b23ac2aac43b": {"__data__": {"text": "fill a packet is the packetization delay . In terms of L, \ndetermine the packetization delay in milliseconds.\nb. Packetization delays greater than 20 msec can cause a noticeable and \nunpleasant echo. Determine the packetization delay for L=1,500  bytes \n(roughly corresponding to a maximum-sized Ethernet packet) and for \nL=50 (corresponding to an ATM packet).\nc. Calculate the store-and-forward delay at a single switch for a link rate of \nR=622 Mbps for L=1,500  bytes, and for L=50 bytes.\nd. Comment on the advantages of using a small packet size.\n P28. Consider the single switch VLAN in Figure 6.25, and assume an external \nrouter is connected to switch port 1. Assign IP addresses to the EE and CS \nhosts and router interface. Trace the steps taken at both the network layer  \nand the link layer to transfer an IP datagram from an EE host to a CS host  \n(Hint:  Reread the discussion of Figure 6.19 in the text).\n P29. Consider the MPLS network shown in Figure 6.29, and suppose that rout-\ners R5 and R6 are now MPLS enabled. Suppose that we want to perform \ntraffic engineering so that packets from R6 destined for A are switched to \nA via R6-R4-R3-R1, and packets from R5 destined for A are switched via \nR5-R4-R2-R1. Show the MPLS tables in R5 and R6, as well as the modified \ntable in R4, that would make this possible.\n P30. Consider again the same scenario as in the previous problem, but suppose \nthat packets from R6 destined for D are switched via R6-R4-R3, while pack-\nets from R5 destined to D are switched via R4-R2-R1-R3. Show the MPLS \ntables in all routers that would make this possible.\n P31. In this problem, you will put together much of what you have learned about \nInternet protocols. Suppose you walk into a room, connect to Ethernet, and \nwant to download a Web page. What are all the protocol steps that take place, \nstarting from powering on your PC to getting the Web page? Assume there  \nis nothing in our DNS or browser caches when you power on your PC.  \n(Hint:  The steps include the use of Ethernet, DHCP, ARP, DNS, TCP, and \nWIRESHARK LABS      543\nHTTP protocols.) Explicitly indicate in your steps how you obtain the IP and \nMAC addresses of a gateway router.\n P32. Consider the data center network with hierarchical topology in Figure 6.30. \nSuppose now there are 80 pairs of flows, with ten flows between the first \nand ninth rack, ten flows between the second and tenth rack, and so on. \nFurther suppose that all links in the network are 10 Gbps, except for the links \nbetween hosts and TOR switches, which are 1 Gbps.\na. Each flow has the same data rate; determine the maximum rate of a flow.\nb. For the same traffic pattern, determine the maximum rate of a flow for the \nhighly interconnected topology in Figure 6.31.\nc. Now suppose there is a similar traffic pattern, but involving 20 hosts on \neach rack and 160 pairs of flows. Determine the maximum flow rates for \nthe two topologies.\n P33. Consider the hierarchical network in Figure 6.30 and suppose that the data \ncenter needs to support e-mail and video distribution among other applica-\ntions. Suppose four racks of servers are reserved for e-mail and four racks are \nreserved for video. For each of the applications, all four racks must lie below \na single tier-2 switch since the tier-2 to tier-1 links do not have sufficient \nbandwidth to support the intra-application traffic. For the e-mail application, \nsuppose that for 99.9 percent of the time only three racks are used, and that \nthe video application has identical usage patterns.\na. For", "doc_id": "a055997a-a88a-4a07-9d8f-b23ac2aac43b", "embedding": null, "doc_hash": "30786c5c19fa1d882a0aeb9c3dda94f845440f366fa5373d9dafaf20c7340099", "extra_info": null, "node_info": {"start": 1597026, "end": 1600575}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "0bdab582-438f-497a-ab1d-7739b6b32673", "3": "d524523e-4fdd-41f8-a6b9-da3f4a98e262"}}, "__type__": "1"}, "d524523e-4fdd-41f8-a6b9-da3f4a98e262": {"__data__": {"text": "is a similar traffic pattern, but involving 20 hosts on \neach rack and 160 pairs of flows. Determine the maximum flow rates for \nthe two topologies.\n P33. Consider the hierarchical network in Figure 6.30 and suppose that the data \ncenter needs to support e-mail and video distribution among other applica-\ntions. Suppose four racks of servers are reserved for e-mail and four racks are \nreserved for video. For each of the applications, all four racks must lie below \na single tier-2 switch since the tier-2 to tier-1 links do not have sufficient \nbandwidth to support the intra-application traffic. For the e-mail application, \nsuppose that for 99.9 percent of the time only three racks are used, and that \nthe video application has identical usage patterns.\na. For what fraction of time does the e-mail application need to use a fourth \nrack? How about for the video application?\nb. Assuming e-mail usage and video usage are independent, for what fraction \nof time do (equivalently, what is the probability that) both applications \nneed their fourth rack?\nc. Suppose that it is acceptable for an application to have a shortage of serv-\ners for 0.001 percent of time or less (causing rare periods of performance \ndegradation for users). Discuss how the topology in Figure 6.31 can be \nused so that only seven racks are collectively assigned to the two applica-\ntions (assuming that the topology can support all the traffic).\nWireshark Labs\nAt the Companion website for this textbook, http://www.pearsonglobaleditions.com/\nkurose, you\u2019ll find a Wireshark lab that examines the operation of the IEEE 802.3 \nprotocol and the Wireshark frame format. A second Wireshark lab examines packet \ntraces taken in a home network scenario.\n544Why did you decide to specialize in networking?\nWhen I arrived at UCLA as a new graduate student in Fall 1969, my intention was to study \ncontrol theory. Then I took the queuing theory classes of Leonard Kleinrock and was very \nimpressed by him. For a while, I was working on adaptive control of queuing systems as a \npossible thesis topic. In early 1972, Larry Roberts initiated the ARPAnet Satellite System \nproject (later called Packet Satellite). Professor Kleinrock asked me to join the project. The \nfirst thing we did was to introduce a simple, yet realistic, backoff algorithm to the slotted \nALOHA protocol. Shortly thereafter, I found many interesting research problems, such as \nALOHA\u2019s instability problem and need for adaptive backoff, which would form the core of \nmy thesis.\nYou were active in the early days of the Internet in the 1970s, beginning with your  \nstudent days at UCLA. What was it like then? Did people have any inkling of what the \nInternet would become?\nThe atmosphere was really no different from other system-building projects I have seen in \nindustry and academia. The initially stated goal of the ARPAnet was fairly modest, that \nis, to provide access to expensive computers from remote locations so that many more \nscientists could use them. However, with the startup of the Packet Satellite project in 1972 \nand the Packet Radio project in 1973, ARPA\u2019s goal had expanded substantially. By 1973, \nARPA was building three different packet networks at the same time, and it became neces -\nsary for Vint Cerf and Bob Kahn to develop an interconnection strategy.\nBack then, all of these progressive developments in networking were viewed  \n(I believe) as logical rather than magical. No one could have envisioned the scale of the \nInternet and power of personal computers today. It was a decade before appearance of the \nfirst PCs. To put things in perspective, most students submitted their computer programs Simon S. Lam\nSimon S. Lam is Professor and Regents Chair in Computer Sciences \nat the University of Texas at Austin. From 1971 to 1974, he was \nwith the ARPA Network Measurement Center at UCLA, where he \nworked on satellite and radio packet switching. He led a research", "doc_id": "d524523e-4fdd-41f8-a6b9-da3f4a98e262", "embedding": null, "doc_hash": "d185d5522bad9e16c68f06e061e0398748c7e12ec7486dc9ed3c2e39715372c3", "extra_info": null, "node_info": {"start": 1600501, "end": 1604443}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "a055997a-a88a-4a07-9d8f-b23ac2aac43b", "3": "c0e00ba5-b9e2-464f-bdc2-cbbc10cd9f94"}}, "__type__": "1"}, "c0e00ba5-b9e2-464f-bdc2-cbbc10cd9f94": {"__data__": {"text": "1973, \nARPA was building three different packet networks at the same time, and it became neces -\nsary for Vint Cerf and Bob Kahn to develop an interconnection strategy.\nBack then, all of these progressive developments in networking were viewed  \n(I believe) as logical rather than magical. No one could have envisioned the scale of the \nInternet and power of personal computers today. It was a decade before appearance of the \nfirst PCs. To put things in perspective, most students submitted their computer programs Simon S. Lam\nSimon S. Lam is Professor and Regents Chair in Computer Sciences \nat the University of Texas at Austin. From 1971 to 1974, he was \nwith the ARPA Network Measurement Center at UCLA, where he \nworked on satellite and radio packet switching. He led a research \ngroup that invented secure sockets and prototyped, in 1993, the \nfirst secure sockets layer named Secure Network Programming, \nwhich won the 2004 ACM Software System Award. His research \ninterests are in design and analysis of network protocols and security \nservices. He received his BSEE from Washington State University \nand his MS and PhD from UCLA. He was elected to the National \nAcademy of Engineering in 2007.\nAN INTERVIEW WITH\u2026\n545as decks of punched cards for batch processing. Only some students had direct access to \ncomputers, which were typically housed in a restricted area. Modems were slow and still a \nrarity. As a graduate student, I had only a phone on my desk, and I used pencil and paper to \ndo most of my work.\nWhere do you see the field of networking and the Internet heading in the future?\nIn the past, the simplicity of the Internet\u2019s IP protocol was its greatest strength in vanquish -\ning competition and becoming the de facto  standard for internetworking. Unlike competi -\ntors, such as X.25 in the 1980s and ATM in the 1990s, IP can run on top of any link-layer \nnetworking technology, because it offers only a best-effort datagram service. Thus, any \npacket network can connect to the Internet.\nToday, IP\u2019s greatest strength is actually a shortcoming. IP is like a straitjacket that \nconfines the Internet\u2019s development to specific directions. In recent years, many research -\ners have redirected their efforts to the application layer only. There is also a great deal of \nresearch on wireless ad hoc networks, sensor networks, and satellite networks. These net -\nworks can be viewed either as stand-alone systems or link-layer systems, which can flourish \nbecause they are outside of the IP straitjacket.\nMany people are excited about the possibility of P2P systems as a platform for novel \nInternet applications. However, P2P systems are highly inefficient in their use of Internet \nresources. A concern of mine is whether the transmission and switching capacity of the \nInternet core will continue to increase faster than the traffic demand on the Internet as it \ngrows to interconnect all kinds of devices and support future P2P-enabled applications. \nWithout substantial overprovisioning of capacity, ensuring network stability in the presence \nof malicious attacks and congestion will continue to be a significant challenge.\nThe Internet\u2019s phenomenal growth also requires the allocation of new IP addresses at \na rapid rate to network operators and enterprises worldwide. At the current rate, the pool of \nunallocated IPv4 addresses would be depleted in a few years. When that happens, large con -\ntiguous blocks of address space can only be allocated from the IPv6 address space. Since \nadoption of IPv6 is off to a slow start, due to lack of incentives for early adopters, IPv4 and \nIPv6 will most likely co-exist on the Internet for many years to come. Successful migra -\ntion from an IPv4-dominant Internet to an IPv6-dominant Internet will require a substantial \nglobal effort.\nWhat is the most challenging part of your job?\nThe most challenging part of my job as a professor is teaching and motivating every  stu-\ndent in my class, and every  doctoral student under my supervision, rather than just the", "doc_id": "c0e00ba5-b9e2-464f-bdc2-cbbc10cd9f94", "embedding": null, "doc_hash": "ba8662e04150c98bfd441c777f4dfd1fce5095262c16cb49fe4b4036830490a9", "extra_info": null, "node_info": {"start": 1604431, "end": 1608464}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "d524523e-4fdd-41f8-a6b9-da3f4a98e262", "3": "72db00b8-72b3-47fa-b009-3c890eafcd7b"}}, "__type__": "1"}, "72db00b8-72b3-47fa-b009-3c890eafcd7b": {"__data__": {"text": "the current rate, the pool of \nunallocated IPv4 addresses would be depleted in a few years. When that happens, large con -\ntiguous blocks of address space can only be allocated from the IPv6 address space. Since \nadoption of IPv6 is off to a slow start, due to lack of incentives for early adopters, IPv4 and \nIPv6 will most likely co-exist on the Internet for many years to come. Successful migra -\ntion from an IPv4-dominant Internet to an IPv6-dominant Internet will require a substantial \nglobal effort.\nWhat is the most challenging part of your job?\nThe most challenging part of my job as a professor is teaching and motivating every  stu-\ndent in my class, and every  doctoral student under my supervision, rather than just the high \nachievers. The very bright and motivated may require a little guidance but not much else.  \n546I often learn more from these students than they learn from me. Educating and motivating \nthe underachievers present a major challenge.\nWhat impacts do you foresee technology having on learning in the future?\nEventually, almost all human knowledge will be accessible through the Internet, which will \nbe the most powerful tool for learning. This vast knowledge base will have the potential of \nleveling the playing field for students all over the world. For example, motivated students in \nany country will be able to access the best-class Web sites, multimedia lectures, and teach -\ning materials. Already, it was said that the IEEE and ACM digital libraries have accelerated \nthe development of computer science researchers in China. In time, the Internet will tran -\nscend all geographic barriers to learning.\n547In the telephony world, the past 20 years have arguably been the golden years of \ncellular telephony. The number of worldwide mobile cellular subscribers increased \nfrom 34 million in 1993 to nearly 7.0 billion subscribers by 2014, with the number \nof cellular subscribers now surpassing the number of wired telephone lines. There \nare now a larger number of mobile phone subscriptions than there are people on our \nplanet. The many advantages of cell phones are evident to all\u2014anywhere, anytime, \nuntethered access to the global telephone network via a highly portable lightweight \ndevice. More recently, laptops, smartphones, and tablets  are wirelessly connected \nto the Internet via a cellular  or  WiFi network.  And increasingly, devices such as \ngaming consoles, thermostats, home security systems, home appliances, watches, \neye glasses, cars, traffic control systems and more are being wirelessly connected to \nthe Internet.\nFrom a networking standpoint, the challenges posed by networking these wire -\nless and mobile devices, particularly at the link layer and the network layer, are so \ndifferent from traditional wired computer networks that an individual chapter devoted \nto the study of wireless and mobile networks (i.e., this chapter) is appropriate.\nWe\u2019ll begin this chapter with a discussion of mobile users, wireless links, and \nnetworks, and their relationship to the larger (typically wired) networks to which \nthey connect. We\u2019ll draw a distinction between the challenges posed by the  wireless  \nnature of the communication links in such networks, and by the mobility  that these \nwireless links enable. Making this important distinction\u2014between wireless and \nmobility\u2014will allow us to better isolate, identify, and master the key concepts in \neach area. Note that there are indeed many networked environments in which the net -\nwork nodes are wireless but not mobile (e.g., wireless home or office networks with 7CHAPTER\nWireless \nand Mobile \nNetworks\n\n548     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\nstationary workstations and large displays), and that there are limited forms of mobil -\nity that do not require wireless links (e.g., a worker who uses a wired laptop at home, \nshuts down the laptop, drives to work, and attaches the laptop to the company\u2019s \nwired network). Of course, many of the most exciting networked environments are \nthose in which users are both wireless and mobile\u2014for example, a", "doc_id": "72db00b8-72b3-47fa-b009-3c890eafcd7b", "embedding": null, "doc_hash": "714c32eb835180504fbc7bbd2d431ebf22f4e4ef64aaec32708d4ee78a475503", "extra_info": null, "node_info": {"start": 1608511, "end": 1612598}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "c0e00ba5-b9e2-464f-bdc2-cbbc10cd9f94", "3": "cf4f0c19-f13c-4981-9d73-7f1673648fed"}}, "__type__": "1"}, "cf4f0c19-f13c-4981-9d73-7f1673648fed": {"__data__": {"text": "isolate, identify, and master the key concepts in \neach area. Note that there are indeed many networked environments in which the net -\nwork nodes are wireless but not mobile (e.g., wireless home or office networks with 7CHAPTER\nWireless \nand Mobile \nNetworks\n\n548     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\nstationary workstations and large displays), and that there are limited forms of mobil -\nity that do not require wireless links (e.g., a worker who uses a wired laptop at home, \nshuts down the laptop, drives to work, and attaches the laptop to the company\u2019s \nwired network). Of course, many of the most exciting networked environments are \nthose in which users are both wireless and mobile\u2014for example, a scenario in which \na mobile user (say in the back seat of car) maintains a Voice-over-IP call and multi -\nple ongoing TCP connections while racing down the autobahn at 160 kilometers per \nhour, soon in an autonomous vehicle. It is here, at the intersection of wireless and \nmobility, that we\u2019ll find the most interesting technical challenges!\nWe\u2019ll begin by illustrating the setting in which we\u2019ll consider wireless commu -\nnication and mobility\u2014a network in which wireless (and possibly mobile) users are \nconnected into the larger network infrastructure by a wireless link at the network\u2019s \nedge. We\u2019ll then consider the characteristics of this wireless link in Section 7.2. We \ninclude a brief introduction to code division multiple access (CDMA), a shared-\nmedium access protocol that is often used in wireless networks, in Section 7.2. In \nSection 7. 3, we\u2019ll examine the link-level aspects of the IEEE 802.11 (WiFi) wireless \nLAN standard in some depth; we\u2019ll also say a few words about Bluetooth and other \nwireless personal area networks. In Section 7.4, we\u2019ll provide an overview of cellular \nInternet access, including 3G and emerging 4G cellular technologies that provide \nboth voice and high-speed Internet access. In Section 7.5, we\u2019ll turn our attention to \nmobility, focusing on the problems of locating a mobile user, routing to the mobile \nuser, and \u201chanding off\u201d the mobile user who dynamically moves from one point of \nattachment to the network to another. We\u2019ll examine how these mobility services are \nimplemented in the mobile IP standard in enterprise 802.11 networks, and in LTE \ncellular networks in Sections 7.6 and 7.7, respectively. Finally, we\u2019ll consider the \nimpact of wireless links and mobility on transport-layer protocols and networked \napplications in Section 7.8.\n7.1 Introduction\nFigure 7. 1 shows the setting in which we\u2019ll consider the topics of wireless data com -\nmunication and mobility. We\u2019ll begin by keeping our discussion general enough to \ncover a wide range of networks, including both wireless LANs such as IEEE 802.11 \nand cellular networks such as a 4G network; we\u2019ll drill down into a more detailed \ndiscussion of specific wireless architectures in later sections. We can identify the \nfollowing elements in a wireless network:\n\u2022 Wireless hosts.  As in the case of wired networks, hosts are the end-system devices \nthat run applications. A wireless host  might be a laptop, tablet, smartphone, or \ndesktop computer. The hosts themselves may or may not be mobile.\n7.1  \u2022  INTRODUCTION      549\n\u2022 Wireless links.  A host connects to a base station (defined below) or to another \nwireless host through a wireless communication link . Different wireless link \ntechnologies have different transmission rates and can transmit over differ -\nent distances. Figure 7.2 shows two key characteristics (coverage area and \nlink rate) of the more popular wireless network standards. (The figure is only \nmeant to provide a rough idea of these characteristics. For example, some of \nthese types of networks are only now being deployed, and", "doc_id": "cf4f0c19-f13c-4981-9d73-7f1673648fed", "embedding": null, "doc_hash": "b7aa62db29a71686ee7c570507e013094830b7543b1418dfce427327b79b4270", "extra_info": null, "node_info": {"start": 1612607, "end": 1616404}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "72db00b8-72b3-47fa-b009-3c890eafcd7b", "3": "0c9ef5f1-76d5-4b5b-9c44-04dfad7900be"}}, "__type__": "1"}, "0c9ef5f1-76d5-4b5b-9c44-04dfad7900be": {"__data__": {"text": "in the case of wired networks, hosts are the end-system devices \nthat run applications. A wireless host  might be a laptop, tablet, smartphone, or \ndesktop computer. The hosts themselves may or may not be mobile.\n7.1  \u2022  INTRODUCTION      549\n\u2022 Wireless links.  A host connects to a base station (defined below) or to another \nwireless host through a wireless communication link . Different wireless link \ntechnologies have different transmission rates and can transmit over differ -\nent distances. Figure 7.2 shows two key characteristics (coverage area and \nlink rate) of the more popular wireless network standards. (The figure is only \nmeant to provide a rough idea of these characteristics. For example, some of \nthese types of networks are only now being deployed, and some link rates can \nincrease or decrease beyond the values shown depending on distance, channel \nconditions, and the number of users in the wireless network.) We\u2019ll cover these \nstandards later in the first half of this chapter; we\u2019ll also consider other wireless \nlink characteristics (such as their bit error rates and the causes of bit errors) in \nSection 7.2.\n In Figure 7.1, wireless links connect wireless hosts located at the edge of the \nnetwork into the larger network infrastructure. We hasten to add that wireless \nlinks are also sometimes used within  a network to connect routers, switches, and Figure 7.1  \u2666 Elements of a wireless networkNetwork\ninfrastructure\nKey:\nWireless access point\nCoverage areaWireless host\nWireless host in motion\n550     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\nother network equipment. However, our focus in this chapter will be on the use of \nwireless communication at the network edge, as it is here that many of the most \nexciting technical challenges, and most of the growth, are occurring.\n\u2022 Base station.  The base station  is a key part of the wireless network infrastructure. \nUnlike the wireless host and wireless link, a base station has no obvious counter -\npart in a wired network. A base station is responsible for sending and receiving \ndata (e.g., packets) to and from a wireless host that is associated with that base \nstation. A base station will often be responsible for coordinating the transmission \nof multiple wireless hosts with which it is associated. When we say a wireless \nhost is \u201cassociated\u201d with a base station, we mean that (1) the host is within the \nwireless communication distance of the base station, and (2) the host uses that \nbase station to relay data between it (the host) and the larger network. Cell towers  \nin cellular networks and access points  in 802.11 wireless LANs are examples of \nbase stations.\n In Figure 7.1, the base station is connected to the larger network (e.g., the  Internet, \ncorporate or home network, or telephone network), thus functioning as a link-\nlayer relay between the wireless host and the rest of the world with which the host \ncommunicates.\n Hosts associated with a base station are often referred to as operating in \n infrastructure mode , since all traditional network services (e.g., address assign -\nment and routing) are provided by the network to which a host is connected via Figure 7.2  \u2666 Link characteristics of selected wireless network standards802.11ac\n802.11a,g802.11n\n802.11b\n802.15.1\n3G: UMTS/WCDMA, CDMA2000\n2G: IS-95, CDMA, GSM\nIndoor Outdoor Mid range\noutdoorLong range\noutdoor\n10\u201330m 50\u2013200m 200m\u20134Km 5Km\u201320Km54 Mbps\n4 Mbps5\u201311 Mbps450 Mbps\n1 Mbps\n384 KbpsEnhanced 3G: HSPA4G: LTE\n802.11a,g point-to-point1300 Mbps\n7.1  \u2022  INTRODUCTION      551\nthe base station. In ad hoc networks , wireless hosts have no such infrastructure \nwith which to connect. In the absence of such infrastructure, the hosts themselves \nmust provide for services such as routing, address assignment,", "doc_id": "0c9ef5f1-76d5-4b5b-9c44-04dfad7900be", "embedding": null, "doc_hash": "a9a538472ee2028ccde5c35381f2f2dfb8274366b1dd728eb768bae17082ae08", "extra_info": null, "node_info": {"start": 1616361, "end": 1620150}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "cf4f0c19-f13c-4981-9d73-7f1673648fed", "3": "564e4b7d-ca49-4965-a6ed-f1cb2a73f0bb"}}, "__type__": "1"}, "564e4b7d-ca49-4965-a6ed-f1cb2a73f0bb": {"__data__": {"text": "UMTS/WCDMA, CDMA2000\n2G: IS-95, CDMA, GSM\nIndoor Outdoor Mid range\noutdoorLong range\noutdoor\n10\u201330m 50\u2013200m 200m\u20134Km 5Km\u201320Km54 Mbps\n4 Mbps5\u201311 Mbps450 Mbps\n1 Mbps\n384 KbpsEnhanced 3G: HSPA4G: LTE\n802.11a,g point-to-point1300 Mbps\n7.1  \u2022  INTRODUCTION      551\nthe base station. In ad hoc networks , wireless hosts have no such infrastructure \nwith which to connect. In the absence of such infrastructure, the hosts themselves \nmust provide for services such as routing, address assignment, DNS-like name \ntranslation, and more.\n When a mobile host moves beyond the range of one base station and into the \nrange of another, it will change its point of attachment into the larger network PUBLIC WIFI ACCESS: COMING SOON TO A LAMP POST NEAR YOU?\nWiFi hotspots\u2014public locations where users can find 802.11 wireless access\u2014are \nbecoming increasingly common in hotels, airports, and caf\u00e9s around the world. Most \ncollege campuses offer ubiquitous wireless access, and it\u2019s hard to find a hotel that \ndoesn\u2019t offer wireless Internet access.\nOver the past decade a number of cities have designed, deployed, and oper -\nated municipal WiFi networks. The vision of providing ubiquitous WiFi access to the \ncommunity as a public service (much like streetlights)\u2014helping to bridge the digital \ndivide by providing Internet access to all citizens and to promote economic develop -\nment\u2014is compelling. Many cities around the world, including Philadelphia, Toronto, \nHong Kong, Minneapolis, London, and Auckland, have plans to provide ubiquitous \nwireless within the city, or have already done so to varying degrees. The goal in \nPhiladelphia was to \u201cturn Philadelphia into the nation\u2019s largest WiFi hotspot and help \nto improve education, bridge the digital divide, enhance neighborhood develop -\nment, and reduce the costs of government.\u201d The ambitious program\u2014an agreement \nbetween the city, Wireless Philadelphia (a nonprofit entity), and the Internet Service \nProvider Earthlink\u2014built an operational network of 802.11b hotspots on streetlamp \npole arms and traffic control devices that covered 80 percent of the city. But financial \nand operational concerns caused the network to be sold to a group of private inves -\ntors in 2008, who later sold the network back to the city in 2010. Other cities, such \nas Minneapolis, Toronto, Hong Kong, and Auckland, have had success with smaller-\nscale efforts.\nThe fact that 802.11 networks operate in the unlicensed spectrum (and hence \ncan be deployed without purchasing expensive spectrum use rights) would seem to \nmake them financially attractive. However, 802.11 access points (see Section 7.3) \nhave much shorter ranges than 4G cellular base stations (see Section 7.4), requir -\ning a larger number of deployed endpoints to cover the same geographic region. \nCellular data networks providing Internet access, on the other hand, operate in the \nlicensed spectrum. Cellular providers pay billions of dollars for spectrum access \nrights for their networks, making cellular data networks a business rather than munic -\nipal undertaking.CASE HISTORY\n\n552     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\n(i.e., change the base station with which it is associated)\u2014a process referred to \nas handoff . Such mobility raises many challenging questions. If a host can move, \nhow does one find the mobile host\u2019s current location in the network so that data \ncan be forwarded to that mobile host? How is addressing performed, given that \na host can be in one of many possible locations? If the host moves during  a \nTCP connection or phone call, how is data routed so that the connection contin -\nues uninterrupted? These and many (many!) other questions make wireless and \nmobile networking an area of exciting networking research.\n\u2022 Network", "doc_id": "564e4b7d-ca49-4965-a6ed-f1cb2a73f0bb", "embedding": null, "doc_hash": "e01f4a4372a9dd8505121ec2b2064bfd8e1c306a1272f7941903d10475762a0f", "extra_info": null, "node_info": {"start": 1620374, "end": 1624142}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "0c9ef5f1-76d5-4b5b-9c44-04dfad7900be", "3": "4dca43ae-fc6e-43d0-a1ba-9d09901f8e6c"}}, "__type__": "1"}, "4dca43ae-fc6e-43d0-a1ba-9d09901f8e6c": {"__data__": {"text": "business rather than munic -\nipal undertaking.CASE HISTORY\n\n552     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\n(i.e., change the base station with which it is associated)\u2014a process referred to \nas handoff . Such mobility raises many challenging questions. If a host can move, \nhow does one find the mobile host\u2019s current location in the network so that data \ncan be forwarded to that mobile host? How is addressing performed, given that \na host can be in one of many possible locations? If the host moves during  a \nTCP connection or phone call, how is data routed so that the connection contin -\nues uninterrupted? These and many (many!) other questions make wireless and \nmobile networking an area of exciting networking research.\n\u2022 Network infrastructure.  This is the larger network with which a wireless host may \nwish to communicate.\nHaving discussed the \u201cpieces\u201d of a wireless network, we note that these pieces \ncan be combined in many different ways to form different types of wireless net -\nworks. You may find a taxonomy of these types of wireless networks useful as you \nread on in this chapter, or read/learn more about wireless networks beyond this book. \nAt the highest level we can classify wireless networks according to two criteria: (i) \nwhether a packet in the wireless network crosses exactly one wireless hop or multiple \nwireless hops , and (ii) whether there is infrastructure  such as a base station in the \nnetwork:\n\u2022 Single-hop, infrastructure-based.  These networks have a base station that is con -\nnected to a larger wired network (e.g., the Internet). Furthermore, all commu -\nnication is between this base station and a wireless host over a single wireless \nhop. The 802.11 networks you use in the classroom, caf\u00e9, or library; and the 4G \nLTE data networks that we will learn about shortly all fall in this category. The \nvast majority of our daily interactions are with single-hop, infrastructure-based \n wireless networks.\n\u2022 Single-hop, infrastructure-less.  In these networks, there is no base station that \nis connected to a wireless network. However, as we will see, one of the nodes \nin this single-hop network may coordinate the transmissions of the other nodes. \n Bluetooth networks (that connect small wireless devices such as keyboards, \nspeakers, and headsets, and which we will study in Section 7.3.6) and 802.11 \nnetworks in ad hoc mode are single-hop, infrastructure-less networks.\n\u2022 Multi-hop, infrastructure-based.  In these networks, a base station is present that \nis wired to the larger network. However, some wireless nodes may have to relay \ntheir communication through other wireless nodes in order to communicate via \nthe base station. Some wireless sensor networks and so-called wireless mesh \nnetworks  fall in this category.\n\u2022 Multi-hop, infrastructure-less.  There is no base station in these networks, and \nnodes may have to relay messages among several other nodes in order to reach \na destination. Nodes may also be mobile, with connectivity changing among \nnodes\u2014a class of networks known as mobile ad hoc networks (MANETs) . \n7.2  \u2022  WIRELESS LINKS AND NETWORK CHARACTERISTICS      553\nIf the mobile nodes are vehicles, the network is a vehicular ad hoc network \n(VANET) . As you might imagine, the development of protocols for such net -\nworks is challenging and is the subject of much ongoing research.\nIn this chapter, we\u2019ll mostly confine ourselves to single-hop networks, and then \nmostly to infrastructure-based networks.\nLet\u2019s now dig deeper into the technical challenges that arise in wireless and \nmobile networks. We\u2019ll begin by first considering the individual wireless link, defer -\nring our discussion of mobility until later in this chapter.\n7.2 Wireless Links and Network Characteristics\nLet\u2019s begin by considering a simple wired network, say a home network, with a \nwired Ethernet switch (see Section", "doc_id": "4dca43ae-fc6e-43d0-a1ba-9d09901f8e6c", "embedding": null, "doc_hash": "1913ed9a5293cc8ae161a56e5011a8df87163b9c8b5971a2f8e929493eea01ae", "extra_info": null, "node_info": {"start": 1623944, "end": 1627827}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "564e4b7d-ca49-4965-a6ed-f1cb2a73f0bb", "3": "9506cf0a-81c6-4a97-b0a0-0d331cf5e99c"}}, "__type__": "1"}, "9506cf0a-81c6-4a97-b0a0-0d331cf5e99c": {"__data__": {"text": "     553\nIf the mobile nodes are vehicles, the network is a vehicular ad hoc network \n(VANET) . As you might imagine, the development of protocols for such net -\nworks is challenging and is the subject of much ongoing research.\nIn this chapter, we\u2019ll mostly confine ourselves to single-hop networks, and then \nmostly to infrastructure-based networks.\nLet\u2019s now dig deeper into the technical challenges that arise in wireless and \nmobile networks. We\u2019ll begin by first considering the individual wireless link, defer -\nring our discussion of mobility until later in this chapter.\n7.2 Wireless Links and Network Characteristics\nLet\u2019s begin by considering a simple wired network, say a home network, with a \nwired Ethernet switch (see Section 6. 4) interconnecting the hosts. If we replace \nthe wired Ethernet with a wireless 802.11 network, a wireless network interface \nwould replace the host\u2019s wired Ethernet interface, and an access point would \nreplace the Ethernet switch, but virtually no changes would be needed at the net -\nwork layer or above. This suggests that we focus our attention on the link layer \nwhen looking for important differences between wired and wireless networks. \nIndeed, we can find a number of important differences between a wired link and \na wireless link:\n\u2022 Decreasing signal strength . Electromagnetic radiation attenuates as it passes \nthrough matter (e.g., a radio signal passing through a wall). Even in free space, \nthe signal will disperse, resulting in decreased signal strength (sometimes referred \nto as path loss ) as the distance between sender and receiver increases.\n\u2022 Interference from other sources.  Radio sources transmitting in the same frequency \nband will interfere with each other. For example, 2.4 GHz wireless phones and \n802.11b wireless LANs transmit in the same frequency band. Thus, the 802.11b \nwireless LAN user talking on a 2.4 GHz wireless phone can expect that neither \nthe network nor the phone will perform particularly well. In addition to interfer -\nence from transmitting sources, electromagnetic noise within the environment \n(e.g., a nearby motor, a microwave) can result in interference.\n\u2022 Multipath propagation.  Multipath propagation  occurs when portions of the \nelectromagnetic wave reflect off objects and the ground, taking paths of different \nlengths between a sender and receiver. This results in the blurring of the received \nsignal at the receiver. Moving objects between the sender and receiver can cause \nmultipath propagation to change over time.\nFor a detailed discussion of wireless channel characteristics, models, and measure -\nments, see [Anderson 1995].\n554     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\nThe discussion above suggests that bit errors will be more common in wireless \nlinks than in wired links. For this reason, it is perhaps not surprising that wireless \nlink protocols (such as the 802.11 protocol we\u2019ll examine in the following section) \nemploy not only powerful CRC error detection codes, but also link-level relia -\nble-data-transfer protocols that retransmit corrupted frames.\nHaving considered the impairments that can occur on a wireless channel, let\u2019s \nnext turn our attention to the host receiving the wireless signal. This host receives an \nelectromagnetic signal that is a combination of a degraded form of the original signal \ntransmitted by the sender (degraded due to the attenuation and multipath propagation \neffects that we discussed above, among others) and background noise in the environ -\nment. The signal-to-noise ratio (SNR)  is a relative measure of the strength of the \nreceived signal (i.e., the information being transmitted) and this noise. The SNR \nis typically measured in units of decibels (dB), a unit of measure that some think \nis used by electrical engineers primarily to confuse computer scientists. The SNR, \nmeasured in dB, is twenty times the ratio of the base-10", "doc_id": "9506cf0a-81c6-4a97-b0a0-0d331cf5e99c", "embedding": null, "doc_hash": "bae8e79bb0e8f6928c128592e1a3196855bc1cbd36a77fa86523e276f8362acf", "extra_info": null, "node_info": {"start": 1627825, "end": 1631736}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "4dca43ae-fc6e-43d0-a1ba-9d09901f8e6c", "3": "f5b5088b-ee0e-459b-908f-4591d6006bc8"}}, "__type__": "1"}, "f5b5088b-ee0e-459b-908f-4591d6006bc8": {"__data__": {"text": "turn our attention to the host receiving the wireless signal. This host receives an \nelectromagnetic signal that is a combination of a degraded form of the original signal \ntransmitted by the sender (degraded due to the attenuation and multipath propagation \neffects that we discussed above, among others) and background noise in the environ -\nment. The signal-to-noise ratio (SNR)  is a relative measure of the strength of the \nreceived signal (i.e., the information being transmitted) and this noise. The SNR \nis typically measured in units of decibels (dB), a unit of measure that some think \nis used by electrical engineers primarily to confuse computer scientists. The SNR, \nmeasured in dB, is twenty times the ratio of the base-10 logarithm of the amplitude \nof the received signal to the amplitude of the noise. For our purposes here, we need \nonly know that a larger SNR makes it easier for the receiver to extract the transmitted \nsignal from the background noise.\nFigure 7. 3 (adapted from [Holland 2001]) shows the bit error rate (BER)\u2014\nroughly speaking, the probability that a transmitted bit is received in error at the \nreceiver\u2014versus the SNR for three different modulation techniques for encoding \ninformation for transmission on an idealized wireless channel. The theory of modu -\nlation and coding, as well as signal extraction and BER, is well beyond the scope of \nFigure 7.3  \u2666 Bit error rate, transmission rate, and SNR10\u2013710\u2013610\u2013510\u2013410\u2013310\u2013210\u20131\n10 20 30 40 0\nSNR (dB)BERQAM16\n(4 Mbps)QAM256\n(8 Mbps)\nBPSK\n(1 Mbps)\n7.2  \u2022  WIRELESS LINKS AND NETWORK CHARACTERISTICS      555\nthis text (see [Schwartz 1980] for a discussion of these topics). Nonetheless, Figure \n7.3 illustrates several physical-layer characteristics that are important in understand -\ning higher-layer wireless communication protocols:\n\u2022 For a given modulation scheme, the higher the SNR, the lower the BER.  Since \na sender can increase the SNR by increasing its transmission power, a sender \ncan decrease the probability that a frame is received in error by increasing its \ntransmission power. Note, however, that there is arguably little practical gain in \nincreasing the power beyond a certain threshold, say to decrease the BER from \n10-12 to 10-13. There are also disadvantages  associated with increasing the trans -\nmission power: More energy must be expended by the sender (an important con -\ncern for battery-powered mobile users), and the sender\u2019s transmissions are more \nlikely to interfere with the transmissions of another sender (see Figure 7.4(b)).\n\u2022 For a given SNR, a modulation technique with a higher bit transmission rate \n(whether in error or not) will have a higher BER.  For example, in Figure 7.3, \nwith an SNR of 10 dB, BPSK modulation with a transmission rate of 1 Mbps has \na BER of less than 10-7, while with QAM16 modulation with a transmission rate \nof 4 Mbps, the BER is 10-1, far too high to be practically useful. However, with \nan SNR of 20 dB, QAM16 modulation has a transmission rate of 4 Mbps and a \nBER of 10-7, while BPSK modulation has a transmission rate of only 1 Mbps \nand a BER that is so low as to be (literally) \u201coff the charts.\u201d If one can tolerate a \nBER of 10-7, the higher transmission rate offered by QAM16 would make it the \npreferred modulation technique in this situation. These considerations give rise to \nthe final characteristic, described next.\n\u2022 Dynamic selection of the physical-layer modulation technique can be used to \nadapt the modulation technique to channel conditions.  The SNR (and hence Figure 7.4  \u2666 Hidden terminal problem caused by obstacle (a) and fading (b)AA\nCBC\nLocation\nb. a.0Signal", "doc_id": "f5b5088b-ee0e-459b-908f-4591d6006bc8", "embedding": null, "doc_hash": "471699721784067a861cb30279e698db681f983d88c6c5bf0b6ec34f47dac1d5", "extra_info": null, "node_info": {"start": 1631743, "end": 1635394}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "9506cf0a-81c6-4a97-b0a0-0d331cf5e99c", "3": "080b7fa0-7ba3-4d1e-b55c-fe0686d98c3c"}}, "__type__": "1"}, "080b7fa0-7ba3-4d1e-b55c-fe0686d98c3c": {"__data__": {"text": "with \nan SNR of 20 dB, QAM16 modulation has a transmission rate of 4 Mbps and a \nBER of 10-7, while BPSK modulation has a transmission rate of only 1 Mbps \nand a BER that is so low as to be (literally) \u201coff the charts.\u201d If one can tolerate a \nBER of 10-7, the higher transmission rate offered by QAM16 would make it the \npreferred modulation technique in this situation. These considerations give rise to \nthe final characteristic, described next.\n\u2022 Dynamic selection of the physical-layer modulation technique can be used to \nadapt the modulation technique to channel conditions.  The SNR (and hence Figure 7.4  \u2666 Hidden terminal problem caused by obstacle (a) and fading (b)AA\nCBC\nLocation\nb. a.0Signal strength\nB\n556     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\nthe BER) may change as a result of mobility or due to changes in the environ -\nment. Adaptive modulation and coding are used in cellular data systems and in \nthe 802.11 WiFi and 4G cellular data networks that we\u2019ll study in Sections 7.3 \nand 7. 4. This allows, for example, the selection of a modulation technique that \nprovides the highest transmission rate possible subject to a constraint on the BER, \nfor given channel characteristics.\nA higher and time-varying bit error rate is not the only difference between a \nwired and wireless link. Recall that in the case of wired broadcast links, all nodes \nreceive the transmissions from all other nodes. In the case of wireless links, the situ -\nation is not as simple, as shown in Figure 7.4. Suppose that Station A is transmit -\nting to Station B. Suppose also that Station C is transmitting to Station B. With the \nso-called hidden terminal problem , physical obstructions in the environment (for \nexample, a mountain or a building) may prevent A and C from hearing each other\u2019s \ntransmissions, even though A\u2019s and C\u2019s transmissions are indeed interfering at the \ndestination, B. This is shown in Figure 7.4(a). A second scenario that results in unde -\ntectable collisions at the receiver results from the fading  of a signal\u2019s strength as it \npropagates through the wireless medium. Figure 7.4(b) illustrates the case where A \nand C are placed such that their signals are not strong enough to detect each other\u2019s \ntransmissions, yet their signals are strong enough to interfere with each other at sta -\ntion B. As we\u2019ll see in Section 7.3, the hidden terminal problem and fading make \nmultiple access in a wireless network considerably more complex than in a wired \nnetwork.\n7.2.1 CDMA\nRecall from Chapter 6 that when hosts communicate over a shared medium, a pro -\ntocol is needed so that the signals sent by multiple senders do not interfere at the \nreceivers. In Chapter 6 we described three classes of medium access protocols: chan -\nnel partitioning, random access, and taking turns. Code division multiple access \n(CDMA) belongs to the family of channel partitioning protocols. It is prevalent in \nwireless LAN and cellular technologies. Because CDMA is so important in the wire -\nless world, we\u2019ll take a quick look at CDMA now, before getting into specific wire -\nless access technologies in the subsequent sections.\nIn a CDMA protocol, each bit being sent is encoded by multiplying the bit by \na signal (the code) that changes at a much faster rate (known as the chipping rate ) \nthan the original sequence of data bits. Figure 7.5 shows a simple, idealized CDMA \nencoding/decoding scenario. Suppose that the rate at which original data bits reach \nthe CDMA encoder defines the unit of time; that is, each original data bit to be \ntransmitted requires a one-bit slot time. Let di be the value of the data bit for the \nith bit slot. For mathematical convenience, we represent a data bit with a 0 value \nas -1. Each bit slot is further", "doc_id": "080b7fa0-7ba3-4d1e-b55c-fe0686d98c3c", "embedding": null, "doc_hash": "f491e6ed5501435d56c11368bc4280a4fe13142457db1fcd1db62057144bbb9d", "extra_info": null, "node_info": {"start": 1635427, "end": 1639192}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "f5b5088b-ee0e-459b-908f-4591d6006bc8", "3": "32dc3a15-4640-4999-a48f-233a54f5af8a"}}, "__type__": "1"}, "32dc3a15-4640-4999-a48f-233a54f5af8a": {"__data__": {"text": "-\nless world, we\u2019ll take a quick look at CDMA now, before getting into specific wire -\nless access technologies in the subsequent sections.\nIn a CDMA protocol, each bit being sent is encoded by multiplying the bit by \na signal (the code) that changes at a much faster rate (known as the chipping rate ) \nthan the original sequence of data bits. Figure 7.5 shows a simple, idealized CDMA \nencoding/decoding scenario. Suppose that the rate at which original data bits reach \nthe CDMA encoder defines the unit of time; that is, each original data bit to be \ntransmitted requires a one-bit slot time. Let di be the value of the data bit for the \nith bit slot. For mathematical convenience, we represent a data bit with a 0 value \nas -1. Each bit slot is further subdivided into M mini-slots; in Figure 7.5, M=8,  \n7.2  \u2022  WIRELESS LINKS AND NETWORK CHARACTERISTICS      557\nalthough in practice M is much larger. The CDMA code used by the sender con -\nsists of a sequence of M values, cm, m=1, . . . , M, each taking a +1 or -1 value. \nIn the example in Figure 7.5, the M-bit CDMA code being used by the sender is \n(1, 1, 1, -1, 1, -1, -1, -1).\nTo illustrate how CDMA works, let us focus on the ith data bit, di. For the mth \nmini-slot of the bit-transmission time of di, the output of the CDMA encoder, Zi,m, is \nthe value of di multiplied by the mth bit in the assigned CDMA code, cm:\n Zi,m=di#cm (7.1)Figure 7.5  \u2666 A simple CDMA example: Sender encoding, receiver decoding1 111\n-1-1-1-11 111\n-1-1-1-11\n-1 -1 -1-1111 1\n-1 -1-1-1111\nTime slot 1\nreceived inputTime slot 0\nreceived input\nCode1\n-1 -1 -1-1111 1\n-1 -1-1-1111 Data bits\nCode 1 111\n-1 -1-1-11 111\n-1-1-1-1d1 = -1d0 = 1\nTime slot 1Sender Channel output Zi,m\nReceiverZi,m di \u2022 cm =\nZi,m\u2022 cm\nd\nMim=1M\n5STime slot 1\nchannel outputTime slot 0\nchannel output\nTime slot 0\nd1 = -1d0 = 1\n558     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\nIn a simple world, with no interfering senders, the receiver would receive the encoded \nbits, Zi,m, and recover the original data bit, di, by computing:\n di=1\nM aM\nm=1Zi,m#cm (7.2)\nThe reader might want to work through the details of the example in Figure 7.5 to \nsee that the original data bits are indeed correctly recovered at the receiver using \nEquation 7.2.\nThe world is far from ideal, however, and as noted above, CDMA must work in \nthe presence of interfering senders that are encoding and transmitting their data using \na different assigned code. But how can a CDMA receiver recover a sender\u2019s original \ndata bits when those data bits are being tangled with bits being transmitted by other \nsenders? CDMA works under the assumption that the interfering transmitted bit sig -\nnals are additive. This means, for example, that if three senders send a 1 value, and a \nfourth sender sends a -1 value during the same mini-slot, then the received signal at \nall receivers during that mini-slot is a 2 (since 1 +1+1-1=2). In the presence \nof multiple senders, sender s computes its encoded transmissions, Zs\ni,m, in exactly \nthe same manner as in Equation 7.1. The value received at a receiver during the mth \nmini-slot of the ith bit slot, however, is", "doc_id": "32dc3a15-4640-4999-a48f-233a54f5af8a", "embedding": null, "doc_hash": "7400ec5e788b807a150c8f8903fa0bff90d0aab5864c14a1747bd061caab9b4b", "extra_info": null, "node_info": {"start": 1639156, "end": 1642300}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "080b7fa0-7ba3-4d1e-b55c-fe0686d98c3c", "3": "7bb267d0-a37d-4ae3-be28-fc19a64e863a"}}, "__type__": "1"}, "7bb267d0-a37d-4ae3-be28-fc19a64e863a": {"__data__": {"text": "But how can a CDMA receiver recover a sender\u2019s original \ndata bits when those data bits are being tangled with bits being transmitted by other \nsenders? CDMA works under the assumption that the interfering transmitted bit sig -\nnals are additive. This means, for example, that if three senders send a 1 value, and a \nfourth sender sends a -1 value during the same mini-slot, then the received signal at \nall receivers during that mini-slot is a 2 (since 1 +1+1-1=2). In the presence \nof multiple senders, sender s computes its encoded transmissions, Zs\ni,m, in exactly \nthe same manner as in Equation 7.1. The value received at a receiver during the mth \nmini-slot of the ith bit slot, however, is now the sum of the transmitted bits from all \nN senders during that mini-slot:\nZ*\ni, m=aN\ns=1Zs\ni,m\nAmazingly, if the senders\u2019 codes are chosen carefully, each receiver can recover the \ndata sent by a given sender out of the aggregate signal simply by using the sender\u2019s \ncode in exactly the same manner as in Equation 7.2:\n di=1\nMaM\nm=1Zi,m*#cm (7.3)\nas shown in Figure 7.6, for a two-sender CDMA example. The M-bit CDMA code \nbeing used by the upper sender is (1, 1, 1, -1, 1, -1, -1, -1), while the CDMA code \nbeing used by the lower sender is (1, -1, 1, 1, 1, -1, 1, 1) . Figure 7.6 illustrates a \nreceiver recovering the original data bits from the upper sender. Note that the receiver \nis able to extract the data from sender 1 in spite of the interfering transmission from  \nsender 2.\nRecall our cocktail analogy from Chapter 6 . A CDMA protocol is similar to \nhaving partygoers speaking in multiple languages; in such circumstances humans are \nactually quite good at locking into the conversation in the language they understand, \nwhile filtering out the remaining conversations. We see here that CDMA is a parti -\ntioning protocol in that it partitions the codespace (as opposed to time or frequency) \nand assigns each node a dedicated piece of the codespace.\nOur discussion here of CDMA is necessarily brief; in practice a number of dif -\nficult issues must be addressed. First, in order for the CDMA receivers to be able \n7.2  \u2022  WIRELESS LINKS AND NETWORK CHARACTERISTICS      559\nto extract a particular sender\u2019s signal, the CDMA codes must be carefully chosen. \n Second, our discussion has assumed that the received signal strengths from various \nsenders are the same; in reality this can be difficult to achieve. There is a consid -\nerable body of literature addressing these and other issues related to CDMA; see \n [Pickholtz 1982; Viterbi 1995] for details.Figure 7.6  \u2666 A two-sender CDMA exampleReceiver 1\n1 111\n-1 -1-1-11 111\n-1-1-1-1Time slot 1\nreceived inputTime slot 0\nreceived inputData bits\nData bits1 111\n-1 -1-1-11 111\n-1-1-1-1CodeSenders\n111\n-1111\n-11\n-1 -1111 11\nCode\nCode+\n-22 222 2\n-22\n-22 222 2\n-22Channel, Zi,m*\nZi,m di \u2022 cm =\nZi,m\u2022 cm\nd\nMim=1M\n5Sd1 = -1d0 = 1\nd1 = 12\n11 *2 22Zi,m di \u2022 cm =11 1\nd0 = 1211\nd1 = -1d0 = 1\n11\n560     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\n7.3 WiFi: 802.11 Wireless LANs\nPervasive in the workplace, the home, educational", "doc_id": "7bb267d0-a37d-4ae3-be28-fc19a64e863a", "embedding": null, "doc_hash": "122db0f07dd08a2693774c5d74ea52a0b057ac9d0fa1cbc928570357ce9f74cb", "extra_info": null, "node_info": {"start": 1642346, "end": 1645433}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "32dc3a15-4640-4999-a48f-233a54f5af8a", "3": "90f809ac-6aba-4d97-a234-4ac14a7b3050"}}, "__type__": "1"}, "90f809ac-6aba-4d97-a234-4ac14a7b3050": {"__data__": {"text": "bits\nData bits1 111\n-1 -1-1-11 111\n-1-1-1-1CodeSenders\n111\n-1111\n-11\n-1 -1111 11\nCode\nCode+\n-22 222 2\n-22\n-22 222 2\n-22Channel, Zi,m*\nZi,m di \u2022 cm =\nZi,m\u2022 cm\nd\nMim=1M\n5Sd1 = -1d0 = 1\nd1 = 12\n11 *2 22Zi,m di \u2022 cm =11 1\nd0 = 1211\nd1 = -1d0 = 1\n11\n560     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\n7.3 WiFi: 802.11 Wireless LANs\nPervasive in the workplace, the home, educational institutions, caf\u00e9s, airports, and \nstreet corners, wireless LANs are now one of the most important access network \ntechnologies in the Internet today. Although many technologies and standards for \nwireless LANs were developed in the 1990s, one particular class of standards has \nclearly emerged as the winner: the IEEE 802.11 wireless LAN , also known as WiFi . \nIn this section, we\u2019ll take a close look at 802.11 wireless LANs, examining its frame \nstructure, its medium access protocol, and its internetworking of 802.11 LANs with \nwired Ethernet LANs.\nThere are several 802.11 standards for wireless LAN technology in the IEEE \n802.11 (\u201cWiFi\u201d) family, as summarized in Table 7.1. The different 802.11 standards \nall share some common characteristics. They all use the same medium access proto -\ncol, CSMA/CA, which we\u2019ll discuss shortly. All three use the same frame structure \nfor their link-layer frames as well. All three standards have the ability to reduce \ntheir transmission rate in order to reach out over greater distances. And, importantly, \n802.11 products are also all backwards compatible, meaning, for example, that a \nmobile capable only of 802.11g may still interact with a newer 802.11ac base station.\nTable 7.1  \u2666 Summary of IEEE 802.11 standardsStandard Frequency Range Data Rate\n802.11b 2.4 GHz up to 11 Mbps\n802.11a 5 GHz up to 54 Mbps\n802.11g 2.4 GHz up to 54 Mbps\n802.11n 2.5 GHz and 5 GHz up to 450 Mbps\n802.11ac 5 GHz up to 1300 MbpsHowever, as shown in Table 7.1 , the standards have some major differences \nat the physical layer. 802.11 devices operate in two difference frequency ranges: \n2.4\u20132.485 GHz (referred to as the 2.4 GHz range) and 5.1 \u2013 5.8 GHz (referred to \nas the 5 GHz range). The 2.4 GHz range is an unlicensed frequency band, where \n802.11 devices may compete for frequency spectrum with 2.4 GHz phones and \nmicrowave ovens. At 5 GHz, 802.11 LANs have a shorter transmission distance \nfor a given power level and suffer more from multipath propagation. The two most \nrecent standards, 802.11n [IEEE 802.11n 2012] and 802.11ac [IEEE 802.11ac 2013; \nCisco 802.11ac 2015] uses multiple input multiple-output (MIMO) antennas; i.e., \ntwo or more antennas on the sending side and two or more antennas on the receiving \nside that are transmitting/receiving different signals [Diggavi 2004]. 802.11ac base \n7.3  \u2022  WIFI: 802.11 WIRELESS LANS      561\nstations may transmit to multiple stations simultaneously, and use \u201csmart\u201d antennas \nto adaptively beamform to target transmissions in the direction of a receiver. This \ndecreases interference and increases the distance reached at a given data rate. The data \nrates shown in Table 7.1 are for an idealized environment, e.g., a receiver placed 1  \nmeter away from the base station, with no interference\u2014a scenario that we\u2019re \nunlikely to experience in practice! So as the", "doc_id": "90f809ac-6aba-4d97-a234-4ac14a7b3050", "embedding": null, "doc_hash": "808a36ae3251ee12f3e3a03ef15b74568c32cb2d137e127b9d45a9515c5b76a0", "extra_info": null, "node_info": {"start": 1645691, "end": 1648932}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "7bb267d0-a37d-4ae3-be28-fc19a64e863a", "3": "cc70efc9-955d-4de3-9945-d5d58bd0f88a"}}, "__type__": "1"}, "cc70efc9-955d-4de3-9945-d5d58bd0f88a": {"__data__": {"text": "i.e., \ntwo or more antennas on the sending side and two or more antennas on the receiving \nside that are transmitting/receiving different signals [Diggavi 2004]. 802.11ac base \n7.3  \u2022  WIFI: 802.11 WIRELESS LANS      561\nstations may transmit to multiple stations simultaneously, and use \u201csmart\u201d antennas \nto adaptively beamform to target transmissions in the direction of a receiver. This \ndecreases interference and increases the distance reached at a given data rate. The data \nrates shown in Table 7.1 are for an idealized environment, e.g., a receiver placed 1  \nmeter away from the base station, with no interference\u2014a scenario that we\u2019re \nunlikely to experience in practice! So as the saying goes, YMMV: Your Mileage (or \nin this case your wireless data rate) May Vary.\n7.3.1 The 802.11 Architecture\nFigure 7. 7 illustrates the principal components of the 802.11 wireless LAN architec -\nture. The fundamental building block of the 802.11 architecture is the basic service \nset (BSS) . A BSS contains one or more wireless stations and a central base station , \nknown as an access point (AP)  in 802.11 parlance. Figure 7.7 shows the AP in each \nof two BSSs connecting to an interconnection device (such as a switch or router), \nwhich in turn leads to the Internet. In a typical home network, there is one AP and one \nrouter (typically integrated together as one unit) that connects the BSS to the Internet.\nAs with Ethernet devices, each 802.11 wireless station has a 6-byte MAC \naddress that is stored in the firmware of the station\u2019s adapter (that is, 802.11 net -\nwork interface card). Each AP also has a MAC address for its wireless interface. As \nwith Ethernet, these MAC addresses are administered by IEEE and are (in theory) \n globally unique.\nFigure 7.7  \u2666 IEEE 802.11 LAN architectureInternet\nSwitch or router\nAP\nBSS 1\nBSS 2AP\n562     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\nAs noted in Section 7.1, wireless LANs that deploy APs are often referred to \nas infrastructure wireless LANs , with the \u201cinfrastructure\u201d being the APs along \nwith the wired Ethernet infrastructure that interconnects the APs and a router. Figure \n7.8 shows that IEEE 802.11 stations can also group themselves together to form an \nad hoc network\u2014a network with no central control and with no connections to the \n \u201coutside world.\u201d Here, the network is formed \u201con the fly,\u201d by mobile devices that \nhave found themselves in proximity to each other, that have a need to communi -\ncate, and that find no preexisting network infrastructure in their location. An ad hoc \nnetwork might be formed when people with laptops get together (for example, in \na conference room, a train, or a car) and want to exchange data in the absence of a \ncentralized AP. There has been tremendous interest in ad hoc networking, as com -\nmunicating portable devices continue to proliferate. In this section, though, we\u2019ll \nfocus our attention on infrastructure wireless LANs.\nChannels and Association\nIn 802.11, each wireless station needs to associate with an AP before it can send or \nreceive network-layer data. Although all of the 802.11 standards use association, \nwe\u2019ll discuss this topic specifically in the context of IEEE 802.11b/g.\nWhen a network administrator installs an AP, the administrator assigns a one- \nor two-word Service Set Identifier (SSID)  to the access point. (When you choose \nWi-Fi under Setting on your iPhone, for example, a list is displayed showing the \nSSID of each AP in range.) The administrator must also assign a channel number \nto the AP. To understand channel numbers, recall that 802.11 operates in the fre", "doc_id": "cc70efc9-955d-4de3-9945-d5d58bd0f88a", "embedding": null, "doc_hash": "422e5c46b3ee903636cf806b52e0233cc4f46a13f32fa54b529f4a28cc93483b", "extra_info": null, "node_info": {"start": 1648677, "end": 1652290}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "90f809ac-6aba-4d97-a234-4ac14a7b3050", "3": "238d8bf8-39d7-4443-b01f-1c30b4b2b337"}}, "__type__": "1"}, "238d8bf8-39d7-4443-b01f-1c30b4b2b337": {"__data__": {"text": "though, we\u2019ll \nfocus our attention on infrastructure wireless LANs.\nChannels and Association\nIn 802.11, each wireless station needs to associate with an AP before it can send or \nreceive network-layer data. Although all of the 802.11 standards use association, \nwe\u2019ll discuss this topic specifically in the context of IEEE 802.11b/g.\nWhen a network administrator installs an AP, the administrator assigns a one- \nor two-word Service Set Identifier (SSID)  to the access point. (When you choose \nWi-Fi under Setting on your iPhone, for example, a list is displayed showing the \nSSID of each AP in range.) The administrator must also assign a channel number \nto the AP. To understand channel numbers, recall that 802.11 operates in the fre -\nquency range of 2.4 GHz to 2.4835 GHz. Within this 85 MHz band, 802.11 defines \n11 partially overlapping channels. Any two channels are non-overlapping if and \nonly if they are separated by four or more channels. In particular, the set of channels Figure 7.8  \u2666 An IEEE 802.11 ad hoc networkBSS\n7.3  \u2022  WIFI: 802.11 WIRELESS LANS      563\n1, 6, and 11 is the only set of three non-overlapping channels. This means that an \nadministrator could create a wireless LAN with an aggregate maximum transmis -\nsion rate of 33 Mbps by installing three 802.11b APs at the same physical location, \nassigning channels 1, 6, and 11 to the APs, and interconnecting each of the APs \nwith a switch.\nNow that we have a basic understanding of 802.11 channels, let\u2019s describe an \ninteresting (and not completely uncommon) situation\u2014that of a WiFi jungle. A WiFi \njungle  is any physical location where a wireless station receives a sufficiently strong \nsignal from two or more APs. For example, in many caf\u00e9s in New York City, a wire -\nless station can pick up a signal from numerous nearby APs. One of the APs might be \nmanaged by the caf\u00e9, while the other APs might be in residential apartments near the \ncaf\u00e9. Each of these APs would likely be located in a different IP subnet and would \nhave been independently assigned a channel.\nNow suppose you enter such a WiFi jungle with your phone, tablet, or  laptop, \nseeking wireless Internet access and a blueberry muffin. Suppose there are five \nAPs in the WiFi jungle. To gain Internet access, your wireless device needs to join \nexactly one of the subnets and hence needs to associate  with exactly one of the APs. \n Associating means the wireless device creates a virtual wire between itself and the \nAP. Specifically, only the associated AP will send data frames (that is, frames con -\ntaining data, such as a datagram) to your wireless device, and your wireless device \nwill send data frames into the Internet only through the associated AP. But how does \nyour wireless device associate with a particular AP? And more fundamentally, how \ndoes your wireless device know which APs, if any, are out there in the jungle?\nThe 802.11 standard requires that an AP periodically send beacon frames , each \nof which includes the AP\u2019s SSID and MAC address. Your wireless device, know -\ning that APs are sending out beacon frames, scans the 11 channels, seeking beacon \nframes from any APs that may be out there (some of which may be transmitting \non the same channel\u2014it\u2019s a jungle out there!). Having learned about available APs \nfrom the beacon frames, you (or your wireless device) select one of the APs for \nassociation.\nThe 802.11 standard does not specify an algorithm for selecting which of \nthe available APs to associate with; that algorithm is left up to the designers of \nthe 802.11 firmware and software in your wireless device. Typically, the device \nchooses the AP whose beacon frame is received with the highest signal strength. \nWhile a high signal strength is good (see, e.g., Figure 7.3), signal", "doc_id": "238d8bf8-39d7-4443-b01f-1c30b4b2b337", "embedding": null, "doc_hash": "f123cc2e485a45de50eeeb4863c104efec3c30a05625ad34eb89fe168a11f4ee", "extra_info": null, "node_info": {"start": 1652246, "end": 1656022}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "cc70efc9-955d-4de3-9945-d5d58bd0f88a", "3": "fca1b334-4168-4e1c-871e-05a03f6fde10"}}, "__type__": "1"}, "fca1b334-4168-4e1c-871e-05a03f6fde10": {"__data__": {"text": "address. Your wireless device, know -\ning that APs are sending out beacon frames, scans the 11 channels, seeking beacon \nframes from any APs that may be out there (some of which may be transmitting \non the same channel\u2014it\u2019s a jungle out there!). Having learned about available APs \nfrom the beacon frames, you (or your wireless device) select one of the APs for \nassociation.\nThe 802.11 standard does not specify an algorithm for selecting which of \nthe available APs to associate with; that algorithm is left up to the designers of \nthe 802.11 firmware and software in your wireless device. Typically, the device \nchooses the AP whose beacon frame is received with the highest signal strength. \nWhile a high signal strength is good (see, e.g., Figure 7.3), signal strength is not \nthe only AP characteristic that will determine the performance a device receives. \nIn particular, it\u2019s possible that the selected AP may have a strong signal, but may \nbe overloaded with other affiliated devices (that will need to share the wireless \nbandwidth at that AP), while an unloaded AP is not selected due to a slightly \nweaker signal. A number of alternative ways of choosing APs have thus recently \nbeen proposed [Vasudevan 2005; Nicholson 2006; Sundaresan 2006]. For an \ninteresting and down-to-earth discussion of how signal strength is measured, see \n[Bardwell 2004].\n564     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\nThe process of scanning channels and listening for beacon frames is known \nas passive scanning  (see Figure 7.9a). A wireless device can also perform active \nscanning , by broadcasting a probe frame that will be received by all APs within the \nwireless device\u2019s range, as shown in Figure 7.9b. APs respond to the probe request \nframe with a probe response frame. The wireless device can then choose the AP with \nwhich to associate from among the responding APs.\nAfter selecting the AP with which to associate, the wireless device sends an asso -\nciation request frame to the AP, and the AP responds with an association response \nframe. Note that this second request/response handshake is needed with active scan -\nning, since an AP responding to the initial probe request frame doesn\u2019t know which \nof the (possibly many) responding APs the device will choose to associate with, in \nmuch the same way that a DHCP client can choose from among multiple DHCP \nservers (see Figure 4.21 ). Once associated with an AP, the device will want to join \nthe subnet (in the IP addressing sense of Section 4.3.3 ) to which the AP belongs. \nThus, the device will typically send a DHCP discovery message (see Figure 4.21 ) \ninto the subnet via the AP in order to obtain an IP address on the subnet. Once the \naddress is obtained, the rest of the world then views that device simply as another \nhost with an IP address in that subnet.\nIn order to create an association with a particular AP, the wireless device may \nbe required to authenticate itself to the AP. 802.11 wireless LANs provide a number \nof alternatives for authentication and access. One approach, used by many compa -\nnies, is to permit access to a wireless network based on a device\u2019s MAC address. A \nsecond approach, used by many Internet caf\u00e9s, employs usernames and passwords. Figure 7.9  \u2666 Active and passive scanning for access points11\n32\nH1AP 2 AP 1BBS 1\na. Passive scanning\n 1. Beacon frames sent from APs\n 2. Association Request frame sent:\n  H1 to selected AP\n 3. Association Response frame sent:\n  Selected AP to H1a. Active scanning\n 1. Probe Request frame broadcast from H1\n 2. Probes Response frame sent from APs\n 3. Association Request frame sent:\n  H1 to selected AP\n 4. Association Response frame sent:\n  Selected AP to H1\n  BBS 2\n22\n43\nH1AP 2 AP 1BBS 1 BBS 2\n1\n7.3  \u2022 ", "doc_id": "fca1b334-4168-4e1c-871e-05a03f6fde10", "embedding": null, "doc_hash": "c05b769a8be5f674ab4a3a95418a13ac4f6cf9d5b433835499ce764928b7ab82", "extra_info": null, "node_info": {"start": 1656007, "end": 1659760}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "238d8bf8-39d7-4443-b01f-1c30b4b2b337", "3": "8023c1e7-359a-4944-a8d0-02ff3ac85e64"}}, "__type__": "1"}, "8023c1e7-359a-4944-a8d0-02ff3ac85e64": {"__data__": {"text": "device\u2019s MAC address. A \nsecond approach, used by many Internet caf\u00e9s, employs usernames and passwords. Figure 7.9  \u2666 Active and passive scanning for access points11\n32\nH1AP 2 AP 1BBS 1\na. Passive scanning\n 1. Beacon frames sent from APs\n 2. Association Request frame sent:\n  H1 to selected AP\n 3. Association Response frame sent:\n  Selected AP to H1a. Active scanning\n 1. Probe Request frame broadcast from H1\n 2. Probes Response frame sent from APs\n 3. Association Request frame sent:\n  H1 to selected AP\n 4. Association Response frame sent:\n  Selected AP to H1\n  BBS 2\n22\n43\nH1AP 2 AP 1BBS 1 BBS 2\n1\n7.3  \u2022  WIFI: 802.11 WIRELESS LANS      565\nIn both cases, the AP typically communicates with an authentication server, relay -\ning information between the wireless device and the authentication server using a \nprotocol such as RADIUS [RFC 2865] or DIAMETER [RFC 3588]. Separating the \nauthentication server from the AP allows one authentication server to serve many \nAPs, centralizing the (often sensitive) decisions of authentication and access within \nthe single server, and keeping AP costs and complexity low. We\u2019ll see in chapter  8 \nthat the new IEEE 802.11i protocol defining security aspects of the 802.11 protocol \nfamily takes precisely this approach.\n7.3.2 The 802.11 MAC Protocol\nOnce a wireless device is associated with an AP, it can start sending and receiving \ndata frames to and from the access point. But because multiple wireless devices, \nor the AP itself may want to transmit data frames at the same time over the same \nchannel, a multiple access protocol is needed to coordinate the transmissions. In \nthe following, we'll refer to the devices or the AP as wireless \u201cstations\u201d that share \nthe multiple access channel. As discussed in Chapter 6 and Section 7.2.1, broadly \nspeaking there are three classes of multiple access protocols: channel partitioning \n(including CDMA), random access, and taking turns. Inspired by the huge suc -\ncess of Ethernet and its random access protocol, the designers of 802.11 chose a \nrandom access protocol for 802.11 wireless LANs. This random access protocol \nis referred to as CSMA with collision avoidance , or more succinctly as CSMA/\nCA. As with Ethernet\u2019s CSMA/CD, the \u201cCSMA\u201d in CSMA/CA stands for \u201ccarrier \nsense multiple access,\u201d meaning that each station senses the channel before trans -\nmitting, and refrains from transmitting when the channel is sensed busy. Although \nboth  Ethernet and 802.11 use carrier-sensing random access, the two MAC protocols \nhave important differences. First, instead of using collision detection, 802.11 uses \ncollision-avoidance techniques. Second, because of the relatively high bit error rates \nof wireless channels, 802.11 (unlike Ethernet) uses a link-layer acknowledgment/\nretransmission (ARQ) scheme. We\u2019ll describe 802.11\u2019s collision-avoidance and \nlink-layer acknowledgment schemes below.\nRecall from Sections 6.3.2 and 6.4.2 that with Ethernet\u2019s collision-detection \nalgorithm, an Ethernet station listens to the channel as it transmits. If, while transmit -\nting, it detects that another station is also transmitting, it aborts its transmission and \ntries to transmit again after waiting a small, random amount of time. Unlike the 802.3 \nEthernet protocol, the 802.11 MAC protocol does not implement collision detection. \nThere are two important reasons for this:\n\u2022 The ability to detect collisions requires the ability to send (the station\u2019s own \n signal) and receive (to determine whether another station is also transmitting) at \nthe same time. Because the strength of the received signal is typically very small \ncompared to the strength of the", "doc_id": "8023c1e7-359a-4944-a8d0-02ff3ac85e64", "embedding": null, "doc_hash": "cdde551094afc41334291528dcd6483c9ded206a900f69c93693366ee5ee4a74", "extra_info": null, "node_info": {"start": 1659895, "end": 1663555}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "fca1b334-4168-4e1c-871e-05a03f6fde10", "3": "68206f21-e5d8-49f4-9c85-ebf80e9ee9f0"}}, "__type__": "1"}, "68206f21-e5d8-49f4-9c85-ebf80e9ee9f0": {"__data__": {"text": "from Sections 6.3.2 and 6.4.2 that with Ethernet\u2019s collision-detection \nalgorithm, an Ethernet station listens to the channel as it transmits. If, while transmit -\nting, it detects that another station is also transmitting, it aborts its transmission and \ntries to transmit again after waiting a small, random amount of time. Unlike the 802.3 \nEthernet protocol, the 802.11 MAC protocol does not implement collision detection. \nThere are two important reasons for this:\n\u2022 The ability to detect collisions requires the ability to send (the station\u2019s own \n signal) and receive (to determine whether another station is also transmitting) at \nthe same time. Because the strength of the received signal is typically very small \ncompared to the strength of the transmitted signal at the 802.11 adapter, it is \ncostly to build hardware that can detect a collision.\n566     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\n\u2022 More importantly, even if the adapter could transmit and listen at the same time \n(and presumably abort transmission when it senses a busy channel), the adapter \nwould still not be able to detect all collisions, due to the hidden terminal problem \nand fading, as discussed in Section 7.2.\nBecause 802.11wireless LANs do not use collision detection, once a station \nbegins to transmit a frame, it transmits the frame in its entirety ; that is, once a station \ngets started, there is no turning back. As one might expect, transmitting entire frames \n(particularly long frames) when collisions are prevalent can significantly degrade a \nmultiple access protocol\u2019s performance. In order to reduce the likelihood of collisions, \n802.11 employs several collision-avoidance techniques, which we\u2019ll shortly discuss.\nBefore considering collision avoidance, however, we\u2019ll first need to examine \n802.11\u2019s link-layer acknowledgment  scheme. Recall from Section 7.2 that when a \nstation in a wireless LAN sends a frame, the frame may not reach the destination sta -\ntion intact for a variety of reasons. To deal with this non-negligible chance of failure, \nthe 802.11 MAC protocol uses link-layer acknowledgments. As shown in Figure 7.10 , \nwhen  the destination station receives a frame that passes the CRC, it waits a short \nperiod of time known as the Short Inter-frame Spacing (SIFS)  and then sends back \nFigure 7.10  \u2666 802.11 uses link-layer acknowledgmentsDestination\nDIFS\nSIFSdata\nackSource\n7.3  \u2022  WIFI: 802.11 WIRELESS LANS      567\nan acknowledgment frame. If the transmitting station does not receive an acknowl -\nedgment within a given amount of time, it assumes that an error has occurred and \nretransmits the frame, using the CSMA/CA protocol to access the channel. If an \nacknowledgment is not received after some fixed number of retransmissions, the trans -\nmitting station gives up and discards the frame.\nHaving discussed how 802.11 uses link-layer acknowledgments, we\u2019re now in a \nposition to describe the 802.11 CSMA/CA protocol. Suppose that a station (wireless \ndevice or an AP) has a frame to transmit.\n 1. If initially the station senses the channel idle, it transmits its frame after a  \nshort period of time known as the Distributed Inter-frame Space (DIFS) ;  \nsee  Figure 7.10.\n 2. Otherwise, the station chooses a random backoff value using binary exponen-\ntial backoff (as we encountered in Section 6.3.2) and counts down this value \nafter DIFS when the channel is sensed idle. While the channel is sensed busy, \nthe counter value remains frozen.\n 3. When the counter reaches zero (note that this can only occur while the chan-\nnel is sensed idle), the station transmits the entire frame and then waits for an", "doc_id": "68206f21-e5d8-49f4-9c85-ebf80e9ee9f0", "embedding": null, "doc_hash": "436dc0501f2ef75f0300215ed953248da57a17b62e86b4d63f4af2187c67e6a6", "extra_info": null, "node_info": {"start": 1663422, "end": 1667064}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "8023c1e7-359a-4944-a8d0-02ff3ac85e64", "3": "ad0e90be-2bc2-4677-832f-2832332d803d"}}, "__type__": "1"}, "ad0e90be-2bc2-4677-832f-2832332d803d": {"__data__": {"text": "CSMA/CA protocol. Suppose that a station (wireless \ndevice or an AP) has a frame to transmit.\n 1. If initially the station senses the channel idle, it transmits its frame after a  \nshort period of time known as the Distributed Inter-frame Space (DIFS) ;  \nsee  Figure 7.10.\n 2. Otherwise, the station chooses a random backoff value using binary exponen-\ntial backoff (as we encountered in Section 6.3.2) and counts down this value \nafter DIFS when the channel is sensed idle. While the channel is sensed busy, \nthe counter value remains frozen.\n 3. When the counter reaches zero (note that this can only occur while the chan-\nnel is sensed idle), the station transmits the entire frame and then waits for an \nacknowledgment.\n 4. If an acknowledgment is received, the transmitting station knows that its frame \nhas been correctly received at the destination station. If the station has another \nframe to send, it begins the CSMA/CA protocol at step 2. If the acknowledg -\nment isn\u2019t received, the transmitting station reenters the backoff phase in step 2,  \nwith the random value chosen from a larger interval.\nRecall that under Ethernet\u2019s CSMA/CD, multiple access protocol (Section 6.3.2 ), \na station begins transmitting as soon as the channel is sensed idle. With CSMA/CA, \nhowever, the station refrains from transmitting while counting down, even when it \nsenses the channel to be idle. Why do CSMA/CD and CDMA/CA take such different \napproaches here?\nTo answer this question, let\u2019s consider a scenario in which two stations each \nhave a data frame to transmit, but neither station transmits immediately because each \nsenses that a third station is already transmitting. With Ethernet\u2019s CSMA/CD, the \ntwo stations would each transmit as soon as they detect that the third station has \nfinished transmitting. This would cause a collision, which isn\u2019t a serious issue in \nCSMA/CD, since both stations would abort their transmissions and thus avoid the \nuseless transmissions of the remainders of their frames. In 802.11, however, the situ -\nation is quite different. Because 802.11 does not detect a collision and abort trans -\nmission, a frame suffering a collision will be transmitted in its entirety. The goal \nin 802.11 is thus to avoid collisions whenever possible. In 802.11, if the two sta -\ntions sense the channel busy, they both immediately enter random backoff, hopefully \nchoosing different backoff values. If these values are indeed different, once the chan -\nnel becomes idle, one of the two stations will begin transmitting before the other, and \n(if the two stations are not hidden from each other) the \u201closing station\u201d will hear the  \n568     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\n\u201cwinning station\u2019s\u201d signal, freeze its counter, and refrain from transmitting until the \nwinning station has completed its transmission. In this manner, a costly collision is \navoided. Of course, collisions can still occur with 802.11 in this scenario: The two \nstations could be hidden from each other, or the two stations could choose random \nbackoff values that are close enough that the transmission from the station starting \nfirst have yet to reach the second station. Recall that we encountered this problem \nearlier in our discussion of random access algorithms in the context of Figure 6.12.\nDealing with Hidden Terminals: RTS and CTS\nThe 802.11 MAC protocol also includes a nifty (but optional) reservation scheme \nthat helps avoid collisions even in the presence of hidden terminals. Let\u2019s investi -\ngate this scheme in the context of Figure 7.11, which shows two wireless  stations \nand one access point. Both of the wireless stations are within range of the AP \n(whose  coverage is shown as a shaded circle) and both have associated with the AP. \n However, due to fading, the", "doc_id": "ad0e90be-2bc2-4677-832f-2832332d803d", "embedding": null, "doc_hash": "f6270c7193728378b7c6e42d80d1e755ead90f26fc7970d8da8a614b3aca7b01", "extra_info": null, "node_info": {"start": 1667117, "end": 1670912}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "68206f21-e5d8-49f4-9c85-ebf80e9ee9f0", "3": "858cf3f8-74ce-4cc4-b668-1e29088919c5"}}, "__type__": "1"}, "858cf3f8-74ce-4cc4-b668-1e29088919c5": {"__data__": {"text": "hidden from each other, or the two stations could choose random \nbackoff values that are close enough that the transmission from the station starting \nfirst have yet to reach the second station. Recall that we encountered this problem \nearlier in our discussion of random access algorithms in the context of Figure 6.12.\nDealing with Hidden Terminals: RTS and CTS\nThe 802.11 MAC protocol also includes a nifty (but optional) reservation scheme \nthat helps avoid collisions even in the presence of hidden terminals. Let\u2019s investi -\ngate this scheme in the context of Figure 7.11, which shows two wireless  stations \nand one access point. Both of the wireless stations are within range of the AP \n(whose  coverage is shown as a shaded circle) and both have associated with the AP. \n However, due to fading, the signal ranges of wireless stations are limited to the inte -\nriors of the shaded circles shown in Figure 7.11. Thus, each of the wireless stations \nis hidden from the other, although neither is hidden from the AP.\nLet\u2019s now consider why hidden terminals can be problematic. Suppose Station H1 is \ntransmitting a frame and halfway through H1\u2019s transmission, Station H2 wants to send a \nframe to the AP. H2, not hearing the transmission from H1, will first wait a DIFS interval \nand then transmit the frame, resulting in a collision. The channel will therefore be wasted \nduring the entire period of H1\u2019s transmission as well as during H2\u2019s transmission.\nIn order to avoid this problem, the IEEE 802.11 protocol allows a station to \nuse a short Request to Send (RTS)  control frame and a short Clear to Send (CTS)  \ncontrol frame to reserve  access to the channel. When a sender wants to send a DATA \nFigure 7.11  \u2666  Hidden terminal example: H1 is hidden from H2, and vice \nversaAPH1 H2\n7.3  \u2022  WIFI: 802.11 WIRELESS LANS      569\nframe, it can first send an RTS frame to the AP, indicating the total time required \nto transmit the DATA frame and the acknowledgment (ACK) frame. When the AP \nreceives the RTS frame, it responds by broadcasting a CTS frame. This CTS frame \nserves two purposes: It gives the sender explicit permission to send and also instructs \nthe other stations not to send for the reserved duration.\nThus, in Figure 7.12, before transmitting a DATA frame, H1 first broadcasts an RTS \nframe, which is heard by all stations in its circle, including the AP. The AP then responds \nFigure 7.12  \u2666 Collision avoidance using the RTS and CTS framesDestination All other nodes\nDefer accessSource\nDIFS\nACKSIFSSIFS\nSIFSDATACTSCTS\nACKRTS\n570     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\nwith a CTS frame, which is heard by all stations within its range, including H1 and H2. \nStation H2, having heard the CTS, refrains from transmitting for the time specified in the \nCTS frame. The RTS, CTS, DATA, and ACK frames are shown in Figure 7.12.\nThe use of the RTS and CTS frames can improve performance in two important \nways:\n\u2022 The hidden station problem is mitigated, since a long DATA frame is transmitted \nonly after the channel has been reserved.\n\u2022 Because the RTS and CTS frames are short, a collision involving an RTS or CTS \nframe will last only for the duration of the short RTS or CTS frame. Once the RTS \nand CTS frames are correctly transmitted, the following DATA and ACK frames \nshould be transmitted without collisions.\nYou are encouraged to check out the 802.11 applet in the textbook\u2019s Web site. \nThis interactive applet illustrates the CSMA/CA protocol, including the RTS/CTS \nexchange sequence.\nAlthough the RTS/CTS exchange can help reduce collisions, it also introduces \ndelay and consumes channel resources. For this reason, the RTS/CTS", "doc_id": "858cf3f8-74ce-4cc4-b668-1e29088919c5", "embedding": null, "doc_hash": "680ebe60477ed43b708b30d4b9a4b15404f9c87c9a28cfe3e7317e3c2379f340", "extra_info": null, "node_info": {"start": 1670825, "end": 1674498}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "ad0e90be-2bc2-4677-832f-2832332d803d", "3": "8697faa3-0f3f-4a71-a422-163528276b8a"}}, "__type__": "1"}, "8697faa3-0f3f-4a71-a422-163528276b8a": {"__data__": {"text": "two important \nways:\n\u2022 The hidden station problem is mitigated, since a long DATA frame is transmitted \nonly after the channel has been reserved.\n\u2022 Because the RTS and CTS frames are short, a collision involving an RTS or CTS \nframe will last only for the duration of the short RTS or CTS frame. Once the RTS \nand CTS frames are correctly transmitted, the following DATA and ACK frames \nshould be transmitted without collisions.\nYou are encouraged to check out the 802.11 applet in the textbook\u2019s Web site. \nThis interactive applet illustrates the CSMA/CA protocol, including the RTS/CTS \nexchange sequence.\nAlthough the RTS/CTS exchange can help reduce collisions, it also introduces \ndelay and consumes channel resources. For this reason, the RTS/CTS exchange is \nonly used (if at all) to reserve the channel for the transmission of a long DATA \nframe. In practice, each wireless station can set an RTS threshold such that the RTS/\nCTS sequence is used only when the frame is longer than the threshold. For many \nwireless stations, the default RTS threshold value is larger than the maximum frame \nlength, so the RTS/CTS sequence is skipped for all DATA frames sent.\nUsing 802.11 as a Point-to-Point Link\nOur discussion so far has focused on the use of 802.11 in a multiple access setting. \nWe should mention that if two nodes each have a directional antenna, they can point \ntheir directional antennas at each other and run the 802.11 protocol over what is essen -\ntially a point-to-point link. Given the low cost of commodity 802.11 hardware, the use \nof directional antennas and an increased transmission power allow 802.11 to be used \nas an inexpensive means of providing wireless point-to-point connections over tens of \nkilometers distance. [Raman 2007] describes one of the first such multi-hop wireless \nnetworks, operating in the rural Ganges plains in India using point-to-point 802.11 links.\n7.3.3 The IEEE 802.11 Frame\nAlthough the 802.11 frame shares many similarities with an Ethernet frame, it also con -\ntains a number of fields that are specific to its use for wireless links. The 802.11 frame \nis shown in Figure 7.13. The numbers above each of the fields in the frame represent \nthe lengths of the fields in bytes ; the numbers above each of the subfields in the frame \ncontrol field represent the lengths of the subfields in bits. Let\u2019s now examine the fields \nin the frame as well as some of the more important subfields in the frame\u2019s control field.\n7.3  \u2022  WIFI: 802.11 WIRELESS LANS      571\nPayload and CRC Fields\nAt the heart of the frame is the payload, which typically consists of an IP datagram \nor an ARP packet. Although the field is permitted to be as long as 2,312 bytes, it is \ntypically fewer than 1,500 bytes, holding an IP datagram or an ARP packet. As with \nan Ethernet frame, an 802.11 frame includes a 32-bit cyclic redundancy check (CRC) \nso that the receiver can detect bit errors in the received frame. As we\u2019ve seen, bit \nerrors are much more common in wireless LANs than in wired LANs, so the CRC is \neven more useful here.\nAddress Fields\nPerhaps the most striking difference in the 802.11 frame is that it has four address \nfields, each of which can hold a 6-byte MAC address. But why four address \nfields? Doesn\u2019t a source MAC field and destination MAC field suffice, as they do \nfor  Ethernet? It turns out that three address fields are needed for internetworking \n purposes\u2014specifically, for moving the network-layer datagram from a wireless sta -\ntion through an AP to a router interface. The fourth address field is used when APs \n forward frames to each other in ad hoc mode. Since we are only considering infra -\nstructure networks here, let\u2019s focus our attention on the first three address fields. The \n802.11 standard defines these fields as follows:\n\u2022 Address 2 is", "doc_id": "8697faa3-0f3f-4a71-a422-163528276b8a", "embedding": null, "doc_hash": "c59dc597ac64b1f3ce64db5ded795e9b7256c97cdbcabc3440a5da15dbc9542a", "extra_info": null, "node_info": {"start": 1674538, "end": 1678360}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "858cf3f8-74ce-4cc4-b668-1e29088919c5", "3": "3d240334-4a68-444d-b9b0-8b242ca320c5"}}, "__type__": "1"}, "3d240334-4a68-444d-b9b0-8b242ca320c5": {"__data__": {"text": "the CRC is \neven more useful here.\nAddress Fields\nPerhaps the most striking difference in the 802.11 frame is that it has four address \nfields, each of which can hold a 6-byte MAC address. But why four address \nfields? Doesn\u2019t a source MAC field and destination MAC field suffice, as they do \nfor  Ethernet? It turns out that three address fields are needed for internetworking \n purposes\u2014specifically, for moving the network-layer datagram from a wireless sta -\ntion through an AP to a router interface. The fourth address field is used when APs \n forward frames to each other in ad hoc mode. Since we are only considering infra -\nstructure networks here, let\u2019s focus our attention on the first three address fields. The \n802.11 standard defines these fields as follows:\n\u2022 Address 2 is the MAC address of the station that transmits the frame. Thus, if a \nwireless station transmits the frame, that station\u2019s MAC address is inserted in the \naddress 2 field. Similarly, if an AP transmits the frame, the AP\u2019s MAC address is \ninserted in the address 2 field.\n\u2022 Address 1 is the MAC address of the wireless station that is to receive the frame. \nThus if a mobile wireless station transmits the frame, address 1 contains the MAC \naddress of the destination AP. Similarly, if an AP transmits the frame, address 1 \ncontains the MAC address of the destination wireless station.Figure 7.13  \u2666 The 802.11 frameFrame\ncontrol2\n22 4 1111 111126 66 26 0-2312 4Frame (numbers indicate \ufb01eld length in bytes):\nAddress\n1Duration Payload CRC\nProtocol\nversionTo\nAPFrom\nAPMore\nfragPower\nmgtMore\ndataAddress\n2Address\n3Address\n4Seq\ncontrol\nType Subtype Retry WEP RsvdFrame control \ufb01eld expanded (numbers indicate \ufb01eld length in bits):\n572     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\n\u2022 To understand address 3, recall that the BSS (consisting of the AP and wire -\nless stations) is part of a subnet, and that this subnet connects to other subnets \nvia some router interface. Address 3 contains the MAC address of this router \n interface.\nTo gain further insight into the purpose of address 3, let\u2019s walk through an inter -\nnetworking example in the context of Figure 7.14. In this figure, there are two APs, \neach of which is responsible for a number of wireless stations. Each of the APs has a \ndirect connection to a router, which in turn connects to the global Internet. We should \nkeep in mind that an AP is a link-layer device, and thus neither \u201cspeaks\u201d IP nor \nunderstands IP addresses. Consider now moving a datagram from the router interface \nR1 to the wireless Station H1. The router is not aware that there is an AP between it \nand H1; from the router\u2019s perspective, H1 is just a host in one of the subnets to which \nit (the router) is connected.\n\u2022 The router, which knows the IP address of H1 (from the destination address of \nthe datagram), uses ARP to determine the MAC address of H1, just as in an \nordinary Ethernet LAN. After obtaining H1\u2019s MAC address, router interface R1 \nencapsulates the datagram within an Ethernet frame. The source address field of \nthis frame contains R1\u2019s MAC address, and the destination address field contains \nH1\u2019s MAC address.Figure 7.14  \u2666  The use of address fields in 802.11 frames: Sending frames \nbetween H1 and R1Internet\nRouter\nAPH1R1\nBSS 1\nBSS 2AP\n7.3  \u2022  WIFI: 802.11 WIRELESS LANS      573\n\u2022 When the Ethernet frame arrives at the AP, the AP converts the 802.3 Ethernet \nframe to an 802.11 frame before transmitting the frame into the wireless chan -\nnel. The AP fills in address 1 and address 2 with H1\u2019s MAC address and its own \nMAC address, respectively, as described above. For address", "doc_id": "3d240334-4a68-444d-b9b0-8b242ca320c5", "embedding": null, "doc_hash": "0c023e3cf8bcebeba22d122e20bc346938da5b0aa7fab3e26cb4a6f41c493e82", "extra_info": null, "node_info": {"start": 1678341, "end": 1681968}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "8697faa3-0f3f-4a71-a422-163528276b8a", "3": "a941df31-d957-4408-99b5-6ad596f237c4"}}, "__type__": "1"}, "a941df31-d957-4408-99b5-6ad596f237c4": {"__data__": {"text": "the datagram within an Ethernet frame. The source address field of \nthis frame contains R1\u2019s MAC address, and the destination address field contains \nH1\u2019s MAC address.Figure 7.14  \u2666  The use of address fields in 802.11 frames: Sending frames \nbetween H1 and R1Internet\nRouter\nAPH1R1\nBSS 1\nBSS 2AP\n7.3  \u2022  WIFI: 802.11 WIRELESS LANS      573\n\u2022 When the Ethernet frame arrives at the AP, the AP converts the 802.3 Ethernet \nframe to an 802.11 frame before transmitting the frame into the wireless chan -\nnel. The AP fills in address 1 and address 2 with H1\u2019s MAC address and its own \nMAC address, respectively, as described above. For address 3, the AP inserts the \nMAC address of R1. In this manner, H1 can determine (from address 3) the MAC \naddress of the router interface that sent the datagram into the subnet.\nNow consider what happens when the wireless station H1 responds by moving a \ndatagram from H1 to R1.\n\u2022 H1 creates an 802.11 frame, filling the fields for address 1 and address 2 with the \nAP\u2019s MAC address and H1\u2019s MAC address, respectively, as described above. For \naddress 3, H1 inserts R1\u2019s MAC address.\n\u2022 When the AP receives the 802.11 frame, it converts the frame to an Ethernet frame. \nThe source address field for this frame is H1\u2019s MAC address, and the destination \naddress field is R1\u2019s MAC address. Thus, address 3 allows the AP to determine \nthe appropriate destination MAC address when constructing the Ethernet frame.\nIn summary, address 3 plays a crucial role for internetworking the BSS with a wired \nLAN.\nSequence Number, Duration, and Frame Control Fields\nRecall that in 802.11, whenever a station correctly receives a frame from another sta -\ntion, it sends back an acknowledgment. Because acknowledgments can get lost, the \nsending station may send multiple copies of a given frame. As we saw in our discus -\nsion of the rdt2.1 protocol (Section 3.4.1 ), the use of sequence numbers allows the \nreceiver to distinguish between a newly transmitted frame and the retransmission of \na previous frame. The sequence number field in the 802.11 frame thus serves exactly \nthe same purpose here at the link layer as it did in the transport layer in Chapter 3.\nRecall that the 802.11 protocol allows a transmitting station to reserve the chan -\nnel for a period of time that includes the time to transmit its data frame and the time \nto transmit an acknowledgment. This duration value is included in the frame\u2019s dura -\ntion field (both for data frames and for the RTS and CTS frames).\nAs shown in Figure 7.13, the frame control field includes many subfields. We\u2019ll \nsay just a few words about some of the more important subfields; for a more complete \ndiscussion, you are encouraged to consult the 802.11 specification [Held 2001; Crow \n1997; IEEE 802.11 1999]. The type and subtype  fields are used to distinguish the asso -\nciation, RTS, CTS, ACK, and data frames. The to and from fields are used to define \nthe meanings of the different address fields. (These meanings change depending on \nwhether ad hoc or infrastructure modes are used and, in the case of infrastructure \nmode, whether a wireless station or an AP is sending the frame.) Finally the WEP field \nindicates whether encryption is being used or not (WEP is discussed in Chapter 8 ).\n574     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\n7.3.4 Mobility in the Same IP Subnet\nIn order to increase the physical range of a wireless LAN, companies and universities \nwill often deploy multiple BSSs within the same IP subnet. This naturally raises the \nissue of mobility among the BSSs\u2014how do wireless stations seamlessly move from one \nBSS to another while maintaining ongoing TCP sessions? As", "doc_id": "a941df31-d957-4408-99b5-6ad596f237c4", "embedding": null, "doc_hash": "bd3c73abac6b3e5a7739c944eba701030cc37cff3da342637e0aba4ef22cbcca", "extra_info": null, "node_info": {"start": 1682095, "end": 1685773}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "3d240334-4a68-444d-b9b0-8b242ca320c5", "3": "ca34bd3f-ab4f-4bf0-bf4e-1e2fea0a781f"}}, "__type__": "1"}, "ca34bd3f-ab4f-4bf0-bf4e-1e2fea0a781f": {"__data__": {"text": "of the different address fields. (These meanings change depending on \nwhether ad hoc or infrastructure modes are used and, in the case of infrastructure \nmode, whether a wireless station or an AP is sending the frame.) Finally the WEP field \nindicates whether encryption is being used or not (WEP is discussed in Chapter 8 ).\n574     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\n7.3.4 Mobility in the Same IP Subnet\nIn order to increase the physical range of a wireless LAN, companies and universities \nwill often deploy multiple BSSs within the same IP subnet. This naturally raises the \nissue of mobility among the BSSs\u2014how do wireless stations seamlessly move from one \nBSS to another while maintaining ongoing TCP sessions? As we\u2019ll see in this subsec -\ntion, mobility can be handled in a relatively straightforward manner when the BSSs are \npart of the subnet. When stations move between subnets, more sophisticated mobility \nmanagement protocols will be needed, such as those we\u2019ll study in Sections 7.5 and 7.6.\nLet\u2019s now look at a specific example of mobility between BSSs in the same sub -\nnet. Figure 7.15 shows two interconnected BSSs with a host, H1, moving from BSS1 \nto BSS2. Because in this example the interconnection device that connects the two \nBSSs is not a router, all of the stations in the two BSSs, including the APs, belong \nto the same IP subnet. Thus, when H1 moves from BSS1 to BSS2, it may keep its IP \naddress and all of its ongoing TCP connections. If the interconnection device were a \nrouter, then H1 would have to obtain a new IP address in the subnet in which it was \nmoving. This address change would disrupt (and eventually terminate) any on-going \nTCP connections at H1. In Section 7.6, we\u2019ll see how a network-layer mobility pro -\ntocol, such as mobile IP, can be used to avoid this problem.\nBut what specifically happens when H1 moves from BSS1 to BSS2? As H1 \nwanders away from AP1, H1 detects a weakening signal from AP1 and starts to scan \nfor a stronger signal. H1 receives beacon frames from AP2 (which in many corporate \nand university settings will have the same SSID as AP1). H1 then disassociates with \nAP1 and associates with AP2, while keeping its IP address and maintaining its ongo -\ning TCP sessions.\nThis addresses the handoff problem from the host and AP viewpoint. But what \nabout the switch in Figure 7.15? How does it know that the host has moved from one \nAP to another? As you may recall from Chapter 6, switches are \u201cself-learning\u201d and \nautomatically build their forwarding tables. This self-learning feature nicely handles \nFigure 7.15  \u2666 Mobility in the same subnetBSS 1 BSS 2\nH1Switch\nAP 1 AP 2\n7.3  \u2022  WIFI: 802.11 WIRELESS LANS      575\noccasional moves (for example, when an employee gets transferred from one depart -\nment to another); however, switches were not designed to support highly mobile \nusers who want to maintain TCP connections while moving between BSSs. To \nappreciate the problem here, recall that before the move, the switch has an entry in \nits forwarding table that pairs H1\u2019s MAC address with the outgoing switch interface \nthrough which H1 can be reached. If H1 is initially in BSS1, then a datagram des -\ntined to H1 will be directed to H1 via AP1. Once H1 associates with BSS2, however, \nits frames should be directed to AP2. One solution (a bit of a hack, really) is for AP2 \nto send a broadcast Ethernet frame with H1\u2019s source address to the switch just after \nthe new association. When the switch receives the frame, it updates its forwarding \ntable, allowing H1 to be", "doc_id": "ca34bd3f-ab4f-4bf0-bf4e-1e2fea0a781f", "embedding": null, "doc_hash": "f8c4c893fb9602dd495dae8459fe2676487e9a4c7c96a3f7bc2be140f2da2d41", "extra_info": null, "node_info": {"start": 1685694, "end": 1689257}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "a941df31-d957-4408-99b5-6ad596f237c4", "3": "10551ba4-3c49-4ce8-9da9-0ee352cbd253"}}, "__type__": "1"}, "10551ba4-3c49-4ce8-9da9-0ee352cbd253": {"__data__": {"text": "support highly mobile \nusers who want to maintain TCP connections while moving between BSSs. To \nappreciate the problem here, recall that before the move, the switch has an entry in \nits forwarding table that pairs H1\u2019s MAC address with the outgoing switch interface \nthrough which H1 can be reached. If H1 is initially in BSS1, then a datagram des -\ntined to H1 will be directed to H1 via AP1. Once H1 associates with BSS2, however, \nits frames should be directed to AP2. One solution (a bit of a hack, really) is for AP2 \nto send a broadcast Ethernet frame with H1\u2019s source address to the switch just after \nthe new association. When the switch receives the frame, it updates its forwarding \ntable, allowing H1 to be reached via AP2. The 802.11f standards group is developing \nan inter-AP protocol to handle these and related issues.\nOur discussion above has focused on mobility with the same LAN subnet. Recall \nthat VLANs, which we studied in Section 6.4.4 , can be used to connect together \nislands of LANs into a large virtual LAN that can span a large geographical region. \nMobility among base stations within such a VLAN can be handled in exactly the \nsame manner as above [Yu 2011].\n7.3.5 Advanced Features in 802.11\nWe\u2019ll wrap up our coverage of 802.11 with a short discussion of two advanced capabili -\nties found in 802.11 networks. As we\u2019ll see, these capabilities are not completely speci -\nfied in the 802.11 standard, but rather are made possible by mechanisms specified in \nthe standard. This allows different vendors to implement these capabilities using their \nown (proprietary) approaches, presumably giving them an edge over the competition.\n802.11 Rate Adaptation\nWe saw earlier in Figure 7.3 that different modulation techniques (with the different \ntransmission rates that they provide) are appropriate for different SNR scenarios. \nConsider for example a mobile 802.11 user who is initially 20 meters away from \nthe base station, with a high signal-to-noise ratio. Given the high SNR, the user can \ncommunicate with the base station using a physical-layer modulation technique that \nprovides high transmission rates while maintaining a low BER. This is one happy \nuser! Suppose now that the user becomes mobile, walking away from the base sta -\ntion, with the SNR falling as the distance from the base station increases. In this case, \nif the modulation technique used in the 802.11 protocol operating between the base \nstation and the user does not change, the BER will become unacceptably high as the \nSNR decreases, and eventually no transmitted frames will be received correctly.\nFor this reason, some 802.11 implementations have a rate adaptation capability \nthat adaptively selects the underlying physical-layer modulation technique to use \nbased on current or recent channel characteristics. If a node sends two frames in a \nrow without receiving an acknowledgment (an implicit indication of bit errors on \n576     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\nthe channel), the transmission rate falls back to the next lower rate. If 10 frames \nin a row are acknowledged, or if a timer that tracks the time since the last fallback \nexpires, the transmission rate increases to the next higher rate. This rate adapta -\ntion mechanism shares the same \u201cprobing\u201d philosophy as TCP\u2019s congestion-control \nmechanism\u2014when conditions are good (reflected by ACK receipts), the transmis -\nsion rate is increased until something \u201cbad\u201d happens (the lack of ACK receipts); \nwhen something \u201cbad\u201d happens, the transmission rate is reduced. 802.11 rate adapta -\ntion and TCP congestion control are thus similar to the young child who is constantly \npushing his/her parents for more and more (say candy for a young child, later curfew \nhours for the teenager) until the parents finally say \u201cEnough!\u201d and the child backs \noff (only", "doc_id": "10551ba4-3c49-4ce8-9da9-0ee352cbd253", "embedding": null, "doc_hash": "64728817059339b37a634852cb656d3f4c8636fdaac2d98857fec8e883301fb7", "extra_info": null, "node_info": {"start": 1689275, "end": 1693119}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "ca34bd3f-ab4f-4bf0-bf4e-1e2fea0a781f", "3": "66bf39ee-69a0-4349-afb7-63ee4caa4d8a"}}, "__type__": "1"}, "66bf39ee-69a0-4349-afb7-63ee4caa4d8a": {"__data__": {"text": "\nexpires, the transmission rate increases to the next higher rate. This rate adapta -\ntion mechanism shares the same \u201cprobing\u201d philosophy as TCP\u2019s congestion-control \nmechanism\u2014when conditions are good (reflected by ACK receipts), the transmis -\nsion rate is increased until something \u201cbad\u201d happens (the lack of ACK receipts); \nwhen something \u201cbad\u201d happens, the transmission rate is reduced. 802.11 rate adapta -\ntion and TCP congestion control are thus similar to the young child who is constantly \npushing his/her parents for more and more (say candy for a young child, later curfew \nhours for the teenager) until the parents finally say \u201cEnough!\u201d and the child backs \noff (only to try again later after conditions have hopefully improved!). A number \nof other schemes have also been proposed to improve on this basic automatic rate-\nadjustment scheme [Kamerman 1997; Holland 2001; Lacage 2004].\nPower Management\nPower is a precious resource in mobile devices, and thus the 802.11 standard pro -\nvides power-management capabilities that allow 802.11 nodes to minimize the \namount of time that their sense, transmit, and receive functions and other circuitry \nneed to be \u201con.\u201d 802.11 power management operates as follows. A node is able to \nexplicitly alternate between sleep and wake states (not unlike a sleepy student in a \nclassroom!). A node indicates to the access point that it will be going to sleep by set -\nting the power-management bit in the header of an 802.11 frame to 1. A timer in the \nnode is then set to wake up the node just before the AP is scheduled to send its bea -\ncon frame (recall that an AP typically sends a beacon frame every 100 msec). Since \nthe AP knows from the set power-transmission bit that the node is going to sleep, it \n(the AP) knows that it should not send any frames to that node, and will buffer any \nframes destined for the sleeping host for later transmission.\nA node will wake up just before the AP sends a beacon frame, and quickly enter \nthe fully active state (unlike the sleepy student, this wakeup requires only 250 micro -\nseconds [Kamerman 1997]!). The beacon frames sent out by the AP contain a list of \nnodes whose frames have been buffered at the AP. If there are no buffered frames \nfor the node, it can go back to sleep. Otherwise, the node can explicitly request that \nthe buffered frames be sent by sending a polling message to the AP. With an inter-\nbeacon time of 100 msec, a wakeup time of 250 microseconds, and a similarly small \ntime to receive a beacon frame and check to ensure that there are no buffered frames, \na node that has no frames to send or receive can be asleep 99% of the time, resulting \nin a significant energy savings.\n7.3.6 Personal Area Networks: Bluetooth and Zigbee\nAs illustrated in Figure 7.2, the IEEE 802.11 WiFi standard is aimed at commu -\nnication among devices separated by up to 100 meters (except when 802.11 is \n7.3  \u2022  WIFI: 802.11 WIRELESS LANS      577\nused in a point-to-point configuration with a directional antenna). Two other wire -\nless protocols in the IEEE 802 family are Bluetooth and Zigbee (defined in the IEEE \n802.15.1 and IEEE 802.15.4 standards [IEEE 802.15 2012]).\nBluetooth\nAn IEEE 802.15.1 network operates over a short range, at low power, and at low cost. \nIt is essentially a low-power, short-range, low-rate \u201ccable replacement\u201d technology \nfor interconnecting a computer with its wireless keyboard, mouse or other periph -\neral device; cellular phones, speakers, headphones, and many other devices, whereas \n802.11 is a higher-power, medium-range, higher-rate \u201caccess\u201d technology. For this \nreason, 802.15.1 networks are sometimes referred to as wireless personal area net -\nworks", "doc_id": "66bf39ee-69a0-4349-afb7-63ee4caa4d8a", "embedding": null, "doc_hash": "f038042418b0d8a9db6a4cefcb28b46e4fec9d7fdb4759554eafad629734d649", "extra_info": null, "node_info": {"start": 1693136, "end": 1696839}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "10551ba4-3c49-4ce8-9da9-0ee352cbd253", "3": "97542c3f-34cd-4146-baf2-7e9019132b43"}}, "__type__": "1"}, "97542c3f-34cd-4146-baf2-7e9019132b43": {"__data__": {"text": "Two other wire -\nless protocols in the IEEE 802 family are Bluetooth and Zigbee (defined in the IEEE \n802.15.1 and IEEE 802.15.4 standards [IEEE 802.15 2012]).\nBluetooth\nAn IEEE 802.15.1 network operates over a short range, at low power, and at low cost. \nIt is essentially a low-power, short-range, low-rate \u201ccable replacement\u201d technology \nfor interconnecting a computer with its wireless keyboard, mouse or other periph -\neral device; cellular phones, speakers, headphones, and many other devices, whereas \n802.11 is a higher-power, medium-range, higher-rate \u201caccess\u201d technology. For this \nreason, 802.15.1 networks are sometimes referred to as wireless personal area net -\nworks (WPANs). The link and physical layers of 802.15.1 are based on the earlier \nBluetooth  specification for personal area networks [Held 2001, Bisdikian 2001]. \n802.15.1 networks operate in the 2.4 GHz unlicensed radio band in a TDM manner, \nwith time slots of 625 microseconds. During each time slot, a sender transmits on \none of 79 channels, with the channel changing in a known but pseudo-random man -\nner from slot to slot. This form of channel hopping, known as frequency-hopping \nspread spectrum (FHSS) , spreads transmissions in time over the frequency spec -\ntrum. 802.15.1 can provide data rates up to 4 Mbps.\n802.15.1 networks are ad hoc networks: No network infrastructure (e.g., an access \npoint) is needed to interconnect 802.15.1 devices. Thus, 802.15.1 devices must organ -\nize themselves. 802.15.1 devices are first organized into a piconet  of up to eight active \ndevices, as shown in Figure 7.16. One of these devices is designated as the master, with \nthe remaining devices acting as slaves. The master node truly rules the piconet\u2014its \nclock determines time in the piconet, it can transmit in each odd-numbered slot, and a \nFigure 7.16  \u2666 A Bluetooth piconetRadius of\ncoverage\nMaster device\nSlave device\nParked deviceKey:M\nMS\nSSSP\nPP\nP\nP\n578     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\nslave can transmit only after the master has communicated with it in the previous slot \nand even then the slave can only transmit to the master. In addition to the slave devices, \nthere can also be up to 255 parked devices in the network. These devices cannot com -\nmunicate until their status has been changed from parked to active by the master node.\nFor more information about WPANs, the interested reader should consult the \nBluetooth references [Held 2001, Bisdikian 2001] or the official IEEE 802.15 Web \nsite [IEEE 802.15 2012].\nZigbee\nA second personal area network standardized by the IEEE is the 802.15.4 standard \n[IEEE 802.15 2012] known as Zigbee. While Bluetooth networks provide a \u201ccable \nreplacement\u201d data rate of over a Megabit per second, Zigbee is targeted at lower-\npowered, lower-data-rate, lower-duty-cycle applications than Bluetooth. While we \nmay tend to think that \u201cbigger and faster is better,\u201d not all network applications \nneed high bandwidth and the consequent higher costs (both economic and power \ncosts). For example, home temperature and light sensors, security devices, and wall-\nmounted switches are all very simple, low-power, low-duty-cycle, low-cost devices. \nZigbee is thus well-suited for these devices. Zigbee defines channel rates of 20, 40, \n100, and 250 Kbps, depending on the channel frequency.\nNodes in a Zigbee network come in two flavors. So-called \u201creduced-  \nfunction devices\u201d operate as slave devices under the control of a single \u201cfull-function \ndevice,\u201d much as Bluetooth slave devices. A full-function device can operate as a \nmaster device as in Bluetooth by", "doc_id": "97542c3f-34cd-4146-baf2-7e9019132b43", "embedding": null, "doc_hash": "7e50b77395c7dfc6b1da3ecbd08485db11960e27e15255c8661d51c486867294", "extra_info": null, "node_info": {"start": 1696832, "end": 1700438}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "66bf39ee-69a0-4349-afb7-63ee4caa4d8a", "3": "2377bcac-830b-476b-8d20-d65d10d8b5c7"}}, "__type__": "1"}, "2377bcac-830b-476b-8d20-d65d10d8b5c7": {"__data__": {"text": "to think that \u201cbigger and faster is better,\u201d not all network applications \nneed high bandwidth and the consequent higher costs (both economic and power \ncosts). For example, home temperature and light sensors, security devices, and wall-\nmounted switches are all very simple, low-power, low-duty-cycle, low-cost devices. \nZigbee is thus well-suited for these devices. Zigbee defines channel rates of 20, 40, \n100, and 250 Kbps, depending on the channel frequency.\nNodes in a Zigbee network come in two flavors. So-called \u201creduced-  \nfunction devices\u201d operate as slave devices under the control of a single \u201cfull-function \ndevice,\u201d much as Bluetooth slave devices. A full-function device can operate as a \nmaster device as in Bluetooth by controlling multiple slave devices, and multiple \nfull-function devices can additionally be configured into a mesh network in which \nfull-function devices route frames amongst themselves. Zigbee shares many protocol \nmechanisms that we\u2019ve already encountered in other link-layer protocols: beacon \nframes and link-layer acknowledgments (similar to 802.11), carrier-sense random \naccess protocols with binary exponential backoff (similar to 802.11 and Ethernet), \nand fixed, guaranteed allocation of time slots (similar to DOCSIS).\nZigbee networks can be configured in many different ways. Let\u2019s consider the \nsimple case of a single full-function device controlling multiple reduced-function \ndevices in a time-slotted manner using beacon frames. Figure 7.17 shows the case \nFigure 7.17  \u2666 Zigbee 802.15.4 super-frame structureBeacon\nGuaranteed slots Contention slots Inactive period\nSuper frame\n7.4  \u2022  CELLULAR INTERNET ACCESS      579\nwhere the Zigbee network divides time into recurring super frames, each of which \nbegins with a beacon frame. Each beacon frame divides the super frame into an active \nperiod (during which devices may transmit) and an inactive period (during which all \ndevices, including the controller, can sleep and thus conserve power). The active \nperiod consists of 16 time slots, some of which are used by devices in a CSMA/CA \nrandom access manner, and some of which are allocated by the controller to specific \ndevices, thus providing guaranteed channel access for those devices. More details \nabout Zigbee networks can be found at [Baronti 2007, IEEE 802.15.4 2012].\n7.4 Cellular Internet Access\nIn the previous section we examined how an Internet host can access the Internet \nwhen inside a WiFi hotspot\u2014that is, when it is within the vicinity of an 802.11 \naccess point. But most WiFi hotspots have a small coverage area of between 10 and \n100 meters in diameter. What do we do then when we have a desperate need for wire -\nless Internet access and we cannot access a WiFi hotspot?\nGiven that cellular telephony is now ubiquitous in many areas throughout the \nworld, a natural strategy is to extend cellular networks so that they support not only \nvoice telephony but wireless Internet access as well. Ideally, this Internet access would \nbe at a reasonably high speed and would provide for seamless mobility, allowing users \nto maintain their TCP sessions while traveling, for example, on a bus or a train. With \nsufficiently high upstream and downstream bit rates, the user could even maintain \nvideo-conferencing sessions while roaming about. This scenario is not that far-fetched. \nData rates of several megabits per second are becoming available as broadband data \nservices such as those we will cover here become more widely deployed.\nIn this section, we provide a brief overview of current and emerging cellular \nInternet access technologies. Our focus here will be on both the wireless first hop as \nwell as the network that connects the wireless first hop into the larger telephone net -\nwork and/or the Internet; in Section 7.7 we\u2019ll consider how calls are routed to a user \nmoving between base stations. Our brief discussion will necessarily provide only a \nsimplified and high-level description of cellular", "doc_id": "2377bcac-830b-476b-8d20-d65d10d8b5c7", "embedding": null, "doc_hash": "3b86f873094f089a72dcb83cf8c21f995021402ae1a9eb961dc078478922f843", "extra_info": null, "node_info": {"start": 1700397, "end": 1704386}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "97542c3f-34cd-4146-baf2-7e9019132b43", "3": "c58c7445-a630-4fe8-9009-c54d4c79e4e7"}}, "__type__": "1"}, "c58c7445-a630-4fe8-9009-c54d4c79e4e7": {"__data__": {"text": "a train. With \nsufficiently high upstream and downstream bit rates, the user could even maintain \nvideo-conferencing sessions while roaming about. This scenario is not that far-fetched. \nData rates of several megabits per second are becoming available as broadband data \nservices such as those we will cover here become more widely deployed.\nIn this section, we provide a brief overview of current and emerging cellular \nInternet access technologies. Our focus here will be on both the wireless first hop as \nwell as the network that connects the wireless first hop into the larger telephone net -\nwork and/or the Internet; in Section 7.7 we\u2019ll consider how calls are routed to a user \nmoving between base stations. Our brief discussion will necessarily provide only a \nsimplified and high-level description of cellular technologies. Modern cellular com -\nmunications, of course, has great breadth and depth, with many universities offering \nseveral courses on the topic. Readers seeking a deeper understanding are encouraged \nto see [Goodman 1997; Kaaranen 2001; Lin 2001; Korhonen 2003; Schiller 2003; \nPalat 2009; Scourias 2012; Turner 2012; Akyildiz 2010], as well as the particularly \nexcellent and exhaustive references [Mouly 1992; Sauter 2014].\n7.4.1 An Overview of Cellular Network Architecture\nIn our description of cellular network architecture in this section, we\u2019ll adopt the \nterminology of the Global System for Mobile Communications ( GSM ) standards. \n580     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\n(For history buffs, the GSM acronym was originally derived from Groupe Sp\u00e9cial \nMobile , until the more anglicized name was adopted, preserving the original acro -\nnym letters.) In the 1980s, Europeans recognized the need for a pan-European digi -\ntal cellular telephony system that would replace the numerous incompatible analog \ncellular telephony systems, leading to the GSM standard [Mouly 1992]. Europeans \ndeployed GSM technology with great success in the early 1990s, and since then \nGSM has grown to be the 800-pound gorilla of the cellular telephone world, with \nmore than 80% of all cellular subscribers worldwide using GSM.\n4G CELLULAR MOBILE VERSUS WIRELESS LANS\nMany cellular mobile phone operators are deploying 4G cellular mobile systems. In \nsome countries (e.g., Korea and Japan), 4G LTE coverage is higher than 90%\u2014nearly \nubiquitous. In 2015, average download rates over deployed LTE systems range from \n10Mbps in the US and India to close to 40 Mbps in New Zealand. These 4G systems \nare being deployed in licensed radio-frequency bands, with some operators paying \nconsiderable sums to governments for spectrum-use licenses. 4G systems allow users \nto access the Internet from remote outdoor locations while on the move, in a manner \nsimilar to today\u2019s cellular phone-only access. In many cases, a user may have simulta -\nneous access to both wireless LANs and 4G. With the capacity of 4G systems being \nboth more constrained and more expensive, many mobile devices default to the use  \nof WiFi rather than 4G, when both are avilable. The question of whether wireless \nedge network access will be primarily over wireless LANs or cellular systems remains \nan open question:\n\u2022  The emerging wireless LAN infrastructure may become nearly ubiquitous. IEEE \n802.11 wireless LANs, operating at 54 Mbps and higher, are enjoying widespread \ndeployment. Essentially all laptops, tablets and smartphones are factory-equipped with \n802.11 LAN capabilities. Furthermore, emerging Internet appliances\u2014such as wire -\nless cameras and picture frames\u2014also have low-powered wireless LAN capabilities.\n\u2022  Wireless LAN base stations can also handle mobile phone appliances. Many \nphones are already capable of connecting to the cellular phone network or to an IP \nnetwork either natively or using a Skype-like Voice-over-IP service, thus", "doc_id": "c58c7445-a630-4fe8-9009-c54d4c79e4e7", "embedding": null, "doc_hash": "06c5642b750f9161ee8d15283dbbfb93c8f507caed466007217461c49f7e4356", "extra_info": null, "node_info": {"start": 1704321, "end": 1708183}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "2377bcac-830b-476b-8d20-d65d10d8b5c7", "3": "ebf1e265-7f83-47e5-83d4-c39e75e23760"}}, "__type__": "1"}, "ebf1e265-7f83-47e5-83d4-c39e75e23760": {"__data__": {"text": "The question of whether wireless \nedge network access will be primarily over wireless LANs or cellular systems remains \nan open question:\n\u2022  The emerging wireless LAN infrastructure may become nearly ubiquitous. IEEE \n802.11 wireless LANs, operating at 54 Mbps and higher, are enjoying widespread \ndeployment. Essentially all laptops, tablets and smartphones are factory-equipped with \n802.11 LAN capabilities. Furthermore, emerging Internet appliances\u2014such as wire -\nless cameras and picture frames\u2014also have low-powered wireless LAN capabilities.\n\u2022  Wireless LAN base stations can also handle mobile phone appliances. Many \nphones are already capable of connecting to the cellular phone network or to an IP \nnetwork either natively or using a Skype-like Voice-over-IP service, thus bypassing \nthe operator\u2019s cellular voice and 4G data services.\nOf course, many other experts believe that 4G not only will be a major  success, \nbut will also dramatically revolutionize the way we work and live. Most likely, \nboth WiFi and 4G will both become prevalent wireless technologies, with roaming \n wireless devices automatically selecting the access technology that provides the best \nservice at their current physical location.CASE HISTORY\n\n7.4  \u2022  CELLULAR INTERNET ACCESS      581\nWhen people talk about cellular technology, they often classify the technology \nas belonging to one of several \u201cgenerations.\u201d The earliest generations were designed \nprimarily for voice traffic. First generation (1G) systems were analog FDMA systems \ndesigned exclusively for voice-only communication. These 1G systems are almost \nextinct now, having been replaced by digital 2G systems. The original 2G systems \nwere also designed for voice, but later extended (2.5G) to support data (i.e., Internet) \nas well as voice service. 3G systems also support voice and data, but with an empha -\nsis on data capabilities and higher-speed radio access links. The 4G systems being \ndeployed today are based on LTE technology, feature an all-IP core network, and \nprovide integrated voice and data at multi-Megabit speeds.\nCellular Network Architecture, 2G: Voice Connections to the \n Telephone Network\nThe term cellular  refers to the fact that the region covered by a cellular network \nis partitioned into a number of geographic coverage areas, known as cells, shown \nas hexagons on the left side of Figure 7.18. As with the 802.11WiFi standard we \n studied in Section 7.3.1, GSM has its own particular nomenclature. Each cell  \nFigure 7.18  \u2666 Components of the GSM 2G cellular network architectureBSC\nBSCMSC\nKey: Base transceiver station\n(BTS)\nBase station contr oller\n(BSC)\nMobile switching center\n(MSC)\nMobile subscribersGateway\nMSCBase Station System\n(BSS)\nBase Station System (BSS)Public telephone\nnetworkG\n582     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\ncontains a base transceiver station (BTS)  that transmits signals to and receives sig -\nnals from the mobile stations in its cell. The coverage area of a cell depends on many \nfactors, including the transmitting power of the BTS, the transmitting power of the \nuser devices, obstructing buildings in the cell, and the height of base station antennas. \nAlthough Figure 7.18 shows each cell containing one base transceiver station residing \nin the middle of the cell, many systems today place the BTS at corners where three \ncells intersect, so that a single BTS with directional antennas can service three cells.\nThe GSM standard for 2G cellular systems uses combined FDM/TDM (radio) \nfor the air interface. Recall from Chapter 1 that, with pure FDM, the channel is parti -\ntioned into a number of frequency bands with each band devoted to a call. Also recall \nfrom Chapter 1 that, with pure TDM, time is partitioned into frames with each frame \nfurther partitioned into slots and each call being", "doc_id": "ebf1e265-7f83-47e5-83d4-c39e75e23760", "embedding": null, "doc_hash": "8c94b4f6ea8512f54ec0e47d029cec3776774fac59d027df7338f14f177cae77", "extra_info": null, "node_info": {"start": 1708203, "end": 1712034}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "c58c7445-a630-4fe8-9009-c54d4c79e4e7", "3": "36732651-f996-4ba5-9291-73a9f6cdb2c4"}}, "__type__": "1"}, "36732651-f996-4ba5-9291-73a9f6cdb2c4": {"__data__": {"text": "the transmitting power of the BTS, the transmitting power of the \nuser devices, obstructing buildings in the cell, and the height of base station antennas. \nAlthough Figure 7.18 shows each cell containing one base transceiver station residing \nin the middle of the cell, many systems today place the BTS at corners where three \ncells intersect, so that a single BTS with directional antennas can service three cells.\nThe GSM standard for 2G cellular systems uses combined FDM/TDM (radio) \nfor the air interface. Recall from Chapter 1 that, with pure FDM, the channel is parti -\ntioned into a number of frequency bands with each band devoted to a call. Also recall \nfrom Chapter 1 that, with pure TDM, time is partitioned into frames with each frame \nfurther partitioned into slots and each call being assigned the use of a particular slot \nin the revolving frame. In combined FDM/TDM systems, the channel is partitioned \ninto a number of frequency sub-bands; within each sub-band, time is partitioned into \nframes and slots. Thus, for a combined FDM/TDM system, if the channel is parti -\ntioned into F sub-bands and time is partitioned into T slots, then the channel will be \nable to support F.T simultaneous calls. Recall that we saw in Section 6.3.4 that cable \naccess networks also use a combined FDM/TDM approach. GSM systems consist of \n200-kHz frequency bands with each band supporting eight TDM calls. GSM encodes \nspeech at 13 kbps and 12.2 kbps.\nA GSM network\u2019s base station controller (BSC)  will typically service several \ntens of base transceiver stations. The role of the BSC is to allocate BTS radio chan -\nnels to mobile subscribers, perform paging  (finding the cell in which a mobile user \nis resident), and perform handoff of mobile users\u2014a topic we\u2019ll cover shortly in \nSection 7. 7.2. The base station controller and its controlled base transceiver stations \ncollectively constitute a GSM base station subsystem (BSS) .\nAs we\u2019ll see in Section 7.7, the mobile switching center (MSC)  plays the cen -\ntral role in user authorization and accounting (e.g., determining whether a mobile \ndevice is allowed to connect to the cellular network), call establishment and tear -\ndown, and handoff. A single MSC will typically contain up to five BSCs, resulting in \napproximately 200K subscribers per MSC. A cellular provider\u2019s network will have \na number of MSCs, with special MSCs known as gateway MSCs connecting the \nprovider\u2019s cellular network to the larger public telephone network.\n7.4.2  3G Cellular Data Networks: Extending the Internet  \nto Cellular Subscribers\nOur discussion in Section 7.4.1 focused on connecting cellular voice users to the pub -\nlic telephone network. But, of course, when we\u2019re on the go, we\u2019d also like to read \ne-mail, access the Web, get location-dependent services (e.g., maps and restaurant \nrecommendations) and perhaps even watch streaming video. To do this, our smart -\nphone will need to run a full TCP/IP protocol stack (including the physical link, net -\nwork, transport, and application layers) and connect into the Internet via the cellular \n7.4  \u2022  CELLULAR INTERNET ACCESS      583\ndata network. The topic of cellular data networks is a rather bewildering collection of \ncompeting and ever-evolving standards as one generation (and half-generation) suc -\nceeds the former and introduces new technologies and services with new acronyms. \nTo make matters worse, there\u2019s no single official body that sets requirements for \n2.5G, 3G, 3.5G, or 4G technologies, making it hard to sort out the differences among \ncompeting standards. In our discussion below, we\u2019ll focus on the UMTS (Universal \nMobile Telecommunications Service) 3G and 4G standards developed by the 3rd \nGeneration Partnership project (3GPP)", "doc_id": "36732651-f996-4ba5-9291-73a9f6cdb2c4", "embedding": null, "doc_hash": "eea97ddfec0f2413005f4e239ade5c997602ffb0093546591a3f04823c78ce6b", "extra_info": null, "node_info": {"start": 1712040, "end": 1715798}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "ebf1e265-7f83-47e5-83d4-c39e75e23760", "3": "c82e75f9-e667-4a7c-9795-e807a11fca1e"}}, "__type__": "1"}, "c82e75f9-e667-4a7c-9795-e807a11fca1e": {"__data__": {"text": "application layers) and connect into the Internet via the cellular \n7.4  \u2022  CELLULAR INTERNET ACCESS      583\ndata network. The topic of cellular data networks is a rather bewildering collection of \ncompeting and ever-evolving standards as one generation (and half-generation) suc -\nceeds the former and introduces new technologies and services with new acronyms. \nTo make matters worse, there\u2019s no single official body that sets requirements for \n2.5G, 3G, 3.5G, or 4G technologies, making it hard to sort out the differences among \ncompeting standards. In our discussion below, we\u2019ll focus on the UMTS (Universal \nMobile Telecommunications Service) 3G and 4G standards developed by the 3rd \nGeneration Partnership project (3GPP) [3GPP 2016].\nLet\u2019s first take a top-down look at 3G cellular data network architecture shown \nin Figure 7.19.\nFigure 7.19  \u2666 3G system architectureGateway\nMSCG\nKey:\nServing GPRS\nSupport Node\n(SGSN)Gateway GPRS\nSupport Node\n(GGSN)Radio Network\nController (RNC) GGSN SGSN\nGGMSCPublic telephone\nnetwork\nRadio Interface\n(WCDMA, HSPA)\nRadio Access Network\nUniversal Terrestrial Radio\nAccess Network (UTRAN)Core Network\nGeneral Packet Radio Service\n(GPRS) Core NetworkPublic\nInternetPublic\nInternet\n584     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\n3G Core Network\nThe 3G core cellular data network connects radio access networks to the public Inter -\nnet. The core network interoperates with components of the existing cellular voice \nnetwork (in particular, the MSC) that we previously encountered in Figure 7.18. \nGiven the considerable amount of existing infrastructure (and profitable services!) \nin the existing cellular voice network, the approach taken by the designers of 3G \ndata services is clear: leave the existing core GSM cellular voice network untouched, \nadding additional cellular data functionality in parallel to the existing cellular voice \nnetwork . The alternative\u2014integrating new data services directly into the core of the \nexisting cellular voice network\u2014would have raised the same challenges encountered \nin Section 4.3, where we discussed integrating new (IPv6) and legacy (IPv4) tech -\nnologies in the Internet.\nThere are two types of nodes in the 3G core network: Serving GPRS Support \nNodes (SGSNs)  and Gateway GPRS Support Nodes (GGSNs) . (GPRS stands for \nGeneralized Packet Radio Service, an early cellular data service in 2G networks; \nhere we discuss the evolved version of GPRS in 3G networks). An SGSN is respon -\nsible for delivering datagrams to/from the mobile nodes in the radio access network \nto which the SGSN is attached. The SGSN interacts with the cellular voice network\u2019s \nMSC for that area, providing user authorization and handoff, maintaining location \n(cell) information about active mobile nodes, and performing datagram forwarding \nbetween mobile nodes in the radio access network and a GGSN. The GGSN acts as \na gateway, connecting multiple SGSNs into the larger Internet. A GGSN is thus the \nlast piece of 3G infrastructure that a datagram originating at a mobile node encoun -\nters before entering the larger Internet. To the outside world, the GGSN looks like \nany other gateway router; the mobility of the 3G nodes within the GGSN\u2019s network \nis hidden from the outside world behind the GGSN.\n3G Radio Access Network: The Wireless Edge\nThe 3G radio access network  is the wireless first-hop network that we see as a 3G \nuser. The Radio Network Controller (RNC)  typically controls several cell base \ntransceiver stations similar to the base stations that we encountered in 2G systems \n(but officially known in 3G UMTS parlance as a \u201cNode Bs\u201d\u2014a rather non-descrip -\ntive name!). Each cell\u2019s wireless link operates between the mobile", "doc_id": "c82e75f9-e667-4a7c-9795-e807a11fca1e", "embedding": null, "doc_hash": "b26ada2af98b00e86c9a836356220a62c766ab0d7945f2f22f90fceab74bb671", "extra_info": null, "node_info": {"start": 1715850, "end": 1719570}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "36732651-f996-4ba5-9291-73a9f6cdb2c4", "3": "eb7b609f-43e2-48d7-8137-0392072ca742"}}, "__type__": "1"}, "eb7b609f-43e2-48d7-8137-0392072ca742": {"__data__": {"text": "\nlast piece of 3G infrastructure that a datagram originating at a mobile node encoun -\nters before entering the larger Internet. To the outside world, the GGSN looks like \nany other gateway router; the mobility of the 3G nodes within the GGSN\u2019s network \nis hidden from the outside world behind the GGSN.\n3G Radio Access Network: The Wireless Edge\nThe 3G radio access network  is the wireless first-hop network that we see as a 3G \nuser. The Radio Network Controller (RNC)  typically controls several cell base \ntransceiver stations similar to the base stations that we encountered in 2G systems \n(but officially known in 3G UMTS parlance as a \u201cNode Bs\u201d\u2014a rather non-descrip -\ntive name!). Each cell\u2019s wireless link operates between the mobile nodes and a base \ntransceiver station, just as in 2G networks. The RNC connects to both the circuit-\nswitched cellular voice network via an MSC, and to the packet-switched Internet via \nan SGSN. Thus, while 3G cellular voice and cellular data services use different core \nnetworks, they share a common first/last-hop radio access network.\nA significant change in 3G UMTS over 2G networks is that rather than using \nGSM\u2019s FDMA/TDMA scheme, UMTS uses a CDMA technique known as Direct \nSequence Wideband CDMA (DS-WCDMA) [Dahlman 1998] within TDMA slots; \nTDMA slots, in turn, are available on multiple frequencies\u2014an interesting use of \n7.4  \u2022  CELLULAR INTERNET ACCESS      585\nall three dedicated channel-sharing approaches that we earlier identified in Chapter \n6 and similar to the approach taken in wired cable access networks (see Section \n6.3.4 ). This change requires a new 3G cellular wireless-access network operating \nin parallel with the 2G BSS radio network shown in Figure 7.19. The data service \nassociated with the WCDMA specification is known as HSPA (High Speed Packet \nAccess) and promises downlink data rates of up to 14 Mbps. Details regarding 3G \nnetworks can be found at the 3rd Generation Partnership Project (3GPP) Web site \n[3GPP 2016].\n7.4.3 On to 4G: LTE\nFourth generation (4G) cellular systems are becoming widely deployed. In 2015, \nmore than 50 countries had 4G coverage exceeding 50%. The 4G Long-Term \n Evolution (LTE) standard [Sauter 2014] put forward by the 3GPP has two important \ninnovations over 3G systems an all-IP core network and an enhanced radio access \nnetwork, as discussed below.\n4G System Architecture: An All-IP Core Network\nFigure 7. 20 shows the overall 4G network architecture, which (unfortunately) intro -\nduces yet another (rather impenetrable) new vocabulary and set of acronyms for \nFigure 7.20  \u2666 4G network architectureE-UTRAN\nradio access\nnetwork all-IP Enhanced Packet Core (EPC)Contr ol planeUE eNodeB MME HHS S-GW P-GW\nData plane\n586     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\n network  components. But let\u2019s not get lost in these acronyms! There are two impor -\ntant high-level observations about the 4G architecture:\n\u2022 A unified, all-IP network architecture.  Unlike the 3G network shown in Figure \n7.19, which has separate network components and paths for voice and data traffic, \nthe 4G architecture shown in Figure 7.20 is \u201call-IP\u201d\u2014both voice and data are car -\nried in IP datagrams to/from the wireless device (the User Equipment, UE in 4G \nparlance) to the gateway to the packet gateway (P-GW) that connects the 4G edge \nnetwork to the rest of the network. With 4G, the last vestiges of cellular networks\u2019 \nroots in the telephony have disappeared, giving way to universal IP service!\n\u2022 A clear separation", "doc_id": "eb7b609f-43e2-48d7-8137-0392072ca742", "embedding": null, "doc_hash": "453c022d9627e1866c0a9ffd498de923f41d07ea7cb261f60622b89e9d615a10", "extra_info": null, "node_info": {"start": 1719567, "end": 1723089}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "c82e75f9-e667-4a7c-9795-e807a11fca1e", "3": "7183b0da-d584-4709-bce6-02084f4c671d"}}, "__type__": "1"}, "7183b0da-d584-4709-bce6-02084f4c671d": {"__data__": {"text": "There are two impor -\ntant high-level observations about the 4G architecture:\n\u2022 A unified, all-IP network architecture.  Unlike the 3G network shown in Figure \n7.19, which has separate network components and paths for voice and data traffic, \nthe 4G architecture shown in Figure 7.20 is \u201call-IP\u201d\u2014both voice and data are car -\nried in IP datagrams to/from the wireless device (the User Equipment, UE in 4G \nparlance) to the gateway to the packet gateway (P-GW) that connects the 4G edge \nnetwork to the rest of the network. With 4G, the last vestiges of cellular networks\u2019 \nroots in the telephony have disappeared, giving way to universal IP service!\n\u2022 A clear separation of the 4G data plane and 4G control plane.  Mirroring our dis -\ntinction between the data and control planes for IP\u2019s network layer in Chapters 4   \nand 5 respectively, the 4G network architecture also clearly separates the data and \ncontrol planes. We\u2019ll discuss their functionality below.\n\u2022 A clear separation between the radio access network, and the all-IP-core  network.  \nIP datagrams carrying user data are forwarded between the user (UE) and the \ngateway (P-GW in Figure 7.20) over a 4G-internal IP network to the external \nInternet. Control packets are exchanged over this same internal network among \nthe 4G\u2019s control services components, whose roles are described below.\nThe principal components of the 4G architecture are as follows.\n\u2022 The eNodeB  is the logical descendant of the 2G base station and the 3G Radio \nNetwork Controller (a.k.a Node B) and again plays a central role here. Its data-\nplane role is to forward datagrams between UE (over the LTE radio access \n network) and the P-GW.\n UE datagrams are encapsulated at the eNodeB and tunneled to the P-GW through \nthe 4G network\u2019s all-IP enhanced packet core (EPC). This tunneling between \nthe eNodeB and P-GW is similar the tunneling we saw in Section 4.3 of IPv6 \ndatagrams between two IPv6 endpoints through a network of IPv4 routers. These \ntunnels may have associated quality of service (QoS) guarantees. For example, \na 4G network may guarantee that voice traffic experiences no more than a 100 \nmsec delay between UE and P-GW, and has a packet loss rate of less than 1%; \nTCP traffic might have a guarantee of 300 msec and a packet loss rate of less than \n.0001% [Palat 2009]. We\u2019ll cover QoS in Chapter 9.\n In the control plane, the eNodeB handles registration and mobility signaling traf -\nfic on behalf of the UE.\n\u2022 The Packet Data Network Gateway (P-GW)  allocates IP addresses to the UEs \nand performs QoS enforcement. As a tunnel endpoint it also performs datagram \nencapsulation/decapsulation when forwarding a datagram to/from a UE.\n\u2022 The Serving Gateway (S-GW) is the data-plane mobility anchor point\u2014all UE \ntraffic will pass through the S-GW. The S-GW also performs charging/billing \nfunctions and lawful traffic interception.\n7.4  \u2022  CELLULAR INTERNET ACCESS      587\n\u2022 The Mobility Management Entity (MME)  performs connection and mobility \nmanagement on behalf of the UEs resident in the cell it controls. It receives UE \nsubscription information from the HHS. We cover mobility in cellular networks \nin detail in Section 7.7.\n\u2022 The Home Subscriber Server (HSS)  contains UE information including roam -\ning access capabilities, quality of service profiles, and authentication information. \nAs we\u2019ll see in Section 7.7, the HSS obtains this information from the UE\u2019s home \ncellular provider.\nVery readable introductions to 4G network architecture and its EPC are [Motorola \n2007; Palat 2009; Sauter 2014].\nLTE Radio Access Network\nLTE", "doc_id": "7183b0da-d584-4709-bce6-02084f4c671d", "embedding": null, "doc_hash": "09a952a3bcbfe1981807ce15ca50d798f0e9714113d39707c6487383dd5c8970", "extra_info": null, "node_info": {"start": 1723150, "end": 1726747}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "eb7b609f-43e2-48d7-8137-0392072ca742", "3": "a55d14c4-0f60-4835-87f0-3b857c93c4d7"}}, "__type__": "1"}, "a55d14c4-0f60-4835-87f0-3b857c93c4d7": {"__data__": {"text": " \u2022  CELLULAR INTERNET ACCESS      587\n\u2022 The Mobility Management Entity (MME)  performs connection and mobility \nmanagement on behalf of the UEs resident in the cell it controls. It receives UE \nsubscription information from the HHS. We cover mobility in cellular networks \nin detail in Section 7.7.\n\u2022 The Home Subscriber Server (HSS)  contains UE information including roam -\ning access capabilities, quality of service profiles, and authentication information. \nAs we\u2019ll see in Section 7.7, the HSS obtains this information from the UE\u2019s home \ncellular provider.\nVery readable introductions to 4G network architecture and its EPC are [Motorola \n2007; Palat 2009; Sauter 2014].\nLTE Radio Access Network\nLTE uses a combination of frequency division multiplexing and time division multi -\nplexing on the downstream channel, known as orthogonal frequency division multi -\nplexing (OFDM) [Rohde 2008; Ericsson 2011]. (The term \u201corthogonal\u201d comes from \nthe fact the signals being sent on different frequency channels are created so that \nthey interfere very little with each other, even when channel frequencies are tightly \nspaced). In LTE, each active mobile node is allocated one or more 0.5 ms time slots \nin one or more of the channel frequencies. Figure 7.21 shows an allocation of eight \ntime slots over four frequencies. By being allocated increasingly more time slots \n(whether on the same frequency or on different frequencies), a mobile node is able \nto achieve increasingly higher transmission rates. Slot (re)allocation among mobile \nFigure 7.21  \u2666  Twenty 0.5 ms slots organized into 10 ms frames at each \nfrequency. An eight-slot allocation is shown shaded.f1f2f3f4f5f6\n0 0.5 1.0 1.5 2.0 2.5 9.0 9.5 10.0\n588     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\nnodes can be performed as often as once every millisecond. Different modulation \nschemes can also be used to change the transmission rate; see our earlier discussion \nof Figure 7.3 and dynamic selection of modulation schemes in WiFi networks.\nThe particular allocation of time slots to mobile nodes is not mandated by the \nLTE standard. Instead, the decision of which mobile nodes will be allowed to transmit \nin a given time slot on a given frequency is determined by the scheduling algorithms \nprovided by the LTE equipment vendor and/or the network operator. With opportun -\nistic scheduling [Bender 2000; Kolding 2003; Kulkarni 2005], matching the physical-\nlayer protocol to the channel conditions between the sender and receiver and choosing \nthe receivers to which packets will be sent based on channel conditions allow the \nradio network controller to make best use of the wireless medium. In addition, user \npriorities and contracted levels of service (e.g., silver, gold, or platinum) can be used \nin scheduling downstream packet transmissions. In addition to the LTE capabilities \ndescribed above, LTE-Advanced allows for downstream bandwidths of hundreds of \nMbps by allocating aggregated channels to a mobile node [Akyildiz 2010].\nAn additional 4G wireless technology\u2014WiMAX (World Interoperability for \nMicrowave Access)\u2014is a family of IEEE 802.16 standards that differ significantly \nfrom LTE. WiMAX has not yet been able to enjoy the widespread deployment of \nLTE. A detailed discussion of WiMAX can be found on this book\u2019s Web site.\n7.5 Mobility Management: Principles\nHaving covered the wireless  nature of the communication links in a wireless net -\nwork, it\u2019s now time to turn our attention to the mobility  that these wireless links \nenable. In the broadest sense, a mobile node is one that changes its point of attach -\nment into the network over time. Because the term mobility  has taken on many mean -\nings in both the computer and telephony worlds, it will serve us well first to consider \nseveral dimensions of mobility in", "doc_id": "a55d14c4-0f60-4835-87f0-3b857c93c4d7", "embedding": null, "doc_hash": "2348b21f16b1128b0ddbdd064c09e04ec07aac9051abbf832a2f683b0ca48bbd", "extra_info": null, "node_info": {"start": 1726713, "end": 1730530}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "7183b0da-d584-4709-bce6-02084f4c671d", "3": "7d684626-1973-474c-86d4-c70655e50682"}}, "__type__": "1"}, "7d684626-1973-474c-86d4-c70655e50682": {"__data__": {"text": "(World Interoperability for \nMicrowave Access)\u2014is a family of IEEE 802.16 standards that differ significantly \nfrom LTE. WiMAX has not yet been able to enjoy the widespread deployment of \nLTE. A detailed discussion of WiMAX can be found on this book\u2019s Web site.\n7.5 Mobility Management: Principles\nHaving covered the wireless  nature of the communication links in a wireless net -\nwork, it\u2019s now time to turn our attention to the mobility  that these wireless links \nenable. In the broadest sense, a mobile node is one that changes its point of attach -\nment into the network over time. Because the term mobility  has taken on many mean -\nings in both the computer and telephony worlds, it will serve us well first to consider \nseveral dimensions of mobility in some detail.\n\u2022 From the network layer\u2019s standpoint, how mobile is a user?  A physically mobile \nuser will present a very different set of challenges to the network layer, depending \non how he or she moves between points of attachment to the network. At one end \nof the spectrum in Figure 7.22, a user may carry a laptop with a wireless network \ninterface card around in a building. As we saw in Section 7.3.4, this user is not \nmobile from a network-layer perspective. Moreover, if the user associates with \nthe same access point regardless of location, the user is not even mobile from the \nperspective of the link layer.\n At the other end of the spectrum, consider the user zooming along the autobahn \nin a BMW or Tesla at 150 kilometers per hour, passing through multiple wireless \naccess networks and wanting to maintain an uninterrupted TCP connection to a \nremote application throughout the trip. This user is definitely  mobile! In between \n7.5  \u2022  MOBILITY MANAGEMENT: PRINCIPLES      589\nthese extremes is a user who takes a laptop from one location (e.g., office or \ndormitory) into another (e.g., coffeeshop, classroom) and wants to connect into \nthe-network in the new location. This user is also mobile (although less so than \nthe BMW driver!) but does not need to maintain an ongoing connection while \nmoving between points of attachment to the network. Figure 7.22 illustrates this \nspectrum of user mobility from the network layer\u2019s perspective.\n\u2022 How important is it for the mobile node\u2019s address to always remain the same?  \nWith mobile telephony, your phone number\u2014essentially the network-layer \naddress of your phone\u2014remains the same as you travel from one provider\u2019s \nmobile phone network to another. Must a laptop similarly maintain the same IP \naddress while moving between IP networks?\n The answer to this question will depend strongly on the applications being run. \nFor the BMW or Tesla driver who wants to maintain an uninterrupted TCP con -\nnection to a remote application while zipping along the autobahn, it would be \nconvenient to maintain the same IP address. Recall from Chapter 3 that an Internet \napplication needs to know the IP address and port number of the remote entity \nwith which it is communicating. If a mobile entity is able to maintain its IP address \nas it moves, mobility becomes invisible from the application standpoint. There is \ngreat value to this transparency\u2014an application need not be concerned with a \npotentially changing IP address, and the same application code serves mobile \nand nonmobile connections alike. We\u2019ll see in the following section that mobile \nIP provides this transparency, allowing a mobile node to maintain its permanent \nIP address while moving among networks.\n On the other hand, a less glamorous mobile user might simply want to turn off \nan office laptop, bring that laptop home, power up, and work from home. If the \nlaptop functions primarily as a client in client-server applications (e.g., send/read \ne-mail, browse the Web, Telnet to a remote host) from home, the particular IP \naddress used by the laptop is not that important. In particular, one could get by \nfine with an address that is temporarily allocated to the laptop by the ISP serving \nthe home. We saw in Section 4.3 that DHCP already", "doc_id": "7d684626-1973-474c-86d4-c70655e50682", "embedding": null, "doc_hash": "08b5c7f46dc7e015635af984e9e59e3d59fec1d6bb5610f94c5e43c71a72afeb", "extra_info": null, "node_info": {"start": 1730493, "end": 1734537}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "a55d14c4-0f60-4835-87f0-3b857c93c4d7", "3": "09f9b482-ee9a-4f8a-a692-c29f6860f6ea"}}, "__type__": "1"}, "09f9b482-ee9a-4f8a-a692-c29f6860f6ea": {"__data__": {"text": "serves mobile \nand nonmobile connections alike. We\u2019ll see in the following section that mobile \nIP provides this transparency, allowing a mobile node to maintain its permanent \nIP address while moving among networks.\n On the other hand, a less glamorous mobile user might simply want to turn off \nan office laptop, bring that laptop home, power up, and work from home. If the \nlaptop functions primarily as a client in client-server applications (e.g., send/read \ne-mail, browse the Web, Telnet to a remote host) from home, the particular IP \naddress used by the laptop is not that important. In particular, one could get by \nfine with an address that is temporarily allocated to the laptop by the ISP serving \nthe home. We saw in Section 4.3 that DHCP already provides this functionality.Figure 7.22  \u2666  Various degrees of mobility, from the network layer\u2019s point \nof viewUser moves only\nwithin same wireless\naccess networkNo mobility High mobility\nUser moves between\naccess networks,\nshutting down while\nmoving between\nnetworksUser moves between\naccess networks,\nwhile maintaining\nongoing connections\n590     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\n\u2022 What supporting wired infrastructure is available?  In all of our scenarios above, \nwe\u2019ve implicitly assumed that there is a fixed infrastructure to which the mobile \nuser can connect\u2014for example, the home\u2019s ISP network, the wireless access net -\nwork in the office, or the wireless access networks lining the autobahn. What if \nno such infrastructure exists? If two users are within communication proximity \nof each other, can they establish a network connection in the absence of any \nother network-layer infrastructure? Ad hoc networking provides precisely these \ncapabilities. This rapidly developing area is at the cutting edge of mobile net -\nworking research and is beyond the scope of this book. [Perkins 2000] and the \nIETF Mobile Ad Hoc Network (manet) working group Web pages [manet 2016] \nprovide thorough treatments of the subject.\nIn order to illustrate the issues involved in allowing a mobile user to maintain \nongoing connections while moving between networks, let\u2019s consider a human anal -\nogy. A twenty-something adult moving out of the family home becomes mobile, \nliving in a series of dormitories and/or apartments, and often changing addresses. If \nan old friend wants to get in touch, how can that friend find the address of her mobile \nfriend? One common way is to contact the family, since a mobile adult will often reg -\nister his or her current address with the family (if for no other reason than so that the \nparents can send money to help pay the rent!). The family home, with its permanent \naddress, becomes that one place that others can go as a first step in communicating \nwith the mobile adult. Later communication from the friend may be either indirect \n(for example, with mail being sent first to the parents\u2019 home and then forwarded to \nthe mobile adult) or direct (for example, with the friend using the address obtained \nfrom the parents to send mail directly to her mobile friend).\nIn a network setting, the permanent home of a mobile node (such as a laptop or \nsmartphone) is known as the home network , and the entity within the home network \nthat performs the mobility management functions discussed below on behalf of the \nmobile node is known as the home agent . The network in which the mobile node is \ncurrently residing is known as the foreign  (or visited ) network , and the entity within \nthe foreign network that helps the mobile node with the mobility management func -\ntions discussed below is known as a foreign agent . For mobile professionals, their \nhome network might likely be their company network, while the visited network \nmight be the network of a colleague they are visiting. A correspondent  is the entity \nwishing to communicate with the mobile node. Figure 7.23 illustrates these concepts, \nas well as addressing concepts considered below. In Figure 7.23, note that agents are \nshown as being collocated with routers (e.g., as processes running on routers), but \nalternatively they could be executing on", "doc_id": "09f9b482-ee9a-4f8a-a692-c29f6860f6ea", "embedding": null, "doc_hash": "bc1f1e793dbdc4a441cc5f72721ae2c83ea6924a496c7d133ae9f08528b7c7ee", "extra_info": null, "node_info": {"start": 1734539, "end": 1738672}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "7d684626-1973-474c-86d4-c70655e50682", "3": "1ce3221c-e06a-429a-b1c9-198aa09172f4"}}, "__type__": "1"}, "1ce3221c-e06a-429a-b1c9-198aa09172f4": {"__data__": {"text": "mobility management functions discussed below on behalf of the \nmobile node is known as the home agent . The network in which the mobile node is \ncurrently residing is known as the foreign  (or visited ) network , and the entity within \nthe foreign network that helps the mobile node with the mobility management func -\ntions discussed below is known as a foreign agent . For mobile professionals, their \nhome network might likely be their company network, while the visited network \nmight be the network of a colleague they are visiting. A correspondent  is the entity \nwishing to communicate with the mobile node. Figure 7.23 illustrates these concepts, \nas well as addressing concepts considered below. In Figure 7.23, note that agents are \nshown as being collocated with routers (e.g., as processes running on routers), but \nalternatively they could be executing on other hosts or servers in the network.\n7.5.1 Addressing\nWe noted above that in order for user mobility to be transparent to network applica -\ntions, it is desirable for a mobile node to keep its address as it moves from one network \n7.5  \u2022  MOBILITY MANAGEMENT: PRINCIPLES      591\nto another. When a mobile node is resident in a foreign network, all traffic addressed \nto the node\u2019s permanent address now needs to be routed to the foreign network. How \ncan this be done? One option is for the foreign network to advertise to all other net -\nworks that the mobile node is resident in its network. This could be via the usual \nexchange of intradomain and interdomain routing information and would require \nfew changes to the existing routing infrastructure. The foreign network could simply \nadvertise to its neighbors that it has a highly specific route to the mobile node\u2019s per -\nmanent address (that is, essentially inform other networks that it has the correct path \nfor routing datagrams to the mobile node\u2019s permanent address; see Section 4.3). These \nneighbors would then propagate this routing information throughout the network as \npart of the normal procedure of updating routing information and forwarding tables. \nWhen the mobile node leaves one foreign network and joins another, the new foreign \nnetwork would advertise a new, highly specific route to the mobile node, and the old \nforeign network would withdraw its routing information regarding the mobile node.\nThis solves two problems at once, and it does so without making significant \nchanges to the network-layer infrastructure. Other networks know the location of Figure 7.23  \u2666 Initial elements of a mobile network architectureHome agentHome network:\n128.119.40/24Visited network:\n79.129.13/24\nMobile node\nPermanent address:\n128.119.40.186 Permanent address:\n128.119.40.186\nForeign agentCare-of address:\n79.129.13.2\nCorrespondentWide ar ea\nnetwork\n592     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\nthe mobile node, and it is easy to route datagrams to the mobile node, since the for -\nwarding tables will direct datagrams to the foreign network. A significant drawback, \nhowever, is that of scalability. If mobility management were to be the responsibility \nof network routers, the routers would have to maintain forwarding table entries for \npotentially millions of mobile nodes, and update these entries as nodes move. Some \nadditional drawbacks are explored in the problems at the end of this chapter.\nAn alternative approach (and one that has been adopted in practice) is to push \nmobility functionality from the network core to the network edge\u2014a recurring theme \nin our study of Internet architecture. A natural way to do this is via the mobile node\u2019s \nhome network. In much the same way that parents of the mobile twenty-something \ntrack their child\u2019s location, the home agent in the mobile node\u2019s home network can \ntrack the foreign network in which the mobile node resides. A protocol between the \nmobile node (or a foreign agent representing the mobile node) and the home agent \nwill certainly be needed to update the mobile node\u2019s location.\nLet\u2019s now consider the foreign agent in more detail. The conceptually simplest \napproach, shown in Figure 7.23, is", "doc_id": "1ce3221c-e06a-429a-b1c9-198aa09172f4", "embedding": null, "doc_hash": "db3479bfc981a174456fdfbdc2b763ba935ec080fd6235ed0514fce03c7dc58d", "extra_info": null, "node_info": {"start": 1738580, "end": 1742692}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "09f9b482-ee9a-4f8a-a692-c29f6860f6ea", "3": "8ee89fc9-d2a3-46e5-9aea-343e87c32a61"}}, "__type__": "1"}, "8ee89fc9-d2a3-46e5-9aea-343e87c32a61": {"__data__": {"text": "are explored in the problems at the end of this chapter.\nAn alternative approach (and one that has been adopted in practice) is to push \nmobility functionality from the network core to the network edge\u2014a recurring theme \nin our study of Internet architecture. A natural way to do this is via the mobile node\u2019s \nhome network. In much the same way that parents of the mobile twenty-something \ntrack their child\u2019s location, the home agent in the mobile node\u2019s home network can \ntrack the foreign network in which the mobile node resides. A protocol between the \nmobile node (or a foreign agent representing the mobile node) and the home agent \nwill certainly be needed to update the mobile node\u2019s location.\nLet\u2019s now consider the foreign agent in more detail. The conceptually simplest \napproach, shown in Figure 7.23, is to locate foreign agents at the edge routers in the \nforeign network. One role of the foreign agent is to create a so-called care-of address \n(COA)  for the mobile node, with the network portion of the COA matching that of \nthe foreign network. There are thus two addresses associated with a mobile node, \nits permanent address  (analogous to our mobile youth\u2019s family\u2019s home address) \nand its COA, sometimes known as a foreign address  (analogous to the address of \nthe house in which our mobile youth is currently residing). In the example in Figure \n7.23, the permanent address of the mobile node is 128.119.40.186. When visiting \nnetwork 79.129.13/24, the mobile node has a COA of 79.129.13.2. A second role of \nthe foreign agent is to inform the home agent that the mobile node is resident in its \n(the foreign agent\u2019s) network and has the given COA. We\u2019ll see shortly that the COA \nwill be used to \u201creroute\u201d datagrams to the mobile node via its foreign agent.\nAlthough we have separated the functionality of the mobile node and the foreign \nagent, it is worth noting that the mobile node can also assume the responsibilities of \nthe foreign agent. For example, the mobile node could obtain a COA in the foreign \nnetwork (for example, using a protocol such as DHCP) and itself inform the home \nagent of its COA.\n7.5.2 Routing to a Mobile Node\nWe have now seen how a mobile node obtains a COA and how the home agent \ncan be informed of that address. But having the home agent know the COA solves \nonly part of the problem. How should datagrams be addressed and forwarded to the \nmobile node? Since only the home agent (and not network-wide routers) knows the \nlocation of the mobile node, it will no longer suffice to simply address a datagram to \nthe mobile node\u2019s permanent address and send it into the network-layer infrastruc -\nture. Something more must be done. Two approaches can be identified, which we \nwill refer to as indirect and direct routing.\n7.5  \u2022  MOBILITY MANAGEMENT: PRINCIPLES      593\nIndirect Routing to a Mobile Node\nLet\u2019s first consider a correspondent that wants to send a datagram to a mobile node. \nIn the indirect routing  approach, the correspondent simply addresses the datagram \nto the mobile node\u2019s permanent address and sends the datagram into the network, \nblissfully unaware of whether the mobile node is resident in its home network or is \nvisiting a foreign network; mobility is thus completely transparent to the correspond -\nent. Such datagrams are first routed, as usual, to the mobile node\u2019s home network. \nThis is illustrated in step 1 in Figure 7.24.\nLet\u2019s now turn our attention to the home agent. In addition to being responsible \nfor interacting with a foreign agent to track the mobile node\u2019s COA, the home agent \nhas another very important function. Its second job is to be on the lookout for arriving \ndatagrams addressed to nodes whose home network is that of the home agent but that \nare currently resident in a foreign network. The home agent intercepts these datagrams \nand then forwards them to a mobile node in a two-step process. The datagram is first \nforwarded to the foreign", "doc_id": "8ee89fc9-d2a3-46e5-9aea-343e87c32a61", "embedding": null, "doc_hash": "8c405da86dcdc93951f63e1ac3b04bd5c23058fdac0b2b36cb49f9e1b953d171", "extra_info": null, "node_info": {"start": 1742736, "end": 1746692}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "1ce3221c-e06a-429a-b1c9-198aa09172f4", "3": "8574f445-4346-4101-aa46-7091eeecdef3"}}, "__type__": "1"}, "8574f445-4346-4101-aa46-7091eeecdef3": {"__data__": {"text": "mobile node is resident in its home network or is \nvisiting a foreign network; mobility is thus completely transparent to the correspond -\nent. Such datagrams are first routed, as usual, to the mobile node\u2019s home network. \nThis is illustrated in step 1 in Figure 7.24.\nLet\u2019s now turn our attention to the home agent. In addition to being responsible \nfor interacting with a foreign agent to track the mobile node\u2019s COA, the home agent \nhas another very important function. Its second job is to be on the lookout for arriving \ndatagrams addressed to nodes whose home network is that of the home agent but that \nare currently resident in a foreign network. The home agent intercepts these datagrams \nand then forwards them to a mobile node in a two-step process. The datagram is first \nforwarded to the foreign agent, using the mobile node\u2019s COA (step 2 in Figure 7.24), \nand then forwarded from the foreign agent to the mobile node (step 3 in Figure 7.24).\nFigure 7.24  \u2666 Indirect routing to a mobile nodeHome\nagentHome network:\n128.119.40/24Visited network:\n79.129.13/24\nMobile node\nPermanent address:\n128.119.40.186 Permanent address:\n128.119.40.186\nForeign\nagentCare-of\naddress:\n79.129.13.2\nWide ar ea\nnetwork\nCorrespondent12\n43\n594     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\nIt is instructive to consider this rerouting in more detail. The home agent will \nneed to address the datagram using the mobile node\u2019s COA, so that the network layer \nwill route the datagram to the foreign network. On the other hand, it is desirable to \nleave the correspondent\u2019s datagram intact, since the application receiving the data -\ngram should be unaware that the datagram was forwarded via the home agent. Both \ngoals can be satisfied by having the home agent encapsulate  the correspondent\u2019s \noriginal complete datagram within a new (larger) datagram. This larger datagram is \naddressed and delivered to the mobile node\u2019s COA. The foreign agent, who \u201cowns\u201d \nthe COA, will receive and decapsulate the datagram\u2014that is, remove the correspond -\nent\u2019s original datagram from within the larger encapsulating datagram and forward \n(step 3 in Figure 7.24) the original datagram to the mobile node. Figure 7.25 shows a \ncorrespondent\u2019s original datagram being sent to the home network, an encapsulated \ndatagram being sent to the foreign agent, and the original datagram being delivered \nto the mobile node. The sharp reader will note that the encapsulation/decapsulation \ndescribed here is identical to the notion of tunneling, discussed in Section 4.3 in the \ncontext of IP multicast and IPv6.\nLet\u2019s next consider how a mobile node sends datagrams to a correspondent. \nThis is quite simple, as the mobile node can address its datagram directly  to the \ncorrespondent (using its own permanent address as the source address, and the \nFigure 7.25  \u2666 Encapsulation and decapsulationHome\nagentPermanent address:\n128.119.40.186 Permanent address:\n128.119.40.186\nForeign\nagent\nCorrespondentdest: 128.119.40.186dest: 79.129.13.2 dest: 128.119.40.186\ndest: 128.119.40.186Care-of address:\n79.129.13.2\n7.5  \u2022  MOBILITY MANAGEMENT: PRINCIPLES      595\ncorrespondent\u2019s address as the destination address). Since the mobile node knows \nthe correspondent\u2019s address, there is no need to route the datagram back through the \nhome agent. This is shown as step 4 in Figure 7.24.\nLet\u2019s summarize our discussion of indirect routing by listing the new network-\nlayer functionality required to support mobility.\n\u2022 A mobile-node\u2013to\u2013foreign-agent protocol.  The mobile node will register with the \nforeign agent when attaching to the foreign network. Similarly, a mobile node \nwill", "doc_id": "8574f445-4346-4101-aa46-7091eeecdef3", "embedding": null, "doc_hash": "4ee8a2d00799e6c3b2e1558d2f1213a1ebc3a70b2498390404cb302a20527f9d", "extra_info": null, "node_info": {"start": 1746705, "end": 1750350}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "8ee89fc9-d2a3-46e5-9aea-343e87c32a61", "3": "a97d9081-5fa9-4e18-85ce-995bba721433"}}, "__type__": "1"}, "a97d9081-5fa9-4e18-85ce-995bba721433": {"__data__": {"text": "79.129.13.2 dest: 128.119.40.186\ndest: 128.119.40.186Care-of address:\n79.129.13.2\n7.5  \u2022  MOBILITY MANAGEMENT: PRINCIPLES      595\ncorrespondent\u2019s address as the destination address). Since the mobile node knows \nthe correspondent\u2019s address, there is no need to route the datagram back through the \nhome agent. This is shown as step 4 in Figure 7.24.\nLet\u2019s summarize our discussion of indirect routing by listing the new network-\nlayer functionality required to support mobility.\n\u2022 A mobile-node\u2013to\u2013foreign-agent protocol.  The mobile node will register with the \nforeign agent when attaching to the foreign network. Similarly, a mobile node \nwill deregister with the foreign agent when it leaves the foreign network.\n\u2022 A foreign-agent\u2013to\u2013home-agent registration protocol.  The foreign agent will \nregister the mobile node\u2019s COA with the home agent. A foreign agent need not \nexplicitly deregister a COA when a mobile node leaves its network, because the \nsubsequent registration of a new COA, when the mobile node moves to a new \nnetwork, will take care of this.\n\u2022 A home-agent datagram encapsulation protocol.  Encapsulation and forward -\ning of the correspondent\u2019s original datagram within a datagram addressed to the \nCOA.\n\u2022 A foreign-agent decapsulation protocol.  Extraction of the correspondent\u2019s origi -\nnal datagram from the encapsulating datagram, and the forwarding of the original \ndatagram to the mobile node.\nThe previous discussion provides all the pieces\u2014foreign agents, the home \nagent, and indirect forwarding\u2014needed for a mobile node to maintain an ongoing \nconnection while moving among networks. As an example of how these pieces fit \ntogether, assume the mobile node is attached to foreign network A, has registered a \nCOA in network A with its home agent, and is receiving datagrams that are being \nindirectly routed through its home agent. The mobile node now moves to foreign \nnetwork B and registers with the foreign agent in network B, which informs the \nhome agent of the mobile node\u2019s new COA. From this point on, the home agent will \nreroute datagrams to foreign network B. As far as a correspondent is concerned, \nmobility is transparent\u2014datagrams are routed via the same home agent both before \nand after the move. As far as the home agent is concerned, there is no disruption in \nthe flow of datagrams\u2014arriving datagrams are first forwarded to foreign network \nA; after the change in COA, datagrams are forwarded to foreign network B. But \nwill the mobile node see an interrupted flow of datagrams as it moves between net -\nworks? As long as the time between the mobile node\u2019s disconnection from network \nA (at which point it can no longer receive datagrams via A) and its attachment to \nnetwork B (at which point it will register a new COA with its home agent) is small, \nfew datagrams will be lost. Recall from Chapter 3 that end-to-end connections can \nsuffer datagram loss due to network congestion. Hence occasional datagram loss \nwithin a connection when a node moves between networks is by no means a cata -\nstrophic problem. If loss-free communication is required, upper-layer mechanisms \n596     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\nwill recover from datagram loss, whether such loss results from network congestion \nor from user mobility.\nAn indirect routing approach is used in the mobile IP standard [RFC 5944], as \ndiscussed in Section 7.6.\nDirect Routing to a Mobile Node\nThe indirect routing approach illustrated in Figure 7.24 suffers from an inef -\nficiency known as the triangle routing problem \u2014datagrams addressed to the \nmobile node must be routed first to the home agent and then to the foreign net -\nwork, even when a much more efficient route exists between the correspondent \nand the mobile node. In the worst case, imagine a mobile user who is visiting the \nforeign", "doc_id": "a97d9081-5fa9-4e18-85ce-995bba721433", "embedding": null, "doc_hash": "5d6f6b88a9bd15cb128ea928a38344e9b74e50d07fd6f0be5f7179479226ec32", "extra_info": null, "node_info": {"start": 1750467, "end": 1754300}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "8574f445-4346-4101-aa46-7091eeecdef3", "3": "510e78ba-26e1-4d52-8ad2-5b1165042a4c"}}, "__type__": "1"}, "510e78ba-26e1-4d52-8ad2-5b1165042a4c": {"__data__": {"text": "is required, upper-layer mechanisms \n596     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\nwill recover from datagram loss, whether such loss results from network congestion \nor from user mobility.\nAn indirect routing approach is used in the mobile IP standard [RFC 5944], as \ndiscussed in Section 7.6.\nDirect Routing to a Mobile Node\nThe indirect routing approach illustrated in Figure 7.24 suffers from an inef -\nficiency known as the triangle routing problem \u2014datagrams addressed to the \nmobile node must be routed first to the home agent and then to the foreign net -\nwork, even when a much more efficient route exists between the correspondent \nand the mobile node. In the worst case, imagine a mobile user who is visiting the \nforeign network of a colleague. The two are sitting side by side and exchanging \ndata over the network. Datagrams from the correspondent (in this case the col -\nleague of the visitor) are routed to the mobile user\u2019s home agent and then back \nagain to the foreign network!\nDirect routing  overcomes the inefficiency of triangle routing, but does so at \nthe cost of additional complexity. In the direct routing approach, a correspondent \nagent  in the correspondent\u2019s network first learns the COA of the mobile node. This \ncan be done by having the correspondent agent query the home agent, assuming that \n(as in the case of indirect routing) the mobile node has an up-to-date value for its \nCOA registered with its home agent. It is also possible for the correspondent itself to \nperform the function of the correspondent agent, just as a mobile node could perform \nthe function of the foreign agent. This is shown as steps 1 and 2 in Figure 7.26. The \ncorrespondent agent then tunnels datagrams directly to the mobile node\u2019s COA, in \na manner analogous to the tunneling performed by the home agent, steps 3 and 4 in \nFigure 7.26.\nWhile direct routing overcomes the triangle routing problem, it introduces two \nimportant additional challenges:\n\u2022 A mobile-user location protocol  is needed for the correspondent agent to query \nthe home agent to obtain the mobile node\u2019s COA (steps 1 and 2 in Figure 7.26).\n\u2022 When the mobile node moves from one foreign network to another, how will data \nnow be forwarded to the new foreign network? In the case of indirect routing, this \nproblem was easily solved by updating the COA maintained by the home agent. \nHowever, with direct routing, the home agent is queried for the COA by the cor -\nrespondent agent only once, at the beginning of the session. Thus, updating the \nCOA at the home agent, while necessary, will not be enough to solve the problem \nof routing data to the mobile node\u2019s new foreign network.\nOne solution would be to create a new protocol to notify the correspondent of \nthe changing COA. An alternate solution, and one that we\u2019ll see adopted in practice \n7.5  \u2022  MOBILITY MANAGEMENT: PRINCIPLES      597\nin GSM networks, works as follows. Suppose data is currently being forwarded to \nthe mobile node in the foreign network where the mobile node was located when \nthe session first started (step 1 in Figure 7.27). We\u2019ll identify the foreign agent  \nin that foreign network where the mobile node was first found as the anchor \n foreign agent . When the mobile node moves to a new foreign network (step 2 in \nFigure 7. 27), the mobile node registers with the new foreign agent (step 3), and the \nnew foreign agent provides the anchor foreign agent with the mobile node\u2019s new \nCOA (step 4). When the anchor foreign agent receives an encapsulated datagram \nfor a departed mobile node, it can then re-encapsulate the datagram and forward \nit to the mobile node (step 5) using the new COA. If the mobile node later moves \nyet again to a new foreign network, the foreign agent in that new visited network \nwould then contact the anchor foreign agent in order to set up forwarding to this \nnew foreign network.Figure 7.26  \u2666 Direct routing to", "doc_id": "510e78ba-26e1-4d52-8ad2-5b1165042a4c", "embedding": null, "doc_hash": "4520fdfce888e4aeaefb4bae3cf0f5cecb5ebcd22f8d999fb7bc6ab1378f8b47", "extra_info": null, "node_info": {"start": 1754237, "end": 1758162}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "a97d9081-5fa9-4e18-85ce-995bba721433", "3": "2db66b8f-2001-42e1-9b7c-1ca86d068deb"}}, "__type__": "1"}, "2db66b8f-2001-42e1-9b7c-1ca86d068deb": {"__data__": {"text": "identify the foreign agent  \nin that foreign network where the mobile node was first found as the anchor \n foreign agent . When the mobile node moves to a new foreign network (step 2 in \nFigure 7. 27), the mobile node registers with the new foreign agent (step 3), and the \nnew foreign agent provides the anchor foreign agent with the mobile node\u2019s new \nCOA (step 4). When the anchor foreign agent receives an encapsulated datagram \nfor a departed mobile node, it can then re-encapsulate the datagram and forward \nit to the mobile node (step 5) using the new COA. If the mobile node later moves \nyet again to a new foreign network, the foreign agent in that new visited network \nwould then contact the anchor foreign agent in order to set up forwarding to this \nnew foreign network.Figure 7.26  \u2666 Direct routing to a mobile userHome\nagentHome network:\n128.119.40/24Visited network:\n79.129.13/24\nMobile node\nPermanent address:\n128.119.40.186\nKey:Permanent address:\n128.119.40.186\nForeign\nagentCare-of address:\n79.129.13.2\nWide ar ea\nnetwork\nCorrespondent\nContr ol messagesCorrespondent\nagent123\nData \ufb02ow4\n598     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\nFigure 7.27  \u2666 Mobile transfer between networks with direct routingHome\nagentHome network:Foreign network\nbeing visited at\nsession start:\nNew for eign\nnetwork:Anchor\nforeign\nagent\nNew foreign agentWide ar ea\nnetwork\nCorrespondentCorrespondent\nagent1\n42\n35\n7.6 Mobile IP\nThe Internet architecture and protocols for supporting mobility, collectively known as \nmobile IP, are defined primarily in RFC 5944 for IPv4. Mobile IP is a flexible standard, \nsupporting many different modes of operation (for example, operation with or without \na foreign agent), multiple ways for agents and mobile nodes to discover each other, use \nof single or multiple COAs, and multiple forms of encapsulation. As such, mobile IP is \na complex standard, and would require an entire book to describe in detail; indeed one \nsuch book is [Perkins 1998b]. Our modest goal here is to provide an overview of the most \nimportant aspects of mobile IP and to illustrate its use in a few common-case scenarios.\nThe mobile IP architecture contains many of the elements we have considered \nabove, including the concepts of home agents, foreign agents, care-of addresses, and \nencapsulation/decapsulation. The current standard [RFC 5944] specifies the use of \nindirect routing to the mobile node.\nThe mobile IP standard consists of three main pieces:\n\u2022 Agent discovery.  Mobile IP defines the protocols used by a home or foreign agent \nto advertise its services to mobile nodes, and protocols for mobile nodes to solicit \nthe services of a foreign or home agent.\n7.6  \u2022  MOBILE IP      599\n\u2022 Registration with the home agent.  Mobile IP defines the protocols used by the \nmobile node and/or foreign agent to register and deregister COAs with a mobile \nnode\u2019s home agent.\n\u2022 Indirect routing of datagrams.  The standard also defines the manner in which \ndatagrams are forwarded to mobile nodes by a home agent, including rules for \nforwarding datagrams, rules for handling error conditions, and several forms of \nencapsulation [RFC 2003, RFC 2004].\nSecurity considerations are prominent throughout the mobile IP standard. \nFor example, authentication of a mobile node is clearly needed to ensure that a \n malicious user does not register a bogus care-of address with a home agent, which \ncould cause all datagrams addressed to an IP address to be redirected to the mali -\ncious user. Mobile IP achieves security using many of the mechanisms that we \nwill examine in Chapter 8, so we will not address security considerations in our \ndiscussion below.\nAgent Discovery\nA mobile IP node arriving to a new network, whether attaching to a foreign network \nor returning to its home network, must learn the identity of the corresponding for -\neign or", "doc_id": "2db66b8f-2001-42e1-9b7c-1ca86d068deb", "embedding": null, "doc_hash": "38b3acc61efff6521f4b1b4eb958cb7d5b6eaba6eda205192188dac3980f5114", "extra_info": null, "node_info": {"start": 1758114, "end": 1761976}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "510e78ba-26e1-4d52-8ad2-5b1165042a4c", "3": "cba47a6d-4142-4f18-b167-8688f2c7150e"}}, "__type__": "1"}, "cba47a6d-4142-4f18-b167-8688f2c7150e": {"__data__": {"text": "rules for \nforwarding datagrams, rules for handling error conditions, and several forms of \nencapsulation [RFC 2003, RFC 2004].\nSecurity considerations are prominent throughout the mobile IP standard. \nFor example, authentication of a mobile node is clearly needed to ensure that a \n malicious user does not register a bogus care-of address with a home agent, which \ncould cause all datagrams addressed to an IP address to be redirected to the mali -\ncious user. Mobile IP achieves security using many of the mechanisms that we \nwill examine in Chapter 8, so we will not address security considerations in our \ndiscussion below.\nAgent Discovery\nA mobile IP node arriving to a new network, whether attaching to a foreign network \nor returning to its home network, must learn the identity of the corresponding for -\neign or home agent. Indeed it is the discovery of a new foreign agent, with a new \nnetwork address, that allows the network layer in a mobile node to learn that it has \nmoved into a new foreign network. This process is known as agent discovery . Agent \ndiscovery can be accomplished in one of two ways: via agent advertisement or via \nagent solicitation.\nWith agent advertisement , a foreign or home agent advertises its services using \nan extension to the existing router discovery protocol [RFC 1256]. The agent peri -\nodically broadcasts an ICMP message with a type field of 9 (router discovery) on all \nlinks to which it is connected. The router discovery message contains the IP address \nof the router (that is, the agent), thus allowing a mobile node to learn the agent\u2019s IP \naddress. The router discovery message also contains a mobility agent advertisement \nextension that contains additional information needed by the mobile node. Among \nthe more important fields in the extension are the following:\n\u2022 Home agent bit (H).  Indicates that the agent is a home agent for the network in \nwhich it resides.\n\u2022 Foreign agent bit (F).  Indicates that the agent is a foreign agent for the network \nin which it resides.\n\u2022 Registration required bit (R).  Indicates that a mobile user in this network must  \nregister with a foreign agent. In particular, a mobile user cannot obtain a care-of \naddress in the foreign network (for example, using DHCP) and assume the func -\ntionality of the foreign agent for itself, without registering with the foreign agent.\n600     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\n\u2022 M, G encapsulation bits.  Indicate whether a form of encapsulation other than IP-\nin-IP encapsulation will be used.\n\u2022 Care-of address (COA) fields.  A list of one or more care-of addresses provided \nby the foreign agent. In our example below, the COA will be associated with the \nforeign agent, who will receive datagrams sent to the COA and then forward them \nto the appropriate mobile node. The mobile user will select one of these addresses \nas its COA when registering with its home agent.\nFigure 7.28 illustrates some of the key fields in the agent advertisement message.\nWith agent solicitation , a mobile node wanting to learn about agents without \nwaiting to receive an agent advertisement can broadcast an agent solicitation mes -\nsage, which is simply an ICMP message with type value 10. An agent receiving the \nsolicitation will unicast an agent advertisement directly to the mobile node, which \ncan then proceed as if it had received an unsolicited advertisement.\nRegistration with the Home Agent\nOnce a mobile IP node has received a COA, that address must be registered with the \nhome agent. This can be done either via the foreign agent (who then registers the Type = 9 Code = 0\nType = 16 Length Sequence number\nRegistration li fetime ReservedRBHFMGrT\nbitsChecksum\nStandard\nICMP \ufb01elds08 16 24\nRouter address\n0 or more care-of addressesMobility agent\nadvertisement\nextension\nFigure 7.28  \u2666  ICMP router discovery message with mobility agent \n advertisement extension\n7.6  \u2022  MOBILE IP      601\nCOA with the home agent) or directly by the mobile IP node itself. We consider the \nformer case below. Four steps are involved.\n 1. Following the", "doc_id": "cba47a6d-4142-4f18-b167-8688f2c7150e", "embedding": null, "doc_hash": "15ae77b3a358e1adad719403dc1ecdc0542b85be1ab5b217703fdd1820a366b8", "extra_info": null, "node_info": {"start": 1761954, "end": 1766032}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "2db66b8f-2001-42e1-9b7c-1ca86d068deb", "3": "cdecce45-df80-4933-ba1b-865bd23a1df6"}}, "__type__": "1"}, "cdecce45-df80-4933-ba1b-865bd23a1df6": {"__data__": {"text": "then proceed as if it had received an unsolicited advertisement.\nRegistration with the Home Agent\nOnce a mobile IP node has received a COA, that address must be registered with the \nhome agent. This can be done either via the foreign agent (who then registers the Type = 9 Code = 0\nType = 16 Length Sequence number\nRegistration li fetime ReservedRBHFMGrT\nbitsChecksum\nStandard\nICMP \ufb01elds08 16 24\nRouter address\n0 or more care-of addressesMobility agent\nadvertisement\nextension\nFigure 7.28  \u2666  ICMP router discovery message with mobility agent \n advertisement extension\n7.6  \u2022  MOBILE IP      601\nCOA with the home agent) or directly by the mobile IP node itself. We consider the \nformer case below. Four steps are involved.\n 1. Following the receipt of a foreign agent advertisement, a mobile node sends a \nmobile IP registration message to the foreign agent. The registration message is \ncarried within a UDP datagram and sent to port 434. The registration message \ncarries a COA advertised by the foreign agent, the address of the home agent \n(HA), the permanent address of the mobile node (MA), the requested life-\ntime of the registration, and a 64-bit registration identification. The requested \nregistration lifetime is the number of seconds that the registration is to be \nvalid. If the registration is not renewed at the home agent within the specified \nlifetime, the registration will become invalid. The registration identifier acts \nlike a sequence number and serves to match a received registration reply with a \nregistration request, as discussed below.\n 2. The foreign agent receives the registration message and records the mobile \nnode\u2019s permanent IP address. The foreign agent now knows that it should be \nlooking for datagrams containing an encapsulated datagram whose destination \naddress matches the permanent address of the mobile node. The foreign agent \nthen sends a mobile IP registration message (again, within a UDP datagram) \nto port 434 of the home agent. The message contains the COA, HA, MA, \nencapsulation format requested, requested registration lifetime, and registration \nidentification.\n 3. The home agent receives the registration request and checks for authentic-\nity and correctness. The home agent binds the mobile node\u2019s permanent IP \naddress with the COA; in the future, datagrams arriving at the home agent \nand addressed to the mobile node will now be encapsulated and tunneled to \nthe COA. The home agent sends a mobile IP registration reply containing the \nHA, MA, actual registration lifetime, and the registration identification of the \nrequest that is being satisfied with this reply.\n 4. The foreign agent receives the registration reply and then forwards it to the \nmobile node.\nAt this point, registration is complete, and the mobile node can receive data -\ngrams sent to its permanent address. Figure 7.29 illustrates these steps. Note that \nthe home agent specifies a lifetime that is smaller than the lifetime requested by the \nmobile node.\nA foreign agent need not explicitly deregister a COA when a mobile node \nleaves its network. This will occur automatically, when the mobile node moves to a \nnew network (whether another foreign network or its home network) and registers \na new COA.\nThe mobile IP standard allows many additional scenarios and capabilities in \naddition to those described previously. The interested reader should consult [Perkins \n1998b; RFC 5944].\n602     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\n7.7 Managing Mobility in Cellular Networks\nHaving examined how mobility is managed in IP networks, let\u2019s now turn our \nattention to networks with an even longer history of supporting mobility\u2014cellular \ntelephony networks. Whereas we focused on the first-hop wireless link in cellular  Figure 7.29  \u2666 Agent advertisement and mobile IP registrationHome agent\nHA: 128.119.40.7Mobile agent\nMA: 128.119.40.186Visited network:\n79.129.13/24\nICMP agent adv .\nCOA: 79.129.13.2\n. .", "doc_id": "cdecce45-df80-4933-ba1b-865bd23a1df6", "embedding": null, "doc_hash": "7ea2013b92cfda0ca0ff29a32a4210d02fe24d80f02402cf7179cdf4c5128325", "extra_info": null, "node_info": {"start": 1766100, "end": 1770051}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "cba47a6d-4142-4f18-b167-8688f2c7150e", "3": "0989dec8-684d-44b6-afd5-0e0c42e9fa47"}}, "__type__": "1"}, "0989dec8-684d-44b6-afd5-0e0c42e9fa47": {"__data__": {"text": "in \naddition to those described previously. The interested reader should consult [Perkins \n1998b; RFC 5944].\n602     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\n7.7 Managing Mobility in Cellular Networks\nHaving examined how mobility is managed in IP networks, let\u2019s now turn our \nattention to networks with an even longer history of supporting mobility\u2014cellular \ntelephony networks. Whereas we focused on the first-hop wireless link in cellular  Figure 7.29  \u2666 Agent advertisement and mobile IP registrationHome agent\nHA: 128.119.40.7Mobile agent\nMA: 128.119.40.186Visited network:\n79.129.13/24\nICMP agent adv .\nCOA: 79.129.13.2\n. . .\nCOA: 79.129.13.2\nHA:128.119.40.7\nMA: 128.119.40.186\nLifetime: 9999\nidenti \ufb01cation: 714\n. . .Registration req.\nCOA: 79.129.13.2\nHA:128.119.40.7\nMA: 128.119.40.186\nLifetime: 9999\nidenti \ufb01cation: 714\nencapsulation format\n. . .Registration req.\nTime Time TimeHA: 128.119.40.7\nMA: 128.119.40.186\nLifetime: 4999\nidenti \ufb01cation: 714\nencapsulation format\n. . .Registration reply\nHA: 128.119.40.7\nMA: 128.119.40.186\nLifetime: 4999\nidenti \ufb01cation: 714\n. . .Registration replyForeign agent\nCOA: 79.129.13.2\n7.7  \u2022  MANAGING MOBILITY IN CELLULAR NETWORKS      603\nnetworks in Section 7.4, we\u2019ll focus here on mobility, using the GSM cellular net -\nwork [Goodman 1997; Mouly 1992; Scourias 2012; Kaaranen 2001; Korhonen 2003; \nTurner 2012] as our case study, since it is a mature and widely deployed technology. \nMobility in 3G and 4G networks is similar in principle to that used in GSM. As in the \ncase of mobile IP, we\u2019ll see that a number of the fundamental principles we identified \nin Section 7.5 are embodied in GSM\u2019s network architecture.\nLike mobile IP, GSM adopts an indirect routing approach (see Section 7.5.2), \nfirst routing the correspondent\u2019s call to the mobile user\u2019s home network and \nfrom there to the visited network. In GSM terminology, the mobile users\u2019s home \nnetwork is referred to as the mobile user\u2019s home public land mobile network \n(home PLMN) . Since the PLMN acronym is a bit of a mouthful, and mindful of \nour quest to avoid an alphabet soup of acronyms, we\u2019ll refer to the GSM home \nPLMN simply as the home network . The home network is the cellular provider \nwith which the mobile user has a subscription (i.e., the provider that bills the \nuser for monthly cellular service). The visited PLMN, which we\u2019ll refer to sim -\nply as the visited network , is the network in which the mobile user is currently \nresiding.\nAs in the case of mobile IP, the responsibilities of the home and visited networks \nare quite different.\n\u2022 The home network maintains a database known as the home location register  \n(HLR ), which contains the permanent cell phone number and subscriber pro -\nfile information for each of its subscribers. Importantly, the HLR also contains \ninformation about the current locations of these subscribers. That is, if a mobile \nuser is currently roaming in another provider\u2019s cellular network, the HLR \ncontains enough information to obtain (via a process we\u2019ll describe shortly) \nan address in the visited network to which a call to the mobile user should \nbe routed. As we\u2019ll see, a special switch in the home network, known as the \nGateway Mobile services Switching Center (GMSC)  is contacted by a corre", "doc_id": "0989dec8-684d-44b6-afd5-0e0c42e9fa47", "embedding": null, "doc_hash": "386ab04d091c3edc81a1c1a2373050ae37cb372163b50daa1a347b71e00e69b6", "extra_info": null, "node_info": {"start": 1770130, "end": 1773406}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "cdecce45-df80-4933-ba1b-865bd23a1df6", "3": "3d569f81-e4ca-4833-8e5a-3403aa3dbb6d"}}, "__type__": "1"}, "3d569f81-e4ca-4833-8e5a-3403aa3dbb6d": {"__data__": {"text": "the case of mobile IP, the responsibilities of the home and visited networks \nare quite different.\n\u2022 The home network maintains a database known as the home location register  \n(HLR ), which contains the permanent cell phone number and subscriber pro -\nfile information for each of its subscribers. Importantly, the HLR also contains \ninformation about the current locations of these subscribers. That is, if a mobile \nuser is currently roaming in another provider\u2019s cellular network, the HLR \ncontains enough information to obtain (via a process we\u2019ll describe shortly) \nan address in the visited network to which a call to the mobile user should \nbe routed. As we\u2019ll see, a special switch in the home network, known as the \nGateway Mobile services Switching Center (GMSC)  is contacted by a corre -\nspondent when a call is placed to a mobile user. Again, in our quest to avoid an \nalphabet soup of acronyms, we\u2019ll refer to the GMSC here by a more descriptive \nterm, home MSC .\n\u2022 The visited network maintains a database known as the visitor location register \n(VLR) . The VLR contains an entry for each mobile user that is currently  in the \nportion of the network served by the VLR. VLR entries thus come and go as \nmobile users enter and leave the network. A VLR is usually co-located with the \nmobile switching center (MSC) that coordinates the setup of a call to and from the \nvisited network.\nIn practice, a provider\u2019s cellular network will serve as a home network for its \nsubscribers and as a visited network for mobile users whose subscription is with a \ndifferent cellular provider.\n604     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\n7.7.1 Routing Calls to a Mobile User\nWe\u2019re now in a position to describe how a call is placed to a mobile GSM user in a \nvisited network. We\u2019ll consider a simple example below; more complex scenarios \nare described in [Mouly 1992]. The steps, as illustrated in Figure 7.30, are as follows:\n 1. The correspondent dials the mobile user\u2019s phone number. This number itself \ndoes not refer to a particular telephone line or location (after all, the phone \nnumber is fixed and the user is mobile!). The leading digits in the number are \nsufficient to globally identify the mobile\u2019s home network. The call is routed \nfrom the correspondent through the PSTN to the home MSC in the mobile\u2019s \nhome network. This is the first leg of the call.\n 2. The home MSC receives the call and interrogates the HLR to determine the \nlocation of the mobile user. In the simplest case, the HLR returns the mobile \nstation roaming number (MSRN) , which we will refer to as the roaming \nnumber . Note that this number is different from the mobile\u2019s permanent phone \nnumber, which is associated with the mobile\u2019s home network. The roaming \nnumber is ephemeral: It is temporarily assigned to a mobile when it enters a \nvisited network. The roaming number serves a role similar to that of the care-of  Figure 7.30  \u2666 Placing a call to a mobile user: Indirect routingMobile\nuser\nVisited\nnetworkHome\nnetwork\nPublic switched \ntelephone\nnetwork1\n3Correspondent\nVLRHLR\n2\n7.7  \u2022  MANAGING MOBILITY IN CELLULAR NETWORKS      605\naddress in mobile IP and, like the COA, is invisible to the correspondent and  \nthe mobile. If HLR does not have the roaming number, it returns the address of \nthe VLR in the visited network. In this case (not shown in Figure 7.30), the home \nMSC will need to query the VLR to obtain the roaming number of the mobile \nnode. But how does the HLR get the roaming number or the VLR address in  \nthe first place? What happens to these values when the mobile user moves to \nanother visited network? We\u2019ll consider these important questions shortly.\n 3. Given the roaming number, the home MSC", "doc_id": "3d569f81-e4ca-4833-8e5a-3403aa3dbb6d", "embedding": null, "doc_hash": "cf938e3b505995bd5564607fb1bc419909cfbc0aeee02f53b7d71111990794c6", "extra_info": null, "node_info": {"start": 1773285, "end": 1777011}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "0989dec8-684d-44b6-afd5-0e0c42e9fa47", "3": "d1dfdf4f-9c9a-473c-8729-55a1bedeb9f3"}}, "__type__": "1"}, "d1dfdf4f-9c9a-473c-8729-55a1bedeb9f3": {"__data__": {"text": " \u2022  MANAGING MOBILITY IN CELLULAR NETWORKS      605\naddress in mobile IP and, like the COA, is invisible to the correspondent and  \nthe mobile. If HLR does not have the roaming number, it returns the address of \nthe VLR in the visited network. In this case (not shown in Figure 7.30), the home \nMSC will need to query the VLR to obtain the roaming number of the mobile \nnode. But how does the HLR get the roaming number or the VLR address in  \nthe first place? What happens to these values when the mobile user moves to \nanother visited network? We\u2019ll consider these important questions shortly.\n 3. Given the roaming number, the home MSC sets up the second leg of the call \nthrough the network to the MSC in the visited network. The call is completed, \nbeing routed from the correspondent to the home MSC, and from there to the \nvisited MSC, and from there to the base station serving the mobile user.\nAn unresolved question in step 2 is how the HLR obtains information about the \nlocation of the mobile user. When a mobile telephone is switched on or enters a part \nof a visited network that is covered by a new VLR, the mobile must register with the \nvisited network. This is done through the exchange of signaling messages between \nthe mobile and the VLR. The visited VLR, in turn, sends a location update request \nmessage to the mobile\u2019s HLR. This message informs the HLR of either the roaming \nnumber at which the mobile can be contacted, or the address of the VLR (which can \nthen later be queried to obtain the mobile number). As part of this exchange, the VLR \nalso obtains subscriber information from the HLR about the mobile and determines \nwhat services (if any) should be accorded the mobile user by the visited network.\n7.7.2 Handoffs in GSM\nA handoff  occurs when a mobile station changes its association from one base sta -\ntion to another during a call. As shown in Figure 7.31, a mobile\u2019s call is initially \n(before handoff) routed to the mobile through one base station (which we\u2019ll refer to \nas the old base station), and after handoff is routed to the mobile through another base \nFigure 7.31  \u2666  Handoff scenario between base stations with a common MSCOld BS New BSOld\nroutingNew\nroutingVLR\n606     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\nstation (which we\u2019ll refer to as the new base station). Note that a handoff between \nbase stations results not only in the mobile transmitting/receiving to/from a new base \nstation, but also in the rerouting of the ongoing call from a switching point within \nthe network to the new base station. Let\u2019s initially assume that the old and new base \nstations share the same MSC, and that the rerouting occurs at this MSC.\nThere may be several reasons for handoff to occur, including (1) the signal \nbetween the current base station and the mobile may have deteriorated to such an \nextent that the call is in danger of being dropped, and (2) a cell may have become \noverloaded, handling a large number of calls. This congestion may be alleviated by \nhanding off mobiles to less congested nearby cells.\nWhile it is associated with a base station, a mobile periodically measures the \nstrength of a beacon signal from its current base station as well as beacon signals \nfrom nearby base stations that it can \u201chear.\u201d These measurements are reported once or \ntwice a second to the mobile\u2019s current base station. Handoff in GSM is initiated by the \nold base station based on these measurements, the current loads of mobiles in nearby \ncells, and other factors [Mouly 1992]. The GSM standard does not specify the specific \nalgorithm to be used by a base station to determine whether or not to perform handoff.\nFigure 7. 32 illustrates the steps involved when a base station does decide to hand \noff a mobile user:\n 1. The old base station (BS) informs the visited MSC that a", "doc_id": "d1dfdf4f-9c9a-473c-8729-55a1bedeb9f3", "embedding": null, "doc_hash": "2ae1e46f209baf4128b0525c86f4e61fb67655367d814f3f57ccb49edf0a27ef", "extra_info": null, "node_info": {"start": 1777163, "end": 1780992}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "3d569f81-e4ca-4833-8e5a-3403aa3dbb6d", "3": "827f83ea-20ad-4cfc-9a81-bd4c4341fffa"}}, "__type__": "1"}, "827f83ea-20ad-4cfc-9a81-bd4c4341fffa": {"__data__": {"text": "cells.\nWhile it is associated with a base station, a mobile periodically measures the \nstrength of a beacon signal from its current base station as well as beacon signals \nfrom nearby base stations that it can \u201chear.\u201d These measurements are reported once or \ntwice a second to the mobile\u2019s current base station. Handoff in GSM is initiated by the \nold base station based on these measurements, the current loads of mobiles in nearby \ncells, and other factors [Mouly 1992]. The GSM standard does not specify the specific \nalgorithm to be used by a base station to determine whether or not to perform handoff.\nFigure 7. 32 illustrates the steps involved when a base station does decide to hand \noff a mobile user:\n 1. The old base station (BS) informs the visited MSC that a handoff is to be per -\nformed and the BS (or possible set of BSs) to which the mobile is to be handed off.\n 2. The visited MSC initiates path setup to the new BS, allocating the resources \nneeded to carry the rerouted call, and signaling the new BS that a handoff is \nabout to occur.\n 3. The new BS allocates and activates a radio channel for use by the mobile.\n 4. The new BS signals back to the visited MSC and the old BS that the visited-\nMSC-to-new-BS path has been established and that the mobile should be \nFigure 7.32  \u2666  Steps in accomplishing a handoff between base stations \nwith a common MSCOld\nBSNew\nBS1\n57 82\n3\n64VLR\n7.7  \u2022  MANAGING MOBILITY IN CELLULAR NETWORKS      607\ninformed of the impending handoff. The new BS provides all of the informa-\ntion that the mobile will need to associate with the new BS.\n 5. The mobile is informed that it should perform a handoff. Note that up until this \npoint, the mobile has been blissfully unaware that the network has been laying \nthe groundwork (e.g., allocating a channel in the new BS and allocating a path \nfrom the visited MSC to the new BS) for a handoff.\n 6. The mobile and the new BS exchange one or more messages to fully activate \nthe new channel in the new BS.\n 7. The mobile sends a handoff complete message to the new BS, which is for-\nwarded up to the visited MSC. The visited MSC then reroutes the ongoing call \nto the mobile via the new BS.\n 8. The resources allocated along the path to the old BS are then released.\nLet\u2019s conclude our discussion of handoff by considering what happens when the \nmobile moves to a BS that is associated with a different  MSC than the old BS, and what \nhappens when this inter-MSC handoff occurs more than once. As shown in Figure 7.33, \nGSM defines the notion of an anchor MSC . The anchor MSC is the MSC visited by \nthe mobile when a call first begins; the anchor MSC thus remains unchanged during \nthe call. Throughout the call\u2019s duration and regardless of the number of inter-MSC \nFigure 7.33  \u2666 Rerouting via the anchor MSCHome networkCorrespondent\na.  Before handof fAnchor\nMSC\nPSTN\nb.  After handof fCorrespondent\nAnchor\nMSC\nPSTNHome network\n608     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\ntransfers performed by the mobile, the call is routed from the home MSC to the anchor \nMSC, and then from the anchor MSC to the visited MSC where the mobile is cur -\nrently located. When a mobile moves from the coverage area of one MSC to another, \nthe ongoing call is rerouted from the anchor MSC to the new visited MSC containing  \nthe new base station. Thus, at all times there are at most three MSCs (the home MSC, \nthe anchor MSC, and the visited MSC) between the correspondent and the mobile. \nFigure 7. 33 illustrates the routing of a call among the MSCs visited by a mobile user.\nRather", "doc_id": "827f83ea-20ad-4cfc-9a81-bd4c4341fffa", "embedding": null, "doc_hash": "5bdd6e454ab88bff2f9b78f281b9e8c087d13adf3351c7a48ca721face75ea3e", "extra_info": null, "node_info": {"start": 1780870, "end": 1784445}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "d1dfdf4f-9c9a-473c-8729-55a1bedeb9f3", "3": "57304954-3365-4190-875b-006d0feb215f"}}, "__type__": "1"}, "57304954-3365-4190-875b-006d0feb215f": {"__data__": {"text": "network\n608     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\ntransfers performed by the mobile, the call is routed from the home MSC to the anchor \nMSC, and then from the anchor MSC to the visited MSC where the mobile is cur -\nrently located. When a mobile moves from the coverage area of one MSC to another, \nthe ongoing call is rerouted from the anchor MSC to the new visited MSC containing  \nthe new base station. Thus, at all times there are at most three MSCs (the home MSC, \nthe anchor MSC, and the visited MSC) between the correspondent and the mobile. \nFigure 7. 33 illustrates the routing of a call among the MSCs visited by a mobile user.\nRather than maintaining a single MSC hop from the anchor MSC to the current \nMSC, an alternative approach would have been to simply chain the MSCs visited by \nthe mobile, having an old MSC forward the ongoing call to the new MSC each time \nthe mobile moves to a new MSC. Such MSC chaining can in fact occur in IS-41 cel -\nlular networks, with an optional path minimization step to remove MSCs between \nthe anchor MSC and the current visited MSC [Lin 2001].\nLet\u2019s wrap up our discussion of GSM mobility management with a compari -\nson of mobility management in GSM and Mobile IP. The comparison in Table 7.2 \nindicates that although IP and cellular networks are fundamentally different in many \nways, they share a surprising number of common functional elements and overall \napproaches in handling mobility.\n7.8 Wireless and Mobility: Impact on  Higher-\nLayer Protocols\nIn this chapter, we\u2019ve seen that wireless networks differ significantly from their \nwired counterparts at both the link layer (as a result of wireless channel charac -\nteristics such as fading, multipath, and hidden terminals) and at the network layer  Table 7.2  \u2666 Commonalities between mobile IP and GSM mobilityGSM element Comment on GSM element Mobile IP element\nHome system Network to which the mobile user's permanent phone number belongs. Home network\nGateway mobile switching center or \nsimply home MSC, Home location \nregister (HLR)Home MSC: point of contact to obtain routable address of mobile user. HLR: \ndatabase in home system containing permanent phone number, profile \ninformation, current location of mobile user, subscription information.Home agent\nVisited system Network other than home system where mobile user is currently residing. Visited network\nVisited mobile services switching  \ncenter, Visitor location register (VLR)Visited MSC: responsible for setting up calls to/from mobile nodes in cells \nassociated with MSC. VLR: temporary database entry in visited system, \ncontaining subscription information for each visiting mobile user.Foreign agent\nMobile station roaming number \n(MSRN) or simply roaming numberRoutable address for telephone call segment between home MSC and visited \nMSC, visible to neither the mobile nor the correspondent.Care-of address\n7.8  \u2022  WIRELESS AND MOBILITY: IMPACT ON  HIGHER-LAYER PROTOCOLS      609\n(as a result of mobile users who change their points of attachment to the network). \nBut are there important differences at the transport and application layers? It\u2019s tempt -\ning to think that these differences will be minor, since the network layer provides the \nsame best-effort delivery service model to upper layers in both wired and wireless \nnetworks. Similarly, if protocols such as TCP or UDP are used to provide transport-\nlayer services to applications in both wired and wireless networks, then the applica -\ntion layer should remain unchanged as well. In one sense our intuition is right\u2014TCP \nand UDP can (and do) operate in networks with wireless links. On the other hand, \ntransport protocols in general, and TCP in particular, can sometimes have very dif -\nferent performance in wired and wireless networks, and it is here, in terms of perfor -\nmance, that differences are", "doc_id": "57304954-3365-4190-875b-006d0feb215f", "embedding": null, "doc_hash": "cdb8ae14dbeb2c5227bb0d7280c954da42bc6764c42dd63408d1e25df7aff88e", "extra_info": null, "node_info": {"start": 1784552, "end": 1788413}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "827f83ea-20ad-4cfc-9a81-bd4c4341fffa", "3": "2530d9ae-66e9-4cc9-a153-ba289adee82b"}}, "__type__": "1"}, "2530d9ae-66e9-4cc9-a153-ba289adee82b": {"__data__": {"text": "and application layers? It\u2019s tempt -\ning to think that these differences will be minor, since the network layer provides the \nsame best-effort delivery service model to upper layers in both wired and wireless \nnetworks. Similarly, if protocols such as TCP or UDP are used to provide transport-\nlayer services to applications in both wired and wireless networks, then the applica -\ntion layer should remain unchanged as well. In one sense our intuition is right\u2014TCP \nand UDP can (and do) operate in networks with wireless links. On the other hand, \ntransport protocols in general, and TCP in particular, can sometimes have very dif -\nferent performance in wired and wireless networks, and it is here, in terms of perfor -\nmance, that differences are manifested. Let\u2019s see why.\nRecall that TCP retransmits a segment that is either lost or corrupted on the path \nbetween sender and receiver. In the case of mobile users, loss can result from either \nnetwork congestion (router buffer overflow) or from handoff (e.g., from delays in \nrerouting segments to a mobile\u2019s new point of attachment to the network). In all \ncases, TCP\u2019s receiver-to-sender ACK indicates only that a segment was not received \nintact; the sender is unaware of whether the segment was lost due to congestion, \nduring handoff, or due to detected bit errors. In all cases, the sender\u2019s response is \nthe same\u2014to retransmit the segment. TCP\u2019s congestion-control response is also the \nsame in all cases\u2014TCP decreases its congestion window, as discussed in Section \n3.7. By unconditionally decreasing its congestion window, TCP implicitly assumes \nthat segment loss results from congestion rather than corruption or handoff. We saw \nin Section 7.2 that bit errors are much more common in wireless networks than in \nwired networks. When such bit errors occur or when handoff loss occurs, there\u2019s \nreally no reason for the TCP sender to decrease its congestion window (and thus \ndecrease its sending rate). Indeed, it may well be the case that router buffers are \nempty and packets are flowing along the end-to-end path unimpeded by congestion.\nResearchers realized in the early to mid 1990s that given high bit error rates on \nwireless links and the possibility of handoff loss, TCP\u2019s congestion-control response \ncould be problematic in a wireless setting. Three broad classes of approaches are \npossible for dealing with this problem:\n\u2022 Local recovery.  Local recovery protocols recover from bit errors when and where \n(e.g., at the wireless link) they occur, e.g., the 802.11 ARQ protocol we studied \nin Section 7.3, or more sophisticated approaches that use both ARQ and FEC \n[Ayanoglu 1995].\n\u2022 TCP sender awareness of wireless links.  In the local recovery approaches, the \nTCP sender is blissfully unaware that its segments are traversing a wireless link. \nAn alternative approach is for the TCP sender and receiver to be aware of the \nexistence of a wireless link, to distinguish between congestive losses occurring \nin the wired network and corruption/loss occurring at the wireless link, and to \ninvoke congestion control only in response to congestive wired-network losses. \n[Balakrishnan 1997] investigates various types of TCP, assuming that end  systems \n610     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\ncan make this distinction. [Liu 2003] investigates techniques for distinguishing \nbetween losses on the wired and wireless segments of an end-to-end path.\n\u2022 Split-connection approaches.  In a split-connection approach [Bakre 1995], the \nend-to-end connection between the mobile user and the other end point is broken \ninto two transport-layer connections: one from the mobile host to the wireless \naccess point, and one from the wireless access point", "doc_id": "2530d9ae-66e9-4cc9-a153-ba289adee82b", "embedding": null, "doc_hash": "f1b520009e0ed44258bb949f8a2bfe486938045ec26c9c829a824a92ab69cdc9", "extra_info": null, "node_info": {"start": 1788320, "end": 1792053}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "57304954-3365-4190-875b-006d0feb215f", "3": "9959f5e9-09e5-4f6f-b79c-d0ae76440c36"}}, "__type__": "1"}, "9959f5e9-09e5-4f6f-b79c-d0ae76440c36": {"__data__": {"text": "wired network and corruption/loss occurring at the wireless link, and to \ninvoke congestion control only in response to congestive wired-network losses. \n[Balakrishnan 1997] investigates various types of TCP, assuming that end  systems \n610     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\ncan make this distinction. [Liu 2003] investigates techniques for distinguishing \nbetween losses on the wired and wireless segments of an end-to-end path.\n\u2022 Split-connection approaches.  In a split-connection approach [Bakre 1995], the \nend-to-end connection between the mobile user and the other end point is broken \ninto two transport-layer connections: one from the mobile host to the wireless \naccess point, and one from the wireless access point to the other communication \nend point (which we\u2019ll assume here is a wired host). The end-to-end connection \nis thus formed by the concatenation of a wireless part and a wired part. The trans -\nport layer over the wireless segment can be a standard TCP connection [Bakre \n1995], or a specially tailored error recovery protocol on top of UDP. [Yavatkar \n1994] investigates the use of a transport-layer selective repeat protocol over the \nwireless connection. Measurements reported in [Wei 2006] indicate that split \nTCP connections are widely used in cellular data networks, and that significant \nimprovements can indeed be made through the use of split TCP connections.\nOur treatment of TCP over wireless links has been necessarily brief here. \n In-depth surveys of TCP challenges and solutions in wireless networks can be found \nin [Hanabali 2005; Leung 2006]. We encourage you to consult the references for \ndetails of this ongoing area of research.\nHaving considered transport-layer protocols, let us next consider the effect of \nwireless and mobility on application-layer protocols. Here, an important consideration \nis that wireless links often have relatively low bandwidths, as we saw in Figure 7.2. As \na result, applications that operate over wireless links, particularly over cellular wireless \nlinks, must treat bandwidth as a scarce commodity. For example, a Web server serving \ncontent to a Web browser executing on a 4G phone will likely not be able to provide the \nsame image-rich content that it gives to a browser operating over a wired connection. \nAlthough wireless links do provide challenges at the application layer, the mobility they \nenable also makes possible a rich set of location-aware and context-aware applications \n[Chen 2000; Baldauf 2007]. More generally, wireless and mobile networks will play \na key role in realizing the ubiquitous computing environments of the future [Weiser \n1991]. It\u2019s fair to say that we\u2019ve only seen the tip of the iceberg when it comes to the \nimpact of wireless and mobile networks on networked applications and their protocols!\n7.9 Summary\nWireless and mobile networks have revolutionized telephony and are having an \nincreasingly profound impact in the world of computer networks as well. With their \nanytime, anywhere, untethered access into the global network infrastructure, they are \nnot only making network access more ubiquitous, they are also enabling an exciting \nnew set of location-dependent services. Given the growing importance of wireless and \nHOMEWORK PROBLEMS AND QUESTIONS      611\nmobile networks, this chapter has focused on the principles, common link technolo -\ngies, and network architectures for supporting wireless and mobile communication.\nWe began this chapter with an introduction to wireless and mobile networks, \ndrawing an important distinction between the challenges posed by the wireless  nature \nof the communication links in such networks, and by the mobility  that these wireless \nlinks enable. This allowed us to better isolate, identify, and master the key concepts \nin each area. We focused first on wireless communication, considering the char -\nacteristics of a wireless link in Section 7.2. In Sections 7.3 and 7.4, we examined \nthe link-level aspects of the IEEE 802.11", "doc_id": "9959f5e9-09e5-4f6f-b79c-d0ae76440c36", "embedding": null, "doc_hash": "8cc693a5ed446ada0f9dde08ac7280a4cff707741a5cdddda02c864738c1ef69", "extra_info": null, "node_info": {"start": 1792052, "end": 1796067}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "2530d9ae-66e9-4cc9-a153-ba289adee82b", "3": "4b543657-da74-442a-851c-82e9e4c62796"}}, "__type__": "1"}, "4b543657-da74-442a-851c-82e9e4c62796": {"__data__": {"text": "of wireless and \nHOMEWORK PROBLEMS AND QUESTIONS      611\nmobile networks, this chapter has focused on the principles, common link technolo -\ngies, and network architectures for supporting wireless and mobile communication.\nWe began this chapter with an introduction to wireless and mobile networks, \ndrawing an important distinction between the challenges posed by the wireless  nature \nof the communication links in such networks, and by the mobility  that these wireless \nlinks enable. This allowed us to better isolate, identify, and master the key concepts \nin each area. We focused first on wireless communication, considering the char -\nacteristics of a wireless link in Section 7.2. In Sections 7.3 and 7.4, we examined \nthe link-level aspects of the IEEE 802.11 (WiFi) wireless LAN standard, two IEEE \n802.15 personal area networks (Bluetooth and Zigbee), and 3G and 4G cellular Inter -\nnet access. We then turned our attention to the issue of mobility. In Section 7.5, we \nidentified several forms of mobility, with points along this spectrum posing different \nchallenges and admitting different solutions. We considered the problems of locating \nand routing to a mobile user, as well as approaches for handing off the mobile user \nwho dynamically moves from one point of attachment to the network to another. We \nexamined how these issues were addressed in the mobile IP standard and in GSM, in \nSections 7. 6 and 7.7, respectively. Finally, we considered the impact of wireless links \nand mobility on transport-layer protocols and networked applications in  Section 7.8.\nAlthough we have devoted an entire chapter to the study of wireless and mobile \nnetworks, an entire book (or more) would be required to fully explore this exciting \nand rapidly expanding field. We encourage you to delve more deeply into this field \nby consulting the many references provided in this chapter.\nHomework Problems and Questions\nChapter 7 Review Questions\nSECTION 7.1\n R1. What does it mean for a wireless network to be operating in \u201cinfrastructure \nmode\u201d? If the network is not in infrastructure mode, what mode of operation \nis it in, and what is the difference between that mode of operation and infra-\nstructure mode?\n R2. Both MANET and VANET are multi-hop infrastructure-less wireless networks. \nWhat is the difference between them?\nSECTION 7.2\n R3. What are the differences between the following types of wireless channel \nimpairments: path loss, multipath propagation, interference from other sources?\n R4. As a mobile node gets farther and farther away from a base station, what are \ntwo actions that a base station could take to ensure that the loss probability of \na transmitted frame does not increase?\n612     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\nSECTIONS 7.3 AND 7.4\n   R5. Describe the role of the beacon frames in 802.11.\n   R6. An access point periodically sends beacon frames. What are the contents of \nthe beacon frames?\n   R7. Why are acknowledgments used in 802.11 but not in wired Ethernet?\n   R8. What is the difference between passive scanning and active scanning?\n   R9. What are the two main purposes of a CTS frame?\n R10. Suppose the IEEE 802.11 RTS and CTS frames were as long as the standard \nDATA and ACK frames. Would there be any advantage to using the CTS and \nRTS frames? Why or why not?\n R11. Section 7.3.4 discusses 802.11 mobility, in which a wireless station moves \nfrom one BSS to another within the same subnet. When the APs are intercon-\nnected with a switch, an AP may need to send a frame with a spoofed MAC \naddress to get the switch to forward the frame properly. Why?\n R12. What is the difference between Bluetooth and Zigbee in terms of data rate?\n R13. What is meant by a", "doc_id": "4b543657-da74-442a-851c-82e9e4c62796", "embedding": null, "doc_hash": "badc807d197a856be5abc9c0a904d617495726affd3b8ed1e8f64bf118136281", "extra_info": null, "node_info": {"start": 1796049, "end": 1799772}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "9959f5e9-09e5-4f6f-b79c-d0ae76440c36", "3": "f3696eae-796a-4f7d-a45b-a42b13e7c359"}}, "__type__": "1"}, "f3696eae-796a-4f7d-a45b-a42b13e7c359": {"__data__": {"text": "difference between passive scanning and active scanning?\n   R9. What are the two main purposes of a CTS frame?\n R10. Suppose the IEEE 802.11 RTS and CTS frames were as long as the standard \nDATA and ACK frames. Would there be any advantage to using the CTS and \nRTS frames? Why or why not?\n R11. Section 7.3.4 discusses 802.11 mobility, in which a wireless station moves \nfrom one BSS to another within the same subnet. When the APs are intercon-\nnected with a switch, an AP may need to send a frame with a spoofed MAC \naddress to get the switch to forward the frame properly. Why?\n R12. What is the difference between Bluetooth and Zigbee in terms of data rate?\n R13. What is meant by a super frame in the 802.15.4 Zigbee standard?\n R14. What is the role of the \u201ccore network\u201d in the 3G cellular data architecture?\n R15. What is the role of the RNC in the 3G cellular data network architecture? \nWhat role does the RNC play in the cellular voice network?\n R16. What is the role of the eNodeB, MME, P-GW, and S-GW in 4G architecture?\n R17. What are three important differences between the 3G and 4G cellular \n architectures?\nSECTIONS 7.5 AND 7.6\n R18. If a node has a wireless connection to the Internet, does that node have to be \nmobile? Explain. Suppose that a user with a laptop walks around her house \nwith her laptop, and always accesses the Internet through the same access \npoint. Is this user mobile from a network standpoint? Explain.\n R19. What is the difference between a permanent address and a care-of address? \nWho assigns a care-of address?\n R20. Consider a TCP connection going over Mobile IP. True or false: The TCP \nconnection phase between the correspondent and the mobile host goes \nthrough the mobile\u2019s home network, but the data transfer phase is directly \nbetween the correspondent and the mobile host, bypassing the home  \nnetwork.\nSECTION 7.7\n R21. What is the role of a GSM network\u2019s base station controller (BSC)?\nR 22. What is the role of the anchor MSC in GSM networks?\nPROBLEMS      613\nSECTION 7.8\n R23. What are three approaches that can be taken to avoid having a single  wireless \nlink degrade the performance of an end-to-end transport-layer TCP  connection?\nProblems\n P1. Consider the single-sender CDMA example in Figure 7.5. What would be the \nsender\u2019s output (for the 2 data bits shown) if the sender\u2019s CDMA code were \n(1, 1, 21, 1, 1, 21, 21, 1)?\n P2. Consider sender 2 in Figure 7.6. Assume that both the first two bits sent by \nsender 2 are 21. What are the sender\u2019s outputs to the channel (before being \nadded to the signal from sender 1)?\n P3. After selecting the AP with which to associate, a wireless host sends an \nassociation request frame to the AP, and the AP responds with an associa -\ntion response frame. Once associated with an AP, the host will want to join \nthe subnet (in the IP addressing sense of Section 4.4.2) to which the AP \nbelongs. What does the host do next?\n P4. If two CDMA senders have codes (1, 1, 1, 21, 1, 21, 21, 21) and (1, 21, \n1, 1, 1, 1, 1, 1), would the corresponding receivers be able to decode the data \ncorrectly? Justify.\n P5. Suppose there are two ISPs providing WiFi access in a particular caf\u00e9, with \neach ISP operating its own AP and having its own IP address block.\na. Further suppose that by accident, each ISP has configured its AP to oper-\nate over channel 11. Will the 802.11 protocol completely break down in \nthis situation? Discuss what happens when two stations, each", "doc_id": "f3696eae-796a-4f7d-a45b-a42b13e7c359", "embedding": null, "doc_hash": "a5ef956b49aecb4238d64c9cf2f35bef4040a5f2c8e40773bf355d5777477244", "extra_info": null, "node_info": {"start": 1799862, "end": 1803325}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "4b543657-da74-442a-851c-82e9e4c62796", "3": "986effca-f321-4ba2-b241-c9e295095733"}}, "__type__": "1"}, "986effca-f321-4ba2-b241-c9e295095733": {"__data__": {"text": "subnet (in the IP addressing sense of Section 4.4.2) to which the AP \nbelongs. What does the host do next?\n P4. If two CDMA senders have codes (1, 1, 1, 21, 1, 21, 21, 21) and (1, 21, \n1, 1, 1, 1, 1, 1), would the corresponding receivers be able to decode the data \ncorrectly? Justify.\n P5. Suppose there are two ISPs providing WiFi access in a particular caf\u00e9, with \neach ISP operating its own AP and having its own IP address block.\na. Further suppose that by accident, each ISP has configured its AP to oper-\nate over channel 11. Will the 802.11 protocol completely break down in \nthis situation? Discuss what happens when two stations, each associated \nwith a different ISP, attempt to transmit at the same time.\nb. Now suppose that one AP operates over channel 1 and the other over \nchannel 11. How do your answers change?\n P6. In step 4 of the CSMA/CA protocol, a station that successfully transmits a \nframe begins the CSMA/CA protocol for a second frame at step 2, rather than \nat step 1. What rationale might the designers of CSMA/CA have had in mind \nby having such a station not transmit the second frame immediately (if the \nchannel is sensed idle)?\n P7. Suppose an 802.11b station is configured to always reserve the channel with \nthe RTS/CTS sequence. Suppose this station suddenly wants to transmit \n1,000 bytes of data, and all other stations are idle at this time. Assume a \ntransmission rate of 12 Mbps. As a function of SIFS and DIFS, and ignoring \npropagation delay and assuming no bit errors, calculate the time required to \ntransmit the frame and receive the acknowledgment.\n P8. Consider the scenario shown in Figure 7.34, in which there are four wireless \nnodes, A, B, C, and D. The radio coverage of the four nodes is shown via \nthe shaded ovals; all nodes share the same frequency. When A transmits, it \n614     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\ncan only be heard/received by B; when B transmits, both A and C can hear/\nreceive from B; when C transmits, both B and D can hear/receive from C; \nwhen D transmits, only C can hear/receive from D.\n  Suppose now that each node has an infinite supply of messages that it wants \nto send to each of the other nodes. If a message\u2019s destination is not an imme-\ndiate neighbor, then the message must be relayed. For example, if A wants \nto send to D, a message from A must first be sent to B, which then sends \nthe message to C, which then sends the message to D. Time is slotted, with \na message transmission time taking exactly one time slot, e.g., as in slotted \nAloha. During a slot, a node can do one of the following: ( i) send a message, \n(ii) receive a message (if exactly one message is being sent to it), ( iii) remain \nsilent. As always, if a node hears two or more simultaneous transmissions, \na collision occurs and none of the transmitted messages are received suc-\ncessfully. You can assume here that there are no bit-level errors, and thus if \nexactly one message is sent, it will be received correctly by those within the \ntransmission radius of the sender.\na. Suppose now that an omniscient controller (i.e., a controller that knows \nthe state of every node in the network) can command each node to do \nwhatever it (the omniscient controller) wishes, i.e., to send a message, \nto receive a message, or to remain silent. Given this omniscient control-\nler, what is the maximum rate at which a data message can be transferred \nfrom C to A, given that there are no other messages between any other \nsource/destination pairs?\nb. Suppose now that A sends messages to B, and", "doc_id": "986effca-f321-4ba2-b241-c9e295095733", "embedding": null, "doc_hash": "69e601403b5952789bd9a2f297f2f7a185ecc7fa6de408377a19257d8f97a314", "extra_info": null, "node_info": {"start": 1803358, "end": 1806921}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "f3696eae-796a-4f7d-a45b-a42b13e7c359", "3": "98565fbf-1d50-4962-86cf-c24070d9603d"}}, "__type__": "1"}, "98565fbf-1d50-4962-86cf-c24070d9603d": {"__data__": {"text": "and none of the transmitted messages are received suc-\ncessfully. You can assume here that there are no bit-level errors, and thus if \nexactly one message is sent, it will be received correctly by those within the \ntransmission radius of the sender.\na. Suppose now that an omniscient controller (i.e., a controller that knows \nthe state of every node in the network) can command each node to do \nwhatever it (the omniscient controller) wishes, i.e., to send a message, \nto receive a message, or to remain silent. Given this omniscient control-\nler, what is the maximum rate at which a data message can be transferred \nfrom C to A, given that there are no other messages between any other \nsource/destination pairs?\nb. Suppose now that A sends messages to B, and D sends messages to C. \nWhat is the combined maximum rate at which data messages can flow \nfrom A to B and from D to C?\nc. Suppose now that A sends messages to B, and C sends messages to D. \nWhat is the combined maximum rate at which data messages can flow \nfrom A to B and from C to D?\nd. Suppose now that the wireless links are replaced by wired links. Repeat \nquestions (a) through (c) again in this wired scenario.Figure 7.34  \u2666 Scenario for problem P8AB CD\nPROBLEMS      615\ne. Now suppose we are again in the wireless scenario, and that for every data \nmessage sent from source to destination, the destination will send an ACK \nmessage back to the source (e.g., as in TCP). Also suppose that each ACK \nmessage takes up one slot. Repeat questions (a)\u2013(c) above for this scenario.\n P9. Power is a precious resource in mobile devices, and thus the 802.11 standard \nprovides power-management capabilities that allow 802.11 nodes to minimize \nthe amount of time that their sense, transmit, and receive functions and other  \ncircuitry need to be \u201con.\u201d In 802.11, a node is able to explicitly alternate \nbetween sleep and wake states. Explain in brief how a node communicates with \nthe AP to perform power management.\n P10. Consider the following idealized LTE scenario. The downstream channel  \n(see Figure 7.21) is slotted in time, across F frequencies. There are four \nnodes, A, B, C, and D, reachable from the base station at rates of 10 Mbps, \n5 Mbps, 2.5 Mbps, and 1 Mbps, respectively, on the downstream channel. \nThese rates assume that the base station utilizes all time slots available on \nall F frequencies to send to just one station. The base station has an infinite \namount of data to send to each of the nodes, and can send to any one of \nthese four nodes using any of the F frequencies during any time slot in the \n downstream sub-frame.\na. What is the maximum rate at which the base station can send to the nodes, \nassuming it can send to any node it chooses during each time slot? Is your \nsolution fair? Explain and define what you mean by \u201cfair.\u201d\nb. If there is a fairness requirement that each node must receive an equal \namount of data during each one second interval, what is the average \ntransmission rate by the base station (to all nodes) during the downstream \nsub-frame? Explain how you arrived at your answer.\nc. Suppose that the fairness criterion is that any node can receive at most \ntwice as much data as any other node during the sub-frame. What is the \naverage transmission rate by the base station (to all nodes) during the sub-\nframe? Explain how you arrived at your answer.\n P11. In Section 7.5, one proposed solution that allowed mobile users to maintain \ntheir IP addresses as they moved among foreign networks was to have a foreign \nnetwork advertise a highly specific route to the mobile user and use the existing \nrouting infrastructure to propagate this information throughout the network. We \nidentified scalability as one concern. Suppose that when a mobile user moves \nfrom one network to another, the new foreign network advertises a specific route \nto the mobile", "doc_id": "98565fbf-1d50-4962-86cf-c24070d9603d", "embedding": null, "doc_hash": "86e556b8c7d761f1ac1f6761f589283759e876ad75ff5dd42e29218dcbf88a81", "extra_info": null, "node_info": {"start": 1806816, "end": 1810688}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "986effca-f321-4ba2-b241-c9e295095733", "3": "b6e0ff96-78c9-4510-adc0-fc61f5f67c9d"}}, "__type__": "1"}, "b6e0ff96-78c9-4510-adc0-fc61f5f67c9d": {"__data__": {"text": "the downstream \nsub-frame? Explain how you arrived at your answer.\nc. Suppose that the fairness criterion is that any node can receive at most \ntwice as much data as any other node during the sub-frame. What is the \naverage transmission rate by the base station (to all nodes) during the sub-\nframe? Explain how you arrived at your answer.\n P11. In Section 7.5, one proposed solution that allowed mobile users to maintain \ntheir IP addresses as they moved among foreign networks was to have a foreign \nnetwork advertise a highly specific route to the mobile user and use the existing \nrouting infrastructure to propagate this information throughout the network. We \nidentified scalability as one concern. Suppose that when a mobile user moves \nfrom one network to another, the new foreign network advertises a specific route \nto the mobile user, and the old foreign network withdraws its route. Consider \nhow routing information propagates in a distance-vector algorithm (particularly \nfor the case of interdomain routing among networks that span the globe).\na. Will other routers be able to route datagrams immediately to the new for-\neign network as soon as the foreign network begins advertising its route?\n616     CHAPTER 7 \u2002\u2002\u2022 \u2002\u2002 WIRELESS AND MOBILE NETWORKS\nb. Is it possible for different routers to believe that different foreign networks \ncontain the mobile user?\nc. Discuss the timescale over which other routers in the network will eventu-\nally learn the path to the mobile users.\n P12. Suppose the correspondent in Figure 7.23 were mobile. Sketch the additional \nnetwork-layer infrastructure that would be needed to route the datagram from \nthe original mobile user to the (now mobile) correspondent. Show the struc -\nture of the datagram(s) between the original mobile user and the (now mobile) \ncorrespondent, as in Figure 7.24.\n P13. In mobile IP, what effect will mobility have on end-to-end delays of data-\ngrams between the source and destination?\n P14. Consider the chaining example discussed at the end of Section 7.7.2. Suppose \na mobile user visits foreign networks A, B, and C, and that a correspondent \nbegins a connection to the mobile user when it is resident in foreign  network \nA. List the sequence of messages between foreign agents, and between \nforeign agents and the home agent as the mobile user moves from network A \nto network B to network C. Next, suppose chaining is not performed, and the \ncorrespondent (as well as the home agent) must be explicitly notified of the \nchanges in the mobile user\u2019s care-of address. List the sequence of messages \nthat would need to be exchanged in this second scenario.\n P15. Consider two mobile nodes in a foreign network having a foreign agent. Is it \npossible for the two mobile nodes to use the same care-of address in mobile \nIP? Explain your answer.\n P16. In our discussion of how the VLR updated the HLR with information about \nthe mobile\u2019s current location, what are the advantages and disadvantages of \nproviding the MSRN as opposed to the address of the VLR to the HLR?\nWireshark Lab\nAt the Web site for this textbook, www.pearsonglobaleditions.com/kurose, you\u2019ll \nfind a Wireshark lab for this chapter that captures and studies the 802.11 frames \nexchanged between a wireless laptop and an access point.\n617\nPlease describe a few of the most exciting projects you have worked on during your \ncareer. What were the biggest challenges?\nIn the mid-90s at USC and ISI, I had the great fortune to work with the likes of Steve \nDeering, Mark Handley, and Van Jacobson on the design of multicast routing protocols  \n(in particular, PIM). I tried to carry many of the architectural design lessons from multicast \ninto the design of ecological monitoring arrays, where for the first time I really began to \ntake applications and multidisciplinary research seriously. That interest in jointly innovat -\ning in the social and technological space is what interests me so much about my latest area \nof", "doc_id": "b6e0ff96-78c9-4510-adc0-fc61f5f67c9d", "embedding": null, "doc_hash": "a1397a62b80cd37a28396490e1a81d357f986e32bd886b0eddea8e9583cb9500", "extra_info": null, "node_info": {"start": 1810620, "end": 1814590}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "98565fbf-1d50-4962-86cf-c24070d9603d", "3": "674b6b81-e0e4-425f-9e3d-96a66393346e"}}, "__type__": "1"}, "674b6b81-e0e4-425f-9e3d-96a66393346e": {"__data__": {"text": "and studies the 802.11 frames \nexchanged between a wireless laptop and an access point.\n617\nPlease describe a few of the most exciting projects you have worked on during your \ncareer. What were the biggest challenges?\nIn the mid-90s at USC and ISI, I had the great fortune to work with the likes of Steve \nDeering, Mark Handley, and Van Jacobson on the design of multicast routing protocols  \n(in particular, PIM). I tried to carry many of the architectural design lessons from multicast \ninto the design of ecological monitoring arrays, where for the first time I really began to \ntake applications and multidisciplinary research seriously. That interest in jointly innovat -\ning in the social and technological space is what interests me so much about my latest area \nof research, mobile health. The challenges in these projects were as diverse as the problem AN INTERVIEW WITH\u2026\nDeborah Estrin\nDeborah Estrin is a Professor of Computer Science at Cornell Tech \nin New York City and a Professor of Public Health at Weill Cornell \nMedical College. She is founder of the Health Tech Hub  \nat Cornell Tech and co-founder of the non-profit startup Open \nmHealth . She received her Ph.D. (1985) in Computer Science \nfrom M.I.T. and her B.S. (1980) from UC Berkeley. Estrin\u2019s early \nresearch focused on the design of network protocols, including \nmulticast and inter-domain routing. In 2002 Estrin founded the \nNSF-funded Science and Technology Center at UCLA, Center for \nEmbedded Networked Sensing (CENS http://cens.ucla.edu.). \nCENS launched new areas of multi-disciplinary computer systems \nresearch from sensor networks for environmental monitoring, to par -\nticipatory sensing for citizen science. Her current focus is on mobile \nhealth and small data, leveraging the pervasiveness of mobile \ndevices and digital interactions for health and life management, as \ndescribed in her 2013 TEDMED talk. Professor Estrin is an elected \nmember of the American Academy of Arts and Sciences (2007) and \nthe National Academy of Engineering (2009). She is a fellow of \nthe IEEE, ACM, and AAAS. She was selected as the first ACM-W \nAthena Lecturer (2006), awarded the Anita Borg Institute\u2019s Women \nof Vision Award for Innovation (2007), inducted into the WITI hall of \nfame (2008) and awarded Doctor Honoris Causa  from EPFL (2008) \nand Uppsala University (2011).\n618domains, but what they all had in common was the need to keep our eyes open to whether \nwe had the problem definition right as we iterated between design and deployment, proto -\ntype and pilot. None of them were problems that could be solved analytically, with simula -\ntion or even in constructed laboratory experiments. They all challenged our ability to retain \nclean architectures in the presence of messy problems and contexts, and they all called for \nextensive collaboration.\nWhat changes and innovations do you see happening in wireless networks and mobility \nin the future?\nIn a prior edition of this interview I said that I have never put much faith into predicting the \nfuture, but I did go on to speculate that we might see the end of feature phones (i.e., those \nthat are not programmable and are used only for voice and text messaging) as smart phones \nbecome more and more powerful and the primary point of Internet access for many\u2014and \nnow not so many years later that is clearly the case. I also predicted that we would see the \ncontinued proliferation of embedded SIMs by which all sorts of devices have the ability \nto communicate via the cellular network at low data rates. While that has occurred, we see \nmany devices and \u201cInternet of Things\u201d that use embedded WiFi and other lower power, \nshorter range, forms of connectivity to local hubs. I did not anticipate at that time the emer -\ngence of a large consumer wearables market. By the time the next edition is published I \nexpect broad proliferation of personal applications that leverage data from IoT and other \ndigital", "doc_id": "674b6b81-e0e4-425f-9e3d-96a66393346e", "embedding": null, "doc_hash": "0b837adeccb49907f2d783fba6533079da7cdb03c63bfd3613316b5ad902942e", "extra_info": null, "node_info": {"start": 1814648, "end": 1818599}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "b6e0ff96-78c9-4510-adc0-fc61f5f67c9d", "3": "b9f0190d-9315-4b11-906d-2d4b2facfce5"}}, "__type__": "1"}, "b9f0190d-9315-4b11-906d-2d4b2facfce5": {"__data__": {"text": "those \nthat are not programmable and are used only for voice and text messaging) as smart phones \nbecome more and more powerful and the primary point of Internet access for many\u2014and \nnow not so many years later that is clearly the case. I also predicted that we would see the \ncontinued proliferation of embedded SIMs by which all sorts of devices have the ability \nto communicate via the cellular network at low data rates. While that has occurred, we see \nmany devices and \u201cInternet of Things\u201d that use embedded WiFi and other lower power, \nshorter range, forms of connectivity to local hubs. I did not anticipate at that time the emer -\ngence of a large consumer wearables market. By the time the next edition is published I \nexpect broad proliferation of personal applications that leverage data from IoT and other \ndigital traces.\nWhere do you see the future of networking and the Internet?\nAgain I think its useful to look both back and forward. Previously I observed that the efforts \nin named data and software-defined networking would emerge to create a more manageable, \nevolvable, and richer infrastructure and more generally represent moving the role of archi -\ntecture higher up in the stack. In the beginnings of the Internet, architecture was layer 4 and \nbelow, with applications being more siloed/monolithic, sitting on top. Now data and analyt -\nics dominate transport. The adoption of SDN (which I\u2019m really happy to see is featured \nin this 7th edition of this book) has been well beyond what I ever anticipated. However, \nlooking up the stack, our dominant applications increasingly live in walled gardens, whether \nmobile apps or large consumer platforms such as Facebook. As Data Science and Big Data \ntechniques develop, they might help to lure these applications out of their silos because of \nthe value in connecting with other apps and platforms.\n619What people inspired you professionally?\nThere are three people who come to mind. First, Dave Clark, the secret sauce and under-\nsung hero of the Internet community. I was lucky to be around in the early days to see him \nact as the \u201corganizing principle\u201d of the IAB and Internet governance; the priest of rough \nconsensus and running code. Second, Scott Shenker, for his intellectual brilliance, integrity, \nand persistence. I strive for, but rarely attain, his clarity in defining problems and solutions. \nHe is always the first person I e-mail for advice on matters large and small. Third, my sister \nJudy Estrin, who had the creativity and courage to spend her career bringing ideas and con -\ncepts to market. Without the Judys of the world the Internet technologies would never have \ntransformed our lives.\nWhat are your recommendations for students who want careers in computer science  \nand networking?\nFirst, build a strong foundation in your academic work, balanced with any and every real-\nworld work experience you can get. As you look for a working environment, seek opportu -\nnities in problem areas you really care about and with smart teams that you can learn from.\nThis page intentionally left blank\n621Way back in Section 1.6 we described some of the more prevalent and damaging \nclasses of Internet attacks, including malware attacks, denial of service, sniffing, \nsource masquerading, and message modification and deletion. Although we have \nsince learned a tremendous amount about computer networks, we still haven\u2019t exam -\nined how to secure networks from those attacks. Equipped with our newly acquired \nexpertise in computer networking and Internet protocols, we\u2019ll now study in-depth \nsecure communication and, in particular, how computer networks can be defended \nfrom those nasty bad guys.\nLet us introduce Alice and Bob, two people who want to communicate and wish \nto do so \u201csecurely.\u201d This being a networking text, we should remark that Alice and \nBob could be two routers that want to exchange routing tables securely, a client and \nserver that want to establish a secure transport connection, or two e-mail applications \nthat want to exchange secure e-mail\u2014all case studies that we will consider later in \nthis", "doc_id": "b9f0190d-9315-4b11-906d-2d4b2facfce5", "embedding": null, "doc_hash": "62dffd548be59846545e44dc0c50e43cd273293b71fef128afeeb77e22cb9349", "extra_info": null, "node_info": {"start": 1818560, "end": 1822676}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "674b6b81-e0e4-425f-9e3d-96a66393346e", "3": "f1b671fe-efcb-4117-9cbf-edf3468c7aa6"}}, "__type__": "1"}, "f1b671fe-efcb-4117-9cbf-edf3468c7aa6": {"__data__": {"text": "learned a tremendous amount about computer networks, we still haven\u2019t exam -\nined how to secure networks from those attacks. Equipped with our newly acquired \nexpertise in computer networking and Internet protocols, we\u2019ll now study in-depth \nsecure communication and, in particular, how computer networks can be defended \nfrom those nasty bad guys.\nLet us introduce Alice and Bob, two people who want to communicate and wish \nto do so \u201csecurely.\u201d This being a networking text, we should remark that Alice and \nBob could be two routers that want to exchange routing tables securely, a client and \nserver that want to establish a secure transport connection, or two e-mail applications \nthat want to exchange secure e-mail\u2014all case studies that we will consider later in \nthis chapter. Alice and Bob are well-known fixtures in the security community, per -\nhaps because their names are more fun than a generic entity named \u201cA\u201d that wants \nto communicate securely with a generic entity named \u201cB.\u201d Love affairs, wartime \ncommunication, and business transactions are the commonly cited human needs for \nsecure communications; preferring the first to the latter two, we\u2019re happy to use \nAlice and Bob as our sender and receiver, and imagine them in this first scenario.\nWe said that Alice and Bob want to communicate and wish to do so \u201csecurely,\u201d \nbut what precisely does this mean? As we will see, security (like love) is a many-\nsplendored thing; that is, there are many facets to security. Certainly, Alice and \nBob would like for the contents of their communication to remain secret from \nan eavesdropper. They probably would also like to make sure that when they are 8CHAPTER\nSecurity in \nComputer \nNetworks\n\n622     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\ncommunicating, they are indeed communicating with each other, and that if their \ncommunication is tampered with by an eavesdropper, that this tampering is detected. \nIn the first part of this chapter, we\u2019ll cover the fundamental cryptography techniques \nthat allow for encrypting communication, authenticating the party with whom one is \ncommunicating, and ensuring message integrity.\nIn the second part of this chapter, we\u2019ll examine how the fundamental \n cryptography principles can be used to create secure networking protocols. Once \nagain taking a top-down approach, we\u2019ll examine secure protocols in each of the \n(top four) layers, beginning with the application layer. We\u2019ll examine how to secure \ne-mail, how to secure a TCP connection, how to provide blanket security at the net -\nwork layer, and how to secure a wireless LAN. In the third part of this chapter we\u2019ll \nconsider operational security, which is about protecting organizational networks \nfrom attacks. In particular, we\u2019ll take a careful look at how firewalls and intrusion \ndetection systems can enhance the security of an organizational network.\n8.1 What Is Network Security?\nLet\u2019s begin our study of network security by returning to our lovers, Alice and Bob, \nwho want to communicate \u201csecurely.\u201d What precisely does this mean? Certainly, \nAlice wants only Bob to be able to understand a message that she has sent, even \nthough they are communicating over an insecure medium where an intruder (Trudy, \nthe intruder) may intercept whatever is transmitted from Alice to Bob. Bob also \nwants to be sure that the message he receives from Alice was indeed sent by Alice, \nand Alice wants to make sure that the person with whom she is communicating is \nindeed Bob. Alice and Bob also want to make sure that the contents of their messages \nhave not been altered in transit. They also want to be assured that they can communi -\ncate in the first place (i.e., that no one denies them access to the resources needed to \ncommunicate). Given these considerations, we can identify the following desirable \nproperties of secure communication .\n\u2022 Confidentiality.  Only the sender and intended receiver should be able to under -\nstand the contents of the", "doc_id": "f1b671fe-efcb-4117-9cbf-edf3468c7aa6", "embedding": null, "doc_hash": "829f7cb6d2d0d870a2e3b4fa95c6e3f8fd099ab1cd47eec1e3fc996acafb72e7", "extra_info": null, "node_info": {"start": 1822711, "end": 1826687}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "b9f0190d-9315-4b11-906d-2d4b2facfce5", "3": "a3a08c5e-feb5-4356-a32f-039ad9eca9e6"}}, "__type__": "1"}, "a3a08c5e-feb5-4356-a32f-039ad9eca9e6": {"__data__": {"text": "are communicating over an insecure medium where an intruder (Trudy, \nthe intruder) may intercept whatever is transmitted from Alice to Bob. Bob also \nwants to be sure that the message he receives from Alice was indeed sent by Alice, \nand Alice wants to make sure that the person with whom she is communicating is \nindeed Bob. Alice and Bob also want to make sure that the contents of their messages \nhave not been altered in transit. They also want to be assured that they can communi -\ncate in the first place (i.e., that no one denies them access to the resources needed to \ncommunicate). Given these considerations, we can identify the following desirable \nproperties of secure communication .\n\u2022 Confidentiality.  Only the sender and intended receiver should be able to under -\nstand the contents of the transmitted message. Because eavesdroppers may \nintercept the message, this necessarily requires that the message be somehow \nencrypted  so that an intercepted message cannot be understood by an interceptor. \nThis aspect of confidentiality is probably the most commonly perceived mean -\ning of the term secure communication . We\u2019ll study cryptographic techniques for \nencrypting and decrypting data in Section 8.2.\n\u2022 Message integrity.  Alice and Bob want to ensure that the content of their \n communication is not altered, either maliciously or by accident, in transit. Exten -\nsions to the checksumming techniques that we encountered in reliable transport \n8.1  \u2022  WHAT IS NETWORK SECURITY?      623\nand data link protocols can be used to provide such message integrity. We will \nstudy message integrity in Section 8.3.\n\u2022 End-point authentication.  Both the sender and receiver should be able to confirm \nthe identity of the other party involved in the communication\u2014to confirm that the \nother party is indeed who or what they claim to be. Face-to-face human commu -\nnication solves this problem easily by visual recognition. When communicating \nentities exchange messages over a medium where they cannot see the other party, \nauthentication is not so simple. When a user wants to access an inbox, how does \nthe mail server verify that the user is the person he or she claims to be? We study \nend-point authentication in Section 8.4.\n\u2022 Operational security.  Almost all organizations (companies, universities, and so \non) today have networks that are attached to the public Internet. These networks \ntherefore can potentially be compromised. Attackers can attempt to deposit worms \ninto the hosts in the network, obtain corporate secrets, map the internal network \nconfigurations, and launch DoS attacks. We\u2019ll see in Section 8.9 that operational \ndevices such as firewalls and intrusion detection systems are used to counter \nattacks against an organization\u2019s network. A firewall sits between the organiza -\ntion\u2019s network and the public network, controlling packet access to and from \nthe network. An intrusion detection system performs \u201cdeep packet  inspection,\u201d \n alerting the network administrators about suspicious activity.\nHaving established what we mean by network security, let\u2019s next consider \nexactly what information an intruder may have access to, and what actions can be \ntaken by the intruder. Figure 8.1 illustrates the scenario. Alice, the sender, wants to \nsend data to Bob, the receiver. In order to exchange data securely, while meeting \nthe requirements of confidentiality, end-point authentication, and message integrity, \nAlice and Bob will exchange control messages and data messages (in much the same \nway that TCP senders and receivers exchange control segments and data segments). \nSecure\nsender\nAlice\nTrudyChannelControl, data messages\nSecure\nreceiver\nBobData Data\nFigure 8.1  \u2666 Sender, receiver, and intruder (Alice, Bob, and Trudy)\n624     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nAll or some of these messages will typically be encrypted. As discussed in Section \n1.6, an intruder can potentially perform\n\u2022", "doc_id": "a3a08c5e-feb5-4356-a32f-039ad9eca9e6", "embedding": null, "doc_hash": "7302f0bd6f8f3396049b3de3df686788568ac12ddc627bb85f33fe241e354ab2", "extra_info": null, "node_info": {"start": 1826670, "end": 1830623}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "f1b671fe-efcb-4117-9cbf-edf3468c7aa6", "3": "04d9f638-42d9-4c6d-91d0-75b882f5b3b4"}}, "__type__": "1"}, "04d9f638-42d9-4c6d-91d0-75b882f5b3b4": {"__data__": {"text": "wants to \nsend data to Bob, the receiver. In order to exchange data securely, while meeting \nthe requirements of confidentiality, end-point authentication, and message integrity, \nAlice and Bob will exchange control messages and data messages (in much the same \nway that TCP senders and receivers exchange control segments and data segments). \nSecure\nsender\nAlice\nTrudyChannelControl, data messages\nSecure\nreceiver\nBobData Data\nFigure 8.1  \u2666 Sender, receiver, and intruder (Alice, Bob, and Trudy)\n624     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nAll or some of these messages will typically be encrypted. As discussed in Section \n1.6, an intruder can potentially perform\n\u2022 eavesdropping \u2014sniffing and recording control and data messages on the  channel.\n\u2022 modification, insertion , or deletion  of messages or message content.\nAs we\u2019ll see, unless appropriate countermeasures are taken, these capabilities \nallow an intruder to mount a wide variety of security attacks: snooping on communi -\ncation (possibly stealing passwords and data), impersonating another entity, hijack -\ning an ongoing session, denying service to legitimate network users by overloading \nsystem resources, and so on. A summary of reported attacks is maintained at the \nCERT Coordination Center [CERT 2016].\nHaving established that there are indeed real threats loose in the Internet, what \nare the Internet equivalents of Alice and Bob, our friends who need to communicate \nsecurely? Certainly, Bob and Alice might be human users at two end systems, for \nexample, a real Alice and a real Bob who really do want to exchange secure e-mail. \nThey might also be participants in an electronic commerce transaction. For example, \na real Bob might want to transfer his credit card number securely to a Web server \nto purchase an item online. Similarly, a real Alice might want to interact with her \nbank online. The parties needing secure communication might themselves also be \npart of the network infrastructure. Recall that the domain name system (DNS, see \nSection 2.4) or routing daemons that exchange routing information (see Chapter 5 ) \nrequire secure communication between two parties. The same is true for network \nmanagement applications, a topic we examined in Chapter 5 ). An intruder that could \nactively interfere with DNS lookups (as discussed in Section 2.4 ), routing computa -\ntions [RFC 4272], or network management functions [RFC 3414] could wreak havoc \nin the Internet.\nHaving now established the framework, a few of the most important definitions, \nand the need for network security, let us next delve into cryptography. While the use \nof cryptography in providing confidentiality is self-evident, we\u2019ll see shortly that it \nis also central to providing end-point authentication and message integrity\u2014making \ncryptography a cornerstone of network security.\n8.2 Principles of Cryptography\nAlthough cryptography has a long history dating back at least as far as Julius Caesar, \nmodern cryptographic techniques, including many of those used in the Internet, are \nbased on advances made in the past 30 years. Kahn\u2019s book, The Codebreakers  [Kahn \n1967], and Singh\u2019s book, The Code Book: The Science of Secrecy from Ancient \nEgypt to Quantum Cryptography  [Singh 1999], provide a fascinating look at the \n8.2  \u2022  PRINCIPLES OF CRYPTOGRAPHY      625\nlong history of cryptography. A complete discussion of cryptography itself requires a \ncomplete book [Kaufman 1995; Schneier 1995] and so we only touch on the essential \naspects of cryptography, particularly as they are practiced on the Internet. We also \nnote that while our focus in this section will be on the use of cryptography for con -\nfidentiality, we\u2019ll see shortly that cryptographic techniques are inextricably woven \ninto authentication, message integrity, nonrepudiation, and more.\nCryptographic techniques allow a sender to disguise data so that an intruder can \ngain no information from the intercepted data. The", "doc_id": "04d9f638-42d9-4c6d-91d0-75b882f5b3b4", "embedding": null, "doc_hash": "261cfc037d4f4adf22a6cc668c327e78d4800735fb5f7439e0d32b7b465a1142", "extra_info": null, "node_info": {"start": 1830713, "end": 1834681}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "a3a08c5e-feb5-4356-a32f-039ad9eca9e6", "3": "0879b85c-b035-450d-a6c0-34bfdcdf88ec"}}, "__type__": "1"}, "0879b85c-b035-450d-a6c0-34bfdcdf88ec": {"__data__": {"text": "Ancient \nEgypt to Quantum Cryptography  [Singh 1999], provide a fascinating look at the \n8.2  \u2022  PRINCIPLES OF CRYPTOGRAPHY      625\nlong history of cryptography. A complete discussion of cryptography itself requires a \ncomplete book [Kaufman 1995; Schneier 1995] and so we only touch on the essential \naspects of cryptography, particularly as they are practiced on the Internet. We also \nnote that while our focus in this section will be on the use of cryptography for con -\nfidentiality, we\u2019ll see shortly that cryptographic techniques are inextricably woven \ninto authentication, message integrity, nonrepudiation, and more.\nCryptographic techniques allow a sender to disguise data so that an intruder can \ngain no information from the intercepted data. The receiver, of course, must be able \nto recover the original data from the disguised data. Figure 8.2 illustrates some of the \nimportant terminology.\nSuppose now that Alice wants to send a message to Bob. Alice\u2019s message in \nits original form (for example, \u201c Bob, I love you. Alice \u201d) is known as \n plaintext , or cleartext . Alice encrypts her plaintext message using an encryption \nalgorithm  so that the encrypted message, known as ciphertext , looks unintelligi -\nble to any intruder. Interestingly, in many modern cryptographic systems, including \nthose used in the Internet, the encryption technique itself is known \u2014published, stand -\nardized, and available to everyone (for example, [RFC 1321; RFC 3447; RFC 2420; \nNIST 2001]), even a potential intruder! Clearly, if everyone knows the method for \nencoding data, then there must be some secret information that prevents an intruder \nfrom decrypting the transmitted data. This is where keys come in.\nIn Figure 8.2, Alice provides a key, KA, a string of numbers or characters, as \ninput to the encryption algorithm. The encryption algorithm takes the key and the \nplaintext message, m, as input and produces ciphertext as output. The notation \nKA(m) refers to the ciphertext form (encrypted using the key KA) of the plaintext \nmessage, m. The actual encryption algorithm that uses key KA will be evident from \nthe context. Similarly, Bob will provide a key, KB, to the decryption algorithm  Figure 8.2  \u2666 Cryptographic componentsEncryption\nalgorithmCiphertext\nChannel\nTrudyAlice BobDecryption\nalgorithmPlaintext\nKey:\nKeyPlaintext\nKA KB\n626     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nthat takes the ciphertext and Bob\u2019s key as input and produces the original plain -\ntext as output. That is, if Bob receives an encrypted message KA(m), he decrypts it \nby computing KB(KA(m))=m. In symmetric key systems , Alice\u2019s and Bob\u2019s keys \nare identical and are secret. In public key systems , a pair of keys is used. One of \nthe keys is known to both Bob and Alice (indeed, it is known to the whole world).  \nThe other key is known only by either Bob or Alice (but not both). In the following \ntwo subsections, we consider symmetric key and public key systems in more detail.\n8.2.1 Symmetric Key Cryptography\nAll cryptographic algorithms involve substituting one thing for another, for exam -\nple, taking a piece of plaintext and then computing and substituting the appropriate \nciphertext to create the encrypted message. Before studying a modern key-based \ncryptographic system, let us first get our feet wet by studying a very old, very simple \nsymmetric key algorithm attributed to Julius Caesar, known as the Caesar cipher   \n(a cipher is a method for encrypting data).\nFor English text, the Caesar cipher would work by taking each letter in the plain -\ntext message and substituting the letter that is k letters later (allowing wraparound; \nthat is, having the letter z followed by the letter a) in the alphabet. For example if \nk=3, then the letter", "doc_id": "0879b85c-b035-450d-a6c0-34bfdcdf88ec", "embedding": null, "doc_hash": "70e7579f26231779576c80de4b328df54d3d8988f667eccd9f4ad7ecee937747", "extra_info": null, "node_info": {"start": 1834622, "end": 1838389}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "04d9f638-42d9-4c6d-91d0-75b882f5b3b4", "3": "0d7ba882-30f8-46df-b9f3-837fe6f51f98"}}, "__type__": "1"}, "0d7ba882-30f8-46df-b9f3-837fe6f51f98": {"__data__": {"text": "Symmetric Key Cryptography\nAll cryptographic algorithms involve substituting one thing for another, for exam -\nple, taking a piece of plaintext and then computing and substituting the appropriate \nciphertext to create the encrypted message. Before studying a modern key-based \ncryptographic system, let us first get our feet wet by studying a very old, very simple \nsymmetric key algorithm attributed to Julius Caesar, known as the Caesar cipher   \n(a cipher is a method for encrypting data).\nFor English text, the Caesar cipher would work by taking each letter in the plain -\ntext message and substituting the letter that is k letters later (allowing wraparound; \nthat is, having the letter z followed by the letter a) in the alphabet. For example if \nk=3, then the letter a in plaintext becomes d in ciphertext; b in plaintext becomes \ne in ciphertext, and so on. Here, the value of k serves as the key. As an example, the \nplaintext message \u201c bob, i love you. Alice \u201d becomes \u201c ere, l oryh \nbrx. dolfh \u201d in ciphertext. While the ciphertext does indeed look like gibberish, \nit wouldn\u2019t take long to break the code if you knew that the Caesar cipher was being \nused, as there are only 25 possible key values.\nAn improvement on the Caesar cipher is the monoalphabetic cipher , which also \nsubstitutes one letter of the alphabet with another letter of the alphabet.  However, \nrather than substituting according to a regular pattern (for example, substitution with \nan offset of k for all letters), any letter can be substituted for any other letter, as long \nas each letter has a unique substitute letter, and vice versa. The substitution rule in \nFigure 8.3 shows one possible rule for encoding plaintext.\nThe plaintext message \u201c bob, i love you. Alice \u201d becomes \u201c nkn, s \ngktc wky. Mgsbc .\u201d Thus, as in the case of the Caesar cipher, this looks like \ngibberish. A monoalphabetic cipher would also appear to be better than the Caesar \ncipher in that there are 26! (on the order of 1026) possible pairings of letters rather \nthan 25 possible pairings. A brute-force approach of trying all 1026 possible pairings \nFigure 8.3  \u2666 A monoalphabetic cipherPlaintext letter: a b c d e f g h i j k l m n o p q r s t u v w x y z\nCiphertext letter: m n b v c x z a s d f g h j k l p o i u y t r e w q\n8.2  \u2022  PRINCIPLES OF CRYPTOGRAPHY      627\nwould require far too much work to be a feasible way of breaking the encryption \nalgorithm and decoding the message. However, by statistical analysis of the plain -\ntext language, for example, knowing that the letters e and t are the most frequently \noccurring letters in typical English text (accounting for 13 percent and 9 percent of \nletter occurrences), and knowing that particular two-and three-letter occurrences of \nletters appear quite often together (for example, \u201cin,\u201d \u201cit,\u201d \u201cthe,\u201d \u201cion,\u201d \u201cing,\u201d and so \nforth) make it relatively easy to break this code. If the intruder has some knowledge \nabout the possible contents of the message, then it is even easier to break the code. \nFor example, if Trudy the intruder is Bob\u2019s wife and suspects Bob of having an \naffair with Alice, then she might suspect that the names \u201cbob\u201d and \u201calice\u201d appear in \nthe text. If Trudy knew for certain that those two names appeared in the ciphertext \nand had a copy of the example ciphertext message above, then she could immedi -\nately determine seven of the 26 letter pairings, requiring 109 fewer possibilities to \nbe checked by a brute-force method. Indeed, if Trudy suspected Bob of having an", "doc_id": "0d7ba882-30f8-46df-b9f3-837fe6f51f98", "embedding": null, "doc_hash": "96bdac8839eebd73559d9dd5649710e945474ffed6c8db2c1461a89f06ff4759", "extra_info": null, "node_info": {"start": 1838381, "end": 1841903}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "0879b85c-b035-450d-a6c0-34bfdcdf88ec", "3": "37883d90-f45e-42da-921b-0a192b32ebe4"}}, "__type__": "1"}, "37883d90-f45e-42da-921b-0a192b32ebe4": {"__data__": {"text": "\u201cing,\u201d and so \nforth) make it relatively easy to break this code. If the intruder has some knowledge \nabout the possible contents of the message, then it is even easier to break the code. \nFor example, if Trudy the intruder is Bob\u2019s wife and suspects Bob of having an \naffair with Alice, then she might suspect that the names \u201cbob\u201d and \u201calice\u201d appear in \nthe text. If Trudy knew for certain that those two names appeared in the ciphertext \nand had a copy of the example ciphertext message above, then she could immedi -\nately determine seven of the 26 letter pairings, requiring 109 fewer possibilities to \nbe checked by a brute-force method. Indeed, if Trudy suspected Bob of having an \naffair, she might well expect to find some other choice words in the message as well.\nWhen considering how easy it might be for Trudy to break Bob and Alice\u2019s \nencryption scheme, one can distinguish three different scenarios, depending on what \ninformation the intruder has.\n\u2022 Ciphertext-only attack.  In some cases, the intruder may have access only to the \nintercepted ciphertext, with no certain information about the contents of the plain -\ntext message. We have seen how statistical analysis can help in a ciphertext-only \nattack  on an encryption scheme.\n\u2022 Known-plaintext attack.  We saw above that if Trudy somehow knew for sure \nthat \u201cbob\u201d and \u201calice\u201d appeared in the ciphertext message, then she could have \ndetermined the (plaintext, ciphertext) pairings for the letters a, l, i, c, e, b , and o. \nTrudy might also have been fortunate enough to have recorded all of the cipher -\ntext transmissions and then found Bob\u2019s own decrypted version of one of the \ntransmissions scribbled on a piece of paper. When an intruder knows some of the \n(plaintext, ciphertext) pairings, we refer to this as a known-plaintext attack  on \nthe encryption scheme.\n\u2022 Chosen-plaintext attack.  In a chosen-plaintext attack , the intruder is able to \nchoose the plaintext message and obtain its corresponding ciphertext form. For \nthe simple encryption algorithms we\u2019ve seen so far, if Trudy could get Alice to \nsend the message, \u201c The quick brown fox jumps over the lazy \ndog,\u201d she could completely break the encryption scheme. We\u2019ll see shortly that \nfor more sophisticated encryption techniques, a chosen-plaintext attack does not \nnecessarily mean that the encryption technique can be broken.\nFive hundred years ago, techniques improving on monoalphabetic encryp -\ntion, known as polyalphabetic encryption , were invented. The idea behind pol -\nyalphabetic encryption is to use multiple monoalphabetic ciphers, with a specific \n628     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nmonoalphabetic cipher to encode a letter in a specific position in the plaintext mes -\nsage. Thus, the same letter, appearing in different positions in the plaintext message, \nmight be encoded differently. An example of a polyalphabetic encryption scheme is \nshown in Figure 8.4. It has two Caesar ciphers (with k=5 and k=19), shown as \nrows. We might choose to use these two Caesar ciphers, C1 and C2, in the repeating \npattern C1, C2, C2, C1, C2. That is, the first letter of plaintext is to be encoded using \nC1, the second and third using C2, the fourth using C1, and the fifth using C2. The \npattern then repeats, with the sixth letter being encoded using C1, the seventh with \nC2, and so on. The plaintext message \u201c bob, i love you .\u201d is thus encrypted \n\u201cghu, n etox dhz .\u201d Note that the first b in the plaintext message is encrypted \nusing C1, while the second b is encrypted using C2. In this example, the", "doc_id": "37883d90-f45e-42da-921b-0a192b32ebe4", "embedding": null, "doc_hash": "23bdf2586ee4eddceebb9a832329348473576e71f3a61c7b11a01dac4de6bad5", "extra_info": null, "node_info": {"start": 1841988, "end": 1845564}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "0d7ba882-30f8-46df-b9f3-837fe6f51f98", "3": "7b6d8745-bba5-495a-933a-283889eb94f9"}}, "__type__": "1"}, "7b6d8745-bba5-495a-933a-283889eb94f9": {"__data__": {"text": "It has two Caesar ciphers (with k=5 and k=19), shown as \nrows. We might choose to use these two Caesar ciphers, C1 and C2, in the repeating \npattern C1, C2, C2, C1, C2. That is, the first letter of plaintext is to be encoded using \nC1, the second and third using C2, the fourth using C1, and the fifth using C2. The \npattern then repeats, with the sixth letter being encoded using C1, the seventh with \nC2, and so on. The plaintext message \u201c bob, i love you .\u201d is thus encrypted \n\u201cghu, n etox dhz .\u201d Note that the first b in the plaintext message is encrypted \nusing C1, while the second b is encrypted using C2. In this example, the encryption \nand decryption \u201ckey\u201d is the knowledge of the two Caesar keys (k=5, k=19) and \nthe pattern C1, C2, C2, C1, C2.\nBlock Ciphers\nLet us now move forward to modern times and examine how symmetric key encryp -\ntion is done today. There are two broad classes of symmetric encryption tech -\nniques: stream ciphers  and block ciphers . We\u2019ll briefly examine stream ciphers in \n Section 8.7 when we investigate security for wireless LANs. In this section, we focus \non block ciphers, which are used in many secure Internet protocols, including PGP \n(for secure e-mail), SSL (for securing TCP connections), and IPsec (for securing the \nnetwork-layer transport).\nIn a block cipher, the message to be encrypted is processed in blocks of k bits. \nFor example, if k=64, then the message is broken into 64-bit blocks, and each block \nis encrypted independently. To encode a block, the cipher uses a one-to-one map -\nping to map the k-bit block of cleartext to a k-bit block of ciphertext. Let\u2019s look at an \nexample. Suppose that k=3, so that the block cipher maps 3-bit inputs  (cleartext) \nto 3-bit outputs (ciphertext). One possible mapping is given in Table 8.1. Notice that \nthis is a one-to-one mapping; that is, there is a different output for each input. This \nblock cipher breaks the message up into 3-bit blocks and encrypts each block accord -\ning to the above mapping. You should verify that the message 010110001111 gets \nencrypted into 101000111001.\nContinuing with this 3-bit block example, note that the mapping in Table 8.1 \nis just one mapping of many possible mappings. How many possible mappings are Figure 8.4  \u2666 A polyalphabetic cipher using two Caesar ciphersPlaintext letter: a b c d e f g h i j k l m n o p q r s t u v w x y z\nC1(k = 5): \nC2(k = 19): f g h i j k l m n o p q r s t u v w x y z a b c d e\nt u v w x y z a b c d e f g h i j k l m n o p q r s\n8.2  \u2022  PRINCIPLES OF CRYPTOGRAPHY      629\nthere? To answer this question, observe that a mapping is nothing more than a permu -\ntation of all the possible inputs. There are 23 (= 8) possible inputs (listed under the \ninput columns). These eight inputs can be permuted in 8!=40,320  different ways. \nSince each of these permutations specifies a mapping, there are 40,320 possible map -\npings. We can view each of these mappings as a key\u2014if Alice and Bob both know \nthe mapping (the key), they can encrypt and decrypt the messages sent between them.\nThe brute-force attack for this cipher is to try to decrypt ciphtertext by using all \nmappings. With only 40,320 mappings (when k=3), this can quickly be accom -\nplished on a desktop PC. To thwart brute-force attacks, block ciphers typically use", "doc_id": "7b6d8745-bba5-495a-933a-283889eb94f9", "embedding": null, "doc_hash": "8636aa0018571df8a44422a36b3ea3ab688b1e4a02f334de8e6a14488a47fe02", "extra_info": null, "node_info": {"start": 1845620, "end": 1848923}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "37883d90-f45e-42da-921b-0a192b32ebe4", "3": "6e175c6b-34df-4d62-843e-36f12490c7f2"}}, "__type__": "1"}, "6e175c6b-34df-4d62-843e-36f12490c7f2": {"__data__": {"text": "that a mapping is nothing more than a permu -\ntation of all the possible inputs. There are 23 (= 8) possible inputs (listed under the \ninput columns). These eight inputs can be permuted in 8!=40,320  different ways. \nSince each of these permutations specifies a mapping, there are 40,320 possible map -\npings. We can view each of these mappings as a key\u2014if Alice and Bob both know \nthe mapping (the key), they can encrypt and decrypt the messages sent between them.\nThe brute-force attack for this cipher is to try to decrypt ciphtertext by using all \nmappings. With only 40,320 mappings (when k=3), this can quickly be accom -\nplished on a desktop PC. To thwart brute-force attacks, block ciphers typically use \nmuch larger blocks, consisting of k=64 bits or even larger. Note that the number of \npossible mappings for a general k-block cipher is 2k!, which is astronomical for even \nmoderate values of k (such as k=64).\nAlthough full-table block ciphers, as just described, with moderate values of k \ncan produce robust symmetric key encryption schemes, they are unfortunately dif -\nficult to implement. For k=64 and for a given mapping, Alice and Bob would \nneed to maintain a table with 264 input values, which is an infeasible task. Moreo -\nver, if Alice and Bob were to change keys, they would have to each regenerate the \ntable. Thus, a full-table block cipher, providing predetermined mappings between all \ninputs and outputs (as in the example above), is simply out of the question.\nInstead, block ciphers typically use functions that simulate randomly permuted \ntables. An example (adapted from [Kaufman 1995]) of such a function for k=64 \nbits is shown in Figure 8.5. The function first breaks a 64-bit block into 8 chunks, \nwith each chunk consisting of 8 bits. Each 8-bit chunk is processed by an 8-bit to \n8-bit table, which is of manageable size. For example, the first chunk is processed \nby the table denoted by T1. Next, the 8 output chunks are reassembled into a 64-bit \nblock. The positions of the 64 bits in the block are then scrambled (permuted) to \nproduce a 64-bit output. This output is fed back to the 64-bit input, where another \ncycle begins. After n such cycles, the function provides a 64-bit block of ciphertext. \nThe purpose of the rounds is to make each input bit affect most (if not all) of the final \noutput bits. (If only one round were used, a given input bit would affect only 8 of the \n64 output bits.) The key for this block cipher algorithm would be the eight permuta -\ntion tables (assuming the scramble function is publicly known).Table 8.1  \u2666 A specific 3-bit block cipherinput output input output\n000 110 100 011\n001 111 101 010\n010 101 110 000\n011 100 111 001\n630     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nToday there are a number of popular block ciphers, including DES (standing \nfor Data Encryption Standard), 3DES, and AES (standing for Advanced Encryption \nStandard). Each of these standards uses functions, rather than predetermined tables, \nalong the lines of Figure 8.5 (albeit more complicated and specific to each cipher). \nEach of these algorithms also uses a string of bits for a key. For example, DES uses \n64-bit blocks with a 56-bit key. AES uses 128-bit blocks and can operate with keys \nthat are 128, 192, and 256 bits long. An algorithm\u2019s key determines the specific \n\u201cmini-table\u201d mappings and permutations within the algorithm\u2019s internals. The brute-\nforce attack for each of these ciphers is to cycle through all the keys, applying the \ndecryption algorithm with each key. Observe that with a key length of n, there are 2n \npossible keys. NIST [NIST 2001] estimates that a machine that could crack 56-bit \nDES in one second (that is, try all 256", "doc_id": "6e175c6b-34df-4d62-843e-36f12490c7f2", "embedding": null, "doc_hash": "1b6019707ac311670f39e9fdae35a6e7abbea4a933fe04f6789ba287b54cfe65", "extra_info": null, "node_info": {"start": 1848844, "end": 1852565}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "7b6d8745-bba5-495a-933a-283889eb94f9", "3": "70d497c6-959d-48d5-8451-005e0909a884"}}, "__type__": "1"}, "70d497c6-959d-48d5-8451-005e0909a884": {"__data__": {"text": "\nalong the lines of Figure 8.5 (albeit more complicated and specific to each cipher). \nEach of these algorithms also uses a string of bits for a key. For example, DES uses \n64-bit blocks with a 56-bit key. AES uses 128-bit blocks and can operate with keys \nthat are 128, 192, and 256 bits long. An algorithm\u2019s key determines the specific \n\u201cmini-table\u201d mappings and permutations within the algorithm\u2019s internals. The brute-\nforce attack for each of these ciphers is to cycle through all the keys, applying the \ndecryption algorithm with each key. Observe that with a key length of n, there are 2n \npossible keys. NIST [NIST 2001] estimates that a machine that could crack 56-bit \nDES in one second (that is, try all 256 keys in one second) would take approximately \n149 trillion years to crack a 128-bit AES key.\nCipher-Block Chaining\nIn computer networking applications, we typically need to encrypt long messages  \n(or long streams of data). If we apply a block cipher as described by simply chopping \nup the message into k-bit blocks and independently encrypting each block, a subtle \nbut important problem occurs. To see this, observe that two or more of the cleartext \nblocks can be identical. For example, the cleartext in two or more blocks could be \n\u201cHTTP/1.1\u201d. For these identical blocks, a block cipher would, of course, produce \nthe same ciphertext. An attacker could potentially guess the cleartext when it sees \nidentical ciphertext blocks and may even be able to decrypt the entire message by Figure 8.5  \u2666 An example of a block cipher64-bit outputLoop\nfor n\nrounds8 bits\n8 bitsT18 bits\n8 bitsT28 bits\n8 bitsT38 bits64-bit input\n8 bitsT48 bits\n8 bitsT58 bits\n8 bitsT68 bits\n8 bitsT78 bits\n8 bitsT8\n64-bit scrambler\n8.2  \u2022  PRINCIPLES OF CRYPTOGRAPHY      631\nidentifying identical ciphtertext blocks and using knowledge about the underlying \nprotocol structure [Kaufman 1995].\nTo address this problem, we can mix some randomness into the ciphertext so \nthat identical plaintext blocks produce different ciphertext blocks. To explain this \nidea, let m(i) denote the ith plaintext block, c(i) denote the ith ciphertext block, and \na/uni2295.altb denote the exclusive-or (XOR) of two bit strings, a and b. (Recall that the  \n0/uni2295.alt0=1/uni2295.alt1=0 and 0 /uni2295.alt1=1/uni2295.alt0=1, and the XOR of two bit strings is  \ndone on a bit-by-bit basis. So, for example, 10101010 /uni2295.alt11110000 =01011010.) \nAlso, denote the block-cipher encryption algorithm with key S as KS. The basic idea \nis as follows. The sender creates a random k-bit number r(i) for the ith block and \ncalculates c(i)=KS(m(i)/uni2295.altr(i )). Note that a new k-bit random number is chosen \nfor each block. The sender then sends c(1), r(1), c(2), r(2), c(3), r(3), and so on. \nSince the receiver receives c(i) and r(i), it can recover each block of the plaintext by \ncomputing m(i)=KS(c(i))/uni2295.altr(i ). It is important to note that, although r(i) is sent \nin the clear and thus can be sniffed by Trudy, she cannot obtain the plaintext m(i), \nsince she does not know the key KS. Also note that if two plaintext blocks m(i) and \nm(j) are the same, the corresponding ciphertext blocks c(i) and c(j) will be different \n(as long as the random numbers r(i) and r(j) are different, which", "doc_id": "70d497c6-959d-48d5-8451-005e0909a884", "embedding": null, "doc_hash": "3eff3ede25d4369ed066514472b0cbce677f7878f408c40a8fa7d785f4a86dce", "extra_info": null, "node_info": {"start": 1852562, "end": 1855845}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "6e175c6b-34df-4d62-843e-36f12490c7f2", "3": "95bd534d-ab95-4d09-b149-da5057ed388c"}}, "__type__": "1"}, "95bd534d-ab95-4d09-b149-da5057ed388c": {"__data__": {"text": "sender then sends c(1), r(1), c(2), r(2), c(3), r(3), and so on. \nSince the receiver receives c(i) and r(i), it can recover each block of the plaintext by \ncomputing m(i)=KS(c(i))/uni2295.altr(i ). It is important to note that, although r(i) is sent \nin the clear and thus can be sniffed by Trudy, she cannot obtain the plaintext m(i), \nsince she does not know the key KS. Also note that if two plaintext blocks m(i) and \nm(j) are the same, the corresponding ciphertext blocks c(i) and c(j) will be different \n(as long as the random numbers r(i) and r(j) are different, which occurs with very \nhigh probability).\nAs an example, consider the 3-bit block cipher in Table 8.1. Suppose the plain -\ntext is 010010010. If Alice encrypts this directly, without including the randomness, \nthe resulting ciphertext becomes 101101101. If Trudy sniffs this ciphertext, because \neach of the three cipher blocks is the same, she can correctly surmise that each of the \nthree plaintext blocks are the same. Now suppose instead Alice generates the ran -\ndom blocks r(1)=001, r(2)=111, and r(3)=100 and uses the above technique \nto generate the ciphertext c(1)=100, c(2)=010, and c(3)=000. Note that the \nthree ciphertext blocks are different even though the plaintext blocks are the same. \nAlice then sends c(1), r(1), c(2), and r(2). You should verify that Bob can obtain the \noriginal plaintext using the shared key KS.\nThe astute reader will note that introducing randomness solves one problem but \ncreates another: namely, Alice must transmit twice as many bits as before. Indeed, \nfor each cipher bit, she must now also send a random bit, doubling the required band -\nwidth. In order to have our cake and eat it too, block ciphers typically use a technique \ncalled Cipher Block Chaining (CBC) . The basic idea is to send only one random \nvalue along with the very first message, and then have the sender and receiver use \nthe computed coded blocks in place of the subsequent random number.  Specifically, \nCBC operates as follows:\n 1. Before encrypting the message (or the stream of data), the sender generates a \nrandom k-bit string, called the Initialization Vector (IV) . Denote this initial-\nization vector by c(0). The sender sends the IV to the receiver in cleartext .\n 2. For the first block, the sender calculates m(1)/uni2295.altc(0), that is, calculates the \nexclusive-or of the first block of cleartext with the IV. It then runs the result \n632     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nthrough the block-cipher algorithm to get the corresponding ciphertext block; \nthat is, c(1)=KS(m(1)/uni2295.altc(0)). The sender sends the encrypted block c(1) to \nthe receiver.\n 3. For the ith block, the sender generates the ith ciphertext block from c(i)= \nKS(m(i)/uni2295.altc(i-1)).\nLet\u2019s now examine some of the consequences of this approach. First, the receiver \nwill still be able to recover the original message. Indeed, when the receiver receives \nc(i), it decrypts it with KS to obtain s(i)=m(i)/uni2295.altc(i-1); since the receiver also \nknows c(i-1), it then obtains the cleartext block from m(i)=s(i)/uni2295.altc(i-1). \nSecond, even if two cleartext blocks are identical, the corresponding ciphtertexts \n(almost always) will be different. Third, although the sender sends the IV in the \nclear, an intruder will still not be able to", "doc_id": "95bd534d-ab95-4d09-b149-da5057ed388c", "embedding": null, "doc_hash": "4ddc48cf2ba9cbe94528ae09101324b675e195beb850b80a9578d9f0e084bda7", "extra_info": null, "node_info": {"start": 1855966, "end": 1859310}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "70d497c6-959d-48d5-8451-005e0909a884", "3": "e50a8f7f-f8cf-4baa-9629-dad11ae8996d"}}, "__type__": "1"}, "e50a8f7f-f8cf-4baa-9629-dad11ae8996d": {"__data__": {"text": "\nKS(m(i)/uni2295.altc(i-1)).\nLet\u2019s now examine some of the consequences of this approach. First, the receiver \nwill still be able to recover the original message. Indeed, when the receiver receives \nc(i), it decrypts it with KS to obtain s(i)=m(i)/uni2295.altc(i-1); since the receiver also \nknows c(i-1), it then obtains the cleartext block from m(i)=s(i)/uni2295.altc(i-1). \nSecond, even if two cleartext blocks are identical, the corresponding ciphtertexts \n(almost always) will be different. Third, although the sender sends the IV in the \nclear, an intruder will still not be able to decrypt the ciphertext blocks, since the \nintruder does not know the secret key, S. Finally, the sender only sends one overhead \nblock (the IV), thereby negligibly increasing the bandwidth usage for long messages  \n(consisting of hundreds of blocks).\nAs an example, let\u2019s now determine the ciphertext for the 3-bit block cipher in \nTable 8. 1 with plaintext 010010010 and IV = c(0) = 001. The sender first uses the  \nIV to calculate c(1)=KS(m(1)/uni2295.altc(0))=100. The sender then calculates c(2) =  \nKS(m(2)/uni2295.altc(1))=KS(010/uni2295.alt100)=000, and c(3)=KS(m(3)/uni2295.altc(2))=KS(010/uni2295.alt \n000)=101. The reader should verify that the receiver, knowing the IV and KS can \nrecover the original plaintext.\nCBC has an important consequence when designing secure network protocols: \nwe\u2019ll need to provide a mechanism within the protocol to distribute the IV from sender \nto receiver. We\u2019ll see how this is done for several protocols later in this chapter.\n8.2.2 Public Key Encryption\nFor more than 2,000 years (since the time of the Caesar cipher and up to the 1970s), \nencrypted communication required that the two communicating parties share a com -\nmon secret\u2014the symmetric key used for encryption and decryption. One difficulty \nwith this approach is that the two parties must somehow agree on the shared key; \nbut to do so requires (presumably secure ) communication! Perhaps the parties could \nfirst meet and agree on the key in person (for example, two of Caesar\u2019s centurions \nmight meet at the Roman baths) and thereafter communicate with encryption. In a \nnetworked world, however, communicating parties may never meet and may never \nconverse except over the network. Is it possible for two parties to communicate with \nencryption without having a shared secret key that is known in advance? In 1976, \nDiffie and Hellman [Diffie 1976] demonstrated an algorithm (known now as Dif -\nfie-Hellman Key Exchange) to do just that\u2014a radically different and marvelously \nelegant approach toward secure communication that has led to the development of \ntoday\u2019s public key cryptography systems. We\u2019ll see shortly that public key cryptog -\nraphy systems also have several wonderful properties that make them useful not only \n8.2  \u2022  PRINCIPLES OF CRYPTOGRAPHY      633\nfor encryption, but for authentication and digital signatures as well. Interestingly, it \nhas recently come to light that ideas similar to those in [Diffie 1976] and [RSA 1978] \nhad been independently developed in the early 1970s in a series of secret reports \nby researchers at the Communications-Electronics Security Group in the United \n Kingdom [Ellis 1987]. As is often the case, great ideas can spring up independently \nin many places; fortunately, public key advances took place not only in private, but \nalso in the public view, as well.\nThe use of public key cryptography is conceptually quite simple. Suppose Alice \nwants to communicate with Bob. As shown in Figure 8.6, rather", "doc_id": "e50a8f7f-f8cf-4baa-9629-dad11ae8996d", "embedding": null, "doc_hash": "3df30e48bf76b1634ffc1c1a3291be77677df029ae0a302e437d44f5640bd11d", "extra_info": null, "node_info": {"start": 1859282, "end": 1862840}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "95bd534d-ab95-4d09-b149-da5057ed388c", "3": "54ffef70-b630-4f7c-af0f-92d4e5304291"}}, "__type__": "1"}, "54ffef70-b630-4f7c-af0f-92d4e5304291": {"__data__": {"text": "that make them useful not only \n8.2  \u2022  PRINCIPLES OF CRYPTOGRAPHY      633\nfor encryption, but for authentication and digital signatures as well. Interestingly, it \nhas recently come to light that ideas similar to those in [Diffie 1976] and [RSA 1978] \nhad been independently developed in the early 1970s in a series of secret reports \nby researchers at the Communications-Electronics Security Group in the United \n Kingdom [Ellis 1987]. As is often the case, great ideas can spring up independently \nin many places; fortunately, public key advances took place not only in private, but \nalso in the public view, as well.\nThe use of public key cryptography is conceptually quite simple. Suppose Alice \nwants to communicate with Bob. As shown in Figure 8.6, rather than Bob and Alice \nsharing a single secret key (as in the case of symmetric key systems), Bob (the recipi -\nent of Alice\u2019s messages) instead has two keys\u2014a public key  that is available to \neveryone  in the world (including Trudy the intruder) and a private key  that is known \nonly to Bob. We will use the notation K+\nB and K-\nB to refer to Bob\u2019s public and pri -\nvate keys, respectively. In order to communicate with Bob, Alice first fetches Bob\u2019s \npublic key. Alice then encrypts her message, m, to Bob using Bob\u2019s public key and \na known (for example, standardized) encryption algorithm; that is, Alice computes \nK+\nB(m). Bob receives Alice\u2019s encrypted message and uses his private key and a known \n(for example, standardized) decryption algorithm to decrypt Alice\u2019s encrypted mes -\nsage. That is, Bob computes K-\nB(K+\nB(m)). We will see below that there are encryption/\ndecryption algorithms and techniques for choosing public and private keys such that \nK-\nB(K+\nB(m))=m; that is, applying Bob\u2019s public key, K+\nB, to a message, m (to get \nK+\nB(m)), and then applying Bob\u2019s private key, K-\nB, to the encrypted version of m (that \nis, computing K-\nB(K+\nB(m))) gives back m. This is a remarkable result! In this manner, \nAlice can use Bob\u2019s publicly available key to send a secret message to Bob without \neither of them having to distribute any secret keys! We will see shortly that we can \ninterchange the public key and private key encryption and get the same remarkable \nresult\u2013\u2013that is, K-\nB (B +(m))=K+\nB (K-\nB(m))=m.Figure 8.6  \u2666 Public key cryptographyEncryption\nalgorithmCiphertext\nDecryption\nalgorithmPlaintext\nmessage, mPlaintext\nmessage, mPrivate decryption key\nm = KB\u2013(KB+(m))KB\u2013\nKB+(m)Public encryption keyKB+\n634     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nThe use of public key cryptography is thus conceptually simple. But two immedi -\nate worries may spring to mind. A first concern is that although an intruder intercept -\ning Alice\u2019s encrypted message will see only gibberish, the intruder knows both the \nkey (Bob\u2019s public key, which is available for all the world to see) and the algorithm \nthat Alice used for encryption. Trudy can thus mount a chosen-plaintext attack, using \nthe known standardized encryption algorithm and Bob\u2019s publicly available encryption \nkey to encode any message she chooses! Trudy might well try, for example, to encode \nmessages, or parts of messages, that she suspects that Alice might send. Clearly, if \npublic key cryptography is to work, key selection and encryption/decryption must be \ndone in such a way that it is impossible (or at least so hard as to be nearly impossible) \nfor an intruder to either determine Bob\u2019s private key or somehow otherwise decrypt \nor guess Alice\u2019s message to Bob.", "doc_id": "54ffef70-b630-4f7c-af0f-92d4e5304291", "embedding": null, "doc_hash": "20d49b915cfa786a104be03eea0cc2305cffceb852d30a909667e65a77ab888a", "extra_info": null, "node_info": {"start": 1862710, "end": 1866231}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "e50a8f7f-f8cf-4baa-9629-dad11ae8996d", "3": "d522fbf7-626e-421e-80ae-b1cd7645422d"}}, "__type__": "1"}, "d522fbf7-626e-421e-80ae-b1cd7645422d": {"__data__": {"text": "knows both the \nkey (Bob\u2019s public key, which is available for all the world to see) and the algorithm \nthat Alice used for encryption. Trudy can thus mount a chosen-plaintext attack, using \nthe known standardized encryption algorithm and Bob\u2019s publicly available encryption \nkey to encode any message she chooses! Trudy might well try, for example, to encode \nmessages, or parts of messages, that she suspects that Alice might send. Clearly, if \npublic key cryptography is to work, key selection and encryption/decryption must be \ndone in such a way that it is impossible (or at least so hard as to be nearly impossible) \nfor an intruder to either determine Bob\u2019s private key or somehow otherwise decrypt \nor guess Alice\u2019s message to Bob. A second concern is that since Bob\u2019s encryption key \nis public, anyone can send an encrypted message to Bob, including Alice or someone \nclaiming  to be Alice. In the case of a single shared secret key, the fact that the sender \nknows the secret key implicitly identifies the sender to the receiver. In the case of \npublic key cryptography, however, this is no longer the case since anyone can send \nan encrypted message to Bob using Bob\u2019s publicly available key. A digital signature, \na topic we will study in Section 8.3, is needed to bind a sender to a message.\nRSA\nWhile there may be many algorithms that address these concerns, the RSA  algorithm  \n(named after its founders, Ron Rivest, Adi Shamir, and Leonard Adleman) has \nbecome almost synonymous with public key cryptography. Let\u2019s first see how RSA \nworks and then examine why it works.\nRSA makes extensive use of arithmetic operations using modulo- n arithmetic. \nSo let\u2019s briefly review modular arithmetic. Recall that x mod n simply means the \nremainder of x when divided by n; so, for example, 19 mod 5=4. In modular arith -\nmetic, one performs the usual operations of addition, multiplication, and exponen -\ntiation. However, the result of each operation is replaced by the integer remainder \nthat is left when the result is divided by n. Adding and multiplying with modular \narithmetic is facilitated with the following handy facts:\n[(a mod n) + (b mod n)] mod n = (a + b) mod n\n[(a mod n) - (b mod n)] mod n = (a - b) mod n\n[(a mod n) # (b mod n)] mod n = (a # b) mod n\nIt follows from the third fact that (a mod n)d mod n=ad mod n, which is an identity \nthat we will soon find very useful.\nNow suppose that Alice wants to send to Bob an RSA-encrypted message, as \nshown in Figure 8.6. In our discussion of RSA, let\u2019s always keep in mind that a mes -\nsage is nothing but a bit pattern, and every bit pattern can be uniquely represented by \n8.2  \u2022  PRINCIPLES OF CRYPTOGRAPHY      635\nan integer number (along with the length of the bit pattern). For example, suppose \na message is the bit pattern 1001; this message can be represented by the decimal \ninteger 9. Thus, when encrypting a message with RSA, it is equivalent to encrypting \nthe unique integer number that represents the message.\nThere are two interrelated components of RSA:\n\u2022 The choice of the public key and the private key\n\u2022 The encryption and decryption algorithm\nTo generate the public and private RSA keys, Bob performs the following steps:\n 1. Choose two large prime numbers, p and q. How large should p and q be? The \nlarger the values, the more difficult it is to break RSA, but the longer it takes \nto perform the encoding and decoding. RSA Laboratories recommends that \nthe product of p and q be on the order of 1,024 bits. For a discussion of how to \nfind large prime numbers, see [Caldwell 2012].\n 2. Compute n=pq and z = (p - 1)(q -", "doc_id": "d522fbf7-626e-421e-80ae-b1cd7645422d", "embedding": null, "doc_hash": "3bc6fcd362a30ab24a6e3d7e6349a76790c81f4fbe51697a4f7d16cddf33c6dd", "extra_info": null, "node_info": {"start": 1866250, "end": 1869865}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "54ffef70-b630-4f7c-af0f-92d4e5304291", "3": "7a228fe7-5cbc-49de-ab6e-aad6cdb1f97f"}}, "__type__": "1"}, "7a228fe7-5cbc-49de-ab6e-aad6cdb1f97f": {"__data__": {"text": "message with RSA, it is equivalent to encrypting \nthe unique integer number that represents the message.\nThere are two interrelated components of RSA:\n\u2022 The choice of the public key and the private key\n\u2022 The encryption and decryption algorithm\nTo generate the public and private RSA keys, Bob performs the following steps:\n 1. Choose two large prime numbers, p and q. How large should p and q be? The \nlarger the values, the more difficult it is to break RSA, but the longer it takes \nto perform the encoding and decoding. RSA Laboratories recommends that \nthe product of p and q be on the order of 1,024 bits. For a discussion of how to \nfind large prime numbers, see [Caldwell 2012].\n 2. Compute n=pq and z = (p - 1)(q - 1).\n 3. Choose a number, e, less than n, that has no common factors (other than 1) \nwith z. (In this case, e and z are said to be relatively prime.) The letter e is used \nsince this value will be used in encryption.\n 4. Find a number, d, such that ed - 1 is exactly divisible (that is, with no  remainder) \nby z. The letter d is used because this value will be used in decryption. Put another \nway, given e, we choose d such that\ned mod z = 1\n 5. The public key that Bob makes available to the world, K+\nB, is the pair of num-\nbers ( n, e); his private key, K-\nB, is the pair of numbers ( n, d).\nThe encryption by Alice and the decryption by Bob are done as follows:\n\u2022 Suppose Alice wants to send Bob a bit pattern represented by the integer num -\nber m (with m6n). To encode, Alice performs the exponentiation me, and then \ncomputes the integer remainder when me is divided by n. In other words, the \nencrypted value, c, of Alice\u2019s plaintext message, m, is\nc=me mod n\n The bit pattern corresponding to this ciphertext c is sent to Bob.\n\u2022 To decrypt the received ciphertext message, c, Bob computes\nm=cd mod n\nwhich requires the use of his private key ( n, d).\n636     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nAs a simple example of RSA, suppose Bob chooses p = 5 and q = 7.  (Admittedly, \nthese values are far too small to be secure.) Then n = 35 and z = 24. Bob chooses \ne = 5, since 5 and 24 have no common factors. Finally, Bob chooses d = 29, since \n5#29-1 (that is, ed - 1) is exactly divisible by 24. Bob makes the two values, n = 35  \nand e = 5, public and keeps the value d = 29 secret. Observing these two public \nvalues, suppose Alice now wants to send the letters l, o, v, and e to Bob. Interpreting \neach letter as a number between 1 and 26 (with a being 1, and z being 26), Alice and \nBob perform the encryption and decryption shown in Tables 8.2 and 8.3, respectively. \nNote that in this example, we consider each of the four letters as a distinct message. \nA more realistic example would be to convert the four letters into their 8-bit ASCII \nrepresentations and then encrypt the integer corresponding to the resulting 32-bit bit \npattern. (Such a realistic example generates numbers that are much too long to print \nin a textbook!)\nGiven that the \u201ctoy\u201d example in Tables 8.2 and 8.3 has already produced some \nextremely large numbers, and given that we saw earlier that p and q should each be \nseveral hundred bits long, several practical issues regarding RSA come to mind. \nHow does one choose large prime numbers? How does one then choose e and d? \nHow does one perform exponentiation with large numbers? A discussion of these \nimportant issues is beyond the scope of this book; see [Kaufman 1995] and the refer -\nences therein for details.Table 8.2  \u2666 Alice\u2019s RSA encryption, e = 5, n =", "doc_id": "7a228fe7-5cbc-49de-ab6e-aad6cdb1f97f", "embedding": null, "doc_hash": "b68899937be87f5c878b696b736a305da8fc126c4e42312d5c2add7d700fa9ef", "extra_info": null, "node_info": {"start": 1869889, "end": 1873424}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "d522fbf7-626e-421e-80ae-b1cd7645422d", "3": "3ca1c954-2d8c-4e06-856b-f42d96d97a81"}}, "__type__": "1"}, "3ca1c954-2d8c-4e06-856b-f42d96d97a81": {"__data__": {"text": "encrypt the integer corresponding to the resulting 32-bit bit \npattern. (Such a realistic example generates numbers that are much too long to print \nin a textbook!)\nGiven that the \u201ctoy\u201d example in Tables 8.2 and 8.3 has already produced some \nextremely large numbers, and given that we saw earlier that p and q should each be \nseveral hundred bits long, several practical issues regarding RSA come to mind. \nHow does one choose large prime numbers? How does one then choose e and d? \nHow does one perform exponentiation with large numbers? A discussion of these \nimportant issues is beyond the scope of this book; see [Kaufman 1995] and the refer -\nences therein for details.Table 8.2  \u2666 Alice\u2019s RSA encryption, e = 5, n = 35Plaintext Letter m: numeric representation meCiphertext c = me mod n\nl 12 248832 17\no 15 759375 15\nv 22 5153632 22\ne 5 3125 10\nTable 8.3  \u2666 Bob\u2019s RSA decryption, d = 29, n = 35Ciphertext c cdm = cd mod n Plaintext Letter\n17 4819685721067509150915091411825223071697 12 l\n15 127834039403948858939111232757568359375 15 o\n22 851643319086537701956194499721106030592 22 v\n10 1000000000000000000000000000000 5 e\n8.2  \u2022  PRINCIPLES OF CRYPTOGRAPHY      637\nSession Keys\nWe note here that the exponentiation required by RSA is a rather time-consuming process. \nBy contrast, DES is at least 100 times faster in software and between 1,000 and 10,000 \ntimes faster in hardware [RSA Fast 2012]. As a result, RSA is often used in practice \nin combination with symmetric key cryptography. For example, if Alice wants to send \nBob a large amount of encrypted data, she could do the following. First Alice chooses \na key that will be used to encode the data itself; this key is referred to as a session key , \nand is denoted by KS. Alice must inform Bob of the session key, since this is the shared \n symmetric key they will use with a symmetric key cipher (e.g., with DES or AES). Alice \nencrypts the session key using Bob\u2019s public key, that is, computes c=(KS)e mod n. Bob \nreceives the RSA-encrypted session key, c, and decrypts it to obtain the session key, KS. \nBob now knows the session key that Alice will use for her encrypted data transfer.\nWhy Does RSA Work?\nRSA encryption/decryption appears rather magical. Why should it be that by apply -\ning the encryption algorithm and then the decryption algorithm, one recovers the \noriginal message? In order to understand why RSA works, again denote n = pq, \nwhere p and q are the large prime numbers used in the RSA algorithm.\nRecall that, under RSA encryption, a message (uniquely represented by an  integer), \nm, is exponentiated to the power e using modulo- n arithmetic, that is,\nc = me mod n\nDecryption is performed by raising this value to the power d, again using modulo- n \narithmetic. The result of an encryption step followed by a decryption step is thus  \n(me mod n)d mod n. Let\u2019s now see what we can say about this quantity. As mentioned \nearlier, one important property of modulo arithmetic is ( a mod n)d mod n = ad mod n \nfor any values a, n, and d. Thus, using a = me in this property, we have\n(me mod n)d mod n=med mod n\nIt therefore remains to show that med mod n = m. Although we\u2019re trying to \nremove some of the magic about why RSA works, to establish this, we\u2019ll need to use a \nrather magical result from number theory here. Specifically, we\u2019ll need the result that \nsays if p and q are prime, n = pq, and z = (p - 1)(q - 1), then xy mod n is the same as \nx(y mod", "doc_id": "3ca1c954-2d8c-4e06-856b-f42d96d97a81", "embedding": null, "doc_hash": "567922197e1ec4275236bcf56ae81cba915abb5443b678c1343446cbea1914f9", "extra_info": null, "node_info": {"start": 1873421, "end": 1876867}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "7a228fe7-5cbc-49de-ab6e-aad6cdb1f97f", "3": "47934ca0-c3da-4769-bd70-1d4c6df2388e"}}, "__type__": "1"}, "47934ca0-c3da-4769-bd70-1d4c6df2388e": {"__data__": {"text": "step is thus  \n(me mod n)d mod n. Let\u2019s now see what we can say about this quantity. As mentioned \nearlier, one important property of modulo arithmetic is ( a mod n)d mod n = ad mod n \nfor any values a, n, and d. Thus, using a = me in this property, we have\n(me mod n)d mod n=med mod n\nIt therefore remains to show that med mod n = m. Although we\u2019re trying to \nremove some of the magic about why RSA works, to establish this, we\u2019ll need to use a \nrather magical result from number theory here. Specifically, we\u2019ll need the result that \nsays if p and q are prime, n = pq, and z = (p - 1)(q - 1), then xy mod n is the same as \nx(y mod z) mod n [Kaufman 1995]. Applying this result with x = m and y = ed we have\nmed mod n=m(ed mod z) mod n\nBut remember that we have chosen e and d such that ed mod z=1. This gives us\nmed mod n=m1 mod n=m\n638     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nwhich is exactly the result we are looking for! By first exponentiating to the power of \ne (that is, encrypting) and then exponentiating to the power of d (that is,  decrypting), \nwe obtain the original value, m. Even more  wonderful is the fact that if we first \nexponentiate to the power of d and then exponentiate to the power of e\u2014that is, we \nreverse the order of encryption and decryption, performing the decryption operation \nfirst and then applying the encryption operation\u2014we also obtain the original value, \nm. This wonderful result follows immediately from the modular arithmetic:\n(md mod n)e mod n=mde mod n=med mod n=(me mod n)d mod n\nThe security of RSA relies on the fact that there are no known algorithms for \nquickly factoring a number, in this case the public value n, into the primes p and q. If \none knew p and q, then given the public value e, one could easily compute the secret \nkey, d. On the other hand, it is not known whether or not there exist fast algorithms \nfor factoring a number, and in this sense, the security of RSA is not guaranteed.\nAnother popular public-key encryption algorithm is the Diffie-Hellman algo -\nrithm, which we will briefly explore in the homework problems. Diffie-Hellman \nis not as versatile as RSA in that it cannot be used to encrypt messages of arbitrary \nlength; it can be used, however, to establish a symmetric session key, which is in turn \nused to encrypt messages.\n8.3 Message Integrity and Digital Signatures\nIn the previous section we saw how encryption can be used to provide confidenti -\nality to two communicating entities. In this section we turn to the equally impor -\ntant cryptography topic of providing message integrity  (also known as message \n authentication). Along with message integrity, we will discuss two related topics in \nthis section: digital signatures and end-point authentication.\nWe define the message integrity problem using, once again, Alice and Bob. \nSuppose Bob receives a message (which may be encrypted or may be in plaintext) \nand he believes this message was sent by Alice. To authenticate this message, Bob \nneeds to verify:\n 1. The message indeed originated from Alice.\n 2. The message was not tampered with on its way to Bob.\nWe\u2019ll see in Sections 8.4 through 8.7 that this problem of message integrity is a criti -\ncal concern in just about all secure networking protocols.\nAs a specific example, consider a computer network using a link-state routing \nalgorithm (such as OSPF) for determining routes between each pair of routers in the \n8.3  \u2022  MESSAGE INTEGRITY AND DIGITAL SIGNATURES      639\nnetwork (see Chapter 5 ). In a link-state algorithm, each router needs to broadcast a", "doc_id": "47934ca0-c3da-4769-bd70-1d4c6df2388e", "embedding": null, "doc_hash": "837de7c846948e40cea2bf3190cdda879a064bd8a9299066e4503ab9e372615d", "extra_info": null, "node_info": {"start": 1876968, "end": 1880543}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "3ca1c954-2d8c-4e06-856b-f42d96d97a81", "3": "84a04cfd-1e14-4e5e-bdb9-0e74da05c032"}}, "__type__": "1"}, "84a04cfd-1e14-4e5e-bdb9-0e74da05c032": {"__data__": {"text": "may be encrypted or may be in plaintext) \nand he believes this message was sent by Alice. To authenticate this message, Bob \nneeds to verify:\n 1. The message indeed originated from Alice.\n 2. The message was not tampered with on its way to Bob.\nWe\u2019ll see in Sections 8.4 through 8.7 that this problem of message integrity is a criti -\ncal concern in just about all secure networking protocols.\nAs a specific example, consider a computer network using a link-state routing \nalgorithm (such as OSPF) for determining routes between each pair of routers in the \n8.3  \u2022  MESSAGE INTEGRITY AND DIGITAL SIGNATURES      639\nnetwork (see Chapter 5 ). In a link-state algorithm, each router needs to broadcast a \nlink-state message to all other routers in the network. A router\u2019s link-state message \nincludes a list of its directly connected neighbors and the direct costs to these neigh -\nbors. Once a router receives link-state messages from all of the other routers, it can \ncreate a complete map of the network, run its least-cost routing algorithm, and con -\nfigure its forwarding table. One relatively easy attack on the routing algorithm is for \nTrudy to distribute bogus link-state messages with incorrect link-state information. \nThus the need for message integrity\u2014when router B receives a link-state message \nfrom router A, router B should verify that router A actually created the message and, \nfurther, that no one tampered with the message in transit.\nIn this section, we describe a popular message integrity technique that is used \nby many secure networking protocols. But before doing so, we need to cover another \nimportant topic in cryptography\u2014cryptographic hash functions.\n8.3.1 Cryptographic Hash Functions\nAs shown in Figure 8.7, a hash function takes an input, m, and computes a fixed-size \nstring H(m) known as a hash. The Internet checksum (Chapter 3 ) and CRCs (Chapter 6 ) \nmeet this definition. A cryptographic hash function  is required to have the follow -\ning additional property:\n\u2022 It is computationally infeasible to find any two different messages x and y such \nthat H(x) = H(y).\nInformally, this property means that it is computationally infeasible for an \nintruder to substitute one message for another message that is protected by the hash \nFigure 8.7  \u2666 Hash functionsMany-to-one\nhash functionLong message: m\nDear Alice:\nThis is a VERY long letter\nsince there is so much to\nsay.....\n..........\n..........\nBobFixed-length\nhash: H(m)\nOpgmdvboijrtnsd\ngghPPdogm;lcvkb\n640     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nfunction. That is, if ( m, H(m)) are the message and the hash of the message created \nby the sender, then an intruder cannot forge the contents of another message, y, that \nhas the same hash value as the original message.\nLet\u2019s convince ourselves that a simple checksum, such as the Internet checksum, \nwould make a poor cryptographic hash function. Rather than performing 1s comple -\nment arithmetic (as in the Internet checksum), let us compute a checksum by treating \neach character as a byte and adding the bytes together using 4-byte chunks at a time. \nSuppose Bob owes Alice $100.99 and sends an IOU to Alice consisting of the text \nstring \u201cIOU100.99BOB .\u201d The ASCII representation (in hexadecimal notation) for \nthese letters is 49,4F,55,31,30,30,2E,39,39,42,4F,42 .\nFigure 8. 8 (top) shows that the 4-byte checksum for this message is B2 \nC1 D2 AC. A slightly different message (and a much more costly one for Bob) \nis shown in the bottom half of Figure 8.8. The messages \u201c IOU100.99BOB \u201d and", "doc_id": "84a04cfd-1e14-4e5e-bdb9-0e74da05c032", "embedding": null, "doc_hash": "233501e397a1a27daa505330ee1dceccbf1cc81a6b77832ab17b2d93b64fe404", "extra_info": null, "node_info": {"start": 1880463, "end": 1884010}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "47934ca0-c3da-4769-bd70-1d4c6df2388e", "3": "c0da706e-cda8-42d0-ae0c-bb85030eb3bb"}}, "__type__": "1"}, "c0da706e-cda8-42d0-ae0c-bb85030eb3bb": {"__data__": {"text": "-\nment arithmetic (as in the Internet checksum), let us compute a checksum by treating \neach character as a byte and adding the bytes together using 4-byte chunks at a time. \nSuppose Bob owes Alice $100.99 and sends an IOU to Alice consisting of the text \nstring \u201cIOU100.99BOB .\u201d The ASCII representation (in hexadecimal notation) for \nthese letters is 49,4F,55,31,30,30,2E,39,39,42,4F,42 .\nFigure 8. 8 (top) shows that the 4-byte checksum for this message is B2 \nC1 D2 AC. A slightly different message (and a much more costly one for Bob) \nis shown in the bottom half of Figure 8.8. The messages \u201c IOU100.99BOB \u201d and \n\u201cIOU900.19BOB \u201d have the same  checksum. Thus, this simple checksum algorithm \nviolates the requirement above. Given the original data, it is simple to find another \nset of data with the same checksum. Clearly, for security purposes, we are going to \nneed a more powerful hash function than a checksum.\nThe MD5 hash algorithm of Ron Rivest [RFC 1321] is in wide use today. It \ncomputes a 128-bit hash in a four-step process consisting of a padding step (adding \na one followed by enough zeros so that the length of the message satisfies certain \nconditions), an append step (appending a 64-bit representation of the message length \nbefore padding), an initialization of an accumulator, and a final looping step in which \nthe message\u2019s 16-word blocks are processed (mangled) in four rounds. For a descrip -\ntion of MD5 (including a C source code implementation) see [RFC 1321].Figure 8.8  \u2666  Initial message and fraudulent message have the same \n checksum!Message\nIOU1\n00.9\n9BOBASCII\nRepresentation\n49 4F 55 31\n30 30 2E 39\n39 42 4F 42\nB2 C1 D2 AC Checksum\nMessage\nIOU9\n00.1\n9BOBASCII\nRepresentation\n49 4F 55 39\n30 30 2E 31\n39 42 4F 42\nB2 C1 D2 AC Checksum\n8.3  \u2022  MESSAGE INTEGRITY AND DIGITAL SIGNATURES      641\nThe second major hash algorithm in use today is the Secure Hash Algorithm \n(SHA-1) [FIPS 1995]. This algorithm is based on principles similar to those used \nin the design of MD4 [RFC 1320], the predecessor to MD5. SHA-1, a US federal \nstandard, is required for use whenever a cryptographic hash algorithm is needed for \nfederal applications. It produces a 160-bit message digest. The longer output length \nmakes SHA-1 more secure.\n8.3.2 Message Authentication Code\nLet\u2019s now return to the problem of message integrity. Now that we understand hash \nfunctions, let\u2019s take a first stab at how we might perform message integrity:\n 1. Alice creates message m and calculates the hash H(m) (for example with  \nSHA-1).\n 2. Alice then appends H(m) to the message m, creating an extended message  \n(m, H(m)), and sends the extended message to Bob.\n 3. Bob receives an extended message ( m, h) and calculates H(m). If H(m) = h, \nBob concludes that everything is fine.\nThis approach is obviously flawed. Trudy can create a bogus message m\u00b4 in which \nshe says she is Alice, calculate H(m\u00b4), and send Bob ( m\u00b4, H(m\u00b4)). When Bob receives \nthe message, everything checks out in step 3, so Bob doesn\u2019t suspect any funny \n business.\nTo perform message integrity, in addition to using cryptographic hash functions, \nAlice and Bob will need a shared secret s. This shared secret, which is nothing more \nthan a string of bits, is called the authentication key . Using this shared secret, mes -\nsage integrity can be performed as follows:\n 1. Alice creates message m, concatenates", "doc_id": "c0da706e-cda8-42d0-ae0c-bb85030eb3bb", "embedding": null, "doc_hash": "79fd0831e919e3f55da4dd4e17a620f9b8972909025367be2dc8c5dc37426ff1", "extra_info": null, "node_info": {"start": 1884076, "end": 1887466}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "84a04cfd-1e14-4e5e-bdb9-0e74da05c032", "3": "4078330f-c85d-4ef9-ac4c-c66d3ce845c8"}}, "__type__": "1"}, "4078330f-c85d-4ef9-ac4c-c66d3ce845c8": {"__data__": {"text": "message ( m, h) and calculates H(m). If H(m) = h, \nBob concludes that everything is fine.\nThis approach is obviously flawed. Trudy can create a bogus message m\u00b4 in which \nshe says she is Alice, calculate H(m\u00b4), and send Bob ( m\u00b4, H(m\u00b4)). When Bob receives \nthe message, everything checks out in step 3, so Bob doesn\u2019t suspect any funny \n business.\nTo perform message integrity, in addition to using cryptographic hash functions, \nAlice and Bob will need a shared secret s. This shared secret, which is nothing more \nthan a string of bits, is called the authentication key . Using this shared secret, mes -\nsage integrity can be performed as follows:\n 1. Alice creates message m, concatenates s with m to create m + s, and calculates \nthe hash H(m + s) (for example with SHA-1). H(m + s) is called the message \nauthentication code (MAC) .\n 2. Alice then appends the MAC to the message m, creating an extended message \n(m, H (m + s)), and sends the extended message to Bob.\n 3. Bob receives an extended message ( m, h) and knowing s, calculates the MAC \nH(m + s). If H(m + s) = h, Bob concludes that everything is fine.\nA summary of the procedure is shown in Figure 8.9. Readers should note that the \nMAC here (standing for \u201cmessage authentication code\u201d) is not the same MAC used \nin link-layer protocols (standing for \u201cmedium access control\u201d)!\nOne nice feature of a MAC is that it does not require an encryption algorithm. \nIndeed, in many applications, including the link-state routing algorithm described \nearlier, communicating entities are only concerned with message integrity and are not \nconcerned with message confidentiality. Using a MAC, the entities can authenticate \n642     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nthe messages they send to each other without having to integrate complex encryption \nalgorithms into the integrity process.\nAs you might expect, a number of different standards for MACs have been pro -\nposed over the years. The most popular standard today is HMAC , which can be used \neither with MD5 or SHA-1. HMAC actually runs data and the authentication key \nthrough the hash function twice [Kaufman 1995; RFC 2104].\nThere still remains an important issue. How do we distribute the shared authen-\ntication key to the communicating entities? For example, in the link-state routing \nalgorithm, we would somehow need to distribute the secret authentication key to \neach of the routers in the autonomous system. (Note that the routers can all use the \nsame authentication key.) A network administrator could actually accomplish this by \nphysically visiting each of the routers. Or, if the network administrator is a lazy guy, \nand if each router has its own public key, the network administrator could distribute \nthe authentication key to any one of the routers by encrypting it with the router\u2019s \npublic key and then sending the encrypted key over the network to the router.\n8.3.3 Digital Signatures\nThink of the number of the times you\u2019ve signed your name to a piece of paper dur -\ning the last week. You sign checks, credit card receipts, legal documents, and let -\nters. Your signature attests to the fact that you (as opposed to someone else) have \nacknowledged and/or agreed with the document\u2019s contents. In a digital world, one \noften wants to indicate the owner or creator of a document, or to signify one\u2019s agree -\nment with a document\u2019s content. A digital signature  is a cryptographic technique \nfor achieving these goals in a digital world.\nJust as with handwritten signatures, digital signing should be done in a way that \nis verifiable and nonforgeable. That is, it must be possible to prove that a document Figure 8.9  \u2666 Message authentication code (MAC)H(.)H(.)\nmm\nm\nms\nss\n+", "doc_id": "4078330f-c85d-4ef9-ac4c-c66d3ce845c8", "embedding": null, "doc_hash": "370230dbc78245f79d93b7c6c14ea782e86a80b2976cd49550757a087365a266", "extra_info": null, "node_info": {"start": 1887407, "end": 1891131}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "c0da706e-cda8-42d0-ae0c-bb85030eb3bb", "3": "bfdfda61-6111-43b9-a35f-dc0b71b60778"}}, "__type__": "1"}, "bfdfda61-6111-43b9-a35f-dc0b71b60778": {"__data__": {"text": "-\ning the last week. You sign checks, credit card receipts, legal documents, and let -\nters. Your signature attests to the fact that you (as opposed to someone else) have \nacknowledged and/or agreed with the document\u2019s contents. In a digital world, one \noften wants to indicate the owner or creator of a document, or to signify one\u2019s agree -\nment with a document\u2019s content. A digital signature  is a cryptographic technique \nfor achieving these goals in a digital world.\nJust as with handwritten signatures, digital signing should be done in a way that \nis verifiable and nonforgeable. That is, it must be possible to prove that a document Figure 8.9  \u2666 Message authentication code (MAC)H(.)H(.)\nmm\nm\nms\nss\n+ Internet\nCompare\nKey:\n= Message\n= Shared secr etH(m+s)H(m+s)\n8.3  \u2022  MESSAGE INTEGRITY AND DIGITAL SIGNATURES      643\nsigned by an individual was indeed signed by that individual (the signature must be \nverifiable) and that only that individual could have signed the document (the signa -\nture cannot be forged).\nLet\u2019s now consider how we might design a digital signature scheme. Observe \nthat when Bob signs a message, Bob must put something on the message that is \nunique to him. Bob could consider attaching a MAC for the signature, where the \nMAC is created by appending his key (unique to him) to the message, and then tak -\ning the hash. But for Alice to verify the signature, she must also have a copy of the \nkey, in which case the key would not be unique to Bob. Thus, MACs are not going \nto get the job done here.\nRecall that with public-key cryptography, Bob has both a public and private \nkey, with both of these keys being unique to Bob. Thus, public-key cryptography is \nan excellent candidate for providing digital signatures. Let us now examine how it \nis done.\nSuppose that Bob wants to digitally sign a document, m. We can think of the \ndocument as a file or a message that Bob is going to sign and send. As shown in \nFigure 8. 10, to sign this document, Bob simply uses his private key, K-\nB, to compute \nK-\nB(m). At first, it might seem odd that Bob is using his private key (which, as we \nsaw in Section 8.2, was used to decrypt a message that had been encrypted with his \npublic key) to sign a document. But recall that encryption and decryption are nothing \nmore than mathematical operations (exponentiation to the power of e or d in RSA; \nsee Section 8.2) and recall that Bob\u2019s goal is not to scramble or obscure the contents \nof the document, but rather to sign the document in a manner that is verifiable and \nnonforgeable. Bob\u2019s digital signature of the document is K-\nB(m).\nDoes the digital signature K-\nB(m) meet our requirements of being verifiable and \nnonforgeable? Suppose Alice has m and K-\nB(m). She wants to prove in court (being \nFigure 8.10  \u2666 Creating a digital signature for a documentEncryption\nalgorithmMessage: m\nBob\u2019s private\nkey, KB\u2013Dear Alice:\nSorry I have been unable\nto write for so long. Since\nwe.....\n..........\n..........\nBobSigned message:\nKB\u2013 (m)\nfadfg54986fgnzmcnv\nT98734ngldskg02j\nser09tugkjd\ufb02g\n..........\n644     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nlitigious) that Bob had indeed signed the document and was the only person who \ncould have possibly signed the document. Alice takes Bob\u2019s public key, K+\nB, and \napplies it to the digital signature, K-\nB(m), associated with the document, m. That is, \nshe computes K+\nB(K-\nB(m)), and voil\u00e0, with a dramatic flurry, she produces m, which \nexactly matches the", "doc_id": "bfdfda61-6111-43b9-a35f-dc0b71b60778", "embedding": null, "doc_hash": "f5651639784d3c8848858e00b58c226d3987bc6079030b3d75dcfbd4bd668e80", "extra_info": null, "node_info": {"start": 1891112, "end": 1894594}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "4078330f-c85d-4ef9-ac4c-c66d3ce845c8", "3": "abd9322f-9a53-485a-adde-d19475fb0893"}}, "__type__": "1"}, "abd9322f-9a53-485a-adde-d19475fb0893": {"__data__": {"text": "write for so long. Since\nwe.....\n..........\n..........\nBobSigned message:\nKB\u2013 (m)\nfadfg54986fgnzmcnv\nT98734ngldskg02j\nser09tugkjd\ufb02g\n..........\n644     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nlitigious) that Bob had indeed signed the document and was the only person who \ncould have possibly signed the document. Alice takes Bob\u2019s public key, K+\nB, and \napplies it to the digital signature, K-\nB(m), associated with the document, m. That is, \nshe computes K+\nB(K-\nB(m)), and voil\u00e0, with a dramatic flurry, she produces m, which \nexactly matches the original document! Alice then argues that only Bob could have \nsigned the document, for the following reasons:\n\u2022 Whoever signed the message must have used the private key, K-\nB, in computing \nthe signature K-\nB(m), such that K+\nB(K-\nB(m))=m.\n\u2022 The only person who could have known the private key, K-\nB, is Bob. Recall from \nour discussion of RSA in Section 8.2 that knowing the public key, K+\nB, is of no \nhelp in learning the private key, K-\nB. Therefore, the only person who could know \nK-\nB is the person who generated the pair of keys, ( K+\nB, K-\nB), in the first place, Bob. \n(Note that this assumes, though, that Bob has not given K-\nB to anyone, nor has \nanyone stolen K-\nB from Bob.)\nIt is also important to note that if the original document, m, is ever modified to \nsome alternate form, m\u00b4, the signature that Bob created for m will not be valid for m\u00b4, \nsince K+\nB(K-\nB(m)) does not equal m\u00b4. Thus we see that digital signatures also provide \nmessage integrity, allowing the receiver to verify that the message was unaltered as \nwell as the source of the message.\nOne concern with signing data by encryption is that encryption and decryption \nare computationally expensive. Given the overheads of encryption and decryption, \nsigning data via complete encryption/decryption can be overkill. A more efficient \napproach is to introduce hash functions into the digital signature. Recall from \n Section 8.3.2 that a hash algorithm takes a message, m, of arbitrary length and com -\nputes a fixed-length \u201cfingerprint\u201d of the message, denoted by H(m). Using a hash \nfunction, Bob signs the hash of a message rather than the message itself, that is, \nBob calculates K-\nB(H(m)). Since H(m) is generally much smaller than the original \nmessage m, the computational effort required to create the digital signature is sub -\nstantially reduced.\nIn the context of Bob sending a message to Alice, Figure 8.11 provides a sum -\nmary of the operational procedure of creating a digital signature. Bob puts his origi -\nnal long message through a hash function. He then digitally signs the resulting hash \nwith his private key. The original message (in cleartext) along with the digitally \nsigned message digest (henceforth referred to as the digital signature) is then sent  \nto Alice. Figure 8.12 provides a summary of the operational procedure of the sig -\nnature. Alice applies the sender\u2019s public key to the message to obtain a hash result. \nAlice also applies the hash function to the cleartext message to obtain a second hash \nresult. If the two hashes match, then Alice can be sure about the integrity and author \nof the message.\nBefore moving on, let\u2019s briefly compare digital signatures with MACs, since they \nhave parallels, but also have important subtle differences. Both digital signatures and \n8.3  \u2022  MESSAGE INTEGRITY AND DIGITAL SIGNATURES      645\nMACs start with a message (or a document). To create a MAC out of the message, \nwe append an authentication key to the message, and", "doc_id": "abd9322f-9a53-485a-adde-d19475fb0893", "embedding": null, "doc_hash": "a32c0ee3c23fcc9fc541ff5d25c16af5365ebe85af256eca8558e55f5ffebc43", "extra_info": null, "node_info": {"start": 1894710, "end": 1898253}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "bfdfda61-6111-43b9-a35f-dc0b71b60778", "3": "932a95a6-61b0-4e1d-933c-6af76fab904f"}}, "__type__": "1"}, "932a95a6-61b0-4e1d-933c-6af76fab904f": {"__data__": {"text": "is then sent  \nto Alice. Figure 8.12 provides a summary of the operational procedure of the sig -\nnature. Alice applies the sender\u2019s public key to the message to obtain a hash result. \nAlice also applies the hash function to the cleartext message to obtain a second hash \nresult. If the two hashes match, then Alice can be sure about the integrity and author \nof the message.\nBefore moving on, let\u2019s briefly compare digital signatures with MACs, since they \nhave parallels, but also have important subtle differences. Both digital signatures and \n8.3  \u2022  MESSAGE INTEGRITY AND DIGITAL SIGNATURES      645\nMACs start with a message (or a document). To create a MAC out of the message, \nwe append an authentication key to the message, and then take the hash of the result. \nNote that neither public key nor symmetric key encryption is involved in creating the \nMAC. To create a digital signature, we first take the hash of the message and then \nencrypt the message with our private key (using public key cryptography). Thus, a \ndigital signature is a \u201cheavier\u201d technique, since it requires an underlying Public Key \nInfrastructure (PKI) with certification authorities as described below. We\u2019ll see in \nSection 8. 4 that PGP\u2014a popular secure e-mail system\u2014uses digital signatures for \nmessage integrity. We\u2019ve seen already that OSPF uses MACs for message integrity. \nWe\u2019ll see in Sections 8.5 and 8.6 that MACs are also used for popular transport-layer \nand network-layer security protocols.\nPublic Key Certification\nAn important application of digital signatures is public key certification , that is, \ncertifying that a public key belongs to a specific entity. Public key certification is \nused in many popular secure networking protocols, including IPsec and SSL.\nTo gain insight into this problem, let\u2019s consider an Internet-commerce version of \nthe classic \u201cpizza prank.\u201d Alice is in the pizza delivery business and accepts orders Figure 8.11  \u2666 Sending a digitally signed messageBob\u2019s private\nkey, KB\u2013Many-to-one\nhash functionLong message\nDear Alice:\nThis is a VERY long letter\nsince there is so much to\nsay.....\n..........\n..........\nBobFixed-length\nhash\nOpgmdvboijrtnsd\ngghPPdogm;lcvkb\nSigned\nhash Package to send\nto Alice\nFgkopdgoo69cmxw\n54psdterma[asofmzEncryption\nalgorithm\n646     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nover the Internet. Bob, a pizza lover, sends Alice a plaintext message that includes \nhis home address and the type of pizza he wants. In this message, Bob also includes \na digital signature (that is, a signed hash of the original plaintext message) to prove to \nAlice that he is the true source of the message. To verify the signature, Alice obtains \nBob\u2019s public key (perhaps from a public key server or from the e-mail message) \nand checks the digital signature. In this manner she makes sure that Bob, rather than \nsome adolescent prankster, placed the order.\nThis all sounds fine until clever Trudy comes along. As shown in Figure 8.13, \nTrudy is indulging in a prank. She sends a message to Alice in which she says she is \nBob, gives Bob\u2019s home address, and orders a pizza. In this message she also includes \nher (Trudy\u2019s) public key, although Alice naturally assumes it is Bob\u2019s public key. \nTrudy also attaches a digital signature, which was created with her own (Trudy\u2019s) \nprivate key. After receiving the message, Alice applies Trudy\u2019s public key (thinking \nthat it is Bob\u2019s) to the digital signature and concludes that the plaintext message was Bob\u2019s public\nkey, KB+\nLong message\nDear Alice:\nThis is a VERY long letter\nsince there is so much", "doc_id": "932a95a6-61b0-4e1d-933c-6af76fab904f", "embedding": null, "doc_hash": "f51edb373aad7dd4da8cc7d456af6d5960570b4925df0425430952fb215b703f", "extra_info": null, "node_info": {"start": 1898126, "end": 1901715}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "abd9322f-9a53-485a-adde-d19475fb0893", "3": "4a4bede2-c2ca-49b0-9016-63b519ba93b4"}}, "__type__": "1"}, "4a4bede2-c2ca-49b0-9016-63b519ba93b4": {"__data__": {"text": "until clever Trudy comes along. As shown in Figure 8.13, \nTrudy is indulging in a prank. She sends a message to Alice in which she says she is \nBob, gives Bob\u2019s home address, and orders a pizza. In this message she also includes \nher (Trudy\u2019s) public key, although Alice naturally assumes it is Bob\u2019s public key. \nTrudy also attaches a digital signature, which was created with her own (Trudy\u2019s) \nprivate key. After receiving the message, Alice applies Trudy\u2019s public key (thinking \nthat it is Bob\u2019s) to the digital signature and concludes that the plaintext message was Bob\u2019s public\nkey, KB+\nLong message\nDear Alice:\nThis is a VERY long letter\nsince there is so much to\nsay.....\n..........\n..........\nBob\nFixed-length\nhash\nOpgmdvboijrtnsd\ngghPPdogm;lcvkbSigned\nhash\nFgkopdgoo69cmxw\n54psdterma[asofmz\nMany-to-one\nhash functionCompareFixed-length\nhash\nOpgmdvboijrtnsd\ngghPPdogm;lcvkbEncryption\nalgorithm\nFigure 8.12  \u2666 Verifying a signed message\n8.3  \u2022  MESSAGE INTEGRITY AND DIGITAL SIGNATURES      647\nindeed created by Bob. Bob will be very surprised when the delivery person brings a \npizza with pepperoni and anchovies to his home!\nWe see from this example that for public key cryptography to be useful, you \nneed to be able to verify that you have the actual public key of the entity (person, \nrouter, browser, and so on) with whom you want to communicate. For example, \nwhen Alice wants to communicate with Bob using public key cryptography, she \nneeds to verify that the public key that is supposed to be Bob\u2019s is indeed Bob\u2019s.\nBinding a public key to a particular entity is typically done by a Certification \nAuthority (CA) , whose job is to validate identities and issue certificates. A CA has \nthe following roles:\n 1. A CA verifies that an entity (a person, a router, and so on) is who it says it is. \nThere are no mandated procedures for how certification is done. When dealing \nwith a CA, one must trust the CA to have performed a suitably rigorous iden-\ntity verification. For example, if Trudy were able to walk into the Fly-by-Night Figure 8.13  \u2666 Trudy masquerades as Bob using public key cryptographyTrudy\u2019 s private\nkey, KT\u2013\nTrudy\u2019 s public\nkey, KT+Signed (using\nTrudy's private key)\nmessage digest\nFgkopdgoo69cmxw\n54psdterma[asofmzMessage\nAlice,\nDeliver a pizza to me.\n                               BobMany-to-one\nhash function\nAlice uses T rudy\u2019 s\npublic key, thinking\nit is Bob\u2019s, and\nconcludes the\nmessage is from BobPIZZAEncryption\nalgorithm\n648     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nCA and simply announce \u201cI am Alice\u201d and receive certificates associated  \nwith the identity of Alice, then one shouldn\u2019t put much faith in public keys \ncertified by the Fly-by-Night CA. On the other hand, one might (or might not!) \nbe more willing to trust a CA that is part of a federal or state program. You  \ncan trust the identity associated with a public key only to the extent to which \nyou can trust a CA and its identity verification techniques. What a tangled  \nweb of trust we spin!\n 2. Once the CA verifies the identity of the entity, the CA creates a certificate  \nthat binds the public key of the entity to the identity. The certificate contains \nthe public key and globally unique identifying information about the owner of", "doc_id": "4a4bede2-c2ca-49b0-9016-63b519ba93b4", "embedding": null, "doc_hash": "68dafb431ac5f61f1f9e2e1b62294416cd4333961a8a164b0949e1bc8d6eced0", "extra_info": null, "node_info": {"start": 1901766, "end": 1905025}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "932a95a6-61b0-4e1d-933c-6af76fab904f", "3": "304aefc4-ebf0-443e-b501-a0750afc67a5"}}, "__type__": "1"}, "304aefc4-ebf0-443e-b501-a0750afc67a5": {"__data__": {"text": "IN COMPUTER NETWORKS\nCA and simply announce \u201cI am Alice\u201d and receive certificates associated  \nwith the identity of Alice, then one shouldn\u2019t put much faith in public keys \ncertified by the Fly-by-Night CA. On the other hand, one might (or might not!) \nbe more willing to trust a CA that is part of a federal or state program. You  \ncan trust the identity associated with a public key only to the extent to which \nyou can trust a CA and its identity verification techniques. What a tangled  \nweb of trust we spin!\n 2. Once the CA verifies the identity of the entity, the CA creates a certificate  \nthat binds the public key of the entity to the identity. The certificate contains \nthe public key and globally unique identifying information about the owner of \nthe public key (for example, a human name or an IP address). The certificate is \ndigitally signed by the CA. These steps are shown in Figure 8.14.\nLet us now see how certificates can be used to combat pizza-ordering prank -\nsters, like Trudy, and other undesirables. When Bob places his order he also sends his \nCA-signed certificate. Alice uses the CA\u2019s public key to check the validity of Bob\u2019s \ncertificate and extract Bob\u2019s public key.\nBoth the International Telecommunication Union (ITU) and the IETF have \ndeveloped standards for CAs. ITU X.509 [ITU 2005a] specifies an authentication \nservice as well as a specific syntax for certificates. [RFC 1422] describes CA-based \nkey management for use with secure Internet e-mail. It is compatible with X.509 but \ngoes beyond X.509 by establishing procedures and conventions for a key manage -\nment architecture. Table 8.4 describes some of the important fields in a certificate.Figure 8.14  \u2666 Bob has his public key certified by the CABob\u2019s CA-signed\ncerti\ufb01cate containing\nhis public key, KB+Certi\ufb01cation\nAuthority (CA)(KB+, B)CA\u2019s private\nkey, KCA\u2013\nEncryption\nalgorithm\n8.4  \u2022  END-POINT AUTHENTICATION      649\n8.4 End-Point Authentication\nEnd-point authentication  is the process of one entity proving its identity to another \nentity over a computer network, for example, a user proving its identity to an e-mail \nserver. As humans, we authenticate each other in many ways: We recognize each \n other\u2019s faces when we meet, we recognize each other\u2019s voices on the telephone, we are \nauthenticated by the customs official who checks us against the picture on our passport.\nIn this section, we consider how one party can authenticate another party when \nthe two are communicating over a network. We focus here on authenticating a \u201clive\u201d \nparty, at the point in time when communication is actually occurring. A concrete \nexample is a user authenticating him or herself to an e-mail server. This is a subtly \ndifferent problem from proving that a message received at some point in the past did \nindeed come from that claimed sender, as studied in Section 8.3.\nWhen performing authentication over the network, the communicating parties \ncannot rely on biometric information, such as a visual appearance or a voiceprint. \nIndeed, we will see in our later case studies that it is often network elements such as \nrouters and client/server processes that must authenticate each other. Here, authen -\ntication must be done solely on the basis of messages and data exchanged as part of \nan authentication protocol . Typically, an authentication protocol would run before  \nthe two communicating parties run some other protocol (for example, a reliable data \ntransfer protocol, a routing information exchange protocol, or an e-mail protocol). \nThe authentication protocol first establishes the identities of the parties to each oth -\ner\u2019s satisfaction; only after authentication do the parties get down to the work at hand.\nAs in the case of our development of a reliable data transfer (rdt) protocol in Chapter \n3, we will find it instructive here to develop various versions of an", "doc_id": "304aefc4-ebf0-443e-b501-a0750afc67a5", "embedding": null, "doc_hash": "2e4fffbb8ecf513749effa070e9450c0af0b230c84bf93e1b578e0d7e33d1a3b", "extra_info": null, "node_info": {"start": 1904961, "end": 1908842}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "4a4bede2-c2ca-49b0-9016-63b519ba93b4", "3": "a34c95e5-ed3a-455c-9b6f-738ab3cee1b9"}}, "__type__": "1"}, "a34c95e5-ed3a-455c-9b6f-738ab3cee1b9": {"__data__": {"text": "studies that it is often network elements such as \nrouters and client/server processes that must authenticate each other. Here, authen -\ntication must be done solely on the basis of messages and data exchanged as part of \nan authentication protocol . Typically, an authentication protocol would run before  \nthe two communicating parties run some other protocol (for example, a reliable data \ntransfer protocol, a routing information exchange protocol, or an e-mail protocol). \nThe authentication protocol first establishes the identities of the parties to each oth -\ner\u2019s satisfaction; only after authentication do the parties get down to the work at hand.\nAs in the case of our development of a reliable data transfer (rdt) protocol in Chapter \n3, we will find it instructive here to develop various versions of an authentication pro -\ntocol, which we will call ap (authentication protocol), and poke holes in each version Table 8.4  \u2666 Selected fields in an X.509 and RFC 1422 public keyField Name Description\nVersion Version number of X.509 specification\nSerial number CA-issued unique identifier for a certificate\nSignature Specifies the algorithm used by CA to sign this certificate\nIssuer name Identity of CA issuing this certificate, in distinguished name (DN) [RFC 4514] format\nValidity period Start and end of period of validity for certificate\nSubject name Identity of entity whose public key is associated with this certificate, in DN format\nSubject public key The subject\u2019s public key as well indication of the public key algorithm (and algorithm \nparameters) to be used with this key\n650     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nas we proceed. (If you enjoy this stepwise evolution of a design, you might also enjoy \n[Bryant 1988], which recounts a fictitious narrative between designers of an open-  \nnetwork authentication system, and their discovery of the many subtle issues involved.)\nLet\u2019s assume that Alice needs to authenticate herself to Bob.\n8.4.1 Authentication Protocol ap1.0\nPerhaps the simplest authentication protocol we can imagine is one where Alice sim -\nply sends a message to Bob saying she is Alice. This protocol is shown in Figure 8.15. \nThe flaw here is obvious\u2014there is no way for Bob actually to know that the person \nsending the message \u201cI am Alice\u201d is indeed Alice. For example, Trudy (the intruder) \ncould just as well send such a message.\n8.4.2 Authentication Protocol ap2.0\nIf Alice has a well-known network address (e.g., an IP address) from which she \nalways communicates, Bob could attempt to authenticate Alice by verifying that \nthe source address on the IP datagram carrying the authentication message matches \nAlice\u2019s well-known address. In this case, Alice would be authenticated. This might \nstop a very network-naive intruder from impersonating Alice, but it wouldn\u2019t stop \nthe determined student studying this book, or many others!\nFrom our study of the network and data link layers, we know that it is not that \nhard (for example, if one had access to the operating system code and could build \none\u2019s own operating system kernel, as is the case with Linux and several other \nfreely available operating systems) to create an IP datagram, put whatever IP source \naddress we want (for example, Alice\u2019s well-known IP address) into the IP datagram, \nand send the datagram over the link-layer protocol to the first-hop router. From then Figure 8.15  \u2666 Protocol ap1.0  and a failure scenarioAlice\nI am AliceBob\nTrudyTrudyAlice\nI am AliceBob\n8.4  \u2022  END-POINT AUTHENTICATION      651\non, the incorrectly source-addressed datagram would be dutifully forwarded to Bob. \nThis approach, shown in Figure 8.16, is a form of IP spoofing. IP spoofing can be \navoided if Trudy\u2019s first-hop router is configured to forward only datagrams con -\ntaining Trudy\u2019s IP source address", "doc_id": "a34c95e5-ed3a-455c-9b6f-738ab3cee1b9", "embedding": null, "doc_hash": "9ce608ddbac01903f29872ef4c338faaf9237a729d3a7ebb8060ad96f28181b7", "extra_info": null, "node_info": {"start": 1908777, "end": 1912601}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "304aefc4-ebf0-443e-b501-a0750afc67a5", "3": "3d57c494-6517-4132-85de-11d7c016c3ee"}}, "__type__": "1"}, "3d57c494-6517-4132-85de-11d7c016c3ee": {"__data__": {"text": "put whatever IP source \naddress we want (for example, Alice\u2019s well-known IP address) into the IP datagram, \nand send the datagram over the link-layer protocol to the first-hop router. From then Figure 8.15  \u2666 Protocol ap1.0  and a failure scenarioAlice\nI am AliceBob\nTrudyTrudyAlice\nI am AliceBob\n8.4  \u2022  END-POINT AUTHENTICATION      651\non, the incorrectly source-addressed datagram would be dutifully forwarded to Bob. \nThis approach, shown in Figure 8.16, is a form of IP spoofing. IP spoofing can be \navoided if Trudy\u2019s first-hop router is configured to forward only datagrams con -\ntaining Trudy\u2019s IP source address [RFC 2827]. However, this capability is not uni -\nversally deployed or enforced. Bob would thus be foolish to assume that Trudy\u2019s \nnetwork manager (who might be Trudy herself) had configured Trudy\u2019s first-hop \nrouter to forward only appropriately addressed datagrams.\n8.4.3 Authentication Protocol ap3.0\nOne classic approach to authentication is to use a secret password. The password is \na shared secret between the authenticator and the person being authenticated. Gmail, \nFacebook, telnet, FTP, and many other services use password authentication. In pro -\ntocol ap3.0, Alice thus sends her secret password to Bob, as shown in Figure 8.17.\nSince passwords are so widely used, we might suspect that protocol ap3.0  is \nfairly secure. If so, we\u2019d be wrong! The security flaw here is clear. If Trudy eaves -\ndrops on Alice\u2019s communication, then she can learn Alice\u2019s password. Lest you think \nthis is unlikely, consider the fact that when you Telnet to another machine and log  \nin, the login password is sent unencrypted to the Telnet server. Someone connected \nto the Telnet client or server\u2019s LAN can possibly sniff (read and store) all packets \ntransmitted on the LAN and thus steal the login password. In fact, this is a well-\nknown approach for stealing passwords (see, for example, [Jimenez 1997]). Such a \nthreat is obviously very real, so ap3.0  clearly won\u2019t do.\n8.4.4 Authentication Protocol ap3.1\nOur next idea for fixing ap3.0 is naturally to encrypt the password. By encrypting \nthe password, we can prevent Trudy from learning Alice\u2019s password. If we assume Figure 8.16  \u2666 Protocol ap2.0  and a failure scenarioAlice\nI am Alice\nAlice\u2019s IP addr.Bob\nTrudyAlice\nI am Alice\nAlice\u2019s IP addr.Bob\nTrudy\n652     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nthat Alice and Bob share a symmetric secret key, KA-B, then Alice can encrypt the \npassword and send her identification message, \u201c I am Alice ,\u201d and her encrypted \npassword to Bob. Bob then decrypts the password and, assuming the password is cor -\nrect, authenticates Alice. Bob feels comfortable in authenticating Alice since Alice \nnot only knows the password, but also knows the shared secret key value needed to \nencrypt the password. Let\u2019s call this protocol ap3.1 .\nWhile it is true that ap3.1  prevents Trudy from learning Alice\u2019s password, the \nuse of cryptography here does not solve the authentication problem. Bob is subject \nto a playback attack : Trudy need only eavesdrop on Alice\u2019s communication, record \nthe encrypted version of the password, and play back the encrypted version of the \npassword to Bob to pretend that she is Alice. The use of an encrypted password in \nap3.1  doesn\u2019t make the situation manifestly different from that of protocol ap3.0  in \nFigure 8.17.\n8.4.5 Authentication Protocol ap4.0\nThe failure scenario in Figure 8.17 resulted from the fact that Bob could not distin -\nguish between the original authentication of", "doc_id": "3d57c494-6517-4132-85de-11d7c016c3ee", "embedding": null, "doc_hash": "0c6d0a2c72c29ec54e57271e2e731126ff7ed345cf86ac7dd072fac96a5ca386", "extra_info": null, "node_info": {"start": 1912769, "end": 1916311}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "a34c95e5-ed3a-455c-9b6f-738ab3cee1b9", "3": "ce91a5ba-ee74-4db3-ae03-be4fa4670970"}}, "__type__": "1"}, "ce91a5ba-ee74-4db3-ae03-be4fa4670970": {"__data__": {"text": "the password. Let\u2019s call this protocol ap3.1 .\nWhile it is true that ap3.1  prevents Trudy from learning Alice\u2019s password, the \nuse of cryptography here does not solve the authentication problem. Bob is subject \nto a playback attack : Trudy need only eavesdrop on Alice\u2019s communication, record \nthe encrypted version of the password, and play back the encrypted version of the \npassword to Bob to pretend that she is Alice. The use of an encrypted password in \nap3.1  doesn\u2019t make the situation manifestly different from that of protocol ap3.0  in \nFigure 8.17.\n8.4.5 Authentication Protocol ap4.0\nThe failure scenario in Figure 8.17 resulted from the fact that Bob could not distin -\nguish between the original authentication of Alice and the later playback of Alice\u2019s \noriginal authentication. That is, Bob could not tell if Alice was live (that is, was \ncurrently really on the other end of the connection) or whether the messages he was \nreceiving were a recorded playback of a previous authentication of Alice. The very \n(very) observant reader will recall that the three-way TCP handshake protocol needed Figure 8.17  \u2666 Protocol ap3.0  and a failure scenarioAlice\nI am Alice,\npassword\nOKBob\nTrudyAlice\nI am Alice,\npasswordOKBob\nTrudy\nTape recorderKey:\n8.4  \u2022  END-POINT AUTHENTICATION      653\nto address the same problem\u2014the server side of a TCP connection did not want to \naccept a connection if the received SYN segment was an old copy (retransmission) \nof a SYN segment from an earlier connection. How did the TCP server side solve \nthe problem of determining whether the client was really live? It chose an initial \nsequence number that had not been used in a very long time, sent that number to the \nclient, and then waited for the client to respond with an ACK segment containing that \nnumber. We can adopt the same idea here for authentication purposes.\nA nonce  is a number that a protocol will use only once in a lifetime. That is, \nonce a protocol uses a nonce, it will never use that number again. Our ap4.0  protocol \nuses a nonce as follows:\n 1. Alice sends the message \u201c I am Alice \u201d to Bob.\n 2. Bob chooses a nonce, R, and sends it to Alice.\n 3. Alice encrypts the nonce using Alice and Bob\u2019s symmetric secret key, KA-B, \nand sends the encrypted nonce, KA-B (R), back to Bob. As in protocol ap3.1 , \nit is the fact that Alice knows KA-B and uses it to encrypt a value that lets Bob \nknow that the message he receives was generated by Alice. The nonce is used \nto ensure that Alice is live.\n 4. Bob decrypts the received message. If the decrypted nonce equals the nonce he \nsent Alice, then Alice is authenticated.\nProtocol ap4.0  is illustrated in Figure 8.18. By using the once-in-a-lifetime \nvalue, R, and then checking the returned value, KA-B (R), Bob can be sure that Alice \nis both who she says she is (since she knows the secret key value needed to encrypt \nR) and live (since she has encrypted the nonce, R, that Bob just created).\nThe use of a nonce and symmetric key cryptography forms the basis of ap4.0 . A \nnatural question is whether we can use a nonce and public key cryptography (rather \nthan symmetric key cryptography) to solve the authentication problem. This issue is \nexplored in the problems at the end of the chapter.\nFigure 8.18  \u2666 Protocol ap4.0  and a failure scenarioAlice\nR\nKA\u2013B(R)I am AliceBob\n654     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\n8.5 Securing E-Mail\nIn previous sections, we examined fundamental issues in network security, including \nsymmetric key and public key cryptography, end-point authentication, key distribu", "doc_id": "ce91a5ba-ee74-4db3-ae03-be4fa4670970", "embedding": null, "doc_hash": "93b94669ace487595422b4f245d1f0687c0d6364e56f5d9126722580cb1f5247", "extra_info": null, "node_info": {"start": 1916221, "end": 1919807}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "3d57c494-6517-4132-85de-11d7c016c3ee", "3": "00f6ce1f-02b4-4958-b207-215e73b12b99"}}, "__type__": "1"}, "00f6ce1f-02b4-4958-b207-215e73b12b99": {"__data__": {"text": "she has encrypted the nonce, R, that Bob just created).\nThe use of a nonce and symmetric key cryptography forms the basis of ap4.0 . A \nnatural question is whether we can use a nonce and public key cryptography (rather \nthan symmetric key cryptography) to solve the authentication problem. This issue is \nexplored in the problems at the end of the chapter.\nFigure 8.18  \u2666 Protocol ap4.0  and a failure scenarioAlice\nR\nKA\u2013B(R)I am AliceBob\n654     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\n8.5 Securing E-Mail\nIn previous sections, we examined fundamental issues in network security, including \nsymmetric key and public key cryptography, end-point authentication, key distribu -\ntion, message integrity, and digital signatures. We are now going to examine how \nthese tools are being used to provide security in the Internet.\nInterestingly, it is possible to provide security services in any of the top four \nlayers of the Internet protocol stack. When security is provided for a specific applica -\ntion-layer protocol, the application using the protocol will enjoy one or more security \nservices, such as confidentiality, authentication, or integrity. When security is pro -\nvided for a transport-layer protocol, all applications that use that protocol enjoy the \nsecurity services of the transport protocol. When security is provided at the network \nlayer on a host-to-host basis, all transport-layer segments (and hence all application-\nlayer data) enjoy the security services of the network layer. When security is pro -\nvided on a link basis, then the data in all frames traveling over the link receive the \nsecurity services of the link.\nIn Sections 8.5 through 8.8, we examine how security tools are being used in \nthe application, transport, network, and link layers. Being consistent with the general \nstructure of this book, we begin at the top of the protocol stack and discuss security at \nthe application layer. Our approach is to use a specific application, e-mail, as a case \nstudy for application-layer security. We then move down the protocol stack. We\u2019ll \nexamine the SSL protocol (which provides security at the transport layer), IPsec \n(which provides security at the network layer), and the security of the IEEE 802.11 \nwireless LAN protocol.\nYou might be wondering why security functionality is being provided at more \nthan one layer in the Internet. Wouldn\u2019t it suffice simply to provide the security \nfunctionality at the network layer and be done with it? There are two answers to this \nquestion. First, although security at the network layer can offer \u201cblanket coverage\u201d \nby encrypting all the data in the datagrams (that is, all the transport-layer segments) \nand by authenticating all the source IP addresses, it can\u2019t provide user-level secu -\nrity. For example, a commerce site cannot rely on IP-layer security to authenticate \na customer who is purchasing goods at the commerce site. Thus, there is a need \nfor security functionality at higher layers as well as blanket coverage at lower lay -\ners. Second, it is generally easier to deploy new Internet services, including security \nservices, at the higher layers of the protocol stack. While waiting for security to be \nbroadly deployed at the network layer, which is probably still many years in the \nfuture, many application developers \u201cjust do it\u201d and introduce security functional -\nity into their favorite applications. A classic example is Pretty Good Privacy (PGP), \nwhich provides secure e-mail (discussed later in this section). Requiring only client \nand server application code, PGP was one of the first security technologies to be \nbroadly used in the Internet.\n8.5  \u2022  SECURING E-MAIL      655\n8.5.1 Secure E-Mail\nWe now use the cryptographic principles of Sections 8.2 through 8.3 to create a \nsecure e-mail system. We create this high-level design in an incremental manner, \nat each step introducing new security services. When designing a secure e-mail sys", "doc_id": "00f6ce1f-02b4-4958-b207-215e73b12b99", "embedding": null, "doc_hash": "8b8c122f7c027ea28fb331d7ed1854cf459d018993c764d9033f572b82f253f3", "extra_info": null, "node_info": {"start": 1919847, "end": 1923804}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "ce91a5ba-ee74-4db3-ae03-be4fa4670970", "3": "66307222-fac4-4f4e-b83c-7d5138a9d88b"}}, "__type__": "1"}, "66307222-fac4-4f4e-b83c-7d5138a9d88b": {"__data__": {"text": "be \nbroadly deployed at the network layer, which is probably still many years in the \nfuture, many application developers \u201cjust do it\u201d and introduce security functional -\nity into their favorite applications. A classic example is Pretty Good Privacy (PGP), \nwhich provides secure e-mail (discussed later in this section). Requiring only client \nand server application code, PGP was one of the first security technologies to be \nbroadly used in the Internet.\n8.5  \u2022  SECURING E-MAIL      655\n8.5.1 Secure E-Mail\nWe now use the cryptographic principles of Sections 8.2 through 8.3 to create a \nsecure e-mail system. We create this high-level design in an incremental manner, \nat each step introducing new security services. When designing a secure e-mail sys -\ntem, let us keep in mind the racy example introduced in Section 8.1\u2014the love affair \nbetween Alice and Bob. Imagine that Alice wants to send an e-mail message to Bob, \nand Trudy wants to intrude.\nBefore plowing ahead and designing a secure e-mail system for Alice and Bob, \nwe should consider which security features would be most desirable for them. First \nand foremost is confidentiality.  As discussed in Section 8.1, neither Alice nor Bob \nwants Trudy to read Alice\u2019s e-mail message. The second feature that Alice and Bob \nwould most likely want to see in the secure e-mail system is sender authentication . \nIn particular, when Bob receives the message \u201c I don\u2019t love you anymore. \nI never want to see you again. Formerly yours, Alice ,\u201d \nhe would naturally want to be sure that the message came from Alice and not from \nTrudy. Another feature that the two lovers would appreciate is message integrity , \nthat is, assurance that the message Alice sends is not modified while en route to \nBob. Finally, the e-mail system should provide receiver authentication ; that is, Alice \nwants to make sure that she is indeed sending the letter to Bob and not to someone \nelse (for example, Trudy) who is impersonating Bob.\nSo let\u2019s begin by addressing the foremost concern, confidentiality. The most \nstraightforward way to provide confidentiality is for Alice to encrypt the message \nwith symmetric key technology (such as DES or AES) and for Bob to decrypt the \nmessage on receipt. As discussed in Section 8.2, if the symmetric key is long enough, \nand if only Alice and Bob have the key, then it is extremely difficult for anyone else \n(including Trudy) to read the message. Although this approach is straightforward, it \nhas the fundamental difficulty that we discussed in Section 8.2\u2014distributing a sym -\nmetric key so that only Alice and Bob have copies of it. So we naturally consider an \nalternative approach\u2014public key cryptography (using, for example, RSA). In the \npublic key approach, Bob makes his public key publicly available (e.g., in a public \nkey server or on his personal Web page), Alice encrypts her message with Bob\u2019s \npublic key, and she sends the encrypted message to Bob\u2019s e-mail address. When Bob \nreceives the message, he simply decrypts it with his private key. Assuming that Alice \nknows for sure that the public key is Bob\u2019s public key, this approach is an excellent \nmeans to provide the desired confidentiality. One problem, however, is that public \nkey encryption is relatively inefficient, particularly for long messages.\nTo overcome the efficiency problem, let\u2019s make use of a session key (discussed \nin Section 8.2.2). In particular, Alice (1) selects a random symmetric session key, KS,  \n(2) encrypts her message, m, with the symmetric key, (3) encrypts the symmetric \nkey with Bob\u2019s public key, KB +, (4) concatenates the encrypted message and the \nencrypted symmetric key to form a \u201cpackage,\u201d and (5) sends the package to Bob\u2019s \n656     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER", "doc_id": "66307222-fac4-4f4e-b83c-7d5138a9d88b", "embedding": null, "doc_hash": "3913ad9e2984c6ac0507de2b2e3acb78498c8993d9eccace026abbf775bd2702", "extra_info": null, "node_info": {"start": 1923743, "end": 1927511}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "00f6ce1f-02b4-4958-b207-215e73b12b99", "3": "e437cd0e-beaf-4f94-bed0-ba052e18b3a9"}}, "__type__": "1"}, "e437cd0e-beaf-4f94-bed0-ba052e18b3a9": {"__data__": {"text": "approach is an excellent \nmeans to provide the desired confidentiality. One problem, however, is that public \nkey encryption is relatively inefficient, particularly for long messages.\nTo overcome the efficiency problem, let\u2019s make use of a session key (discussed \nin Section 8.2.2). In particular, Alice (1) selects a random symmetric session key, KS,  \n(2) encrypts her message, m, with the symmetric key, (3) encrypts the symmetric \nkey with Bob\u2019s public key, KB +, (4) concatenates the encrypted message and the \nencrypted symmetric key to form a \u201cpackage,\u201d and (5) sends the package to Bob\u2019s \n656     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\ne-mail address. The steps are illustrated in Figure 8.19. (In this and the subsequent \nfigures, the circled \u201c +\u201d represents concatenation and the circled \u201c -\u201d represents \ndeconcatenation.) When Bob receives the package, he (1) uses his private key, K-\nB,  \nto obtain the symmetric key, KS, and (2) uses the symmetric key KS to decrypt the \nmessage m.\nHaving designed a secure e-mail system that provides confidentiality, let\u2019s now \ndesign another system that provides both sender authentication and message integ -\nrity. We\u2019ll suppose, for the moment, that Alice and Bob are no longer concerned with \nconfidentiality (they want to share their feelings with everyone!), and are concerned \nonly about sender authentication and message integrity. To accomplish this task, we \nuse digital signatures and message digests, as described in Section 8.3. Specifically, \nAlice (1) applies a hash function, H (for example, MD5), to her message, m, to obtain \na message digest, (2) signs the result of the hash function with her private key, K-\nA, to \ncreate a digital signature, (3) concatenates the original (unencrypted) message with \nthe signature to create a package, and (4) sends the package to Bob\u2019s e-mail address. \nWhen Bob receives the package, he (1) applies Alice\u2019s public key, K+\nA, to the signed \nmessage digest and (2) compares the result of this operation with his own hash, H, \nof the message. The steps are illustrated in Figure 8.20. As discussed in Section 8.3, \nif the two results are the same, Bob can be pretty confident that the message came \nfrom Alice and is unaltered.\nNow let\u2019s consider designing an e-mail system that provides confidentiality, \nsender authentication, and message integrity. This can be done by combining the \nprocedures in Figures 8.19 and 8.20. Alice first creates a preliminary package, \nexactly as in Figure 8.20, that consists of her original message along with a digitally \nsigned hash of the message. She then treats this preliminary package as a message in \nitself and sends this new message through the sender steps in Figure 8.19, creating a \nnew package that is sent to Bob. The steps applied by Alice are shown in Figure 8.21. \nWhen Bob receives the package, he first applies his side of Figure 8.19 and then his Figure 8.19  \u2666  Alice used a symmetric session key, KS, to send a secret \ne-mail to BobKS(.) KS(.)KS(m) KS(m)\nKSKS\nKB+(.)\nKB+(KS) KB+(KS)m m\n+ \u2013 Internet\nKB\u2013(.)\nAlice sends e-mail message m Bob receives e-mail message m\n8.5  \u2022  SECURING E-MAIL      657\nside of Figure 8.20. It should be clear that this design achieves the goal of provid -\ning confidentiality, sender authentication, and message integrity. Note that, in this \nscheme, Alice uses public key cryptography twice: once with her own private key \nand once with Bob\u2019s public key. Similarly, Bob also uses public key cryptography", "doc_id": "e437cd0e-beaf-4f94-bed0-ba052e18b3a9", "embedding": null, "doc_hash": "d3091e2f40a7f0af2b1a1035b6064ec095b8ec980f591dae102f45b4253e8451", "extra_info": null, "node_info": {"start": 1927610, "end": 1931109}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "66307222-fac4-4f4e-b83c-7d5138a9d88b", "3": "fef3d819-161a-4522-9aa4-e816e0fc4407"}}, "__type__": "1"}, "fef3d819-161a-4522-9aa4-e816e0fc4407": {"__data__": {"text": "side of Figure 8.19 and then his Figure 8.19  \u2666  Alice used a symmetric session key, KS, to send a secret \ne-mail to BobKS(.) KS(.)KS(m) KS(m)\nKSKS\nKB+(.)\nKB+(KS) KB+(KS)m m\n+ \u2013 Internet\nKB\u2013(.)\nAlice sends e-mail message m Bob receives e-mail message m\n8.5  \u2022  SECURING E-MAIL      657\nside of Figure 8.20. It should be clear that this design achieves the goal of provid -\ning confidentiality, sender authentication, and message integrity. Note that, in this \nscheme, Alice uses public key cryptography twice: once with her own private key \nand once with Bob\u2019s public key. Similarly, Bob also uses public key cryptography \ntwice\u2014once with his private key and once with Alice\u2019s public key.\nThe secure e-mail design outlined in Figure 8.21 probably provides satisfactory \nsecurity for most e-mail users for most occasions. But there is still one important \nissue that remains to be addressed. The design in Figure 8.21 requires Alice to obtain \nBob\u2019s public key, and requires Bob to obtain Alice\u2019s public key. The distribution \nof these public keys is a nontrivial problem. For example, Trudy might masquerade \nas Bob and give Alice her own public key while saying that it is Bob\u2019s public key, Figure 8.20  \u2666  Using hash functions and digital signatures to provide \n sender authentication and message integrityH(.) KA\u2013(.) KA+(.)KA\u2013(H(m)) KA\u2013(H(m))\nm\nm\nm+ \u2013 Internet\nAlice sends e-mail message m Bob receives e-mail message mH(.)Compare\nFigure 8.21  \u2666  Alice uses symmetric key cyptography, public key \n cryptography, a hash function, and a digital signature to \n provide secrecy, sender authentication, and message integrityH(.) KA\u2013(.)\nKS(.)\nKSKA\u2013(H(m))\nm\nm+\n+ to Internet\nKB+(.)\n658     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nenabling her to receive the message meant for Bob. As we learned in Section 8.3, a \npopular approach for securely distributing public keys is to certify  the public keys \nusing a CA.\n8.5.2 PGP\nWritten by Phil Zimmermann in 1991, Pretty Good Privacy (PGP)  is a nice exam-\nple of an e-mail encryption scheme [PGPI 2016]. Versions of PGP are available in \nthe public domain; for example, you can find the PGP software for your favorite plat -\nform as well as lots of interesting reading at the International PGP Home Page [PGPI \n2016]. The PGP design is, in essence, the same as the design shown in Figure 8.21. \nDepending on the version, the PGP software uses MD5 or SHA for calculating the \nmessage digest; CAST, triple-DES, or IDEA for symmetric key encryption; and \nRSA for the public key encryption.\nWhen PGP is installed, the software creates a public key pair for the user. The \npublic key can be posted on the user\u2019s Web site or placed in a public key server. The \nprivate key is protected by the use of a password. The password has to be entered \nevery time the user accesses the private key. PGP gives the user the option of dig -\nitally signing the message, encrypting the message, or both digitally signing and \nencrypting. Figure 8.22 shows a PGP signed message. This message appears after the \nMIME header. The encoded data in the message is K-\nA (H(m)), that is, the digitally \nsigned message digest. As we discussed above, in order for Bob to verify the integ -\nrity of the message, he needs to have access to Alice\u2019s public key.\nFigure 8. 23 shows a secret PGP message. This message also appears after the \nMIME header. Of course, the plaintext message is not included within the secret e-mail \nmessage. When a sender (such as Alice) wants both confidentiality and", "doc_id": "fef3d819-161a-4522-9aa4-e816e0fc4407", "embedding": null, "doc_hash": "a563ad71b815e8af56811bbfc977aa222bdfc16b91f4f9cf183dac040b1dbe84", "extra_info": null, "node_info": {"start": 1931130, "end": 1934642}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "e437cd0e-beaf-4f94-bed0-ba052e18b3a9", "3": "9f114e9e-5c33-4a2d-8f6a-449708caa684"}}, "__type__": "1"}, "9f114e9e-5c33-4a2d-8f6a-449708caa684": {"__data__": {"text": "password has to be entered \nevery time the user accesses the private key. PGP gives the user the option of dig -\nitally signing the message, encrypting the message, or both digitally signing and \nencrypting. Figure 8.22 shows a PGP signed message. This message appears after the \nMIME header. The encoded data in the message is K-\nA (H(m)), that is, the digitally \nsigned message digest. As we discussed above, in order for Bob to verify the integ -\nrity of the message, he needs to have access to Alice\u2019s public key.\nFigure 8. 23 shows a secret PGP message. This message also appears after the \nMIME header. Of course, the plaintext message is not included within the secret e-mail \nmessage. When a sender (such as Alice) wants both confidentiality and integrity, PGP \ncontains a message like that of Figure 8.23 within the message of Figure 8.22.\nPGP also provides a mechanism for public key certification, but the mechanism \nis quite different from the more conventional CA. PGP public keys are certified by \nFigure 8.22  \u2666 A PGP signed message-----BEGIN PGP SIGNED MESSAGE-----\nHash:  SHA1\nBob:\nCan I see you tonight?\nPassionately yours, Alice\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP for Personal Privacy 5.0\nCharset: noconv\nyhHJRHhGJGhgg/12EpJ+lo8gE4vB3mqJhFEvZP9t6n7G6m5Gw2\n-----END PGP SIGNATURE-----\n8.6  \u2022  SECURING TCP CONNECTIONS: SSL      659\na web of trust.  Alice herself can certify any key/username pair when she believes \nthe pair really belong together. In addition, PGP permits Alice to say that she trusts \nanother user to vouch for the authenticity of more keys. Some PGP users sign each \nother\u2019s keys by holding key-signing parties. Users physically gather, exchange \n public keys, and certify each other\u2019s keys by signing them with their private keys.\n8.6 Securing TCP Connections: SSL\nIn the previous section, we saw how cryptographic techniques can provide confiden -\ntiality, data integrity, and end-point authentication to a specific application, namely, \ne-mail. In this section, we\u2019ll drop down a layer in the protocol stack and examine \nhow cryptography can enhance TCP with security services, including confidential -\nity, data integrity, and end-point authentication. This enhanced version of TCP is \ncommonly known as Secure Sockets Layer (SSL) . A slightly modified version of \nSSL version 3, called Transport Layer Security (TLS) , has been standardized by \nthe IETF [RFC 4346].\nThe SSL protocol was originally designed by Netscape, but the basic ideas behind \nsecuring TCP had predated Netscape\u2019s work (for example, see Woo [Woo 1994]). \nSince its inception, SSL has enjoyed broad deployment. SSL is supported by all popu -\nlar Web browsers and Web servers, and it is used by Gmail and essentially all Internet \ncommerce sites (including Amazon, eBay, and TaoBao). Hundreds of billions of dol -\nlars are spent over SSL every year. In fact, if you have ever purchased anything over \nthe Internet with your credit card, the communication between your browser and the \nserver for this purchase almost certainly went over SSL. (You can identify that SSL is \nbeing used by your browser when the URL begins with https: rather than http.)\nTo understand the need for SSL, let\u2019s walk through a typical Internet commerce \nscenario. Bob is surfing the Web and arrives at the Alice Incorporated site, which is \nselling perfume. The Alice Incorporated site displays a form in which Bob is sup -\nposed to enter the type of perfume and quantity desired, his address, and his pay -\nment card number. Bob enters this information, clicks on Submit, and expects to \nreceive (via ordinary postal mail) the purchased perfumes; he also expects to", "doc_id": "9f114e9e-5c33-4a2d-8f6a-449708caa684", "embedding": null, "doc_hash": "a25ea82aa71b6b2b83e3d1c578d303ec1fdebf6830679b475beb39760ccba2c5", "extra_info": null, "node_info": {"start": 1934534, "end": 1938197}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "fef3d819-161a-4522-9aa4-e816e0fc4407", "3": "f9e460ff-79f0-4056-84db-bd92a3346cf3"}}, "__type__": "1"}, "f9e460ff-79f0-4056-84db-bd92a3346cf3": {"__data__": {"text": "In fact, if you have ever purchased anything over \nthe Internet with your credit card, the communication between your browser and the \nserver for this purchase almost certainly went over SSL. (You can identify that SSL is \nbeing used by your browser when the URL begins with https: rather than http.)\nTo understand the need for SSL, let\u2019s walk through a typical Internet commerce \nscenario. Bob is surfing the Web and arrives at the Alice Incorporated site, which is \nselling perfume. The Alice Incorporated site displays a form in which Bob is sup -\nposed to enter the type of perfume and quantity desired, his address, and his pay -\nment card number. Bob enters this information, clicks on Submit, and expects to \nreceive (via ordinary postal mail) the purchased perfumes; he also expects to receive Figure 8.23  \u2666 A secret PGP message-----BEGIN PGP MESSAGE-----\nVersion: PGP for Personal Privacy 5.0\nu2R4d+/jKmn8Bc5+hgDsqAewsDfrGdszX68liKm5F6Gc4sDfcXyt\nRfdS10juHgbcfDssWe7/K=lKhnMikLo0+1/BvcX4t==Ujk9PbcD4\nThdf2awQfgHbnmKlok8iy6gThlp\n-----END PGP MESSAGE\n660     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\na charge for his order in his next payment card statement. This all sounds good, but \nif no security measures are taken, Bob could be in for a few surprises.\n\u2022 If no confidentiality (encryption) is used, an intruder could intercept Bob\u2019s order \nand obtain his payment card information. The intruder could then make purchases \nat Bob\u2019s expense.\n\u2022 If no data integrity is used, an intruder could modify Bob\u2019s order, having him \npurchase ten times more bottles of perfume than desired.\n\u2022 Finally, if no server authentication is used, a server could display Alice Incor -\nporated\u2019s famous logo when in actuality the site maintained by Trudy, who is \nmasquerading as Alice Incorporated. After receiving Bob\u2019s order, Trudy could \ntake Bob\u2019s money and run. Or Trudy could carry out an identity theft by collect -\ning Bob\u2019s name, address, and credit card number.\nSSL addresses these issues by enhancing TCP with confidentiality, data integrity, \nserver authentication, and client authentication.\nSSL is often used to provide security to transactions that take place over HTTP. \nHowever, because SSL secures TCP, it can be employed by any application that runs \nover TCP. SSL provides a simple Application Programmer Interface (API) with sock -\nets, which is similar and analogous to TCP\u2019s API. When an application wants to employ \nSSL, the application includes SSL classes/libraries. As shown in Figure 8.24, although \nSSL technically resides in the application layer, from the developer\u2019s perspective it \nis a transport protocol that provides TCP\u2019s services enhanced with security services.\n8.6.1 The Big Picture\nWe begin by describing a simplified version of SSL, one that will allow us to get a \nbig-picture understanding of the why and how of SSL. We will refer to this simplified \nFigure 8.24  \u2666  Although SSL technically resides in the application layer, \nfrom the developer\u2019s perspective it is a transport-layer \n protocolTCPSSL sublayer\nIPApplication\nApplication\nlayer\nTCP enhanced with SSLSSL socket\nTCP socket\nTCP\nIPApplication\nTCP APITCP socket\n8.6  \u2022  SECURING TCP CONNECTIONS: SSL      661\nversion of SSL as \u201calmost-SSL.\u201d After describing almost-SSL, in the next subsec -\ntion we\u2019ll then describe the real SSL, filling in the details. Almost-SSL (and SSL) \nhas three phases: handshake , key derivation , and data transfer . We now describe \nthese", "doc_id": "f9e460ff-79f0-4056-84db-bd92a3346cf3", "embedding": null, "doc_hash": "93f50e74dd109c0f1cef442d4e06ce757512b641181c92ded579901e544fb582", "extra_info": null, "node_info": {"start": 1938163, "end": 1941627}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "9f114e9e-5c33-4a2d-8f6a-449708caa684", "3": "a2f8d9b1-8344-4af8-9ed5-767f6a6ed229"}}, "__type__": "1"}, "a2f8d9b1-8344-4af8-9ed5-767f6a6ed229": {"__data__": {"text": "a \nbig-picture understanding of the why and how of SSL. We will refer to this simplified \nFigure 8.24  \u2666  Although SSL technically resides in the application layer, \nfrom the developer\u2019s perspective it is a transport-layer \n protocolTCPSSL sublayer\nIPApplication\nApplication\nlayer\nTCP enhanced with SSLSSL socket\nTCP socket\nTCP\nIPApplication\nTCP APITCP socket\n8.6  \u2022  SECURING TCP CONNECTIONS: SSL      661\nversion of SSL as \u201calmost-SSL.\u201d After describing almost-SSL, in the next subsec -\ntion we\u2019ll then describe the real SSL, filling in the details. Almost-SSL (and SSL) \nhas three phases: handshake , key derivation , and data transfer . We now describe \nthese three phases for a communication session between a client (Bob) and a server \n(Alice), with Alice having a private/public key pair and a certificate that binds her \nidentity to her public key.\nHandshake\nDuring the handshake phase, Bob needs to (a) establish a TCP connection with Alice, \n(b) verify that Alice is really  Alice, and (c) send Alice a master secret key, which \nwill be used by both Alice and Bob to generate all the symmetric keys they need for \nthe SSL session. These three steps are shown in Figure 8.25. Note that once the TCP \nconnection is established, Bob sends Alice a hello message. Alice then responds with \nher certificate, which contains her public key. As discussed in Section 8.3, because \nthe certificate has been certified by a CA, Bob knows for sure that the public key in \nthe certificate belongs to Alice. Bob then generates a Master Secret (MS) (which will \nonly be used for this SSL session), encrypts the MS with Alice\u2019s public key to create \nthe Encrypted Master Secret (EMS), and sends the EMS to Alice. Alice decrypts the \nEMS with her private key to get the MS. After this phase, both Bob and Alice (and \nno one else) know the master secret for this SSL session.\nFigure 8.25  \u2666  The almost-SSL handshake, beginning with a TCP \n connectionTCP SYN\nTCP/SYNACK\nDecrypts EMS with\nKA\u2013 to get MSEMS = KA+(MS)TCP ACK\nSSL hello\ncerti\ufb01cate(b)(a)\n(c) \nCreate Master\nSecret (MS)\n662     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nKey Derivation\nIn principle, the MS, now shared by Bob and Alice, could be used as the symmetric \nsession key for all subsequent encryption and data integrity checking. It is, however, \ngenerally considered safer for Alice and Bob to each use different cryptographic \nkeys, and also to use different keys for encryption and integrity checking. Thus, both \nAlice and Bob use the MS to generate four keys:\n\u2022 EB=session encryption key for data sent from Bob to Alice\n\u2022 MB=session MAC key for data sent from Bob to Alice\n\u2022 EA=session encryption key for data sent from Alice to Bob\n\u2022 MA=session MAC key for data sent from Alice to Bob\nAlice and Bob each generate the four keys from the MS. This could be done by sim -\nply slicing the MS into four keys. (But in real SSL it is a little more complicated, as \nwe\u2019ll see.) At the end of the key derivation phase, both Alice and Bob have all four \nkeys. The two encryption keys will be used to encrypt data; the two MAC keys will \nbe used to verify the integrity of the data.\nData Transfer\nNow that Alice and Bob share the same four session keys (EB, M B, EA, and M A), they \ncan start to send secured data to each other over the TCP connection. Since TCP is a byte-\nstream protocol, a natural approach would be for SSL to encrypt application data on the fly \nand then pass the encrypted data on the fly to TCP. But if we were to do this, where would \nwe put the MAC for the integrity check? We certainly do not want to wait until the end \nof the TCP session to verify the integrity of all of Bob\u2019s data that was sent over the entire \nsession! To address this", "doc_id": "a2f8d9b1-8344-4af8-9ed5-767f6a6ed229", "embedding": null, "doc_hash": "dc9b5ef0d895771c9f7f7e8c90de8327cdcaed90ebcc069003fa18486a1c3040", "extra_info": null, "node_info": {"start": 1941727, "end": 1945451}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "f9e460ff-79f0-4056-84db-bd92a3346cf3", "3": "94db9a0f-dd4d-4feb-bf37-8af039620c54"}}, "__type__": "1"}, "94db9a0f-dd4d-4feb-bf37-8af039620c54": {"__data__": {"text": "of the key derivation phase, both Alice and Bob have all four \nkeys. The two encryption keys will be used to encrypt data; the two MAC keys will \nbe used to verify the integrity of the data.\nData Transfer\nNow that Alice and Bob share the same four session keys (EB, M B, EA, and M A), they \ncan start to send secured data to each other over the TCP connection. Since TCP is a byte-\nstream protocol, a natural approach would be for SSL to encrypt application data on the fly \nand then pass the encrypted data on the fly to TCP. But if we were to do this, where would \nwe put the MAC for the integrity check? We certainly do not want to wait until the end \nof the TCP session to verify the integrity of all of Bob\u2019s data that was sent over the entire \nsession! To address this issue, SSL breaks the data stream into records, appends a MAC \nto each record for integrity checking, and then encrypts the record +MAC. To create the \nMAC, Bob inputs the record data along with the key MB into a hash function, as discussed \nin Section 8.3. To encrypt the package record +MAC, Bob uses his session encryption key \nEB. This encrypted package is then passed to TCP for transport over the Internet.\nAlthough this approach goes a long way, it still isn\u2019t bullet-proof when it comes \nto providing data integrity for the entire message stream. In particular, suppose \nTrudy is a woman-in-the-middle and has the ability to insert, delete, and replace \nsegments in the stream of TCP segments sent between Alice and Bob. Trudy, for \nexample, could capture two segments sent by Bob, reverse the order of the segments, \nadjust the TCP sequence numbers (which are not encrypted), and then send the two \nreverse-ordered segments to Alice. Assuming that each TCP segment encapsulates \nexactly one record, let\u2019s now take a look at how Alice would process these segments.\n 1. TCP running in Alice would think everything is fine and pass the two records \nto the SSL sublayer.\n 2. SSL in Alice would decrypt the two records.\n8.6  \u2022  SECURING TCP CONNECTIONS: SSL      663\n 3. SSL in Alice would use the MAC in each record to verify the data integrity of \nthe two records.\n 4. SSL would then pass the decrypted byte streams of the two records to the \napplication layer; but the complete byte stream received by Alice would not be \nin the correct order due to reversal of the records!\nYou are encouraged to walk through similar scenarios for when Trudy removes seg -\nments or when Trudy replays segments.\nThe solution to this problem, as you probably guessed, is to use sequence num -\nbers. SSL does this as follows. Bob maintains a sequence number counter, which \nbegins at zero and is incremented for each SSL record he sends. Bob doesn\u2019t actually \ninclude a sequence number in the record itself, but when he calculates the MAC, he \nincludes the sequence number in the MAC calculation. Thus, the MAC is now a hash \nof the data plus the MAC key MB plus the current sequence number . Alice tracks \nBob\u2019s sequence numbers, allowing her to verify the data integrity of a record by \nincluding the appropriate sequence number in the MAC calculation. This use of SSL \nsequence numbers prevents Trudy from carrying out a woman-in-the-middle attack, \nsuch as reordering or replaying segments. (Why?)\nSSL Record\nThe SSL record (as well as the almost-SSL record) is shown in Figure 8.26. The \nrecord consists of a type field, version field, length field, data field, and MAC field. \nNote that the first three fields are not encrypted. The type field indicates whether the \nrecord is a handshake message or a message that contains application data. It is also \nused to close the SSL connection, as discussed below. SSL at the receiving end uses \nthe length field to extract the SSL records out of the incoming TCP byte stream. The \nversion field is self-explanatory.\n8.6.2 A More Complete Picture\nThe previous subsection covered the almost-SSL protocol; it served to give us a basic \nunderstanding of the why and how of", "doc_id": "94db9a0f-dd4d-4feb-bf37-8af039620c54", "embedding": null, "doc_hash": "d9d0550d5e729d3225fb70053d2408865876251e48e4be4acb970d2b38400156", "extra_info": null, "node_info": {"start": 1945390, "end": 1949371}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "a2f8d9b1-8344-4af8-9ed5-767f6a6ed229", "3": "e55ae45e-9943-4179-8d45-7aa57a303126"}}, "__type__": "1"}, "e55ae45e-9943-4179-8d45-7aa57a303126": {"__data__": {"text": "attack, \nsuch as reordering or replaying segments. (Why?)\nSSL Record\nThe SSL record (as well as the almost-SSL record) is shown in Figure 8.26. The \nrecord consists of a type field, version field, length field, data field, and MAC field. \nNote that the first three fields are not encrypted. The type field indicates whether the \nrecord is a handshake message or a message that contains application data. It is also \nused to close the SSL connection, as discussed below. SSL at the receiving end uses \nthe length field to extract the SSL records out of the incoming TCP byte stream. The \nversion field is self-explanatory.\n8.6.2 A More Complete Picture\nThe previous subsection covered the almost-SSL protocol; it served to give us a basic \nunderstanding of the why and how of SSL. Now that we have a basic understanding \nof SSL, we can dig a little deeper and examine the essentials of the actual SSL proto -\ncol. In parallel to reading this description of the SSL protocol, you are encouraged to \ncomplete the Wireshark SSL lab, available at the textbook\u2019s Web site.\nFigure 8.26  \u2666 Record format for SSLVersion Length Type Data MAC\nEncrypted with EB\n664     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nSSL Handshake\nSSL does not mandate that Alice and Bob use a specific symmetric key algorithm, \na specific public-key algorithm, or a specific MAC. Instead, SSL allows Alice and \nBob to agree on the cryptographic algorithms at the beginning of the SSL session, \nduring the handshake phase. Additionally, during the handshake phase, Alice and \nBob send nonces to each other, which are used in the creation of the session keys \n(EB, M B, EA, and M A). The steps of the real SSL handshake are as follows:\n 1. The client sends a list of cryptographic algorithms it supports, along with a \n client nonce.\n 2. From the list, the server chooses a symmetric algorithm (for example, AES), \na public key algorithm (for example, RSA with a specific key length), and a \nMAC algorithm. It sends back to the client its choices, as well as a certificate \nand a server nonce.\n 3. The client verifies the certificate, extracts the server\u2019s public key, generates a \nPre-Master Secret (PMS), encrypts the PMS with the server\u2019s public key, and \nsends the encrypted PMS to the server.\n 4. Using the same key derivation function (as specified by the SSL standard), \nthe client and server independently compute the Master Secret (MS) from the \nPMS and nonces. The MS is then sliced up to generate the two encryption and \ntwo MAC keys. Furthermore, when the chosen symmetric cipher employs \nCBC (such as 3DES or AES), then two Initialization Vectors (IVs)\u2014one for \neach side of the connection\u2014are also obtained from the MS. Henceforth, all \n messages sent between client and server are encrypted and authenticated (with \nthe MAC).\n 5. The client sends a MAC of all the handshake messages.\n 6. The server sends a MAC of all the handshake messages.\nThe last two steps protect the handshake from tampering. To see this, observe \nthat in step 1, the client typically offers a list of algorithms\u2014some strong, some \nweak. This list of algorithms is sent in cleartext, since the encryption algorithms and \nkeys have not yet been agreed upon. Trudy, as a woman-in-the-middle, could delete \nthe stronger algorithms from the list, forcing the client to select a weak algorithm. \nTo prevent such a tampering attack, in step 5 the client sends a MAC of the concat -\nenation of all the handshake messages it sent and received. The server can compare \nthis MAC with the MAC of the handshake messages it received and sent. If there \nis an inconsistency, the server can terminate the connection. Similarly, the server \nsends a MAC of the handshake messages it has seen, allowing the client to check for \ninconsistencies.\nYou may be wondering why there are nonces in steps 1 and", "doc_id": "e55ae45e-9943-4179-8d45-7aa57a303126", "embedding": null, "doc_hash": "7732786a6ccdf078de010fb6d050730107a41dd3a881ab013260d82b34cf6eca", "extra_info": null, "node_info": {"start": 1949349, "end": 1953190}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "94db9a0f-dd4d-4feb-bf37-8af039620c54", "3": "0b62ae51-4ec3-4a1c-994a-bdf2e413c230"}}, "__type__": "1"}, "0b62ae51-4ec3-4a1c-994a-bdf2e413c230": {"__data__": {"text": "some \nweak. This list of algorithms is sent in cleartext, since the encryption algorithms and \nkeys have not yet been agreed upon. Trudy, as a woman-in-the-middle, could delete \nthe stronger algorithms from the list, forcing the client to select a weak algorithm. \nTo prevent such a tampering attack, in step 5 the client sends a MAC of the concat -\nenation of all the handshake messages it sent and received. The server can compare \nthis MAC with the MAC of the handshake messages it received and sent. If there \nis an inconsistency, the server can terminate the connection. Similarly, the server \nsends a MAC of the handshake messages it has seen, allowing the client to check for \ninconsistencies.\nYou may be wondering why there are nonces in steps 1 and 2. Don\u2019t sequence \nnumbers suffice for preventing the segment replay attack? The answer is yes, but they \ndon\u2019t alone prevent the \u201cconnection replay attack.\u201d Consider the following connection \n8.7  \u2022  NETWORK-LAYER SECURITY: IPSEC AND VIRTUAL PRIVATE NETWORKS      665\nreplay attack. Suppose Trudy sniffs all messages between Alice and Bob. The next \nday, Trudy masquerades as Bob and sends to Alice exactly the same sequence of \nmessages that Bob sent to Alice on the previous day. If Alice doesn\u2019t use nonces, \nshe will respond with exactly the same sequence of messages she sent the previous \nday. Alice will not suspect any funny business, as each message she receives will \npass the integrity check. If Alice is an e-commerce server, she will think that Bob is \nplacing a second order (for exactly the same thing). On the other hand, by including a \nnonce in the protocol, Alice will send different nonces for each TCP session, causing \nthe encryption keys to be different on the two days. Therefore, when Alice receives \nplayed-back SSL records from Trudy, the records will fail the integrity checks, and \nthe bogus e-commerce transaction will not succeed. In summary, in SSL, nonces are \nused to defend against the \u201cconnection replay attack\u201d and sequence numbers are used \nto defend against replaying individual packets during an ongoing session.\nConnection Closure\nAt some point, either Bob or Alice will want to end the SSL session. One approach \nwould be to let Bob end the SSL session by simply terminating the underlying TCP \nconnection\u2014that is, by having Bob send a TCP FIN segment to Alice. But such a \nnaive design sets the stage for the truncation attack  whereby Trudy once again gets \nin the middle of an ongoing SSL session and ends the session early with a TCP \nFIN. If Trudy were to do this, Alice would think she received all of Bob\u2019s data \nwhen  actuality she only received a portion of it. The solution to this problem is to \nindicate in the type field whether the record serves to terminate the SSL session. \n(Although the SSL type is sent in the clear, it is authenticated at the receiver using the \nrecord\u2019s MAC.) By including such a field, if Alice were to receive a TCP FIN before \n receiving a closure SSL record, she would know that something funny was going on.\nThis completes our introduction to SSL. We\u2019ve seen that it uses many of the \ncryptography principles discussed in Sections 8.2 and 8.3. Readers who want to \nexplore SSL on yet a deeper level can read Rescorla\u2019s highly readable book on SSL \n[Rescorla 2001].\n8.7 Network-Layer Security: IPsec and Virtual \nPrivate Networks\nThe IP security protocol, more commonly known as IPsec , provides security at the \nnetwork layer. IPsec secures IP datagrams between any two network-layer entities, \nincluding hosts and routers. As we will soon describe, many institutions (corpora -\ntions, government branches, non-profit organizations, and so on) use IPsec to create \nvirtual private networks (VPNs)  that run over the public Internet.\n666     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN", "doc_id": "0b62ae51-4ec3-4a1c-994a-bdf2e413c230", "embedding": null, "doc_hash": "84b6dfe7242902f3003a75242f127c77745165278aa478aa4c41df893220aa25", "extra_info": null, "node_info": {"start": 1953209, "end": 1957022}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "e55ae45e-9943-4179-8d45-7aa57a303126", "3": "21378c85-52f7-4bef-933e-3f08476ff735"}}, "__type__": "1"}, "21378c85-52f7-4bef-933e-3f08476ff735": {"__data__": {"text": "of the \ncryptography principles discussed in Sections 8.2 and 8.3. Readers who want to \nexplore SSL on yet a deeper level can read Rescorla\u2019s highly readable book on SSL \n[Rescorla 2001].\n8.7 Network-Layer Security: IPsec and Virtual \nPrivate Networks\nThe IP security protocol, more commonly known as IPsec , provides security at the \nnetwork layer. IPsec secures IP datagrams between any two network-layer entities, \nincluding hosts and routers. As we will soon describe, many institutions (corpora -\ntions, government branches, non-profit organizations, and so on) use IPsec to create \nvirtual private networks (VPNs)  that run over the public Internet.\n666     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nBefore getting into the specifics of IPsec, let\u2019s step back and consider what \nit means to provide confidentiality at the network layer. With network-layer con -\nfidentiality between a pair of network entities (for example, between two routers, \nbetween two hosts, or between a router and a host), the sending entity encrypts the \npayloads of all the datagrams it sends to the receiving entity. The encrypted payload \ncould be a TCP segment, a UDP segment, an ICMP message, and so on. If such \na network-layer service were in place, all data sent from one entity to the other\u2014\nincluding e-mail, Web pages, TCP handshake messages, and management mes -\nsages (such as ICMP and SNMP)\u2014would be hidden from any third party that might \nbe sniffing the network. For this reason, network-layer security is said to provide  \n\u201cblanket coverage.\u201d\nIn addition to confidentiality, a network-layer security protocol could potentially \nprovide other security services. For example, it could provide source authentication, \nso that the receiving entity can verify the source of the secured datagram. A network-\nlayer security protocol could provide data integrity, so that the receiving entity can \ncheck for any tampering of the datagram that may have occurred while the datagram \nwas in transit. A network-layer security service could also provide replay-attack pre -\nvention, meaning that Bob could detect any duplicate datagrams that an attacker \nmight insert. We will soon see that IPsec indeed provides mechanisms for all these \nsecurity services, that is, for confidentiality, source authentication, data  integrity, and \nreplay-attack prevention.\n8.7.1 IPsec and Virtual Private Networks (VPNs)\nAn institution that extends over multiple geographical regions often desires its own \nIP network, so that its hosts and servers can send data to each other in a secure and \nconfidential manner. To achieve this goal, the institution could actually deploy a \nstand-alone physical network\u2014including routers, links, and a DNS  infrastructure\u2014\nthat is completely separate from the public Internet. Such a disjoint network, dedi -\ncated to a particular institution, is called a private network . Not surprisingly, a \nprivate network can be very costly, as the institution needs to purchase, install, and \nmaintain its own physical network infrastructure.\nInstead of deploying and maintaining a private network, many institutions \ntoday create VPNs over the existing public Internet. With a VPN, the institu -\ntion\u2019s inter-office traffic is sent over the public Internet rather than over a physi -\ncally independent network. But to provide confidentiality, the inter-office traffic \nis encrypted before it enters the public Internet. A simple example of a VPN is \nshown in Figure\u00a0 8.27. Here the institution consists of a headquarters, a branch \noffice, and traveling salespersons that typically access the Internet from their hotel \nrooms. (There is only one salesperson shown in the figure.) In this VPN, whenever \ntwo hosts within headquarters send IP datagrams to each other or whenever two \nhosts within the branch office want to communicate, they use good-old vanilla \nIPv4 (that is, without IPsec services). However, when two of the institution\u2019s hosts", "doc_id": "21378c85-52f7-4bef-933e-3f08476ff735", "embedding": null, "doc_hash": "410f8bcf994ca97afc78546bb814ce174c1e6bdeff423bdcdefd839f7e0c6fb9", "extra_info": null, "node_info": {"start": 1957067, "end": 1961017}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "0b62ae51-4ec3-4a1c-994a-bdf2e413c230", "3": "e4eddac3-4ce7-4bff-b394-e0ab0bf482d2"}}, "__type__": "1"}, "e4eddac3-4ce7-4bff-b394-e0ab0bf482d2": {"__data__": {"text": "Internet. With a VPN, the institu -\ntion\u2019s inter-office traffic is sent over the public Internet rather than over a physi -\ncally independent network. But to provide confidentiality, the inter-office traffic \nis encrypted before it enters the public Internet. A simple example of a VPN is \nshown in Figure\u00a0 8.27. Here the institution consists of a headquarters, a branch \noffice, and traveling salespersons that typically access the Internet from their hotel \nrooms. (There is only one salesperson shown in the figure.) In this VPN, whenever \ntwo hosts within headquarters send IP datagrams to each other or whenever two \nhosts within the branch office want to communicate, they use good-old vanilla \nIPv4 (that is, without IPsec services). However, when two of the institution\u2019s hosts \n8.7  \u2022  NETWORK-LAYER SECURITY: IPSEC AND VIRTUAL PRIVATE NETWORKS      667\ncommunicate over a path that traverses the public Internet, the traffic is encrypted \nbefore it enters the Internet.\nTo get a feel for how a VPN works, let\u2019s walk through a simple example in the \ncontext of Figure 8.27. When a host in headquarters sends an IP datagram to a sales -\nperson in a hotel, the gateway router in headquarters converts the vanilla IPv4 data -\ngram into an IPsec datagram and then forwards this IPsec datagram into the Internet. \nThis IPsec datagram actually has a traditional IPv4 header, so that the routers in the \npublic Internet process the datagram as if it were an ordinary IPv4 datagram\u2014to \nthem, the datagram is a perfectly ordinary datagram. But, as shown Figure 8.27, \nthe payload of the IPsec datagram includes an IPsec header, which is used for IPsec \nprocessing; furthermore, the payload of the IPsec datagram is encrypted. When the \nIPsec datagram arrives at the salesperson\u2019s laptop, the OS in the laptop decrypts the \npayload (and provides other security services, such as verifying data integrity) and \npasses the unencrypted payload to the upper-layer protocol (for example, to TCP  \nor UDP).\nWe have just given a high-level overview of how an institution can employ \nIPsec to create a VPN. To see the forest through the trees, we have brushed aside \nmany important details. Let\u2019s now take a closer look.Figure 8.27  \u2666 Virtual private network (VPN)IP\nheaderIPsec\nheaderSecure\npayload\nIP\nheaderIPsec\nheaderSecure\npayload\nIP\nheaderIPsec\nheaderSecure\npayloadIP\nheaderPayload\nIP\nheaderPayloadLaptop w/IPsec\nRouter\nw/IPv4 and\nIPsec\nRouter\nw/IPv4 and\nIPsecBranch Of \ufb01ce\nHeadquartersSalesperson\nin Hotel\nPublic\nInternet\n668     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\n8.7.2 The AH and ESP Protocols\nIPsec is a rather complex animal\u2014it is defined in more than a dozen RFCs. Two \nimportant RFCs are RFC 4301, which describes the overall IP security architecture, \nand RFC 6071, which provides an overview of the IPsec protocol suite. Our goal in \nthis textbook, as usual, is not simply to re-hash the dry and arcane RFCs, but instead \ntake a more operational and pedagogic approach to describing the protocols.\nIn the IPsec protocol suite, there are two principal protocols: the Authentication \nHeader (AH)  protocol and the Encapsulation Security Payload (ESP)  protocol. \nWhen a source IPsec entity (typically a host or a router) sends secure datagrams to a \ndestination entity (also a host or a router), it does so with either the AH protocol or \nthe ESP protocol. The AH protocol provides source authentication and data integrity \nbut does not  provide confidentiality. The ESP protocol provides source authentica -\ntion, data integrity, and confidentiality. Because confidentiality is often critical for \nVPNs and other IPsec", "doc_id": "e4eddac3-4ce7-4bff-b394-e0ab0bf482d2", "embedding": null, "doc_hash": "af374620cc59aed12aa62128bcc526e5512fbefffdcd950223606c9eae4c68be", "extra_info": null, "node_info": {"start": 1960940, "end": 1964575}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "21378c85-52f7-4bef-933e-3f08476ff735", "3": "c497851d-2f87-4323-81b4-859a87e8e5bc"}}, "__type__": "1"}, "c497851d-2f87-4323-81b4-859a87e8e5bc": {"__data__": {"text": "not simply to re-hash the dry and arcane RFCs, but instead \ntake a more operational and pedagogic approach to describing the protocols.\nIn the IPsec protocol suite, there are two principal protocols: the Authentication \nHeader (AH)  protocol and the Encapsulation Security Payload (ESP)  protocol. \nWhen a source IPsec entity (typically a host or a router) sends secure datagrams to a \ndestination entity (also a host or a router), it does so with either the AH protocol or \nthe ESP protocol. The AH protocol provides source authentication and data integrity \nbut does not  provide confidentiality. The ESP protocol provides source authentica -\ntion, data integrity, and confidentiality. Because confidentiality is often critical for \nVPNs and other IPsec applications, the ESP protocol is much more widely used than \nthe AH protocol. In order to de-mystify IPsec and avoid much of its complication, we \nwill henceforth focus exclusively on the ESP protocol. Readers wanting to learn also \nabout the AH protocol are encouraged to explore the RFCs and other online resources.\n8.7.3 Security Associations\nIPsec datagrams are sent between pairs of network entities, such as between two \nhosts, between two routers, or between a host and router. Before sending IPsec data -\ngrams from source entity to destination entity, the source and destination entities cre -\nate a network-layer logical connection. This logical connection is called a security \nassociation (SA) . An SA is a simplex logical connection; that is, it is unidirectional \nfrom source to destination. If both entities want to send secure datagrams to each \nother, then two SAs (that is, two logical connections) need to be established, one in \neach direction.\nFor example, consider once again the institutional VPN in Figure 8.27. This \ninstitution consists of a headquarters office, a branch office and, say, n traveling \nsalespersons. For the sake of example, let\u2019s suppose that there is bi-directional IPsec \ntraffic between headquarters and the branch office and bi-directional IPsec traffic \nbetween headquarters and the salespersons. In this VPN, how many SAs are there? \nTo answer this question, note that there are two SAs between the headquarters gate -\nway router and the branch-office gateway router (one in each direction); for each \nsalesperson\u2019s laptop, there are two SAs between the headquarters gateway router and \nthe laptop (again, one in each direction). So, in total, there are (2 + 2n) SAs. Keep \nin mind, however, that not all traffic sent into the Internet by the gateway routers or \nby the laptops will be IPsec secured.  For example, a host in headquarters may want \nto access a Web server (such as Amazon or Google) in the public Internet. Thus, \nthe gateway router (and the laptops) will emit into the Internet both vanilla IPv4 \n datagrams and secured IPsec datagrams.\n8.7  \u2022  NETWORK-LAYER SECURITY: IPSEC AND VIRTUAL PRIVATE NETWORKS      669\nLet\u2019s now take a look \u201cinside\u201d an SA. To make the discussion tangible and \n concrete, let\u2019s do this in the context of an SA from router R1 to router R2 in Fig -\nure\u00a08. 28. (You can think of Router R1 as the headquarters gateway router and Router \nR2 as the branch office gateway router from Figure 8.27.) Router R1 will maintain \nstate information about this SA, which will include:\n\u2022 A 32-bit identifier for the SA, called the Security Parameter Index (SPI)\n\u2022 The origin interface of the SA (in this case 200.168.1.100) and the destination \ninterface of the SA (in this case 193.68.2.23)\n\u2022 The type of encryption to be used (for example, 3DES with CBC)\n\u2022 The encryption key\n\u2022 The type of integrity check (for example, HMAC with MD5)\n\u2022 The authentication key\nWhenever", "doc_id": "c497851d-2f87-4323-81b4-859a87e8e5bc", "embedding": null, "doc_hash": "e06013b27ffb997166da1f5fe2bc631667825606b1860b4d61831f632a47b8dd", "extra_info": null, "node_info": {"start": 1964601, "end": 1968303}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "e4eddac3-4ce7-4bff-b394-e0ab0bf482d2", "3": "2e2e8e5f-b8f6-4aed-b9d4-b83b91372d26"}}, "__type__": "1"}, "2e2e8e5f-b8f6-4aed-b9d4-b83b91372d26": {"__data__": {"text": "do this in the context of an SA from router R1 to router R2 in Fig -\nure\u00a08. 28. (You can think of Router R1 as the headquarters gateway router and Router \nR2 as the branch office gateway router from Figure 8.27.) Router R1 will maintain \nstate information about this SA, which will include:\n\u2022 A 32-bit identifier for the SA, called the Security Parameter Index (SPI)\n\u2022 The origin interface of the SA (in this case 200.168.1.100) and the destination \ninterface of the SA (in this case 193.68.2.23)\n\u2022 The type of encryption to be used (for example, 3DES with CBC)\n\u2022 The encryption key\n\u2022 The type of integrity check (for example, HMAC with MD5)\n\u2022 The authentication key\nWhenever router R1 needs to construct an IPsec datagram for forwarding over \nthis SA, it accesses this state information to determine how it should authenticate \nand encrypt the datagram. Similarly, router R2 will maintain the same state informa -\ntion for this SA and will use this information to authenticate and decrypt any IPsec \ndatagram that arrives from the SA.\nAn IPsec entity (router or host) often maintains state information for many SAs. \nFor example, in the VPN example in Figure 8.27 with n salespersons, the headquar -\nters gateway router maintains state information for (2 + 2n) SAs. An IPsec entity \nstores the state information for all of its SAs in its Security Association Database  \n(SAD ), which is a data structure in the entity\u2019s OS kernel.\n8.7.4 The IPsec Datagram\nHaving now described SAs, we can now describe the actual IPsec datagram. IPsec \nhas two different packet forms, one for the so-called tunnel mode  and the other for \nthe so-called transport mode . The tunnel mode, being more appropriate for VPNs, Figure 8.28  \u2666 Security association (SA) from R1 to R2Internet\nSAR1\n172.16.1/24Headquarters Branch Of \ufb01ce\n200.168.1.100 193.68.2.23\n172.16.2/24R2\n670     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nis more widely deployed than the transport mode. In order to further de-mystify \nIPsec and avoid much of its complication, we henceforth focus exclusively on the \ntunnel mode. Once you have a solid grip on the tunnel mode, you should be able to \neasily learn about the transport mode on your own.\nThe packet format of the IPsec datagram is shown in Figure 8.29. You might \nthink that packet formats are boring and insipid, but we will soon see that the IPsec \ndatagram actually looks and tastes like a popular Tex-Mex delicacy! Let\u2019s examine \nthe IPsec fields in the context of Figure 8.28. Suppose router R1 receives an ordinary \nIPv4 datagram from host 172.16.1.17 (in the headquarters network) which is destined \nto host 172.16.2.48 (in the branch-office network). Router R1 uses the  following \nrecipe to convert this \u201coriginal IPv4 datagram\u201d into an IPsec datagram:\n\u2022 Appends to the back of the original IPv4 datagram (which includes the original \nheader fields!) an \u201cESP trailer\u201d field\n\u2022 Encrypts the result using the algorithm and key specified by the SA\n\u2022 Appends to the front of this encrypted quantity a field called \u201cESP header\u201d; the \nresulting package is called the \u201cenchilada\u201d\n\u2022 Creates an authentication MAC over the whole enchilada  using the algorithm and \nkey specified in the SA\n\u2022 Appends the MAC to the back of the enchilada forming the payload\n\u2022 Finally, creates a brand new IP header with all the classic IPv4 header fields \n(together normally 20 bytes long), which it appends before the payload\nNote that the resulting IPsec datagram is a bona fide IPv4 datagram, with the \ntraditional IPv4 header fields followed by a", "doc_id": "2e2e8e5f-b8f6-4aed-b9d4-b83b91372d26", "embedding": null, "doc_hash": "04a7bed1754a41d86f1d4bfa2d2c1f70c8e8a6e10b69d5d9f3d0599acbd18d64", "extra_info": null, "node_info": {"start": 1968381, "end": 1971926}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "c497851d-2f87-4323-81b4-859a87e8e5bc", "3": "0453f06c-1ac2-4dd6-8c90-8ecdaa5e0965"}}, "__type__": "1"}, "0453f06c-1ac2-4dd6-8c90-8ecdaa5e0965": {"__data__": {"text": "back of the original IPv4 datagram (which includes the original \nheader fields!) an \u201cESP trailer\u201d field\n\u2022 Encrypts the result using the algorithm and key specified by the SA\n\u2022 Appends to the front of this encrypted quantity a field called \u201cESP header\u201d; the \nresulting package is called the \u201cenchilada\u201d\n\u2022 Creates an authentication MAC over the whole enchilada  using the algorithm and \nkey specified in the SA\n\u2022 Appends the MAC to the back of the enchilada forming the payload\n\u2022 Finally, creates a brand new IP header with all the classic IPv4 header fields \n(together normally 20 bytes long), which it appends before the payload\nNote that the resulting IPsec datagram is a bona fide IPv4 datagram, with the \ntraditional IPv4 header fields followed by a payload. But in this case, the payload \ncontains an ESP header, the original IP datagram, an ESP trailer, and an ESP authen -\ntication field (with the original datagram and ESP trailer encrypted). The origi -\nnal IP datagram has 172.16.1.17 for the source IP address and 172.16.2.48 for the Figure 8.29  \u2666 IPsec datagram formatNew IP\nheaderESP\nheaderESP\ntrailerESP\nMACOriginal\nIP headerOriginal IP\ndatagram payloadEncrypted\u201cEnchilada\u201d authenticated\nPad\nlengthPaddingNext\nheaderSPI Seq #\n8.7  \u2022  NETWORK-LAYER SECURITY: IPSEC AND VIRTUAL PRIVATE NETWORKS      671\ndestination IP address. Because the IPsec datagram includes the original IP data -\ngram, these addresses are included (and encrypted) as part of the payload of the \nIPsec packet. But what about the source and destination IP addresses that are in the \nnew IP header, that is, in the left-most header of the IPsec datagram? As you might \nexpect, they are set to the source and destination router interfaces at the two ends of \nthe tunnels, namely, 200.168.1.100 and 193.68.2.23. Also, the protocol number in \nthis new IPv4 header field is not set to that of TCP, UDP, or SMTP, but instead to 50, \ndesignating that this is an IPsec datagram using the ESP protocol.\nAfter R1 sends the IPsec datagram into the public Internet, it will pass through \nmany routers before reaching R2. Each of these routers will process the datagram as if it \nwere an ordinary datagram\u2014they are completely oblivious to the fact that the datagram \nis carrying IPsec-encrypted data. For these public Internet routers, because the destina -\ntion IP address in the outer header is R2, the ultimate destination of the datagram is R2.\nHaving walked through an example of how an IPsec datagram is constructed, \nlet\u2019s now take a closer look at the ingredients in the enchilada. We see in Figure 8.29 \nthat the ESP trailer consists of three fields: padding; pad length; and next header. \nRecall that block ciphers require the message to be encrypted to be an integer mul -\ntiple of the block length. Padding (consisting of meaningless bytes) is used so that \nwhen added to the original datagram (along with the pad length and next header \nfields), the resulting \u201cmessage\u201d is an integer number of blocks. The pad-length field \nindicates to the receiving entity how much padding was inserted (and thus needs to \nbe removed). The next header identifies the type (e.g., UDP) of data contained in the \npayload-data field. The payload data (typically the original IP datagram) and the ESP \ntrailer are concatenated and then encrypted.\nAppended to the front of this encrypted unit is the ESP header, which is sent in \nthe clear and consists of two fields: the SPI and the sequence number field. The SPI \nindicates to the receiving entity the SA to which the datagram belongs; the receiving \nentity can then index its SAD with the SPI to determine the appropriate authentica -\ntion/decryption algorithms and keys. The sequence number field is used to defend \nagainst replay attacks.\nThe", "doc_id": "0453f06c-1ac2-4dd6-8c90-8ecdaa5e0965", "embedding": null, "doc_hash": "5af3d2a62c620dc018c4f4e6f2a11e9d6c58df99b50d418ea7aa8bf2383aa169", "extra_info": null, "node_info": {"start": 1971859, "end": 1975619}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "2e2e8e5f-b8f6-4aed-b9d4-b83b91372d26", "3": "ff9b3115-4276-4746-893a-7f96949bb7bb"}}, "__type__": "1"}, "ff9b3115-4276-4746-893a-7f96949bb7bb": {"__data__": {"text": "The pad-length field \nindicates to the receiving entity how much padding was inserted (and thus needs to \nbe removed). The next header identifies the type (e.g., UDP) of data contained in the \npayload-data field. The payload data (typically the original IP datagram) and the ESP \ntrailer are concatenated and then encrypted.\nAppended to the front of this encrypted unit is the ESP header, which is sent in \nthe clear and consists of two fields: the SPI and the sequence number field. The SPI \nindicates to the receiving entity the SA to which the datagram belongs; the receiving \nentity can then index its SAD with the SPI to determine the appropriate authentica -\ntion/decryption algorithms and keys. The sequence number field is used to defend \nagainst replay attacks.\nThe sending entity also appends an authentication MAC. As stated earlier, the \nsending entity calculates a MAC over the whole enchilada (consisting of the ESP \nheader, the original IP datagram, and the ESP trailer\u2014with the datagram and trailer \nbeing encrypted). Recall that to calculate a MAC, the sender appends a secret MAC \nkey to the enchilada and then calculates a fixed-length hash of the result.\nWhen R2 receives the IPsec datagram, R2 observes that the destination IP \naddress of the datagram is R2 itself. R2 therefore processes the datagram. Because \nthe protocol field (in the left-most IP header) is 50, R2 sees that it should apply \nIPsec ESP processing to the datagram. First, peering into the enchilada, R2 uses the \nSPI to determine to which SA the datagram belongs. Second, it calculates the MAC \nof the enchilada and verifies that the MAC is consistent with the value in the ESP \nMAC field. If it is, it knows that the enchilada comes from R1 and has not been tam -\npered with. Third, it checks the sequence-number field to verify that the datagram is \n672     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nfresh (and not a replayed datagram). Fourth, it decrypts the encrypted unit using the \ndecryption algorithm and key associated with the SA. Fifth, it removes padding and \nextracts the original, vanilla IP datagram. And finally, sixth, it forwards the original \ndatagram into the branch office network toward its ultimate destination. Whew, what \na complicated recipe, huh? Well no one ever said that preparing and unraveling an \nenchilada was easy!\nThere is actually another important subtlety that needs to be addressed. It centers \non the following question: When R1 receives an (unsecured) datagram from a host \nin the headquarters network, and that datagram is destined to some destination IP \naddress outside of headquarters, how does R1 know whether it should be converted to \nan IPsec datagram? And if it is to be processed by IPsec, how does R1 know which SA \n(of many SAs in its SAD) should be used to construct the IPsec datagram? The prob -\nlem is solved as follows. Along with a SAD, the IPsec entity also maintains another \ndata structure called the Security Policy Database (SPD) . The SPD indicates what \ntypes of datagrams (as a function of source IP address, destination IP address, and \nprotocol type) are to be IPsec processed; and for those that are to be IPsec processed, \nwhich SA should be used. In a sense, the information in a SPD indicates \u201cwhat\u201d to \ndo with an arriving datagram; the information in the SAD indicates \u201chow\u201d to do it.\nSummary of IPsec Services\nSo what services does IPsec provide, exactly? Let us examine these services from \nthe perspective of an attacker, say Trudy, who is a woman-in-the-middle, sitting \nsomewhere on the path between R1 and R2 in Figure 8.28. Assume throughout this \n discussion that Trudy does not know the authentication and encryption keys used by \nthe SA. What can and cannot Trudy", "doc_id": "ff9b3115-4276-4746-893a-7f96949bb7bb", "embedding": null, "doc_hash": "912ac2aaec7373fbaadc94327841bf8e640d657282ac2330371b1e883147c275", "extra_info": null, "node_info": {"start": 1975600, "end": 1979346}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "0453f06c-1ac2-4dd6-8c90-8ecdaa5e0965", "3": "6fea1f64-a948-4bf2-ba5d-bac639c82b2d"}}, "__type__": "1"}, "6fea1f64-a948-4bf2-ba5d-bac639c82b2d": {"__data__": {"text": "a function of source IP address, destination IP address, and \nprotocol type) are to be IPsec processed; and for those that are to be IPsec processed, \nwhich SA should be used. In a sense, the information in a SPD indicates \u201cwhat\u201d to \ndo with an arriving datagram; the information in the SAD indicates \u201chow\u201d to do it.\nSummary of IPsec Services\nSo what services does IPsec provide, exactly? Let us examine these services from \nthe perspective of an attacker, say Trudy, who is a woman-in-the-middle, sitting \nsomewhere on the path between R1 and R2 in Figure 8.28. Assume throughout this \n discussion that Trudy does not know the authentication and encryption keys used by \nthe SA. What can and cannot Trudy do? First, Trudy cannot see the original data -\ngram. If fact, not only is the data in the original datagram hidden from Trudy, but \nso is the protocol number, the source IP address, and the destination IP address. For \ndatagrams sent over the SA, Trudy only knows that the datagram originated from \nsome host in 172.16.1.0/24 and is destined to some host in 172.16.2.0/24. She does \nnot know if it is carrying TCP, UDP, or ICMP data; she does not know if it is carrying \nHTTP, SMTP, or some other type of application data. This confidentiality thus goes \na lot farther than SSL. Second, suppose Trudy tries to tamper with a datagram in the \nSA by flipping some of its bits. When this tampered datagram arrives at R2, it will \nfail the integrity check (using the MAC), thwarting Trudy\u2019s vicious attempts once \nagain. Third, suppose Trudy tries to masquerade as R1, creating a IPsec datagram \nwith source 200.168.1.100 and destination 193.68.2.23. Trudy\u2019s attack will be futile, \nas this datagram will again fail the integrity check at R2. Finally, because IPsec \nincludes sequence numbers, Trudy will not be able create a successful replay attack. \nIn summary, as claimed at the beginning of this section, IPsec provides\u2014between \nany pair of devices that process packets through the network layer\u2014confidentiality, \nsource authentication, data integrity, and replay-attack prevention.\n8.7  \u2022  NETWORK-LAYER SECURITY: IPSEC AND VIRTUAL PRIVATE NETWORKS      673\n8.7.5 IKE: Key Management in IPsec\nWhen a VPN has a small number of end points (for example, just two routers as \nin Figure 8.28), the network administrator can manually enter the SA information \n(encryption/authentication algorithms and keys, and the SPIs) into the SADs of the \nendpoints. Such \u201cmanual keying\u201d is clearly impractical for a large VPN, which \nmay consist of hundreds or even thousands of IPsec routers and hosts. Large, geo -\ngraphically distributed deployments require an automated mechanism for creating \nthe SAs. IPsec does this with the Internet Key Exchange (IKE) protocol, specified \nin RFC 5996.\nIKE has some similarities with the handshake in SSL (see Section 8.6). Each \nIPsec entity has a certificate, which includes the entity\u2019s public key. As with SSL, \nthe IKE protocol has the two entities exchange certificates, negotiate authentication \nand encryption algorithms, and securely exchange key material for creating session \nkeys in the IPsec SAs. Unlike SSL, IKE employs two phases to carry out these tasks.\nLet\u2019s investigate these two phases in the context of two routers, R1 and R2,  \nin Figure 8.28. The first phase consists of two exchanges of message pairs between \nR1 and R2:\n\u2022 During the first exchange of messages, the two sides use Diffie-Hellman (see \nHomework Problems) to create a bi-directional IKE SA  between the routers. To \nkeep us all confused,", "doc_id": "6fea1f64-a948-4bf2-ba5d-bac639c82b2d", "embedding": null, "doc_hash": "cbdef8df7da517d380fa806afa63a7c6155f53788f6dd840c33633d0940bc7fd", "extra_info": null, "node_info": {"start": 1979410, "end": 1982967}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "ff9b3115-4276-4746-893a-7f96949bb7bb", "3": "d9a37cc1-262b-4343-9ec9-2fe1deb9b6c0"}}, "__type__": "1"}, "d9a37cc1-262b-4343-9ec9-2fe1deb9b6c0": {"__data__": {"text": "Each \nIPsec entity has a certificate, which includes the entity\u2019s public key. As with SSL, \nthe IKE protocol has the two entities exchange certificates, negotiate authentication \nand encryption algorithms, and securely exchange key material for creating session \nkeys in the IPsec SAs. Unlike SSL, IKE employs two phases to carry out these tasks.\nLet\u2019s investigate these two phases in the context of two routers, R1 and R2,  \nin Figure 8.28. The first phase consists of two exchanges of message pairs between \nR1 and R2:\n\u2022 During the first exchange of messages, the two sides use Diffie-Hellman (see \nHomework Problems) to create a bi-directional IKE SA  between the routers. To \nkeep us all confused, this bi-directional IKE SA is entirely different from the \nIPsec SAs discussed in Sections 8.6.3 and 8.6.4. The IKE SA provides an authen -\nticated and encrypted channel between the two routers. During this first message-\npair exchange, keys are established for encryption and authentication for the IKE \nSA. Also established is a master secret that will be used to compute IPSec SA \nkeys later in phase 2. Observe that during this first step, RSA public and private \nkeys are not used. In particular, neither R1 nor R2 reveals its identity by signing \na message with its private key.\n\u2022 During the second exchange of messages, both sides reveal their identity to each \nother by signing their messages. However, the identities are not revealed to a pas -\nsive sniffer, since the messages are sent over the secured IKE SA channel. Also \nduring this phase, the two sides negotiate the IPsec encryption and authentication \nalgorithms to be employed by the IPsec SAs.\nIn phase 2 of IKE, the two sides create an SA in each direction. At the end of \nphase 2, the encryption and authentication session keys are established on both sides \nfor the two SAs. The two sides can then use the SAs to send secured datagrams, as \ndescribed in Sections 8.7.3 and 8.7.4. The primary motivation for having two phases \nin IKE is computational cost\u2014since the second phase doesn\u2019t involve any public-\nkey cryptography, IKE can generate a large number of SAs between the two IPsec \nentities with relatively little computational cost.\n674     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\n8.8 Securing Wireless LANs\nSecurity is a particularly important concern in wireless networks, where radio waves \ncarrying frames can propagate far beyond the building containing the wireless base \nstation and hosts. In this section we present a brief introduction to wireless security. \nFor a more in-depth treatment, see the highly readable book by Edney and Arbaugh \n[Edney 2003].\nThe issue of security in 802.11 has attracted considerable attention in both \ntechnical circles and in the media. While there has been considerable discussion, \nthere has been little debate\u2014there seems to be universal agreement that the origi -\nnal 802.11 specification contains a number of serious security flaws. Indeed, public \ndomain software can now be downloaded that exploits these holes, making those \nwho use the vanilla 802.11 security mechanisms as open to security attacks as users \nwho use no security features at all.\nIn the following section, we discuss the security mechanisms initially standard -\nized in the 802.11 specification, known collectively as Wired Equivalent Privacy \n(WEP) . As the name suggests, WEP is meant to provide a level of security similar to \nthat found in wired networks. We\u2019ll then discuss a few of the security holes in WEP \nand discuss the 802.11i standard, a fundamentally more secure version of 802.11 \nadopted in 2004.\n8.8.1 Wired Equivalent Privacy (WEP)\nThe IEEE 802.11 WEP protocol was designed in 1999 to provide authentication and \ndata encryption between a host and a wireless access point (that is, base station) using \na symmetric", "doc_id": "d9a37cc1-262b-4343-9ec9-2fe1deb9b6c0", "embedding": null, "doc_hash": "fb16406b1551e7a06ec3c0b44848485d9b8d5da8de5bb8e181838fd93a597e7d", "extra_info": null, "node_info": {"start": 1982966, "end": 1986800}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "6fea1f64-a948-4bf2-ba5d-bac639c82b2d", "3": "7c4f17cc-3cf8-4b19-b680-6cf3e223d761"}}, "__type__": "1"}, "7c4f17cc-3cf8-4b19-b680-6cf3e223d761": {"__data__": {"text": "security mechanisms as open to security attacks as users \nwho use no security features at all.\nIn the following section, we discuss the security mechanisms initially standard -\nized in the 802.11 specification, known collectively as Wired Equivalent Privacy \n(WEP) . As the name suggests, WEP is meant to provide a level of security similar to \nthat found in wired networks. We\u2019ll then discuss a few of the security holes in WEP \nand discuss the 802.11i standard, a fundamentally more secure version of 802.11 \nadopted in 2004.\n8.8.1 Wired Equivalent Privacy (WEP)\nThe IEEE 802.11 WEP protocol was designed in 1999 to provide authentication and \ndata encryption between a host and a wireless access point (that is, base station) using \na symmetric shared key approach. WEP does not specify a key management algo -\nrithm, so it is assumed that the host and wireless access point have somehow agreed \non the key via an out-of-band method. Authentication is carried out as  follows:\n 1. A wireless host requests authentication by an access point.\n 2. The access point responds to the authentication request with a 128-byte nonce \nvalue.\n 3. The wireless host encrypts the nonce using the symmetric key that it shares \nwith the access point.\n 4. The access point decrypts the host-encrypted nonce.\nIf the decrypted nonce matches the nonce value originally sent to the host, then the \nhost is authenticated by the access point.\nThe WEP data encryption algorithm is illustrated in Figure 8.30. A secret \n40-bit symmetric key, KS, is assumed to be known by both a host and the access \npoint. In addition, a 24-bit Initialization Vector (IV) is appended to the 40-bit \nkey to create a 64-bit key that will be used to encrypt a single frame. The IV will \n8.8  \u2022  SECURING WIRELESS LANS      675\nchange from one frame to another, and hence each frame will be encrypted with \na different 64-bit key. Encryption is performed as follows. First a 4-byte CRC \nvalue (see Section 6.2 ) is computed for the data payload. The payload and the four \nCRC bytes are then encrypted using the RC4 stream cipher. We will not cover \nthe details of RC4 here (see [Schneier 1995] and [Edney 2003] for details). For \nour purposes, it is enough to know that when presented with a key value (in this \ncase, the 64-bit ( KS, IV) key), the RC4 algorithm produces a stream of key values,  \nk1IV, k2IV, k3IV, . . . that are used to encrypt the data and CRC value in a frame. For \npractical purposes, we can think of these operations being performed a byte at a \ntime. Encryption is performed by XOR-ing the ith byte of data, di, with the ith key, \nki IV, in the stream of key values generated by the ( KS, IV) pair to produce the ith \nbyte of ciphertext, ci:\nci=di/uni2295.altkiIV\nThe IV value changes from one frame to the next and is included in plaintext  \nin the header of each WEP-encrypted 802.11 frame, as shown in Figure 8.30. The \nreceiver takes the secret 40-bit symmetric key that it shares with the sender, appends \nthe IV, and uses the resulting 64-bit key (which is identical to the key used by the \nsender to perform encryption) to decrypt the frame:\ndi=ci/uni2295.altkiIV\nProper use of the RC4 algorithm requires that the same 64-bit key value \nnever  be used more than once. Recall that the WEP key changes on a frame-\nby-frame basis. For a given KS (which changes rarely, if ever), this means that \nthere are only 224 unique keys. If these keys are chosen randomly, we can show \n[Edney 2003] that the probability of having chosen the same IV value (and hence \nused the same 64-bit key) is more than 99 percent after only 12,000 frames. With ", "doc_id": "7c4f17cc-3cf8-4b19-b680-6cf3e223d761", "embedding": null, "doc_hash": "11f55b3c44c1743fe3519f127b0b83f7d49e71287e3b56ad048dd01c7b9f5127", "extra_info": null, "node_info": {"start": 1986760, "end": 1990384}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "d9a37cc1-262b-4343-9ec9-2fe1deb9b6c0", "3": "2896608c-533e-4013-98ff-d5c0714d38fe"}}, "__type__": "1"}, "2896608c-533e-4013-98ff-d5c0714d38fe": {"__data__": {"text": "secret 40-bit symmetric key that it shares with the sender, appends \nthe IV, and uses the resulting 64-bit key (which is identical to the key used by the \nsender to perform encryption) to decrypt the frame:\ndi=ci/uni2295.altkiIV\nProper use of the RC4 algorithm requires that the same 64-bit key value \nnever  be used more than once. Recall that the WEP key changes on a frame-\nby-frame basis. For a given KS (which changes rarely, if ever), this means that \nthere are only 224 unique keys. If these keys are chosen randomly, we can show \n[Edney 2003] that the probability of having chosen the same IV value (and hence \nused the same 64-bit key) is more than 99 percent after only 12,000 frames. With  \n1 Kbyte frame sizes and a data transmission rate of 11 Mbps, only a few seconds are Figure 8.30  \u2666 802.11 WEP protocolKey sequence generator\n(for given Ks, IV)\nk1IV\nd1\nc1k2IVk3IVkNIV IVkN+1IVkN+4Ks: 40-bit secret symmetric\nPlaintext frame data plus CRCIV (per frame)\n802.11\nheaderIVWEP-encrypted data\nplus CRC\nd2\nc2d3\nc3dN\ncNCRC1\ncN+1 cN+4CRC4\n676     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nneeded before 12,000 frames are transmitted. Furthermore, since the IV is transmit -\nted in plaintext in the frame, an eavesdropper will know whenever a duplicate IV \nvalue is used.\nTo see one of the several problems that occur when a duplicate key is used, \nconsider the following chosen-plaintext attack taken by Trudy against Alice. Sup -\npose that Trudy (possibly using IP spoofing) sends a request (for example, an HTTP  \nor FTP request) to Alice to transmit a file with known content, d1, d2, d3, d4,. . . . \nTrudy also observes the encrypted data c1, c2, c3, c4. . . . Since di=ci/uni2295.altkiIV, if we \nXOR ci with each side of this equality we have\ndi/uni2295.altci=kiIV\nWith this relationship, Trudy can use the known values of di and ci to compute kiIV. \nThe next time Trudy sees the same value of IV being used, she will know the key \nsequence k1IV, k2IV, k3IV, . . . and will thus be able to decrypt the encrypted message.\nThere are several additional security concerns with WEP as well. [Fluhrer \n2001] described an attack exploiting a known weakness in RC4 when certain weak \nkeys are chosen. [Stubblefield 2002] discusses efficient ways to implement and \nexploit this attack. Another concern with WEP involves the CRC bits shown in \nFigure 8. 30 and transmitted in the 802.11 frame to detect altered bits in the pay -\nload. However, an attacker who changes the encrypted content (e.g., substituting \ngibberish for the original encrypted data), computes a CRC over the substituted \ngibberish, and places the CRC into a WEP frame can produce an 802.11 frame \nthat will be accepted by the receiver. What is needed here are message integrity \ntechniques such as those we studied in Section 8.3 to detect content tampering or \nsubstitution. For more details of WEP security, see [Edney 2003; Wright 2015] and \nthe  references therein.\n8.8.2 IEEE 802.11i\nSoon after the 1999 release of IEEE 802.11, work began on developing a new and \nimproved version of 802.11 with stronger security mechanisms. The new standard, \nknown as 802.11i, underwent final ratification in 2004. As we\u2019ll see, while WEP \nprovided relatively weak encryption, only a single way to perform authentication, \nand no key distribution mechanisms, IEEE", "doc_id": "2896608c-533e-4013-98ff-d5c0714d38fe", "embedding": null, "doc_hash": "8eda1c3864aa6dcded92a92e05003035d1f3ac5efdaa5db39859de1c5ce381e8", "extra_info": null, "node_info": {"start": 1990436, "end": 1993768}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "7c4f17cc-3cf8-4b19-b680-6cf3e223d761", "3": "2f80f4f9-02c2-4108-aa0f-ab4199a8ed13"}}, "__type__": "1"}, "2f80f4f9-02c2-4108-aa0f-ab4199a8ed13": {"__data__": {"text": "places the CRC into a WEP frame can produce an 802.11 frame \nthat will be accepted by the receiver. What is needed here are message integrity \ntechniques such as those we studied in Section 8.3 to detect content tampering or \nsubstitution. For more details of WEP security, see [Edney 2003; Wright 2015] and \nthe  references therein.\n8.8.2 IEEE 802.11i\nSoon after the 1999 release of IEEE 802.11, work began on developing a new and \nimproved version of 802.11 with stronger security mechanisms. The new standard, \nknown as 802.11i, underwent final ratification in 2004. As we\u2019ll see, while WEP \nprovided relatively weak encryption, only a single way to perform authentication, \nand no key distribution mechanisms, IEEE 802.11i provides for much stronger forms \nof encryption, an extensible set of authentication mechanisms, and a key distribu -\ntion mechanism. In the following, we present an overview of 802.11i; an excellent \n(streaming audio) technical overview of 802.11i is [TechOnline 2012].\nFigure 8. 31 overviews the 802.11i framework. In addition to the wireless cli -\nent and access point, 802.11i defines an authentication server with which the AP \ncan communicate. Separating the authentication server from the AP allows one \nauthentication server to serve many APs, centralizing the (often sensitive) decisions \n8.8  \u2022  SECURING WIRELESS LANS      677\nregarding authentication and access within the single server, and keeping AP costs \nand complexity low. 802.11i operates in four phases:\n 1. Discovery.  In the discovery phase, the AP advertises its presence and the forms \nof authentication and encryption that can be provided to the wireless client \nnode. The client then requests the specific forms of authentication and encryp-\ntion that it desires. Although the client and AP are already exchanging mes-\nsages, the client has not yet been authenticated nor does it have an encryption \nkey, and so several more steps will be required before the client can communi-\ncate with an arbitrary remote host over the wireless channel.\n 2. Mutual authentication and Master Key (MK) generation.  Authentication takes \nplace between the wireless client and the authentication server. In this phase, the \naccess point acts essentially as a relay, forwarding messages between the client  \nand the authentication server. The Extensible Authentication Protocol (EAP)  \n[RFC 3748] defines the end-to-end message formats used in a simple request/\nresponse mode of interaction between the client and authentication server. As \nshown in Figure 8.32, EAP messages are encapsulated using EAPoL  (EAP over \nLAN, [IEEE 802.1X]) and sent over the 802.11 wireless link. These EAP mes -\nsages are then decapsulated at the access point, and then re-encapsulated using the \nRADIUS  protocol for transmission over UDP/IP to the authentication server. While Figure 8.31  \u2666 802.11i: Four phases of operationSTA:\nclient stationAP:\naccess point\nWired\nnetworkAS:\nauthentication\nserver\n1\nDiscovery of\nsecurity capabilities\n4\nSTA, AP use PMK to derive\nTemporal Key (TK) used for\nmessage encryption, integrityAS derives same PMK,\nsends to APSTA derives Pairwise \nMaster Key (PMK)2\n3 3STA and AS mutually authenticate, together generate\nMaster Key (MK). AP serves as \u201cpass through\u201d\n678     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nthe RADIUS server and protocol [RFC 2865] are not required by the 802.11i pro -\ntocol, they are de facto  standard components for 802.11i. The recently standardized \nDIAMETER  protocol [RFC 3588] is likely to replace RADIUS in the near future.\nWith EAP, the authentication server can choose one of a number of ways \nto perform authentication. While", "doc_id": "2f80f4f9-02c2-4108-aa0f-ab4199a8ed13", "embedding": null, "doc_hash": "d826423c6a72e14dd7ca669f9964e2274c2f852343743b423c162ef81ddf5c69", "extra_info": null, "node_info": {"start": 1993743, "end": 1997408}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "2896608c-533e-4013-98ff-d5c0714d38fe", "3": "3c257d56-e09f-44c1-9a6e-404fdfc979cd"}}, "__type__": "1"}, "3c257d56-e09f-44c1-9a6e-404fdfc979cd": {"__data__": {"text": "(TK) used for\nmessage encryption, integrityAS derives same PMK,\nsends to APSTA derives Pairwise \nMaster Key (PMK)2\n3 3STA and AS mutually authenticate, together generate\nMaster Key (MK). AP serves as \u201cpass through\u201d\n678     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nthe RADIUS server and protocol [RFC 2865] are not required by the 802.11i pro -\ntocol, they are de facto  standard components for 802.11i. The recently standardized \nDIAMETER  protocol [RFC 3588] is likely to replace RADIUS in the near future.\nWith EAP, the authentication server can choose one of a number of ways \nto perform authentication. While 802.11i does not mandate a particular authen-\ntication method, the EAP-TLS authentication scheme [RFC 5216] is often \nused. EAP-TLS uses public key techniques (including nonce encryption and \nmessage digests) similar to those we studied in Section 8.3 to allow the client \nand the authentication server to mutually authenticate each other, and to derive \na Master Key (MK) that is known to both parties.\n 3. Pairwise Master Key (PMK) generation.  The MK is a shared secret known \nonly to the client and the authentication server, which they each use to generate \na second key, the Pairwise Master Key (PMK). The authentication server then \nsends the PMK to the AP. This is where we wanted to be! The client and AP \nnow have a shared key (recall that in WEP, the problem of key distribution was \nnot addressed at all) and have mutually authenticated each other. They\u2019re just \nabout ready to get down to business.\n 4. Temporal Key (TK) generation.  With the PMK, the wireless client and AP can \nnow generate additional keys that will be used for communication. Of  particular \ninterest is the Temporal Key (TK), which will be used to perform the link-level \nencryption of data sent over the wireless link and to an arbitrary remote host.\n802.11i provides several forms of encryption, including an AES-based encryption \nscheme and a strengthened version of WEP encryption.Figure 8.32  \u2666  EAP is an end-to-end protocol. EAP messages are encap -\nsulated using EAPoL over the wireless link between the \n client and the access point, and using RADIUS over UDP/IP \nbetween the access point and the authentication serverSTA:\nclient stationAP:\naccess point\nWired\nnetworkAS:\nauthentication\nserver\nEAP TLS\nEAP\nEAP over LAN (EAPoL) RADIUS\nIEEE 802.11 UDP/IP\n8.9  \u2022  OPERATIONAL SECURITY: FIREWALLS AND INTRUSION DETECTION SYSTEMS      679\n8.9 Operational Security: Firewalls and Intrusion \nDetection Systems\nWe\u2019ve seen throughout this chapter that the Internet is not a very safe place\u2014bad \nguys are out there, wreaking all sorts of havoc. Given the hostile nature of the \nInternet, let\u2019s now consider an organization\u2019s network and the network administra -\ntor who administers it. From a network administrator\u2019s point of view, the world \ndivides quite neatly into two camps\u2014the good guys (who belong to the organiza -\ntion\u2019s network, and who should be able to access resources inside the organiza -\ntion\u2019s network in a relatively unconstrained manner) and the bad guys (everyone \nelse, whose access to network resources must be carefully scrutinized). In many \norganizations, ranging from medieval castles to modern corporate office buildings, \nthere is a single point of entry/exit where both good guys and bad guys entering and \nleaving the organization are security-checked. In a castle, this was done at a gate \nat one end of the drawbridge; in a corporate building, this is done at the security \ndesk. In a computer network, when traffic entering/leaving", "doc_id": "3c257d56-e09f-44c1-9a6e-404fdfc979cd", "embedding": null, "doc_hash": "5036f90e1c7b2db1ff13603110a9a8ae941830f004adf3e10526dd164cd8fc83", "extra_info": null, "node_info": {"start": 1997492, "end": 2001057}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "2f80f4f9-02c2-4108-aa0f-ab4199a8ed13", "3": "88ce8775-ef34-40c5-a9d5-fb9bd7d0a233"}}, "__type__": "1"}, "88ce8775-ef34-40c5-a9d5-fb9bd7d0a233": {"__data__": {"text": "network administrator\u2019s point of view, the world \ndivides quite neatly into two camps\u2014the good guys (who belong to the organiza -\ntion\u2019s network, and who should be able to access resources inside the organiza -\ntion\u2019s network in a relatively unconstrained manner) and the bad guys (everyone \nelse, whose access to network resources must be carefully scrutinized). In many \norganizations, ranging from medieval castles to modern corporate office buildings, \nthere is a single point of entry/exit where both good guys and bad guys entering and \nleaving the organization are security-checked. In a castle, this was done at a gate \nat one end of the drawbridge; in a corporate building, this is done at the security \ndesk. In a computer network, when traffic entering/leaving a network is security-\nchecked, logged, dropped, or forwarded, it is done by operational devices known \nas firewalls, intrusion detection systems (IDSs), and intrusion prevention systems \n(IPSs).\n8.9.1 Firewalls\nA firewall  is a combination of hardware and software that isolates an organization\u2019s \ninternal network from the Internet at large, allowing some packets to pass and block -\ning others. A firewall allows a network administrator to control access between the \noutside world and resources within the administered network by managing the traffic \nflow to and from these resources. A firewall has three goals:\n\u2022 All traffic from outside to inside, and vice versa, passes through the firewall . \nFigure 8. 33 shows a firewall, sitting squarely at the boundary between the admin -\nistered network and the rest of the Internet. While large organizations may use \nmultiple levels of firewalls or distributed firewalls [Skoudis 2006], locating a \nfirewall at a single access point to the network, as shown in Figure 8.33, makes it \neasier to manage and enforce a security-access policy.\n\u2022 Only authorized traffic, as defined by the local security policy, will be allowed \nto pass . With all traffic entering and leaving the institutional network passing \nthrough the firewall, the firewall can restrict access to authorized traffic.\n\u2022 The firewall itself is immune to penetration . The firewall itself is a device con -\nnected to the network. If not designed or installed properly, it can be compro -\nmised, in which case it provides only a false sense of security (which is worse \nthan no firewall at all!).\n680     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nCisco and Check Point are two of the leading firewall vendors today. You can also easily \ncreate a firewall (packet filter) from a Linux box using iptables (public-domain software \nthat is normally shipped with Linux). Furthermore, as discussed in Chapters 4 and 5, fire -\nwalls are now frequently implemented in routers and controlled remotely using SDNs.\nFirewalls can be classified in three categories: traditional packet filters , state-\nful filters , and application gateways . We\u2019ll cover each of these in turn in the fol -\nlowing subsections.\nTraditional Packet Filters\nAs shown in Figure 8.33, an organization typically has a gateway router connecting \nits internal network to its ISP (and hence to the larger public Internet). All traffic leav -\ning and entering the internal network passes through this router, and it is at this router \nwhere packet filtering  occurs. A packet filter examines each datagram in isolation, \ndetermining whether the datagram should be allowed to pass or should be dropped \nbased on administrator-specific rules. Filtering decisions are typically based on:\n\u2022 IP source or destination address\n\u2022 Protocol type in IP datagram field: TCP, UDP, ICMP, OSPF, and so on\n\u2022 TCP or UDP source and destination portFigure 8.33  \u2666  Firewall placement between the administered network and \nthe outside worldAdministered\nnetworkFirewallPublic\nInternet\n8.9  \u2022  OPERATIONAL SECURITY: FIREWALLS AND INTRUSION DETECTION SYSTEMS      681\n\u2022 TCP flag bits:", "doc_id": "88ce8775-ef34-40c5-a9d5-fb9bd7d0a233", "embedding": null, "doc_hash": "eeea7ee8e9709170dde67802b2d8a518ca2e2d4be6ed28ebfbdf3c9f279f8bef", "extra_info": null, "node_info": {"start": 2000929, "end": 2004841}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "3c257d56-e09f-44c1-9a6e-404fdfc979cd", "3": "cad56b14-8d2d-4395-8cf2-c478de344d7d"}}, "__type__": "1"}, "cad56b14-8d2d-4395-8cf2-c478de344d7d": {"__data__": {"text": "-\ning and entering the internal network passes through this router, and it is at this router \nwhere packet filtering  occurs. A packet filter examines each datagram in isolation, \ndetermining whether the datagram should be allowed to pass or should be dropped \nbased on administrator-specific rules. Filtering decisions are typically based on:\n\u2022 IP source or destination address\n\u2022 Protocol type in IP datagram field: TCP, UDP, ICMP, OSPF, and so on\n\u2022 TCP or UDP source and destination portFigure 8.33  \u2666  Firewall placement between the administered network and \nthe outside worldAdministered\nnetworkFirewallPublic\nInternet\n8.9  \u2022  OPERATIONAL SECURITY: FIREWALLS AND INTRUSION DETECTION SYSTEMS      681\n\u2022 TCP flag bits: SYN, ACK, and so on\n\u2022 ICMP message type\n\u2022 Different rules for datagrams leaving and entering the network\n\u2022 Different rules for the different router interfaces\nA network administrator configures the firewall based on the policy of the organ -\nization. The policy may take user productivity and bandwidth usage into account as \nwell as the security concerns of an organization. Table 8.5 lists a number of possible \npolices an organization may have, and how they would be addressed with a packet \nfilter. For example, if the organization doesn\u2019t want any incoming TCP connections \nexcept those for its public Web server, it can block all incoming TCP SYN segments \nexcept TCP SYN segments with destination port 80 and the destination IP address \ncorresponding to the Web server. If the organization doesn\u2019t want its users to monop -\nolize access bandwidth with Internet radio applications, it can block all not-critical \nUDP traffic (since Internet radio is often sent over UDP). If the organization doesn\u2019t \nwant its internal network to be mapped (tracerouted) by an outsider, it can block all \nICMP TTL expired messages leaving the organization\u2019s network.\nA filtering policy can be based on a combination of addresses and port numbers. \nFor example, a filtering router could forward all Telnet datagrams (those with a port \nnumber of 23) except those going to and coming from a list of specific IP addresses. \nThis policy permits Telnet connections to and from hosts on the allowed list. Unfor -\ntunately, basing the policy on external addresses provides no protection against data -\ngrams that have had their source addresses spoofed.\nFiltering can also be based on whether or not the TCP ACK bit is set. This trick \nis quite useful if an organization wants to let its internal clients connect to external \nservers but wants to prevent external clients from connecting to internal servers. Table 8.5  \u2666  Policies and corresponding filtering rules for an organization\u2019s \nnetwork 130.207/16 with Web server at 130.207.244.203Policy Firewall Setting\nNo outside Web access. Drop all outgoing packets to any IP address, port 80.\nNo incoming TCP connections, except those  \nfor organization\u2019s public Web server only.Drop all incoming TCP SYN packets to any IP except \n130.207.244.203, port 80.\nPrevent Web-radios from eating up the  \navailable bandwidth.Drop all incoming UDP packets\u2014except DNS packets.\nPrevent your network from being used for a  \nsmurf DoS attack.Drop all ICMP ping packets going to a \u201cbroadcast\u201d \naddress (eg 130.207.255.255).\nPrevent your network from being tracerouted. Drop all outgoing ICMP TTL expired traffic.\n682     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nRecall from Section 3.5 that the first segment in every TCP connection has the ACK \nbit set to 0, whereas all the other segments in the connection have the ACK bit set to 1.  \nThus, if an organization wants to prevent external clients from initiating connections \nto internal servers, it simply filters all incoming segments with the ACK bit set to 0. \nThis policy kills all TCP connections originating from the outside, but permits", "doc_id": "cad56b14-8d2d-4395-8cf2-c478de344d7d", "embedding": null, "doc_hash": "d74c44a963d607a874f41db3f7157cc9929cb28bd7c426d969ba9ffedd7357a5", "extra_info": null, "node_info": {"start": 2004882, "end": 2008721}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "88ce8775-ef34-40c5-a9d5-fb9bd7d0a233", "3": "bbf6aea5-b4ed-40dc-a24d-2fcd4946d705"}}, "__type__": "1"}, "bbf6aea5-b4ed-40dc-a24d-2fcd4946d705": {"__data__": {"text": "used for a  \nsmurf DoS attack.Drop all ICMP ping packets going to a \u201cbroadcast\u201d \naddress (eg 130.207.255.255).\nPrevent your network from being tracerouted. Drop all outgoing ICMP TTL expired traffic.\n682     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nRecall from Section 3.5 that the first segment in every TCP connection has the ACK \nbit set to 0, whereas all the other segments in the connection have the ACK bit set to 1.  \nThus, if an organization wants to prevent external clients from initiating connections \nto internal servers, it simply filters all incoming segments with the ACK bit set to 0. \nThis policy kills all TCP connections originating from the outside, but permits con -\nnections originating internally.\nFirewall rules are implemented in routers with access control lists, with each \nrouter interface having its own list. An example of an access control list for an organ -\nization 222.22/16 is shown in Table 8.6. This access control list is for an interface \nthat connects the router to the organization\u2019s external ISPs. Rules are applied to each \ndatagram that passes through the interface from top to bottom. The first two rules \ntogether allow internal users to surf the Web: The first rule allows any TCP packet \nwith destination port 80 to leave the organization\u2019s network; the second rule allows \nany TCP packet with source port 80 and the ACK bit set to enter the organization\u2019s \nnetwork. Note that if an external source attempts to establish a TCP connection with \nan internal host, the connection will be blocked, even if the source or destination \nport is 80. The second two rules together allow DNS packets to enter and leave the \norganization\u2019s network. In summary, this rather restrictive access control list blocks \nall traffic except Web traffic initiated from within the organization and DNS traffic. \n[CERT Filtering 2012] provides a list of recommended port/protocol packet filterings \nto avoid a number of well-known security holes in existing network applications.\nStateful Packet Filters\nIn a traditional packet filter, filtering decisions are made on each packet in isola -\ntion. Stateful filters actually track TCP connections, and use this knowledge to make \n filtering decisions.Table 8.6  \u2666 An access control list for a router interfaceaction source address dest address protocol source port dest port flag bit\nallow 222.22/16 outside of \n222.22/16TCP > 1023 80 any\nallow outside of \n222.22/16222.22/16 TCP 80 > 1023 ACK\nallow 222.22/16 outside of \n222.22/16UDP > 1023 53 \u2014\nallow outside of \n222.22/16222.22/16 UDP 53 > 1023 \u2014\ndeny all all all all all all\n8.9  \u2022  OPERATIONAL SECURITY: FIREWALLS AND INTRUSION DETECTION SYSTEMS      683\nTo understand stateful filters, let\u2019s reexamine the access control list in \nTable 8. 6. Although rather restrictive, the access control list in Table 8.6 neverthe -\nless allows any packet arriving from the outside with ACK = 1 and source port 80 \nto get through the filter. Such packets could be used by attackers in attempts to \ncrash internal systems with malformed packets, carry out denial-of-service attacks, \nor map the internal network. The naive solution is to block TCP ACK packets as \nwell, but such an approach would prevent the organization\u2019s internal users from \nsurfing the Web.\nStateful filters solve this problem by tracking all ongoing TCP connections in \na connection table. This is possible because the firewall can observe the beginning \nof a new connection by observing a three-way handshake (SYN, SYNACK, and \nACK); and it can observe the end of a connection when it sees a FIN packet for \nthe connection. The firewall can also (conservatively) assume that the connection \nis over when it hasn\u2019t seen any activity over the connection for, say, 60 seconds. \nAn example connection table for a firewall is shown", "doc_id": "bbf6aea5-b4ed-40dc-a24d-2fcd4946d705", "embedding": null, "doc_hash": "ed52128835471c8f6eed68f281bdc18b019b52cb4a2316e36f63c3dc7fc8a51f", "extra_info": null, "node_info": {"start": 2008761, "end": 2012579}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "cad56b14-8d2d-4395-8cf2-c478de344d7d", "3": "41d7f66d-2bda-4c18-ae78-c7c7ba4d791d"}}, "__type__": "1"}, "41d7f66d-2bda-4c18-ae78-c7c7ba4d791d": {"__data__": {"text": "with malformed packets, carry out denial-of-service attacks, \nor map the internal network. The naive solution is to block TCP ACK packets as \nwell, but such an approach would prevent the organization\u2019s internal users from \nsurfing the Web.\nStateful filters solve this problem by tracking all ongoing TCP connections in \na connection table. This is possible because the firewall can observe the beginning \nof a new connection by observing a three-way handshake (SYN, SYNACK, and \nACK); and it can observe the end of a connection when it sees a FIN packet for \nthe connection. The firewall can also (conservatively) assume that the connection \nis over when it hasn\u2019t seen any activity over the connection for, say, 60 seconds. \nAn example connection table for a firewall is shown in Table 8.7. This connec -\ntion table indicates that there are currently three ongoing TCP connections, all of \nwhich have been initiated from within the organization. Additionally, the stateful \nfilter includes a new column, \u201ccheck connection,\u201d in its access control list, as \nshown in Table 8.8. Note that Table 8.8 is identical to the access control list in \nTable 8.6, except now it indicates that the connection should be checked for two \nof the rules.\nLet\u2019s walk through some examples to see how the connection table and the \nextended access control list work hand-in-hand. Suppose an attacker attempts \nto send a malformed packet into the organization\u2019s network by sending a data -\ngram with TCP source port 80 and with the ACK flag set. Further suppose that \nthis packet has source port number 12543 and source IP address 150.23.23.155. \nWhen this packet reaches the firewall, the firewall checks the access control list in \nTable 8. 7, which indicates that the connection table must also be checked before \npermitting this packet to enter the organization\u2019s network. The firewall duly \nchecks the connection table, sees that this packet is not part of an ongoing TCP \nconnection, and rejects the packet. As a second example, suppose that an internal \nuser wants to surf an external Web site. Because this user first sends a TCP SYN \nsegment, the user\u2019s TCP connection gets recorded in the connection table. When Table 8.7  \u2666 Connection table for stateful filtersource address dest address source port dest port\n222.22.1.7 37.96.87.123 12699 80\n222.22.93.2 199.1.205.23 37654 80\n222.22.65.143 203.77.240.43 48712 80\n684     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nthe Web server sends back packets (with the ACK bit necessarily set), the fire -\nwall checks the table and sees that a corresponding connection is in progress. The \nfirewall will thus let these packets pass, thereby not interfering with the internal \nuser\u2019s Web surfing activity.\nApplication Gateway\nIn the examples above, we have seen that packet-level filtering allows an organiza -\ntion to perform coarse-grain filtering on the basis of the contents of IP and TCP/UDP \nheaders, including IP addresses, port numbers, and acknowledgment bits. But what if \nan organization wants to provide a Telnet service to a restricted set of internal users \n(as opposed to IP addresses)? And what if the organization wants such privileged \nusers to authenticate themselves first before being allowed to create Telnet sessions \nto the outside world? Such tasks are beyond the capabilities of traditional and stateful \nfilters. Indeed, information about the identity of the internal users is application-layer \ndata and is not included in the IP/TCP/UDP headers.\nTo have finer-level security, firewalls must combine packet filters with appli -\ncation gateways. Application gateways look beyond the IP/TCP/UDP headers and \nmake policy decisions based on application data. An application gateway  is an \napplication-specific server through which all application data (inbound and out -\nbound) must pass. Multiple application gateways can run on the same host, but each \ngateway is a", "doc_id": "41d7f66d-2bda-4c18-ae78-c7c7ba4d791d", "embedding": null, "doc_hash": "a3bbf254c09cf4ddf562acedb56b6a7cd373756a3e0878b7d2707258f1cc8f61", "extra_info": null, "node_info": {"start": 2012499, "end": 2016423}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "bbf6aea5-b4ed-40dc-a24d-2fcd4946d705", "3": "24198e3d-49b8-4422-9bf1-00d8bed144f1"}}, "__type__": "1"}, "24198e3d-49b8-4422-9bf1-00d8bed144f1": {"__data__": {"text": "set of internal users \n(as opposed to IP addresses)? And what if the organization wants such privileged \nusers to authenticate themselves first before being allowed to create Telnet sessions \nto the outside world? Such tasks are beyond the capabilities of traditional and stateful \nfilters. Indeed, information about the identity of the internal users is application-layer \ndata and is not included in the IP/TCP/UDP headers.\nTo have finer-level security, firewalls must combine packet filters with appli -\ncation gateways. Application gateways look beyond the IP/TCP/UDP headers and \nmake policy decisions based on application data. An application gateway  is an \napplication-specific server through which all application data (inbound and out -\nbound) must pass. Multiple application gateways can run on the same host, but each \ngateway is a separate server with its own processes.\nTo get some insight into application gateways, let\u2019s design a firewall that allows \nonly a restricted set of internal users to Telnet outside and prevents all external cli -\nents from Telneting inside. Such a policy can be accomplished by implementing Table 8.8  \u2666 Access control list for stateful filteraction source  \naddressdest  \naddressprotocol source port dest port flag bit check \nconxion\nallow 222.22/16 outside of \n222.22/16TCP > 1023 80 any\nallow outside of \n222.22/16222.22/16 TCP 80 > 1023 ACK X\nallow 222.22/16 outside of \n222.22/16UDP > 1023 53 \u2014\nallow outside of \n222.22/16222.22/16 UDP 53 > 1023 \u2014 X\ndeny all all all all all all\n8.9  \u2022  OPERATIONAL SECURITY: FIREWALLS AND INTRUSION DETECTION SYSTEMS      685\na combination of a packet filter (in a router) and a Telnet application gateway, as \nshown in Figure 8.34. The router\u2019s filter is configured to block all Telnet connec -\ntions except those that originate from the IP address of the application gateway. \nSuch a filter configuration forces all outbound Telnet connections to pass through \nthe application gateway. Consider now an internal user who wants to Telnet to \nthe outside world. The user must first set up a Telnet session with the application \ngateway. An application running in the gateway, which listens for incoming Telnet \nsessions, prompts the user for a user ID and password. When the user supplies this \ninformation, the application gateway checks to see if the user has permission to Tel -\nnet to the outside world. If not, the Telnet connection from the internal user to the \ngateway is terminated by the gateway. If the user has permission, then the gateway \n(1) prompts the user for the host name of the external host to which the user wants \nto connect, (2) sets up a Telnet session between the gateway and the external host, \nand (3) relays to the external host all data arriving from the user, and relays to the \nuser all data arriving from the external host. Thus, the Telnet application gateway \nnot only performs user authorization but also acts as a Telnet server and a Telnet \nclient, relaying information between the user and the remote Telnet server. Note \nthat the filter will permit step 2 because the gateway initiates the Telnet connection \nto the outside world.Figure 8.34  \u2666 Firewall consisting of an application gateway and a filterApplication\ngatewayHost-to-gateway\nTelnet sessionGateway-to-remote\nhost Telnet session\nRouter \nand \ufb01lter\n686     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nANONYMITY AND PRIVACY\nSuppose you want to visit a controversial Web site (for example, a political activist \nsite) and you (1) don\u2019t want to reveal your IP address to the Web site, (2) don\u2019t want \nyour local ISP (which may be your home or office ISP) to know that you are visiting \nthe site, and (3) don\u2019t want your local ISP to see the data you are exchanging with \nthe site. If you use the traditional approach of connecting directly to the Web", "doc_id": "24198e3d-49b8-4422-9bf1-00d8bed144f1", "embedding": null, "doc_hash": "161462bbfe18ea20c87cb5dcf1487af31d10f13376f2cd9ed748fdbaa655471c", "extra_info": null, "node_info": {"start": 2016357, "end": 2020190}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "41d7f66d-2bda-4c18-ae78-c7c7ba4d791d", "3": "4c7e6271-02d0-4dc1-92fc-4a8b6d54ee14"}}, "__type__": "1"}, "4c7e6271-02d0-4dc1-92fc-4a8b6d54ee14": {"__data__": {"text": "of an application gateway and a filterApplication\ngatewayHost-to-gateway\nTelnet sessionGateway-to-remote\nhost Telnet session\nRouter \nand \ufb01lter\n686     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nANONYMITY AND PRIVACY\nSuppose you want to visit a controversial Web site (for example, a political activist \nsite) and you (1) don\u2019t want to reveal your IP address to the Web site, (2) don\u2019t want \nyour local ISP (which may be your home or office ISP) to know that you are visiting \nthe site, and (3) don\u2019t want your local ISP to see the data you are exchanging with \nthe site. If you use the traditional approach of connecting directly to the Web site \nwithout any encryption, you fail on all three counts. Even if you use SSL, you fail \non the first two counts: Your source IP address is presented to the Web site in every \ndatagram you send; and the destination address of every packet you send can easily \nbe sniffed by your local ISP.\nTo obtain privacy and anonymity, you can instead use a combination of a trusted \nproxy server and SSL, as shown in Figure 8.35. With this approach, you first make \nan SSL connection to the trusted proxy. You then send, into this SSL connection, \nan HTTP request for a page at the desired site. When the proxy receives the SSL-\nencrypted HTTP request, it decrypts the request and forwards the cleartext HTTP \nrequest to the Web site. The Web site then responds to the proxy, which in turn for -\nwards the response to you over SSL. Because the Web site only sees the IP address \nof the proxy, and not of your client\u2019s address, you are indeed obtaining anony -\nmous access to the Web site. And because all traffic between you and the proxy is \nencrypted, your local ISP cannot invade your privacy by logging the site you visited \nor recording the data you are exchanging. Many companies today (such as proxify  \n.com) make available such proxy services.\nOf course, in this solution, your proxy knows everything: It knows your IP address \nand the IP address of the site you\u2019re surfing; and it can see all the traffic in  cleartext \nexchanged between you and the Web site. Such a solution, therefore, is only as \ngood as the trustworthiness of the proxy. A more robust approach, taken by the \nTOR anonymizing and privacy service, is to route your traffic through a series of \nnon- colluding proxy servers [TOR 2016]. In particular, TOR allows independent \n individuals to contribute proxies to its proxy pool. When a user connects to a server \nusing TOR, TOR randomly chooses (from its proxy pool) a chain of three proxies and \nroutes all traffic between client and server over the chain. In this manner, assuming \nthe proxies do not collude, no one knows that communication took place between \nyour IP address and the target Web site. Furthermore, although cleartext is sent \nbetween the last proxy and the server, the last proxy doesn\u2019t know what IP address  \nis sending and receiving the cleartext.CASE HISTORY\n\n8.9  \u2022  OPERATIONAL SECURITY: FIREWALLS AND INTRUSION DETECTION SYSTEMS      687\nInternal networks often have multiple application gateways, for example, gate -\nways for Telnet, HTTP, FTP, and e-mail. In fact, an organization\u2019s mail server  \n(see Section 2.3) and Web cache are application gateways.\nApplication gateways do not come without their disadvantages. First, a different \napplication gateway is needed for each application. Second, there is a performance \npenalty to be paid, since all data will be relayed via the gateway. This becomes a \nconcern particularly when multiple users or applications are using the same gateway \nmachine. Finally, the client software must know how to contact the gateway when \nthe user makes a request, and must know how to tell the application gateway what \nexternal server to connect to.\n8.9.2 Intrusion Detection Systems\nWe\u2019ve just seen that a", "doc_id": "4c7e6271-02d0-4dc1-92fc-4a8b6d54ee14", "embedding": null, "doc_hash": "8fd849eb8697505eb99449e5cf3ed1d67a8628bd18d10bd45aa5dd90da4a1a0c", "extra_info": null, "node_info": {"start": 2020371, "end": 2024203}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "24198e3d-49b8-4422-9bf1-00d8bed144f1", "3": "8306308a-2e69-4087-980a-0e3680811f4b"}}, "__type__": "1"}, "8306308a-2e69-4087-980a-0e3680811f4b": {"__data__": {"text": "  687\nInternal networks often have multiple application gateways, for example, gate -\nways for Telnet, HTTP, FTP, and e-mail. In fact, an organization\u2019s mail server  \n(see Section 2.3) and Web cache are application gateways.\nApplication gateways do not come without their disadvantages. First, a different \napplication gateway is needed for each application. Second, there is a performance \npenalty to be paid, since all data will be relayed via the gateway. This becomes a \nconcern particularly when multiple users or applications are using the same gateway \nmachine. Finally, the client software must know how to contact the gateway when \nthe user makes a request, and must know how to tell the application gateway what \nexternal server to connect to.\n8.9.2 Intrusion Detection Systems\nWe\u2019ve just seen that a packet filter (traditional and stateful) inspects IP, TCP, UDP, \nand ICMP header fields when deciding which packets to let pass through the firewall. \nHowever, to detect many attack types, we need to perform deep packet inspection , \nthat is, look beyond the header fields and into the actual application data that the \npackets carry. As we saw in Section 8.9.1, application gateways often do deep packet \ninspection. But an application gateway only does this for a specific application.\nClearly, there is a niche for yet another device\u2014a device that not only exam -\nines the headers of all packets passing through it (like a packet filter), but also per -\nforms deep packet inspection (unlike a packet filter). When such a device observes \na suspicious packet, or a suspicious series of packets, it could prevent those packets \nfrom entering the organizational network. Or, because the activity is only deemed \nas suspicious, the device could let the packets pass, but send alerts to a network \nadministrator, who can then take a closer look at the traffic and take appropriate \nactions. A device that generates alerts when it observes potentially malicious traf -\nfic is called an intrusion detection system (IDS) . A device that filters out suspi -\ncious traffic is called an intrusion prevention system (IPS) . In this section we study Figure 8.35  \u2666 Providing anonymity and privacy with a proxyAliceAnonymizing\nProxy\nSSLCleartext\n688     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nboth systems\u2014IDS and IPS\u2014together, since the most interesting technical aspect \nof these systems is how they detect suspicious traffic (and not whether they send \nalerts or drop packets). We will henceforth collectively refer to IDS systems and IPS \nsystems as IDS systems.\nAn IDS can be used to detect a wide range of attacks, including network map -\nping (emanating, for example, from nmap), port scans, TCP stack scans, DoS band -\nwidth-flooding attacks, worms and viruses, OS vulnerability attacks, and application \nvulnerability attacks. (See Section 1.6 for a survey of network attacks.) Today, \nthousands of organizations employ IDS systems. Many of these deployed systems \nare proprietary, marketed by Cisco, Check Point, and other security equipment ven -\ndors. But many of the deployed IDS systems are public-domain systems, such as the \nimmensely popular Snort IDS system (which we\u2019ll discuss shortly).\nAn organization may deploy one or more IDS sensors in its organizational net -\nwork. Figure 8.36 shows an organization that has three IDS sensors. When multi -\nple sensors are deployed, they typically work in concert, sending information about \nFigure 8.36  \u2666  An organization deploying a filter, an application gateway, \nand IDS sensorsInternet\nWeb\nserverFTP\nserverDNS\nserverInternal\nnetwork\nApplication\ngateway\nDemilitarized zoneFilter\nKey:\n= IDS sensors\n8.9  \u2022  OPERATIONAL SECURITY: FIREWALLS AND INTRUSION DETECTION SYSTEMS      689\nsuspicious traffic activity to a central IDS processor, which collects and integrates \nthe information and sends alarms to network administrators", "doc_id": "8306308a-2e69-4087-980a-0e3680811f4b", "embedding": null, "doc_hash": "56ba0274661f68c56164ef093f06bfe5e11db478c9800c7310c57c08ba9f2350", "extra_info": null, "node_info": {"start": 2024058, "end": 2027956}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "4c7e6271-02d0-4dc1-92fc-4a8b6d54ee14", "3": "e7e4d45a-c6bc-44c6-80f3-5b8b13ea0926"}}, "__type__": "1"}, "e7e4d45a-c6bc-44c6-80f3-5b8b13ea0926": {"__data__": {"text": "discuss shortly).\nAn organization may deploy one or more IDS sensors in its organizational net -\nwork. Figure 8.36 shows an organization that has three IDS sensors. When multi -\nple sensors are deployed, they typically work in concert, sending information about \nFigure 8.36  \u2666  An organization deploying a filter, an application gateway, \nand IDS sensorsInternet\nWeb\nserverFTP\nserverDNS\nserverInternal\nnetwork\nApplication\ngateway\nDemilitarized zoneFilter\nKey:\n= IDS sensors\n8.9  \u2022  OPERATIONAL SECURITY: FIREWALLS AND INTRUSION DETECTION SYSTEMS      689\nsuspicious traffic activity to a central IDS processor, which collects and integrates \nthe information and sends alarms to network administrators when deemed appropri -\nate. In Figure 8.36, the organization has partitioned its network into two regions: a \nhigh-security region, protected by a packet filter and an application gateway and \nmonitored by IDS sensors; and a lower-security region\u2014referred to as the demilita-\nrized zone (DMZ) \u2014which is protected only by the packet filter, but also monitored \nby IDS sensors. Note that the DMZ includes the organization\u2019s servers that need to \ncommunicate with the outside world, such as its public Web server and its authorita -\ntive DNS server.\nYou may be wondering at this stage, why multiple IDS sensors? Why not just \nplace one IDS sensor just behind the packet filter (or even integrated with the packet \nfilter) in Figure 8.36? We will soon see that an IDS not only needs to do deep packet \ninspection, but must also compare each passing packet with tens of thousands of \n\u201csignatures\u201d; this can be a significant amount of processing, particularly if the organ -\nization receives gigabits/sec of traffic from the Internet. By placing the IDS sensors \nfurther downstream, each sensor sees only a fraction of the organization\u2019s traffic, \nand can more easily keep up. Nevertheless, high-performance IDS and IPS systems \nare available today, and many organizations can actually get by with just one sensor \nlocated near its access router.\nIDS systems are broadly classified as either signature-based systems  or  anomaly- \nbased systems . A signature-based IDS maintains an extensive database of attack \nsignatures. Each signature is a set of rules pertaining to an intrusion activity. A sig -\nnature may simply be a list of characteristics about a single packet (e.g., source and \ndestination port numbers, protocol type, and a specific string of bits in the packet \npayload), or may relate to a series of packets. The signatures are normally created by \nskilled network security engineers who research known attacks. An organization\u2019s \nnetwork administrator can customize the signatures or add its own to the database.\nOperationally, a signature-based IDS sniffs every packet passing by it, compar -\ning each sniffed packet with the signatures in its database. If a packet (or series of \npackets) matches a signature in the database, the IDS generates an alert. The alert \ncould be sent to the network administrator in an e-mail message, could be sent to the \nnetwork management system, or could simply be logged for future inspection.\nSignature-based IDS systems, although widely deployed, have a number of limi -\ntations. Most importantly, they require previous knowledge of the attack to generate \nan accurate signature. In other words, a signature-based IDS is completely blind to \nnew attacks that have yet to be recorded. Another disadvantage is that even if a sig -\nnature is matched, it may not be the result of an attack, so that a false alarm is gener -\nated. Finally, because every packet must be compared with an extensive collection \nof signatures, the IDS can become overwhelmed with processing and actually fail to \ndetect many malicious packets.\nAn anomaly-based IDS creates a traffic profile as it observes traffic in normal \noperation. It then looks for packet streams that are statistically unusual, for exam", "doc_id": "e7e4d45a-c6bc-44c6-80f3-5b8b13ea0926", "embedding": null, "doc_hash": "f4f8e53d95cd12cf69232622b84dbc6f2cf2488bc5dac91e2917173e0779e2f5", "extra_info": null, "node_info": {"start": 2028034, "end": 2031967}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "8306308a-2e69-4087-980a-0e3680811f4b", "3": "96741912-1e72-48b1-abaf-3c6da4497147"}}, "__type__": "1"}, "96741912-1e72-48b1-abaf-3c6da4497147": {"__data__": {"text": "IDS systems, although widely deployed, have a number of limi -\ntations. Most importantly, they require previous knowledge of the attack to generate \nan accurate signature. In other words, a signature-based IDS is completely blind to \nnew attacks that have yet to be recorded. Another disadvantage is that even if a sig -\nnature is matched, it may not be the result of an attack, so that a false alarm is gener -\nated. Finally, because every packet must be compared with an extensive collection \nof signatures, the IDS can become overwhelmed with processing and actually fail to \ndetect many malicious packets.\nAn anomaly-based IDS creates a traffic profile as it observes traffic in normal \noperation. It then looks for packet streams that are statistically unusual, for exam -\nple, an inordinate percentage of ICMP packets or a sudden exponential growth in \n690     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nport scans and ping sweeps. The great thing about anomaly-based IDS systems is \nthat they don\u2019t rely on previous knowledge about existing attacks\u2014that is, they can \npotentially detect new, undocumented attacks. On the other hand, it is an extremely \nchallenging problem to distinguish between normal traffic and statistically unusual \ntraffic. To date, most IDS deployments are primarily signature-based, although some \ninclude some anomaly-based features.\nSnort\nSnort is a public-domain, open source IDS with hundreds of thousands of existing \ndeployments [Snort 2012; Koziol 2003]. It can run on Linux, UNIX, and Windows \nplatforms. It uses the generic sniffing interface libpcap, which is also used by Wire -\nshark and many other packet sniffers. It can easily handle 100 Mbps of traffic; for \ninstallations with gibabit/sec traffic rates, multiple Snort sensors may be needed.\nTo gain some insight into Snort, let\u2019s take a look at an example of a Snort \nsignature:\nalert icmp $EXTERNAL_NET any -> $HOME_NET any  \n(msg:\u201dICMP PING NMAP\u201d; dsize: 0; itype: 8;)\nThis signature is matched by any ICMP packet that enters the organization\u2019s network \n($HOME_NET ) from the outside ( $EXTERNAL_NET ), is of type 8 (ICMP ping), and \nhas an empty payload (dsize = 0). Since nmap (see Section 1.6 ) generates ping pack -\nets with these specific characteristics, this signature is designed to detect nmap ping \nsweeps. When a packet matches this signature, Snort generates an alert that includes \nthe message \u201c ICMP PING NMAP \u201d.\nPerhaps what is most impressive about Snort is the vast community of users and \nsecurity experts that maintain its signature database. Typically within a few hours \nof a new attack, the Snort community writes and releases an attack signature, which \nis then downloaded by the hundreds of thousands of Snort deployments distributed \naround the world. Moreover, using the Snort signature syntax, network administra -\ntors can tailor the signatures to their own organization\u2019s needs by either modifying \nexisting signatures or creating entirely new ones.\n8.10  Summary\nIn this chapter, we\u2019ve examined the various mechanisms that our secret lovers, Bob \nand Alice, can use to communicate securely. We\u2019ve seen that Bob and Alice are \ninterested in confidentiality (so they alone are able to understand the contents of a \ntransmitted message), end-point authentication (so they are sure that they are talking \n8.10  \u2022  SUMMARY      691\nwith each other), and message integrity (so they are sure that their messages are not \naltered in transit). Of course, the need for secure communication is not confined to \nsecret lovers. Indeed, we saw in Sections 8.5 through 8.8 that security can be used in \nvarious layers in a network architecture to protect against bad guys who have a large \narsenal of possible attacks at hand.\nThe first part of this chapter presented various", "doc_id": "96741912-1e72-48b1-abaf-3c6da4497147", "embedding": null, "doc_hash": "4d58c7de75ba1faf5bfac60594f9ee6ac7433d126776a0c5156f7269f4aa60f2", "extra_info": null, "node_info": {"start": 2031925, "end": 2035721}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "e7e4d45a-c6bc-44c6-80f3-5b8b13ea0926", "3": "662010ae-67f5-4901-8835-b55571bee389"}}, "__type__": "1"}, "662010ae-67f5-4901-8835-b55571bee389": {"__data__": {"text": "the various mechanisms that our secret lovers, Bob \nand Alice, can use to communicate securely. We\u2019ve seen that Bob and Alice are \ninterested in confidentiality (so they alone are able to understand the contents of a \ntransmitted message), end-point authentication (so they are sure that they are talking \n8.10  \u2022  SUMMARY      691\nwith each other), and message integrity (so they are sure that their messages are not \naltered in transit). Of course, the need for secure communication is not confined to \nsecret lovers. Indeed, we saw in Sections 8.5 through 8.8 that security can be used in \nvarious layers in a network architecture to protect against bad guys who have a large \narsenal of possible attacks at hand.\nThe first part of this chapter presented various principles underlying secure \ncommunication. In Section 8.2, we covered cryptographic techniques for encrypting \nand decrypting data, including symmetric key cryptography and public key cryp -\ntography. DES and RSA were examined as specific case studies of these two major \nclasses of cryptographic techniques in use in today\u2019s networks.\nIn Section 8.3, we examined two approaches for providing message integrity: \nmessage authentication codes (MACs) and digital signatures. The two approaches \nhave a number of parallels. Both use cryptographic hash functions and both tech -\nniques enable us to verify the source of the message as well as the integrity of the \nmessage itself. One important difference is that MACs do not rely on encryption \nwhereas digital signatures require a public key infrastructure. Both techniques are \nextensively used in practice, as we saw in Sections 8.5 through 8.8. Furthermore, \ndigital signatures are used to create digital certificates, which are important for veri -\nfying the validity of public keys. In Section 8.4, we examined endpoint authentica -\ntion and introduced nonces to defend against the replay attack.\nIn Sections 8.5 through 8.8 we examined several security networking protocols \nthat enjoy extensive use in practice. We saw that symmetric key cryptography is at \nthe core of PGP, SSL, IPsec, and wireless security. We saw that public key cryptog -\nraphy is crucial for both PGP and SSL. We saw that PGP uses digital signatures for \nmessage integrity, whereas SSL and IPsec use MACs. Having now an understand -\ning of the basic principles of cryptography, and having studied how these princi -\nples are actually used, you are now in position to design your own secure network \nprotocols!\nArmed with the techniques covered in Sections 8.2 through 8.8, Bob and Alice \ncan communicate securely. (One can only hope that they are networking students \nwho have learned this material and can thus avoid having their tryst uncovered by \nTrudy!) But confidentiality is only a small part of the network security picture. As \nwe learned in Section 8.9, increasingly, the focus in network security has been on \nsecuring the network infrastructure against a potential onslaught by the bad guys. \nIn the latter part of this chapter, we thus covered firewalls and IDS systems which \ninspect packets entering and leaving an organization\u2019s network.\nThis chapter has covered a lot of ground, while focusing on the most important \ntopics in modern network security. Readers who desire to dig deeper are encour -\naged to investigate the references cited in this chapter. In particular, we recommend \n[Skoudis 2006] for attacks and operational security, [Kaufman 1995] for cryptog -\nraphy and how it applies to network security, [Rescorla 2001] for an in-depth but \nreadable treatment of SSL, and [Edney 2003] for a thorough discussion of 802.11 \nsecurity, including an insightful investigation into WEP and its flaws.\n692     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nHomework Problems and Questions\nChapter 8 Review Problems\nSECTION 8.1\n R1. Operational devices such as firewalls and intrusion detection systems are \nused to counter attacks", "doc_id": "662010ae-67f5-4901-8835-b55571bee389", "embedding": null, "doc_hash": "e04c7229cd168c941dc5d5a65e10bd7e06fcbf8bca47025763a98f29e2f48041", "extra_info": null, "node_info": {"start": 2035739, "end": 2039682}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "96741912-1e72-48b1-abaf-3c6da4497147", "3": "a2c5b6b1-6b06-445b-87a7-b96b4bf5078a"}}, "__type__": "1"}, "a2c5b6b1-6b06-445b-87a7-b96b4bf5078a": {"__data__": {"text": "in modern network security. Readers who desire to dig deeper are encour -\naged to investigate the references cited in this chapter. In particular, we recommend \n[Skoudis 2006] for attacks and operational security, [Kaufman 1995] for cryptog -\nraphy and how it applies to network security, [Rescorla 2001] for an in-depth but \nreadable treatment of SSL, and [Edney 2003] for a thorough discussion of 802.11 \nsecurity, including an insightful investigation into WEP and its flaws.\n692     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nHomework Problems and Questions\nChapter 8 Review Problems\nSECTION 8.1\n R1. Operational devices such as firewalls and intrusion detection systems are \nused to counter attacks against an organization\u2019s network. What is the basic \ndifference between a firewall and an intrusion detection system?\n R2. Internet entities (routers, switches, DNS servers, Web servers, user end \nsystems, and so on) often need to communicate securely. Give three specific \nexample pairs of Internet entities that may want secure communication.\nSECTION 8.2\n R3. The encryption technique itself is known\u2014published, standardized, and \navailable to everyone, even a potential intruder. Then where does the security \nof an encryption technique come from?\n R4. What is the difference between known plaintext attack and chosen plaintext \nattack?\n R5. Consider a 16-block cipher. How many possible input blocks does this cipher \nhave? How many possible mappings are there? If we view each mapping as a \nkey, then how many possible keys does this cipher have?\n R6. Suppose N people want to communicate with each of N-1 other peo-\nple using symmetric key encryption. All communication between any two \npeople, i and j, is visible to all other people in this group of N, and no other \nperson in this group should be able to decode their communication. How \nmany keys are required in the system as a whole? Now suppose that public \nkey encryption is used. How many keys are required in this case?\n R7. Suppose n = 1,000, a = 1,017, and b = 1,006. Use an identity of modular \narithmetic to calculate in your head ( a # b) mod n.\n R8. Suppose you want to encrypt the message 10010111 by encrypting the deci-\nmal number that corresponds to the message. What is the decimal number?\nSECTIONS 8.3\u20138.4 \n R9. In what way does a hash provide a better message integrity check than a \nchecksum (such as the Internet checksum)?\n R10. Can you \u201cdecrypt\u201d a hash of a message to get the original message? Explain \nyour answer.\n R11. Consider a variation of the MAC algorithm (Figure 8.9) where the sender \nsends ( m, H(m) + s), where H(m) + s is the concatenation of H(m) and s. Is \nthis variation flawed? Why or why not?\nHOMEWORK PROBLEMS AND QUESTIONS      693\n R12. What does it mean for a signed document to be verifiable and nonforgeable?\n R13. In the link-state routing algorithm, we would somehow need to distribute the \nsecret authentication key to each of the routers in the autonomous system. How \ndo we distribute the shared authentication key to the communicating entities?\n R14. Name two popular secure networking protocols in which public key certifica-\ntion is used.\n R15. Suppose Alice has a message that she is ready to send to anyone who asks. \nThousands of people want to obtain Alice\u2019s message, but each wants to be \nsure of the integrity of the message. In this context, do you think a MAC-\nbased or a digital-signature-based integrity scheme is more suitable? Why?\n R16. What is the purpose of a nonce in an end-point authentication protocol?\n R17. What does it mean to say that a nonce is a once-in-a-lifetime value? In whose \nlifetime?\n", "doc_id": "a2c5b6b1-6b06-445b-87a7-b96b4bf5078a", "embedding": null, "doc_hash": "c3c509fadc304ec7edfa80231f7beaefb1f51773588997b0e395d85499494898", "extra_info": null, "node_info": {"start": 2039717, "end": 2043359}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "662010ae-67f5-4901-8835-b55571bee389", "3": "4e7f917a-c35c-469c-b61d-9da8a05c792f"}}, "__type__": "1"}, "4e7f917a-c35c-469c-b61d-9da8a05c792f": {"__data__": {"text": "the \nsecret authentication key to each of the routers in the autonomous system. How \ndo we distribute the shared authentication key to the communicating entities?\n R14. Name two popular secure networking protocols in which public key certifica-\ntion is used.\n R15. Suppose Alice has a message that she is ready to send to anyone who asks. \nThousands of people want to obtain Alice\u2019s message, but each wants to be \nsure of the integrity of the message. In this context, do you think a MAC-\nbased or a digital-signature-based integrity scheme is more suitable? Why?\n R16. What is the purpose of a nonce in an end-point authentication protocol?\n R17. What does it mean to say that a nonce is a once-in-a-lifetime value? In whose \nlifetime?\n R18. Is the message integrity scheme based on HMAC susceptible to playback \nattacks? If so, how can a nonce be incorporated into the scheme to remove \nthis susceptibility?\nSECTIONS 8.5\u20138.8\n R19. What is the de facto e-mail encryption scheme? What does it use for authenti-\ncation and message integrity?\n R20. In the SSL record, there is a field for SSL sequence numbers. True or false?\n R21. What is the purpose of the random nonces in the SSL handshake?\n R22. Suppose an SSL session employs a block cipher with CBC. True or false: The \nserver sends to the client the IV in the clear.\n R23. Suppose Bob initiates a TCP connection to Trudy who is pretending to be Alice. \nDuring the handshake, Trudy sends Bob Alice\u2019s certificate. In what step of the SSL \nhandshake algorithm will Bob discover that he is not communicating with Alice?\n R24. Consider sending a stream of packets from Host A to Host B using IPsec. \nTypically, a new SA will be established for each packet sent in the stream. \nTrue or false?\n R25. Suppose that TCP is being run over IPsec between headquarters and the \nbranch office in Figure 8.28. If TCP retransmits the same packet, then the \ntwo corresponding packets sent by R1 packets will have the same sequence \nnumber in the ESP header. True or false?\n R26. Is there a fixed encryption algorithm in SSL?\n R27. Consider WEP for 802.11. Suppose that the data is 10001101 and the  \nkeystream is 01101010. What is the resulting ciphertext?\n R28. Is the Initialization Vector (IV) appended to the secret 40-bit symmetric key \nin WEP protocol sent encrypted?\n694     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\nSECTION 8.9\n R29. Stateful packet filters maintain two data structures. Name them and briefly \ndescribe what they do.\n R30. Consider a traditional (stateless) packet filter. This packet filter may filter \npackets based on TCP flag bits as well as other header fields. True or false?\n R31. In a traditional packet filter, each interface can have its own access control \nlist. True or false?\n R32. Why must an application gateway work in conjunction with a router filter to \nbe effective?\n R33. Signature-based IDSs and IPSs inspect into the payloads of TCP and UDP \nsegments. True or false?\nProblems\n P1. Using the monoalphabetic cipher in Figure 8.3, encode the message \u201cThis is \na secret message.\u201d Decode the message \u201cfsgg ash.\u201d\n P2. Show that Trudy\u2019s known-plaintext attack, in which she knows the (cipher-\ntext, plaintext) translation pairs for seven letters, reduces the number of \npossible substitutions to be checked in the example in Section 8.2.1 by \napproximately 109.\n P3. Consider the polyalphabetic system shown in Figure 8.4. Will a chosen-\nplaintext attack that is able to get the plaintext encoding of the message \u201cThe \nquick brown fox jumps over the lazy dog.\u201d be sufficient to decode all mes-\nsages? Why or why", "doc_id": "4e7f917a-c35c-469c-b61d-9da8a05c792f", "embedding": null, "doc_hash": "e93933f743fbdbcecbd6a274f79db146fef7335cecb4eab96719681e6024bfc1", "extra_info": null, "node_info": {"start": 2043345, "end": 2046939}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "a2c5b6b1-6b06-445b-87a7-b96b4bf5078a", "3": "4b473ee4-621a-4493-9594-d1d23d5069f8"}}, "__type__": "1"}, "4b473ee4-621a-4493-9594-d1d23d5069f8": {"__data__": {"text": "UDP \nsegments. True or false?\nProblems\n P1. Using the monoalphabetic cipher in Figure 8.3, encode the message \u201cThis is \na secret message.\u201d Decode the message \u201cfsgg ash.\u201d\n P2. Show that Trudy\u2019s known-plaintext attack, in which she knows the (cipher-\ntext, plaintext) translation pairs for seven letters, reduces the number of \npossible substitutions to be checked in the example in Section 8.2.1 by \napproximately 109.\n P3. Consider the polyalphabetic system shown in Figure 8.4. Will a chosen-\nplaintext attack that is able to get the plaintext encoding of the message \u201cThe \nquick brown fox jumps over the lazy dog.\u201d be sufficient to decode all mes-\nsages? Why or why not?\n P4. Consider the block cipher in Figure 8.5. Suppose that each block cipher \nTi simply reverses the order of the eight input bits (so that, for example, \n11110000 becomes 00001111). Further suppose that the 64-bit scrambler \ndoes not modify any bits (so that the output value of the mth bit is equal to \nthe input value of the mth bit). (a) With n=3 and the original 64-bit input \nequal to 10100000 repeated eight times, what is the value of the output?  \n(b) Repeat part (a) but now change the last bit of the original 64-bit input \nfrom a 0 to a 1. (c) Repeat parts (a) and (b) but now suppose that the 64-bit \nscrambler inverses the order of the 64 bits.\n P5. Consider the block cipher in Figure 8.5. Suppose, for a given \u201ckey,\u201d Alice and \nBob would need to keep 16 tables, each 16 bits by 8 bits. For Alice (or Bob) to \nstore all 16 tables, how many bits of storage are necessary? How does this number \ncompare with the number of bits required for a full-table 128-bit block cipher?\n P6. Consider the 3-bit block cipher in Table 8.1. Suppose the plaintext is \n100100100. (a) Initially assume that CBC is not used. What is the resulting \nciphertext? (b) Suppose Trudy sniffs the ciphertext. Assuming she knows that \nPROBLEMS      695\na 3-bit block cipher without CBC is being employed (but doesn\u2019t know the \nspecific cipher), what can she surmise? (c) Now suppose that CBC is used \nwith IV = 111. What is the resulting ciphertext?\n P7. a.  Using RSA, cho ose p=5 and q=7, and encode the numbers 12, 19, and \n27 separately. Apply the decryption algorithm to the encrypted version to \nrecover the original plaintext message.\nb. Choose p and q of your own and encrypt 1834 as one message m.\n P8. Consider RSA with p=7 and q=13.\na. What are n and z?\nb. Let e be 17. Why is this an acceptable choice for e?\nc. Find d such that de = 1 (mod z).\nd. Encrypt the message m = 9 using the key ( n, e). Let c denote the correspond -\ning ciphertext. Show all work.\n P9. In this problem, we explore the Diffie-Hellman (DH) public-key encryption \nalgorithm, which allows two entities to agree on a shared key. The DH algo-\nrithm makes use of a large prime number p and another large number g less \nthan p. Both p and g are made public (so that an attacker would know them). \nIn DH, Alice and Bob each independently choose secret keys, SA and SB, \nrespectively. Alice then computes her public key, TA, by raising g to SA and \nthen taking mod p. Bob similarly computes his own public key TB by raising \ng to SB and then taking mod p. Alice and Bob then exchange their public keys \nover the Internet. Alice then calculates the shared secret key S by raising TB \nto SA and then taking mod p. Similarly, Bob calculates the shared key S\u2032 by \nraising TA to SB and then taking mod p.\na. Prove that, in general, Alice and Bob obtain the same", "doc_id": "4b473ee4-621a-4493-9594-d1d23d5069f8", "embedding": null, "doc_hash": "1410f0db96b0846067a80cb26028fce60860f880b8df133a4ff1cc1d3a0fd867", "extra_info": null, "node_info": {"start": 2046992, "end": 2050485}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "4e7f917a-c35c-469c-b61d-9da8a05c792f", "3": "566b6ddc-b99e-47eb-b2a8-e3606c8f3082"}}, "__type__": "1"}, "566b6ddc-b99e-47eb-b2a8-e3606c8f3082": {"__data__": {"text": "which allows two entities to agree on a shared key. The DH algo-\nrithm makes use of a large prime number p and another large number g less \nthan p. Both p and g are made public (so that an attacker would know them). \nIn DH, Alice and Bob each independently choose secret keys, SA and SB, \nrespectively. Alice then computes her public key, TA, by raising g to SA and \nthen taking mod p. Bob similarly computes his own public key TB by raising \ng to SB and then taking mod p. Alice and Bob then exchange their public keys \nover the Internet. Alice then calculates the shared secret key S by raising TB \nto SA and then taking mod p. Similarly, Bob calculates the shared key S\u2032 by \nraising TA to SB and then taking mod p.\na. Prove that, in general, Alice and Bob obtain the same symmetric key, that \nis, prove S=S\u2032.\nb. With p = 11 and g = 2, suppose Alice and Bob choose private keys \nSA=5 and SB=12, respectively. Calculate Alice\u2019s and Bob\u2019s public \nkeys, TA and TB. Show all work.\nc. Following up on part (b), now calculate S as the shared symmetric key. \nShow all work.\nd. Provide a timing diagram that shows how Diffie-Hellman can be \nattacked by a man-in-the-middle. The timing diagram should have \nthree vertical lines, one for Alice, one for Bob, and one for the attacker \nTrudy.\n P10. Suppose Alice wants to communicate with Bob using symmetric key cryp-\ntography using a session key KS. In Section 8.2, we learned how public-key \ncryptography can be used to distribute the session key from Alice to Bob.  \nIn this problem, we explore how the session key can be distributed\u2014without \n696     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\npublic key cryptography\u2014using a key distribution center (KDC). The KDC \nis a server that shares a unique secret symmetric key with each registered \nuser. For Alice and Bob, denote these keys by KA@KDC and KB@KDC. Design a \nscheme that uses the KDC to distribute KS to Alice and Bob. Your scheme \nshould use three messages to distribute the session key: a message from Alice \nto the KDC; a message from the KDC to Alice; and finally a message from \nAlice to Bob. The first message is KA@KDC (A, B). Using the notation, KA@KDC, \nKB@KDC, S, A,  and B answer the following questions.\na. What is the second message?\nb. What is the third message?\n P11. Compute a third message, different from the two messages in Figure 8.8, that \nhas the same checksum as the messages in Figure 8.8.\n P12. The sender can mix some randomness into the ciphertext so that identical \nplaintext blocks produce different ciphertext blocks. But for each cipher bit, \nthe sender must now also send a random bit, doubling the required bandwidth. \nIs there any way around this?\n P13. In the BitTorrent P2P file distribution protocol (see Chapter 2), the seed \nbreaks the file into blocks, and the peers redistribute the blocks to each other. \nWithout any protection, an attacker can easily wreak havoc in a torrent by \nmasquerading as a benevolent peer and sending bogus blocks to a small \nsubset of peers in the torrent. These unsuspecting peers then redistribute the \nbogus blocks to other peers, which in turn redistribute the bogus blocks to \neven more peers. Thus, it is critical for BitTorrent to have a mechanism that \nallows a peer to verify the integrity of a block, so that it doesn\u2019t redistrib-\nute bogus blocks. Assume that when a peer joins a torrent, it initially gets a \n.torrent  file from a fully trusted source. Describe a simple scheme that \nallows peers to verify the integrity of blocks.\n P14. Solving factorization in polynomial time implies breaking the RSA cryptosystem. \nIs the converse", "doc_id": "566b6ddc-b99e-47eb-b2a8-e3606c8f3082", "embedding": null, "doc_hash": "4b02b20e2940671d6bc7571eb29e858ade3595dae92d60a5e1f39a38207883f5", "extra_info": null, "node_info": {"start": 2050423, "end": 2054044}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "4b473ee4-621a-4493-9594-d1d23d5069f8", "3": "97445140-56a3-4e3f-a851-a2f5aa417a42"}}, "__type__": "1"}, "97445140-56a3-4e3f-a851-a2f5aa417a42": {"__data__": {"text": "in a torrent by \nmasquerading as a benevolent peer and sending bogus blocks to a small \nsubset of peers in the torrent. These unsuspecting peers then redistribute the \nbogus blocks to other peers, which in turn redistribute the bogus blocks to \neven more peers. Thus, it is critical for BitTorrent to have a mechanism that \nallows a peer to verify the integrity of a block, so that it doesn\u2019t redistrib-\nute bogus blocks. Assume that when a peer joins a torrent, it initially gets a \n.torrent  file from a fully trusted source. Describe a simple scheme that \nallows peers to verify the integrity of blocks.\n P14. Solving factorization in polynomial time implies breaking the RSA cryptosystem. \nIs the converse true?\n P15. Consider our authentication protocol in Figure 8.18 in which Alice authen-\nticates herself to Bob, which we saw works well (i.e., we found no flaws in \nit). Now suppose that while Alice is authenticating herself to Bob, Bob must \nauthenticate himself to Alice. Give a scenario by which Trudy, pretending to \nbe Alice, can now authenticate herself to Bob as Alice. ( Hint: Consider that \nthe sequence of operations of the protocol, one with Trudy initiating and one \nwith Bob initiating, can be arbitrarily interleaved. Pay particular attention to \nthe fact that both Bob and Alice will use a nonce, and that if care is not taken, \nthe same nonce can be used maliciously.)\n P16. A natural question is whether we can use a nonce and public key cryptography to \nsolve the end-point authentication problem in Section 8.4. Consider the following \nnatural protocol: (1) Alice sends the message \u201cI am Alice\u201d  to Bob. (2) Bob \nchooses a nonce, R, and sends it to Alice. (3) Alice uses her private  key to encrypt \nPROBLEMS      697\nthe nonce and sends the resulting value to Bob. (4) Bob applies Alice\u2019s public key \nto the received message. Thus, Bob computes R and authenticates Alice.\na. Diagram this protocol, using the notation for public and private keys \nemployed in the textbook.\nb. Suppose that certificates are not used. Describe how Trudy can become  \na \u201cwoman-in-the-middle\u201d by intercepting Alice\u2019s messages and then \n pretending to be Alice to Bob.\n P17. Figure 8.19 shows the operations that Alice must perform with PGP to pro-\nvide confidentiality, authentication, and integrity. Diagram the corresponding \noperations that Bob must perform on the package received from Alice.\n P18. Suppose Alice wants to send an e-mail to Bob. Bob has a public-private key  \npair (K   B+, K   B-), and Alice has Bob\u2019s certificate. But Alice does not have a \npublic, private key pair. Alice and Bob (and the entire world) share the same \nhash function H(#).\na. In this situation, is it possible to design a scheme so that Bob can verify \nthat Alice created the message? If so, show how with a block diagram for \nAlice and Bob.\nb. Is it possible to design a scheme that provides confidentiality for sending \nthe message from Alice to Bob? If so, show how with a block diagram for \nAlice and Bob.\n P19. Consider the Wireshark output below for a portion of an SSL session.\na. Is Wireshark packet 112 sent by the client or server?\nb. What is the server\u2019s IP address and port number?\nc. Assuming no loss and no retransmissions, what will be the sequence num-\nber of the next TCP segment sent by the client?\nd. How many SSL records does Wireshark packet 112 contain?\ne. Does packet 112 contain a Master Secret or an Encrypted Master Secret or \nneither?\nf. Assuming that the handshake type field is 1 byte and each length field is \n3 bytes, what are the values of the first and last bytes of the Master Secret \n(or Encrypted Master", "doc_id": "97445140-56a3-4e3f-a851-a2f5aa417a42", "embedding": null, "doc_hash": "2292a6cf8eb65b9b73bba9d309647a8b2c3da41eaced93201f7042e78e15a06b", "extra_info": null, "node_info": {"start": 2054081, "end": 2057716}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "566b6ddc-b99e-47eb-b2a8-e3606c8f3082", "3": "9e57d4a5-7a53-4139-8b4a-8b881a740fda"}}, "__type__": "1"}, "9e57d4a5-7a53-4139-8b4a-8b881a740fda": {"__data__": {"text": "for sending \nthe message from Alice to Bob? If so, show how with a block diagram for \nAlice and Bob.\n P19. Consider the Wireshark output below for a portion of an SSL session.\na. Is Wireshark packet 112 sent by the client or server?\nb. What is the server\u2019s IP address and port number?\nc. Assuming no loss and no retransmissions, what will be the sequence num-\nber of the next TCP segment sent by the client?\nd. How many SSL records does Wireshark packet 112 contain?\ne. Does packet 112 contain a Master Secret or an Encrypted Master Secret or \nneither?\nf. Assuming that the handshake type field is 1 byte and each length field is \n3 bytes, what are the values of the first and last bytes of the Master Secret \n(or Encrypted Master Secret)?\ng. The client encrypted handshake message takes into account how many \nSSL records?\nh. The server encrypted handshake message takes into account how many \nSSL records?\n P20. In Section 8.6.1, it is shown that without sequence numbers, Trudy (a \nwoman-in-the middle) can wreak havoc in an SSL session by interchanging \nTCP segments. Can Trudy do something similar by deleting a TCP seg -\nment? What does she need to do to succeed at the deletion attack? What \neffect will it have?\n698     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\n P21. A router\u2019s link-state message includes a list of its directly connected neighbors \nand the direct costs to these neighbors. Once a router receives link-state messages \nfrom all of the other routers, it can create a complete map of the network, run its \nleast-cost routing algorithm, and configure its forwarding table. One relatively \neasy attack on the routing algorithm is for the attacker to distribute bogus link -\nstate messages with incorrect link-state information. How can this be prevented? \n P22. The following true/false questions pertain to Figure 8.28.\na. When a host in 172.16.1/24 sends a datagram to an Amazon.com server, \nthe router R1 will encrypt the datagram using IPsec.\nb. When a host in 172.16.1/24 sends a datagram to a host in 172.16.2/24, the \nrouter R1 will change the source and destination address of the IP datagram.\nc. Suppose a host in 172.16.1/24 initiates a TCP connection to a Web server \nin 172.16.2/24. As part of this connection, all datagrams sent by R1 will \nhave protocol number 50 in the left-most IPv4 header field.(Wireshark screenshot reprinted by permission of the Wireshark Foundation.)\n\nPROBLEMS      699\nd. Consider sending a TCP segment from a host in 172.16.1/24 to a host in \n172.16.2/24. Suppose the acknowledgment for this segment gets lost, so \nthat TCP resends the segment. Because IPsec uses sequence numbers, R1 \nwill not resend the TCP segment.\n P23. When Bob signs a message, Bob must put something on the message that \nis unique to him. Bob could consider attaching a MAC for the signature, \nwhere the MAC is created by appending his key (unique to him) to the \nmessage, and then taking the hash. Will it cause any problem when Alice \nwould try verification?\n P24. Consider the following pseudo-WEP protocol. The key is 4 bits and the IV \nis 2 bits. The IV is appended to the end of the key when generating the key -\nstream. Suppose that the shared secret key is 1010. The keystreams for the \nfour possible inputs are as follows:\n  101000: 0010101101010101001011010100100 . . .\n  101001: 1010011011001010110100100101101 . . .\n  101010: 0001101000111100010100101001111 . . .\n  101011: 1111101010000000101010100010111 . . .\n", "doc_id": "9e57d4a5-7a53-4139-8b4a-8b881a740fda", "embedding": null, "doc_hash": "6bd7fa9f75699bf180d64b1b8f31e5d015b116981f0d7bba2ad0a88c1fb3be09", "extra_info": null, "node_info": {"start": 2057706, "end": 2061170}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "97445140-56a3-4e3f-a851-a2f5aa417a42", "3": "c5111d56-dec7-4b22-bae4-628aafbff881"}}, "__type__": "1"}, "c5111d56-dec7-4b22-bae4-628aafbff881": {"__data__": {"text": "for the signature, \nwhere the MAC is created by appending his key (unique to him) to the \nmessage, and then taking the hash. Will it cause any problem when Alice \nwould try verification?\n P24. Consider the following pseudo-WEP protocol. The key is 4 bits and the IV \nis 2 bits. The IV is appended to the end of the key when generating the key -\nstream. Suppose that the shared secret key is 1010. The keystreams for the \nfour possible inputs are as follows:\n  101000: 0010101101010101001011010100100 . . .\n  101001: 1010011011001010110100100101101 . . .\n  101010: 0001101000111100010100101001111 . . .\n  101011: 1111101010000000101010100010111 . . .\n  Suppose all messages are 8 bits long. Suppose the ICV (integrity check) is  \n4 bits long, and is calculated by XOR-ing the first 4 bits of data with the last \n4 bits of data. Suppose the pseudo-WEP packet consists of three fields: first \nthe IV field, then the message field, and last the ICV field, with some of these \nfields encrypted.\na. We want to send the message m = 10100000 using the IV = 11 and using \nWEP. What will be the values in the three WEP fields?\nb. Show that when the receiver decrypts the WEP packet, it recovers the \nmessage and the ICV.\nc. Suppose Trudy intercepts a WEP packet (not necessarily with the IV = 11) \nand wants to modify it before forwarding it to the receiver. Suppose Trudy \nflips the first ICV bit. Assuming that Trudy does not know the keystreams \nfor any of the IVs, what other bit(s) must Trudy also flip so that the \nreceived packet passes the ICV check?\nd. Justify your answer by modifying the bits in the WEP packet in \npart (a), decrypting the resulting packet, and verifying the integrity \ncheck.\n P25. Provide a filter table and a connection table for a stateful firewall that is as \nrestrictive as possible but accomplishes the following:\na. Allows all internal users to establish Telnet sessions with external hosts.\nb. Allows external users to surf the company Web site at 222.22.0.12.\nc. But otherwise blocks all inbound and outbound traffic.\n700     CHAPTER 8 \u2002\u2002\u2022 \u2002\u2002 SECURITY IN COMPUTER NETWORKS\n  The internal network is 222.22/16. In your solution, suppose that the connec-\ntion table is currently caching three connections, all from inside to outside. \nYou\u2019ll need to invent appropriate IP addresses and port numbers.\n P26. Suppose Alice wants to visit the Web site activist.com using a TOR-like \n service. This service uses two non-colluding proxy servers, Proxy1 and \nProxy2. Alice first obtains the certificates (each containing a public key)  \nfor Proxy1 and Proxy2 from some central server. Denote K1+( ), K2+( ), K1-( ), \nand K2-( ) for the encryption/decryption with public and private RSA keys.\na. Using a timing diagram, provide a protocol (as simple as possible) that \nenables Alice to establish a shared session key S1 with Proxy1. Denote \nS1(m) for encryption/decryption of data m with the shared key S1.\nb. Using a timing diagram, provide a protocol (as simple as possible) that \nallows Alice to establish a shared session key S2 with Proxy2 without \nrevealing her IP address to Proxy2 .\nc. Assume now that shared keys S1 and S2 are now established. Using a \ntiming diagram, provide a protocol (as simple as possible and not using \npublic-key cryptography ) that allows Alice to request an html page from \nactivist.com without revealing her IP address to Proxy2  and without \nrevealing to Proxy1 which site she is visiting . Your diagram should end \nwith an HTTP request arriving at activist.com.\nWireshark Lab\nIn this lab (available from the", "doc_id": "c5111d56-dec7-4b22-bae4-628aafbff881", "embedding": null, "doc_hash": "c4e9f9c5cb5763c21e7d517dff33d14024791e10c0198274e298fe5d4424e1af", "extra_info": null, "node_info": {"start": 2061229, "end": 2064792}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "9e57d4a5-7a53-4139-8b4a-8b881a740fda", "3": "d723b96f-d88c-4ccd-99d4-5dc9c9352293"}}, "__type__": "1"}, "d723b96f-d88c-4ccd-99d4-5dc9c9352293": {"__data__": {"text": "shared session key S1 with Proxy1. Denote \nS1(m) for encryption/decryption of data m with the shared key S1.\nb. Using a timing diagram, provide a protocol (as simple as possible) that \nallows Alice to establish a shared session key S2 with Proxy2 without \nrevealing her IP address to Proxy2 .\nc. Assume now that shared keys S1 and S2 are now established. Using a \ntiming diagram, provide a protocol (as simple as possible and not using \npublic-key cryptography ) that allows Alice to request an html page from \nactivist.com without revealing her IP address to Proxy2  and without \nrevealing to Proxy1 which site she is visiting . Your diagram should end \nwith an HTTP request arriving at activist.com.\nWireshark Lab\nIn this lab (available from the book Web site), we investigate the Secure Sockets \nLayer (SSL) protocol. Recall from Section 8.6 that SSL is used for securing a TCP \nconnection, and that it is extensively used in practice for secure Internet transactions. \nIn this lab, we will focus on the SSL records sent over the TCP connection. We will \nattempt to delineate and classify each of the records, with a goal of understanding the \nwhy and how for each record. We investigate the various SSL record types as well \nas the fields in the SSL messages. We do so by analyzing a trace of the SSL records \nsent between your host and an e-commerce server.\nIPsec Lab\nIn this lab (available from the book Web site), we will explore how to create IPsec \nSAs between linux boxes. You can do the first part of the lab with two ordinary linux \nboxes, each with one Ethernet adapter. But for the second part of the lab, you will \nneed four linux boxes, two of which having two Ethernet adapters. In the second half \nof the lab, you will create IPsec SAs using the ESP protocol in the tunnel mode. You \nwill do this by first manually creating the SAs, and then by having IKE create the SAs.\n701\nWhat led you to specialize in the networking security area?\nThis is going to sound odd, but the answer is simple: It was fun. My background was in \n systems programming and systems administration, which leads fairly naturally to security. \nAnd I\u2019ve always been interested in communications, ranging back to part-time systems \n programming jobs when I was in college.\nMy work on security continues to be motivated by two things\u2014a desire to keep com -\nputers useful, which means that their function can\u2019t be corrupted by attackers, and a desire \nto protect privacy.\nWhat was your vision for Usenet at the time that you were developing it? And now?\nWe originally viewed it as a way to talk about computer science and computer program -\nming around the country, with a lot of local use for administrative matters, for-sale ads, and \nso on. In fact, my original prediction was one to two messages per day, from 50\u2013100 sites at \nthe most\u2014ever. But the real growth was in people-related topics, including\u2014but not limited \nto\u2014human interactions with computers. My favorite newsgroups, over the years, have been \nthings like rec.woodworking, as well as sci.crypt.\nTo some extent, netnews has been displaced by the Web. Were I to start designing it \ntoday, it would look very different. But it still excels as a way to reach a very broad audi -\nence that is interested in the topic, without having to rely on particular Web sites.\nHas anyone inspired you professionally? In what ways?\nProfessor Fred Brooks\u2014the founder and original chair of the computer science department \nat the University of North Carolina at Chapel Hill, the manager of the team that developed \nthe IBM S/360 and OS/360, and the author of The Mythical Man-Month \u2014was a tremendous AN INTERVIEW WITH\u2026\nSteven M. Bellovin\nSteven M. Bellovin joined the faculty at Columbia University after \nmany years at the Network Services Research Lab at AT&T Labs \nResearch in Florham Park, New Jersey. His focus is on networks, \nsecurity, and why the two are incompatible. In 1995, he was \nawarded the Usenix Lifetime", "doc_id": "d723b96f-d88c-4ccd-99d4-5dc9c9352293", "embedding": null, "doc_hash": "78f72963d1f63f145cfd5297108be8c105d672e885a8a4e06b9f9632ccb4e938", "extra_info": null, "node_info": {"start": 2064712, "end": 2068668}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "c5111d56-dec7-4b22-bae4-628aafbff881", "3": "40e5f72e-ebc4-4f6b-98e7-28781c99989b"}}, "__type__": "1"}, "40e5f72e-ebc4-4f6b-98e7-28781c99989b": {"__data__": {"text": "as a way to reach a very broad audi -\nence that is interested in the topic, without having to rely on particular Web sites.\nHas anyone inspired you professionally? In what ways?\nProfessor Fred Brooks\u2014the founder and original chair of the computer science department \nat the University of North Carolina at Chapel Hill, the manager of the team that developed \nthe IBM S/360 and OS/360, and the author of The Mythical Man-Month \u2014was a tremendous AN INTERVIEW WITH\u2026\nSteven M. Bellovin\nSteven M. Bellovin joined the faculty at Columbia University after \nmany years at the Network Services Research Lab at AT&T Labs \nResearch in Florham Park, New Jersey. His focus is on networks, \nsecurity, and why the two are incompatible. In 1995, he was \nawarded the Usenix Lifetime Achievement Award for his work in the \ncreation of Usenet, the first newsgroup exchange network that linked \ntwo or more computers and allowed users to share information and \njoin in discussions. Steve is also an elected member of the National \nAcademy of Engineering. He received his BA from Columbia \nUniversity and his PhD from the University of North Carolina at \nChapel Hill.\n702influence on my career. More than anything else, he taught outlook and trade-offs\u2014how to \nlook at problems in the context of the real world (and how much messier the real world is \nthan a theorist would like), and how to balance competing interests in designing a solution. \nMost computer work is engineering\u2014the art of making the right trade-offs to satisfy many \ncontradictory objectives.\nWhat is your vision for the future of networking and security?\nThus far, much of the security we have has come from isolation. A firewall, for example, \nworks by cutting off access to certain machines and services. But we\u2019re in an era of increas -\ning connectivity\u2014it\u2019s gotten harder to isolate things. Worse yet, our production systems \nrequire far more separate pieces, interconnected by networks. Securing all that is one of our \nbiggest challenges.\nWhat would you say have been the greatest advances in security? How much further do \nwe have to go?\nAt least scientifically, we know how to do cryptography. That\u2019s been a big help. But most \nsecurity problems are due to buggy code, and that\u2019s a much harder problem. In fact, it\u2019s \nthe oldest unsolved problem in computer science, and I think it will remain that way. The \nchallenge is figuring out how to secure systems when we have to build them out of insecure \ncomponents. We can already do that for reliability in the face of hardware failures; can we \ndo the same for security?\nDo you have any advice for students about the Internet and networking security?\nLearning the mechanisms is the easy part. Learning how to \u201cthink paranoid\u201d is harder. You \nhave to remember that probability distributions don\u2019t apply\u2014the attackers can and will find \nimprobable conditions. And the details matter\u2014a lot.\n703While lounging in bed or riding buses and subways, people in all corners of the world \nare currently using the Internet to watch movies and television shows on demand. \nInternet movie and television distribution companies such as Netflix and Amazon \nin North America and Youku and Kankan in China have practically become house -\nhold names. But people are not only watching Internet videos, they are using sites \nlike YouTube to upload and distribute their own user-generated content, becoming \nInternet video producers as well as consumers. Moreover, network applications such \nas Skype, Google Talk, and WeChat (enormously popular in China) allow people \nto not only make \u201ctelephone calls\u201d over the Internet, but to also enhance those calls \nwith video and multi-person conferencing. In fact, we predict that by the end of the \ncurrent decade most of the video consumption and voice conversations will take \nplace end-to-end over the Internet, more typically to wireless devices connected to  \nthe Internet via cellular and WiFi access networks. Traditional telephony and broad -\ncast television are quickly becoming obsolete.\nWe begin this chapter with a taxonomy of multimedia", "doc_id": "40e5f72e-ebc4-4f6b-98e7-28781c99989b", "embedding": null, "doc_hash": "74ffea1043dc43cc1766368a05e00381f6029eab5ca6db659f6c4aa3ea13ab8a", "extra_info": null, "node_info": {"start": 2068652, "end": 2072729}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "d723b96f-d88c-4ccd-99d4-5dc9c9352293", "3": "1be5860d-eb4d-4edf-aa33-718c6dce73e5"}}, "__type__": "1"}, "1be5860d-eb4d-4edf-aa33-718c6dce73e5": {"__data__": {"text": "names. But people are not only watching Internet videos, they are using sites \nlike YouTube to upload and distribute their own user-generated content, becoming \nInternet video producers as well as consumers. Moreover, network applications such \nas Skype, Google Talk, and WeChat (enormously popular in China) allow people \nto not only make \u201ctelephone calls\u201d over the Internet, but to also enhance those calls \nwith video and multi-person conferencing. In fact, we predict that by the end of the \ncurrent decade most of the video consumption and voice conversations will take \nplace end-to-end over the Internet, more typically to wireless devices connected to  \nthe Internet via cellular and WiFi access networks. Traditional telephony and broad -\ncast television are quickly becoming obsolete.\nWe begin this chapter with a taxonomy of multimedia applications in Sec-\ntion 9.1. We\u2019ll see that a multimedia application can be classified as either stream-\ning stored audio/video , conversational voice/video-over-IP , or streaming live audio/\nvideo . We\u2019ll see that each of these classes of applications has its own unique service \nrequirements that differ significantly from those of traditional elastic applications \nsuch as e-mail, Web browsing, and remote login. In Section 9.2, we\u2019ll examine video \nstreaming in some detail. We\u2019ll explore many of the underlying principles behind 9CHAPTER\nMultimedia \nNetworking\n\n704     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\nvideo streaming, including client buffering, prefetching, and adapting video qual -\nity to available bandwidth. In Section 9.3, we investigate conversational voice and \nvideo, which, unlike elastic applications, are highly sensitive to end-to-end delay \nbut can tolerate occasional loss of data. Here we\u2019ll examine how techniques such \nas adaptive playout, forward error correction, and error concealment can mitigate \nagainst network-induced packet loss and delay. We\u2019ll also examine Skype as a case \nstudy. In Section 9.4, we\u2019ll study RTP and SIP, two popular protocols for real-time \nconversational voice and video applications. In Section 9.5, we\u2019ll investigate mecha -\nnisms within the network that can be used to distinguish one class of traffic (e.g., \ndelay-sensitive applications such as conversational voice) from another (e.g., elastic \napplications such as browsing Web pages), and provide differentiated service among \nmultiple classes of traffic.\n9.1 Multimedia Networking Applications\nWe define a multimedia network application as any network application that employs \naudio or video. In this section, we provide a taxonomy of multimedia applications. \nWe\u2019ll see that each class of applications in the taxonomy has its own unique set of \nservice requirements and design issues. But before diving into an in-depth discussion \nof Internet multimedia applications, it is useful to consider the intrinsic characteris -\ntics of the audio and video media themselves.\n9.1.1  Properties of Video\nPerhaps the most salient characteristic of video is its high bit rate . Video distributed \nover the Internet typically ranges from 100 kbps for low-quality video conferencing \nto over 3 Mbps for streaming high-definition movies. To get a sense of how video \nbandwidth demands compare with those of other Internet applications, let\u2019s briefly \nconsider three different users, each using a different Internet application. Our first \nuser, Frank, is going quickly through photos posted on his friends\u2019 Facebook pages. \nLet\u2019s assume that Frank is looking at a new photo every 10 seconds, and that photos \nare on average 200 Kbytes in size. (As usual, throughout this discussion we make \nthe simplifying assumption that 1 Kbyte =8,000 bits.) Our second user, Martha, \nis streaming music from the Internet (\u201cthe cloud\u201d) to her smartphone. Let\u2019s assume \nMartha is using a service such as Spotify to listen to many MP3 songs, one after the \nother, each encoded at a rate of 128 kbps. Our third user,", "doc_id": "1be5860d-eb4d-4edf-aa33-718c6dce73e5", "embedding": null, "doc_hash": "a92796e377cc1559134affc46c293d9b859c413200de2dbc4174170f898a5bd6", "extra_info": null, "node_info": {"start": 2072653, "end": 2076609}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "40e5f72e-ebc4-4f6b-98e7-28781c99989b", "3": "f2245af4-a884-4aff-bfdd-2a53b12b712c"}}, "__type__": "1"}, "f2245af4-a884-4aff-bfdd-2a53b12b712c": {"__data__": {"text": "get a sense of how video \nbandwidth demands compare with those of other Internet applications, let\u2019s briefly \nconsider three different users, each using a different Internet application. Our first \nuser, Frank, is going quickly through photos posted on his friends\u2019 Facebook pages. \nLet\u2019s assume that Frank is looking at a new photo every 10 seconds, and that photos \nare on average 200 Kbytes in size. (As usual, throughout this discussion we make \nthe simplifying assumption that 1 Kbyte =8,000 bits.) Our second user, Martha, \nis streaming music from the Internet (\u201cthe cloud\u201d) to her smartphone. Let\u2019s assume \nMartha is using a service such as Spotify to listen to many MP3 songs, one after the \nother, each encoded at a rate of 128 kbps. Our third user, Victor, is watching a video \nthat has been encoded at 2 Mbps. Finally, let\u2019s suppose that the session length for all \nthree users is 4,000 seconds (approximately 67 minutes). Table 9.1 compares the bit \nrates and the total bytes transferred for these three users. We see that video streaming \nconsumes by far the most bandwidth, having a bit rate of more than ten times greater \nthan that of the Facebook and music-streaming applications. Therefore, when design -\n9.1  \u2022  MULTIMEDIA NETWORKING APPLICATIONS      705\ning networked video applications, the first thing we must keep in mind is the high \nbit-rate requirements of video. Given the popularity of video and its high bit rate, it \nis perhaps not surprising that Cisco predicts [Cisco 2015] that streaming and stored \nvideo will be approximately 80 percent of global consumer Internet traffic by 2019.\nAnother important characteristic of video is that it can be compressed, thereby \ntrading off video quality with bit rate. A video is a sequence of images, typically \nbeing displayed at a constant rate, for example, at 24 or 30 images per second. An \nuncompressed, digitally encoded image consists of an array of pixels, with each \npixel encoded into a number of bits to represent luminance and color. There are two \ntypes of redundancy in video, both of which can be exploited by video compression .  \nSpatial redundancy  is the redundancy within a given image. Intuitively, an image that \nconsists of mostly white space has a high degree of redundancy and can be efficiently \ncompressed without significantly sacrificing image quality. Temporal redundancy  \nreflects repetition from image to subsequent image. If, for example, an image and the \nsubsequent image are exactly the same, there is no reason to re-encode the subsequent \nimage; it is instead more efficient simply to indicate during encoding that the subse -\nquent image is exactly the same. Today\u2019s off-the-shelf compression algorithms can \ncompress a video to essentially any bit rate desired. Of course, the higher the bit rate, \nthe better the image quality and the better the overall user viewing experience.\nWe can also use compression to create multiple versions  of the same video, \neach at a different quality level. For example, we can use compression to create, \nsay, three versions of the same video, at rates of 300 kbps, 1 Mbps, and 3 Mbps. \nUsers can then decide which version they want to watch as a function of their current \navailable bandwidth. Users with high-speed Internet connections might choose the \n3 Mbps version; users watching the video over 3G with a smartphone might choose \nthe 300 kbps version. Similarly, the video in a video conference application can  \nbe compressed \u201con-the-fly\u201d to provide the best video quality given the available  \nend-to-end bandwidth between conversing users.\n9.1.2  Properties of Audio\nDigital audio (including digitized speech and music) has significantly lower band -\nwidth requirements than video. Digital audio, however, has its own unique prop -\nerties that must be considered when designing multimedia network applications.  Table 9.1  \u2666 Comparison of bit-rate requirements of three Internet applicationsBit rate Bytes transferred in 67 min\nFacebook Frank 160 kbps 80 Mbytes\nMartha Music 128 kbps 64 Mbytes\nVictor Video 2 Mbps 1", "doc_id": "f2245af4-a884-4aff-bfdd-2a53b12b712c", "embedding": null, "doc_hash": "2e8bb641ce8c06137cde7a7ff024e5616d78354e7eab256c03df4eaac9b67684", "extra_info": null, "node_info": {"start": 2076696, "end": 2080770}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "1be5860d-eb4d-4edf-aa33-718c6dce73e5", "3": "a0ec949e-d3ae-4104-a959-f29f95ce29ee"}}, "__type__": "1"}, "a0ec949e-d3ae-4104-a959-f29f95ce29ee": {"__data__": {"text": "might choose the \n3 Mbps version; users watching the video over 3G with a smartphone might choose \nthe 300 kbps version. Similarly, the video in a video conference application can  \nbe compressed \u201con-the-fly\u201d to provide the best video quality given the available  \nend-to-end bandwidth between conversing users.\n9.1.2  Properties of Audio\nDigital audio (including digitized speech and music) has significantly lower band -\nwidth requirements than video. Digital audio, however, has its own unique prop -\nerties that must be considered when designing multimedia network applications.  Table 9.1  \u2666 Comparison of bit-rate requirements of three Internet applicationsBit rate Bytes transferred in 67 min\nFacebook Frank 160 kbps 80 Mbytes\nMartha Music 128 kbps 64 Mbytes\nVictor Video 2 Mbps 1 Gbyte\n706     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\nTo understand these properties, let\u2019s first consider how analog audio (which humans \nand musical instruments generate) is converted to a digital signal:\n\u2022 The analog audio signal is sampled at some fixed rate, for example, at 8,000  \nsamples per second. The value of each sample will be some real number.\n\u2022 Each of the samples is then rounded to one of a finite number of values. This \noperation is referred to as quantization . The number of such finite values\u2014called \nquantization values\u2014is typically a power of two, for example, 256 quantization \nvalues.\n\u2022 Each of the quantization values is represented by a fixed number of bits. For \nexample, if there are 256 quantization values, then each value\u2014and hence each \naudio sample\u2014is represented by one byte. The bit representations of all the sam -\nples are then concatenated together to form the digital representation of the signal. \nAs an example, if an analog audio signal is sampled at 8,000 samples per second \nand each sample is quantized and represented by 8 bits, then the resulting digital \nsignal will have a rate of 64,000 bits per second. For playback through audio \nspeakers, the digital signal can then be converted back\u2014that is, decoded\u2014to an \nanalog signal. However, the decoded analog signal is only an approximation of \nthe original signal, and the sound quality may be noticeably degraded (for exam-\nple, high-frequency sounds may be missing in the decoded signal). By increasing \nthe sampling rate and the number of quantization values, the decoded signal can \nbetter approximate the original analog signal. Thus (as with video), there is a \ntrade-off between the quality of the decoded signal and the bit-rate and storage \nrequirements of the digital signal.\nThe basic encoding technique that we just described is called pulse code modulation \n(PCM) . Speech encoding often uses PCM, with a sampling rate of 8,000 samples per \nsecond and 8 bits per sample, resulting in a rate of 64 kbps. The audio compact disk \n(CD) also uses PCM, with a sampling rate of 44,100 samples per second with 16 \nbits per sample; this gives a rate of 705.6 kbps for mono and 1.411 Mbps for stereo.\nPCM-encoded speech and music, however, are rarely used in the Internet. \nInstead, as with video, compression techniques are used to reduce the bit rates of \nthe stream. Human speech can be compressed to less than 10 kbps and still be intel -\nligible. A popular compression technique for near CD-quality stereo music is MPEG \n1 layer 3 , more commonly known as MP3 . MP3 encoders can compress to many \ndifferent rates; 128 kbps is the most common encoding rate and produces very little \nsound degradation. A related standard is Advanced Audio Coding (AAC) , which \nhas been popularized by Apple. As with video, multiple versions of a prerecorded \naudio stream can be created, each at a different bit rate.\nAlthough audio bit rates are generally much less than those of video, users are \ngenerally much more sensitive to audio glitches than video glitches. Consider, for \nexample, a video conference taking place over the Internet. If, from time to time, \nthe video signal is lost for a few seconds, the", "doc_id": "a0ec949e-d3ae-4104-a959-f29f95ce29ee", "embedding": null, "doc_hash": "0e34c1f308019c62603ef98d7e4fea797ef7262aaa8d0a46296000b7b714d45d", "extra_info": null, "node_info": {"start": 2080734, "end": 2084726}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "f2245af4-a884-4aff-bfdd-2a53b12b712c", "3": "850f3fb1-9217-4604-a022-ffebd61cb105"}}, "__type__": "1"}, "850f3fb1-9217-4604-a022-ffebd61cb105": {"__data__": {"text": "Human speech can be compressed to less than 10 kbps and still be intel -\nligible. A popular compression technique for near CD-quality stereo music is MPEG \n1 layer 3 , more commonly known as MP3 . MP3 encoders can compress to many \ndifferent rates; 128 kbps is the most common encoding rate and produces very little \nsound degradation. A related standard is Advanced Audio Coding (AAC) , which \nhas been popularized by Apple. As with video, multiple versions of a prerecorded \naudio stream can be created, each at a different bit rate.\nAlthough audio bit rates are generally much less than those of video, users are \ngenerally much more sensitive to audio glitches than video glitches. Consider, for \nexample, a video conference taking place over the Internet. If, from time to time, \nthe video signal is lost for a few seconds, the video conference can likely proceed \n9.1  \u2022  MULTIMEDIA NETWORKING APPLICATIONS      707\nwithout too much user frustration. If, however, the audio signal is frequently lost, the \nusers may have to terminate the session.\n9.1.3  Types of Multimedia Network Applications\nThe Internet supports a large variety of useful and entertaining multimedia applica -\ntions. In this subsection, we classify multimedia applications into three broad cat -\negories: (i) streaming stored audio/video , (ii) conversational voice/video-over-IP , \nand (iii) streaming live audio/video . As we will soon see, each of these application \ncategories has its own set of service requirements and design issues.\nStreaming Stored Audio and Video\nTo keep the discussion concrete, we focus here on streaming stored video, which typ -\nically combines video and audio components. Streaming stored audio (such as Spo -\ntify\u2019s streaming music service) is very similar to streaming stored video, although the \nbit rates are typically much lower.\nIn this class of applications, the underlying medium is prerecorded video, such \nas a movie, a television show, a prerecorded sporting event, or a prerecorded user-\ngenerated video (such as those commonly seen on YouTube). These prerecorded \nvideos are placed on servers, and users send requests to the servers to view the vid -\neos on demand . Many Internet companies today provide streaming video, including \nYouTube (Google), Netflix, Amazon, and Hulu. Streaming stored video has three \nkey distinguishing features.\n\u2022 Streaming.  In a streaming stored video application, the client typically begins \nvideo playout within a few seconds after it begins receiving the video from the \nserver. This means that the client will be playing out from one location in the \nvideo while at the same time receiving later parts of the video from the server. \nThis technique, known as streaming , avoids having to download the entire video \nfile (and incurring a potentially long delay) before playout begins.\n\u2022 Interactivity.  Because the media is prerecorded, the user may pause, reposition \nforward, reposition backward, fast-forward, and so on through the video content. \nThe time from when the user makes such a request until the action manifests itself \nat the client should be less than a few seconds for acceptable responsiveness.\n\u2022 Continuous playout.  Once playout of the video begins, it should proceed accord -\ning to the original timing of the recording. Therefore, data must be received from \nthe server in time for its playout at the client; otherwise, users experience video \nframe freezing (when the client waits for the delayed frames) or frame skipping \n(when the client skips over delayed frames).\nBy far, the most important performance measure for streaming video is average \nthroughput. In order to provide continuous playout, the network must provide an \n708     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\naverage throughput to the streaming application that is at least as large the bit rate of \nthe video itself. As we will see in Section 9.2, by using buffering and prefetching, \nit is possible to provide continuous playout even when the throughput fluctuates, \nas long as the average throughput (averaged over 5\u201310 seconds) remains above the", "doc_id": "850f3fb1-9217-4604-a022-ffebd61cb105", "embedding": null, "doc_hash": "97b001cda3eae0e9323270b62670e8919d51c8b3352f20ce24ac9101ea91e554", "extra_info": null, "node_info": {"start": 2084705, "end": 2088800}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "a0ec949e-d3ae-4104-a959-f29f95ce29ee", "3": "01f0894f-34cb-4a03-8caf-2dea0ab2eeb5"}}, "__type__": "1"}, "01f0894f-34cb-4a03-8caf-2dea0ab2eeb5": {"__data__": {"text": "server in time for its playout at the client; otherwise, users experience video \nframe freezing (when the client waits for the delayed frames) or frame skipping \n(when the client skips over delayed frames).\nBy far, the most important performance measure for streaming video is average \nthroughput. In order to provide continuous playout, the network must provide an \n708     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\naverage throughput to the streaming application that is at least as large the bit rate of \nthe video itself. As we will see in Section 9.2, by using buffering and prefetching, \nit is possible to provide continuous playout even when the throughput fluctuates, \nas long as the average throughput (averaged over 5\u201310 seconds) remains above the \nvideo rate [Wang 2008].\nFor many streaming video applications, prerecorded video is stored on, and \nstreamed from, a CDN rather than from a single data center. There are also many \nP2P video streaming applications for which the video is stored on users\u2019 hosts \n(peers), with different chunks of video arriving from different peers that may \nspread around the globe. Given the prominence of Internet video streaming, we \nwill explore video streaming in some depth in Section 9.2, paying particular atten -\ntion to client buffering, prefetching, adapting quality to bandwidth availability, and \nCDN distribution.\nConversational Voice- and Video-over-IP\nReal-time conversational voice over the Internet is often referred to as Internet \ntelephony , since, from the user\u2019s perspective, it is similar to the traditional circuit-\nswitched telephone service. It is also commonly called Voice-over-IP (VoIP) . Con -\nversational video is similar, except that it includes the video of the participants as \nwell as their voices. Most of today\u2019s voice and video conversational systems allow \nusers to create conferences with three or more participants. Conversational voice and \nvideo are widely used in the Internet today, with the Internet companies Skype, QQ, \nand Google Talk boasting hundreds of millions of daily users.\nIn our discussion of application service requirements in Chapter 2 (Figure 2.4 ), \nwe identified a number of axes along which application requirements can be clas -\nsified. Two of these axes\u2014timing considerations and tolerance of data loss\u2014are \nparticularly important for conversational voice and video applications. Timing con -\nsiderations are important because audio and video conversational applications are \nhighly delay-sensitive . For a conversation with two or more interacting speakers, the \ndelay from when a user speaks or moves until the action is manifested at the other \nend should be less than a few hundred milliseconds. For voice, delays smaller than \n150 milliseconds are not perceived by a human listener, delays between 150 and 400 \nmilliseconds can be acceptable, and delays exceeding 400 milliseconds can result in \nfrustrating, if not completely unintelligible, voice conversations.\nOn the other hand, conversational multimedia applications are loss-tolerant \u2014\noccasional loss only causes occasional glitches in audio/video playback, and these \nlosses can often be partially or fully concealed. These delay-sensitive but loss-tolerant \ncharacteristics are clearly different from those of elastic data applications such as \nWeb browsing, e-mail, social networks, and remote login. For elastic applications, \nlong delays are annoying but not particularly harmful; the completeness and integrity \nof the transferred data, however, are of paramount importance. We will explore con -\nversational voice and video in more depth in Section 9.3, paying particular attention \n9.2  \u2022  STREAMING STORED VIDEO      709\nto how adaptive playout, forward error correction, and error concealment can miti -\ngate against network-induced packet loss and delay.\nStreaming Live Audio and Video\nThis third class of applications is similar to traditional broadcast radio and television, \nexcept that transmission takes place over the Internet. These applications allow a \nuser to", "doc_id": "01f0894f-34cb-4a03-8caf-2dea0ab2eeb5", "embedding": null, "doc_hash": "9779a559e3161638fbeb13cacba849ef3c7845ef0cc66d4819632986333f3666", "extra_info": null, "node_info": {"start": 2088860, "end": 2092909}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "850f3fb1-9217-4604-a022-ffebd61cb105", "3": "c4168a08-c15d-4a39-9bf3-5709f4533adf"}}, "__type__": "1"}, "c4168a08-c15d-4a39-9bf3-5709f4533adf": {"__data__": {"text": "those of elastic data applications such as \nWeb browsing, e-mail, social networks, and remote login. For elastic applications, \nlong delays are annoying but not particularly harmful; the completeness and integrity \nof the transferred data, however, are of paramount importance. We will explore con -\nversational voice and video in more depth in Section 9.3, paying particular attention \n9.2  \u2022  STREAMING STORED VIDEO      709\nto how adaptive playout, forward error correction, and error concealment can miti -\ngate against network-induced packet loss and delay.\nStreaming Live Audio and Video\nThis third class of applications is similar to traditional broadcast radio and television, \nexcept that transmission takes place over the Internet. These applications allow a \nuser to receive a live radio or television transmission\u2014such as a live sporting event \nor an ongoing news event\u2014transmitted from any corner of the world. Today, thou -\nsands of radio and television stations around the world are broadcasting content over \nthe Internet.\nLive, broadcast-like applications often have many users who receive the same \naudio/video program at the same time. In the Internet today, this is typically done \nwith CDNs (Section 2.6 ). As with streaming stored multimedia, the network must \nprovide each live multimedia flow with an average throughput that is larger than \nthe video consumption rate. Because the event is live, delay can also be an issue, \nalthough the timing constraints are much less stringent than those for conversational \nvoice. Delays of up to ten seconds or so from when the user chooses to view a live \ntransmission to when playout begins can be tolerated. We will not cover stream -\ning live media in this book because many of the techniques used for streaming live \nmedia\u2014initial buffering delay, adaptive bandwidth use, and CDN distribution\u2014are \nsimilar to those for streaming stored media.\n9.2 Streaming Stored Video\nFor streaming video applications, prerecorded videos are placed on servers, and \nusers send requests to these servers to view the videos on demand. The user may \nwatch the video from beginning to end without interruption, may stop watching the \nvideo well before it ends, or interact with the video by pausing or repositioning to a \nfuture or past scene. Streaming video systems can be classified into three categories: \nUDP streaming , HTTP streaming , and adaptive HTTP streaming  (see Section \n2.6). Although all three types of systems are used in practice, the majority of today\u2019s \nsystems employ HTTP streaming and adaptive HTTP streaming.\nA common characteristic of all three forms of video streaming is the extensive \nuse of client-side application buffering to mitigate the effects of varying end-to-end \ndelays and varying amounts of available bandwidth between server and client. For \nstreaming video (both stored and live), users generally can tolerate a small several-\nsecond initial delay between when the client requests a video and when video playout \nbegins at the client. Consequently, when the video starts to arrive at the client, the cli -\nent need not immediately begin playout, but can instead build up a reserve of video \nin an application buffer. Once the client has built up a reserve of several seconds of \n710     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\nbuffered-but-not-yet-played video, the client can then begin video playout. There \nare two important advantages provided by such client buffering . First, client-side \nbuffering can absorb variations in server-to-client delay. If a particular piece of video \ndata is delayed, as long as it arrives before the reserve of received-but-not-yet-played \nvideo is exhausted, this long delay will not be noticed. Second, if the server-to-client \nbandwidth briefly drops below the video consumption rate, a user can continue to \nenjoy continuous playback, again as long as the client application buffer does not \nbecome completely drained.\nFigure 9. 1 illustrates client-side buffering. In this simple example, suppose that \nvideo is encoded at a fixed bit rate, and thus each video block", "doc_id": "c4168a08-c15d-4a39-9bf3-5709f4533adf", "embedding": null, "doc_hash": "b74952958a336544057a07647c7fe5a96a0ee397f927da11cfd48865b4a33009", "extra_info": null, "node_info": {"start": 2092882, "end": 2096980}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "01f0894f-34cb-4a03-8caf-2dea0ab2eeb5", "3": "adc4d74d-abf5-4858-8979-fdbfeba0d78b"}}, "__type__": "1"}, "adc4d74d-abf5-4858-8979-fdbfeba0d78b": {"__data__": {"text": "NETWORKING\nbuffered-but-not-yet-played video, the client can then begin video playout. There \nare two important advantages provided by such client buffering . First, client-side \nbuffering can absorb variations in server-to-client delay. If a particular piece of video \ndata is delayed, as long as it arrives before the reserve of received-but-not-yet-played \nvideo is exhausted, this long delay will not be noticed. Second, if the server-to-client \nbandwidth briefly drops below the video consumption rate, a user can continue to \nenjoy continuous playback, again as long as the client application buffer does not \nbecome completely drained.\nFigure 9. 1 illustrates client-side buffering. In this simple example, suppose that \nvideo is encoded at a fixed bit rate, and thus each video block contains video frames \nthat are to be played out over the same fixed amount of time, \u25b3. The server transmits \nthe first video block at t0, the second block at t0+\u25b3, the third block at t0+2\u25b3,  \nand so on. Once the client begins playout, each block should be played out \u25b3 \ntime units after the previous block in order to reproduce the timing of the original \nrecorded video. Because of the variable end-to-end network delays, different video \nblocks experience different delays. The first video block arrives at the client at t1 and \nthe second block arrives at t2. The network delay for the ith block is the horizontal \ndistance between the time the block was transmitted by the server and the time it is \nreceived at the client; note that the network delay varies from one video block to \nanother. In this example, if the client were to begin playout as soon as the first block \narrived at t1, then the second block would not have arrived in time to be played out \nat out at t1+\u25b3. In this case, video playout would either have to stall (waiting for \nblock 2 to arrive) or block 2 could be skipped\u2014both resulting in undesirable playout \nimpairments. Instead, if the client were to delay the start of playout until t3, when \nblocks 1 through 6 have all arrived, periodic playout can proceed with all blocks hav -\ning been received before their playout time.\nVariable\nnetwork\ndelayClient\nplayout\ndelayConstant bit\nrate video\ntransmission\nby server\n123456789101112\nConstant bit\nrate video\nplayout\nby client\nTimeVideo block number\nt0 t1 t2 t3 t0+2D\nt0+D t1+D t3+DVideo\nreception\nat client\nFigure 9.1  \u2666 Client playout delay in video streaming\n9.2  \u2022  STREAMING STORED VIDEO      711\n9.2.1  UDP Streaming\nWe only briefly discuss UDP streaming here, referring the reader to more in-depth \ndiscussions of the protocols behind these systems where appropriate. With UDP \nstreaming, the server transmits video at a rate that matches the client\u2019s video con -\nsumption rate by clocking out the video chunks over UDP at a steady rate. For exam -\nple, if the video consumption rate is 2 Mbps and each UDP packet carries 8,000 \nbits of video, then the server would transmit one UDP packet into its socket every \n(8000 bits)/(2 Mbps) =4 msec. As we learned in Chapter 3, because UDP does \nnot employ a congestion-control mechanism, the server can push packets into the \nnetwork at the consumption rate of the video without the rate-control restrictions of \nTCP. UDP streaming typically uses a small client-side buffer, big enough to hold less \nthan a second of video.\nBefore passing the video chunks to UDP, the server will encapsulate the \nvideo chunks within transport packets specially designed for transporting audio \nand video, using the Real-Time Transport Protocol (RTP) [RFC 3550] or a simi -\nlar (possibly proprietary) scheme. We delay our coverage of RTP until Section \n9.3, where we discuss RTP in the context of conversational voice and video \nsystems.\nAnother distinguishing property of UDP streaming is that", "doc_id": "adc4d74d-abf5-4858-8979-fdbfeba0d78b", "embedding": null, "doc_hash": "4feed2209ac2653e98117e8956748249e693d9cd54f61d0ccf6159e013e7a1c5", "extra_info": null, "node_info": {"start": 2096965, "end": 2100761}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "c4168a08-c15d-4a39-9bf3-5709f4533adf", "3": "b59bd784-c77c-460e-9624-d005b276b338"}}, "__type__": "1"}, "b59bd784-c77c-460e-9624-d005b276b338": {"__data__": {"text": "learned in Chapter 3, because UDP does \nnot employ a congestion-control mechanism, the server can push packets into the \nnetwork at the consumption rate of the video without the rate-control restrictions of \nTCP. UDP streaming typically uses a small client-side buffer, big enough to hold less \nthan a second of video.\nBefore passing the video chunks to UDP, the server will encapsulate the \nvideo chunks within transport packets specially designed for transporting audio \nand video, using the Real-Time Transport Protocol (RTP) [RFC 3550] or a simi -\nlar (possibly proprietary) scheme. We delay our coverage of RTP until Section \n9.3, where we discuss RTP in the context of conversational voice and video \nsystems.\nAnother distinguishing property of UDP streaming is that in addition to the \nserver-to-client video stream, the client and server also maintain, in parallel, \na separate control connection over which the client sends commands regard -\ning session state changes (such as pause, resume, reposition, and so on). The \nReal-Time Streaming Protocol (RTSP) [RFC 2326], explained in some detail \nin the Web site for this textbook, is a popular open protocol for such a control \nconnection.\nAlthough UDP streaming has been employed in many open-source systems and \nproprietary products, it suffers from three significant drawbacks. First, due to the \nunpredictable and varying amount of available bandwidth between server and client, \nconstant-rate UDP streaming can fail to provide continuous playout. For example, \nconsider the scenario where the video consumption rate is 1 Mbps and the server-to-\nclient available bandwidth is usually more than 1 Mbps, but every few minutes the \navailable bandwidth drops below 1 Mbps for several seconds. In such a scenario, a \nUDP streaming system that transmits video at a constant rate of 1 Mbps over RTP/\nUDP would likely provide a poor user experience, with freezing or skipped frames \nsoon after the available bandwidth falls below 1 Mbps. The second drawback of \nUDP streaming is that it requires a media control server, such as an RTSP server, to \nprocess client-to-server interactivity requests and to track client state (e.g., the cli -\nent\u2019s playout point in the video, whether the video is being paused or played, and so \non) for each  ongoing client session. This increases the overall cost and complexity of \ndeploying a large-scale video-on-demand system. The third drawback is that many \nfirewalls are configured to block UDP traffic, preventing the users behind these fire -\nwalls from receiving UDP video.\n712     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\n9.2.2  HTTP Streaming\nIn HTTP streaming, the video is simply stored in an HTTP server as an ordinary \nfile with a specific URL. When a user wants to see the video, the client establishes \na TCP connection with the server and issues an HTTP GET request for that URL. \nThe server then sends the video file, within an HTTP response message, as quickly \nas possible, that is, as quickly as TCP congestion control and flow control will allow. \nOn the client side, the bytes are collected in a client application buffer. Once the \nnumber of bytes in this buffer exceeds a predetermined threshold, the client applica -\ntion begins playback\u2014specifically, it periodically grabs video frames from the client \napplication buffer, decompresses the frames, and displays them on the user\u2019s screen.\nWe learned in Chapter 3 that when transferring a file over TCP, the server-\nto-client transmission rate can vary significantly due to TCP\u2019s congestion control \nmechanism. In particular, it is not uncommon for the transmission rate to vary in a \n\u201csaw-tooth\u201d manner associated with TCP congestion control. Furthermore, packets \ncan also be significantly delayed due to TCP\u2019s retransmission mechanism. Because \nof these characteristics of TCP, the conventional wisdom in the 1990s was that \nvideo streaming would never work well over TCP. Over time,", "doc_id": "b59bd784-c77c-460e-9624-d005b276b338", "embedding": null, "doc_hash": "3cea645c777d70c39a9a81d158f7561ae027a8b3cd4061514340f41336a3c56b", "extra_info": null, "node_info": {"start": 2100784, "end": 2104731}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "adc4d74d-abf5-4858-8979-fdbfeba0d78b", "3": "a3b81293-26f7-4fa6-b408-59a420c9c864"}}, "__type__": "1"}, "a3b81293-26f7-4fa6-b408-59a420c9c864": {"__data__": {"text": "threshold, the client applica -\ntion begins playback\u2014specifically, it periodically grabs video frames from the client \napplication buffer, decompresses the frames, and displays them on the user\u2019s screen.\nWe learned in Chapter 3 that when transferring a file over TCP, the server-\nto-client transmission rate can vary significantly due to TCP\u2019s congestion control \nmechanism. In particular, it is not uncommon for the transmission rate to vary in a \n\u201csaw-tooth\u201d manner associated with TCP congestion control. Furthermore, packets \ncan also be significantly delayed due to TCP\u2019s retransmission mechanism. Because \nof these characteristics of TCP, the conventional wisdom in the 1990s was that \nvideo streaming would never work well over TCP. Over time, however, designers \nof streaming video systems learned that TCP\u2019s congestion control and reliable-data \ntransfer mechanisms do not necessarily preclude continuous playout when client \nbuffering and prefetching (discussed in the next section) are used.\nThe use of HTTP over TCP also allows the video to traverse firewalls and NATs \nmore easily (which are often configured to block most UDP traffic but to allow \nmost HTTP traffic). Streaming over HTTP also obviates the need for a media con -\ntrol server, such as an RTSP server, reducing the cost of a large-scale deployment \nover the Internet. Due to all of these advantages, most video streaming applications \ntoday\u2014including YouTube and Netflix\u2014use HTTP streaming (over TCP) as its \nunderlying streaming protocol.\nPrefetching Video\nAs we just learned, client-side buffering can be used to mitigate the effects of vary -\ning end-to-end delays and varying available bandwidth. In our earlier example in \nFigure 9. 1, the server transmits video at the rate at which the video is to be played \nout. However, for streaming stored  video, the client can attempt to download the \nvideo at a rate higher  than the consumption rate, thereby prefetching  video frames \nthat are to be consumed in the future. This prefetched video is naturally stored in \nthe client application buffer. Such prefetching occurs naturally with TCP streaming, \nsince TCP\u2019s congestion avoidance mechanism will attempt to use all of the available \nbandwidth between server and client.\nTo gain some insight into prefetching, let\u2019s take a look at a simple example. Sup -\npose the video consumption rate is 1 Mbps but the network is capable of delivering \nthe video from server to client at a constant rate of 1.5 Mbps. Then the client will \n9.2  \u2022  STREAMING STORED VIDEO      713\nnot only be able to play out the video with a very small playout delay, but will also \nbe able to increase the amount of buffered video data by 500 Kbits every second. \nIn this manner, if in the future the client receives data at a rate of less than 1 Mbps \nfor a brief period of time, the client will be able to continue to provide continuous \nplayback due to the reserve in its buffer. [Wang 2008] shows that when the average \nTCP throughput is roughly twice the media bit rate, streaming over TCP results in \nminimal starvation and low buffering delays.\nClient Application Buffer and TCP Buffers\nFigure 9. 2 illustrates the interaction between client and server for HTTP streaming. \nAt the server side, the portion of the video file in white has already been sent into the \nserver\u2019s socket, while the darkened portion is what remains to be sent. After \u201cpass -\ning through the socket door,\u201d the bytes are placed in the TCP send buffer before \nbeing transmitted into the Internet, as described in Chapter 3. In Figure 9.2, because \nthe TCP send buffer at the server side is shown to be full, the server is momentarily \nprevented from sending more bytes from the video file into the socket. On the client \nside, the client application (media player) reads bytes from the TCP receive buffer \n(through its client socket) and places the bytes into the client application buffer. At \nthe same time, the client application periodically grabs", "doc_id": "a3b81293-26f7-4fa6-b408-59a420c9c864", "embedding": null, "doc_hash": "6632fed2e86c494e910997cc821cfc53c22af54b235d18f44ec22632dbfd377b", "extra_info": null, "node_info": {"start": 2104744, "end": 2108730}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "b59bd784-c77c-460e-9624-d005b276b338", "3": "9e2c5494-0288-46e8-bd0a-00fbf6f284d4"}}, "__type__": "1"}, "9e2c5494-0288-46e8-bd0a-00fbf6f284d4": {"__data__": {"text": "Buffers\nFigure 9. 2 illustrates the interaction between client and server for HTTP streaming. \nAt the server side, the portion of the video file in white has already been sent into the \nserver\u2019s socket, while the darkened portion is what remains to be sent. After \u201cpass -\ning through the socket door,\u201d the bytes are placed in the TCP send buffer before \nbeing transmitted into the Internet, as described in Chapter 3. In Figure 9.2, because \nthe TCP send buffer at the server side is shown to be full, the server is momentarily \nprevented from sending more bytes from the video file into the socket. On the client \nside, the client application (media player) reads bytes from the TCP receive buffer \n(through its client socket) and places the bytes into the client application buffer. At \nthe same time, the client application periodically grabs video frames from the client \napplication buffer, decompresses the frames, and displays them on the user\u2019s screen. \nNote that if the client application buffer is larger than the video file, then the whole \nprocess of moving bytes from the server\u2019s storage to the client\u2019s application buffer \nis equivalent to an ordinary file download over HTTP\u2014the client simply pulls the \nvideo off the server as fast as TCP will allow!\nVideo \ufb01le\nWeb serverClientTCP send\nbufferTCP receive\nbufferTCP application\nbufferFrames read\nout periodically\nfrom buffer,\ndecompressed,\nand displayed\non screen\nFigure 9.2  \u2666 Streaming stored video over HTTP/TCP\n714     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\nConsider now what happens when the user pauses the video during the stream -\ning process. During the pause period, bits are not removed from the client application \nbuffer, even though bits continue to enter the buffer from the server. If the client \napplication buffer is finite, it may eventually become full, which will cause \u201cback \npressure\u201d all the way back to the server. Specifically, once the client application \nbuffer becomes full, bytes can no longer be removed from the client TCP receive \nbuffer, so it too becomes full. Once the client receive TCP buffer becomes full, bytes \ncan no longer be removed from the server TCP send buffer, so it also becomes full. \nOnce the TCP becomes full, the server cannot send any more bytes into the socket. \nThus, if the user pauses the video, the server may be forced to stop transmitting, in \nwhich case the server will be blocked until the user resumes the video.\nIn fact, even during regular playback (that is, without pausing), if the client \napplication buffer becomes full, back pressure will cause the TCP buffers to become \nfull, which will force the server to reduce its rate. To determine the resulting rate, \nnote that when the client application removes f bits, it creates room for f bits in the \nclient application buffer, which in turn allows the server to send f additional bits. \nThus, the server send rate can be no higher than the video consumption rate at the \nclient. Therefore, a full client application buffer indirectly imposes a limit on the rate \nthat video can be sent from server to client when streaming over HTTP.\nAnalysis of Video Streaming\nSome simple modeling will provide more insight into initial playout delay and freez -\ning due to application buffer depletion. As shown in Figure 9.3, let B denote the size \nFill rate = x Depletion rate = r\nVideo\nserverInternetQB\nClient application buffer\nFigure 9.3  \u2666 Analysis of client-side buffering for video streaming\n9.2  \u2022  STREAMING STORED VIDEO      715\n(in bits) of the client\u2019s application buffer, and let Q denote the number of bits that \nmust be buffered before the client application begins playout. (Of course, Q6B.) \nLet r denote the video consumption rate\u2014the rate at which the client draws bits out \nof the client application buffer during playback. So, for example, if the video\u2019s frame \nrate is 30 frames/sec, and each (compressed) frame is 100,000 bits, then r=3 Mbps. \nTo see the forest through the trees, we\u2019ll ignore TCP\u2019s send and receive buffers.\nLet\u2019s assume", "doc_id": "9e2c5494-0288-46e8-bd0a-00fbf6f284d4", "embedding": null, "doc_hash": "d61431e451ecf51ccc5dd403eb5d6eac97277ee797f97aed8084f2a95dde1a5f", "extra_info": null, "node_info": {"start": 2108669, "end": 2112703}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "a3b81293-26f7-4fa6-b408-59a420c9c864", "3": "63ec6552-6b0f-4827-988f-6b8472fe3720"}}, "__type__": "1"}, "63ec6552-6b0f-4827-988f-6b8472fe3720": {"__data__": {"text": "= r\nVideo\nserverInternetQB\nClient application buffer\nFigure 9.3  \u2666 Analysis of client-side buffering for video streaming\n9.2  \u2022  STREAMING STORED VIDEO      715\n(in bits) of the client\u2019s application buffer, and let Q denote the number of bits that \nmust be buffered before the client application begins playout. (Of course, Q6B.) \nLet r denote the video consumption rate\u2014the rate at which the client draws bits out \nof the client application buffer during playback. So, for example, if the video\u2019s frame \nrate is 30 frames/sec, and each (compressed) frame is 100,000 bits, then r=3 Mbps. \nTo see the forest through the trees, we\u2019ll ignore TCP\u2019s send and receive buffers.\nLet\u2019s assume that the server sends bits at a constant rate x whenever the client \nbuffer is not full. (This is a gross simplification, since TCP\u2019s send rate varies due \nto congestion control; we\u2019ll examine more realistic time-dependent rates x  (t) in the \nproblems at the end of this chapter.) Suppose at time t=0, the application buffer is \nempty and video begins arriving to the client application buffer. We now ask at what \ntime t=tp does playout begin? And while we are at it, at what time t=tf does the \nclient application buffer become full?\nFirst, let\u2019s determine tp, the time when Q bits have entered the application buffer \nand playout begins. Recall that bits arrive to the client application buffer at rate x and \nno bits are removed from this buffer before playout begins. Thus, the amount of time \nrequired to build up Q bits (the initial buffering delay) is tp=Q/x.\nNow let\u2019s determine tf, the point in time when the client application buffer \nbecomes full. We first observe that if x6r (that is, if the server send rate is less than \nthe video consumption rate), then the client buffer will never become full! Indeed, \nstarting at time tp, the buffer will be depleted at rate r and will only be filled at rate \nx6r. Eventually the client buffer will empty out entirely, at which time the video \nwill freeze on the screen while the client buffer waits another tp seconds to build up \nQ bits of video. Thus, when the available rate in the network is less than the video \nrate, playout will alternate between periods of continuous playout and periods of \nfreezing.  In a homework problem, you will be asked to determine the length of each \ncontinuous playout and freezing period as a function of Q, r, and x. Now let\u2019s deter-\nmine tf for when x7r. In this case, starting at time tp, the buffer increases from Q \nto B at rate x-r since bits are being depleted at rate r but are arriving at rate x, as \nshown in Figure 9.3. Given these hints, you will be asked in a homework problem \nto determine tf, the time the client buffer becomes full. Note that when the available \nrate in the network is more than the video rate, after the initial buffering delay, the \nuser will enjoy continuous playout until the video ends.\nEarly Termination and Repositioning the Video\nHTTP streaming systems often make use of the HTTP byte-range header  in the \nHTTP GET request message, which specifies the specific range of bytes the client \ncurrently wants to retrieve from the desired video. This is particularly useful when the \nuser wants to reposition (that is, jump) to a future point in time in the video. When the \nuser repositions to a new position, the client sends a new HTTP request, indicating with \nthe byte-range header from which byte in the file should the server send data. When \nthe server receives the new HTTP request, it can forget about any earlier request and \ninstead send bytes beginning with the byte indicated in the byte-range request.\n716     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\nWhile we are on the subject of repositioning, we briefly mention that when a \nuser repositions to a future point in the video or terminates the video early, some", "doc_id": "63ec6552-6b0f-4827-988f-6b8472fe3720", "embedding": null, "doc_hash": "78a1bcf146d42ea8ed5ea346d21dcc1f28c74141838b6f26e9d3bfedd308b5a8", "extra_info": null, "node_info": {"start": 2112836, "end": 2116673}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "9e2c5494-0288-46e8-bd0a-00fbf6f284d4", "3": "119cd445-7e55-4312-baea-15c06513b721"}}, "__type__": "1"}, "119cd445-7e55-4312-baea-15c06513b721": {"__data__": {"text": "the specific range of bytes the client \ncurrently wants to retrieve from the desired video. This is particularly useful when the \nuser wants to reposition (that is, jump) to a future point in time in the video. When the \nuser repositions to a new position, the client sends a new HTTP request, indicating with \nthe byte-range header from which byte in the file should the server send data. When \nthe server receives the new HTTP request, it can forget about any earlier request and \ninstead send bytes beginning with the byte indicated in the byte-range request.\n716     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\nWhile we are on the subject of repositioning, we briefly mention that when a \nuser repositions to a future point in the video or terminates the video early, some \nprefetched-but-not-yet-viewed data transmitted by the server will go unwatched\u2014\na waste of network bandwidth and server resources. For example, suppose that \nthe client buffer is full with B bits at some time t0 into the video, and at this time \nthe user repositions to some instant t7t0+B/r into the video, and then watches  \nthe video to completion from that point on. In this case, all B bits in the buffer will be \nunwatched and the bandwidth and server resources that were used to transmit those \nB bits have been completely wasted. There is significant wasted bandwidth in the \nInternet due to early termination, which can be quite costly, particularly for wireless \nlinks [Ihm 2011]. For this reason, many streaming systems use only a moderate-size \nclient application buffer, or will limit the amount of prefetched video using the byte-\nrange header in HTTP requests [Rao 2011].\nRepositioning and early termination are analogous to cooking a large meal, eat -\ning only a portion of it, and throwing the rest away, thereby wasting food. So the next \ntime your parents criticize you for wasting food by not eating all your dinner, you can \nquickly retort by saying they are wasting bandwidth and server resources when they \nreposition while watching movies over the Internet! But, of course, two wrongs do \nnot make a right\u2014both food and bandwidth are not to be wasted!\nIn Sections 9.2.1 and 9.2.2, we covered UDP streaming and HTTP streaming, \nrespectively. A third type of streaming is Dynamic Adaptive Streaming over HTTP \n(DASH), which uses multiple versions of the video, each compressed at a different \nrate. DASH is discussed in detail in Section 2.6.2 . CDNs are often used to distribute \nstored and live video. CDNs are discussed in detail in Section 2.6.3.\n9.3 Voice-over-IP\nReal-time conversational voice over the Internet is often referred to as Internet \ntelephony , since, from the user\u2019s perspective, it is similar to the traditional circuit-\nswitched telephone service. It is also commonly called Voice-over-IP (VoIP) . In \nthis section we describe the principles and protocols underlying VoIP. Conversa -\ntional video is similar in many respects to VoIP, except that it includes the video \nof the participants as well as their voices. To keep the discussion focused and \nconcrete, we focus here only on voice in this section rather than combined voice \nand video.\n9.3.1  Limitations of the Best-Effort IP Service\nThe Internet\u2019s network-layer protocol, IP, provides best-effort service. That is to say \nthe service makes its best effort to move each datagram from source to destination \nas quickly as possible but makes no promises whatsoever about getting the packet \n9.3  \u2022  VOICE-OVER-IP      717\nto the destination within some delay bound or about a limit on the percentage of \npackets lost. The lack of such guarantees poses significant challenges to the design \nof real-time conversational applications, which are acutely sensitive to packet delay, \njitter, and loss.\nIn this section, we\u2019ll cover several ways in which the performance of VoIP over \na best-effort network can be enhanced. Our focus will be on", "doc_id": "119cd445-7e55-4312-baea-15c06513b721", "embedding": null, "doc_hash": "4c7f69b0d855b27e011037b6fd3311d7900977a3fc1884263f59dbc9612bab0c", "extra_info": null, "node_info": {"start": 2116609, "end": 2120518}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "63ec6552-6b0f-4827-988f-6b8472fe3720", "3": "65e9971a-8b07-4428-9175-6ddfc2538008"}}, "__type__": "1"}, "65e9971a-8b07-4428-9175-6ddfc2538008": {"__data__": {"text": "Limitations of the Best-Effort IP Service\nThe Internet\u2019s network-layer protocol, IP, provides best-effort service. That is to say \nthe service makes its best effort to move each datagram from source to destination \nas quickly as possible but makes no promises whatsoever about getting the packet \n9.3  \u2022  VOICE-OVER-IP      717\nto the destination within some delay bound or about a limit on the percentage of \npackets lost. The lack of such guarantees poses significant challenges to the design \nof real-time conversational applications, which are acutely sensitive to packet delay, \njitter, and loss.\nIn this section, we\u2019ll cover several ways in which the performance of VoIP over \na best-effort network can be enhanced. Our focus will be on application-layer tech -\nniques, that is, approaches that do not require any changes in the network core or \neven in the transport layer at the end hosts. To keep the discussion concrete, we\u2019ll \ndiscuss the limitations of best-effort IP service in the context of a specific VoIP \nexample. The sender generates bytes at a rate of 8,000 bytes per second; every  \n20 msecs the sender gathers these bytes into a chunk. A chunk and a special header \n(discussed below) are encapsulated in a UDP segment, via a call to the socket interface. \nThus, the number of bytes in a chunk is (20 msecs) #(8,000 bytes/sec) =160 bytes,  \nand a UDP segment is sent every 20 msecs.\nIf each packet makes it to the receiver with a constant end-to-end delay, then \npackets arrive at the receiver periodically every 20 msecs. In these ideal conditions, \nthe receiver can simply play back each chunk as soon as it arrives. But unfortunately, \nsome packets can be lost and most packets will not have the same end-to-end delay, \neven in a lightly congested Internet. For this reason, the receiver must take more care \nin determining (1) when to play back a chunk, and (2) what to do with a missing chunk.\nPacket Loss\nConsider one of the UDP segments generated by our VoIP application. The UDP \nsegment is encapsulated in an IP datagram. As the datagram wanders through the \nnetwork, it passes through router buffers (that is, queues) while waiting for transmis -\nsion on outbound links. It is possible that one or more of the buffers in the path from \nsender to receiver is full, in which case the arriving IP datagram may be discarded, \nnever to arrive at the receiving application.\nLoss could be eliminated by sending the packets over TCP (which provides for \nreliable data transfer) rather than over UDP. However, retransmission mechanisms \nare often considered unacceptable for conversational real-time audio applications \nsuch as VoIP, because they increase end-to-end delay [Bolot 1996]. Furthermore, \ndue to TCP congestion control, packet loss may result in a reduction of the TCP \nsender\u2019s transmission rate to a rate that is lower than the receiver\u2019s drain rate, possi -\nbly leading to buffer starvation. This can have a severe impact on voice intelligibility \nat the receiver. For these reasons, most existing VoIP applications run over UDP by \ndefault. [Baset 2006] reports that UDP is used by Skype unless a user is behind a \nNAT or firewall that blocks UDP segments (in which case TCP is used).\nBut losing packets is not necessarily as disastrous as one might think. Indeed, \npacket loss rates between 1 and 20 percent can be tolerated, depending on how voice \nis encoded and transmitted, and on how the loss is concealed at the receiver. For \nexample, forward error correction (FEC) can help conceal packet loss. We\u2019ll see \n718     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\nbelow that with FEC, redundant information is transmitted along with the original \ninformation so that some of the lost", "doc_id": "65e9971a-8b07-4428-9175-6ddfc2538008", "embedding": null, "doc_hash": "5efe59e43eaca46344157f4910d2c47e76e897144efdf56968d99466c9dcf9dd", "extra_info": null, "node_info": {"start": 2120534, "end": 2124253}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "119cd445-7e55-4312-baea-15c06513b721", "3": "91842ecb-62b1-458e-8fbd-6e5343ffa2fb"}}, "__type__": "1"}, "91842ecb-62b1-458e-8fbd-6e5343ffa2fb": {"__data__": {"text": "For these reasons, most existing VoIP applications run over UDP by \ndefault. [Baset 2006] reports that UDP is used by Skype unless a user is behind a \nNAT or firewall that blocks UDP segments (in which case TCP is used).\nBut losing packets is not necessarily as disastrous as one might think. Indeed, \npacket loss rates between 1 and 20 percent can be tolerated, depending on how voice \nis encoded and transmitted, and on how the loss is concealed at the receiver. For \nexample, forward error correction (FEC) can help conceal packet loss. We\u2019ll see \n718     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\nbelow that with FEC, redundant information is transmitted along with the original \ninformation so that some of the lost original data can be recovered from the redundant \ninformation. Nevertheless, if one or more of the links between sender and receiver is \nseverely congested, and packet loss exceeds 10 to 20 percent (for example, on a wire -\nless link), then there is really nothing that can be done to achieve acceptable audio \nquality. Clearly, best-effort service has its limitations.\nEnd-to-End Delay\nEnd-to-end delay  is the accumulation of transmission, processing, and queuing \ndelays in routers; propagation delays in links; and end-system processing delays. \nFor real-time conversational applications, such as VoIP, end-to-end delays smaller \nthan 150 msecs are not perceived by a human listener; delays between 150 and 400 \nmsecs can be acceptable but are not ideal; and delays exceeding 400 msecs can seri -\nously hinder the interactivity in voice conversations. The receiving side of a VoIP \napplication will typically disregard any packets that are delayed more than a certain \nthreshold, for example, more than 400 msecs. Thus, packets that are delayed by more \nthan the threshold are effectively lost.\nPacket Jitter\nA crucial component of end-to-end delay is the varying queuing delays that a packet \nexperiences in the network\u2019s routers. Because of these varying delays, the time from \nwhen a packet is generated at the source until it is received at the receiver can fluc -\ntuate from packet to packet, as shown in Figure 9.1. This phenomenon is called \njitter . As an example, consider two consecutive packets in our VoIP application. \nThe sender sends the second packet 20 msecs after sending the first packet. But at \nthe receiver, the spacing between these packets can become greater than 20 msecs. \nTo see this, suppose the first packet arrives at a nearly empty queue at a router, but \njust before the second packet arrives at the queue a large number of packets from \nother sources arrive at the same queue. Because the first packet experiences a small \nqueuing delay and the second packet suffers a large queuing delay at this router, \nthe first and second packets become spaced by more than 20 msecs. The spacing \nbetween consecutive packets can also become less than 20 msecs. To see this, again \nconsider two consecutive packets. Suppose the first packet joins the end of a queue \nwith a large number of packets, and the second packet arrives at the queue before \nthis first packet is transmitted and before any packets from other sources arrive at \nthe queue. In this case, our two packets find themselves one right after the other in \nthe queue. If the time it takes to transmit a packet on the router\u2019s outbound link is \nless than 20 msecs, then the spacing between first and second packets becomes less \nthan 20 msecs.\nThe situation is analogous to driving cars on roads. Suppose you and your friend \nare each driving in your own cars from San Diego to Phoenix. Suppose you and your \n9.3  \u2022  VOICE-OVER-IP      719\nfriend have similar driving styles, and that you both drive at 100 km/hour, traffic \npermitting. If your friend starts out one hour before you, depending", "doc_id": "91842ecb-62b1-458e-8fbd-6e5343ffa2fb", "embedding": null, "doc_hash": "9412fae63eac8637f2a22d70a4b975cfa3e4b1207fc4bf5640658e69da93c7b6", "extra_info": null, "node_info": {"start": 2124282, "end": 2128083}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "65e9971a-8b07-4428-9175-6ddfc2538008", "3": "9cc4102e-d43d-4a8c-8038-063c92303fb2"}}, "__type__": "1"}, "9cc4102e-d43d-4a8c-8038-063c92303fb2": {"__data__": {"text": "arrives at the queue before \nthis first packet is transmitted and before any packets from other sources arrive at \nthe queue. In this case, our two packets find themselves one right after the other in \nthe queue. If the time it takes to transmit a packet on the router\u2019s outbound link is \nless than 20 msecs, then the spacing between first and second packets becomes less \nthan 20 msecs.\nThe situation is analogous to driving cars on roads. Suppose you and your friend \nare each driving in your own cars from San Diego to Phoenix. Suppose you and your \n9.3  \u2022  VOICE-OVER-IP      719\nfriend have similar driving styles, and that you both drive at 100 km/hour, traffic \npermitting. If your friend starts out one hour before you, depending on intervening \ntraffic, you may arrive at Phoenix more or less than one hour after your friend.\nIf the receiver ignores the presence of jitter and plays out chunks as soon as \nthey arrive, then the resulting audio quality can easily become unintelligible at the \nreceiver. Fortunately, jitter can often be removed by using sequence numbers , \ntimestamps , and a playout delay , as discussed below.\n9.3.2  Removing Jitter at the Receiver for Audio\nFor our VoIP application, where packets are being generated periodically, the \nreceiver should attempt to provide periodic playout of voice chunks in the presence \nof random network jitter. This is typically done by combining the following two \nmechanisms:\n\u2022 Prepending each chunk with a  timestamp . The sender stamps each chunk with the \ntime at which the chunk was generated.\n\u2022 Delaying playout  of chunks at the receiver . As we saw in our earlier discussion of \nFigure 9. 1, the playout delay of the received audio chunks must be long enough \nso that most of the packets are received before their scheduled playout times. This \nplayout delay can either be fixed throughout the duration of the audio session or \nvary adaptively during the audio session lifetime.\nWe now discuss how these three mechanisms, when combined, can alleviate or even \neliminate the effects of jitter. We examine two playback strategies: fixed playout \ndelay and adaptive playout delay.\nFixed Playout Delay\nWith the fixed-delay strategy, the receiver attempts to play out each chunk exactly q \nmsecs after the chunk is generated. So if a chunk is timestamped at the sender at time \nt, the receiver plays out the chunk at time t+q, assuming the chunk has arrived by \nthat time. Packets that arrive after their scheduled playout times are discarded and \nconsidered lost.\nWhat is a good choice for q? VoIP can support delays up to about 400 msecs, \nalthough a more satisfying conversational experience is achieved with smaller val -\nues of q. On the other hand, if q is made much smaller than 400 msecs, then many \npackets may miss their scheduled playback times due to the network-induced packet \njitter. Roughly speaking, if large variations in end-to-end delay are typical, it is pref -\nerable to use a large q; on the other hand, if delay is small and variations in delay are \nalso small, it is preferable to use a small q, perhaps less than 150 msecs.\nThe trade-off between the playback delay and packet loss is illustrated in  \nFigure 9. 4. The figure shows the times at which packets are generated and played \n720     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\nout for a single talk spurt. Two distinct initial playout delays are considered. As \nshown by the leftmost staircase, the sender generates packets at regular intervals\u2014\nsay, every 20 msecs. The first packet in this talk spurt is received at time r. As shown \nin the figure, the arrivals of subsequent packets are not evenly spaced due to the \nnetwork jitter.\nFor the first playout schedule, the fixed initial playout delay is set to p-r. \nWith this schedule, the fourth", "doc_id": "9cc4102e-d43d-4a8c-8038-063c92303fb2", "embedding": null, "doc_hash": "44e3a83c36bf973b6b93eed5d7c08cc3b572f1f756b70b83be800e661ca6ada1", "extra_info": null, "node_info": {"start": 2128074, "end": 2131869}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "91842ecb-62b1-458e-8fbd-6e5343ffa2fb", "3": "3a2ff404-3f12-4ad8-a13c-33a82e2d98df"}}, "__type__": "1"}, "3a2ff404-3f12-4ad8-a13c-33a82e2d98df": {"__data__": {"text": "perhaps less than 150 msecs.\nThe trade-off between the playback delay and packet loss is illustrated in  \nFigure 9. 4. The figure shows the times at which packets are generated and played \n720     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\nout for a single talk spurt. Two distinct initial playout delays are considered. As \nshown by the leftmost staircase, the sender generates packets at regular intervals\u2014\nsay, every 20 msecs. The first packet in this talk spurt is received at time r. As shown \nin the figure, the arrivals of subsequent packets are not evenly spaced due to the \nnetwork jitter.\nFor the first playout schedule, the fixed initial playout delay is set to p-r. \nWith this schedule, the fourth packet does not arrive by its scheduled playout time, \nand the receiver considers it lost. For the second playout schedule, the fixed initial \nplayout delay is set to p\u2032-r. For this schedule, all packets arrive before their sched -\nuled playout times, and there is therefore no loss.\nAdaptive Playout Delay\nThe previous example demonstrates an important delay-loss trade-off that arises \nwhen designing a playout strategy with fixed playout delays. By making the initial \nplayout delay large, most packets will make their deadlines and there will therefore \nbe negligible loss; however, for conversational services such as VoIP, long delays \ncan become bothersome if not intolerable. Ideally, we would like the playout delay to \nbe minimized subject to the constraint that the loss be below a few percent.\nThe natural way to deal with this trade-off is to estimate the network delay and \nthe variance of the network delay, and to adjust the playout delay accordingly at the \nbeginning of each talk spurt. This adaptive adjustment of playout delays at the begin -\nning of the talk spurts will cause the sender\u2019s silent periods to be compressed and \nelongated; however, compression and elongation of silence by a small amount is not \nnoticeable in speech.Packets\ngenerated\nTimePackets\nrp p'Playout\nschedule\np\u2013r\nPlayout\nschedule\np'\u2013r\nPackets\nreceivedMissed\nplayout\nFigure 9.4  \u2666 Packet loss for different fixed playout delays\n9.3  \u2022  VOICE-OVER-IP      721\nFollowing [Ramjee 1994], we now describe a generic algorithm that the receiver \ncan use to adaptively adjust its playout delays. To this end, let\nti= the timestamp of the ith packet =the time the packet was generated by \nthe sender\nri=the time packet i is received by receiver\npi=the time packet i is played at receiver\nThe end-to-end network delay of the ith packet is ri-ti. Due to network jitter, \nthis delay will vary from packet to packet. Let di denote an estimate of the average  \nnetwork delay upon reception of the ith packet. This estimate is constructed from the \ntimestamps as follows:\ndi=(1-u) di-1+u (ri-ti)\nwhere u is a fixed constant (for example, u=0.01). Thus di is a smoothed average \nof the observed network delays r1-t1, . . . , ri-ti. The estimate places more weight \non the recently observed network delays than on the observed network delays of the \ndistant past. This form of estimate should not be completely unfamiliar; a similar \nidea is used to estimate round-trip times in TCP, as discussed in Chapter 3. Let vi \ndenote an estimate of the average deviation of the delay from the estimated average \ndelay. This estimate is also constructed from the timestamps:\nvi=(1-u) vi-1+u \u2219ri-ti-di\u2219\nThe estimates di and vi are calculated for every packet received, although they are \nused only to determine the playout point for the first packet in any talk spurt.\nOnce having calculated these estimates, the receiver employs the following \nalgorithm for the playout", "doc_id": "3a2ff404-3f12-4ad8-a13c-33a82e2d98df", "embedding": null, "doc_hash": "a5e5366f1884d107530e046ad04b5a6454eb59ae026af10574c69bbeb3237233", "extra_info": null, "node_info": {"start": 2131889, "end": 2135533}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "9cc4102e-d43d-4a8c-8038-063c92303fb2", "3": "60b42a54-d6d4-4445-b73c-52d293d29cea"}}, "__type__": "1"}, "60b42a54-d6d4-4445-b73c-52d293d29cea": {"__data__": {"text": ". . . , ri-ti. The estimate places more weight \non the recently observed network delays than on the observed network delays of the \ndistant past. This form of estimate should not be completely unfamiliar; a similar \nidea is used to estimate round-trip times in TCP, as discussed in Chapter 3. Let vi \ndenote an estimate of the average deviation of the delay from the estimated average \ndelay. This estimate is also constructed from the timestamps:\nvi=(1-u) vi-1+u \u2219ri-ti-di\u2219\nThe estimates di and vi are calculated for every packet received, although they are \nused only to determine the playout point for the first packet in any talk spurt.\nOnce having calculated these estimates, the receiver employs the following \nalgorithm for the playout of packets. If packet i is the first packet of a talk spurt, its \nplayout time, pi, is computed as:\npi=ti+di+Kvi\nwhere K is a positive constant (for example, K=4). The purpose of the Kvi term \nis to set the playout time far enough into the future so that only a small frac -\ntion of the arriving packets in the talk spurt will be lost due to late arrivals. The \nplayout point for any subsequent packet in a talk spurt is computed as an offset \nfrom the point in time when the first packet in the talk spurt was played out. In \nparticular, let\nqi=pi-ti\n722     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\nbe the length of time from when the first packet in the talk spurt is generated until it \nis played out. If packet j also belongs to this talk spurt, it is played out at time\npj=tj+qi\nThe algorithm just described makes perfect sense assuming that the receiver can \ntell whether a packet is the first packet in the talk spurt. This can be done by examin -\ning the signal energy in each received packet.\n9.3.3  Recovering from Packet Loss\nWe have discussed in some detail how a VoIP application can deal with packet \njitter. We now briefly describe several schemes that attempt to preserve accept -\nable audio quality in the presence of packet loss. Such schemes are called loss \nrecovery schemes . Here we define packet loss in a broad sense: A packet is lost \neither if it never arrives at the receiver or if it arrives after its scheduled playout \ntime. Our VoIP example will again serve as a context for describing loss recov -\nery schemes.\nAs mentioned at the beginning of this section, retransmitting lost packets may \nnot be feasible in a real-time conversational application such as VoIP. Indeed, \nretransmitting a packet that has missed its playout deadline serves absolutely no \npurpose. And retransmitting a packet that overflowed a router queue cannot normally \nbe accomplished quickly enough. Because of these considerations, VoIP applica -\ntions often use some type of loss anticipation scheme. Two types of loss anticipation \nschemes are forward error correction (FEC) and interleaving .\nForward Error Correction (FEC)\nThe basic idea of FEC is to add redundant information to the original packet \nstream. For the cost of marginally increasing the transmission rate, the redundant \ninformation can be used to reconstruct approximations or exact versions of some of \nthe lost packets. Following [Bolot 1996] and [Perkins 1998], we now outline two \nsimple FEC mechanisms. The first mechanism sends a redundant encoded chunk \nafter every n chunks. The redundant chunk is obtained by exclusive OR-ing the n \noriginal chunks [Shacham 1990]. In this manner if any one packet of the group of \nn+1 packets is lost, the receiver can fully reconstruct the lost packet. But if two \nor more packets in a group are lost, the receiver cannot reconstruct the lost packets. \nBy keeping n+1, the group size, small, a large fraction of the lost packets can \nbe recovered when loss is", "doc_id": "60b42a54-d6d4-4445-b73c-52d293d29cea", "embedding": null, "doc_hash": "fd63e80b2855ecf4046f407b2ea0dc437c7a4b7937ffe5befffdbf567f92ff72", "extra_info": null, "node_info": {"start": 2135496, "end": 2139215}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "3a2ff404-3f12-4ad8-a13c-33a82e2d98df", "3": "682844fb-1ff8-4860-bbe4-8e99554224f6"}}, "__type__": "1"}, "682844fb-1ff8-4860-bbe4-8e99554224f6": {"__data__": {"text": "increasing the transmission rate, the redundant \ninformation can be used to reconstruct approximations or exact versions of some of \nthe lost packets. Following [Bolot 1996] and [Perkins 1998], we now outline two \nsimple FEC mechanisms. The first mechanism sends a redundant encoded chunk \nafter every n chunks. The redundant chunk is obtained by exclusive OR-ing the n \noriginal chunks [Shacham 1990]. In this manner if any one packet of the group of \nn+1 packets is lost, the receiver can fully reconstruct the lost packet. But if two \nor more packets in a group are lost, the receiver cannot reconstruct the lost packets. \nBy keeping n+1, the group size, small, a large fraction of the lost packets can \nbe recovered when loss is not excessive. However, the smaller the group size, the \ngreater the relative increase of the transmission rate. In particular, the transmis -\nsion rate increases by a factor of 1/ n, so that, if n=3, then the transmission rate \nincreases by 33 percent. Furthermore, this simple scheme increases the playout \ndelay, as the receiver must wait to receive the entire group of packets before it can \n9.3  \u2022  VOICE-OVER-IP      723\nbegin playout. For more practical details about how FEC works for multimedia \ntransport see [RFC 5109].\nThe second FEC mechanism is to send a lower-resolution audio stream as the \nredundant information. For example, the sender might create a nominal audio stream \nand a corresponding low-resolution, low-bit rate audio stream. (The nominal stream \ncould be a PCM encoding at 64 kbps, and the lower-quality stream could be a GSM \nencoding at 13 kbps.) The low-bit rate stream is referred to as the redundant stream. \nAs shown in Figure 9.5, the sender constructs the nth packet by taking the nth chunk \nfrom the nominal stream and appending to it the (n-1)st chunk from the redundant \nstream. In this manner, whenever there is nonconsecutive packet loss, the receiver \ncan conceal the loss by playing out the low-bit rate encoded chunk that arrives with \nthe subsequent packet. Of course, low-bit rate chunks give lower quality than the \nnominal chunks. However, a stream of mostly high-quality chunks, occasional low-\nquality chunks, and no missing chunks gives good overall audio quality. Note that in \nthis scheme, the receiver only has to receive two packets before playback, so that the \nincreased playout delay is small. Furthermore, if the low-bit rate encoding is much \nless than the nominal encoding, then the marginal increase in the transmission rate \nwill be small.\nIn order to cope with consecutive loss, we can use a simple variation. Instead of \nappending just the (n-1)st low-bit rate chunk to the nth nominal chunk, the sender \ncan append the (n-1)st and (n-2)nd low-bit rate chunk, or append the (n-1)st \nand (n-3)rd low-bit rate chunk, and so on. By appending more low-bit rate chunks \nto each nominal chunk, the audio quality at the receiver becomes acceptable for a \nwider variety of harsh best-effort environments. On the other hand, the additional \nchunks increase the transmission bandwidth and the playout delay.\n1\n11\n1\n12\n22 2\n33\nloss3 4\n3 4 1 23 4\n4Redundancy\nReceived\nstreamOriginal\nstream\nReconstructed\nstream\nFigure 9.5  \u2666 Piggybacking lower-quality redundant information\n724     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\nInterleaving\nAs an alternative to redundant transmission, a VoIP application can send interleaved \naudio. As shown in Figure 9.6, the sender resequences units of audio data before \ntransmission, so that originally adjacent units are separated by a certain distance in \nthe transmitted stream. Interleaving can", "doc_id": "682844fb-1ff8-4860-bbe4-8e99554224f6", "embedding": null, "doc_hash": "174eb723c9ff5339a80c3a7f1246ba3fd9c5ee1e9cdac5736cfcce07e1fe0727", "extra_info": null, "node_info": {"start": 2139229, "end": 2142846}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "60b42a54-d6d4-4445-b73c-52d293d29cea", "3": "a130d41f-4583-4225-8282-917e62b3ebd6"}}, "__type__": "1"}, "a130d41f-4583-4225-8282-917e62b3ebd6": {"__data__": {"text": "variety of harsh best-effort environments. On the other hand, the additional \nchunks increase the transmission bandwidth and the playout delay.\n1\n11\n1\n12\n22 2\n33\nloss3 4\n3 4 1 23 4\n4Redundancy\nReceived\nstreamOriginal\nstream\nReconstructed\nstream\nFigure 9.5  \u2666 Piggybacking lower-quality redundant information\n724     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\nInterleaving\nAs an alternative to redundant transmission, a VoIP application can send interleaved \naudio. As shown in Figure 9.6, the sender resequences units of audio data before \ntransmission, so that originally adjacent units are separated by a certain distance in \nthe transmitted stream. Interleaving can mitigate the effect of packet losses. If, for \nexample, units are 5 msecs in length and chunks are 20 msecs (that is, four units per \nchunk), then the first chunk could contain units 1, 5, 9, and 13; the second chunk could \ncontain units 2, 6, 10, and 14; and so on. Figure 9.6 shows that the loss of a single \npacket from an interleaved stream results in multiple small gaps in the reconstructed \nstream, as opposed to the single large gap that would occur in a noninterleaved stream.\nInterleaving can significantly improve the perceived quality of an audio stream \n[Perkins 1998]. It also has low overhead. The obvious disadvantage of interleaving \nis that it increases latency. This limits its use for conversational applications such as \nVoIP, although it can perform well for streaming stored audio. A major advantage \nof interleaving is that it does not increase the bandwidth requirements of a stream.\nError Concealment\nError concealment schemes attempt to produce a replacement for a lost packet that \nis similar to the original. As discussed in [Perkins 1998], this is possible since audio \nOriginal\nstream\nInterleaved\nstream\nReceived\nstream\nReconstructed\nstream5913 1\n2 4 1234 1\n5913 12 1014 6\n5 8 65 78 6\n2 1014 loss 671115 3\n10 12 9101112 9\n4 1216 8\n13 16 1413 1516 14\n4 1216 8\nFigure 9.6  \u2666 Sending interleaved audio\n9.3  \u2022  VOICE-OVER-IP      725\nsignals, and in particular speech, exhibit large amounts of short-term self-similarity. \nAs such, these techniques work for relatively small loss rates (less than 15 percent), \nand for small packets (4\u201340 msecs). When the loss length approaches the length of \na phoneme (5\u2013100 msecs) these techniques break down, since whole phonemes may \nbe missed by the listener.\nPerhaps the simplest form of receiver-based recovery is packet repetition. Packet \nrepetition replaces lost packets with copies of the packets that arrived immediately \nbefore the loss. It has low computational complexity and performs reasonably well. \nAnother form of receiver-based recovery is interpolation, which uses audio before \nand after the loss to interpolate a suitable packet to cover the loss. Interpolation per -\nforms somewhat better than packet repetition but is significantly more computation -\nally intensive [Perkins 1998].\n9.3.4  Case Study: VoIP with Skype\nSkype is an immensely popular VoIP application with over 50 million accounts \nactive on a daily basis. In addition to providing host-to-host VoIP service, Skype \noffers host-to-phone services, phone-to-host services, and multi-party host-to-host \nvideo conferencing services. (Here, a host is again any Internet connected IP device, \nincluding PCs, tablets, and smartphones.) Skype was acquired by Microsoft in 2011.\nBecause the Skype protocol is proprietary, and because all Skype\u2019s control and \nmedia packets are encrypted, it is difficult to precisely determine how Skype operates. \nNevertheless, from the Skype Web site and several", "doc_id": "a130d41f-4583-4225-8282-917e62b3ebd6", "embedding": null, "doc_hash": "192a37d1a76027e9a72e47a46f143bf320b62871124e9ac58279fcb1f6b5082a", "extra_info": null, "node_info": {"start": 2142879, "end": 2146484}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "682844fb-1ff8-4860-bbe4-8e99554224f6", "3": "35bdc77c-a0f3-4967-bdea-81d89c02e2c2"}}, "__type__": "1"}, "35bdc77c-a0f3-4967-bdea-81d89c02e2c2": {"__data__": {"text": "is significantly more computation -\nally intensive [Perkins 1998].\n9.3.4  Case Study: VoIP with Skype\nSkype is an immensely popular VoIP application with over 50 million accounts \nactive on a daily basis. In addition to providing host-to-host VoIP service, Skype \noffers host-to-phone services, phone-to-host services, and multi-party host-to-host \nvideo conferencing services. (Here, a host is again any Internet connected IP device, \nincluding PCs, tablets, and smartphones.) Skype was acquired by Microsoft in 2011.\nBecause the Skype protocol is proprietary, and because all Skype\u2019s control and \nmedia packets are encrypted, it is difficult to precisely determine how Skype operates. \nNevertheless, from the Skype Web site and several measurement studies, researchers \nhave learned how Skype generally works [Baset 2006; Guha 2006; Chen 2006; Suh \n2006; Ren 2006; Zhang X 2012]. For both voice and video, the Skype clients have \nat their disposal many different codecs, which are capable of encoding the media at \na wide range of rates and qualities. For example, video rates for Skype have been \nmeasured to be as low as 30 kbps for a low-quality session up to almost 1 Mbps for a \nhigh quality session [Zhang X 2012]. Typically, Skype\u2019s audio quality is better than \nthe \u201cPOTS\u201d (Plain Old Telephone Service) quality provided by the wire-line phone \nsystem. (Skype codecs typically sample voice at 16,000 samples/sec or higher, which \nprovides richer tones than POTS, which samples at 8,000/sec.) By default, Skype \nsends audio and video packets over UDP. However, control packets are sent over \nTCP, and media packets are also sent over TCP when firewalls block UDP streams. \nSkype uses FEC for loss recovery for both voice and video streams sent over UDP. \nThe Skype client also adapts the audio and video streams it sends to current network \nconditions, by changing video quality and FEC overhead [Zhang X 2012].\nSkype uses P2P techniques in a number of innovative ways, nicely illustrating \nhow P2P can be used in applications that go beyond content distribution and file \nsharing. As with instant messaging, host-to-host Internet telephony is inherently P2P \nsince, at the heart of the application, pairs of users (that is, peers) communicate with \neach other in real time. But Skype also employs P2P techniques for two other impor -\ntant functions, namely, for user location and for NAT traversal.\n726     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\nAs shown in Figure 9.7, the peers (hosts) in Skype are organized into a hierar -\nchical overlay network, with each peer classified as a super peer or an ordinary peer. \nSkype maintains an index that maps Skype usernames to current IP addresses (and \nport numbers). This index is distributed over the super peers. When Alice wants to \ncall Bob, her Skype client searches the distributed index to determine Bob\u2019s current \nIP address. Because the Skype protocol is proprietary, it is currently not known how \nthe index mappings are organized across the super peers, although some form of \nDHT organization is very possible.\nP2P techniques are also used in Skype relays , which are useful for establishing \ncalls between hosts in home networks. Many home network configurations provide \naccess to the Internet through NATs, as discussed in Chapter 4. Recall that a NAT \nprevents a host from outside the home network from initiating a connection to a \nhost within the home network. If both Skype callers have NATs, then there is a \nproblem\u2014neither can accept a call initiated by the other, making a call seemingly \nimpossible. The clever use of super peers and relays nicely solves this problem. \nSuppose that when Alice signs in, she is assigned to a non-NATed super peer and \ninitiates a session to that", "doc_id": "35bdc77c-a0f3-4967-bdea-81d89c02e2c2", "embedding": null, "doc_hash": "58f5e64267e035d17a669e679670cb800510e34fdbe26163edbe769d595df87e", "extra_info": null, "node_info": {"start": 2146429, "end": 2150184}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "a130d41f-4583-4225-8282-917e62b3ebd6", "3": "8294a9c7-773b-4ba4-bb0a-3e7e7077355e"}}, "__type__": "1"}, "8294a9c7-773b-4ba4-bb0a-3e7e7077355e": {"__data__": {"text": "mappings are organized across the super peers, although some form of \nDHT organization is very possible.\nP2P techniques are also used in Skype relays , which are useful for establishing \ncalls between hosts in home networks. Many home network configurations provide \naccess to the Internet through NATs, as discussed in Chapter 4. Recall that a NAT \nprevents a host from outside the home network from initiating a connection to a \nhost within the home network. If both Skype callers have NATs, then there is a \nproblem\u2014neither can accept a call initiated by the other, making a call seemingly \nimpossible. The clever use of super peers and relays nicely solves this problem. \nSuppose that when Alice signs in, she is assigned to a non-NATed super peer and \ninitiates a session to that super peer. (Since Alice is initiating the session, her NAT \npermits this session.) This session allows Alice and her super peer to exchange Callee\npeer\nCaller\npeerRelay\npeerSuper\npeerSkypeSkype Skype\nSkype\nSkype\nSkype\nSkype\nSkype\nSkypeSkypeSkype\nSkype\nSkypeSkypeSkype\nSkype\nSkype\nFigure 9.7  \u2666 Skype peers\n9.3  \u2022  VOICE-OVER-IP      727\ncontrol messages. The same happens for Bob when he signs in. Now, when Alice \nwants to call Bob, she informs her super peer, who in turn informs Bob\u2019s super \npeer, who in turn informs Bob of Alice\u2019s incoming call. If Bob accepts the call, the \ntwo super peers select a third non-NATed super peer\u2014the relay peer\u2014whose job \nwill be to relay data between Alice and Bob. Alice\u2019s and Bob\u2019s super peers then \ninstruct Alice and Bob respectively to initiate a session with the relay. As shown in  \nFigure 9. 7, Alice then sends voice packets to the relay over the Alice-to-relay con -\nnection (which was initiated by Alice), and the relay then forwards these packets \nover the relay-to-Bob connection (which was initiated by Bob); packets from Bob \nto Alice flow over these same two relay connections in reverse. And voila! \u2014Bob \nand Alice have an end-to-end connection even though neither can accept a session \noriginating from outside.\nUp to now, our discussion on Skype has focused on calls involving two persons. \nNow let\u2019s examine multi-party audio conference calls. With N72 participants, if \neach user were to send a copy of its audio stream to each of the N-1 other users, \nthen a total of N(N-1) audio streams would need to be sent into the network to \nsupport the audio conference. To reduce this bandwidth usage, Skype employs a \nclever distribution technique. Specifically, each user sends its audio stream to the \nconference initiator. The conference initiator combines the audio streams into one \nstream (basically by adding all the audio signals together) and then sends a copy \nof each combined stream to each of the other N-1 participants. In this manner, \nthe number of streams is reduced to 2(N-1). For ordinary two-person video con -\nversations, Skype routes the call peer-to-peer, unless NAT traversal is required, \nin which case the call is relayed through a non-NATed peer, as described earlier. \nFor a video conference call involving N72 participants, due to the nature of the \nvideo medium, Skype does not combine the call into one stream at one location and \nthen redistribute the stream to all the participants, as it does for voice calls. Instead, \neach participant\u2019s video stream is routed to a server cluster (located in Estonia as of \n2011), which in turn relays to each participant the N-1 streams of the N-1 other \nparticipants [Zhang X 2012]. You may be wondering why each participant sends a \ncopy to a server rather than directly sending a copy of its video stream to each of \nthe other N-1 participants? Indeed, for both approaches, N(N-1) video streams", "doc_id": "8294a9c7-773b-4ba4-bb0a-3e7e7077355e", "embedding": null, "doc_hash": "af9447e45b71ce6fe02a7e8cdb704d62625fe1aa7455cb49a28f263f96c9fb53", "extra_info": null, "node_info": {"start": 2150165, "end": 2153871}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "35bdc77c-a0f3-4967-bdea-81d89c02e2c2", "3": "448150f4-0a3a-4bd1-aacb-e2ed7bcfc1d2"}}, "__type__": "1"}, "448150f4-0a3a-4bd1-aacb-e2ed7bcfc1d2": {"__data__": {"text": "which case the call is relayed through a non-NATed peer, as described earlier. \nFor a video conference call involving N72 participants, due to the nature of the \nvideo medium, Skype does not combine the call into one stream at one location and \nthen redistribute the stream to all the participants, as it does for voice calls. Instead, \neach participant\u2019s video stream is routed to a server cluster (located in Estonia as of \n2011), which in turn relays to each participant the N-1 streams of the N-1 other \nparticipants [Zhang X 2012]. You may be wondering why each participant sends a \ncopy to a server rather than directly sending a copy of its video stream to each of \nthe other N-1 participants? Indeed, for both approaches, N(N-1) video streams \nare being collectively received by the N participants in the conference. The reason \nis, because upstream link bandwidths are significantly lower than downstream link \nbandwidths in most access links, the upstream links may not be able to support the \nN-1 streams with the P2P approach.\nVoIP systems such as Skype, WeChat, and Google Talk introduce new privacy \nconcerns. Specifically, when Alice and Bob communicate over VoIP, Alice can sniff \nBob\u2019s IP address and then use geo-location services [MaxMind 2016; Quova 2016] \nto determine Bob\u2019s current location and ISP (for example, his work or home ISP). In \nfact, with Skype it is possible for Alice to block the transmission of certain packets \nduring call establishment so that she obtains Bob\u2019s current IP address, say every \nhour, without Bob knowing that he is being tracked and without being on Bob\u2019s \n728     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\ncontact list. Furthermore, the IP address discovered from Skype can be correlated \nwith IP addresses found in BitTorrent, so that Alice can determine the files that Bob \nis downloading [LeBlond 2011]. Moreover, it is possible to partially decrypt a Skype \ncall by doing a traffic analysis of the packet sizes in a stream [White 2011].\n9.4 Protocols for Real-Time Conversational \nApplications\nReal-time conversational applications, including VoIP and video conferencing, are \ncompelling and very popular. It is therefore not surprising that standards bodies, such \nas the IETF and ITU, have been busy for many years (and continue to be busy!) at \nhammering out standards for this class of applications. With the appropriate stand -\nards in place for real-time conversational applications, independent companies are \ncreating new products that interoperate with each other. In this section we examine \nRTP and SIP for real-time conversational applications. Both standards are enjoying \nwidespread implementation in industry products.\n9.4.1  RTP\nIn the previous section, we learned that the sender side of a VoIP application appends \nheader fields to the audio chunks before passing them to the transport layer. These \nheader fields include sequence numbers and timestamps. Since most multimedia net -\nworking applications can make use of sequence numbers and timestamps, it is con -\nvenient to have a standardized packet structure that includes fields for audio/video \ndata, sequence number, and timestamp, as well as other potentially useful fields. \nRTP, defined in RFC 3550, is such a standard. RTP can be used for transporting \ncommon formats such as PCM, ACC, and MP3 for sound and MPEG and H.263 \nfor video. It can also be used for transporting proprietary sound and video formats. \nToday, RTP enjoys widespread implementation in many products and research pro -\ntotypes. It is also complementary to other important real-time interactive protocols, \nsuch as SIP.\nIn this section, we provide an introduction to RTP. We also encourage you to \nvisit Henning Schulzrinne\u2019s RTP site [Schulzrinne-RTP 2012], which provides a \nwealth of information on the subject. Also, you may want to visit the RAT site [RAT \n2012], which documents", "doc_id": "448150f4-0a3a-4bd1-aacb-e2ed7bcfc1d2", "embedding": null, "doc_hash": "4b37a89b8b05b513ff5fd2a62589bb8a247adbc84f04b984a2f056918b2a4e55", "extra_info": null, "node_info": {"start": 2153904, "end": 2157794}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "8294a9c7-773b-4ba4-bb0a-3e7e7077355e", "3": "fab0b1aa-3e5c-4ac8-870b-7365313930fd"}}, "__type__": "1"}, "fab0b1aa-3e5c-4ac8-870b-7365313930fd": {"__data__": {"text": "other potentially useful fields. \nRTP, defined in RFC 3550, is such a standard. RTP can be used for transporting \ncommon formats such as PCM, ACC, and MP3 for sound and MPEG and H.263 \nfor video. It can also be used for transporting proprietary sound and video formats. \nToday, RTP enjoys widespread implementation in many products and research pro -\ntotypes. It is also complementary to other important real-time interactive protocols, \nsuch as SIP.\nIn this section, we provide an introduction to RTP. We also encourage you to \nvisit Henning Schulzrinne\u2019s RTP site [Schulzrinne-RTP 2012], which provides a \nwealth of information on the subject. Also, you may want to visit the RAT site [RAT \n2012], which documents VoIP application that uses RTP.\nRTP Basics\nRTP typically runs on top of UDP. The sending side encapsulates a media chunk \nwithin an RTP packet, then encapsulates the packet in a UDP segment, and then \n9.4  \u2022  PROTOCOLS FOR REAL-TIME CONVERSATIONAL APPLICATIONS      729\nhands the segment to IP. The receiving side extracts the RTP packet from the UDP \nsegment, then extracts the media chunk from the RTP packet, and then passes the \nchunk to the media player for decoding and rendering.\nAs an example, consider the use of RTP to transport voice. Suppose the voice \nsource is PCM-encoded (that is, sampled, quantized, and digitized) at 64 kbps. Fur -\nther suppose that the application collects the encoded data in 20-msec chunks, that \nis, 160 bytes in a chunk. The sending side precedes each chunk of the audio data \nwith an RTP header  that includes the type of audio encoding, a sequence number, \nand a timestamp. The RTP header is normally 12 bytes. The audio chunk along with \nthe RTP header form the RTP packet . The RTP packet is then sent into the UDP \nsocket interface. At the receiver side, the application receives the RTP packet from \nits socket interface. The application extracts the audio chunk from the RTP packet \nand uses the header fields of the RTP packet to properly decode and play back the \naudio chunk.\nIf an application incorporates RTP\u2014instead of a proprietary scheme to provide \npayload type, sequence numbers, or timestamps\u2014then the application will more eas -\nily interoperate with other networked multimedia applications. For example, if two \ndifferent companies develop VoIP software and they both incorporate RTP into their \nproduct, there may be some hope that a user using one of the VoIP products will \nbe able to communicate with a user using the other VoIP product. In Section 9.4.2, \nwe\u2019ll see that RTP is often used in conjunction with SIP, an important standard for \nInternet telephony.\nIt should be emphasized that RTP does not provide any mechanism to ensure \ntimely delivery of data or provide other quality-of-service (QoS) guarantees; it \ndoes not even guarantee delivery of packets or prevent out-of-order delivery of \npackets. Indeed, RTP encapsulation is seen only at the end systems. Routers do \nnot distinguish between IP datagrams that carry RTP packets and IP datagrams \nthat don\u2019t.\nRTP allows each source (for example, a camera or a microphone) to be assigned \nits own independent RTP stream of packets. For example, for a video conference \nbetween two participants, four RTP streams could be opened\u2014two streams for \ntransmitting the audio (one in each direction) and two streams for transmitting the \nvideo (again, one in each direction). However, many popular encoding techniques\u2014\nincluding MPEG 1 and MPEG 2\u2014bundle the audio and video into a single stream \nduring the encoding process. When the audio and video are bundled by the encoder, \nthen only one RTP stream is generated in each direction.\nRTP packets are not limited to unicast applications. They can also be sent", "doc_id": "fab0b1aa-3e5c-4ac8-870b-7365313930fd", "embedding": null, "doc_hash": "a6582ffafc65c8be7a4fbc26ff83c39fa3037305d588d2199c79cda875fe8031", "extra_info": null, "node_info": {"start": 2157816, "end": 2161558}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "448150f4-0a3a-4bd1-aacb-e2ed7bcfc1d2", "3": "5335b344-f338-42b4-b287-813dbe0bfcb8"}}, "__type__": "1"}, "5335b344-f338-42b4-b287-813dbe0bfcb8": {"__data__": {"text": "do \nnot distinguish between IP datagrams that carry RTP packets and IP datagrams \nthat don\u2019t.\nRTP allows each source (for example, a camera or a microphone) to be assigned \nits own independent RTP stream of packets. For example, for a video conference \nbetween two participants, four RTP streams could be opened\u2014two streams for \ntransmitting the audio (one in each direction) and two streams for transmitting the \nvideo (again, one in each direction). However, many popular encoding techniques\u2014\nincluding MPEG 1 and MPEG 2\u2014bundle the audio and video into a single stream \nduring the encoding process. When the audio and video are bundled by the encoder, \nthen only one RTP stream is generated in each direction.\nRTP packets are not limited to unicast applications. They can also be sent over \none-to-many and many-to-many multicast trees. For a many-to-many multicast ses -\nsion, all of the session\u2019s senders and sources typically use the same multicast group \nfor sending their RTP streams. RTP multicast streams belonging together, such as \naudio and video streams emanating from multiple senders in a video conference \napplication, belong to an RTP session .\n730     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\nRTP Packet Header Fields\nAs shown in Figure 9.8, the four main RTP packet header fields are the payload type, \nsequence number, timestamp, and source identifier fields.\nThe payload type field in the RTP packet is 7 bits long. For an audio stream, the \npayload type field is used to indicate the type of audio encoding (for example, PCM, \nadaptive delta modulation, linear predictive encoding) that is being used. If a sender \ndecides to change the encoding in the middle of a session, the sender can inform the \nreceiver of the change through this payload type field. The sender may want to change \nthe encoding in order to increase the audio quality or to decrease the RTP stream bit \nrate. Table 9.2 lists some of the audio payload types currently supported by RTP.\nFor a video stream, the payload type is used to indicate the type of video encoding \n(for example, motion JPEG, MPEG 1, MPEG 2, H.261). Again, the sender can change \nvideo encoding on the fly during a session. Table 9.3 lists some of the video payload \ntypes currently supported by RTP. The other important fields are the following:\n\u2022 Sequence number field.  The sequence number field is 16 bits long. The sequence \nnumber increments by one for each RTP packet sent, and may be used by the \nreceiver to detect packet loss and to restore packet sequence. For example, if \nthe receiver side of the application receives a stream of RTP packets with a gap \nbetween sequence numbers 86 and 89, then the receiver knows that packets 87 \nand 88 are missing. The receiver can then attempt to conceal the lost data.\n\u2022 Timestamp field.  The timestamp field is 32 bits long. It reflects the sampling \ninstant of the first byte in the RTP data packet. As we saw in the preceding  \nsection, the receiver can use timestamps to remove packet jitter introduced in \nthe network and to provide synchronous playout at the receiver. The timestamp \nis derived from a sampling clock at the sender. As an example, for audio the  \ntimestamp clock increments by one for each sampling period (for example, each \n125 \u03bcsec for an 8 kHz sampling clock); if the audio application generates chunks \nconsisting of 160 encoded samples, then the timestamp increases by 160 for each \nRTP packet when the source is active. The timestamp clock continues to increase \nat a constant rate even if the source is inactive.\n\u2022 Synchronization source identifier (SSRC).  The SSRC field is 32 bits long. It iden -\ntifies the source of the RTP stream. Typically, each stream in an RTP session \nhas a distinct SSRC. The SSRC is not the IP address of the sender, but instead is \na number that the source assigns randomly when the new stream is", "doc_id": "5335b344-f338-42b4-b287-813dbe0bfcb8", "embedding": null, "doc_hash": "be76613bdf6c2812e793ed1ccfbbe6aba3753c446e978ad9ae8f1f9b30d0e9c7", "extra_info": null, "node_info": {"start": 2161499, "end": 2165369}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "fab0b1aa-3e5c-4ac8-870b-7365313930fd", "3": "4dfd71e0-1d6a-4246-85b9-6009cc7d5540"}}, "__type__": "1"}, "4dfd71e0-1d6a-4246-85b9-6009cc7d5540": {"__data__": {"text": "timestamp \nis derived from a sampling clock at the sender. As an example, for audio the  \ntimestamp clock increments by one for each sampling period (for example, each \n125 \u03bcsec for an 8 kHz sampling clock); if the audio application generates chunks \nconsisting of 160 encoded samples, then the timestamp increases by 160 for each \nRTP packet when the source is active. The timestamp clock continues to increase \nat a constant rate even if the source is inactive.\n\u2022 Synchronization source identifier (SSRC).  The SSRC field is 32 bits long. It iden -\ntifies the source of the RTP stream. Typically, each stream in an RTP session \nhas a distinct SSRC. The SSRC is not the IP address of the sender, but instead is \na number that the source assigns randomly when the new stream is started. The \nprobability that two streams get assigned the same SSRC is very small. Should \nthis happen, the two sources pick a new SSRC value.Payload\ntypeSequence\nnumberSynchronization\nsource identi \ufb01erMiscellaneous\n\ufb01eldsTimestamp\nFigure 9.8  \u2666 RTP header fields\n9.4  \u2022  PROTOCOLS FOR REAL-TIME CONVERSATIONAL APPLICATIONS      731\n9.4.2  SIP\nThe Session Initiation Protocol (SIP), defined in [RFC 3261; RFC 5411], is an open \nand lightweight protocol that does the following:\n\u2022 It provides mechanisms for establishing calls between a caller and a callee over \nan IP network. It allows the caller to notify the callee that it wants to start a call. \nIt allows the participants to agree on media encodings. It also allows participants \nto end calls.\n\u2022 It provides mechanisms for the caller to determine the current IP address of the \ncallee. Users do not have a single, fixed IP address because they may be assigned \naddresses dynamically (using DHCP) and because they may have multiple IP \ndevices, each with a different IP address.\n\u2022 It provides mechanisms for call management, such as adding new media streams \nduring the call, changing the encoding during the call, inviting new participants \nduring the call, call transfer, and call holding.Table 9.2  \u2666 Audio payload types supported by RTPPayload-Type Number Audio Format Sampling Rate Rate\n0 PCM \u03bc-law 8 kHz 64 kbps\n1 1016 8 kHz 4.8 kbps\n3 GSM 8 kHz 13 kbps\n7 LPC 8 kHz 2.4 kbps\n9 G.722 16 kHz 48\u201364 kbps\n14 MPEG Audio 90 kHz \u2014\n15 G.728 8 kHz 16 kbps\nTable 9.3  \u2666 Some video payload types supported by RTPPayload-Type Number Video Format\n26 Motion JPEG\n31 H.261\n32 MPEG 1 video\n33 MPEG 2 video\n732     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\nSetting Up a Call to a Known IP Address\nTo understand the essence of SIP, it is best to take a look at a concrete example. In \nthis example, Alice is at her PC and she wants to call Bob, who is also working at \nhis PC. Alice\u2019s and Bob\u2019s PCs are both equipped with SIP-based software for mak -\ning and receiving phone calls. In this initial example, we\u2019ll assume that Alice knows \nthe IP address of Bob\u2019s PC. Figure 9.9 illustrates the SIP call-establishment process.\nIn Figure 9.9, we see that an SIP session begins when Alice sends Bob an INVITE \nmessage, which resembles an HTTP request message. This INVITE message is sent \nover UDP to the well-known port 5060 for SIP. (SIP messages can also be sent over \nTCP.) The INVITE message includes an identifier for Bob (bob@193.64.210.89), \nan indication of Alice\u2019s current IP address, an indication that Alice desires to \nreceive audio, which is to be encoded in format AVP 0 (PCM encoded \u03bc-law) and \nTime Time167.180.112.24\nINVITE", "doc_id": "4dfd71e0-1d6a-4246-85b9-6009cc7d5540", "embedding": null, "doc_hash": "d34632145ab9e18a57a34cfa08cf07811d7db8e17e8601129fd3c134dd9309ab", "extra_info": null, "node_info": {"start": 2165390, "end": 2168846}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "5335b344-f338-42b4-b287-813dbe0bfcb8", "3": "f1637a71-3a24-452c-8bd4-1301caf073e2"}}, "__type__": "1"}, "f1637a71-3a24-452c-8bd4-1301caf073e2": {"__data__": {"text": "In this initial example, we\u2019ll assume that Alice knows \nthe IP address of Bob\u2019s PC. Figure 9.9 illustrates the SIP call-establishment process.\nIn Figure 9.9, we see that an SIP session begins when Alice sends Bob an INVITE \nmessage, which resembles an HTTP request message. This INVITE message is sent \nover UDP to the well-known port 5060 for SIP. (SIP messages can also be sent over \nTCP.) The INVITE message includes an identifier for Bob (bob@193.64.210.89), \nan indication of Alice\u2019s current IP address, an indication that Alice desires to \nreceive audio, which is to be encoded in format AVP 0 (PCM encoded \u03bc-law) and \nTime Time167.180.112.24\nINVITE bob@193.64.210.\n89 c=IN IP4 167.180.112.24\nm=audio 38060 R\nTP/AVP 0\n200 OK\nc=In IP4 193.64.210.89\nm=audio 48753 RTP/AVP 3Bob\u2019s\nterminal rings193.64.210.89\nm Law audioport 5060\nport 5060\nport 38060Alice Bob\nport 5060\nport 48753ACK\nGSM\nFigure 9.9  \u2666 SIP call establishment when Alice knows Bob\u2019s IP address\n9.4  \u2022  PROTOCOLS FOR REAL-TIME CONVERSATIONAL APPLICATIONS      733\nencapsulated in RTP, and an indication that she wants to receive the RTP packets \non port 38060. After receiving Alice\u2019s INVITE message, Bob sends an SIP response \nmessage, which resembles an HTTP response message. This response SIP message \nis also sent to the SIP port 5060. Bob\u2019s response includes a 200 OK as well as an \nindication of his IP address, his desired encoding and packetization for reception, and \nhis port number to which the audio packets should be sent. Note that in this example \nAlice and Bob are going to use different audio-encoding mechanisms: Alice is asked \nto encode her audio with GSM whereas Bob is asked to encode his audio with PCM \n\u03bc-law. After receiving Bob\u2019s response, Alice sends Bob an SIP acknowledgment \nmessage. After this SIP transaction, Bob and Alice can talk. (For visual convenience, \nFigure 9. 9 shows Alice talking after Bob, but in truth they would normally talk at the \nsame time.) Bob will encode and packetize the audio as requested and send the audio \npackets to port number 38060 at IP address 167.180.112.24. Alice will also encode \nand packetize the audio as requested and send the audio packets to port number \n48753 at IP address 193.64.210.89.\nFrom this simple example, we have learned a number of key characteristics of \nSIP. First, SIP is an out-of-band protocol: The SIP messages are sent and received in \nsockets that are different from those used for sending and receiving the media data. \nSecond, the SIP messages themselves are ASCII-readable and resemble HTTP mes -\nsages. Third, SIP requires all messages to be acknowledged, so it can run over UDP \nor TCP.\nIn this example, let\u2019s consider what would happen if Bob does not have a PCM \n\u03bc-law codec for encoding audio. In this case, instead of responding with 200 OK, \nBob would likely respond with a 606 Not Acceptable and list in the message all the \ncodecs he can use. Alice would then choose one of the listed codecs and send another \nINVITE message, this time advertising the chosen codec. Bob could also simply \nreject the call by sending one of many possible rejection reply codes. (There are \nmany such codes, including \u201cbusy,\u201d \u201cgone,\u201d \u201cpayment required,\u201d and \u201cforbidden.\u201d)\nSIP Addresses\nIn the previous example, Bob\u2019s SIP address is sip:bob@193.64.210.89. However, we \nexpect many\u2014if not most\u2014SIP addresses to resemble e-mail addresses. For exam", "doc_id": "f1637a71-3a24-452c-8bd4-1301caf073e2", "embedding": null, "doc_hash": "925ec4af90dd6f9ea0f91ee44c48ae97d5077e7690ec92faafc8fd9c7c7e2451", "extra_info": null, "node_info": {"start": 2168938, "end": 2172336}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "4dfd71e0-1d6a-4246-85b9-6009cc7d5540", "3": "12170e4e-ccc1-4d59-9013-ddf2056c65ba"}}, "__type__": "1"}, "12170e4e-ccc1-4d59-9013-ddf2056c65ba": {"__data__": {"text": "codec for encoding audio. In this case, instead of responding with 200 OK, \nBob would likely respond with a 606 Not Acceptable and list in the message all the \ncodecs he can use. Alice would then choose one of the listed codecs and send another \nINVITE message, this time advertising the chosen codec. Bob could also simply \nreject the call by sending one of many possible rejection reply codes. (There are \nmany such codes, including \u201cbusy,\u201d \u201cgone,\u201d \u201cpayment required,\u201d and \u201cforbidden.\u201d)\nSIP Addresses\nIn the previous example, Bob\u2019s SIP address is sip:bob@193.64.210.89. However, we \nexpect many\u2014if not most\u2014SIP addresses to resemble e-mail addresses. For exam -\nple, Bob\u2019s address might be sip:bob@domain.com. When Alice\u2019s SIP device sends \nan INVITE message, the message would include this e-mail-like address; the SIP \ninfrastructure would then route the message to the IP device that Bob is currently \nusing (as we\u2019ll discuss below). Other possible forms for the SIP address could be \nBob\u2019s legacy phone number or simply Bob\u2019s first/middle/last name (assuming it is \nunique).\nAn interesting feature of SIP addresses is that they can be included in Web \npages, just as people\u2019s e-mail addresses are included in Web pages with the mailto \nURL. For example, suppose Bob has a personal homepage, and he wants to provide \na means for visitors to the homepage to call him. He could then simply include the \n734     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\nURL sip:bob@domain.com. When the visitor clicks on the URL, the SIP application \nin the visitor\u2019s device is launched and an INVITE message is sent to Bob.\nSIP Messages\nIn this short introduction to SIP, we\u2019ll not cover all SIP message types and headers. \nInstead, we\u2019ll take a brief look at the SIP INVITE message, along with a few com -\nmon header lines. Let us again suppose that Alice wants to initiate a VoIP call to \nBob, and this time Alice knows only Bob\u2019s SIP address, bob@domain.com, and does \nnot know the IP address of the device that Bob is currently using. Then her message \nmight look something like this:\nINVITE sip:bob@domain.com SIP/2.0\nVia: SIP/2.0/UDP 167.180.112.24\nFrom: sip:alice@hereway.com\nTo: sip:bob@domain.com\nCall-ID: a2e3a@pigeon.hereway.com\nContent-Type: application/sdp\nContent-Length: 885\nc=IN IP4 167.180.112.24\nm=audio 38060 RTP/AVP 0\nThe INVITE line includes the SIP version, as does an HTTP request message. \nWhenever an SIP message passes through an SIP device (including the device that origi -\nnates the message), it attaches a Via header, which indicates the IP address of the device. \n(We\u2019ll see soon that the typical INVITE message passes through many SIP devices \nbefore reaching the callee\u2019s SIP application.) Similar to an e-mail message, the SIP mes -\nsage includes a From header line and a To header line. The message includes a Call-ID, \nwhich uniquely identifies the call (similar to the message-ID in e-mail). It includes a \nContent-Type header line, which defines the format used to describe the content con -\ntained in the SIP message. It also includes a Content-Length header line, which provides \nthe length in bytes of the content in the message. Finally, after a carriage return and line \nfeed, the message contains the content. In this case, the content provides information \nabout Alice\u2019s IP address and how Alice wants to receive the audio.\nName Translation and User Location\nIn the example in Figure 9.9, we assumed that Alice\u2019s SIP device knew the IP address", "doc_id": "12170e4e-ccc1-4d59-9013-ddf2056c65ba", "embedding": null, "doc_hash": "4cb43b24a520dbbbc61058b6c526edfb0b72db200195a575d290eab3d279cf05", "extra_info": null, "node_info": {"start": 2172329, "end": 2175801}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "f1637a71-3a24-452c-8bd4-1301caf073e2", "3": "16a9c0c3-2ba0-49b3-a336-de6af11c8861"}}, "__type__": "1"}, "16a9c0c3-2ba0-49b3-a336-de6af11c8861": {"__data__": {"text": "callee\u2019s SIP application.) Similar to an e-mail message, the SIP mes -\nsage includes a From header line and a To header line. The message includes a Call-ID, \nwhich uniquely identifies the call (similar to the message-ID in e-mail). It includes a \nContent-Type header line, which defines the format used to describe the content con -\ntained in the SIP message. It also includes a Content-Length header line, which provides \nthe length in bytes of the content in the message. Finally, after a carriage return and line \nfeed, the message contains the content. In this case, the content provides information \nabout Alice\u2019s IP address and how Alice wants to receive the audio.\nName Translation and User Location\nIn the example in Figure 9.9, we assumed that Alice\u2019s SIP device knew the IP address \nwhere Bob could be contacted. But this assumption is quite unrealistic, not only \nbecause IP addresses are often dynamically assigned with DHCP, but also because \nBob may have multiple IP devices (for example, different devices for his home, \nwork, and car). So now let us suppose that Alice knows only Bob\u2019s e-mail address, \n9.4  \u2022  PROTOCOLS FOR REAL-TIME CONVERSATIONAL APPLICATIONS      735\nbob@domain.com, and that this same address is used for SIP-based calls. In this \ncase, Alice needs to obtain the IP address of the device that the user bob@domain.\ncom is currently using. To find this out, Alice creates an INVITE message that begins \nwith INVITE bob@domain.com SIP/2.0 and sends this message to an SIP proxy . \nThe proxy will respond with an SIP reply that might include the IP address of the  \ndevice that bob@domain.com is currently using. Alternatively, the reply might \ninclude the IP address of Bob\u2019s voicemail box, or it might include a URL of a Web \npage (that says \u201cBob is sleeping. Leave me alone!\u201d). Also, the result returned by the \nproxy might depend on the caller: If the call is from Bob\u2019s wife, he might accept \nthe call and supply his IP address; if the call is from Bob\u2019s mother-in-law, he might \nrespond with the URL that points to the I-am-sleeping Web page!\nNow, you are probably wondering, how can the proxy server determine the cur -\nrent IP address for bob@domain.com? To answer this question, we need to say a few \nwords about another SIP device, the SIP registrar . Every SIP user has an associated \nregistrar. Whenever a user launches an SIP application on a device, the application \nsends an SIP register message to the registrar, informing the registrar of its current \nIP address. For example, when Bob launches his SIP application on his PDA, the \napplication would send a message along the lines of:\nREGISTER sip:domain.com SIP/2.0\nVia: SIP/2.0/UDP 193.64.210.89\nFrom: sip:bob@domain.com\nTo: sip:bob@domain.com\nExpires: 3600\nBob\u2019s registrar keeps track of Bob\u2019s current IP address. Whenever Bob switches \nto a new SIP device, the new device sends a new register message, indicating the \nnew IP address. Also, if Bob remains at the same device for an extended period of \ntime, the device will send refresh register messages, indicating that the most recently \nsent IP address is still valid. (In the example above, refresh messages need to be sent \nevery 3600 seconds to maintain the address at the registrar server.) It is worth noting \nthat the registrar is analogous to a DNS authoritative name server: The DNS server \ntranslates fixed host names to fixed IP addresses; the SIP registrar translates fixed \nhuman identifiers (for example, bob@domain.com) to dynamic IP addresses. Often \nSIP registrars and SIP proxies are run on the same host.\nNow let\u2019s examine how Alice\u2019s SIP proxy server obtains Bob\u2019s current IP \naddress. From the preceding", "doc_id": "16a9c0c3-2ba0-49b3-a336-de6af11c8861", "embedding": null, "doc_hash": "72adfdbe6ad8f19765855a8a2c7419800b961d618dae869e9122c1774bb89d64", "extra_info": null, "node_info": {"start": 2175697, "end": 2179379}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "12170e4e-ccc1-4d59-9013-ddf2056c65ba", "3": "57a40e1c-4b5e-45f5-80a6-61f22b406681"}}, "__type__": "1"}, "57a40e1c-4b5e-45f5-80a6-61f22b406681": {"__data__": {"text": "if Bob remains at the same device for an extended period of \ntime, the device will send refresh register messages, indicating that the most recently \nsent IP address is still valid. (In the example above, refresh messages need to be sent \nevery 3600 seconds to maintain the address at the registrar server.) It is worth noting \nthat the registrar is analogous to a DNS authoritative name server: The DNS server \ntranslates fixed host names to fixed IP addresses; the SIP registrar translates fixed \nhuman identifiers (for example, bob@domain.com) to dynamic IP addresses. Often \nSIP registrars and SIP proxies are run on the same host.\nNow let\u2019s examine how Alice\u2019s SIP proxy server obtains Bob\u2019s current IP \naddress. From the preceding discussion we see that the proxy server simply needs \nto forward Alice\u2019s INVITE message to Bob\u2019s registrar/proxy. The registrar/proxy \ncould then forward the message to Bob\u2019s current SIP device. Finally, Bob, having \nnow received Alice\u2019s INVITE message, could send an SIP response to Alice.\nAs an example, consider Figure 9.10, in which jim@umass.edu, currently \nworking on 217.123.56.89, wants to initiate a Voice-over-IP (VoIP) session with  \nkeith@upenn.edu, currently working on 197.87.54.21. The following steps are taken: \n736     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\n(1) Jim sends an INVITE message to the umass SIP proxy. (2) The proxy does a DNS \nlookup on the SIP registrar upenn.edu (not shown in diagram) and then forwards the \nmessage to the registrar server. (3) Because keith@upenn.edu is no longer registered \nat the upenn registrar, the upenn registrar sends a redirect response, indicating that \nit should try keith@nyu.edu. (4) The umass proxy sends an INVITE message to the \nNYU SIP registrar. (5) The NYU registrar knows the IP address of keith@upenn.\nedu and forwards the INVITE message to the host 197.87.54.21, which is running \nKeith\u2019s SIP client. (6\u20138) An SIP response is sent back through registrars/proxies to \nthe SIP client on 217.123.56.89. (9) Media is sent directly between the two clients. \n(There is also an SIP acknowledgment message, which is not shown.)\nOur discussion of SIP has focused on call initiation for voice calls. SIP, being \na signaling protocol for initiating and ending calls in general, can be used for video \nconference calls as well as for text-based sessions. In fact, SIP has become a fun -\ndamental component in many instant messaging applications. Readers desiring to \nlearn more about SIP are encouraged to visit Henning Schulzrinne\u2019s SIP Web site \n[Schulzrinne-SIP 2016]. In particular, on this site you will find open source software \nfor SIP clients and servers [SIP Software 2016].9564\n72\n3\n1\n8SIP registrar\nupenn.edu\nSIP proxy\numass.edu\nSIP client\n217.123.56.89SIP client\n197.87.54.21SIP registrar\nnyu.edu\nFigure 9.10  \u2666 Session initiation, involving SIP proxies and registrars\n9.5  \u2022  NETWORK SUPPORT FOR MULTIMEDIA      737\n9.5 Network Support for Multimedia\nIn Sections 9.2 through 9.4, we learned how application-level mechanisms such as \nclient buffering, prefetching, adapting media quality to available bandwidth, adap -\ntive playout, and loss mitigation techniques can be used by multimedia applications \nto improve a multimedia application\u2019s performance. We also learned how content \ndistribution networks and P2P overlay networks can be", "doc_id": "57a40e1c-4b5e-45f5-80a6-61f22b406681", "embedding": null, "doc_hash": "b16619b212894e4122b7c8cf16ecfe1139fb13c13ff17226d382d63810c33be1", "extra_info": null, "node_info": {"start": 2179426, "end": 2182775}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "16a9c0c3-2ba0-49b3-a336-de6af11c8861", "3": "8f5575ca-13d6-40f4-9c6b-fae1e2b015a2"}}, "__type__": "1"}, "8f5575ca-13d6-40f4-9c6b-fae1e2b015a2": {"__data__": {"text": "proxy\numass.edu\nSIP client\n217.123.56.89SIP client\n197.87.54.21SIP registrar\nnyu.edu\nFigure 9.10  \u2666 Session initiation, involving SIP proxies and registrars\n9.5  \u2022  NETWORK SUPPORT FOR MULTIMEDIA      737\n9.5 Network Support for Multimedia\nIn Sections 9.2 through 9.4, we learned how application-level mechanisms such as \nclient buffering, prefetching, adapting media quality to available bandwidth, adap -\ntive playout, and loss mitigation techniques can be used by multimedia applications \nto improve a multimedia application\u2019s performance. We also learned how content \ndistribution networks and P2P overlay networks can be used to provide a system-\nlevel  approach for delivering multimedia content. These techniques and approaches \nare all designed to be used in today\u2019s best-effort Internet. Indeed, they are in use \ntoday precisely because the Internet provides only a single, best-effort class of ser -\nvice. But as designers of computer networks, we can\u2019t help but ask whether the \nnetwork  (rather than the applications or application-level infrastructure alone) might \nprovide mechanisms to support multimedia content delivery. As we\u2019ll see shortly, \nthe answer is, of course, \u201cyes\u201d! But we\u2019ll also see that a number of these new  \nnetwork-level mechanisms have yet to be widely deployed. This may be due to their \ncomplexity and to the fact that application-level techniques together with best-effort \nservice and properly dimensioned network resources (for example, bandwidth) can \nindeed provide a \u201cgood-enough\u201d (even if not-always-perfect) end-to-end multimedia \ndelivery service.\nTable 9. 4 summarizes three broad approaches towards providing network-level \nsupport for multimedia applications.\n\u2022 Making the best of best-effort service.  The application-level mechanisms and \ninfrastructure that we studied in Sections 9.2 through 9.4 can be successfully used \nin a well-dimensioned network where packet loss and excessive end-to-end delay \nrarely occur. When demand increases are forecasted, the ISPs deploy additional \nbandwidth and switching capacity to continue to ensure satisfactory delay and \npacket-loss performance [Huang 2005]. We\u2019ll discuss such network dimension -\ning further in Section 9.5.1.\n\u2022 Differentiated service.  Since the early days of the Internet, it\u2019s been envisioned \nthat different types of traffic (for example, as indicated in the Type-of-Service \nfield in the IP4v packet header) could be provided with different classes of ser -\nvice, rather than a single one-size-fits-all best-effort service. With differentiated \nservice , one type of traffic might be given strict priority over another class of traf -\nfic when both types of traffic are queued at a router. For example, packets belong -\ning to a real-time conversational application might be given priority over other \npackets due to their stringent delay constraints. Introducing differentiated service \ninto the network will require new mechanisms for packet marking (indicating a \npacket\u2019s class of service), packet scheduling, and more. We\u2019ll cover differenti -\nated service, and new network mechanisms needed to implement this service, in \nSections 9.5.2 and 9.5.3.\n738     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\n\u2022 Per-connection Quality-of-Service (QoS) Guarantees.  With per-connection \nQoS guarantees, each instance of an application explicitly reserves end-to-end  \nbandwidth and thus has a guaranteed end-to-end performance. A hard guarantee  \nmeans the application will receive its requested quality of service (QoS) with cer -\ntainty. A soft guarantee  means the application will receive its requested quality \nof service with high probability. For example, if a user wants to make a", "doc_id": "8f5575ca-13d6-40f4-9c6b-fae1e2b015a2", "embedding": null, "doc_hash": "372e27da0354ccfd32d9adb7e5dd78a44e4979ee22c1792a204e1f0446c90be3", "extra_info": null, "node_info": {"start": 2182851, "end": 2186546}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "57a40e1c-4b5e-45f5-80a6-61f22b406681", "3": "9c3e1e26-1196-4f0d-8d9d-e3d99ce967bf"}}, "__type__": "1"}, "9c3e1e26-1196-4f0d-8d9d-e3d99ce967bf": {"__data__": {"text": "We\u2019ll cover differenti -\nated service, and new network mechanisms needed to implement this service, in \nSections 9.5.2 and 9.5.3.\n738     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\n\u2022 Per-connection Quality-of-Service (QoS) Guarantees.  With per-connection \nQoS guarantees, each instance of an application explicitly reserves end-to-end  \nbandwidth and thus has a guaranteed end-to-end performance. A hard guarantee  \nmeans the application will receive its requested quality of service (QoS) with cer -\ntainty. A soft guarantee  means the application will receive its requested quality \nof service with high probability. For example, if a user wants to make a VoIP call \nfrom Host A to Host B, the user\u2019s VoIP application reserves bandwidth explicitly \nin each link along a route between the two hosts. But permitting applications to \nmake reservations and requiring the network to honor the reservations requires \nsome big changes. First, we need a protocol that, on behalf of the applications, \nreserves link bandwidth on the paths from the senders to their receivers. Second, \nwe\u2019ll need new scheduling policies in the router queues so that per-connection \nbandwidth reservations can be honored. Finally, in order to make a reservation, \nthe applications must give the network a description of the traffic that they intend \nto send into the network and the network will need to police each application\u2019s \ntraffic to make sure that it abides by that description. These mechanisms, when \ncombined, require new and complex software in hosts and routers. Because  \nper-connection QoS guaranteed service has not seen significant deployment, \nwe\u2019ll cover these mechanisms only briefly in Section 9.5.4.Table 9.4  \u2666   Three network-level approaches to supporting multimedia  \napplicationsApproach Granularity Guarantee Mechanisms Complexity Deployment to date\nMaking the \nbest of best-\neffort serviceall traffic \ntreated \nequallynone, or  \nsoftapplication-layer \nsupport, CDNs, \noverlays, network-\nlevel resource \nprovisioningminimal everywhere\nDifferentiated \nservicedifferent \nclasses \nof traffic \ntreated \ndifferentlynone,  \nor softpacket marking, \npolicing, \nschedulingmedium some\nPer-connection \nQuality-of-\nService (QoS) \nGuaranteeseach \nsource-\ndestination \nflows \ntreated \ndifferentlysoft or hard,  \nonce flow  \nis admittedpacket marking, \npolicing, \nscheduling; call \nadmission and \nsignalinglight little\n9.5  \u2022  NETWORK SUPPORT FOR MULTIMEDIA      739\n9.5.1  Dimensioning Best-Effort Networks\nFundamentally, the difficulty in supporting multimedia applications arises from \ntheir stringent performance requirements\u2014low end-to-end packet delay, delay \njitter, and loss\u2014and the fact that packet delay, delay jitter, and loss occur when -\never the network becomes congested. A first approach to improving the quality of \nmultimedia applications\u2014an approach that can often be used to solve just about \nany problem where resources are constrained\u2014is simply to \u201cthrow money at the \nproblem\u201d and thus simply avoid resource contention. In the case of networked \nmultimedia, this means providing enough link capacity throughout the network \nso that network congestion, and its consequent packet delay and loss, never (or \nonly very rarely) occurs. With enough link capacity, packets could zip through \ntoday\u2019s Internet without queuing delay or loss. From many perspectives this is an \nideal situation\u2014multimedia applications would perform perfectly, users would \nbe happy, and this could all be achieved with no changes to Internet\u2019s best-effort \narchitecture.\nThe question, of course, is how much capacity is \u201cenough\u201d to achieve this nirvana, \nand whether the costs of providing \u201cenough\u201d bandwidth are practical from", "doc_id": "9c3e1e26-1196-4f0d-8d9d-e3d99ce967bf", "embedding": null, "doc_hash": "96940548d121543a0cb3ef0419766d3cd0f229be52711bbf9498b282187deb48", "extra_info": null, "node_info": {"start": 2186534, "end": 2190243}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "8f5575ca-13d6-40f4-9c6b-fae1e2b015a2", "3": "3d33a658-16af-4fff-a309-fd969f50e14b"}}, "__type__": "1"}, "3d33a658-16af-4fff-a309-fd969f50e14b": {"__data__": {"text": "simply to \u201cthrow money at the \nproblem\u201d and thus simply avoid resource contention. In the case of networked \nmultimedia, this means providing enough link capacity throughout the network \nso that network congestion, and its consequent packet delay and loss, never (or \nonly very rarely) occurs. With enough link capacity, packets could zip through \ntoday\u2019s Internet without queuing delay or loss. From many perspectives this is an \nideal situation\u2014multimedia applications would perform perfectly, users would \nbe happy, and this could all be achieved with no changes to Internet\u2019s best-effort \narchitecture.\nThe question, of course, is how much capacity is \u201cenough\u201d to achieve this nirvana, \nand whether the costs of providing \u201cenough\u201d bandwidth are practical from a business \nstandpoint to the ISPs. The question of how much capacity to provide at network \nlinks in a given topology to achieve a given level of performance is often known as \nbandwidth provisioning . The even more complicated problem of how to design a \nnetwork topology (where to place routers, how to interconnect routers with links, and \nwhat capacity to assign to links) to achieve a given level of end-to-end performance \nis a network design problem often referred to as network dimensioning . Both band -\nwidth provisioning and network dimensioning are complex topics, well beyond the \nscope of this textbook. We note here, however, that the following issues must be \naddressed in order to predict application-level performance between two network \nend points, and thus provision enough capacity to meet an application\u2019s performance \nrequirements.\n\u2022 Models of traffic demand between network end points.  Models may need to be \nspecified at both the call level (for example, users \u201carriving\u201d to the network and \nstarting up end-to-end applications) and at the packet level (for example, packets \nbeing generated by ongoing applications). Note that workload may change over \ntime.\n\u2022 Well-defined performance requirements.  For example, a performance require -\nment for supporting delay-sensitive traffic, such as a conversational multimedia \napplication, might be that the probability that the end-to-end delay of the packet \nis greater than a maximum tolerable delay be less than some small value [Fraleigh \n2003].\n\u2022 Models to predict end-to-end performance for a given workload model, and  \ntechniques to find a minimal cost bandwidth allocation that will result in all user \n740     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\nrequirements being met.  Here, researchers are busy developing performance \nmodels that can quantify performance for a given workload, and optimization \ntechniques to find minimal-cost bandwidth allocations meeting performance \nrequirements.\nGiven that today\u2019s best-effort Internet could (from a technology standpoint) sup -\nport multimedia traffic at an appropriate performance level if it were dimensioned \nto do so, the natural question is why today\u2019s Internet doesn\u2019t do so. The answers \nare primarily economic and organizational. From an economic standpoint, would \nusers be willing to pay their ISPs enough for the ISPs to install sufficient bandwidth \nto support multimedia applications over a best-effort Internet? The organizational \nissues are perhaps even more daunting. Note that an end-to-end path between two \nmultimedia end points will pass through the networks of multiple ISPs. From an \norganizational standpoint, would these ISPs be willing to cooperate (perhaps with \nrevenue sharing) to ensure that the end-to-end path is properly dimensioned to sup -\nport multimedia applications? For a perspective on these economic and organiza -\ntional issues, see [Davies 2005]. For a perspective on provisioning tier-1 backbone \nnetworks to support delay-sensitive traffic, see [Fraleigh 2003].\n9.5.2  Providing Multiple Classes of Service\nPerhaps the simplest enhancement to the one-size-fits-all best-effort service in \ntoday\u2019s Internet is to divide traffic into classes, and provide different levels of ser -\nvice to these different classes of traffic. For example, an ISP might well", "doc_id": "3d33a658-16af-4fff-a309-fd969f50e14b", "embedding": null, "doc_hash": "ec9a134f93f3781fb017e9d0f9cbed97c7834c7a31144906c43e81d6b531ee99", "extra_info": null, "node_info": {"start": 2190149, "end": 2194240}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "9c3e1e26-1196-4f0d-8d9d-e3d99ce967bf", "3": "fffdcded-2c11-420d-b4b2-a26b3a36cf7a"}}, "__type__": "1"}, "fffdcded-2c11-420d-b4b2-a26b3a36cf7a": {"__data__": {"text": "will pass through the networks of multiple ISPs. From an \norganizational standpoint, would these ISPs be willing to cooperate (perhaps with \nrevenue sharing) to ensure that the end-to-end path is properly dimensioned to sup -\nport multimedia applications? For a perspective on these economic and organiza -\ntional issues, see [Davies 2005]. For a perspective on provisioning tier-1 backbone \nnetworks to support delay-sensitive traffic, see [Fraleigh 2003].\n9.5.2  Providing Multiple Classes of Service\nPerhaps the simplest enhancement to the one-size-fits-all best-effort service in \ntoday\u2019s Internet is to divide traffic into classes, and provide different levels of ser -\nvice to these different classes of traffic. For example, an ISP might well want to \nprovide a higher class of service to delay-sensitive Voice-over-IP or teleconferenc -\ning traffic (and charge more for this service!) than to elastic traffic such as e-mail or \nHTTP. Alternatively, an ISP may simply want to provide a higher quality of service \nto customers willing to pay more for this improved service. A number of residential \nwired-access ISPs and cellular wireless-access ISPs have adopted such tiered lev -\nels of service\u2014with platinum-service subscribers receiving better performance than \ngold- or silver-service subscribers.\nWe\u2019re all familiar with different classes of service from our everyday lives\u2014\nfirst-class airline passengers get better service than business-class passengers, who \nin turn get better service than those of us who fly economy class; VIPs are provided \nimmediate entry to events while everyone else waits in line; elders are revered in \nsome countries and provided seats of honor and the finest food at a table. It\u2019s impor -\ntant to note that such differential service is provided among aggregates of traffic, \nthat is, among classes of traffic, not among individual connections. For example, all \nfirst-class passengers are handled the same (with no first-class passenger receiving \nany better treatment than any other first-class passenger), just as all VoIP packets \nwould receive the same treatment within the network, independent of the particular \nend-to-end connection to which they belong. As we will see, by dealing with a small \nnumber of traffic aggregates, rather than a large number of individual connections, \n9.5  \u2022  NETWORK SUPPORT FOR MULTIMEDIA      741\nthe new network mechanisms required to provide better-than-best service can be \nkept relatively simple.\nThe early Internet designers clearly had this notion of multiple classes of ser -\nvice in mind. Recall the type-of-service (ToS) field in the IPv4 header discussed in \nChapter 4. IEN123 [ISI 1979] describes the ToS field also present in an ancestor of \nthe IPv4 datagram as follows: \u201cThe Type of Service [field] provides an indication \nof the abstract parameters of the quality of service desired. These parameters are to \nbe used to guide the selection of the actual service parameters when transmitting a \ndatagram through a particular network. Several networks offer service precedence, \nwhich somehow treats high precedence traffic as more important that other traffic.\u201d \nMore than four decades ago, the vision of providing different levels of service to dif -\nferent classes of traffic was clear! However, it\u2019s taken us an equally long period of \ntime to realize this vision.\nMotivating Scenarios\nLet\u2019s begin our discussion of network mechanisms for providing multiple classes of \nservice with a few motivating scenarios.\nFigure 9. 11 shows a simple network scenario in which two application packet \nflows originate on Hosts H1 and H2 on one LAN and are destined for Hosts H3 and \nH4 on another LAN. The routers on the two LANs are connected by a 1.5 Mbps link. \nLet\u2019s assume the LAN speeds are significantly higher than 1.5 Mbps, and focus on \nthe output queue of router R1; it is here that packet delay and packet loss will occur \nif the aggregate", "doc_id": "fffdcded-2c11-420d-b4b2-a26b3a36cf7a", "embedding": null, "doc_hash": "13ad55bfdc5b68ea7362a066cc22dc6477434ca9fc14306d5f6fc6e07413734e", "extra_info": null, "node_info": {"start": 2194249, "end": 2198186}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "3d33a658-16af-4fff-a309-fd969f50e14b", "3": "64a35d7b-682e-4695-a163-0070d5a1d853"}}, "__type__": "1"}, "64a35d7b-682e-4695-a163-0070d5a1d853": {"__data__": {"text": "providing different levels of service to dif -\nferent classes of traffic was clear! However, it\u2019s taken us an equally long period of \ntime to realize this vision.\nMotivating Scenarios\nLet\u2019s begin our discussion of network mechanisms for providing multiple classes of \nservice with a few motivating scenarios.\nFigure 9. 11 shows a simple network scenario in which two application packet \nflows originate on Hosts H1 and H2 on one LAN and are destined for Hosts H3 and \nH4 on another LAN. The routers on the two LANs are connected by a 1.5 Mbps link. \nLet\u2019s assume the LAN speeds are significantly higher than 1.5 Mbps, and focus on \nthe output queue of router R1; it is here that packet delay and packet loss will occur \nif the aggregate sending rate of H1 and H2 exceeds 1.5 Mbps. Let\u2019s further suppose \nthat a 1 Mbps audio application (for example, a CD-quality audio call) shares the \nR1\n1.5 Mbps linkR2\nH2H1\nH4H3\nFigure 9.11  \u2666 Competing audio and HTTP applications\n742     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\n1.5 Mbps link between R1 and R2 with an HTTP Web-browsing application that is \ndownloading a Web page from H2 to H4.\nIn the best-effort Internet, the audio and HTTP packets are mixed in the output \nqueue at R1 and (typically) transmitted in a first-in-first-out (FIFO) order. In this \nscenario, a burst of packets from the Web server could potentially fill up the queue, \ncausing IP audio packets to be excessively delayed or lost due to buffer overflow \nat R1. How should we solve this potential problem? Given that the HTTP Web-\nbrowsing application does not have time constraints, our intuition might be to give \nstrict priority to audio packets at R1. Under a strict priority scheduling discipline, an \naudio packet in the R1 output buffer would always be transmitted before any HTTP \npacket in the R1 output buffer. The link from R1 to R2 would look like a dedicated \nlink of 1.5 Mbps to the audio traffic, with HTTP traffic using the R1-to-R2 link only \nwhen no audio traffic is queued. In order for R1 to distinguish between the audio and \nHTTP packets in its queue, each packet must be marked as belonging to one of these \ntwo classes of traffic. This was the original goal of the type-of-service (ToS) field in \nIPv4. As obvious as this might seem, this then is our first insight into mechanisms \nneeded to provide multiple classes of traffic:\nInsight 1: Packet marking  allows a router to distinguish among packets \nbelonging to different classes of traffic.\nNote that although our example considers a competing multimedia and elastic \nflow, the same insight applies to the case that platinum, gold, and silver classes of \nservice are implemented\u2014a packet-marking mechanism is still needed to indicate \nthat class of service to which a packet belongs.\nNow suppose that the router is configured to give priority to packets marked \nas belonging to the 1 Mbps audio application. Since the outgoing link speed is 1.5 \nMbps, even though the HTTP packets receive lower priority, they can still, on aver -\nage, receive 0.5 Mbps of transmission service. But what happens if the audio applica -\ntion starts sending packets at a rate of 1.5 Mbps or higher (either maliciously or due \nto an error in the application)? In this case, the HTTP packets will starve, that is, they \nwill not receive any service on the R1-to-R2 link. Similar problems would occur if \nmultiple applications (for example, multiple audio calls), all with the same class of \nservice as the audio application, were sharing the link\u2019s bandwidth; they too could \ncollectively starve the FTP session. Ideally, one wants a degree of isolation among \nclasses of traffic so that one class of traffic can be protected from the", "doc_id": "64a35d7b-682e-4695-a163-0070d5a1d853", "embedding": null, "doc_hash": "3fce808e1189a610f269f276fdb50b53d78009e100220cdc7514be0a29bb72a7", "extra_info": null, "node_info": {"start": 2198218, "end": 2201924}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "fffdcded-2c11-420d-b4b2-a26b3a36cf7a", "3": "2cc3dfec-0bb3-4bca-933c-a9753c1ece86"}}, "__type__": "1"}, "2cc3dfec-0bb3-4bca-933c-a9753c1ece86": {"__data__": {"text": "\nMbps, even though the HTTP packets receive lower priority, they can still, on aver -\nage, receive 0.5 Mbps of transmission service. But what happens if the audio applica -\ntion starts sending packets at a rate of 1.5 Mbps or higher (either maliciously or due \nto an error in the application)? In this case, the HTTP packets will starve, that is, they \nwill not receive any service on the R1-to-R2 link. Similar problems would occur if \nmultiple applications (for example, multiple audio calls), all with the same class of \nservice as the audio application, were sharing the link\u2019s bandwidth; they too could \ncollectively starve the FTP session. Ideally, one wants a degree of isolation among \nclasses of traffic so that one class of traffic can be protected from the other. This pro -\ntection could be implemented at different places in the network\u2014at each and every \nrouter, at first entry to the network, or at inter-domain network boundaries. This then \nis our second insight:\nInsight 2:  It is desirable to provide a degree of traffic isolation  among \nclasses so that one class is not adversely affected by another class of traffic \nthat misbehaves.\n9.5  \u2022  NETWORK SUPPORT FOR MULTIMEDIA      743\nWe\u2019ll examine several specific mechanisms for providing such isolation among \ntraffic classes. We note here that two broad approaches can be taken. First, it is pos-\nsible to perform traffic policing , as shown in Figure 9.12. If a traffic class or flow \nmust meet certain criteria (for example, that the audio flow not exceed a peak rate of \n1 Mbps), then a policing mechanism can be put into place to ensure that these criteria \nare indeed observed. If the policed application misbehaves, the policing mechanism \nwill take some action (for example, drop or delay packets that are in violation of \nthe criteria) so that the traffic actually entering the network conforms to the criteria. \nThe leaky bucket mechanism that we\u2019ll examine shortly is perhaps the most widely \nused policing mechanism. In Figure 9.12, the packet classification and marking \nmechanism (Insight 1) and the policing mechanism (Insight 2) are both implemented \ntogether at the network\u2019s edge, either in the end system or at an edge router.\nA complementary approach for providing isolation among traffic classes is for \nthe link-level packet-scheduling mechanism to explicitly allocate a fixed amount of \nlink bandwidth to each class. For example, the audio class could be allocated 1 Mbps \nat R1, and the HTTP class could be allocated 0.5 Mbps. In this case, the audio and \nR1\n1.5 Mbps linkPacket marking\nand policing\nMetering and policing MarksR2\nH2H1\nKey:H4H3\nFigure 9.12  \u2666 Policing (and marking) the audio and HTTP traffic classes\n744     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\nHTTP flows see a logical link with capacity 1.0 and 0.5 Mbps, respectively, as shown \nin Figure 9.13. With strict enforcement of the link-level allocation of bandwidth, a \nclass can use only the amount of bandwidth that has been allocated; in particular, it \ncannot utilize bandwidth that is not currently being used by others. For example, if \nthe audio flow goes silent (for example, if the speaker pauses and generates no audio \npackets), the HTTP flow would still not be able to transmit more than 0.5 Mbps over \nthe R1-to-R2 link, even though the audio flow\u2019s 1 Mbps bandwidth allocation is not \nbeing used at that moment. Since bandwidth is a \u201cuse-it-or-lose-it\u201d resource, there is \nno reason to prevent HTTP traffic from using bandwidth not used by the audio traf -\nfic. We\u2019d like to use bandwidth as efficiently as possible, never wasting it when it \ncould be otherwise used. This gives", "doc_id": "2cc3dfec-0bb3-4bca-933c-a9753c1ece86", "embedding": null, "doc_hash": "8e4890bd4b5733cedcba97465a8c64b7ae2d4f1d71701b67fe975f0ba974be7f", "extra_info": null, "node_info": {"start": 2201897, "end": 2205551}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "64a35d7b-682e-4695-a163-0070d5a1d853", "3": "a0cba3bf-336e-407d-94ca-d9fbfc35e22c"}}, "__type__": "1"}, "a0cba3bf-336e-407d-94ca-d9fbfc35e22c": {"__data__": {"text": "can use only the amount of bandwidth that has been allocated; in particular, it \ncannot utilize bandwidth that is not currently being used by others. For example, if \nthe audio flow goes silent (for example, if the speaker pauses and generates no audio \npackets), the HTTP flow would still not be able to transmit more than 0.5 Mbps over \nthe R1-to-R2 link, even though the audio flow\u2019s 1 Mbps bandwidth allocation is not \nbeing used at that moment. Since bandwidth is a \u201cuse-it-or-lose-it\u201d resource, there is \nno reason to prevent HTTP traffic from using bandwidth not used by the audio traf -\nfic. We\u2019d like to use bandwidth as efficiently as possible, never wasting it when it \ncould be otherwise used. This gives rise to our third insight:\nInsight 3:  While providing isolation among classes or flows, it is desirable \nto use resources (for example, link bandwidth and buffers) as efficiently as \npossible.\nRecall from our discussion in Sections 1.3 and 4.2 that packets belonging to vari -\nous network flows are multiplexed and queued for transmission at the output buff -\ners associated with a link. The manner in which queued packets are selected for \ntransmission on the link is known as the link-scheduling discipline , and was \ndiscussed in detail in Section 4.2. Recall that in Section 4.2 three link-scheduling \ndisciplines were discussed, namely, FIFO, priority queuing, and Weighted Fair  \nQueuing (WFQ). We\u2019ll see soon see that WFQ will play a particularly important role \nfor isolating the traffic classes.R1\n1.5 Mbps link1.0 Mbps\nlogical link\n0.5 Mbps\nlogical linkR2\nH2H1\nH4H3\nFigure 9.13  \u2666 Logical isolation of audio and HTTP traffic classes\n9.5  \u2022  NETWORK SUPPORT FOR MULTIMEDIA      745\nThe Leaky Bucket\nOne of our earlier insights was that policing, the regulation of the rate at which a \nclass or flow (we will assume the unit of policing is a flow in our discussion below) is \nallowed to inject packets into the network, is an important QoS mechanism. But what \naspects of a flow\u2019s packet rate should be policed? We can identify three important \npolicing criteria, each differing from the other according to the time scale over which \nthe packet flow is policed:\n\u2022 Average rate.  The network may wish to limit the long-term average rate (packets \nper time interval) at which a flow\u2019s packets can be sent into the network. A crucial \nissue here is the interval of time over which the average rate will be policed. A \nflow whose average rate is limited to 100 packets per second is more constrained \nthan a source that is limited to 6,000 packets per minute, even though both have \nthe same average rate over a long enough interval of time. For example, the latter \nconstraint would allow a flow to send 1,000 packets in a given second-long inter -\nval of time, while the former constraint would disallow this sending behavior.\n\u2022 Peak rate.  While the average-rate constraint limits the amount of traffic that can \nbe sent into the network over a relatively long period of time, a peak-rate con -\nstraint limits the maximum number of packets that can be sent over a shorter \nperiod of time. Using our example above, the network may police a flow at an \naverage rate of 6,000 packets per minute, while limiting the flow\u2019s peak rate to \n1,500 packets per second.\n\u2022 Burst size.  The network may also wish to limit the maximum number of packets \n(the \u201cburst\u201d of packets) that can be sent into the network over an extremely short \ninterval of time. In the limit, as the interval length approaches zero, the burst size \nlimits the number of packets that can be instantaneously sent into the network. \nEven though it is physically impossible to instantaneously send multiple packets \ninto the network (after all, every link has a physical transmission rate that cannot \nbe", "doc_id": "a0cba3bf-336e-407d-94ca-d9fbfc35e22c", "embedding": null, "doc_hash": "793639ab9584c3beb7184e9c7882e3152a16983dc8a5bab08a91548ea47c690d", "extra_info": null, "node_info": {"start": 2205597, "end": 2209385}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "2cc3dfec-0bb3-4bca-933c-a9753c1ece86", "3": "8a420f6f-a273-435f-8e46-c2bf54f73754"}}, "__type__": "1"}, "8a420f6f-a273-435f-8e46-c2bf54f73754": {"__data__": {"text": "period of time, a peak-rate con -\nstraint limits the maximum number of packets that can be sent over a shorter \nperiod of time. Using our example above, the network may police a flow at an \naverage rate of 6,000 packets per minute, while limiting the flow\u2019s peak rate to \n1,500 packets per second.\n\u2022 Burst size.  The network may also wish to limit the maximum number of packets \n(the \u201cburst\u201d of packets) that can be sent into the network over an extremely short \ninterval of time. In the limit, as the interval length approaches zero, the burst size \nlimits the number of packets that can be instantaneously sent into the network. \nEven though it is physically impossible to instantaneously send multiple packets \ninto the network (after all, every link has a physical transmission rate that cannot \nbe exceeded!), the abstraction of a maximum burst size is a useful one.\nThe leaky bucket mechanism is an abstraction that can be used to characterize \nthese policing limits. As shown in Figure 9.14, a leaky bucket consists of a bucket \nthat can hold up to b tokens. Tokens are added to this bucket as follows. New tokens, \nwhich may potentially be added to the bucket, are always being generated at a rate \nof r tokens per second. (We assume here for simplicity that the unit of time is a \nsecond.) If the bucket is filled with less than b tokens when a token is generated, the \nnewly generated token is added to the bucket; otherwise the newly generated token \nis ignored, and the token bucket remains full with b tokens.\nLet us now consider how the leaky bucket can be used to police a packet flow. \nSuppose that before a packet is transmitted into the network, it must first remove a \ntoken from the token bucket. If the token bucket is empty, the packet must wait for \n746     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\na token. (An alternative is for the packet to be dropped, although we will not con -\nsider that option here.) Let us now consider how this behavior polices a traffic flow. \nBecause there can be at most b tokens in the bucket, the maximum burst size for a \nleaky-bucket-policed flow is b packets. Furthermore, because the token generation \nrate is r, the maximum number of packets that can enter the network of any interval \nof time of length t is rt+b. Thus, the token-generation rate, r, serves to limit the \nlong-term average rate at which packets can enter the network. It is also possible to \nuse leaky buckets (specifically, two leaky buckets in series) to police a flow\u2019s peak \nrate in addition to the long-term average rate; see the homework problems at the end \nof this chapter.\nLeaky Bucket \u2219Weighted Fair Queuing \u2219Provable Maximum Delay \nin a Queue\nLet\u2019s close our discussion on policing by showing how the leaky bucket and WFQ \ncan be combined to provide a bound on the delay through a router\u2019s queue. (Readers  \nwho have forgotten about WFQ are encouraged to review WFQ, which is covered \nin Section 4.2.) Let\u2019s consider a router\u2019s output link that multiplexes n flows, each \npoliced by a leaky bucket with parameters bi and ri, i=1, . . . , n, using WFQ  \nscheduling. We use the term flow here loosely to refer to the set of packets that are \nnot distinguished from each other by the scheduler. In practice, a flow might be com -\nprised of traffic from a single end-to-end connection or a collection of many such \nconnections, see Figure 9.15.\nRecall from our discussion of WFQ that each flow, i, is guaranteed to receive a \nshare of the link bandwidth equal to at least R#wi>(gwj), where R is the transmission To networkPackets\nRemove\ntokenToken\nwait areaBucket holds\nup to\nb tokensr token s/sec\nFigure 9.14  \u2666 The leaky bucket policer\n9.5  \u2022", "doc_id": "8a420f6f-a273-435f-8e46-c2bf54f73754", "embedding": null, "doc_hash": "37e9c4ad78f16137ac5fd910be41d8c4f9e0e83cde58b2f38f39cd1bb65a1893", "extra_info": null, "node_info": {"start": 2209315, "end": 2212991}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "a0cba3bf-336e-407d-94ca-d9fbfc35e22c", "3": "4b64f3f2-89f5-43e9-a2ec-458308e8c960"}}, "__type__": "1"}, "4b64f3f2-89f5-43e9-a2ec-458308e8c960": {"__data__": {"text": "with parameters bi and ri, i=1, . . . , n, using WFQ  \nscheduling. We use the term flow here loosely to refer to the set of packets that are \nnot distinguished from each other by the scheduler. In practice, a flow might be com -\nprised of traffic from a single end-to-end connection or a collection of many such \nconnections, see Figure 9.15.\nRecall from our discussion of WFQ that each flow, i, is guaranteed to receive a \nshare of the link bandwidth equal to at least R#wi>(gwj), where R is the transmission To networkPackets\nRemove\ntokenToken\nwait areaBucket holds\nup to\nb tokensr token s/sec\nFigure 9.14  \u2666 The leaky bucket policer\n9.5  \u2022  NETWORK SUPPORT FOR MULTIMEDIA      747\nrate of the link in packets/sec. What then is the maximum delay that a packet will \nexperience while waiting for service in the WFQ (that is, after passing through the \nleaky bucket)? Let us focus on flow 1. Suppose that flow 1\u2019s token bucket is initially \nfull. A burst of b1 packets then arrives to the leaky bucket policer for flow 1. These \npackets remove all of the tokens (without wait) from the leaky bucket and then join \nthe WFQ waiting area for flow 1. Since these b1 packets are served at a rate of at least \nR#wi>(gwj) packet/sec, the last of these packets will then have a maximum delay, \ndmax, until its transmission is completed, where\ndmax=b1\nR#w1>gwj\nThe rationale behind this formula is that if there are b1 packets in the queue and \npackets are being serviced (removed) from the queue at a rate of at least R#w1>(gwj) \npackets per second, then the amount of time until the last bit of the last packet is \ntransmitted cannot be more than b1>(R#w1>(gwj)). A homework problem asks you \nto prove that as long as r16R#w1>(gwj), then dmax is indeed the maximum delay \nthat any packet in flow 1 will ever experience in the WFQ queue.\n9.5.3  Diffserv\nHaving seen the motivation, insights, and specific mechanisms for providing  \nmultiple classes of service, let\u2019s wrap up our study of approaches toward prov -\ning multiple classes of service with an example\u2014the Internet Diffserv architecture \n[RFC 2475; Kilkki 1999]. Diffserv provides service differentiation\u2014that is, the b1r1\nw1\nwnbnrn\nFigure 9.15  \u2666   n multiplexed leaky bucket flows with WFQ scheduling\n748     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\nability to handle different classes of traffic in different ways within the Internet \nin a scalable manner. The need for scalability arises from the fact that millions of \nsimultaneous source-destination traffic flows may be present at a backbone router. \nWe\u2019ll see shortly that this need is met by placing only simple functionality within \nthe network core, with more complex control operations being implemented at the \nnetwork\u2019s edge.\nLet\u2019s begin with the simple network shown in Figure 9.16. We\u2019ll describe one \npossible use of Diffserv here; other variations are possible, as described in RFC \n2475. The Diffserv architecture consists of two sets of functional elements:\n\u2022 Edge functions: Packet classification and traffic conditioning.  At the incoming \nedge of the network (that is, at either a Diffserv-capable host that generates traf -\nfic or at the first Diffserv-capable router that the traffic passes through), arriving \npackets are marked. More specifically, the differentiated service (DS) field in the \nIPv4 or IPv6 packet header is set to some value [RFC 3260]. The definition of \nthe DS field is intended to supersede the earlier definitions of the IPv4 type-of-\nservice field and the", "doc_id": "4b64f3f2-89f5-43e9-a2ec-458308e8c960", "embedding": null, "doc_hash": "39a893a75bb893b1774e9803c54a12552c94f436180cc6abf774d4e6482bedf5", "extra_info": null, "node_info": {"start": 2213125, "end": 2216628}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "8a420f6f-a273-435f-8e46-c2bf54f73754", "3": "b4d4e508-30cb-492a-b3aa-8e5c56ed6e63"}}, "__type__": "1"}, "b4d4e508-30cb-492a-b3aa-8e5c56ed6e63": {"__data__": {"text": "simple network shown in Figure 9.16. We\u2019ll describe one \npossible use of Diffserv here; other variations are possible, as described in RFC \n2475. The Diffserv architecture consists of two sets of functional elements:\n\u2022 Edge functions: Packet classification and traffic conditioning.  At the incoming \nedge of the network (that is, at either a Diffserv-capable host that generates traf -\nfic or at the first Diffserv-capable router that the traffic passes through), arriving \npackets are marked. More specifically, the differentiated service (DS) field in the \nIPv4 or IPv6 packet header is set to some value [RFC 3260]. The definition of \nthe DS field is intended to supersede the earlier definitions of the IPv4 type-of-\nservice field and the IPv6 traffic class fields that we discussed in Chapter 4. For \nexample, in Figure 9.16, packets being sent from H1 to H3 might be marked at \nR1, while packets being sent from H2 to H4 might be marked at R2. The mark \nthat a packet receives identifies the class of traffic to which it belongs. Different \nclasses of traffic will then receive different service within the core network.\nR4\nLeaf r outerKey:\nCore routerR2R1 R6\nR7R3 R5H1\nH2H4\nH3\nR2 R3\nFigure 9.16  \u2666 A simple Diffserv network example\n9.5  \u2022  NETWORK SUPPORT FOR MULTIMEDIA      749\n\u2022 Core function: Forwarding.  When a DS-marked packet arrives at a Diffserv-  \ncapable router, the packet is forwarded onto its next hop according to the so-\ncalled per-hop behavior (PHB) associated with that packet\u2019s class. The per-hop \nbehavior influences how a router\u2019s buffers and link bandwidth are shared among \nthe competing classes of traffic. A crucial tenet of the Diffserv architecture is that \na router\u2019s per-hop behavior will be based only on packet markings, that is, the \nclass of traffic to which a packet belongs. Thus, if packets being sent from H1 to \nH3 in Figure 9.16 receive the same marking as packets being sent from H2 to H4, \nthen the network routers treat these packets as an aggregate, without distinguishing \nwhether the packets originated at H1 or H2. For example, R3 would not distin -\nguish between packets from H1 and H2 when forwarding these packets on to R4. \nThus, the Diffserv architecture obviates the need to keep router state for individual \nsource-destination pairs\u2014a critical consideration in making Diffserv scalable.\nAn analogy might prove useful here. At many large-scale social events (for example, \na large public reception, a large dance club or discoth\u00e8que, a concert, or a football \ngame), people entering the event receive a pass of one type or another: VIP passes \nfor Very Important People; over-21 passes for people who are 21 years old or older \n(for example, if alcoholic drinks are to be served); backstage passes at concerts; press \npasses for reporters; even an ordinary pass for the Ordinary Person. These passes \nare typically distributed upon entry to the event, that is, at the edge of the event. It \nis here at the edge where computationally intensive operations, such as paying for \nentry, checking for the appropriate type of invitation, and matching an invitation \nagainst a piece of identification, are performed. Furthermore, there may be a limit on \nthe number of people of a given type that are allowed into an event. If there is such \na limit, people may have to wait before entering the event. Once inside the event, \none\u2019s pass allows one to receive differentiated service at many locations around the \nevent\u2014a VIP is provided with free drinks, a better table, free food, entry to exclusive \nrooms, and fawning service. Conversely, an ordinary person is excluded from cer -\ntain areas, pays for drinks, and receives only basic service. In both cases, the service \nreceived within the event depends", "doc_id": "b4d4e508-30cb-492a-b3aa-8e5c56ed6e63", "embedding": null, "doc_hash": "f5be5e5f0094c868de54d5bab45f7a91e5614044b6d7b660ea1b7c8c49d15719", "extra_info": null, "node_info": {"start": 2216533, "end": 2220292}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "4b64f3f2-89f5-43e9-a2ec-458308e8c960", "3": "8be020db-f71d-4fe9-96d2-dfbfc068f75d"}}, "__type__": "1"}, "8be020db-f71d-4fe9-96d2-dfbfc068f75d": {"__data__": {"text": "at the edge of the event. It \nis here at the edge where computationally intensive operations, such as paying for \nentry, checking for the appropriate type of invitation, and matching an invitation \nagainst a piece of identification, are performed. Furthermore, there may be a limit on \nthe number of people of a given type that are allowed into an event. If there is such \na limit, people may have to wait before entering the event. Once inside the event, \none\u2019s pass allows one to receive differentiated service at many locations around the \nevent\u2014a VIP is provided with free drinks, a better table, free food, entry to exclusive \nrooms, and fawning service. Conversely, an ordinary person is excluded from cer -\ntain areas, pays for drinks, and receives only basic service. In both cases, the service \nreceived within the event depends solely on the type of one\u2019s pass. Moreover, all \npeople within a class are treated alike.\nFigure 9. 17 provides a logical view of the classification and marking functions \nwithin the edge router. Packets arriving to the edge router are first classified. The \nclassifier selects packets based on the values of one or more packet header fields (for \nexample, source address, destination address, source port, destination port, and pro -\ntocol ID) and steers the packet to the appropriate marking function. As noted above, \na packet\u2019s marking is carried in the DS field in the packet header.\nIn some cases, an end user may have agreed to limit its packet-sending rate to \nconform to a declared traffic profile . The traffic profile might contain a limit on the \npeak rate, as well as the burstiness of the packet flow, as we saw previously with the \nleaky bucket mechanism. As long as the user sends packets into the network in a  \nway that conforms to the negotiated traffic profile, the packets receive their priority \n750     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\nmarking and are forwarded along their route to the destination. On the other hand, \nif the traffic profile is violated, out-of-profile packets might be marked differently, \nmight be shaped (for example, delayed so that a maximum rate constraint would be \nobserved), or might be dropped at the network edge. The role of the metering function ,  \nshown in Figure 9.17, is to compare the incoming packet flow with the negotiated \ntraffic profile and to determine whether a packet is within the negotiated traffic pro -\nfile. The actual decision about whether to immediately remark, forward, delay, or \ndrop a packet is a policy issue determined by the network administrator and is not \nspecified in the Diffserv architecture.\nSo far, we have focused on the marking and policing functions in the Diffserv \narchitecture. The second key component of the Diffserv architecture involves the \nper-hop behavior (PHB) performed by Diffserv-capable routers. PHB is rather cryp -\ntically, but carefully, defined as \u201ca description of the externally observable forward -\ning behavior of a Diffserv node applied to a particular Diffserv behavior aggregate\u201d \n[RFC 2475]. Digging a little deeper into this definition, we can see several important \nconsiderations embedded within:\n\u2022 A PHB can result in different classes of traffic receiving different performance \n(that is, different externally observable forwarding behaviors).\n\u2022 While a PHB defines differences in performance (behavior) among classes, it \ndoes not mandate any particular mechanism for achieving these behaviors. As \nlong as the externally observable performance criteria are met, any implemen -\ntation mechanism and any buffer/bandwidth allocation policy can be used. For \nexample, a PHB would not require that a particular packet-queuing discipline (for \nexample, a priority queue versus a WFQ queue versus a FCFS queue) be used to \nachieve a particular behavior. The PHB is the end, to which resource allocation \nand implementation mechanisms are the means.\n\u2022 Differences in performance must be observable and hence measurable.Packets", "doc_id": "8be020db-f71d-4fe9-96d2-dfbfc068f75d", "embedding": null, "doc_hash": "71ae732c7be8e31264beeb8c4ccc2316a0743f4c0b4a56e2d72e50fd6f099abb", "extra_info": null, "node_info": {"start": 2220223, "end": 2224213}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "b4d4e508-30cb-492a-b3aa-8e5c56ed6e63", "3": "0372966c-3c2e-4fbd-8ffc-51e4d77748ce"}}, "__type__": "1"}, "0372966c-3c2e-4fbd-8ffc-51e4d77748ce": {"__data__": {"text": "of traffic receiving different performance \n(that is, different externally observable forwarding behaviors).\n\u2022 While a PHB defines differences in performance (behavior) among classes, it \ndoes not mandate any particular mechanism for achieving these behaviors. As \nlong as the externally observable performance criteria are met, any implemen -\ntation mechanism and any buffer/bandwidth allocation policy can be used. For \nexample, a PHB would not require that a particular packet-queuing discipline (for \nexample, a priority queue versus a WFQ queue versus a FCFS queue) be used to \nachieve a particular behavior. The PHB is the end, to which resource allocation \nand implementation mechanisms are the means.\n\u2022 Differences in performance must be observable and hence measurable.Packets ForwardClassi\ufb01er Marker\nDropShaper/\nDropperMeter\nFigure 9.17  \u2666 A simple Diffserv network example\n9.5  \u2022  NETWORK SUPPORT FOR MULTIMEDIA      751\nTwo PHBs have been defined: an expedited forwarding (EF) PHB [RFC 3246] and an \nassured forwarding (AF) PHB [RFC 2597]. The expedited forwarding  PHB speci -\nfies that the departure rate of a class of traffic from a router must equal or exceed \na configured rate. The assured forwarding  PHB divides traffic into four classes, \nwhere each AF class is guaranteed to be provided with some minimum amount of \nbandwidth and buffering.\nLet\u2019s close our discussion of Diffserv with a few observations regarding its ser -\nvice model. First, we have implicitly assumed that Diffserv is deployed within a \nsingle administrative domain, but typically an end-to-end service must be fashioned \nfrom multiple ISPs sitting between communicating end systems. In order to provide \nend-to-end Diffserv service, all the ISPs between the end systems must not only pro -\nvide this service, but most also cooperate and make settlements in order to offer end \ncustomers true end-to-end service. Without this kind of cooperation, ISPs directly \nselling Diffserv service to customers will find themselves repeatedly saying: \u201cYes, \nwe know you paid extra, but we don\u2019t have a service agreement with the ISP that \ndropped and delayed your traffic. I\u2019m sorry that there were so many gaps in your \nVoIP call!\u201d Second, if Diffserv were actually in place and the network ran at only \nmoderate load, most of the time there would be no perceived difference between a \nbest-effort service and a Diffserv service. Indeed, end-to-end delay is usually domi -\nnated by access rates and router hops rather than by queuing delays in the routers. \nImagine the unhappy Diffserv customer who has paid more for premium service but \nfinds that the best-effort service being provided to others almost always has the same \nperformance as premium service!\n9.5.4   Per-Connection Quality-of-Service (QoS) Guarantees: \nResource Reservation and Call Admission\nIn the previous section, we have seen that packet marking and policing, traffic isola -\ntion, and link-level scheduling can provide one class of service with better perfor -\nmance than another. Under certain scheduling disciplines, such as priority scheduling, \nthe lower classes of traffic are essentially \u201cinvisible\u201d to the highest-priority class of \ntraffic. With proper network dimensioning, the highest class of service can indeed \nachieve extremely low packet loss and delay\u2014essentially circuit-like performance. \nBut can the network guarantee  that an ongoing flow in a high-priority traffic class \nwill continue to receive such service throughout the flow\u2019s duration using only the \nmechanisms that we have described so far? It cannot. In this section, we\u2019ll see why \nyet additional network mechanisms and protocols are required when a hard service \nguarantee is provided to individual connections.\nLet\u2019s return to our scenario from Section 9.5.2 and consider two 1 Mbps \naudio applications transmitting their packets over the 1.5 Mbps", "doc_id": "0372966c-3c2e-4fbd-8ffc-51e4d77748ce", "embedding": null, "doc_hash": "99d61130096014f57b3883d58f09a3700e318fff6102ef65971ca25320cc543e", "extra_info": null, "node_info": {"start": 2224238, "end": 2228122}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "8be020db-f71d-4fe9-96d2-dfbfc068f75d", "3": "1402cb4c-8839-4ec4-af61-79b0b189958e"}}, "__type__": "1"}, "1402cb4c-8839-4ec4-af61-79b0b189958e": {"__data__": {"text": "as priority scheduling, \nthe lower classes of traffic are essentially \u201cinvisible\u201d to the highest-priority class of \ntraffic. With proper network dimensioning, the highest class of service can indeed \nachieve extremely low packet loss and delay\u2014essentially circuit-like performance. \nBut can the network guarantee  that an ongoing flow in a high-priority traffic class \nwill continue to receive such service throughout the flow\u2019s duration using only the \nmechanisms that we have described so far? It cannot. In this section, we\u2019ll see why \nyet additional network mechanisms and protocols are required when a hard service \nguarantee is provided to individual connections.\nLet\u2019s return to our scenario from Section 9.5.2 and consider two 1 Mbps \naudio applications transmitting their packets over the 1.5 Mbps link, as shown in  \nFigure 9. 18. The combined data rate of the two flows (2 Mbps) exceeds the link \ncapacity. Even with classification and marking, isolation of flows, and sharing of \nunused bandwidth (of which there is none), this is clearly a losing proposition. There \nis simply not enough bandwidth to accommodate the needs of both applications at \n752     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\nthe same time. If the two applications equally share the bandwidth, each application \nwould lose 25 percent of its transmitted packets. This is such an unacceptably low \nQoS that both audio applications are completely unusable; there\u2019s no need even to \ntransmit any audio packets in the first place.\nGiven that the two applications in Figure 9.18 cannot both be satisfied simul -\ntaneously, what should the network do? Allowing both to proceed with an unusable \nQoS wastes network resources on application flows that ultimately provide no utility \nto the end user. The answer is hopefully clear\u2014one of the application flows should \nbe blocked (that is, denied access to the network), while the other should be allowed \nto proceed on, using the full 1 Mbps needed by the application. The telephone net -\nwork is an example of a network that performs such call blocking\u2014if the required \nresources (an end-to-end circuit in the case of the telephone network) cannot be allo -\ncated to the call, the call is blocked (prevented from entering the network) and a busy \nsignal is returned to the user. In our example, there is no gain in allowing a flow into \nthe network if it will not receive a sufficient QoS to be considered usable. Indeed, \nthere is a cost to admitting a flow that does not receive its needed QoS, as network \nresources are being used to support a flow that provides no utility to the end user.\nBy explicitly admitting or blocking flows based on their resource requirements, \nand the source requirements of already-admitted flows, the network can guarantee \nthat admitted flows will be able to receive their requested QoS. Implicit in the need \nto provide a guaranteed QoS to a flow is the need for the flow to declare its QoS \nrequirements. This process of having a flow declare its QoS requirement, and then \nhaving the network either accept the flow (at the required QoS) or block the flow is \nreferred to as the call admission  process. This then is our fourth insight (in addi -\ntion to the three earlier insights from Section 9.5.2,) into the mechanisms needed to \nprovide QoS.R1\n1.5 Mbps link1 Mbps\naudio\n1 Mbps\naudioR2\nH2H1\nH4H3\nFigure 9.18  \u2666   Two competing audio applications overloading the  \nR1-to-R2 link\n9.5  \u2022  NETWORK SUPPORT FOR MULTIMEDIA      753\nInsight 4:  If sufficient resources will not always be available, and QoS is \nto be guaranteed , a call admission process is needed in which flows declare \ntheir QoS requirements and are then either admitted to the network (at the \nrequired QoS) or blocked from the network (if the required QoS cannot be \nprovided by the network).\nOur motivating example in Figure 9.18", "doc_id": "1402cb4c-8839-4ec4-af61-79b0b189958e", "embedding": null, "doc_hash": "e52641a5b071d5d585d1178177931031289bc66fbe642eb2edff747c0b961303", "extra_info": null, "node_info": {"start": 2228110, "end": 2231968}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "0372966c-3c2e-4fbd-8ffc-51e4d77748ce", "3": "4b3519c6-7117-4f27-ab96-b977d4d56577"}}, "__type__": "1"}, "4b3519c6-7117-4f27-ab96-b977d4d56577": {"__data__": {"text": "the three earlier insights from Section 9.5.2,) into the mechanisms needed to \nprovide QoS.R1\n1.5 Mbps link1 Mbps\naudio\n1 Mbps\naudioR2\nH2H1\nH4H3\nFigure 9.18  \u2666   Two competing audio applications overloading the  \nR1-to-R2 link\n9.5  \u2022  NETWORK SUPPORT FOR MULTIMEDIA      753\nInsight 4:  If sufficient resources will not always be available, and QoS is \nto be guaranteed , a call admission process is needed in which flows declare \ntheir QoS requirements and are then either admitted to the network (at the \nrequired QoS) or blocked from the network (if the required QoS cannot be \nprovided by the network).\nOur motivating example in Figure 9.18 highlights the need for several new network \nmechanisms and protocols if a call (an end-to-end flow) is to be guaranteed a given \nquality of service once it begins:\n\u2022 Resource reservation.   The only way to guarantee  that a call will have the resources \n(link bandwidth, buffers) needed to meet its desired QoS is to explicitly allocate \nthose resources to the call\u2014a process known in networking parlance as resource \nreservation . Once resources are reserved, the call has on-demand access to these \nresources throughout its duration, regardless of the demands of all other calls. If \na call reserves and receives a guarantee of x Mbps of link bandwidth, and never \ntransmits at a rate greater than x, the call will see loss- and delay-free performance.\n\u2022 Call admission.  If resources are to be reserved, then the network must have a \nmechanism for calls to request and reserve resources. Since resources are not \ninfinite, a call making a call admission request will be denied admission, that is, \nbe blocked, if the requested resources are not available. Such a call admission \nis performed by the telephone network\u2014we request resources when we dial a \nnumber. If the circuits (TDMA slots) needed to complete the call are available, \nthe circuits are allocated and the call is completed. If the circuits are not avail -\nable, then the call is blocked, and we receive a busy signal. A blocked call can try \nagain to gain admission to the network, but it is not allowed to send traffic into the \nnetwork until it has successfully completed the call admission process. Of course, \na router that allocates link bandwidth should not allocate more than is available \nat that link. Typically, a call may reserve only a fraction of the link\u2019s bandwidth, \nand so a router may allocate link bandwidth to more than one call. However, the \nsum of the allocated bandwidth to all calls should be less than the link capacity if \nhard quality of service guarantees are to be provided.\n\u2022 Call setup signaling.  The call admission process described above requires that a \ncall be able to reserve sufficient resources at each and every network router on its \nsource-to-destination path to ensure that its end-to-end QoS requirement is met. \nEach router must determine the local resources required by the session, consider \nthe amounts of its resources that are already committed to other ongoing sessions, \nand determine whether it has sufficient resources to satisfy the per-hop QoS \nrequirement of the session at this router without violating local QoS guarantees \nmade to an already-admitted session. A signaling protocol is needed to coordinate \nthese various activities\u2014the per-hop allocation of local resources, as well as the \noverall end-to-end decision of whether or not the call has been able to reserve suf -\n754     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\nficient resources at each and every router on the end-to-end path. This is the job \nof the call setup protocol , as shown in Figure 9.19. The RSVP protocol  [Zhang \n1993, RFC 2210] was proposed for this purpose within an Internet architecture \nfor providing quality-of-service guarantees. In ATM networks, the Q2931b pro -\ntocol [Black", "doc_id": "4b3519c6-7117-4f27-ab96-b977d4d56577", "embedding": null, "doc_hash": "645c071c100a73db8bc2f97dff8f45071706fea3feb79898634184796a746db1", "extra_info": null, "node_info": {"start": 2232119, "end": 2235952}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "1402cb4c-8839-4ec4-af61-79b0b189958e", "3": "55416b58-22b0-4740-9c4e-2fe239247b72"}}, "__type__": "1"}, "55416b58-22b0-4740-9c4e-2fe239247b72": {"__data__": {"text": "without violating local QoS guarantees \nmade to an already-admitted session. A signaling protocol is needed to coordinate \nthese various activities\u2014the per-hop allocation of local resources, as well as the \noverall end-to-end decision of whether or not the call has been able to reserve suf -\n754     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\nficient resources at each and every router on the end-to-end path. This is the job \nof the call setup protocol , as shown in Figure 9.19. The RSVP protocol  [Zhang \n1993, RFC 2210] was proposed for this purpose within an Internet architecture \nfor providing quality-of-service guarantees. In ATM networks, the Q2931b pro -\ntocol [Black 1995] carries this information among the ATM network\u2019s switches \nand end point.\nDespite a tremendous amount of research and development, and even products \nthat provide for per-connection quality of service guarantees, there has been almost \nno extended deployment of such services. There are many possible reasons. First and \nforemost, it may well be the case that the simple application-level mechanisms that \nwe studied in Sections 9.2 through 9.4, combined with proper network dimensioning \n(Section 9. 5.1) provide \u201cgood enough\u201d best-effort network service for multimedia \napplications. In addition, the added complexity and cost of deploying and managing \na network that provides per-connection quality of service guarantees may be judged \nby ISPs to be simply too high given predicted customer revenues for that service.\n9.6 Summary\nMultimedia networking is one of the most exciting developments in the Internet \ntoday. People throughout the world less and less time in front of their televisions, \nand are instead use their smartphones and devices to receive audio and video trans -QoS call signaling setup\nRequest/reply\nFigure 9.19  \u2666 The call setup process\nHOMEWORK PROBLEMS AND QUESTIONS      755\nmissions, both live and prerecorded. Moreover, with sites like YouTube, users have \nbecome producers as well as consumers of multimedia Internet content. In addition \nto video distribution, the Internet is also being used to transport phone calls. In fact, \nover the next 10 years, the Internet, along with wireless Internet access, may make \nthe traditional circuit-switched telephone system a thing of the past. VoIP not only \nprovides phone service inexpensively, but also provides numerous value-added ser -\nvices, such as video conferencing, online directory services, voice messaging, and \nintegration into social networks such as Facebook and WeChat.\nIn Section 9.1, we described the intrinsic characteristics of video and voice, and \nthen classified multimedia applications into three categories: (i) streaming stored \naudio/video, (ii) conversational voice/video-over-IP, and (iii) streaming live audio/\nvideo.\nIn Section 9.2, we studied streaming stored video in some depth. For stream -\ning video applications, prerecorded videos are placed on servers, and users send \nrequests to these servers to view the videos on demand. We saw that streaming \nvideo systems can be classified into two categories: UDP streaming and HTTP. \nWe observed that the most important performance measure for streaming video is \naverage throughput.\nIn Section 9.3, we examined how conversational multimedia applications, such \nas VoIP, can be designed to run over a best-effort network. For conversational mul -\ntimedia, timing considerations are important because conversational applications \nare highly delay-sensitive. On the other hand, conversational multimedia applica -\ntions are loss\u2014tolerant\u2014occasional loss only causes occasional glitches in audio/\nvideo playback, and these losses can often be partially or fully concealed. We saw \nhow a combination of client buffers, packet sequence numbers, and timestamps can \ngreatly alleviate the effects of network-induced jitter. We also surveyed the tech -\nnology behind Skype, one of the leading voice- and", "doc_id": "55416b58-22b0-4740-9c4e-2fe239247b72", "embedding": null, "doc_hash": "b13a256ae91b4d305a5d8e1eff219beb52ebecb6899127030c32ceea5c7c0ff4", "extra_info": null, "node_info": {"start": 2235924, "end": 2239856}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "4b3519c6-7117-4f27-ab96-b977d4d56577", "3": "c63bb663-8844-4694-9ec4-c1b1ceccf389"}}, "__type__": "1"}, "c63bb663-8844-4694-9ec4-c1b1ceccf389": {"__data__": {"text": "for streaming video is \naverage throughput.\nIn Section 9.3, we examined how conversational multimedia applications, such \nas VoIP, can be designed to run over a best-effort network. For conversational mul -\ntimedia, timing considerations are important because conversational applications \nare highly delay-sensitive. On the other hand, conversational multimedia applica -\ntions are loss\u2014tolerant\u2014occasional loss only causes occasional glitches in audio/\nvideo playback, and these losses can often be partially or fully concealed. We saw \nhow a combination of client buffers, packet sequence numbers, and timestamps can \ngreatly alleviate the effects of network-induced jitter. We also surveyed the tech -\nnology behind Skype, one of the leading voice- and video-over-IP companies. In  \nSection 9. 4, we examined two of the most important standardized protocols for \nVoIP, namely, RTP and SIP.\nIn Section 9.5, we introduced how several network mechanisms (link-level \nscheduling disciplines and traffic policing) can be used to provide differentiated ser -\nvice among several classes of traffic.\nHomework Problems and Questions\nChapter 9 Review Questions\nSECTION 9.1\n R1. Reconstruct Table 9.1 for when Victor Video is watching a 5 Mbps video, \nFacebook Frank is looking at a new 150 Kbyte image every 25 seconds, and \nMartha Music is listening to 210 kbps audio stream. \n756     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\n R2. For 128 quantization levels, what is the size of each sample signal?\n R3. Suppose an analog audio signal is sampled 8,000 times per second, and each \nsample is quantized into one of 512 levels. What would be the resulting bit \nrate of the PCM digital audio signal?\n R4. Many Internet companies today provide streaming video, including YouTube \n(Google), Netflix, and Hulu. Streaming stored video has three key distinguishing \nfeatures. List them.\nSECTION 9.2\n R5. What are advantages of client buffering?\n R6. In video streaming applications, why is HTTP streaming more popular than \nUDP streaming? \n R7. With HTTP streaming, are the TCP receive buffer and the client\u2019s application \nbuffer the same thing? If not, how do they interact?\n R8. Consider the simple model for HTTP streaming. Suppose the server sends \nbits at a constant rate of 2 Mbps and playback begins when 8 million bits \nhave been received. What is the initial buffering delay tp?\nSECTION 9.3\n R9. What mechanisms are used at the receiver side to eliminate packet jitter?\n R10. What are the two types of loss anticipation schemes used in VoIP?\n R11. Section 9.3 describes two FEC schemes. Briefly summarize them. Both \nschemes increase the transmission rate of the stream by adding overhead. \nDoes interleaving also increase the transmission rate?\nSECTION 9.4\n R12. What are the four main RTP header fields?\n R13. What is network dimensioning?\nProblems\n P1. Consider the figure below. Similar to our discussion of Figure 9.1, suppose \nthat video is encoded at a fixed bit rate, and thus each video block contains \nvideo frames that are to be played out over the same fixed amount of time, \u25b3.  \nThe server transmits the first video block at t0, the second block at t0+\u25b3,  \nPROBLEMS      757\nthe third block at t0+2\u25b3, and so on. Once the client begins playout, each \nblock should be played out \u25b3 time units after the previous block.\nConstant bit\nrate video\ntransmission\nby server\n123456789\nTimeDD DDDDDDDDDVideo block number\nt0 t1Video\nreception\nat client\na. Suppose that the client begins playout as soon as the first block arrives \nat t1. In the figure below, how many blocks of video (including the first \nblock) will have arrived at the client in time for their", "doc_id": "c63bb663-8844-4694-9ec4-c1b1ceccf389", "embedding": null, "doc_hash": "9dd50268e136ca55002ec86e3037c140110a01cc874031aab4940852f6aff324", "extra_info": null, "node_info": {"start": 2239771, "end": 2243424}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "55416b58-22b0-4740-9c4e-2fe239247b72", "3": "b6be149a-2ebc-4488-af3e-b1a778c7e73f"}}, "__type__": "1"}, "b6be149a-2ebc-4488-af3e-b1a778c7e73f": {"__data__": {"text": "and thus each video block contains \nvideo frames that are to be played out over the same fixed amount of time, \u25b3.  \nThe server transmits the first video block at t0, the second block at t0+\u25b3,  \nPROBLEMS      757\nthe third block at t0+2\u25b3, and so on. Once the client begins playout, each \nblock should be played out \u25b3 time units after the previous block.\nConstant bit\nrate video\ntransmission\nby server\n123456789\nTimeDD DDDDDDDDDVideo block number\nt0 t1Video\nreception\nat client\na. Suppose that the client begins playout as soon as the first block arrives \nat t1. In the figure below, how many blocks of video (including the first \nblock) will have arrived at the client in time for their playout? Explain \nhow you arrived at your answer.\nb. Suppose that the client begins playout now at t1+\u25b3. How many blocks \nof video (including the first block) will have arrived at the client in time \nfor their playout? Explain how you arrived at your answer.\nc. In the same scenario at (b) above, what is the largest number of blocks \nthat is ever stored in the client buffer, awaiting playout? Explain how you \narrived at your answer.\nd. What is the smallest playout delay at the client, such that every video block \nhas arrived in time for its playout? Explain how you arrived at your answer.\n P2. Recall the simple model for HTTP streaming shown in Figure 9.3. Recall that \nB denotes the size of the client\u2019s application buffer, and Q denotes the num-\nber of bits that must be buffered before the client application begins playout. \nAlso r denotes the video consumption rate. Assume that the server sends bits \nat a constant rate x whenever the client buffer is not full.\na. Suppose that x6r. As discussed in the text, in this case playout will \nalternate between periods of continuous playout and periods of freezing. \nDetermine the length of each continuous playout and freezing period as a \nfunction of Q, r, and x.\nb. Now suppose that x7r. At what time t=tf does the client application \nbuffer become full?\n758     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\n P3. Recall the simple model for HTTP streaming shown in Figure 9.3. Suppose \nthe buffer size is infinite but the server sends bits at variable rate x(t). Specifi-\ncally, suppose x(t) has the following saw-tooth shape. The rate is initially \nzero at time t=0 and linearly climbs to H at time t=T. It then repeats this \npattern again and again, as shown in the figure below.\nH\nTimeT 2T 3T 4TBit rate x(t)\na. What is the server\u2019s average send rate?\nb. Suppose that Q=0, so that the client starts playback as soon as it \nreceives a video frame. What will happen?\nc. Now suppose Q70 and HT/2\u00daQ. Determine as a function of Q, H, \nand T the time at which playback first begins.\nd. Suppose H72r and Q=HT/2. Prove there will be no freezing after the \ninitial playout delay.\ne. Suppose H72r. Find the smallest value of Q such that there will be no \nfreezing after the initial playback delay.\nf. Now suppose that the buffer size B is finite. Suppose H72r. As a func-\ntion of Q, B, T, and H, determine the time t=tf when the client applica-\ntion buffer first becomes full.\n P4. Consider the following in the context of prefetching. Suppose the video \nconsumption rate is 2 Mbps but the network is capable of delivering the  \nvideo from server to client at a constant rate of 2.5 Mbps. Then the client \nwill not only be able to play out the video with a very small playout delay,  \nbut will also be able to increase the amount of buffered video data by \n500\u00a0Kbits every second. In this", "doc_id": "b6be149a-2ebc-4488-af3e-b1a778c7e73f", "embedding": null, "doc_hash": "8dad14cdd1a6ce3561d28a603a98c2278d0ab70e97cbd44857df45897f830718", "extra_info": null, "node_info": {"start": 2243508, "end": 2247028}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "c63bb663-8844-4694-9ec4-c1b1ceccf389", "3": "81f78aeb-a0c5-4645-b4ff-7dcacb66c7e3"}}, "__type__": "1"}, "81f78aeb-a0c5-4645-b4ff-7dcacb66c7e3": {"__data__": {"text": "delay.\ne. Suppose H72r. Find the smallest value of Q such that there will be no \nfreezing after the initial playback delay.\nf. Now suppose that the buffer size B is finite. Suppose H72r. As a func-\ntion of Q, B, T, and H, determine the time t=tf when the client applica-\ntion buffer first becomes full.\n P4. Consider the following in the context of prefetching. Suppose the video \nconsumption rate is 2 Mbps but the network is capable of delivering the  \nvideo from server to client at a constant rate of 2.5 Mbps. Then the client \nwill not only be able to play out the video with a very small playout delay,  \nbut will also be able to increase the amount of buffered video data by \n500\u00a0Kbits every second. In this manner, if in the future, the client receives \ndata at a rate of less than 2 Mbps for a brief period of time, the client will \nbe able to continue to provide continuous playback due to the reserve in \nits buffer. At what throughput does streaming over TCP result in minimal \nstarvation and low buffering delays?\nPROBLEMS      759\n P5. As an example of jitter, consider two consecutive packets in our VoIP appli -\ncation. The sender sends the second packet 20 msecs after sending the first \npacket. But at the receiver, the spacing between these packets can become \ngreater than 20 msecs. To see this, suppose the first packet arrives at a nearly \nempty queue at a router, but just before the second packet arrives at the queue a \nlarge number of packets from other sources arrive at the same queue. Because \nthe first packet experiences a small queuing delay and the second packet suffers \na large queuing delay at this router, the first and second packets become spaced \nby more than 20 msecs. Give an analogy with driving cars on roads. \n P6. In the VoIP example in Section 9.3, let h be the total number of header byte \nadded to each chunk, including UDP and IP header.\na. Assuming an IP datagram is emitted every 40 msecs, find the transmission rate \nin bits per second for the datagrams generated by one side of this application.\nb. What is a typical value of h when RTP is used? How much time is \nrequired to transmit the header?\n P7. Consider the procedure described in Section 9.3 for estimating average delay \ndi. Suppose that u=0.1. Let r1-t1 be the most recent sample delay, let \nr2-t2 be the next most recent sample delay, and so on.\na. For a given audio application suppose four packets have arrived at the \nreceiver with sample delays r4-t4, r3-t3, r2-t2, and r1-t1. Express \nthe estimate of delay d in terms of the four samples.\nb. Generalize your formula for n sample delays.\nc. For the formula in part (b), let n approach infinity and give the resulting \nformula. Comment on why this averaging procedure is called an exponen-\ntial moving average.\n P8. Repeat parts (a) and (b) in Question P7 for the estimate of average delay deviation.\n P9. For the VoIP example in Section 9.3, we introduced an online procedure \n(exponential moving average) for estimating delay. In this problem we will \nexamine an alternative procedure. Let ti be the timestamp of the ith packet \nreceived; let ri be the time at which the ith packet is received. Let dn be our \nestimate of average delay after receiving the nth packet. After the first packet \nis received, we set the delay estimate equal to d1=r1-t1.\na. Suppose that we would like dn=(r1-t1+r2-t2+g+rn-tn)/n \nfor all n. Give a recursive formula for dn in terms of dn-1, rn, and tn.\nb. Describe why for Internet telephony, the delay estimate described in  \nSection 9. 3 is more appropriate than the delay estimate outlined in part", "doc_id": "81f78aeb-a0c5-4645-b4ff-7dcacb66c7e3", "embedding": null, "doc_hash": "b0d1022922962e62164469ebd48cf0a51798f04617cc1df98d5adf452b216271", "extra_info": null, "node_info": {"start": 2247014, "end": 2250612}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "b6be149a-2ebc-4488-af3e-b1a778c7e73f", "3": "feadf6fd-deed-4b51-91d4-bea1cfb022ab"}}, "__type__": "1"}, "feadf6fd-deed-4b51-91d4-bea1cfb022ab": {"__data__": {"text": "we introduced an online procedure \n(exponential moving average) for estimating delay. In this problem we will \nexamine an alternative procedure. Let ti be the timestamp of the ith packet \nreceived; let ri be the time at which the ith packet is received. Let dn be our \nestimate of average delay after receiving the nth packet. After the first packet \nis received, we set the delay estimate equal to d1=r1-t1.\na. Suppose that we would like dn=(r1-t1+r2-t2+g+rn-tn)/n \nfor all n. Give a recursive formula for dn in terms of dn-1, rn, and tn.\nb. Describe why for Internet telephony, the delay estimate described in  \nSection 9. 3 is more appropriate than the delay estimate outlined in part (a).\n P10. With the fixed-delay strategy, the receiver attempts to play out each chunk \nexactly q msecs after the chunk is generated. So if a chunk is timestamped at \nthe sender at time t, the receiver plays out the chunk at time t 1 q, assuming \nthe chunk has arrived by that time. Packets that arrive after their scheduled \nplayout times are discarded and considered lost. What is a good choice for q? \n760     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\n P11. Consider the figure below (which is similar to Figure 9.3). A sender begins \nsending packetized audio periodically at t=1. The first packet arrives at the \nreceiver at t=8.\nPackets\ngenerated\nTimePackets\n18Packets\nreceived\na. What are the delays (from sender to receiver, ignoring any playout delays) \nof packets 2 through 8? Note that each vertical and horizontal line segment \nin the figure has a length of 1, 2, or 3 time units.\nb. If audio playout begins as soon as the first packet arrives at the receiver at \nt=8, which of the first eight packets sent will not arrive in time for playout?\nc. If audio playout begins at t=9, which of the first eight packets sent will \nnot arrive in time for playout?\nd. What is the minimum playout delay at the receiver that results in all of the \nfirst eight packets arriving in time for their playout?\n P12. Consider again the figure in P11, showing packet audio transmission and \nreception times.\na. Compute the estimated delay for packets 2 through 8, using the formula \nfor di from Section 9.3.2. Use a value of u=0.1.\nb. Compute the estimated deviation of the delay from the estimated average \nfor packets 2 through 8, using the formula for vi from Section 9.3.2. Use a \nvalue of u=0.1.\n P13. A is at her PC and she wants to call B, who is also working at his PC. A\u2019s and \nB\u2019s PCs are both equipped with SIP-based software for making and receiving \nphone calls. Assume that A knows the IP address of B\u2019s PC. Illustrate the SIP \ncall-establishment process. \nPROBLEMS      761\n P14. a.  Consider an audio conference call in Skype with N72 participants.  \nSuppose each participant generates a constant stream of rate r bps. How \nmany bits per second will the call initiator need to send? How many bits \nper second will each of the other N-1 participants need to send? What is \nthe total send rate, aggregated over all participants?\nb. Repeat part (a) for a Skype video conference call using a central server.\nc. Repeat part (b), but now for when each peer sends a copy of its video \nstream to each of the N-1 other peers.\n P15. a.  Suppose we send into the Internet two IP datagrams, each carrying a \ndifferent UDP segment. The first datagram has source IP address A1, \ndestination IP address B, source port P1, and destination port T. The \nsecond datagram has source IP address A2, destination IP address B, \nsource port", "doc_id": "feadf6fd-deed-4b51-91d4-bea1cfb022ab", "embedding": null, "doc_hash": "7a55dd20c904bdc9ca072a2b5357a58fe4e973da8a65d280916615e0b9a21c20", "extra_info": null, "node_info": {"start": 2250625, "end": 2254133}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "81f78aeb-a0c5-4645-b4ff-7dcacb66c7e3", "3": "74bb21af-d11c-4317-bd73-991e49635380"}}, "__type__": "1"}, "74bb21af-d11c-4317-bd73-991e49635380": {"__data__": {"text": "participant generates a constant stream of rate r bps. How \nmany bits per second will the call initiator need to send? How many bits \nper second will each of the other N-1 participants need to send? What is \nthe total send rate, aggregated over all participants?\nb. Repeat part (a) for a Skype video conference call using a central server.\nc. Repeat part (b), but now for when each peer sends a copy of its video \nstream to each of the N-1 other peers.\n P15. a.  Suppose we send into the Internet two IP datagrams, each carrying a \ndifferent UDP segment. The first datagram has source IP address A1, \ndestination IP address B, source port P1, and destination port T. The \nsecond datagram has source IP address A2, destination IP address B, \nsource port P2, and destination port T. Suppose that A1 is different from \nA2 and that P1 is different from P2. Assuming that both datagrams reach \ntheir final destination, will the two UDP datagrams be received by the \nsame socket? Why or why not?\nb. Suppose Alice, Bob, and Claire want to have an audio conference call \nusing SIP and RTP. For Alice to send and receive RTP packets to and \nfrom Bob and Claire, is only one UDP socket sufficient (in addition to \nthe socket needed for the SIP messages)? If yes, then how does Alice\u2019s \nSIP client distinguish between the RTP packets received from Bob and \nClaire?\n P16. True or false:\na. If stored video is streamed directly from a Web server to a media player, \nthen the application is using TCP as the underlying transport protocol.\nb. When using RTP, it is possible for a sender to change encoding in the \nmiddle of a session.\nc. All applications that use RTP must use port 87.\nd. If an RTP session has a separate audio and video stream for each sender, \nthen the audio and video streams use the same SSRC.\ne. In differentiated services, while per-hop behavior defines differences in \nperformance among classes, it does not mandate any particular mecha-\nnism for achieving these performances.\n762     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\nf. Suppose Alice wants to establish an SIP session with Bob. In her INVITE \nmessage she includes the line: m=audio 48753 RTP/AVP 3 (AVP 3 denotes \nGSM audio). Alice has therefore indicated in this message that she wishes \nto send GSM audio.\ng. Referring to the preceding statement, Alice has indicated in her INVITE \nmessage that she will send audio to port 48753.\nh. SIP messages are typically sent between SIP entities using a default SIP \nport number.\ni. In order to maintain registration, SIP clients must periodically send  \nREGISTER messages.\nj. SIP mandates that all SIP clients support G.711 audio encoding.\n P17. Consider the figure below, which shows a leaky bucket policer being fed by \na stream of packets. The token buffer can hold at most two tokens, and is \ninitially full at t=0. New tokens arrive at a rate of one token per slot. The \noutput link speed is such that if two packets obtain tokens at the beginning \nof a time slot, they can both go to the output link in the same slot. The tim -\ning details of the system are as follows:\n1. Packets (if any) arrive at the beginning of the slot. Thus in the figure, \npackets 1, 2, and 3 arrive in slot 0. If there are already packets in the \nqueue, then the arriving packets join the end of the queue. Packets pro-\nceed towards the front of the queue in a FIFO manner.\n2. After the arrivals have been added to the queue, if there are any queued \npackets, one or two of those packets (depending on the number of avail-\nable tokens) will each remove a token from the token buffer and go to the \noutput link during that slot. Thus, packets 1 and 2 each remove a token \nfrom", "doc_id": "74bb21af-d11c-4317-bd73-991e49635380", "embedding": null, "doc_hash": "e5257407a0fb21e6a1c801fb5d55a1bb7d4014993b9692644232fd69b580ea2d", "extra_info": null, "node_info": {"start": 2254087, "end": 2257753}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "feadf6fd-deed-4b51-91d4-bea1cfb022ab", "3": "bfc3105b-5fb4-43e5-accf-5ee5306aec02"}}, "__type__": "1"}, "bfc3105b-5fb4-43e5-accf-5ee5306aec02": {"__data__": {"text": "\nof a time slot, they can both go to the output link in the same slot. The tim -\ning details of the system are as follows:\n1. Packets (if any) arrive at the beginning of the slot. Thus in the figure, \npackets 1, 2, and 3 arrive in slot 0. If there are already packets in the \nqueue, then the arriving packets join the end of the queue. Packets pro-\nceed towards the front of the queue in a FIFO manner.\n2. After the arrivals have been added to the queue, if there are any queued \npackets, one or two of those packets (depending on the number of avail-\nable tokens) will each remove a token from the token buffer and go to the \noutput link during that slot. Thus, packets 1 and 2 each remove a token \nfrom the buffer (since there are initially two tokens) and go to the output \nlink during slot 0.Arrivals\nPacket queue\n(wait for tokens)910\n7 6 48 5\n13\n2\nt = 8 t = 6 t = 4 t = 2 t = 0 t = 4 t = 2 t = 0r = 1 token/slot\nb = 2 tokens\nPROGRAMMING ASSIGNMENT      763\n3. A new token is added to the token buffer if it is not full, since the token \ngeneration rate is r = 1 token/slot.\n4. Time then advances to the next time slot, and these steps repeat.\nAnswer the following questions:\na. For each time slot, identify the packets that are in the queue and the number \nof tokens in the bucket, immediately after the arrivals have been processed \n(step 1 above) but before any of the packets have passed through the queue \nand removed a token. Thus, for the t=0 time slot in the example above, \npackets 1, 2, and 3 are in the queue, and there are two tokens in the buffer.\nb. For each time slot indicate which packets appear on the output after the \ntoken(s) have been removed from the queue. Thus, for the t=0 time slot \nin the example above, packets 1 and 2 appear on the output link from the \nleaky buffer during slot 0.\n P18. Repeat P17 but assume that r=2. Assume again that the bucket is initially full.\n P19. Consider P18 and suppose now that r=3 and that b=2 as before. Will \nyour answer to the question above change?\n P20. Consider the leaky bucket policer that polices the average rate and burst size \nof a packet flow. We now want to police the peak rate, p, as well. Show how \nthe output of this leaky bucket policer can be fed into a second leaky bucket \npolicer so that the two leaky buckets in series police the average rate, peak \nrate, and burst size. Be sure to give the bucket size and token generation rate \nfor the second policer.\n P21. A packet flow is said to conform to a leaky bucket specification ( r, b) with \nburst size b and average rate r if the number of packets that arrive to the \nleaky bucket is less than rt+b packets in every interval of time of length t \nfor all t. Will a packet flow that conforms to a leaky bucket specification  \n(r, b) ever have to wait at a leaky bucket policer with parameters r and b? \nJustify your answer.\n P22.  Show that as long as r16Rw1>(gwj), then dmax is indeed the maximum \ndelay that any packet in flow 1 will ever experience in the WFQ queue.\nProgramming Assignment\nIn this lab, you will implement a streaming video server and client. The client will \nuse the real-time streaming protocol (RTSP) to control the actions of the server. The \nserver will use the real-time protocol (RTP) to packetize the video for transport over \nUDP. You will be given Python code that partially implements RTSP and RTP at \nthe client and server. Your job will be to complete both the client and server code. \n764     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\nWhen you are finished, you", "doc_id": "bfc3105b-5fb4-43e5-accf-5ee5306aec02", "embedding": null, "doc_hash": "92bd21d6fa847376091cf8fd19fdde3853f315118dac937567c878c9735a0d3a", "extra_info": null, "node_info": {"start": 2257804, "end": 2261331}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "74bb21af-d11c-4317-bd73-991e49635380", "3": "d1cca5b0-d600-4deb-9914-b1d795bff567"}}, "__type__": "1"}, "d1cca5b0-d600-4deb-9914-b1d795bff567": {"__data__": {"text": "\nJustify your answer.\n P22.  Show that as long as r16Rw1>(gwj), then dmax is indeed the maximum \ndelay that any packet in flow 1 will ever experience in the WFQ queue.\nProgramming Assignment\nIn this lab, you will implement a streaming video server and client. The client will \nuse the real-time streaming protocol (RTSP) to control the actions of the server. The \nserver will use the real-time protocol (RTP) to packetize the video for transport over \nUDP. You will be given Python code that partially implements RTSP and RTP at \nthe client and server. Your job will be to complete both the client and server code. \n764     CHAPTER 9 \u2002\u2002\u2022 \u2002\u2002 MULTIMEDIA NETWORKING\nWhen you are finished, you will have created a client-server application that does \nthe following:\n\u2022 The client sends SETUP, PLAY, PAUSE, and TEARDOWN RTSP commands, \nand the server responds to the commands.\n\u2022 When the server is in the playing state, it periodically grabs a stored JPEG frame, \npacketizes the frame with RTP, and sends the RTP packet into a UDP socket.\n\u2022 The client receives the RTP packets, removes the JPEG frames, decompresses the \nframes, and renders the frames on the client\u2019s monitor.\nThe code you will be given implements the RTSP protocol in the server and \nthe RTP depacketization in the client. The code also takes care of displaying the \ntransmitted video. You will need to implement RTSP in the client and RTP server. \nThis programming assignment will significantly enhance the student\u2019s understand -\ning of RTP, RTSP, and streaming video. It is highly recommended. The assignment \nalso suggests a number of optional exercises, including implementing the RTSP \nDESCRIBE command at both client and server. You can find full details of the \nassignment, as well as an overview of the RTSP protocol, at the Web site www  \n.pearsonglobaleditions.com/kurose.\n765What made you decide to specialize in multimedia networking?\nThis happened almost by accident. As a PhD student, I got involved with DARTnet, an \nexperimental network spanning the United States with T1 lines. DARTnet was used as a \nproving ground for multicast and Internet real-time tools. That led me to write my first \naudio tool, NeVoT. Through some of the DARTnet participants, I became involved in the \nIETF, in the then-nascent Audio Video Transport working group. This group later ended up \nstandardizing RTP.\nWhat was your first job in the computer industry? What did it entail?\nMy first job in the computer industry was soldering together an Altair computer kit when I \nwas a high school student in Livermore, California. Back in Germany, I started a little con -\nsulting company that devised an address management program for a travel agency\u2014storing \ndata on cassette tapes for our TRS-80 and using an IBM Selectric typewriter with a home-\nbrew hardware interface as a printer.\nMy first real job was with AT&T Bell Laboratories, developing a network emulator for \nconstructing experimental networks in a lab environment.\nWhat are the goals of the Internet Real-Time Lab?\nOur goal is to provide components and building blocks for the Internet as the single future \ncommunications infrastructure. This includes developing new protocols, such as GIST \n(for network-layer signaling) and LoST (for finding resources by location), or enhancing \nprotocols that we have worked on earlier, such as SIP, through work on rich presence, peer-\nto-peer systems, next-generation emergency calling, and service creation tools. Recently, \nwe have also looked extensively at wireless systems for VoIP, as 802.11b and 802.11n net -\nworks and maybe WiMax networks are likely to become important last-mile technologies \nfor telephony. We are also trying to greatly improve the ability of users to diagnose faults \nin the complicated tangle of providers and equipment, using a peer-to-peer fault diagnosis \nsystem called", "doc_id": "d1cca5b0-d600-4deb-9914-b1d795bff567", "embedding": null, "doc_hash": "06ca548b40c628ec78e0b32aa2b6676a5a445f1e7472a420239d0f1d04a45952", "extra_info": null, "node_info": {"start": 2261331, "end": 2265188}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "bfc3105b-5fb4-43e5-accf-5ee5306aec02", "3": "3e34d314-da92-4bf7-a431-99f6b6d2cc11"}}, "__type__": "1"}, "3e34d314-da92-4bf7-a431-99f6b6d2cc11": {"__data__": {"text": "components and building blocks for the Internet as the single future \ncommunications infrastructure. This includes developing new protocols, such as GIST \n(for network-layer signaling) and LoST (for finding resources by location), or enhancing \nprotocols that we have worked on earlier, such as SIP, through work on rich presence, peer-\nto-peer systems, next-generation emergency calling, and service creation tools. Recently, \nwe have also looked extensively at wireless systems for VoIP, as 802.11b and 802.11n net -\nworks and maybe WiMax networks are likely to become important last-mile technologies \nfor telephony. We are also trying to greatly improve the ability of users to diagnose faults \nin the complicated tangle of providers and equipment, using a peer-to-peer fault diagnosis \nsystem called DYSWIS (Do You See What I See).Henning Schulzrinne is a professor, chair of the Department of \nComputer Science, and head of the Internet Real-Time Laboratory \nat Columbia University. He is the co-author of RTP, RTSP, SIP, and \nGIST\u2014key protocols for audio and video communications over \nthe Internet. Henning received his BS in electrical and industrial \nengineering at TU Darmstadt in Germany, his MS in electrical and \ncomputer engineering at the University of Cincinnati, and his PhD in \nelectrical engineering at the University of Massachusetts, Amherst.Henning SchulzrinneAN INTERVIEW WITH . . .\n\n766We try to do practically relevant work, by building prototypes and open source sys -\ntems, by measuring performance of real systems, and by contributing to IETF standards.\nWhat is your vision for the future of multimedia networking?\nWe are now in a transition phase; just a few years shy of when IP will be the universal plat -\nform for multimedia services, from IPTV to VoIP. We expect radio, telephone, and TV to \nbe available even during snowstorms and earthquakes, so when the Internet takes over the \nrole of these dedicated networks, users will expect the same level of reliability.\nWe will have to learn to design network technologies for an ecosystem of compet -\ning carriers, service and content providers, serving lots of technically untrained users \nand defending them against a small, but destructive, set of malicious and criminal users. \nChanging protocols is becoming increasingly hard. They are also becoming more complex, \nas they need to take into account competing business interests, security, privacy, and the \nlack of transparency of networks caused by firewalls and network address translators.\nSince multimedia networking is becoming the foundation for almost all of consumer \nentertainment, there will be an emphasis on managing very large networks, at low cost. \nUsers will expect ease of use, such as finding the same content on all of their devices.\nWhy does SIP have a promising future?\nAs the current wireless network upgrade to 3G networks proceeds, there is the hope of \na single multimedia signaling mechanism spanning all types of networks, from cable \nmodems, to corporate telephone networks and public wireless networks. Together with \nsoftware radios, this will make it possible in the future that a single device can be used \non a home network, as a cordless BlueTooth phone, in a corporate network via 802.11 \nand in the wide area via 3G networks. Even before we have such a single universal wire -\nless device, the personal mobility mechanisms make it possible to hide the differences \nbetween networks. One identifier becomes the universal means of reaching a person, \nrather than remembering or passing around half a dozen technology- or location-specific \ntelephone numbers.\nSIP also breaks apart the provision of voice (bit) transport from voice services. It now \nbecomes technically possible to break apart the local telephone monopoly, where one com -\npany provides neutral bit transport, while others provide IP \u201cdial tone\u201d and the classical \ntelephone services, such as gateways, call forwarding, and caller ID.\nBeyond multimedia signaling, SIP offers a new service that has been missing in the \nInternet: event notification. We have approximated such services with HTTP", "doc_id": "3e34d314-da92-4bf7-a431-99f6b6d2cc11", "embedding": null, "doc_hash": "a1c236183f4f1b131d67f199141a8f812a3bb4bfd8204de5e837975ef5c5b5ca", "extra_info": null, "node_info": {"start": 2265071, "end": 2269200}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "d1cca5b0-d600-4deb-9914-b1d795bff567", "3": "f82de0e1-2638-4662-9ca0-75777eb908c0"}}, "__type__": "1"}, "f82de0e1-2638-4662-9ca0-75777eb908c0": {"__data__": {"text": "Even before we have such a single universal wire -\nless device, the personal mobility mechanisms make it possible to hide the differences \nbetween networks. One identifier becomes the universal means of reaching a person, \nrather than remembering or passing around half a dozen technology- or location-specific \ntelephone numbers.\nSIP also breaks apart the provision of voice (bit) transport from voice services. It now \nbecomes technically possible to break apart the local telephone monopoly, where one com -\npany provides neutral bit transport, while others provide IP \u201cdial tone\u201d and the classical \ntelephone services, such as gateways, call forwarding, and caller ID.\nBeyond multimedia signaling, SIP offers a new service that has been missing in the \nInternet: event notification. We have approximated such services with HTTP kludges and \ne-mail, but this was never very satisfactory. Since events are a common abstraction for dis -\ntributed systems, this may simplify the construction of new services.\n767Do you have any advice for students entering the networking field?\nNetworking bridges disciplines. It draws from electrical engineering, all aspects of computer \nscience, operations research, statistics, economics, and other disciplines. Thus, networking \nresearchers have to be familiar with subjects well beyond protocols and routing algorithms.\nGiven that networks are becoming such an important part of everyday life, students wanting \nto make a difference in the field should think of the new resource constraints in networks: \nhuman time and effort, rather than just bandwidth or storage.\nWork in networking research can be immensely satisfying since it is about allowing \npeople to communicate and exchange ideas, one of the essentials of being human. The \nInternet has become the third major global infrastructure, next to the transportation system \nand energy distribution. Almost no part of the economy can work without high-performance \nnetworks, so there should be plenty of opportunities for the foreseeable future.\nThis page intentionally left blank\n769References\nA note on URLs.  In the references below, we have provided URLs for Web pages, \nWeb-only documents, and other material that has not been published in a confer-\nence or journal (when we have been able to locate a URL for such material). We \nhave not provided URLs for conference and journal publications, as these docu-\nments can usually be located via a search engine, from the conference Web site \n(e.g., papers in all ACM SIGCOMM  conferences and workshops can be located via \nhttp://www.acm.org/sigcomm), or via a digital library subscription. While all URLs \nprovided below were valid (and tested) in Jan. 2016, URLs can become out of date. \nPlease consult the online version of this book (www.pearsonglobaleditions.com/\nkurose) for an up-to-date bibliography.\nA note on Internet Request for Comments (RFCs):  Copies of Internet RFCs are \navailable at many sites. The RFC Editor of the Internet Society (the body that over-\nsees the RFCs) maintains the site, http://www.rfc-editor.org. This site allows you to \nsearch for a specific RFC by title, number, or authors, and will show updates to any \nRFCs listed. Internet RFCs can be updated or obsoleted by later RFCs. Our favorite \nsite for getting RFCs is the original source\u2014http://www.rfc-editor.org.\n[3GPP 2016]  Third Generation Partnership Project homepage, http://www.3gpp.org/\n[Abramson 1970]  N. Abramson, \u201cThe Aloha System\u2014Another Alternative for \nComputer Communications,\u201d Proc. 1970 Fall Joint Computer Conference, AFIPS \nConference , p. 37, 1970.\n[Abramson 1985]  N. Abramson, \u201cDevelopment of the Alohanet,\u201d IEEE Transac-\ntions on Information Theory , Vol. IT-31, No. 3 (Mar. 1985), pp. 119\u2013123.\n[Abramson 2009]  N. Abramson, \u201cThe Alohanet\u2014Surfing for Wireless Data,\u201d \nIEEE Communications Magazine ,", "doc_id": "f82de0e1-2638-4662-9ca0-75777eb908c0", "embedding": null, "doc_hash": "e1791ddd6330d467d874a75c1c96a1d7d6be32cb7984f2ae46aaba77de56ec4d", "extra_info": null, "node_info": {"start": 2269180, "end": 2273035}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "3e34d314-da92-4bf7-a431-99f6b6d2cc11", "3": "7859985d-9838-4f20-be4d-627840497009"}}, "__type__": "1"}, "7859985d-9838-4f20-be4d-627840497009": {"__data__": {"text": "Our favorite \nsite for getting RFCs is the original source\u2014http://www.rfc-editor.org.\n[3GPP 2016]  Third Generation Partnership Project homepage, http://www.3gpp.org/\n[Abramson 1970]  N. Abramson, \u201cThe Aloha System\u2014Another Alternative for \nComputer Communications,\u201d Proc. 1970 Fall Joint Computer Conference, AFIPS \nConference , p. 37, 1970.\n[Abramson 1985]  N. Abramson, \u201cDevelopment of the Alohanet,\u201d IEEE Transac-\ntions on Information Theory , Vol. IT-31, No. 3 (Mar. 1985), pp. 119\u2013123.\n[Abramson 2009]  N. Abramson, \u201cThe Alohanet\u2014Surfing for Wireless Data,\u201d \nIEEE Communications Magazine , Vol. 47, No. 12, pp. 21\u201325.\n[Adhikari 2011a]  V. K. Adhikari, S. Jain, Y. Chen, Z. L. Zhang, \u201cVivisecting \nYouTube: An Active Measurement Study,\u201d Technical Report, University of  \nMinnesota, 2011.\n[Adhikari 2012]  V. K. Adhikari, Y. Gao, F. Hao, M. Varvello, V. Hilt, M. Steiner, \nZ. L. Zhang, \u201cUnreeling Netflix: Understanding and Improving Multi-CDN Movie \nDelivery,\u201d Technical Report, University of Minnesota, 2012.\n[Afanasyev 2010]  A. Afanasyev, N. Tilley, P. Reiher, L. Kleinrock, \u201cHost-to-Host  \nCongestion Control for TCP,\u201d IEEE Communications Surveys & Tutorials , Vol. 12, \nNo. 3, pp. 304\u2013342.\n770     REFERENCES\n[Agarwal 2009]  S. Agarwal, J. Lorch, \u201cMatchmaking for Online Games and Other \nLatency-sensitive P2P Systems,\u201d Proc. 2009 ACM SIGCOMM.\n[Ager 2012]  B. Ager, N. Chatzis, A. Feldmann, N. Sarrar, S. Uhlig, W. Willinger, \n\u201cAnatomy of a Large European ISP,\u201d Sigcomm, 2012.\n[Ahn 1995]  J. S. Ahn, P. B. Danzig, Z. Liu, and Y. Yan, \u201cExperience with TCP \nVegas: Emulation and Experiment,\u201d Proc. 1995 ACM SIGCOMM  (Boston, MA, \nAug. 1995), pp. 185\u2013195.\n[Akamai 2016]  Akamai homepage, http://www.akamai.com\n[Akella 2003]  A. Akella, S. Seshan, A. Shaikh, \u201cAn Empirical Evaluation of Wide-\nArea Internet Bottlenecks,\u201d Proc. 2003 ACM Internet Measurement Conference  \n(Miami, FL, Nov. 2003).\n[Akhshabi 2011]  S. Akhshabi, A. C. Begen, C. Dovrolis, \u201cAn Experimental Evalu-\nation of Rate-Adaptation Algorithms in Adaptive Streaming over HTTP,\u201d Proc. 2011 \nACM Multimedia Systems Conf .\n[Akyildiz 2010]  I. Akyildiz, D. Gutierrex-Estevez, E. Reyes, \u201cThe Evolution to 4G \nCellular Systems, LTE Advanced,\u201d Physical Communication , Elsevier, 3 (2010), \n217\u2013244.\n[Albitz 1993]  P. Albitz and C. Liu, DNS and BIND , O\u2019Reilly & Associates, Petaluma, \nCA, 1993.\n[Al-Fares 2008]  M. Al-Fares, A. Loukissas, A. Vahdat, \u201cA Scalable, Commodity \nData Center Network Architecture,\u201d Proc. 2008 ACM SIGCOMM .\n[Amazon 2014]  J. Hamilton, \u201cAWS: Innovation at Scale , YouTube video,", "doc_id": "7859985d-9838-4f20-be4d-627840497009", "embedding": null, "doc_hash": "8b29090e1bc7eb805feb5aebd5cb6cb3db15fd7de62358c826de15d7d597e23d", "extra_info": null, "node_info": {"start": 2273227, "end": 2275795}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "f82de0e1-2638-4662-9ca0-75777eb908c0", "3": "2f25b6a5-bb15-437c-bd3f-4d1f062c98fd"}}, "__type__": "1"}, "2f25b6a5-bb15-437c-bd3f-4d1f062c98fd": {"__data__": {"text": "Multimedia Systems Conf .\n[Akyildiz 2010]  I. Akyildiz, D. Gutierrex-Estevez, E. Reyes, \u201cThe Evolution to 4G \nCellular Systems, LTE Advanced,\u201d Physical Communication , Elsevier, 3 (2010), \n217\u2013244.\n[Albitz 1993]  P. Albitz and C. Liu, DNS and BIND , O\u2019Reilly & Associates, Petaluma, \nCA, 1993.\n[Al-Fares 2008]  M. Al-Fares, A. Loukissas, A. Vahdat, \u201cA Scalable, Commodity \nData Center Network Architecture,\u201d Proc. 2008 ACM SIGCOMM .\n[Amazon 2014]  J. Hamilton, \u201cAWS: Innovation at Scale , YouTube video, https://\nwww.youtube.com/watch?v=JIQETrFC_SQ\n[Anderson 1995]  J. B. Andersen, T. S. Rappaport, S. Yoshida, \u201cPropagation Mea-\nsurements and Models for Wireless Communications Channels,\u201d IEEE Communi-\ncations Magazine , (Jan. 1995), pp. 42\u201349.\n[Alizadeh 2010]  M. Alizadeh, A. Greenberg, D. Maltz, J. Padhye, P. Patel,  \nB. Prabhakar, S. Sengupta, M. Sridharan. \u201cData center TCP (DCTCP),\u201d ACM  \nSIGCOMM 2010 Conference , ACM, New York, NY, USA, pp. 63\u201374.\n[Allman 2011]  E. Allman, \u201cThe Robustness Principle Reconsidered: Seeking a \nMiddle Ground,\u201d Communications of the ACM , Vol. 54, No. 8 (Aug. 2011), pp. \n40\u201345.\n[Appenzeller 2004]  G. Appenzeller, I. Keslassy, N. McKeown, \u201cSizing Router \nBuffers,\u201d Proc. 2004 ACM SIGCOMM  (Portland, OR, Aug. 2004).\n[ASO-ICANN 2016]  The Address Supporting Organization homepage,  \nhttp://www.aso.icann.org\nREFERENCES      771\n[AT&T 2013]  \u201cAT&T Vision Alignment Challenge Technology Survey,\u201d AT&T \nDomain 2.0 Vision White Paper, November 13, 2013.\n[Atheros 2016]  Atheros Communications Inc., \u201cAtheros AR5006 WLAN Chipset \nProduct Bulletins,\u201d http://www.atheros.com/pt/AR5006Bulletins.htm\n[Ayanoglu 1995]  E. Ayanoglu, S. Paul, T. F. La Porta, K. K. Sabnani, R. D. Gitlin, \n\u201cAIRMAIL: A Link-Layer Protocol for Wireless Networks,\u201d ACM ACM/Baltzer \nWireless Networks Journal , 1: 47\u201360, Feb. 1995.\n[Bakre 1995]  A. Bakre, B. R. Badrinath, \u201cI-TCP: Indirect TCP for Mobile Hosts,\u201d \nProc. 1995 Int. Conf. on Distributed Computing Systems (ICDCS)  (May 1995),  \npp. 136\u2013143.\n[Balakrishnan 1997]  H. Balakrishnan, V. Padmanabhan, S. Seshan, R. Katz, \n\u201cA Comparison of Mechanisms for Improving TCP Performance Over Wireless \nLinks,\u201d IEEE/ACM Transactions on Networking  Vol. 5, No. 6 (Dec. 1997).\n[Balakrishnan 2003]  H. Balakrishnan, F. Kaashoek, D. Karger, R. Morris, I. \nStoica, \u201cLooking Up Data in P2P Systems,\u201d Communications of the ACM , Vol. 46, \nNo. 2 (Feb. 2003), pp. 43\u201348.\n[Baldauf 2007 ] M. Baldauf, S. Dustdar, F. Rosenberg, \u201cA Survey on Context-\nAware Systems,\u201d Int. J. Ad Hoc and", "doc_id": "2f25b6a5-bb15-437c-bd3f-4d1f062c98fd", "embedding": null, "doc_hash": "2b32328d97d5d8620749f0a8b165b696c4708e5a3506d486f50a22591b89b1f9", "extra_info": null, "node_info": {"start": 2275886, "end": 2278414}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "7859985d-9838-4f20-be4d-627840497009", "3": "75c2fe5f-8eaa-4585-b8df-0d0a1e9c0265"}}, "__type__": "1"}, "75c2fe5f-8eaa-4585-b8df-0d0a1e9c0265": {"__data__": {"text": "Balakrishnan, V. Padmanabhan, S. Seshan, R. Katz, \n\u201cA Comparison of Mechanisms for Improving TCP Performance Over Wireless \nLinks,\u201d IEEE/ACM Transactions on Networking  Vol. 5, No. 6 (Dec. 1997).\n[Balakrishnan 2003]  H. Balakrishnan, F. Kaashoek, D. Karger, R. Morris, I. \nStoica, \u201cLooking Up Data in P2P Systems,\u201d Communications of the ACM , Vol. 46, \nNo. 2 (Feb. 2003), pp. 43\u201348.\n[Baldauf 2007 ] M. Baldauf, S. Dustdar, F. Rosenberg, \u201cA Survey on Context-\nAware Systems,\u201d Int. J. Ad Hoc and Ubiquitous Computing , Vol. 2, No. 4 (2007), \npp. 263\u2013277.\n[Baran 1964]  P. Baran, \u201cOn Distributed Communication Networks,\u201d IEEE Trans-\nactions on Communication Systems , Mar. 1964. Rand Corporation Technical report \nwith the same title (Memorandum RM-3420-PR, 1964). http://www.rand.org/publi-\ncations/RM/RM3420/\n[Bardwell 2004]  J. Bardwell, \u201cYou Believe You Understand What You Think I \nSaid . . . The Truth About 802.11 Signal and Noise Metrics: A Discussion Clarify-\ning Often-Misused 802.11 WLAN Terminologies,\u201d http://www.connect802.com/\ndownload/techpubs/2004/you_believe_D100201.pdf\n[Barford 2009]  P. Barford, N. Duffield, A. Ron, J. Sommers, \u201cNetwork Perfor-\nmance Anomaly Detection and Localization,\u201d Proc. 2009 IEEE INFOCOM   \n(Apr. 2009).\n[Baronti 2007]  P. Baronti, P. Pillai, V. Chook, S. Chessa, A. Gotta, Y. Hu,  \n\u201cWireless Sensor Networks: A Survey on the State of the Art and the 802.15.4 \nand ZigBee Standards,\u201d Computer Communications , Vol. 30, No. 7 (2007), pp. \n1655\u20131695.\n[Baset 2006]  S. A. Basset and H. Schulzrinne, \u201cAn Analysis of the Skype Peer-to-\nPeer Internet Telephony Protocol,\u201d Proc. 2006 IEEE INFOCOM  (Barcelona, Spain, \nApr. 2006).\n772     REFERENCES\n[BBC 2001]  BBC news online \u201cA Small Slice of Design,\u201d Apr. 2001, http://news.\nbbc.co.uk/2/hi/science/nature/1264205.stm\n[Beheshti 2008]  N. Beheshti, Y. Ganjali, M. Ghobadi, N. McKeown, G. Salmon,  \n\u201cExperimental Study of Router Buffer Sizing,\u201d Proc. ACM Internet Measurement  \nConference  (Oct. 2008, Vouliagmeni, Greece).\n[Bender 2000]  P. Bender, P. Black, M. Grob, R. Padovani, N. Sindhushayana, A. \nViterbi, \u201cCDMA/HDR: A Bandwidth-Efficient High-Speed Wireless Data Service \nfor Nomadic Users,\u201d IEEE Commun. Mag. , Vol. 38, No. 7 (July 2000),  \npp. 70\u201377.\n[Berners-Lee 1989]  T. Berners-Lee, CERN, \u201cInformation Management: A  \nProposal,\u201d Mar. 1989, May 1990. http://www.w3.org/History/1989/proposal \n.html\n[Berners-Lee 1994]  T. Berners-Lee, R. Cailliau, A. Luotonen, H. Frystyk Nielsen,  \nA. Secret, \u201cThe World-Wide Web,\u201d Communications of the ACM , Vol. 37, No. 8  \n(Aug. 1994), pp. 76\u201382.\n[Bertsekas 1991]", "doc_id": "75c2fe5f-8eaa-4585-b8df-0d0a1e9c0265", "embedding": null, "doc_hash": "2095792e3b0178bdd3f455f9fd0c306d360a8851cca00075159ca3b4e5d16514", "extra_info": null, "node_info": {"start": 2278428, "end": 2281027}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "2f25b6a5-bb15-437c-bd3f-4d1f062c98fd", "3": "841eefaa-cf8a-4968-8622-3deaea4dfb65"}}, "__type__": "1"}, "841eefaa-cf8a-4968-8622-3deaea4dfb65": {"__data__": {"text": "A Bandwidth-Efficient High-Speed Wireless Data Service \nfor Nomadic Users,\u201d IEEE Commun. Mag. , Vol. 38, No. 7 (July 2000),  \npp. 70\u201377.\n[Berners-Lee 1989]  T. Berners-Lee, CERN, \u201cInformation Management: A  \nProposal,\u201d Mar. 1989, May 1990. http://www.w3.org/History/1989/proposal \n.html\n[Berners-Lee 1994]  T. Berners-Lee, R. Cailliau, A. Luotonen, H. Frystyk Nielsen,  \nA. Secret, \u201cThe World-Wide Web,\u201d Communications of the ACM , Vol. 37, No. 8  \n(Aug. 1994), pp. 76\u201382.\n[Bertsekas 1991]  D. Bertsekas, R. Gallagher, Data Networks, 2nd Ed. , Prentice \nHall, Englewood Cliffs, NJ, 1991.\n[Biersack 1992]  E. W. Biersack, \u201cPerformance Evaluation of Forward Error Cor-\nrection in ATM Networks,\u201d Proc. 1999 ACM SIGCOMM  (Baltimore, MD, Aug. \n1992), pp. 248\u2013257.\n[BIND 2016]  Internet Software Consortium page on BIND, http://www.isc.org/\nbind.html\n[Bisdikian 2001]  C. Bisdikian, \u201cAn Overview of the Bluetooth Wireless Technol-\nogy,\u201d IEEE Communications Magazine , No. 12 (Dec. 2001), pp. 86\u201394.\n[Bishop 2003]  M. Bishop, Computer Security: Art and Science , Boston: Addison \nWesley, Boston MA, 2003.\n[Black 1995]  U. Black, ATM Volume I: Foundation for Broadband Networks , \nPrentice Hall, 1995.\n[Black 1997]  U. Black, ATM Volume II: Signaling in Broadband Networks , Prentice \nHall, 1997.\n[Blumenthal 2001]  M. Blumenthal, D. Clark, \u201cRethinking the Design of the  \nInternet: The End-to-end Arguments vs. the Brave New World,\u201d ACM Transactions \non Internet Technology , Vol. 1, No. 1 (Aug. 2001), pp. 70\u2013109.\n[Bochman 1984]  G. V. Bochmann, C. A. Sunshine, \u201cFormal Methods in Commu-\nnication Protocol Design,\u201d IEEE Transactions on Communications , Vol. 28, No. 4 \n(Apr. 1980) pp. 624\u2013631.\nREFERENCES      773\n[Bolot 1996]  J-C. Bolot, A. Vega-Garcia, \u201cControl Mechanisms for Packet Audio \nin the Internet,\u201d Proc. 1996 IEEE INFOCOM , pp. 232\u2013239.\n[Bosshart 2013]  P. Bosshart, G. Gibb, H. Kim, G. Varghese, N. McKeown,  \nM. Izzard, F. Mujica, M. Horowitz, \u201cForwarding Metamorphosis: Fast Program-\nmable Match-Action Processing in Hardware for SDN,\u201d ACM SIGCOMM Comput.  \nCommun. Rev.  43, 4 (Aug. 2013), 99\u2013110 .\n[Bosshart 2014]  P. Bosshart, D. Daly, G. Gibb, M. Izzard, N. McKeown,  \nJ. Rexford, C. Schlesinger, D. Talayco, A. Vahdat, G. Varghese, D. Walker,  \n\u201cP4: Programming Protocol-Independent Packet Processors,\u201d ACM SIGCOMM \nComput. Commun. Rev.  44, 3 (July 2014), pp. 87\u201395.\n[Brakmo 1995]  L. Brakmo, L. Peterson, \u201cTCP Vegas: End to End Congestion \nAvoidance on a Global Internet,\u201d IEEE Journal of Selected Areas in Communica-\ntions , Vol. 13, No. 8 (Oct. 1995), pp. 1465\u20131480.\n[Bryant 1988]  B. Bryant, \u201cDesigning an Authentication System: A Dialogue in \nFour Scenes,\u201d", "doc_id": "841eefaa-cf8a-4968-8622-3deaea4dfb65", "embedding": null, "doc_hash": "31e94956cd247b5e4735900d54b21ce0526dec89dc5af22886fa9718953d9bca", "extra_info": null, "node_info": {"start": 2281024, "end": 2283702}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "75c2fe5f-8eaa-4585-b8df-0d0a1e9c0265", "3": "7c8ac85a-7b57-4c46-b3db-6b3e3a4b51a1"}}, "__type__": "1"}, "7c8ac85a-7b57-4c46-b3db-6b3e3a4b51a1": {"__data__": {"text": "McKeown,  \nJ. Rexford, C. Schlesinger, D. Talayco, A. Vahdat, G. Varghese, D. Walker,  \n\u201cP4: Programming Protocol-Independent Packet Processors,\u201d ACM SIGCOMM \nComput. Commun. Rev.  44, 3 (July 2014), pp. 87\u201395.\n[Brakmo 1995]  L. Brakmo, L. Peterson, \u201cTCP Vegas: End to End Congestion \nAvoidance on a Global Internet,\u201d IEEE Journal of Selected Areas in Communica-\ntions , Vol. 13, No. 8 (Oct. 1995), pp. 1465\u20131480.\n[Bryant 1988]  B. Bryant, \u201cDesigning an Authentication System: A Dialogue in \nFour Scenes,\u201d http://web.mit.edu/kerberos/www/dialogue.html\n[Bush 1945]  V. Bush, \u201cAs We May Think,\u201d The Atlantic Monthly , July 1945. \nhttp://www.theatlantic.com/unbound/flashbks/computer/bushf.htm\n[Byers 1998]  J. Byers, M. Luby, M. Mitzenmacher, A. Rege, \u201cA Digital Fountain \nApproach to Reliable Distribution of Bulk Data,\u201d Proc. 1998 ACM SIGCOMM  \n(Vancouver, Canada, Aug. 1998), pp. 56\u201367.\n[Caesar 2005a]  M. Caesar, D. Caldwell, N. Feamster, J. Rexford, A. Shaikh, J. van \nder Merwe, \u201cDesign and implementation of a Routing Control Platform,\u201d Proc. \nNetworked Systems Design and Implementation  (May 2005).\n[Caesar 2005b]  M. Caesar, J. Rexford, \u201cBGP Routing Policies in ISP Networks,\u201d \nIEEE Network Magazine , Vol. 19, No. 6 (Nov. 2005).\n[Caldwell 2012]  C. Caldwell, \u201cThe Prime Pages,\u201d http://www.utm.edu/research/\nprimes/prove\n[Cardwell 2000]  N. Cardwell, S. Savage, T. Anderson, \u201cModeling TCP Latency,\u201d \nProc. 2000 IEEE INFOCOM  (Tel-Aviv, Israel, Mar. 2000).\n[Casado 2007]  M. Casado, M. Freedman, J. Pettit, J. Luo, N. McKeown, S. Shen-\nker, \u201cEthane: Taking Control of the Enterprise,\u201d Proc. ACM SIGCOMM \u201907 , New \nYork, pp. 1\u201312. See also IEEE/ACM Trans. Networking , 17, 4 (Aug. 2007), pp. \n270\u20131283.\n[Casado 2009]  M. Casado, M. Freedman, J. Pettit, J. Luo, N. Gude, N. McKeown,  \nS. Shenker, \u201cRethinking Enterprise Network Control,\u201d IEEE/ACM Transactions on \nNetworking (ToN) , Vol. 17, No. 4 (Aug. 2009), pp. 1270\u20131283.\n774     REFERENCES\n[Casado 2014]  M. Casado, N. Foster, A. Guha, \u201cAbstractions for Software- \nDefined Networks,\u201d Communications of the ACM , Vol. 57 No. 10, (Oct. 2014),  \npp. 86\u201395.\n[Cerf 1974]  V. Cerf, R. Kahn, \u201cA Protocol for Packet Network Interconnection,\u201d \nIEEE Transactions on Communications Technology , Vol. COM-22, No. 5, pp. \n627\u2013641.\n[CERT 2001\u201309] CERT, \u201cAdvisory 2001\u201309: Statistical Weaknesses in TCP/IP \nInitial Sequence Numbers,\u201d http://www.cert.org/advisories/CA-2001-09.html\n[CERT 2003\u201304]  CERT, \u201cCERT Advisory CA-2003-04 MS-SQL Server Worm,\u201d \nhttp://www.cert.org/advisories/CA-2003-04.html\n[CERT 2016] ", "doc_id": "7c8ac85a-7b57-4c46-b3db-6b3e3a4b51a1", "embedding": null, "doc_hash": "c53e0775139ee5a7381ddc9a82c0a19bc81d9d150dc9cc98f98f9b1729b94715", "extra_info": null, "node_info": {"start": 2283695, "end": 2286250}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "841eefaa-cf8a-4968-8622-3deaea4dfb65", "3": "7e4b2c4d-5771-4da9-826a-89616aab08b3"}}, "__type__": "1"}, "7e4b2c4d-5771-4da9-826a-89616aab08b3": {"__data__": {"text": "of the ACM , Vol. 57 No. 10, (Oct. 2014),  \npp. 86\u201395.\n[Cerf 1974]  V. Cerf, R. Kahn, \u201cA Protocol for Packet Network Interconnection,\u201d \nIEEE Transactions on Communications Technology , Vol. COM-22, No. 5, pp. \n627\u2013641.\n[CERT 2001\u201309] CERT, \u201cAdvisory 2001\u201309: Statistical Weaknesses in TCP/IP \nInitial Sequence Numbers,\u201d http://www.cert.org/advisories/CA-2001-09.html\n[CERT 2003\u201304]  CERT, \u201cCERT Advisory CA-2003-04 MS-SQL Server Worm,\u201d \nhttp://www.cert.org/advisories/CA-2003-04.html\n[CERT 2016]  CERT, http://www.cert.org\n[CERT Filtering 2012]  CERT, \u201cPacket Filtering for Firewall Systems,\u201d http://\nwww.cert.org/tech_tips/packet_filtering.html\n[Cert SYN 1996]  CERT, \u201cAdvisory CA-96.21: TCP SYN Flooding and IP Spoof-\ning Attacks,\u201d http://www.cert.org/advisories/CA-1998-01.html\n[Chandra 2007]  T. Chandra, R. Greisemer, J. Redstone, \u201cPaxos Made Live: an \nEngineering Perspective,\u201d Proc. of 2007 ACM Symposium on Principles of Distrib -\nuted Computing (PODC), pp. 398\u2013407.\n[Chao 2001]  H. J. Chao, C. Lam, E. Oki, Broadband Packet Switching Technol-\nogies\u2014A Practical Guide to ATM Switches and IP Routers , John Wiley & Sons, \n2001.\n[Chao 2011]  C. Zhang, P. Dunghel, D. Wu, K. W. Ross, \u201cUnraveling the  \nBitTorrent Ecosystem,\u201d IEEE Transactions on Parallel and Distributed Systems , \nVol. 22, No. 7 (July 2011).\n[Chen 2000]  G. Chen, D. Kotz, \u201cA Survey of Context-Aware Mobile Computing \nResearch,\u201d Technical Report TR2000-381 , Dept. of Computer Science, Dartmouth \nCollege, Nov. 2000. http://www.cs.dartmouth.edu/reports/TR2000-381.pdf\n[Chen 2006]  K.-T. Chen, C.-Y. Huang, P. Huang, C.-L. Lei, \u201cQuantifying Skype \nUser Satisfaction,\u201d Proc. 2006 ACM SIGCOMM  (Pisa, Italy, Sept. 2006).\n[Chen 2011]  Y. Chen, S. Jain, V. K. Adhikari, Z. Zhang, \u201cCharacterizing Roles  \nof Front-End Servers in End-to-End Performance of Dynamic Content Distribu-\ntion,\u201d Proc. 2011 ACM Internet Measurement Conference  (Berlin, Germany,  \nNov. 2011).\n[Cheswick 2000]  B. Cheswick, H. Burch, S. Branigan, \u201cMapping and Visualizing \nthe Internet,\u201d Proc. 2000 Usenix Conference  (San Diego, CA, June 2000).\nREFERENCES      775\n[Chiu 1989]  D. Chiu, R. Jain, \u201cAnalysis of the Increase and Decrease Algorithms \nfor Congestion Avoidance in Computer Networks,\u201d Computer Networks and ISDN \nSystems , Vol. 17, No. 1, pp. 1\u201314. http://www.cs.wustl.edu/~jain/papers/cong_\nav.htm\n[Christiansen 2001]  M. Christiansen, K. Jeffay, D. Ott, F. D. Smith, \u201cTuning Red \nfor Web Traffic,\u201d IEEE/ACM Transactions on Networking , Vol. 9, No. 3 (June \n2001), pp. 249\u2013264.\n[Chuang 2005]  S. Chuang, S. Iyer, N. McKeown, \u201cPractical Algorithms for Perfor-\nmance", "doc_id": "7e4b2c4d-5771-4da9-826a-89616aab08b3", "embedding": null, "doc_hash": "17e53556a7018d22015821ab4b5960116ba0c6167edb8c6a38d032d3cb5ea225", "extra_info": null, "node_info": {"start": 2286243, "end": 2288860}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "7c8ac85a-7b57-4c46-b3db-6b3e3a4b51a1", "3": "66033e4a-95da-454c-861a-4a4502e9a917"}}, "__type__": "1"}, "66033e4a-95da-454c-861a-4a4502e9a917": {"__data__": {"text": "1989]  D. Chiu, R. Jain, \u201cAnalysis of the Increase and Decrease Algorithms \nfor Congestion Avoidance in Computer Networks,\u201d Computer Networks and ISDN \nSystems , Vol. 17, No. 1, pp. 1\u201314. http://www.cs.wustl.edu/~jain/papers/cong_\nav.htm\n[Christiansen 2001]  M. Christiansen, K. Jeffay, D. Ott, F. D. Smith, \u201cTuning Red \nfor Web Traffic,\u201d IEEE/ACM Transactions on Networking , Vol. 9, No. 3 (June \n2001), pp. 249\u2013264.\n[Chuang 2005]  S. Chuang, S. Iyer, N. McKeown, \u201cPractical Algorithms for Perfor-\nmance Guarantees in Buffered Crossbars,\u201d Proc. 2005 IEEE INFOCOM.\n[Cisco 802.11ac 2014]  Cisco Systems, \u201c802.11ac: The Fifth Generation of Wi-Fi,\u201d  \nTechnical White Paper, Mar. 2014.\n[Cisco 7600 2016]  Cisco Systems, \u201cCisco 7600 Series Solution and Design Guide,\u201d  \nhttp://www.cisco.com/en/US/products/hw/routers/ps368/prod_technical_ \nreference09186a0080092246.html\n[Cisco 8500 2012]  Cisco Systems Inc., \u201cCatalyst 8500 Campus Switch Router  \nArchitecture,\u201d http://www.cisco.com/univercd/cc/td/doc/product/l3sw/8540/\nrel_12_0/w5_6f/softcnfg/1cfg8500.pdf\n[Cisco 12000 2016]  Cisco Systems Inc., \u201cCisco XR 12000 Series and Cisco 12000 \nSeries Routers,\u201d http://www.cisco.com/en/US/products/ps6342/index.html\n[Cisco 2012]  Cisco 2012, Data Centers, http://www.cisco.com/go/dce\n[Cisco 2015]  Cisco Visual Networking Index: Forecast and Methodology, 2014\u2013\n2019, White Paper, 2015.\n[Cisco 6500 2016]  Cisco Systems, \u201cCisco Catalyst 6500 Architecture White  \nPaper,\u201d http://www.cisco.com/c/en/us/products/collateral/switches/ \ncatalyst-6500-series-switches/prod_white_paper0900aecd80673385.html\n[Cisco NAT 2016]  Cisco Systems Inc., \u201cHow NAT Works,\u201d http://www.cisco.\ncom/en/US/tech/tk648/tk361/technologies_tech_note09186a0080094831.shtml\n[Cisco QoS 2016]  Cisco Systems Inc., \u201cAdvanced QoS Services for the Intelligent \nInternet,\u201d http://www.cisco.com/warp/public/cc/pd/iosw/ioft/ioqo/tech/qos_wp.htm\n[Cisco Queue 2016]  Cisco Systems Inc., \u201cCongestion Management Overview,\u201d \nhttp://www.cisco.com/en/US/docs/ios/12_2/qos/configuration/guide/qcfconmg.\nhtml\n[Cisco SYN 2016]  Cisco Systems Inc., \u201cDefining Strategies to Protect Against \nTCP SYN Denial of Service Attacks,\u201d http://www.cisco.com/en/US/tech/tk828/\ntechnologies_tech_note09186a00800f67d5.shtml\n776     REFERENCES\n[Cisco TCAM 2014]  Cisco Systems Inc., \u201cCAT 6500 and 7600 Series Routers and \nSwitches TCAM Allocation Adjustment Procedures,\u201d http://www.cisco.com/c/en/\nus/support/docs/switches/catalyst-6500-series-switches/117712-problemsolution-\ncat6500-00.html\n[Cisco VNI 2015]  Cisco Systems Inc., \u201cVisual Networking Index,\u201d", "doc_id": "66033e4a-95da-454c-861a-4a4502e9a917", "embedding": null, "doc_hash": "816aed658ab179cc3739ad37a50f8f27b5be36f22fbe25d527a269797945db82", "extra_info": null, "node_info": {"start": 2288865, "end": 2291446}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "7e4b2c4d-5771-4da9-826a-89616aab08b3", "3": "f1b7603a-15cb-4251-80d5-0dda429c6cf2"}}, "__type__": "1"}, "f1b7603a-15cb-4251-80d5-0dda429c6cf2": {"__data__": {"text": "2016]  Cisco Systems Inc., \u201cDefining Strategies to Protect Against \nTCP SYN Denial of Service Attacks,\u201d http://www.cisco.com/en/US/tech/tk828/\ntechnologies_tech_note09186a00800f67d5.shtml\n776     REFERENCES\n[Cisco TCAM 2014]  Cisco Systems Inc., \u201cCAT 6500 and 7600 Series Routers and \nSwitches TCAM Allocation Adjustment Procedures,\u201d http://www.cisco.com/c/en/\nus/support/docs/switches/catalyst-6500-series-switches/117712-problemsolution-\ncat6500-00.html\n[Cisco VNI 2015]  Cisco Systems Inc., \u201cVisual Networking Index,\u201d http://www.\ncisco.com/web/solutions/sp/vni/vni_forecast_highlights/index.html\n[Clark 1988]  D. Clark, \u201cThe Design Philosophy of the DARPA Internet Proto-\ncols,\u201d Proc. 1988 ACM SIGCOMM  (Stanford, CA, Aug. 1988).\n[Cohen 1977]  D. Cohen, \u201cIssues in Transnet Packetized Voice Communication,\u201d \nProc. Fifth Data Communications Symposium  (Snowbird, UT, Sept. 1977),  \npp. 6\u201313.\n[Cookie Central 2016]  Cookie Central homepage, http://www.cookiecentral.com/ \nn_cookie_faq.htm\n[Cormen 2001]  T. H. Cormen, Introduction to Algorithms , 2nd Ed., MIT Press, \nCambridge, MA, 2001.\n[Crow 1997]  B. Crow, I. Widjaja, J. Kim, P. Sakai, \u201cIEEE 802.11 Wireless  \nLocal Area Networks,\u201d IEEE Communications Magazine  (Sept. 1997),  \npp. 116\u2013126.\n[Cusumano 1998]  M. A. Cusumano, D. B. Yoffie, Competing on Internet Time: \nLessons from Netscape and Its Battle with Microsoft , Free Press, New York, NY, \n1998.\n[Czyz 2014]  J. Czyz, M. Allman, J. Zhang, S. Iekel-Johnson, E. Osterweil, M. Bai-\nley, \u201cMeasuring IPv6 Adoption,\u201d Proc. ACM SIGCOMM 2014 , ACM, New York, \nNY, USA, pp. 87\u201398.\n[Dahlman 1998]  E. Dahlman, B. Gudmundson, M. Nilsson, J. Sk\u00f6ld, \u201cUMTS/\nIMT-2000 Based on Wideband CDMA,\u201d IEEE Communications Magazine  (Sept. \n1998), pp. 70\u201380.\n[Daigle 1991]  J. N. Daigle, Queuing Theory for Telecommunications , Addison-\nWesley, Reading, MA, 1991.\n[DAM 2016]  Digital Attack Map, http://www.digitalattackmap.com\n[Davie 2000]  B. Davie and Y. Rekhter, MPLS: Technology and Applications ,  \nMorgan Kaufmann Series in Networking, 2000.\n[Davies 2005]  G. Davies, F. Kelly, \u201cNetwork Dimensioning, Service Costing, and  \nPricing in a Packet-Switched Environment,\u201d Telecommunications Policy , Vol. 28, \nNo. 4, pp. 391\u2013412.\nREFERENCES      777\n[DEC 1990]  Digital Equipment Corporation, \u201cIn Memoriam: J. C. R. Licklider \n1915\u20131990,\u201d SRC Research Report 61, Aug. 1990. http://www.memex.org/ \nlicklider.pdf\n[DeClercq 2002]  J. DeClercq, O. Paridaens, \u201cScalability Implications of Virtual \nPrivate Networks,\u201d IEEE Communications Magazine , Vol. 40, No. 5 (May 2002), \npp. 151\u2013157.\n[Demers 1990]  A. Demers, S. Keshav, S. Shenker, \u201cAnalysis and Simulation", "doc_id": "f1b7603a-15cb-4251-80d5-0dda429c6cf2", "embedding": null, "doc_hash": "bc2aee9b8a7f66215753c4ecd9889283338bf2638e9fe4cb63f10c426d84fa75", "extra_info": null, "node_info": {"start": 2291408, "end": 2294056}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "66033e4a-95da-454c-861a-4a4502e9a917", "3": "db65d9b8-d8b3-4f6d-9ef0-983b89fe8ec9"}}, "__type__": "1"}, "db65d9b8-d8b3-4f6d-9ef0-983b89fe8ec9": {"__data__": {"text": "in a Packet-Switched Environment,\u201d Telecommunications Policy , Vol. 28, \nNo. 4, pp. 391\u2013412.\nREFERENCES      777\n[DEC 1990]  Digital Equipment Corporation, \u201cIn Memoriam: J. C. R. Licklider \n1915\u20131990,\u201d SRC Research Report 61, Aug. 1990. http://www.memex.org/ \nlicklider.pdf\n[DeClercq 2002]  J. DeClercq, O. Paridaens, \u201cScalability Implications of Virtual \nPrivate Networks,\u201d IEEE Communications Magazine , Vol. 40, No. 5 (May 2002), \npp. 151\u2013157.\n[Demers 1990]  A. Demers, S. Keshav, S. Shenker, \u201cAnalysis and Simulation of a \nFair Queuing Algorithm,\u201d Internetworking: Research and Experience , Vol. 1, No. 1 \n(1990), pp. 3\u201326.\n[dhc 2016]  IETF Dynamic Host Configuration working group homepage, http://\nwww.ietf.org/html.charters/dhc-charter.html\n[Dhungel 2012]  P. Dhungel, K. W. Ross, M. Steiner., Y. Tian, X. Hei, \u201cXunlei: \nPeer-Assisted Download Acceleration on a Massive Scale,\u201d Passive and Active \nMeasurement Conference (PAM) 2012 , Vienna, 2012.\n[Diffie 1976]  W. Diffie, M. E. Hellman, \u201cNew Directions in Cryptography,\u201d IEEE \nTransactions on Information Theory , Vol IT-22 (1976), pp. 644\u2013654.\n[Diggavi 2004]  S. N. Diggavi, N. Al-Dhahir, A. Stamoulis, R. Calderbank, \u201cGreat \nExpectations: The Value of Spatial Diversity in Wireless Networks,\u201d Proceedings \nof the IEEE , Vol. 92, No. 2 (Feb. 2004).\n[Dilley 2002]  J. Dilley, B. Maggs, J. Parikh, H. Prokop, R. Sitaraman, B. Weihl, \n\u201cGlobally Distributed Content Delivert,\u201d IEEE Internet Computing  (Sept.\u2013Oct. \n2002).\n[Diot 2000]  C. Diot, B. N. Levine, B. Lyles, H. Kassem, D. Balensiefen, \u201cDeploy-\nment Issues for the IP Multicast Service and Architecture,\u201d IEEE Network , Vol. 14, \nNo. 1 (Jan./Feb. 2000) pp. 78\u201388.\n[Dischinger 2007]  M. Dischinger, A. Haeberlen, K. Gummadi, S. Saroiu, \u201cCharac-\nterizing residential broadband networks,\u201d Proc. 2007 ACM Internet Measurement \nConference , pp. 24\u201326.\n[Dmitiropoulos 2007]  X. Dmitiropoulos, D. Krioukov, M. Fomenkov, B. Huffaker,  \nY. Hyun, K. C. Claffy, G. Riley, \u201cAS Relationships: Inference and Validation,\u201d \nACM Computer Communication Review  (Jan. 2007).\n[DOCSIS 2011]  Data-Over-Cable Service Interface Specifications, DOCSIS 3.0: \nMAC and Upper Layer Protocols Interface Specification, CM-SP-MULPIv3.0-\nI16-110623, 2011.\n[Dodge 2016]  M. Dodge, \u201cAn Atlas of Cyberspaces,\u201d http://www.cybergeography.\norg/atlas/isp_maps.html\n778     REFERENCES\n[Donahoo 2001]  M. Donahoo, K. Calvert, TCP/IP Sockets in C: Practical Guide \nfor Programmers , Morgan Kaufman, 2001.\n[DSL 2016]  DSL Forum homepage, http://www.dslforum.org/\n[Dhunghel 2008]  P. Dhungel, D. Wu, B. Schonhorst, K.W. Ross, \u201cA Measurement \nStudy of Attacks on BitTorrent", "doc_id": "db65d9b8-d8b3-4f6d-9ef0-983b89fe8ec9", "embedding": null, "doc_hash": "39faa31f604ada5b21c8ff339cd1669698a74c66589cfe64ba873e19c130acef", "extra_info": null, "node_info": {"start": 2294081, "end": 2296724}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "f1b7603a-15cb-4251-80d5-0dda429c6cf2", "3": "f94f7338-c363-454e-8577-99c407c812e0"}}, "__type__": "1"}, "f94f7338-c363-454e-8577-99c407c812e0": {"__data__": {"text": "\nMAC and Upper Layer Protocols Interface Specification, CM-SP-MULPIv3.0-\nI16-110623, 2011.\n[Dodge 2016]  M. Dodge, \u201cAn Atlas of Cyberspaces,\u201d http://www.cybergeography.\norg/atlas/isp_maps.html\n778     REFERENCES\n[Donahoo 2001]  M. Donahoo, K. Calvert, TCP/IP Sockets in C: Practical Guide \nfor Programmers , Morgan Kaufman, 2001.\n[DSL 2016]  DSL Forum homepage, http://www.dslforum.org/\n[Dhunghel 2008]  P. Dhungel, D. Wu, B. Schonhorst, K.W. Ross, \u201cA Measurement \nStudy of Attacks on BitTorrent Leechers,\u201d 7th International Workshop on Peer-to-\nPeer Systems (IPTPS 2008)  (Tampa Bay, FL, Feb. 2008).\n[Droms 2002]  R. Droms, T. Lemon, The DHCP Handbook  (2nd Edition), SAMS \nPublishing, 2002.\n[Edney 2003]  J. Edney and W. A. Arbaugh, Real 802.11 Security: Wi-Fi Protected \nAccess and 802.11i , Addison-Wesley Professional, 2003.\n[Edwards 2011]  W. K. Edwards, R. Grinter, R. Mahajan, D. Wetherall, \u201cAdvancing \nthe State of Home Networking,\u201d Communications of the ACM , Vol. 54, No. 6 (June \n2011), pp. 62\u201371.\n[Ellis 1987]  H. Ellis, \u201cThe Story of Non-Secret Encryption,\u201d http://jya.com/ellis-\ndoc.htm\n[Erickson 2013]  D. Erickson, \u201c The Beacon Openflow Controller,\u201d 2nd ACM SIG-\nCOMM Workshop on Hot Topics in Software Defined Networking  (HotSDN \u201913). \nACM, New York, NY, USA, pp. 13\u201318.\n[Ericsson 2012]  Ericsson, \u201cThe Evolution of Edge,\u201d http://www.ericsson.com/\ntechnology/whitepapers/broadband/evolution_of_EDGE.shtml\n[Facebook 2014]  A. Andreyev, \u201cIntroducing Data Center Fabric, the Next-\nGeneration Facebook Data Center Network,\u201d https://code.facebook.com/\nposts/360346274145943/introducing-data-center-fabric-the-next-generation-face-\nbook-data-center-network\n[Faloutsos 1999]  C. Faloutsos, M. Faloutsos, P. Faloutsos, \u201cWhat Does the Internet \nLook Like? Empirical Laws of the Internet Topology,\u201d Proc. 1999 ACM SIG-\nCOMM  (Boston, MA, Aug. 1999).\n[Farrington 2010]  N. Farrington, G. Porter, S. Radhakrishnan, H. Bazzaz, V. Sub-\nramanya, Y. Fainman, G. Papen, A. Vahdat, \u201cHelios: A Hybrid Electrical/Optical \nSwitch Architecture for Modular Data Centers,\u201d Proc. 2010 ACM SIGCOMM .\n[Feamster 2004]  N. Feamster, H. Balakrishnan, J. Rexford, A. Shaikh, K. van der \nMerwe, \u201cThe Case for Separating Routing from Routers,\u201d ACM SIGCOMM Work-\nshop on Future Directions in Network Architecture , Sept. 2004.\n[Feamster 2004]  N. Feamster, J. Winick, J. Rexford, \u201cA Model for BGP Routing \nfor Network Engineering,\u201d Proc. 2004 ACM SIGMETRICS  (New York, NY, June \n2004).\nREFERENCES      779\n[Feamster 2005]  N. Feamster, H. Balakrishnan, \u201cDetecting BGP Configuration \nFaults with Static Analysis,\u201d NSDI  (May 2005).\n[Feamster 2013]  N. Feamster, J. Rexford, E. Zegura,", "doc_id": "f94f7338-c363-454e-8577-99c407c812e0", "embedding": null, "doc_hash": "c9edab6085d43250c706644bfbcb236280bcac30f13c1414a14bd9091b924ca9", "extra_info": null, "node_info": {"start": 2296740, "end": 2299409}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "db65d9b8-d8b3-4f6d-9ef0-983b89fe8ec9", "3": "3020e5ca-d14d-44ab-8e27-5b6a6b69898b"}}, "__type__": "1"}, "3020e5ca-d14d-44ab-8e27-5b6a6b69898b": {"__data__": {"text": "A. Shaikh, K. van der \nMerwe, \u201cThe Case for Separating Routing from Routers,\u201d ACM SIGCOMM Work-\nshop on Future Directions in Network Architecture , Sept. 2004.\n[Feamster 2004]  N. Feamster, J. Winick, J. Rexford, \u201cA Model for BGP Routing \nfor Network Engineering,\u201d Proc. 2004 ACM SIGMETRICS  (New York, NY, June \n2004).\nREFERENCES      779\n[Feamster 2005]  N. Feamster, H. Balakrishnan, \u201cDetecting BGP Configuration \nFaults with Static Analysis,\u201d NSDI  (May 2005).\n[Feamster 2013]  N. Feamster, J. Rexford, E. Zegura, \u201cThe Road to SDN,\u201d ACM \nQueue , Volume 11, Issue 12, (Dec. 2013).\n[Feldmeier 1995]  D. Feldmeier, \u201cFast Software Implementation of Error Detection \nCodes,\u201d IEEE/ACM Transactions on Networking , Vol. 3, No. 6 (Dec. 1995), pp. \n640\u2013652.\n[Ferguson 2013]  A. Ferguson, A. Guha, C. Liang, R. Fonseca, S. Krishnamurthi, \n\u201cParticipatory Networking: An API for Application Control of SDNs,\u201d Proceedings \nACM SIGCOMM 2013 , pp. 327\u2013338.\n[Fielding 2000]  R. Fielding, \u201cArchitectural Styles and the Design of Network-\nbased Software Architectures,\u201d 2000. PhD Thesis, UC Irvine, 2000.\n[FIPS 1995]  Federal Information Processing Standard, \u201cSecure Hash Standard,\u201d \nFIPS Publication 180-1. http://www.itl.nist.gov/fipspubs/fip180-1.htm\n[Floyd 1999]  S. Floyd, K. Fall, \u201cPromoting the Use of End-to-End Congestion \nControl in the Internet,\u201d IEEE/ACM Transactions on Networking , Vol. 6, No. 5 \n(Oct. 1998), pp. 458\u2013472.\n[Floyd 2000]  S. Floyd, M. Handley, J. Padhye, J. Widmer, \u201cEquation-Based  \nCongestion Control for Unicast Applications,\u201d Proc. 2000 ACM SIGCOMM  \n(Stockholm, Sweden, Aug. 2000).\n[Floyd 2001]  S. Floyd, \u201cA Report on Some Recent Developments in TCP Conges-\ntion Control,\u201d IEEE Communications Magazine  (Apr. 2001).\n[Floyd 2016]  S. Floyd, \u201cReferences on RED (Random Early Detection) Queue \nManagement,\u201d http://www.icir.org/floyd/red.html\n[Floyd Synchronization 1994]  S. Floyd, V. Jacobson, \u201cSynchronization of Peri-\nodic Routing Messages,\u201d IEEE/ACM Transactions on Networking , Vol. 2, No. 2 \n(Apr. 1997) pp. 122\u2013136.\n[Floyd TCP 1994]  S. Floyd, \u201cTCP and Explicit Congestion Notification,\u201d ACM \nSIGCOMM Computer Communications Review , Vol. 24, No. 5 (Oct. 1994), pp. \n10\u201323.\n[Fluhrer 2001]  S. Fluhrer, I. Mantin, A. Shamir, \u201cWeaknesses in the Key Schedul-\ning Algorithm of RC4,\u201d Eighth Annual Workshop on Selected Areas in Cryptogra-\nphy (Toronto, Canada, Aug. 2002).\n[Fortz 2000]  B. Fortz, M. Thorup, \u201cInternet Traffic Engineering by Optimizing \nOSPF Weights,\u201d Proc. 2000 IEEE INFOCOM  (Tel Aviv, Israel, Apr. 2000).\n780     REFERENCES\n[Fortz 2002]  B. Fortz, J. Rexford, M. Thorup, \u201cTraffic Engineering with  \nTraditional IP Routing Protocols,\u201d IEEE Communication Magazine   \n(Oct. 2002).\n[Fraleigh 2003]  C.", "doc_id": "3020e5ca-d14d-44ab-8e27-5b6a6b69898b", "embedding": null, "doc_hash": "b942a56efd18644a1450527ce3379c55fe3f95368b3219db50686d952b0a8853", "extra_info": null, "node_info": {"start": 2299406, "end": 2302142}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "f94f7338-c363-454e-8577-99c407c812e0", "3": "02898aee-e156-4779-ac23-ee57e6573ebb"}}, "__type__": "1"}, "02898aee-e156-4779-ac23-ee57e6573ebb": {"__data__": {"text": "2001]  S. Fluhrer, I. Mantin, A. Shamir, \u201cWeaknesses in the Key Schedul-\ning Algorithm of RC4,\u201d Eighth Annual Workshop on Selected Areas in Cryptogra-\nphy (Toronto, Canada, Aug. 2002).\n[Fortz 2000]  B. Fortz, M. Thorup, \u201cInternet Traffic Engineering by Optimizing \nOSPF Weights,\u201d Proc. 2000 IEEE INFOCOM  (Tel Aviv, Israel, Apr. 2000).\n780     REFERENCES\n[Fortz 2002]  B. Fortz, J. Rexford, M. Thorup, \u201cTraffic Engineering with  \nTraditional IP Routing Protocols,\u201d IEEE Communication Magazine   \n(Oct. 2002).\n[Fraleigh 2003]  C. Fraleigh, F. Tobagi, C. Diot, \u201cProvisioning IP Backbone Net-\nworks to Support Latency Sensitive Traffic,\u201d Proc. 2003 IEEE INFOCOM  (San \nFrancisco, CA, Mar. 2003).\n[Frost 1994]  J. Frost, \u201cBSD Sockets: A Quick and Dirty Primer,\u201d http://world.std \n.com/~jimf/papers/sockets/sockets.html\n[FTC 2015]  Internet of Things: Privacy and Security in a Connected World, Fed-\neral Trade Commission, 2015, https://www.ftc.gov/system/files/documents/reports/\nfederal-trade-commission-staff-report-november-2013-workshop-entitled-internet-\nthings-privacy/150127iotrpt.pdf\n[FTTH 2016]  Fiber to the Home Council, http://www.ftthcouncil.org/\n[Gao 2001]  L. Gao, J. Rexford, \u201cStable Internet Routing Without Global Coordi-\nnation,\u201d IEEE/ACM Transactions on Networking , Vol. 9, No. 6 (Dec. 2001), pp. \n681\u2013692.\n[Gartner 2014]  Gartner report on Internet of Things, http://www.gartner.com/ \ntechnology/research/internet-of-things\n[Gauthier 1999]  L. Gauthier, C. Diot, and J. Kurose, \u201cEnd-to-End Transmission \nControl Mechanisms for Multiparty Interactive Applications on the Internet,\u201d Proc. \n1999 IEEE INFOCOM  (New York, NY, Apr. 1999).\n[Gember-Jacobson 2014]  A. Gember-Jacobson, R. Viswanathan, C. Prakash,  \nR. Grandl, J. Khalid, S. Das, A. Akella, \u201cOpenNF: Enabling Innovation in Network \nFunction Control,\u201d Proc. ACM SIGCOMM 2014 , pp. 163\u2013174.\n[Goodman 1997]  David J. Goodman, Wireless Personal Communications Systems , \nPrentice-Hall, 1997.\n[Google IPv6 2015]  Google Inc. \u201cIPv6 Statistics,\u201d https://www.google.com/intl/en/\nipv6/statistics.html\n[Google Locations 2016]  Google data centers. http://www.google.com/corporate/\ndatacenter/locations.html\n[Goralski 1999]  W. Goralski, Frame Relay for High-Speed Networks , John Wiley, \nNew York, 1999.\n[Greenberg 2009a]  A. Greenberg, J. Hamilton, D. Maltz, P. Patel, \u201cThe Cost of a \nCloud: Research Problems in Data Center Networks,\u201d ACM Computer Communica -\ntions Review  (Jan. 2009).\nREFERENCES      781\n[Greenberg 2009b]  A. Greenberg, N. Jain, S. Kandula, C. Kim, P. Lahiri, D. \nMaltz, P. Patel, S. Sengupta, \u201cVL2: A Scalable and Flexible Data Center Network,\u201d \nProc. 2009 ACM SIGCOMM .\n[Greenberg 2011]  A. Greenberg, J. Hamilton, N. Jain, S. Kandula, C. Kim,  \nP. Lahiri,", "doc_id": "02898aee-e156-4779-ac23-ee57e6573ebb", "embedding": null, "doc_hash": "836413bd44f938c80f8d73d5857fa29be4cc05a555dfbad47b0c33cef0cad926", "extra_info": null, "node_info": {"start": 2302132, "end": 2304878}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "3020e5ca-d14d-44ab-8e27-5b6a6b69898b", "3": "aa190f9a-324e-4852-b59f-e18360b36ffb"}}, "__type__": "1"}, "aa190f9a-324e-4852-b59f-e18360b36ffb": {"__data__": {"text": "York, 1999.\n[Greenberg 2009a]  A. Greenberg, J. Hamilton, D. Maltz, P. Patel, \u201cThe Cost of a \nCloud: Research Problems in Data Center Networks,\u201d ACM Computer Communica -\ntions Review  (Jan. 2009).\nREFERENCES      781\n[Greenberg 2009b]  A. Greenberg, N. Jain, S. Kandula, C. Kim, P. Lahiri, D. \nMaltz, P. Patel, S. Sengupta, \u201cVL2: A Scalable and Flexible Data Center Network,\u201d \nProc. 2009 ACM SIGCOMM .\n[Greenberg 2011]  A. Greenberg, J. Hamilton, N. Jain, S. Kandula, C. Kim,  \nP. Lahiri, D. Maltz, P. Patel, S. Sengupta, \u201cVL2: A Scalable and Flexible Data  \nCenter Network,\u201d Communications of the ACM , Vol. 54, No. 3 (Mar. 2011),  \npp. 95\u2013104.\n[Greenberg 2015]  A. Greenberg, \u201cSDN for the Cloud,\u201d Sigcomm 2015 Keynote \nAddress, http://conferences.sigcomm.org/sigcomm/2015/pdf/papers/keynote.pdf\n[Griffin 2012]  T. Griffin, \u201cInterdomain Routing Links,\u201d http://www.cl.cam.\nac.uk/~tgg22/interdomain/\n[Gude 2008]  N. Gude, T. Koponen, J. Pettit, B. Pfaff, M. Casado, N. McKeown, \nand S. Shenker, \u201cNOX: Towards an Operating System for Networks,\u201d ACM SIG -\nCOMM Computer Communication Review , July 2008.\n[Guha 2006]  S. Guha, N. Daswani, R. Jain, \u201cAn Experimental Study of the Skype \nPeer-to-Peer VoIP System,\u201d Proc. Fifth Int. Workshop on P2P Systems  (Santa \nBarbara, CA, 2006).\n[Guo 2005]  L. Guo, S. Chen, Z. Xiao, E. Tan, X. Ding, X. Zhang, \u201cMeasurement, \nAnalysis, and Modeling of BitTorrent-Like Systems,\u201d Proc. 2005 ACM Internet \nMeasurement Conference .\n[Guo 2009]  C. Guo, G. Lu, D. Li, H. Wu, X. Zhang, Y. Shi, C. Tian, Y. Zhang,  \nS. Lu, \u201cBCube: A High Performance, Server-centric Network Architecture for \nModular Data Centers,\u201d Proc. 2009 ACM SIGCOMM .\n[Gupta 2001]  P. Gupta, N. McKeown, \u201cAlgorithms for Packet Classification,\u201d \nIEEE Network Magazine , Vol. 15, No. 2 (Mar./Apr. 2001), pp. 24\u201332.\n[Gupta 2014]  A. Gupta, L. Vanbever, M. Shahbaz, S. Donovan, B. Schlinker,  \nN. Feamster, J. Rexford, S. Shenker, R. Clark, E. Katz-Bassett, \u201cSDX: A Software \nDefined Internet Exchange, \u201c Proc. ACM SIGCOMM 2014  (Aug. 2014),  \npp. 551\u2013562.\n[Ha 2008]  S. Ha, I. Rhee, L. Xu, \u201cCUBIC: A New TCP-Friendly High-Speed TCP  \nVariant,\u201d ACM SIGOPS Operating System Review , 2008.\n[Halabi 2000]  S. Halabi, Internet Routing Architectures , 2nd Ed., Cisco Press, \n2000.\n[Hanabali 2005]  A. A. Hanbali, E. Altman, P. Nain, \u201cA Survey of TCP over Ad \nHoc Networks, \u201d IEEE Commun. Surveys and Tutorials , Vol. 7, No. 3 (2005),  \npp. 22\u201336.\n782     REFERENCES\n[Hei 2007] ", "doc_id": "aa190f9a-324e-4852-b59f-e18360b36ffb", "embedding": null, "doc_hash": "0600348e974b93c9e309ede8f7fa36dc645d96a351547835ece7fbe9e72f8976", "extra_info": null, "node_info": {"start": 2304920, "end": 2307384}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "02898aee-e156-4779-ac23-ee57e6573ebb", "3": "324c62d1-6350-4fbc-9a28-82bfef998ad1"}}, "__type__": "1"}, "324c62d1-6350-4fbc-9a28-82bfef998ad1": {"__data__": {"text": "ACM SIGCOMM 2014  (Aug. 2014),  \npp. 551\u2013562.\n[Ha 2008]  S. Ha, I. Rhee, L. Xu, \u201cCUBIC: A New TCP-Friendly High-Speed TCP  \nVariant,\u201d ACM SIGOPS Operating System Review , 2008.\n[Halabi 2000]  S. Halabi, Internet Routing Architectures , 2nd Ed., Cisco Press, \n2000.\n[Hanabali 2005]  A. A. Hanbali, E. Altman, P. Nain, \u201cA Survey of TCP over Ad \nHoc Networks, \u201d IEEE Commun. Surveys and Tutorials , Vol. 7, No. 3 (2005),  \npp. 22\u201336.\n782     REFERENCES\n[Hei 2007]  X. Hei, C. Liang, J. Liang, Y. Liu, K. W. Ross, \u201cA Measurement Study \nof a Large-scale P2P IPTV System,\u201d IEEE Trans. on Multimedia  (Dec. 2007).\n[Heidemann 1997]  J. Heidemann, K. Obraczka, J. Touch, \u201cModeling the Perfor-\nmance of HTTP over Several Transport Protocols,\u201d IEEE/ACM Transactions on \nNetworking , Vol. 5, No. 5 (Oct. 1997), pp. 616\u2013630.\n[Held 2001]  G. Held, Data Over Wireless Networks: Bluetooth, WAP, and Wireless \nLANs , McGraw-Hill, 2001.\n[Holland 2001]  G. Holland, N. Vaidya, V. Bahl, \u201cA Rate-Adaptive MAC Protocol \nfor Multi-Hop Wireless Networks,\u201d Proc. 2001 ACM Int. Conference of Mobile \nComputing and Networking (Mobicom01)  (Rome, Italy, July 2001).\n[Hollot 2002]  C.V. Hollot, V. Misra, D. Towsley, W. Gong, \u201cAnalysis and Design \nof Controllers for AQM Routers Supporting TCP Flows,\u201d IEEE Transactions on \nAutomatic Control , Vol. 47, No. 6 (June 2002), pp. 945\u2013959.\n[Hong 2013]  C. Hong, S, Kandula, R. Mahajan, M.Zhang, V. Gill, M. Nanduri, \nR. Wattenhofer, \u201cAchieving High Utilization with Software-driven WAN,\u201d ACM \nSIGCOMM Conference  (Aug. 2013), pp.15\u201326.\n[Huang 2002]  C. Haung, V. Sharma, K. Owens, V. Makam, \u201cBuilding Reliable \nMPLS Networks Using a Path Protection Mechanism,\u201d IEEE Communications \nMagazine , Vol. 40, No. 3 (Mar. 2002), pp. 156\u2013162.\n[Huang 2005]  Y. Huang, R. Guerin, \u201cDoes Over-Provisioning Become More or \nLess Efficient as Networks Grow Larger?,\u201d Proc. IEEE Int. Conf. Network Proto-\ncols (ICNP)  (Boston MA, Nov. 2005).\n[Huang 2008]  C. Huang, J. Li, A. Wang, K. W. Ross, \u201cUnderstanding Hybrid CDN-\nP2P: Why Limelight Needs Its Own Red Swoosh,\u201d Proc. 2008 NOSSDAV , Braunsch -\nweig, Germany.\n[Huitema 1998]  C. Huitema, IPv6: The New Internet Protocol , 2nd Ed., Prentice \nHall, Englewood Cliffs, NJ, 1998.\n[Huston 1999a]  G. Huston, \u201cInterconnection, Peering, and Settlements\u2014Part I,\u201d \nThe Internet Protocol Journal , Vol. 2, No. 1 (Mar. 1999).\n[Huston 2004]  G. Huston, \u201cNAT Anatomy: A Look Inside Network Address \nTranslators,\u201d The Internet Protocol Journal , Vol. 7, No. 3 (Sept. 2004).\n[Huston 2008a]  G. Huston, \u201cConfronting IPv4 Address", "doc_id": "324c62d1-6350-4fbc-9a28-82bfef998ad1", "embedding": null, "doc_hash": "807bea0c3092ee42db9d542e103a405477fd9a766dd3ab3277e7527d8abb9d49", "extra_info": null, "node_info": {"start": 2307413, "end": 2309977}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "aa190f9a-324e-4852-b59f-e18360b36ffb", "3": "ae658b46-ea3d-44c3-ad75-33a608ba6b23"}}, "__type__": "1"}, "ae658b46-ea3d-44c3-ad75-33a608ba6b23": {"__data__": {"text": "Needs Its Own Red Swoosh,\u201d Proc. 2008 NOSSDAV , Braunsch -\nweig, Germany.\n[Huitema 1998]  C. Huitema, IPv6: The New Internet Protocol , 2nd Ed., Prentice \nHall, Englewood Cliffs, NJ, 1998.\n[Huston 1999a]  G. Huston, \u201cInterconnection, Peering, and Settlements\u2014Part I,\u201d \nThe Internet Protocol Journal , Vol. 2, No. 1 (Mar. 1999).\n[Huston 2004]  G. Huston, \u201cNAT Anatomy: A Look Inside Network Address \nTranslators,\u201d The Internet Protocol Journal , Vol. 7, No. 3 (Sept. 2004).\n[Huston 2008a]  G. Huston, \u201cConfronting IPv4 Address Exhaustion,\u201d http://www.\npotaroo.net/ispcol/2008-10/v4depletion.html\n[Huston 2008b]  G. Huston, G. Michaelson, \u201cIPv6 Deployment: Just where are \nwe?\u201d http://www.potaroo.net/ispcol/2008-04/ipv6.html\nREFERENCES      783\n[Huston 2011a]  G. Huston, \u201cA Rough Guide to Address Exhaustion,\u201d The Internet \nProtocol Journal , Vol. 14, No. 1 (Mar. 2011).\n[Huston 2011b]  G. Huston, \u201cTransitioning Protocols,\u201d The Internet Protocol Jour-\nnal, Vol. 14, No. 1 (Mar. 2011).\n[IAB 2016]  Internet Architecture Board homepage, http://www.iab.org/\n[IANA Protocol Numbers 2016]  Internet Assigned Numbers Authority, Protocol \nNumbers, http://www.iana.org/assignments/protocol-numbers/protocol-numbers.\nxhtml\n[IBM 1997]  IBM Corp., IBM Inside APPN - The Essential Guide to the Next- \nGeneration SNA , SG24-3669-03, June 1997.\n[ICANN 2016]  The Internet Corporation for Assigned Names and Numbers \nhomepage, http://www.icann.org\n[IEEE 802 2016]  IEEE 802 LAN/MAN Standards Committee homepage, http://\nwww.ieee802.org/\n[IEEE 802.11 1999]  IEEE 802.11, \u201c1999 Edition (ISO/IEC 8802-11: 1999) IEEE \nStandards for Information Technology\u2014Telecommunications and Information \nExchange Between Systems\u2014Local and Metropolitan Area Network\u2014Specific \nRequirements\u2014Part 11: Wireless LAN Medium Access Control (MAC) and \nPhysical Layer (PHY) Specification,\u201d http://standards.ieee.org/getieee802/down-\nload/802.11-1999.pdf\n[IEEE 802.11ac 2013]  IEEE, \u201c802.11ac-2013\u2014IEEE Standard for Information \ntechnology\u2014Telecommunications and Information Exchange Between Systems\u2014\nLocal and Metropolitan Area Networks\u2014Specific Requirements\u2014Part 11: Wire-\nless LAN Medium Access Control (MAC) and Physical Layer (PHY) Specifica-\ntions\u2014Amendment 4: Enhancements for Very High Throughput for Operation in \nBands Below 6 GHz.\u201d\n[IEEE 802.11n 2012]  IEEE, \u201cIEEE P802.11\u2014Task Group N\u2014Meeting Update: \nStatus of 802.11n,\u201d http://grouper.ieee.org/groups/802/11/Reports/tgn_update \n.htm\n[IEEE 802.15 2012]  IEEE 802.15 Working Group for WPAN homepage, http://\ngrouper.ieee.org/groups/802/15/.\n[IEEE 802.15.4 2012]  IEEE 802.15 WPAN Task Group 4, http://www.ieee802.\norg/15/pub/TG4.html\n[IEEE 802.16d 2004]  IEEE, \u201cIEEE Standard for Local and Metropolitan Area \nNetworks, Part 16: Air Interface for Fixed Broadband Wireless Access Systems,\u201d \nhttp://standards.ieee.org/getieee802/download/802.16-2004.pdf\n784    ", "doc_id": "ae658b46-ea3d-44c3-ad75-33a608ba6b23", "embedding": null, "doc_hash": "5f144011efb114633a7f01ee35a80b9a4d2abbe8853a25eeff7e63d3eb90836c", "extra_info": null, "node_info": {"start": 2309910, "end": 2312788}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "324c62d1-6350-4fbc-9a28-82bfef998ad1", "3": "f928bd9b-f860-4775-9d5b-75794aac06c4"}}, "__type__": "1"}, "f928bd9b-f860-4775-9d5b-75794aac06c4": {"__data__": {"text": "Update: \nStatus of 802.11n,\u201d http://grouper.ieee.org/groups/802/11/Reports/tgn_update \n.htm\n[IEEE 802.15 2012]  IEEE 802.15 Working Group for WPAN homepage, http://\ngrouper.ieee.org/groups/802/15/.\n[IEEE 802.15.4 2012]  IEEE 802.15 WPAN Task Group 4, http://www.ieee802.\norg/15/pub/TG4.html\n[IEEE 802.16d 2004]  IEEE, \u201cIEEE Standard for Local and Metropolitan Area \nNetworks, Part 16: Air Interface for Fixed Broadband Wireless Access Systems,\u201d \nhttp://standards.ieee.org/getieee802/download/802.16-2004.pdf\n784     REFERENCES\n[IEEE 802.16e 2005]  IEEE, \u201cIEEE Standard for Local and Metropolitan Area \nNetworks, Part 16: Air Interface for Fixed and Mobile Broadband Wireless Access \nSystems, Amendment 2: Physical and Medium Access Control Layers for Com-\nbined Fixed and Mobile Operation in Licensed Bands and Corrigendum 1,\u201d http://\nstandards.ieee.org/getieee802/download/802.16e-2005.pdf\n[IEEE 802.1q 2005]  IEEE, \u201cIEEE Standard for Local and Metropolitan Area  \nNetworks: Virtual Bridged Local Area Networks,\u201d http://standards.ieee.org/ \ngetieee802/download/802.1Q-2005.pdf\n[IEEE 802.1X]  IEEE Std 802.1X-2001 Port-Based Network Access Control,  \nhttp://standards.ieee.org/reading/ieee/std_public/description/lanman/ \n802.1x-2001_desc.html\n[IEEE 802.3 2012]  IEEE, \u201cIEEE 802.3 CSMA/CD (Ethernet),\u201d http://grouper.ieee.\norg/groups/802/3/\n[IEEE 802.5 2012 ] IEEE, IEEE 802.5 homepage, http://www.ieee802.org/5/ \nwww8025org/\n[IETF 2016]  Internet Engineering Task Force homepage, http://www.ietf.org\n[Ihm 2011]  S. Ihm, V. S. Pai, \u201cTowards Understanding Modern Web Traffic,\u201d \nProc. 2011 ACM Internet Measurement Conference  (Berlin).\n[IMAP 2012]  The IMAP Connection, http://www.imap.org/\n[Intel 2016]  Intel Corp., \u201cIntel 710 Ethernet Adapter,\u201d http://www.intel.com/ \ncontent/www/us/en/ethernet-products/converged-network-adapters/ethernet-xl710 \n.html\n[Internet2 Multicast 2012]  Internet2 Multicast Working Group homepage, http://\nwww.internet2.edu/multicast/\n[ISC 2016]  Internet Systems Consortium homepage, http://www.isc.org\n[ISI 1979]  Information Sciences Institute, \u201cDoD Standard Internet Protocol,\u201d  \nInternet Engineering Note 123 (Dec. 1979), http://www.isi.edu/in-notes/ien/ \nien123.txt\n[ISO 2016]  International Organization for Standardization homepage, International \nOrganization for Standardization, http://www.iso.org/\n[ISO X.680 2002]  International Organization for Standardization, \u201cX.680: ITU-T \nRecommendation X.680 (2002) Information Technology\u2014Abstract Syntax Nota-\ntion One (ASN.1): Specification of Basic Notation,\u201d http://www.itu.int/ITU-T/\nstudygroups/com17/languages/X.680-0207.pdf\nREFERENCES      785\n[ITU 1999]  Asymmetric Digital Subscriber Line (ADSL) Transceivers. ITU-T \nG.992.1, 1999.\n[ITU 2003]  Asymmetric Digital Subscriber Line (ADSL) Transceivers\u2014Extended \nBandwidth ADSL2 (ADSL2Plus). ITU-T G.992.5, 2003.\n[ITU 2005a]  International Telecommunication", "doc_id": "f928bd9b-f860-4775-9d5b-75794aac06c4", "embedding": null, "doc_hash": "ab4ba9e3c16ea673f30f5a0e132d960f178203c32b2ee76d8423b751fce75f06", "extra_info": null, "node_info": {"start": 2312773, "end": 2315668}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "ae658b46-ea3d-44c3-ad75-33a608ba6b23", "3": "375815e8-c01f-4812-81c4-03acbb11fd81"}}, "__type__": "1"}, "375815e8-c01f-4812-81c4-03acbb11fd81": {"__data__": {"text": "X.680 2002]  International Organization for Standardization, \u201cX.680: ITU-T \nRecommendation X.680 (2002) Information Technology\u2014Abstract Syntax Nota-\ntion One (ASN.1): Specification of Basic Notation,\u201d http://www.itu.int/ITU-T/\nstudygroups/com17/languages/X.680-0207.pdf\nREFERENCES      785\n[ITU 1999]  Asymmetric Digital Subscriber Line (ADSL) Transceivers. ITU-T \nG.992.1, 1999.\n[ITU 2003]  Asymmetric Digital Subscriber Line (ADSL) Transceivers\u2014Extended \nBandwidth ADSL2 (ADSL2Plus). ITU-T G.992.5, 2003.\n[ITU 2005a]  International Telecommunication Union, \u201cITU-T X.509, The Direc-\ntory: Public-key and attribute certificate frameworks\u201d (Aug. 2005).\n[ITU 2006]  ITU, \u201cG.993.1: Very High Speed Digital Subscriber Line Transceivers \n(VDSL),\u201d https://www.itu.int/rec/T-REC-G.993.1-200406-I/en, 2006.\n[ITU 2015]  \u201cMeasuring the Information Society Report,\u201d 2015, http://www.itu.int/\nen/ITU-D/Statistics/Pages/publications/mis2015.aspx\n[ITU 2012]  The ITU homepage, http://www.itu.int/\n[ITU-T Q.2931 1995]  International Telecommunication Union, \u201cRecommendation \nQ.2931 (02/95)\u2014Broadband Integrated Services Digital Network (B-ISDN)\u2014 \nDigital Subscriber Signalling System No. 2 (DSS 2)\u2014User-Network Interface \n(UNI)\u2014Layer 3 Specification for Basic Call/Connection Control.\u201d\n[IXP List 2016]  List of IXPs, Wikipedia, https://en.wikipedia.org/wiki/List_of_ \nInternet_exchange_points\n[Iyengar 2015]  J. Iyengar, I. Swett, \u201cQUIC: A UDP-Based Secure and Reliable \nTransport for HTTP/2,\u201d Internet Draft draft-tsvwg-quic-protocol-00, June 2015.\n[Iyer 2008]  S. Iyer, R. R. Kompella, N. McKeown, \u201cDesigning Packet Buffers for \nRouter Line Cards,\u201d IEEE Transactions on Networking , Vol. 16, No. 3 (June 2008), \npp. 705\u2013717.\n[Jacobson 1988]  V. Jacobson, \u201cCongestion Avoidance and Control,\u201d Proc. 1988 \nACM SIGCOMM  (Stanford, CA, Aug. 1988), pp. 314\u2013329.\n[Jain 1986]  R. Jain, \u201cA Timeout-Based Congestion Control Scheme for Window \nFlow-Controlled Networks,\u201d IEEE Journal on Selected Areas in Communications \nSAC-4 , 7 (Oct. 1986).\n[Jain 1989]  R. Jain, \u201cA Delay-Based Approach for Congestion Avoidance in \nInterconnected Heterogeneous Computer Networks,\u201d ACM SIGCOMM Computer \nCommunications Review , Vol. 19, No. 5 (1989), pp. 56\u201371.\n[Jain 1994]  R. Jain, FDDI Handbook: High-Speed Networking Using Fiber and \nOther Media , Addison-Wesley, Reading, MA, 1994.\n[Jain 1996]  R. Jain. S. Kalyanaraman, S. Fahmy, R. Goyal, S. Kim, \u201cTutorial \nPaper on ABR Source Behavior,\u201d ATM Forum /96-1270, Oct. 1996. http://www.cse.\nwustl.edu/~jain/atmf/ftp/atm96-1270.pdf\n786     REFERENCES\n[Jain 2013]  S. Jain, A. Kumar, S. Mandal, J. Ong, L. Poutievski, A. Singh, \nS.Venkata, J. Wanderer, J. Zhou, M. Zhu, J. Zolla, U.", "doc_id": "375815e8-c01f-4812-81c4-03acbb11fd81", "embedding": null, "doc_hash": "ecbc715e8bb3cda42e8defb1e5ba109e550b2f7dda6de1d0dec9e1f7b0ac5402", "extra_info": null, "node_info": {"start": 2315637, "end": 2318331}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "f928bd9b-f860-4775-9d5b-75794aac06c4", "3": "78d7588b-c5d6-4c2f-8be2-3a03941d386e"}}, "__type__": "1"}, "78d7588b-c5d6-4c2f-8be2-3a03941d386e": {"__data__": {"text": "Networking Using Fiber and \nOther Media , Addison-Wesley, Reading, MA, 1994.\n[Jain 1996]  R. Jain. S. Kalyanaraman, S. Fahmy, R. Goyal, S. Kim, \u201cTutorial \nPaper on ABR Source Behavior,\u201d ATM Forum /96-1270, Oct. 1996. http://www.cse.\nwustl.edu/~jain/atmf/ftp/atm96-1270.pdf\n786     REFERENCES\n[Jain 2013]  S. Jain, A. Kumar, S. Mandal, J. Ong, L. Poutievski, A. Singh, \nS.Venkata, J. Wanderer, J. Zhou, M. Zhu, J. Zolla, U. H\u00f6lzle, S. Stuart, A, Vahdat, \n\u201cB4: Experience with a Globally Deployed Software Defined Wan,\u201d ACM  \nSIGCOMM 2013 , pp. 3\u201314.\n[Jaiswal 2003]  S. Jaiswal, G. Iannaccone, C. Diot, J. Kurose, D. Towsley, \u201cMea-\nsurement and Classification of Out-of-Sequence Packets in a Tier-1 IP backbone,\u201d \nProc. 2003 IEEE INFOCOM .\n[Ji 2003]  P. Ji, Z. Ge, J. Kurose, D. Towsley, \u201cA Comparison of Hard-State and \nSoft-State Signaling Protocols,\u201d Proc. 2003 ACM SIGCOMM  (Karlsruhe, Ger-\nmany, Aug. 2003).\n[Jimenez 1997]  D. Jimenez, \u201cOutside Hackers Infiltrate MIT Network, Compro-\nmise Security,\u201d The Tech , Vol. 117, No 49 (Oct. 1997), p. 1, http://www-tech.mit.\nedu/V117/N49/hackers.49n.html\n[Jin 2004]  C. Jin, D. X. We, S. Low, \u201cFAST TCP: Motivation, Architecture,  \nAlgorithms, Performance,\u201d Proc. 2004 IEEE INFOCOM  (Hong Kong,  \nMar. 2004).\n[Juniper Contrail 2016]  Juniper Networks, \u201cContrail,\u201d http://www.juniper.net/us/\nen/products-services/sdn/contrail/\n[Juniper MX2020 2015]  Juniper Networks, \u201cMX2020 and MX2010 3D Universal \nEdge Routers,\u201d www.juniper.net/us/en/local/pdf/.../1000417-en.pdf\n[Kaaranen 2001]  H. Kaaranen, S. Naghian, L. Laitinen, A. Ahtiainen, V. Niemi, \nNetworks: Architecture, Mobility and Services , New York: John Wiley & Sons, \n2001.\n[Kahn 1967]  D. Kahn, The Codebreakers: The Story of Secret Writing , The  \nMacmillan Company, 1967.\n[Kahn 1978]  R. E. Kahn, S. Gronemeyer, J. Burchfiel, R. Kunzelman,  \n\u201cAdvances in Packet Radio Technology,\u201d Proc. 1978 IEEE INFOCOM , 66, 11 \n(Nov. 1978).\n[Kamerman 1997]  A. Kamerman, L. Monteban, \u201cWaveLAN-II: A High\u2013 \nPerformance Wireless LAN for the Unlicensed Band,\u201d Bell Labs Technical Journal  \n(Summer 1997), pp. 118\u2013133.\n[Kar 2000]  K. Kar, M. Kodialam, T. V. Lakshman, \u201cMinimum Interference Rout-\ning of Bandwidth Guaranteed Tunnels with MPLS Traffic Engineering Applica-\ntions,\u201d IEEE J. Selected Areas in Communications  (Dec. 2000).\n[Karn 1987]  P. Karn, C. Partridge, \u201cImproving Round-Trip Time Estimates in \nReliable Transport Protocols,\u201d Proc. 1987 ACM SIGCOMM .\nREFERENCES     ", "doc_id": "78d7588b-c5d6-4c2f-8be2-3a03941d386e", "embedding": null, "doc_hash": "340de30b5846013a826fde5042dd50a68162a77d17e0659d01b5565a28721ad8", "extra_info": null, "node_info": {"start": 2318467, "end": 2320937}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "375815e8-c01f-4812-81c4-03acbb11fd81", "3": "24a28517-c435-4a31-841f-1035c01f3d5f"}}, "__type__": "1"}, "24a28517-c435-4a31-841f-1035c01f3d5f": {"__data__": {"text": "1997]  A. Kamerman, L. Monteban, \u201cWaveLAN-II: A High\u2013 \nPerformance Wireless LAN for the Unlicensed Band,\u201d Bell Labs Technical Journal  \n(Summer 1997), pp. 118\u2013133.\n[Kar 2000]  K. Kar, M. Kodialam, T. V. Lakshman, \u201cMinimum Interference Rout-\ning of Bandwidth Guaranteed Tunnels with MPLS Traffic Engineering Applica-\ntions,\u201d IEEE J. Selected Areas in Communications  (Dec. 2000).\n[Karn 1987]  P. Karn, C. Partridge, \u201cImproving Round-Trip Time Estimates in \nReliable Transport Protocols,\u201d Proc. 1987 ACM SIGCOMM .\nREFERENCES      787\n[Karol 1987]  M. Karol, M. Hluchyj, A. Morgan, \u201cInput Versus Output Queuing on \na Space-Division Packet Switch,\u201d IEEE Transactions on Communications , Vol. 35, \nNo. 12 (Dec.1987), pp. 1347\u20131356.\n[Kaufman 1995]  C. Kaufman, R. Perlman, M. Speciner, Network Security, Private \nCommunication in a Public World , Prentice Hall, Englewood Cliffs, NJ, 1995.\n[Kelly 1998]  F. P. Kelly, A. Maulloo, D. Tan, \u201cRate Control for Communication \nNetworks: Shadow Prices, Proportional Fairness and Stability,\u201d J. Operations Res. \nSoc., Vol. 49, No. 3 (Mar. 1998), pp. 237\u2013252.\n[Kelly 2003]  T. Kelly, \u201cScalable TCP: Improving Performance in High Speed \nWide Area  \nNetworks,\u201d ACM SIGCOMM Computer Communications Review , Volume 33, No. \n2 (Apr. 2003), pp 83\u201391.\n[Kilkki 1999]  K. Kilkki, Differentiated Services for the Internet , Macmillan Tech-\nnical Publishing, Indianapolis, IN, 1999.\n[Kim 2005]  H. Kim, S. Rixner, V. Pai, \u201cNetwork Interface Data Caching,\u201d IEEE \nTransactions on Computers , Vol. 54, No. 11 (Nov. 2005), pp. 1394\u20131408.\n[Kim 2008]  C. Kim, M. Caesar, J. Rexford, \u201cFloodless in SEATTLE: A Scalable \nEthernet Architecture for Large Enterprises,\u201d Proc. 2008 ACM SIGCOMM  (Se-\nattle, WA, Aug. 2008).\n[Kleinrock 1961]  L. Kleinrock, \u201cInformation Flow in Large Communication Net-\nworks,\u201d RLE Quarterly Progress Report, July 1961.\n[Kleinrock 1964]  L. Kleinrock, 1964 Communication Nets: Stochastic Message \nFlow and Delay , McGraw-Hill, New York, NY, 1964.\n[Kleinrock 1975]  L. Kleinrock, Queuing Systems, Vol. 1 , John Wiley, New York, \n1975.\n[Kleinrock 1975b]  L. Kleinrock, F. A. Tobagi, \u201cPacket Switching in Radio Chan-\nnels: Part I\u2014Carrier Sense Multiple-Access Modes and Their Throughput-Delay \nCharacteristics,\u201d IEEE Transactions on Communications , Vol. 23, No. 12 (Dec. \n1975), pp. 1400\u20131416.\n[Kleinrock 1976]  L. Kleinrock, Queuing Systems, Vol. 2 , John Wiley, New York, \n1976.\n[Kleinrock 2004]  L. Kleinrock, \u201cThe Birth of the Internet,\u201d http://www.lk.cs.ucla.\nedu/LK/Inet/birth.html\n[Kohler 2006]  E. Kohler, M. Handley, S. Floyd, \u201cDDCP: Designing DCCP: \nCongestion Control Without Reliability,\u201d Proc. 2006 ACM SIGCOMM  (Pisa, Italy, \nSept. 2006).\n788     REFERENCES\n[Kolding 2003]  T. Kolding, K. Pedersen, J. Wigard, F. Frederiksen,", "doc_id": "24a28517-c435-4a31-841f-1035c01f3d5f", "embedding": null, "doc_hash": "d63701597cab7a4dcb54d339c30c0ef3724deef36e51a44fe570cd5d23a411df", "extra_info": null, "node_info": {"start": 2320848, "end": 2323626}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "78d7588b-c5d6-4c2f-8be2-3a03941d386e", "3": "f1ee7129-cc5a-41fa-ad7f-af7e253eeb71"}}, "__type__": "1"}, "f1ee7129-cc5a-41fa-ad7f-af7e253eeb71": {"__data__": {"text": "pp. 1400\u20131416.\n[Kleinrock 1976]  L. Kleinrock, Queuing Systems, Vol. 2 , John Wiley, New York, \n1976.\n[Kleinrock 2004]  L. Kleinrock, \u201cThe Birth of the Internet,\u201d http://www.lk.cs.ucla.\nedu/LK/Inet/birth.html\n[Kohler 2006]  E. Kohler, M. Handley, S. Floyd, \u201cDDCP: Designing DCCP: \nCongestion Control Without Reliability,\u201d Proc. 2006 ACM SIGCOMM  (Pisa, Italy, \nSept. 2006).\n788     REFERENCES\n[Kolding 2003]  T. Kolding, K. Pedersen, J. Wigard, F. Frederiksen, P. Mogensen, \n\u201cHigh Speed Downlink Packet Access: WCDMA Evolution,\u201d IEEE Vehicular \nTechnology Society News  (Feb. 2003), pp. 4\u201310.\n[Koponen 2010]  T. Koponen, M. Casado, N. Gude, J. Stribling, L. Poutievski,  \nM. Zhu, R. Ramanathan, Y. Iwata, H. Inoue, T. Hama, S. Shenker, \u201cOnix: A \nDistributed Control Platform for Large-Scale Production Networks,\u201d 9th USENIX \nconference on Operating systems design and implementation  (OSDI\u201910) , pp. 1\u20136.\n[Koponen 2011]  T. Koponen, S. Shenker, H. Balakrishnan, N. Feamster, I. \nGanichev, A. Ghodsi, P. B. Godfrey, N. McKeown, G. Parulkar, B. Raghavan, J. \nRexford, S. Arianfar, D. Kuptsov, \u201cArchitecting for Innovation,\u201d ACM Computer \nCommunications Review , 2011.\n[Korhonen 2003]  J. Korhonen, Introduction to 3G Mobile Communications , 2nd \ned., Artech House, 2003.\n[Koziol 2003]  J. Koziol, Intrusion Detection with Snort , Sams Publishing, 2003.\n[Kreutz 2015]  D. Kreutz, F.M.V. Ramos, P. Esteves Verissimo, C. Rothenberg,  \nS. Azodolmolky, S. Uhlig, \u201cSoftware-Defined Networking: A Comprehensive  \nSurvey,\u201d Proceedings of the IEEE , Vol. 103, No. 1 (Jan. 2015), pp. 14-76.  \nThis paper is also being updated at https://github.com/SDN-Survey/latex/wiki\n[Krishnamurthy 2001]  B. Krishnamurthy, J. Rexford, Web Protocols and Prac-\ntice: HTTP/ 1.1, Networking Protocols, and Traffic Measurement , Addison-Wes-\nley, Boston, MA, 2001.\n[Kulkarni 2005]  S. Kulkarni, C. Rosenberg, \u201cOpportunistic Scheduling: General-\nizations to Include Multiple Constraints, Multiple Interfaces, and Short Term Fair-\nness,\u201d Wireless Networks , 11 (2005), 557\u2013569.\n[Kumar 2006]  R. Kumar, K.W. Ross, \u201cOptimal Peer-Assisted File Distribution: \nSingle and Multi-Class Problems,\u201d IEEE Workshop on Hot Topics in Web Systems \nand Technologies  (Boston, MA, 2006).\n[Labovitz 1997]  C. Labovitz, G. R. Malan, F. Jahanian, \u201cInternet Routing Instabil-\nity,\u201d Proc. 1997 ACM SIGCOMM  (Cannes, France, Sept. 1997), pp. 115\u2013126.\n[Labovitz 2010]  C. Labovitz, S. Iekel-Johnson, D. McPherson, J. Oberheide, F. \nJahanian, \u201cInternet Inter-Domain Traffic,\u201d Proc. 2010 ACM SIGCOMM .\n[Labrador 1999]  M. Labrador, S. Banerjee,", "doc_id": "f1ee7129-cc5a-41fa-ad7f-af7e253eeb71", "embedding": null, "doc_hash": "589db80d6fd3fdfcb8d9c85d85b4a34bd58f44776291f849426571f92dc2af46", "extra_info": null, "node_info": {"start": 2323680, "end": 2326267}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "24a28517-c435-4a31-841f-1035c01f3d5f", "3": "026e893b-acf4-46d0-9d9b-f87519604bb7"}}, "__type__": "1"}, "026e893b-acf4-46d0-9d9b-f87519604bb7": {"__data__": {"text": "Ross, \u201cOptimal Peer-Assisted File Distribution: \nSingle and Multi-Class Problems,\u201d IEEE Workshop on Hot Topics in Web Systems \nand Technologies  (Boston, MA, 2006).\n[Labovitz 1997]  C. Labovitz, G. R. Malan, F. Jahanian, \u201cInternet Routing Instabil-\nity,\u201d Proc. 1997 ACM SIGCOMM  (Cannes, France, Sept. 1997), pp. 115\u2013126.\n[Labovitz 2010]  C. Labovitz, S. Iekel-Johnson, D. McPherson, J. Oberheide, F. \nJahanian, \u201cInternet Inter-Domain Traffic,\u201d Proc. 2010 ACM SIGCOMM .\n[Labrador 1999]  M. Labrador, S. Banerjee, \u201cPacket Dropping Policies for ATM \nand IP Networks,\u201d IEEE Communications Surveys , Vol. 2, No. 3 (Third Quarter \n1999), pp. 2\u201314.\n[Lacage 2004]  M. Lacage, M.H. Manshaei, T. Turletti, \u201cIEEE 802.11 Rate Adapta-\ntion: A Practical Approach,\u201d ACM Int. Symposium on Modeling, Analysis, and \nSimulation of Wireless and Mobile Systems (MSWiM)  (Venice, Italy, Oct. 2004).\nREFERENCES      789\n[Lakhina 2004]  A. Lakhina, M. Crovella, C. Diot, \u201cDiagnosing Network-Wide \nTraffic Anomalies,\u201d Proc. 2004 ACM SIGCOMM .\n[Lakhina 2005]  A. Lakhina, M. Crovella, C. Diot, \u201cMining Anomalies Using Traf-\nfic Feature Distributions,\u201d Proc. 2005 ACM SIGCOMM .\n[Lakshman 1997]  T. V. Lakshman, U. Madhow, \u201cThe Performance of TCP/IP for \nNetworks with High Bandwidth-Delay Products and Random Loss,\u201d IEEE/ACM \nTransactions on Networking , Vol. 5, No. 3 (1997), pp. 336\u2013350.\n[Lakshman 2004]  T. V. Lakshman, T. Nandagopal, R. Ramjee, K. Sabnani, T. \nWoo, \u201cThe SoftRouter Architecture,\u201d Proc. 3nd ACM Workshop on Hot Topics in \nNetworks (Hotnets-III) , Nov. 2004.\n[Lam 1980]  S. Lam, \u201cA Carrier Sense Multiple Access Protocol for Local Net-\nworks,\u201d Computer Networks , Vol. 4 (1980), pp. 21\u201332.\n[Lamport 1989]  L. Lamport, \u201cThe Part-Time Parliament,\u201d Technical Report 49, \nSystems Research Center, Digital Equipment Corp., Palo Alto, Sept. 1989.\n[Lampson 1983]  Lampson, Butler W. \u201cHints for computer system design,\u201d ACM \nSIGOPS Operating Systems Review , Vol. 17, No. 5, 1983.\n[Lampson 1996]  B. Lampson, \u201cHow to Build a Highly Available System Using \nConsensus,\u201d Proc. 10th International Workshop on Distributed Algorithms  (WDAG \n\u201996), \u00d6zalp Babaoglu and Keith Marzullo (Eds.), Springer-Verlag, pp. 1\u201317.\n[Lawton 2001]  G. Lawton, \u201cIs IPv6 Finally Gaining Ground?\u201d IEEE Computer \nMagazine  (Aug. 2001), pp. 11\u201315.\n[LeBlond 2011]  S. Le Blond, C. Zhang, A. Legout, K. Ross, W. Dabbous. 2011,  \n\u201cI know where you are and what you are sharing: exploiting P2P communications \nto invade users\u2019 privacy.\u201d 2011 ACM Internet Measurement Conference , ACM, \nNew York, NY, USA, pp. 45\u201360.\n[Leighton 2009]  T. Leighton, \u201cImproving Performance on the Internet,\u201d Communi-\ncations of the ACM , Vol. 52,", "doc_id": "026e893b-acf4-46d0-9d9b-f87519604bb7", "embedding": null, "doc_hash": "7e102646f961513e220ed4d956ebbe7e9d27f8ac6b5aaa8a08d32e54df105819", "extra_info": null, "node_info": {"start": 2326223, "end": 2328901}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "f1ee7129-cc5a-41fa-ad7f-af7e253eeb71", "3": "61b52c42-716f-4b5f-9eb7-c8ced71af64a"}}, "__type__": "1"}, "61b52c42-716f-4b5f-9eb7-c8ced71af64a": {"__data__": {"text": "and Keith Marzullo (Eds.), Springer-Verlag, pp. 1\u201317.\n[Lawton 2001]  G. Lawton, \u201cIs IPv6 Finally Gaining Ground?\u201d IEEE Computer \nMagazine  (Aug. 2001), pp. 11\u201315.\n[LeBlond 2011]  S. Le Blond, C. Zhang, A. Legout, K. Ross, W. Dabbous. 2011,  \n\u201cI know where you are and what you are sharing: exploiting P2P communications \nto invade users\u2019 privacy.\u201d 2011 ACM Internet Measurement Conference , ACM, \nNew York, NY, USA, pp. 45\u201360.\n[Leighton 2009]  T. Leighton, \u201cImproving Performance on the Internet,\u201d Communi-\ncations of the ACM , Vol. 52, No. 2 (Feb. 2009), pp. 44\u201351.\n[Leiner 1998]  B. Leiner, V. Cerf, D. Clark, R. Kahn, L. Kleinrock, D. Lynch, J. \nPostel, L. Roberts, S. Woolf, \u201cA Brief History of the Internet,\u201d http://www.isoc.\norg/internet/history/brief.html\n[Leung 2006]  K. Leung, V. O.K. Li, \u201cTCP in Wireless Networks: Issues,  \nApproaches, and Challenges,\u201d IEEE Commun. Surveys and Tutorials , Vol. 8, No. 4 \n(2006), pp. 64\u201379.\n[Levin 2012]  D. Levin, A. Wundsam, B. Heller, N. Handigol, A. Feldmann, \u201cLogi-\ncally Centralized?: State Distribution Trade-offs in Software Defined Networks,\u201d \nProc. First Workshop on Hot Topics in Software Defined Networks  (Aug. 2012), \npp. 1\u20136.\n790     REFERENCES\n[Li 2004]  L. Li, D. Alderson, W. Willinger, J. Doyle, \u201cA First-Principles Approach \nto Understanding the Internet\u2019s Router-Level Topology,\u201d Proc. 2004 ACM SIG-\nCOMM  (Portland, OR, Aug. 2004).\n[Li 2007]  J. Li, M. Guidero, Z. Wu, E. Purpus, T. Ehrenkranz, \u201cBGP Routing  \nDynamics Revisited.\u201d ACM Computer Communication Review  (Apr. 2007).\n[Li 2015]  S.Q. Li, \u201cBuilding Softcom Ecosystem Foundation,\u201d Open Networking \nSummit, 2015.\n[Lin 2001]  Y. Lin, I. Chlamtac, Wireless and Mobile Network Architectures , John \nWiley and Sons, New York, NY, 2001.\n[Liogkas 2006]  N. Liogkas, R. Nelson, E. Kohler, L. Zhang, \u201cExploiting BitTor-\nrent for Fun (but Not Profit),\u201d 6th International Workshop on Peer-to-Peer Systems \n(IPTPS 2006).\n[Liu 2003]  J. Liu, I. Matta, M. Crovella, \u201cEnd-to-End Inference of Loss Nature in \na Hybrid Wired/Wireless Environment,\u201d Proc. WiOpt\u201903: Modeling and Optimiza-\ntion in Mobile, Ad Hoc and Wireless Networks .\n[Locher 2006]  T. Locher, P. Moor, S. Schmid, R. Wattenhofer, \u201cFree Riding in \nBitTorrent is Cheap,\u201d Proc. ACM HotNets 2006 (Irvine CA, Nov. 2006).\n[Lui 2004]  J. Lui, V. Misra, D. Rubenstein, \u201cOn the Robustness of Soft State Pro-\ntocols,\u201d Proc. IEEE Int. Conference on Network Protocols (ICNP \u201904) , pp. 50\u201360.\n[Mahdavi 1997]  J. Mahdavi, S. Floyd, \u201cTCP-Friendly Unicast Rate-Based Flow \nControl,\u201d unpublished note (Jan. 1997).\n[MaxMind 2016] ", "doc_id": "61b52c42-716f-4b5f-9eb7-c8ced71af64a", "embedding": null, "doc_hash": "f7b69c3800029c3d8f8ee08b98de64c784f443977d5e0ba452633f9d46d546a6", "extra_info": null, "node_info": {"start": 2328891, "end": 2331478}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "026e893b-acf4-46d0-9d9b-f87519604bb7", "3": "8ea37156-d79d-4225-9625-3a81fd5a4c94"}}, "__type__": "1"}, "8ea37156-d79d-4225-9625-3a81fd5a4c94": {"__data__": {"text": "in Mobile, Ad Hoc and Wireless Networks .\n[Locher 2006]  T. Locher, P. Moor, S. Schmid, R. Wattenhofer, \u201cFree Riding in \nBitTorrent is Cheap,\u201d Proc. ACM HotNets 2006 (Irvine CA, Nov. 2006).\n[Lui 2004]  J. Lui, V. Misra, D. Rubenstein, \u201cOn the Robustness of Soft State Pro-\ntocols,\u201d Proc. IEEE Int. Conference on Network Protocols (ICNP \u201904) , pp. 50\u201360.\n[Mahdavi 1997]  J. Mahdavi, S. Floyd, \u201cTCP-Friendly Unicast Rate-Based Flow \nControl,\u201d unpublished note (Jan. 1997).\n[MaxMind 2016]  http://www.maxmind.com/app/ip-location\n[Maymounkov 2002]  P. Maymounkov, D. Mazi\u00e8res. \u201cKademlia: A Peer-to-Peer \nInformation System Based on the XOR Metric.\u201d Proceedings of the 1st Interna-\ntional Workshop on Peerto-Peer Systems (IPTPS \u201802)  (Mar. 2002), pp. 53\u201365.\n[McKeown 1997a]  N. McKeown, M. Izzard, A. Mekkittikul, W. Ellersick, M. \nHorowitz, \u201cThe Tiny Tera: A Packet Switch Core,\u201d IEEE Micro Magazine   \n(Jan.\u2013Feb. 1997).\n[McKeown 1997b]  N. McKeown, \u201cA Fast Switched Backplane for a Gigabit \nSwitched Router,\u201d Business Communications Review , Vol. 27, No. 12. http://tiny-\ntera.stanford.edu/~nickm/papers/cisco_fasts_wp.pdf\n[McKeown 2008]  N. McKeown, T. Anderson, H. Balakrishnan, G. Parulkar,  \nL. Peterson, J. Rexford, S. Shenker, J. Turner. 2008. OpenFlow: Enabling Innova-\ntion in Campus Networks. SIGCOMM Comput. Commun. Rev.  38, 2 (Mar. 2008),  \npp. 69\u201374.\nREFERENCES      791\n[McQuillan 1980]  J. McQuillan, I. Richer, E. Rosen, \u201cThe New Routing Algo-\nrithm for the Arpanet,\u201d IEEE Transactions on Communications , Vol. 28, No. 5 \n(May 1980), pp. 711\u2013719.\n[Metcalfe 1976]  R. M. Metcalfe, D. R. Boggs. \u201cEthernet: Distributed Packet \nSwitching for Local Computer Networks,\u201d Communications of the Association for \nComputing Machinery , Vol. 19, No. 7 (July 1976), pp. 395\u2013404.\n[Meyers 2004]  A. Myers, T. Ng, H. Zhang, \u201cRethinking the Service Model: Scal-\ning Ethernet to a Million Nodes, \u201d ACM Hotnets Conference , 2004.\n[MFA Forum 2016]  IP/MPLS Forum homepage, http://www.ipmplsforum.org/\n[Mockapetris 1988 ] P. V. Mockapetris, K. J. Dunlap, \u201cDevelopment of the Do-\nmain Name System,\u201d Proc. 1988 ACM SIGCOMM  (Stanford, CA, Aug. 1988).\n[Mockapetris 2005]  P. Mockapetris, Sigcomm Award Lecture, video available at \nhttp://www.postel.org/sigcomm\n[Molinero-Fernandez 2002]  P. Molinaro-Fernandez, N. McKeown, H. Zhang, \n\u201cIs IP Going to Take Over the World (of Communications)?\u201d Proc. 2002 ACM \nHotnets .\n[Molle 1987]  M. L. Molle, K. Sohraby, A. N. Venetsanopoulos, \u201cSpace-Time \nModels of Asynchronous CSMA Protocols for Local Area Networks,\u201d", "doc_id": "8ea37156-d79d-4225-9625-3a81fd5a4c94", "embedding": null, "doc_hash": "91b81af42e43cb80dd82f4f37e75adc5608b86203ca7bfd8069dfa934bfe1b0f", "extra_info": null, "node_info": {"start": 2331520, "end": 2334065}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "61b52c42-716f-4b5f-9eb7-c8ced71af64a", "3": "16324afe-0c23-44d3-85ab-e728f6c62477"}}, "__type__": "1"}, "16324afe-0c23-44d3-85ab-e728f6c62477": {"__data__": {"text": "K. J. Dunlap, \u201cDevelopment of the Do-\nmain Name System,\u201d Proc. 1988 ACM SIGCOMM  (Stanford, CA, Aug. 1988).\n[Mockapetris 2005]  P. Mockapetris, Sigcomm Award Lecture, video available at \nhttp://www.postel.org/sigcomm\n[Molinero-Fernandez 2002]  P. Molinaro-Fernandez, N. McKeown, H. Zhang, \n\u201cIs IP Going to Take Over the World (of Communications)?\u201d Proc. 2002 ACM \nHotnets .\n[Molle 1987]  M. L. Molle, K. Sohraby, A. N. Venetsanopoulos, \u201cSpace-Time \nModels of Asynchronous CSMA Protocols for Local Area Networks,\u201d IEEE Jour-\nnal on Selected Areas in Communications , Vol. 5, No. 6 (1987), pp. 956\u2013968.\n[Moore 2001]  D. Moore, G. Voelker, S. Savage, \u201cInferring Internet Denial of Ser-\nvice Activity,\u201d Proc. 2001 USENIX Security Symposium  (Washington, DC, Aug. \n2001).\n[Motorola 2007]  Motorola, \u201cLong Term Evolution (LTE): A Technical Overview,\u201d  \n http://www.motorola.com/staticfiles/Business/Solutions/Industry%20Solu-\ntions/Service%20Providers/Wireless%20Operators/LTE/_Document/Static%20\nFiles/6834_MotDoc_New.pdf\n[Mouly 1992]  M. Mouly, M. Pautet, The GSM System for Mobile Communications , \nCell and Sys, Palaiseau, France, 1992.\n[Moy 1998]  J. Moy, OSPF: Anatomy of An Internet Routing Protocol , Addison-\nWesley, Reading, MA, 1998.\n[Mukherjee 1997]  B. Mukherjee, Optical Communication Networks , McGraw-\nHill, 1997.\n[Mukherjee 2006]  B. Mukherjee, Optical WDM Networks , Springer, 2006.\n[Mysore 2009]  R. N. Mysore, A. Pamboris, N. Farrington, N. Huang, P. Miri,  \nS. Radhakrishnan, V. Subramanya, A. Vahdat, \u201cPortLand: A Scalable Fault- \nTolerant Layer 2 Data Center Network Fabric,\u201d Proc. 2009 ACM SIGCOMM .\n792     REFERENCES\n[Nahum 2002]  E. Nahum, T. Barzilai, D. Kandlur, \u201cPerformance Issues in WWW \nServers,\u201d IEEE/ACM Transactions on Networking , Vol 10, No. 1 (Feb. 2002).\n[Netflix Open Connect 2016]  Netflix Open Connect CDN, 2016, https:// \nopenconnect.netflix.com/\n[Netflix Video 1]  Designing Netflix\u2019s Content Delivery System, D. Fulllager, \n2014, https://www.youtube.com/watch?v=LkLLpYdDINA\n[Netflix Video 2]  Scaling the Netflix Global CDN, D. Temkin, 2015, https://www \n.youtube.com/watch?v=tbqcsHg-Q_o\n[Neumann 1997]  R. Neumann, \u201cInternet Routing Black Hole,\u201d The Risks Digest: \nForum on Risks to the Public in Computers and Related Systems , Vol. 19, No. 12 \n(May 1997). http://catless.ncl.ac.uk/Risks/19.12.html#subj1.1\n[Neville-Neil 2009]  G. Neville-Neil, \u201cWhither Sockets?\u201d Communications of the \nACM , Vol. 52, No. 6 (June 2009), pp. 51\u201355.\n[Nicholson 2006]  A Nicholson, Y. Chawathe, M. Chen, B. Noble, D. Wetherall, \n\u201cImproved Access Point Selection,\u201d Proc. 2006 ACM Mobisys Conference   \n(Uppsala Sweden, 2006).\n[Nielsen 1997]  H. F.", "doc_id": "16324afe-0c23-44d3-85ab-e728f6c62477", "embedding": null, "doc_hash": "cab3ee766bc81c1ef66dabee2f22f0b7f57d021e0494a8c3af815f0c3fc43cd8", "extra_info": null, "node_info": {"start": 2334036, "end": 2336705}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "8ea37156-d79d-4225-9625-3a81fd5a4c94", "3": "30016a60-1c80-4d34-8d5e-b059775ed3e3"}}, "__type__": "1"}, "30016a60-1c80-4d34-8d5e-b059775ed3e3": {"__data__": {"text": "\u201cInternet Routing Black Hole,\u201d The Risks Digest: \nForum on Risks to the Public in Computers and Related Systems , Vol. 19, No. 12 \n(May 1997). http://catless.ncl.ac.uk/Risks/19.12.html#subj1.1\n[Neville-Neil 2009]  G. Neville-Neil, \u201cWhither Sockets?\u201d Communications of the \nACM , Vol. 52, No. 6 (June 2009), pp. 51\u201355.\n[Nicholson 2006]  A Nicholson, Y. Chawathe, M. Chen, B. Noble, D. Wetherall, \n\u201cImproved Access Point Selection,\u201d Proc. 2006 ACM Mobisys Conference   \n(Uppsala Sweden, 2006).\n[Nielsen 1997]  H. F. Nielsen, J. Gettys, A. Baird-Smith, E. Prud\u2019hommeaux, H. W. \nLie, C. Lilley, \u201cNetwork Performance Effects of HTTP/1.1, CSS1, and PNG,\u201d W3C \nDocument , 1997 (also appears in Proc. 1997 ACM SIGCOM  (Cannes, France, Sept \n1997), pp. 155\u2013166.\n[NIST 2001]  National Institute of Standards and Technology, \u201cAdvanced Encryp-\ntion Standard (AES),\u201d Federal Information Processing Standards 197, Nov. 2001, \nhttp://csrc.nist.gov/publications/fips/fips197/fips-197.pdf\n[NIST IPv6 2015]  US National Institute of Standards and Technology, \u201cEstimating \nIPv6 & DNSSEC Deployment SnapShots,\u201d http://fedv6-deployment.antd.nist.gov/\nsnap-all.html\n[Nmap 2012]  Nmap homepage, http://www.insecure.com/nmap\n[Nonnenmacher 1998]  J. Nonnenmacher, E. Biersak, D. Towsley, \u201cParity-Based \nLoss Recovery for Reliable Multicast Transmission,\u201d IEEE/ACM Transactions on \nNetworking , Vol. 6, No. 4 (Aug. 1998), pp. 349\u2013361.\n[Nygren 2010]  Erik Nygren, Ramesh K. Sitaraman, and Jennifer Sun, \u201cThe Aka-\nmai Network: A Platform for High-performance Internet Applications,\u201d SIGOPS \nOper. Syst. Rev.  44, 3 (Aug. 2010), 2\u201319.\n[ONF 2016 ] Open Networking Foundation, Technical Library, https://www.open-\nnetworking.org/sdn-resources/technical-library\nREFERENCES      793\n[ONOS 2016]  Open Network Operating System (ONOS), \u201cArchitecture Guide,\u201d \nhttps://wiki.onosproject.org/display/ONOS/Architecture+Guide, 2016.\n[OpenFlow 2009]  Open Network Foundation, \u201cOpenFlow Switch Specification \n1.0.0, TS-001,\u201d https://www.opennetworking.org/images/stories/downloads/sdn-\nresources/onf-specifications/openflow/openflow-spec-v1.0.0.pdf\n[OpenDaylight Lithium 2016]  OpenDaylight, \u201cLithium,\u201d https://www.openday-\nlight.org/lithium\n[OSI 2012]  International Organization for Standardization homepage, http://www.\niso.org/iso/en/ISOOnline.frontpage\n[Osterweil 2012]  E. Osterweil, D. McPherson, S. DiBenedetto, C. Papadopoulos, D. \nMassey, \u201cBehavior of DNS Top Talkers,\u201d Passive and Active Measurement Confer -\nence, 2012.\n[Padhye 2000]  J. Padhye, V. Firoiu, D. Towsley, J. Kurose, \u201cModeling TCP Reno \nPerformance: A Simple Model and Its Empirical Validation,\u201d IEEE/ACM Transac-\ntions on Networking , Vol. 8 No. 2 (Apr. 2000), pp. 133\u2013145.\n[Padhye 2001]  J.", "doc_id": "30016a60-1c80-4d34-8d5e-b059775ed3e3", "embedding": null, "doc_hash": "91c1d9be0a952d0f9443c9da19005af289032109300d83fcf1ab5e8c21d4e831", "extra_info": null, "node_info": {"start": 2336708, "end": 2339432}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "16324afe-0c23-44d3-85ab-e728f6c62477", "3": "18fa325c-61bd-43c0-bba9-f201fa1cab48"}}, "__type__": "1"}, "18fa325c-61bd-43c0-bba9-f201fa1cab48": {"__data__": {"text": "2012]  International Organization for Standardization homepage, http://www.\niso.org/iso/en/ISOOnline.frontpage\n[Osterweil 2012]  E. Osterweil, D. McPherson, S. DiBenedetto, C. Papadopoulos, D. \nMassey, \u201cBehavior of DNS Top Talkers,\u201d Passive and Active Measurement Confer -\nence, 2012.\n[Padhye 2000]  J. Padhye, V. Firoiu, D. Towsley, J. Kurose, \u201cModeling TCP Reno \nPerformance: A Simple Model and Its Empirical Validation,\u201d IEEE/ACM Transac-\ntions on Networking , Vol. 8 No. 2 (Apr. 2000), pp. 133\u2013145.\n[Padhye 2001]  J. Padhye, S. Floyd, \u201cOn Inferring TCP Behavior,\u201d Proc. 2001 \nACM SIGCOMM  (San Diego, CA, Aug. 2001).\n[Palat 2009]  S. Palat, P. Godin, \u201cThe LTE Network Architecture: A Comprehensive \nTutorial,\u201d in LTE\u2014The UMTS Long Term Evolution: From Theory to Practice.  \nAlso available as a standalone Alcatel white paper.\n[Panda 2013]  A. Panda, C. Scott, A. Ghodsi, T. Koponen, S. Shenker, \u201cCAP for \nNetworks,\u201d Proc. ACM HotSDN \u201913 , pp. 91\u201396.\n[Parekh 1993]  A. Parekh, R. Gallagher, \u201cA Generalized Processor Sharing Ap-\nproach to Flow Control in Integrated Services Networks: The Single-Node Case,\u201d \nIEEE/ACM Transactions on Networking , Vol. 1, No. 3 (June 1993), pp. 344\u2013357.\n[Partridge 1992]  C. Partridge, S. Pink, \u201cAn Implementation of the Revised Internet \nStream Protocol (ST-2),\u201d Journal of Internetworking: Research and Experience , Vol. 3, \nNo. 1 (Mar. 1992).\n[Partridge 1998]  C. Partridge, et al. \u201cA Fifty Gigabit per second IP Router,\u201d IEEE/\nACM Transactions on Networking , Vol. 6, No. 3 (Jun. 1998), pp. 237\u2013248.\n[Pathak 2010]  A. Pathak, Y. A. Wang, C. Huang, A. Greenberg, Y. C. Hu, J. Li, \nK. W. Ross, \u201cMeasuring and Evaluating TCP Splitting for Cloud Services,\u201d Pas-\nsive and Active Measurement (PAM) Conference  (Zurich, 2010).\n[Perkins 1994]  A. Perkins, \u201cNetworking with Bob Metcalfe,\u201d The Red Herring \nMagazine  (Nov. 1994).\n794     REFERENCES\n[Perkins 1998]  C. Perkins, O. Hodson, V. Hardman, \u201cA Survey of Packet Loss \nRecovery Techniques for Streaming Audio,\u201d IEEE Network Magazine  (Sept./Oct. \n1998), pp. 40\u201347.\n[Perkins 1998b]  C. Perkins, Mobile IP: Design Principles and Practice , Addison-\nWesley, Reading, MA, 1998.\n[Perkins 2000]  C. Perkins, Ad Hoc Networking , Addison-Wesley, Reading, MA, \n2000.\n[Perlman 1999]  R. Perlman, Interconnections: Bridges, Routers, Switches, and In -\nternetworking Protocols , 2nd ed., Addison-Wesley Professional Computing Series, \nReading, MA, 1999.\n[PGPI 2016]  The International PGP homepage, http://www.pgpi.org\n[Phifer 2000]  L. Phifer, \u201cThe Trouble with NAT,\u201d The Internet Protocol Journal , \nVol. 3, No. 4 (Dec. 2000), http://www.cisco.com/warp/public/759/ipj_3-4/ipj_ \n3-4_nat.html\n[Piatek 2007]  M. Piatek, T. Isdal, T. Anderson, A.", "doc_id": "18fa325c-61bd-43c0-bba9-f201fa1cab48", "embedding": null, "doc_hash": "554436cbd85065d9a32fca016c1646b3163f1305730c81026bb9d9b9b360c03f", "extra_info": null, "node_info": {"start": 2339420, "end": 2342138}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "30016a60-1c80-4d34-8d5e-b059775ed3e3", "3": "9de094da-ed65-4ef8-b038-2c8e6227f5ea"}}, "__type__": "1"}, "9de094da-ed65-4ef8-b038-2c8e6227f5ea": {"__data__": {"text": "Networking , Addison-Wesley, Reading, MA, \n2000.\n[Perlman 1999]  R. Perlman, Interconnections: Bridges, Routers, Switches, and In -\nternetworking Protocols , 2nd ed., Addison-Wesley Professional Computing Series, \nReading, MA, 1999.\n[PGPI 2016]  The International PGP homepage, http://www.pgpi.org\n[Phifer 2000]  L. Phifer, \u201cThe Trouble with NAT,\u201d The Internet Protocol Journal , \nVol. 3, No. 4 (Dec. 2000), http://www.cisco.com/warp/public/759/ipj_3-4/ipj_ \n3-4_nat.html\n[Piatek 2007]  M. Piatek, T. Isdal, T. Anderson, A. Krishnamurthy, A. Venkataram-\nani, \u201cDo Incentives Build Robustness in Bittorrent?,\u201d Proc. NSDI  (2007).\n[Piatek 2008]  M. Piatek, T. Isdal, A. Krishnamurthy, T. Anderson, \u201cOne Hop \nReputations for Peer-to-peer File Sharing Workloads,\u201d Proc. NSDI  (2008).\n[Pickholtz 1982]  R. Pickholtz, D. Schilling, L. Milstein, \u201cTheory of Spread Spec-\ntrum Communication\u2014a Tutorial,\u201d IEEE Transactions on Communications , Vol. \n30, No. 5 (May 1982), pp. 855\u2013884.\n[PingPlotter 2016]  PingPlotter homepage, http://www.pingplotter.com\n[Piscatello 1993]  D. Piscatello, A. Lyman Chapin, Open Systems Networking , \nAddison-Wesley, Reading, MA, 1993.\n[Pomeranz 2010]  H. Pomeranz, \u201cPractical, Visual, Three-Dimensional Pedagogy \nfor Internet Protocol Packet Header Control Fields,\u201d https://righteousit.wordpress.\ncom/2010/06/27/practical-visual-three-dimensional-pedagogy-for-internet-proto-\ncol-packet-header-control-fields/, June 2010.\n[Potaroo 2016]  \u201cGrowth of the BGP Table\u20131994 to Present,\u201d http://bgp.potaroo.\nnet/\n[PPLive 2012]  PPLive homepage, http://www.pplive.com\n[Qazi 2013]  Z. Qazi, C. Tu, L. Chiang, R. Miao, V. Sekar, M. Yu, \u201cSIMPLE-fying \nMiddlebox Policy Enforcement Using SDN,\u201d ACM SIGCOMM Conference   \n(Aug. 2013), pp. 27\u201338.\n[Quagga 2012]  Quagga, \u201cQuagga Routing Suite,\u201d http://www.quagga.net/\nREFERENCES      795\n[Quittner 1998]  J. Quittner, M. Slatalla, Speeding the Net: The Inside Story of \nNetscape and How It Challenged Microsoft , Atlantic Monthly Press, 1998.\n[Quova 2016]  www.quova.com\n[Ramakrishnan 1990]  K. K. Ramakrishnan, R. Jain, \u201cA Binary Feedback Scheme \nfor Congestion Avoidance in Computer Networks,\u201d ACM Transactions on Com-\nputer Systems , Vol. 8, No. 2 (May 1990), pp. 158\u2013181.\n[Raman 1999]  S. Raman, S. McCanne, \u201cA Model, Analysis, and Protocol Frame-\nwork for Soft State-based Communication,\u201d Proc. 1999 ACM SIGCOMM  (Boston, \nMA, Aug. 1999).\n[Raman 2007]  B. Raman, K. Chebrolu, \u201cExperiences in Using WiFi for Rural In-\nternet in India,\u201d IEEE Communications Magazine , Special Issue on New Directions \nin Networking Technologies in Emerging Economies (Jan. 2007).\n[Ramaswami 2010]  R. Ramaswami, K. Sivarajan, G. Sasaki, Optical Networks: A \nPractical  Perspective , Morgan Kaufman", "doc_id": "9de094da-ed65-4ef8-b038-2c8e6227f5ea", "embedding": null, "doc_hash": "b674c444631df5e67b6523bef06ea4b33e0679c92a780623f60cd31cf8a9edfe", "extra_info": null, "node_info": {"start": 2342132, "end": 2344869}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "18fa325c-61bd-43c0-bba9-f201fa1cab48", "3": "85a900fa-c0fb-463e-b136-01eeaa9fc704"}}, "__type__": "1"}, "85a900fa-c0fb-463e-b136-01eeaa9fc704": {"__data__": {"text": "Systems , Vol. 8, No. 2 (May 1990), pp. 158\u2013181.\n[Raman 1999]  S. Raman, S. McCanne, \u201cA Model, Analysis, and Protocol Frame-\nwork for Soft State-based Communication,\u201d Proc. 1999 ACM SIGCOMM  (Boston, \nMA, Aug. 1999).\n[Raman 2007]  B. Raman, K. Chebrolu, \u201cExperiences in Using WiFi for Rural In-\nternet in India,\u201d IEEE Communications Magazine , Special Issue on New Directions \nin Networking Technologies in Emerging Economies (Jan. 2007).\n[Ramaswami 2010]  R. Ramaswami, K. Sivarajan, G. Sasaki, Optical Networks: A \nPractical  Perspective , Morgan Kaufman Publishers, 2010.\n[Ramjee 1994]  R. Ramjee, J. Kurose, D. Towsley, H. Schulzrinne, \u201cAdaptive \nPlayout Mechanisms for Packetized Audio Applications in Wide-Area Networks,\u201d \nProc. 1994 IEEE INFOCOM.\n[Rao 2011]  A. S. Rao, Y. S. Lim, C. Barakat, A. Legout, D. Towsley, W. Dabbous,  \n\u201cNetwork Characteristics of Video Streaming Traffic,\u201d Proc. 2011 ACM CoNEXT  \n(Tokyo).\n[Ren 2006]  S. Ren, L. Guo, X. Zhang, \u201cASAP: An AS-Aware Peer-Relay Protocol \nfor High Quality VoIP,\u201d Proc. 2006 IEEE ICDCS  (Lisboa, Portugal, July 2006).\n[Rescorla 2001]  E. Rescorla, SSL and TLS: Designing and Building Secure Sys-\ntems, Addison-Wesley, Boston, 2001.\n[RFC 001]  S. Crocker, \u201cHost Software,\u201d RFC 001 (the very first  RFC!).\n[RFC 768]  J. Postel, \u201cUser Datagram Protocol,\u201d RFC 768, Aug. 1980.\n[RFC 791]  J. Postel, \u201cInternet Protocol: DARPA Internet Program Protocol Speci-\nfication,\u201d RFC 791, Sept. 1981.\n[RFC 792]  J. Postel, \u201cInternet Control Message Protocol,\u201d RFC 792, Sept. 1981.\n[RFC 793]  J. Postel, \u201cTransmission Control Protocol,\u201d RFC 793, Sept. 1981.\n[RFC 801]  J. Postel, \u201cNCP/TCP Transition Plan,\u201d RFC 801, Nov. 1981.\n[RFC 826]  D. C. Plummer, \u201cAn Ethernet Address Resolution Protocol\u2014or\u2014 \nConverting Network Protocol Addresses to 48-bit Ethernet Address for Transmis-\nsion on Ethernet Hardware,\u201d RFC 826, Nov. 1982.\n796     REFERENCES\n[RFC 829]  V. Cerf, \u201cPacket Satellite Technology Reference Sources,\u201d RFC 829, \nNov. 1982.\n[RFC 854]  J. Postel, J. Reynolds, \u201cTELNET Protocol Specification,\u201d RFC 854, \nMay 1993.\n[RFC 950]  J. Mogul, J. Postel, \u201cInternet Standard Subnetting Procedure,\u201d RFC \n950, Aug. 1985.\n[RFC 959]  J. Postel and J. Reynolds, \u201cFile Transfer Protocol (FTP),\u201d RFC 959, \nOct. 1985.\n[RFC 1034]  P. V. Mockapetris, \u201cDomain Names\u2014Concepts and Facilities,\u201d RFC \n1034, Nov. 1987.\n[RFC 1035]  P. Mockapetris, \u201cDomain Names\u2014Implementation and Specifica-\ntion,\u201d RFC 1035, Nov. 1987.\n[RFC 1058]  C. L. Hendrick, \u201cRouting Information Protocol,\u201d RFC 1058, June \n1988.\n[RFC 1071]  R. Braden, D. Borman, and C. Partridge, \u201cComputing the Internet \nChecksum,\u201d RFC 1071, Sept. 1988.\n[RFC", "doc_id": "85a900fa-c0fb-463e-b136-01eeaa9fc704", "embedding": null, "doc_hash": "958bd6cc8658f64d9b67e9a3c914a5df43984ec05825c7d7777da11b56019a19", "extra_info": null, "node_info": {"start": 2344856, "end": 2347499}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "9de094da-ed65-4ef8-b038-2c8e6227f5ea", "3": "6751cdbf-0004-477d-9679-bac6d12033b9"}}, "__type__": "1"}, "6751cdbf-0004-477d-9679-bac6d12033b9": {"__data__": {"text": "1985.\n[RFC 959]  J. Postel and J. Reynolds, \u201cFile Transfer Protocol (FTP),\u201d RFC 959, \nOct. 1985.\n[RFC 1034]  P. V. Mockapetris, \u201cDomain Names\u2014Concepts and Facilities,\u201d RFC \n1034, Nov. 1987.\n[RFC 1035]  P. Mockapetris, \u201cDomain Names\u2014Implementation and Specifica-\ntion,\u201d RFC 1035, Nov. 1987.\n[RFC 1058]  C. L. Hendrick, \u201cRouting Information Protocol,\u201d RFC 1058, June \n1988.\n[RFC 1071]  R. Braden, D. Borman, and C. Partridge, \u201cComputing the Internet \nChecksum,\u201d RFC 1071, Sept. 1988.\n[RFC 1122]  R. Braden, \u201cRequirements for Internet Hosts\u2014Communication  \nLayers,\u201d RFC 1122, Oct. 1989.\n[RFC 1123]  R. Braden, ed., \u201cRequirements for Internet Hosts\u2014Application and \nSupport,\u201d RFC-1123, Oct. 1989.\n[RFC 1142]  D. Oran, \u201cOSI IS-IS Intra-Domain Routing Protocol,\u201d RFC 1142,  \nFeb. 1990.\n[RFC 1190]  C. Topolcic, \u201cExperimental Internet Stream Protocol: Version 2  \n(ST-II),\u201d RFC 1190, Oct. 1990.\n[RFC 1256]  S. Deering, \u201cICMP Router Discovery Messages,\u201d RFC 1256, Sept. \n1991.\n[RFC 1320]  R. Rivest, \u201cThe MD4 Message-Digest Algorithm,\u201d RFC 1320, Apr. \n1992.\n[RFC 1321]  R. Rivest, \u201cThe MD5 Message-Digest Algorithm,\u201d RFC 1321, Apr. \n1992.\n[RFC 1323]  V. Jacobson, S. Braden, D. Borman, \u201cTCP Extensions for High Per-\nformance,\u201d RFC 1323, May 1992.\n[RFC 1422]  S. Kent, \u201cPrivacy Enhancement for Internet Electronic Mail: Part II: \nCertificate-Based Key Management,\u201d RFC 1422.\nREFERENCES      797\n[RFC 1546]  C. Partridge, T. Mendez, W. Milliken, \u201cHost Anycasting Service,\u201d \nRFC 1546, 1993.\n[RFC 1584]  J. Moy, \u201cMulticast Extensions to OSPF,\u201d RFC 1584, Mar. 1994.\n[RFC 1633]  R. Braden, D. Clark, S. Shenker, \u201cIntegrated Services in the Internet \nArchitecture: an Overview,\u201d RFC 1633, June 1994.\n[RFC 1636]  R. Braden, D. Clark, S. Crocker, C. Huitema, \u201cReport of IAB Work-\nshop on Security in the Internet Architecture,\u201d RFC 1636, Nov. 1994.\n[RFC 1700]  J. Reynolds, J. Postel, \u201cAssigned Numbers,\u201d RFC 1700, Oct. 1994.\n[RFC 1752]  S. Bradner, A. Mankin, \u201cThe Recommendations for the IP Next Gen-\neration Protocol,\u201d RFC 1752, Jan. 1995.\n[RFC 1918]  Y. Rekhter, B. Moskowitz, D. Karrenberg, G. J. de Groot, E. Lear, \n\u201cAddress Allocation for Private Internets,\u201d RFC 1918, Feb. 1996.\n[RFC 1930]  J. Hawkinson, T. Bates, \u201cGuidelines for Creation, Selection, and Reg-\nistration of an Autonomous System (AS),\u201d RFC 1930, Mar. 1996.\n[RFC 1939]  J. Myers, M. Rose, \u201cPost Office Protocol\u2014Version 3,\u201d RFC 1939, \nMay 1996.\n[RFC 1945]  T. Berners-Lee, R. Fielding, H. Frystyk, \u201cHypertext Transfer Proto-\ncol\u2014HTTP/1.0,\u201d RFC 1945, May 1996.\n[RFC 2003]  C. Perkins, \u201cIP Encapsulation Within", "doc_id": "6751cdbf-0004-477d-9679-bac6d12033b9", "embedding": null, "doc_hash": "5122c9c4e010fb8a34f704464e4a1e5b5cdb7d41512501f37e5ea870c17304ee", "extra_info": null, "node_info": {"start": 2347556, "end": 2350119}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "85a900fa-c0fb-463e-b136-01eeaa9fc704", "3": "e4c1ab21-9457-49ae-be99-f373122fb8ed"}}, "__type__": "1"}, "e4c1ab21-9457-49ae-be99-f373122fb8ed": {"__data__": {"text": "B. Moskowitz, D. Karrenberg, G. J. de Groot, E. Lear, \n\u201cAddress Allocation for Private Internets,\u201d RFC 1918, Feb. 1996.\n[RFC 1930]  J. Hawkinson, T. Bates, \u201cGuidelines for Creation, Selection, and Reg-\nistration of an Autonomous System (AS),\u201d RFC 1930, Mar. 1996.\n[RFC 1939]  J. Myers, M. Rose, \u201cPost Office Protocol\u2014Version 3,\u201d RFC 1939, \nMay 1996.\n[RFC 1945]  T. Berners-Lee, R. Fielding, H. Frystyk, \u201cHypertext Transfer Proto-\ncol\u2014HTTP/1.0,\u201d RFC 1945, May 1996.\n[RFC 2003]  C. Perkins, \u201cIP Encapsulation Within IP,\u201d RFC 2003, Oct. 1996.\n[RFC 2004]  C. Perkins, \u201cMinimal Encapsulation Within IP,\u201d RFC 2004, Oct. \n1996.\n[RFC 2018]  M. Mathis, J. Mahdavi, S. Floyd, A. Romanow, \u201cTCP Selective  \nAcknowledgment Options,\u201d RFC 2018, Oct. 1996.\n[RFC 2131]  R. Droms, \u201cDynamic Host Configuration Protocol,\u201d RFC 2131, Mar. \n1997.\n[RFC 2136]  P. Vixie, S. Thomson, Y. Rekhter, J. Bound, \u201cDynamic Updates in the \nDomain Name System,\u201d RFC 2136, Apr. 1997.\n[RFC 2205]  R. Braden, Ed., L. Zhang, S. Berson, S. Herzog, S. Jamin, \u201cResource \nReSerVation Protocol (RSVP)\u2014Version 1 Functional Specification,\u201d RFC 2205, \nSept. 1997.\n[RFC 2210]  J. Wroclawski, \u201cThe Use of RSVP with IETF Integrated Services,\u201d \nRFC 2210, Sept. 1997.\n[RFC 2211]  J. Wroclawski, \u201cSpecification of the Controlled-Load Network Ele-\nment Service,\u201d RFC 2211, Sept. 1997.\n798     REFERENCES\n[RFC 2215]  S. Shenker, J. Wroclawski, \u201cGeneral Characterization Parameters for \nIntegrated Service Network Elements,\u201d RFC 2215, Sept. 1997.\n[RFC 2326]  H. Schulzrinne, A. Rao, R. Lanphier, \u201cReal Time Streaming Protocol \n(RTSP),\u201d RFC 2326, Apr. 1998.\n[RFC 2328]  J. Moy, \u201cOSPF Version 2,\u201d RFC 2328, Apr. 1998.\n[RFC 2420]  H. Kummert, \u201cThe PPP Triple-DES Encryption Protocol (3DESE),\u201d \nRFC 2420, Sept. 1998.\n[RFC 2453]  G. Malkin, \u201cRIP Version 2,\u201d RFC 2453, Nov. 1998.\n[RFC 2460]  S. Deering, R. Hinden, \u201cInternet Protocol, Version 6 (IPv6) Specifica-\ntion,\u201d RFC 2460, Dec. 1998.\n[RFC 2475]  S. Blake, D. Black, M. Carlson, E. Davies, Z. Wang, W. Weiss, \u201cAn \nArchitecture for Differentiated Services,\u201d RFC 2475, Dec. 1998.\n[RFC 2578]  K. McCloghrie, D. Perkins, J. Schoenwaelder, \u201cStructure of Manage-\nment Information Version 2 (SMIv2),\u201d RFC 2578, Apr. 1999.\n[RFC 2579]  K. McCloghrie, D. Perkins, J. Schoenwaelder, \u201cTextual Conventions \nfor SMIv2,\u201d RFC 2579, Apr. 1999.\n[RFC 2580]  K. McCloghrie, D. Perkins, J. Schoenwaelder, \u201cConformance State-\nments for SMIv2,\u201d RFC 2580, Apr. 1999.\n[RFC 2597]  J. Heinanen, F. Baker, W. Weiss, J. Wroclawski, \u201cAssured", "doc_id": "e4c1ab21-9457-49ae-be99-f373122fb8ed", "embedding": null, "doc_hash": "473b9277d3d3944a80991bb6110fdb506c9572499af621b02577216302d63c90", "extra_info": null, "node_info": {"start": 2350099, "end": 2352603}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "6751cdbf-0004-477d-9679-bac6d12033b9", "3": "ded34db0-7fa7-4b21-ac86-7e919d875e8c"}}, "__type__": "1"}, "ded34db0-7fa7-4b21-ac86-7e919d875e8c": {"__data__": {"text": "RFC 2475, Dec. 1998.\n[RFC 2578]  K. McCloghrie, D. Perkins, J. Schoenwaelder, \u201cStructure of Manage-\nment Information Version 2 (SMIv2),\u201d RFC 2578, Apr. 1999.\n[RFC 2579]  K. McCloghrie, D. Perkins, J. Schoenwaelder, \u201cTextual Conventions \nfor SMIv2,\u201d RFC 2579, Apr. 1999.\n[RFC 2580]  K. McCloghrie, D. Perkins, J. Schoenwaelder, \u201cConformance State-\nments for SMIv2,\u201d RFC 2580, Apr. 1999.\n[RFC 2597]  J. Heinanen, F. Baker, W. Weiss, J. Wroclawski, \u201cAssured Forward-\ning PHB Group,\u201d RFC 2597, June 1999.\n[RFC 2616]  R. Fielding, J. Gettys, J. Mogul, H. Frystyk, L. Masinter, P. Leach, T. \nBerners-Lee, R. Fielding, \u201cHypertext Transfer Protocol\u2014HTTP/1.1,\u201d RFC 2616, \nJune 1999.\n[RFC 2663]  P. Srisuresh, M. Holdrege, \u201cIP Network Address Translator (NAT) \nTerminology and Considerations,\u201d RFC 2663.\n[RFC 2702]  D. Awduche, J. Malcolm, J. Agogbua, M. O\u2019Dell, J. McManus, \u201cRe-\nquirements for Traffic Engineering Over MPLS,\u201d RFC 2702, Sept. 1999.\n[RFC 2827]  P. Ferguson, D. Senie, \u201cNetwork Ingress Filtering: Defeating Denial \nof Service Attacks which Employ IP Source Address Spoofing,\u201d RFC 2827, May \n2000.\n[RFC 2865]  C. Rigney, S. Willens, A. Rubens, W. Simpson, \u201cRemote Authentica-\ntion Dial In User Service (RADIUS),\u201d RFC 2865, June 2000.\n[RFC 3007]  B. Wellington, \u201cSecure Domain Name System (DNS) Dynamic  \nUpdate,\u201d RFC 3007, Nov. 2000.\nREFERENCES      799\n[RFC 3022]  P. Srisuresh, K. Egevang, \u201cTraditional IP Network Address Translator \n(Traditional NAT),\u201d RFC 3022, Jan. 2001.\n[RFC 3022]  P. Srisuresh, K. Egevang, \u201cTraditional IP Network Address Translator \n(Traditional NAT),\u201d RFC 3022, Jan. 2001.\n[RFC 3031]  E. Rosen, A. Viswanathan, R. Callon, \u201cMultiprotocol Label Switching \nArchitecture,\u201d RFC 3031, Jan. 2001.\n[RFC 3032]  E. Rosen, D. Tappan, G. Fedorkow, Y. Rekhter, D. Farinacci, T. Li, \nA. Conta, \u201cMPLS Label Stack Encoding,\u201d RFC 3032, Jan. 2001.\n[RFC 3168]  K. Ramakrishnan, S. Floyd, D. Black, \u201cThe Addition of Explicit Con-\ngestion Notification (ECN) to IP,\u201d RFC 3168, Sept. 2001.\n[RFC 3209]  D. Awduche, L. Berger, D. Gan, T. Li, V. Srinivasan, G. Swallow, \n\u201cRSVP-TE: Extensions to RSVP for LSP Tunnels,\u201d RFC 3209, Dec. 2001.\n[RFC 3221]  G. Huston, \u201cCommentary on Inter-Domain Routing in the Internet,\u201d \nRFC 3221, Dec. 2001.\n[RFC 3232]  J. Reynolds, \u201cAssigned Numbers: RFC 1700 Is Replaced by an On-\nline Database,\u201d RFC 3232, Jan. 2002.\n[RFC 3234]  B. Carpenter, S. Brim, \u201cMiddleboxes: Taxonomy and Issues,\u201d RFC \n3234, Feb. 2002.\n[RFC 3246]  B. Davie, A.", "doc_id": "ded34db0-7fa7-4b21-ac86-7e919d875e8c", "embedding": null, "doc_hash": "5d9f6383a56f9875a6db0ae2257d4fc33e9cc964efafb521a59f748cb892bc94", "extra_info": null, "node_info": {"start": 2352653, "end": 2355125}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "e4c1ab21-9457-49ae-be99-f373122fb8ed", "3": "35c33495-164b-4623-aa64-94e83f98f07c"}}, "__type__": "1"}, "35c33495-164b-4623-aa64-94e83f98f07c": {"__data__": {"text": " D. Awduche, L. Berger, D. Gan, T. Li, V. Srinivasan, G. Swallow, \n\u201cRSVP-TE: Extensions to RSVP for LSP Tunnels,\u201d RFC 3209, Dec. 2001.\n[RFC 3221]  G. Huston, \u201cCommentary on Inter-Domain Routing in the Internet,\u201d \nRFC 3221, Dec. 2001.\n[RFC 3232]  J. Reynolds, \u201cAssigned Numbers: RFC 1700 Is Replaced by an On-\nline Database,\u201d RFC 3232, Jan. 2002.\n[RFC 3234]  B. Carpenter, S. Brim, \u201cMiddleboxes: Taxonomy and Issues,\u201d RFC \n3234, Feb. 2002.\n[RFC 3246]  B. Davie, A. Charny, J.C.R. Bennet, K. Benson, J.Y. Le Boudec, W. \nCourtney, S. Davari, V. Firoiu, D. Stiliadis, \u201cAn Expedited Forwarding PHB  \n(Per-Hop Behavior),\u201d RFC 3246, Mar. 2002.\n[RFC 3260]  D. Grossman, \u201cNew Terminology and Clarifications for Diffserv,\u201d \nRFC 3260, Apr. 2002.\n[RFC 3261]  J. Rosenberg, H. Schulzrinne, G. Carmarillo, A. Johnston, J. Peterson, \nR. Sparks, M. Handley, E. Schooler, \u201cSIP: Session Initiation Protocol,\u201d RFC 3261, \nJuly 2002.\n[RFC 3272]  J. Boyle, V. Gill, A. Hannan, D. Cooper, D. Awduche, B. Christian, \nW. S. Lai, \u201cOverview and Principles of Internet Traffic Engineering,\u201d RFC 3272, \nMay 2002.\n[RFC 3286]  L. Ong, J. Yoakum, \u201cAn Introduction to the Stream Control Transmis-\nsion Protocol (SCTP),\u201d RFC 3286, May 2002.\n[RFC 3346]  J. Boyle, V. Gill, A. Hannan, D. Cooper, D. Awduche, B. Christian, \nW. S. Lai, \u201cApplicability Statement for Traffic Engineering with MPLS,\u201d RFC \n3346, Aug. 2002.\n800     REFERENCES\n[RFC 3390]  M. Allman, S. Floyd, C. Partridge, \u201cIncreasing TCP\u2019s Initial  \nWindow,\u201d RFC 3390, Oct. 2002.\n[RFC 3410]  J. Case, R. Mundy, D. Partain, \u201cIntroduction and Applicability State-\nments for Internet Standard Management Framework,\u201d RFC 3410, Dec. 2002.\n[RFC 3414]  U. Blumenthal and B. Wijnen, \u201cUser-based Security Model (USM) for \nVersion 3 of the Simple Network Management Protocol (SNMPv3),\u201d RFC 3414, \nDec. 2002.\n[RFC 3416]  R. Presuhn, J. Case, K. McCloghrie, M. Rose, S. Waldbusser, \u201cVer-\nsion 2 of the Protocol Operations for the Simple Network Management Protocol \n(SNMP),\u201d Dec. 2002.\n[RFC 3439]  R. Bush, D. Meyer, \u201cSome Internet Architectural Guidelines and Phi -\nlosophy,\u201d RFC 3439, Dec. 2003.\n[RFC 3447]  J. Jonsson, B. Kaliski, \u201cPublic-Key Cryptography Standards (PKCS) \n#1: RSA Cryptography Specifications Version 2.1,\u201d RFC 3447, Feb. 2003.\n[RFC 3468]  L. Andersson, G. Swallow, \u201cThe Multiprotocol Label Switching \n(MPLS) Working Group Decision on MPLS Signaling Protocols,\u201d RFC 3468,  \nFeb. 2003.\n[RFC 3469]  V. Sharma, Ed., F. Hellstrand, Ed, \u201cFramework for Multi-Protocol  \nLabel Switching (MPLS)-based Recovery,\u201d RFC 3469, Feb.", "doc_id": "35c33495-164b-4623-aa64-94e83f98f07c", "embedding": null, "doc_hash": "663a499f07107a5ef134fc1af20c90857ca6410b4e6675a5a868c6f6c690545b", "extra_info": null, "node_info": {"start": 2355127, "end": 2357678}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "ded34db0-7fa7-4b21-ac86-7e919d875e8c", "3": "0ae03ccd-74ad-41f4-a57e-430c1e2eed0e"}}, "__type__": "1"}, "0ae03ccd-74ad-41f4-a57e-430c1e2eed0e": {"__data__": {"text": "\u201cSome Internet Architectural Guidelines and Phi -\nlosophy,\u201d RFC 3439, Dec. 2003.\n[RFC 3447]  J. Jonsson, B. Kaliski, \u201cPublic-Key Cryptography Standards (PKCS) \n#1: RSA Cryptography Specifications Version 2.1,\u201d RFC 3447, Feb. 2003.\n[RFC 3468]  L. Andersson, G. Swallow, \u201cThe Multiprotocol Label Switching \n(MPLS) Working Group Decision on MPLS Signaling Protocols,\u201d RFC 3468,  \nFeb. 2003.\n[RFC 3469]  V. Sharma, Ed., F. Hellstrand, Ed, \u201cFramework for Multi-Protocol  \nLabel Switching (MPLS)-based Recovery,\u201d RFC 3469, Feb. 2003.  \nftp://ftp.rfc-editor.org/in-notes/rfc3469.txt\n[RFC 3501]  M. Crispin, \u201cInternet Message Access Protocol\u2014Version 4rev1,\u201d RFC \n3501, Mar. 2003.\n[RFC 3550]  H. Schulzrinne, S. Casner, R. Frederick, V. Jacobson, \u201cRTP: A Trans-\nport Protocol for Real-Time Applications,\u201d RFC 3550, July 2003.\n[RFC 3588]  P. Calhoun, J. Loughney, E. Guttman, G. Zorn, J. Arkko, \u201cDiameter \nBase Protocol,\u201d RFC 3588, Sept. 2003.\n[RFC 3649]  S. Floyd, \u201cHighSpeed TCP for Large Congestion Windows,\u201d RFC \n3649, Dec. 2003.\n[RFC 3746]  L. Yang, R. Dantu, T. Anderson, R. Gopal, \u201cForwarding and Control \nElement Separation (ForCES) Framework,\u201d Internet, RFC 3746, Apr. 2004.\n[RFC 3748]  B. Aboba, L. Blunk, J. Vollbrecht, J. Carlson, H. Levkowetz, Ed., \n\u201cExtensible Authentication Protocol (EAP),\u201d RFC 3748, June 2004.\n[RFC 3782]  S. Floyd, T. Henderson, A. Gurtov, \u201cThe NewReno Modification to \nTCP\u2019s Fast Recovery Algorithm,\u201d RFC 3782, Apr. 2004.\nREFERENCES      801\n[RFC 4213]  E. Nordmark, R. Gilligan, \u201cBasic Transition Mechanisms for IPv6 \nHosts and Routers,\u201d RFC 4213, Oct. 2005.\n[RFC 4271]  Y. Rekhter, T. Li, S. Hares, Ed., \u201cA Border Gateway Protocol 4 (BGP-\n4),\u201d RFC 4271, Jan. 2006.\n[RFC 4272]  S. Murphy, \u201cBGP Security Vulnerabilities Analysis,\u201d RFC 4274, Jan. \n2006.\n[RFC 4291]  R. Hinden, S. Deering, \u201cIP Version 6 Addressing Architecture,\u201d RFC \n4291, Feb. 2006.\n[RFC 4340]  E. Kohler, M. Handley, S. Floyd, \u201cDatagram Congestion Control \nProtocol (DCCP),\u201d RFC 4340, Mar. 2006.\n[RFC 4443]  A. Conta, S. Deering, M. Gupta, Ed., \u201cInternet Control Message Pro-\ntocol (ICMPv6) for the Internet Protocol Version 6 (IPv6) Specification,\u201d  \nRFC 4443, Mar. 2006.\n[RFC 4346]  T. Dierks, E. Rescorla, \u201cThe Transport Layer Security (TLS) Protocol \nVersion 1.1,\u201d RFC 4346, Apr. 2006.\n[RFC 4514]  K. Zeilenga, Ed., \u201cLightweight Directory Access Protocol (LDAP): \nString Representation of Distinguished Names,\u201d RFC 4514, June 2006.\n[RFC 4601]  B. Fenner, M. Handley, H. Holbrook, I. Kouvelas, \u201cProtocol  \nIndependent Multicast\u2014Sparse Mode (PIM-SM): Protocol", "doc_id": "0ae03ccd-74ad-41f4-a57e-430c1e2eed0e", "embedding": null, "doc_hash": "0f067b17d07192ee42e1faf7430237baf046636eff803475684f24bd03f95b46", "extra_info": null, "node_info": {"start": 2357618, "end": 2360173}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "35c33495-164b-4623-aa64-94e83f98f07c", "3": "c1fec69a-8603-4f84-8338-8dff1b8efd5b"}}, "__type__": "1"}, "c1fec69a-8603-4f84-8338-8dff1b8efd5b": {"__data__": {"text": "Deering, M. Gupta, Ed., \u201cInternet Control Message Pro-\ntocol (ICMPv6) for the Internet Protocol Version 6 (IPv6) Specification,\u201d  \nRFC 4443, Mar. 2006.\n[RFC 4346]  T. Dierks, E. Rescorla, \u201cThe Transport Layer Security (TLS) Protocol \nVersion 1.1,\u201d RFC 4346, Apr. 2006.\n[RFC 4514]  K. Zeilenga, Ed., \u201cLightweight Directory Access Protocol (LDAP): \nString Representation of Distinguished Names,\u201d RFC 4514, June 2006.\n[RFC 4601]  B. Fenner, M. Handley, H. Holbrook, I. Kouvelas, \u201cProtocol  \nIndependent Multicast\u2014Sparse Mode (PIM-SM): Protocol Specification  \n(Revised),\u201d RFC 4601, Aug. 2006.\n[RFC 4632]  V. Fuller, T. Li, \u201cClassless Inter-domain Routing (CIDR): The Inter-\nnet Address Assignment and Aggregation Plan,\u201d RFC 4632, Aug. 2006.\n[RFC 4960]  R. Stewart, ed., \u201cStream Control Transmission Protocol,\u201d RFC 4960, \nSept. 2007.\n[RFC 4987]  W. Eddy, \u201cTCP SYN Flooding Attacks and Common Mitigations,\u201d \nRFC 4987, Aug. 2007.\n[RFC 5000]  RFC editor, \u201cInternet Official Protocol Standards,\u201d RFC 5000, May \n2008.\n[RFC 5109]  A. Li (ed.), \u201cRTP Payload Format for Generic Forward Error Correc-\ntion,\u201d RFC 5109, Dec. 2007.\n[RFC 5216]  D. Simon, B. Aboba, R. Hurst, \u201cThe EAP-TLS Authentication Proto-\ncol,\u201d RFC 5216, Mar. 2008.\n[RFC 5218]  D. Thaler, B. Aboba, \u201cWhat Makes for a Successful Protocol?,\u201d RFC \n5218, July 2008.\n802     REFERENCES\n[RFC 5321]  J. Klensin, \u201cSimple Mail Transfer Protocol,\u201d RFC 5321, Oct. 2008.\n[RFC 5322]  P. Resnick, Ed., \u201cInternet Message Format,\u201d RFC 5322, Oct. 2008.\n[RFC 5348]  S. Floyd, M. Handley, J. Padhye, J. Widmer, \u201cTCP Friendly Rate \nControl (TFRC): Protocol Specification,\u201d RFC 5348, Sept. 2008.\n[RFC 5389]  J. Rosenberg, R. Mahy, P. Matthews, D. Wing, \u201cSession Traversal \nUtilities for NAT (STUN),\u201d RFC 5389, Oct. 2008.\n[RFC 5411]  J Rosenberg, \u201cA Hitchhiker\u2019s Guide to the Session Initiation Protocol \n(SIP),\u201d RFC 5411, Feb. 2009.\n[RFC 5681]  M. Allman, V. Paxson, E. Blanton, \u201cTCP Congestion Control,\u201d RFC \n5681, Sept. 2009.\n[RFC 5944]  C. Perkins, Ed., \u201cIP Mobility Support for IPv4, Revised,\u201d RFC 5944, \nNov. 2010.\n[RFC 6265]  A Barth, \u201cHTTP State Management Mechanism,\u201d RFC 6265, Apr. \n2011.\n[RFC 6298]  V. Paxson, M. Allman, J. Chu, M. Sargent, \u201cComputing TCP\u2019s Re-\ntransmission Timer,\u201d RFC 6298, June 2011.\n[RFC 7020]  R. Housley, J. Curran, G. Huston, D. Conrad, \u201cThe Internet Numbers \nRegistry System,\u201d RFC 7020, Aug. 2013.\n[RFC 7094]  D. McPherson, D. Oran, D. Thaler, E. Osterweil, \u201cArchitectural Con-\nsiderations of IP Anycast,\u201d RFC 7094, Jan. 2014.\n[RFC 7323]  D. Borman, R. Braden, V. Jacobson, R. Scheffenegger", "doc_id": "c1fec69a-8603-4f84-8338-8dff1b8efd5b", "embedding": null, "doc_hash": "29f16a89e42dad009adf4416b4984c3f268c093f6325b629805a4da814beb912", "extra_info": null, "node_info": {"start": 2360158, "end": 2362717}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "0ae03ccd-74ad-41f4-a57e-430c1e2eed0e", "3": "4f6a46ff-d6c9-4f3d-a7a0-9f2ac784b33f"}}, "__type__": "1"}, "4f6a46ff-d6c9-4f3d-a7a0-9f2ac784b33f": {"__data__": {"text": "RFC 6265, Apr. \n2011.\n[RFC 6298]  V. Paxson, M. Allman, J. Chu, M. Sargent, \u201cComputing TCP\u2019s Re-\ntransmission Timer,\u201d RFC 6298, June 2011.\n[RFC 7020]  R. Housley, J. Curran, G. Huston, D. Conrad, \u201cThe Internet Numbers \nRegistry System,\u201d RFC 7020, Aug. 2013.\n[RFC 7094]  D. McPherson, D. Oran, D. Thaler, E. Osterweil, \u201cArchitectural Con-\nsiderations of IP Anycast,\u201d RFC 7094, Jan. 2014.\n[RFC 7323]  D. Borman, R. Braden, V. Jacobson, R. Scheffenegger (ed.), \u201cTCP \nExtensions for High Performance,\u201d RFC 7323, Sept. 2014.\n[RFC 7540]  M. Belshe, R. Peon, M. Thomson (Eds), \u201cHypertext Transfer Protocol \nVersion 2 (HTTP/2),\u201d RFC 7540, May 2015.\n[Richter 2015]  P. Richter, M. Allman, R. Bush, V. Paxson, \u201cA Primer on IPv4 \nScarcity,\u201d ACM SIGCOMM Computer Communication Review , Vol. 45, No. 2 \n(Apr. 2015), pp. 21\u201332.\n[Roberts 1967]  L. Roberts, T. Merril, \u201cToward a Cooperative Network of Time-\nShared Computers,\u201d AFIPS Fall Conference  (Oct. 1966).\n[Rodriguez 2010]  R. Rodrigues, P. Druschel, \u201cPeer-to-Peer Systems,\u201d Communi-\ncations of the ACM , Vol. 53, No. 10 (Oct. 2010), pp. 72\u201382.\n[Rohde 2008]  Rohde, Schwarz, \u201cUMTS Long Term Evolution (LTE) Technology \nIntroduction,\u201d Application Note 1MA111.\nREFERENCES      803\n[Rom 1990]  R. Rom, M. Sidi, Multiple Access Protocols: Performance and Analy-\nsis, Springer-Verlag, New York, 1990.\n[Root Servers 2016]  Root Servers home page, http://www.root-servers.org/\n[RSA 1978]  R. Rivest, A. Shamir, L. Adelman, \u201cA Method for Obtaining Digital \nSignatures and Public-key Cryptosystems,\u201d Communications of the ACM , Vol. 21, \nNo. 2 (Feb. 1978), pp. 120\u2013126.\n[RSA Fast 2012]  RSA Laboratories, \u201cHow Fast Is RSA?\u201d http://www.rsa.com/\nrsalabs/node.asp?id=2215\n[RSA Key 2012]  RSA Laboratories, \u201cHow Large a Key Should Be Used in the \nRSA Crypto System?\u201d http://www.rsa.com/rsalabs/node.asp?id=2218\n[Rubenstein 1998]  D. Rubenstein, J. Kurose, D. Towsley, \u201cReal-Time Reliable \nMulticast Using Proactive Forward Error Correction,\u201d Proceedings of NOSSDAV \n\u201898 (Cambridge, UK, July 1998).\n[Ruiz-Sanchez 2001 ] M. Ruiz-S\u00e1nchez, E. Biersack, W. Dabbous, \u201cSurvey and \nTaxonomy of IP Address Lookup Algorithms,\u201d IEEE Network Magazine , Vol. 15, \nNo. 2 (Mar./Apr. 2001), pp. 8\u201323.\n[Saltzer 1984]  J. Saltzer, D. Reed, D. Clark, \u201cEnd-to-End Arguments in System \nDesign,\u201d ACM Transactions on Computer Systems (TOCS) , Vol. 2, No. 4 (Nov. \n1984).\n[Sandvine 2015]  \u201cGlobal Internet Phenomena Report, Spring 2011,\u201d http://www.\nsandvine.com/news/global\u00a0broadband\u00a0trends.asp, 2011.\n[Sardar 2006]  B. Sardar, D. Saha, \u201cA Survey of TCP Enhancements for Last-Hop", "doc_id": "4f6a46ff-d6c9-4f3d-a7a0-9f2ac784b33f", "embedding": null, "doc_hash": "c447c6ac3c21f3a3be7cdf8e73a7ee32df55142369ac0c536dd599cd6e795f66", "extra_info": null, "node_info": {"start": 2362802, "end": 2365386}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "c1fec69a-8603-4f84-8338-8dff1b8efd5b", "3": "cb47a884-0d9c-4ed8-a911-6c13c93571b7"}}, "__type__": "1"}, "cb47a884-0d9c-4ed8-a911-6c13c93571b7": {"__data__": {"text": "Biersack, W. Dabbous, \u201cSurvey and \nTaxonomy of IP Address Lookup Algorithms,\u201d IEEE Network Magazine , Vol. 15, \nNo. 2 (Mar./Apr. 2001), pp. 8\u201323.\n[Saltzer 1984]  J. Saltzer, D. Reed, D. Clark, \u201cEnd-to-End Arguments in System \nDesign,\u201d ACM Transactions on Computer Systems (TOCS) , Vol. 2, No. 4 (Nov. \n1984).\n[Sandvine 2015]  \u201cGlobal Internet Phenomena Report, Spring 2011,\u201d http://www.\nsandvine.com/news/global\u00a0broadband\u00a0trends.asp, 2011.\n[Sardar 2006]  B. Sardar, D. Saha, \u201cA Survey of TCP Enhancements for Last-Hop \nWireless Networks,\u201d IEEE Commun. Surveys and Tutorials , Vol. 8, No. 3 (2006), \npp. 20\u201334.\n[Saroiu 2002]  S. Saroiu, P. K. Gummadi, S. D. Gribble, \u201cA Measurement Study of \nPeer-to-Peer File Sharing Systems,\u201d Proc. of Multimedia Computing and Network-\ning (MMCN)  (2002).\n[Sauter 2014]  M. Sauter, From GSM to LTE-Advanced , John Wiley and Sons, \n2014.\n[Savage 2015]  D. Savage, J. Ng, S. Moore, D. Slice, P. Paluch, R. White,  \n\u201cEnhanced Interior Gateway Routing Protocol,\u201d Internet Draft, draft- \nsavage-eigrp-04.txt, Aug. 2015.\n[Saydam 1996]  T. Saydam, T. Magedanz, \u201cFrom Networks and Network Man-\nagement into Service and Service Management,\u201d Journal of Networks and System \nManagement , Vol. 4, No. 4 (Dec. 1996), pp. 345\u2013348.\n804     REFERENCES\n[Schiller 2003]  J. Schiller, Mobile Communications  2nd edition, Addison Wesley, \n2003.\n[Schneier 1995]  B. Schneier, Applied Cryptography: Protocols, Algorithms, and \nSource Code in C , John Wiley and Sons, 1995.\n[Schulzrinne-RTP 2012]  Henning Schulzrinne\u2019s RTP site, http://www.cs.columbia  \n.edu/~hgs/rtp\n[Schulzrinne-SIP 2016]  Henning Schulzrinne\u2019s SIP site, http://www.cs.columbia.\nedu/~hgs/sip\n[Schwartz 1977]  M. Schwartz, Computer-Communication Network Design and \nAnalysis , Prentice-Hall, Englewood Cliffs, NJ, 1997.\n[Schwartz 1980]  M. Schwartz, Information, Transmission, Modulation, and Noise,  \nMcGraw Hill, New York, NY 1980.\n[Schwartz 1982]  M. Schwartz, \u201cPerformance Analysis of the SNA Virtual Route  \nPacing Control,\u201d IEEE Transactions on Communications , Vol. 30, No. 1 (Jan. \n1982), pp. 172\u2013184.\n[Scourias 2012]  J. Scourias, \u201cOverview of the Global System for Mobile Commu-\nnications: GSM.\u201d http://www.privateline.com/PCS/GSM0.html\n[SDNHub 2016]  SDNHub, \u201cApp Development Tutorials,\u201d http://sdnhub.org/ \ntutorials/\n[Segaller 1998]  S. Segaller, Nerds 2.0.1, A Brief History of the Internet , TV Books, \nNew York, 1998.\n[Sekar 2011 ] V. Sekar, S. Ratnasamy, M. Reiter, N. Egi, G. Shi, \u201c The Middle-\nbox Manifesto: Enabling Innovation in Middlebox Deployment,\u201d Proc. 10th ACM \nWorkshop on Hot Topics in Networks (HotNets) , Article 21, 6 pages.\n[Serpanos 2011]  D. Serpanos, T. Wolf, Architecture of Network", "doc_id": "cb47a884-0d9c-4ed8-a911-6c13c93571b7", "embedding": null, "doc_hash": "3abadb3ce16936b52b2d130e939cd618e73e136b35c66b3afb9e39f845650397", "extra_info": null, "node_info": {"start": 2365322, "end": 2368022}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "4f6a46ff-d6c9-4f3d-a7a0-9f2ac784b33f", "3": "8ba1e891-7fae-43a0-9502-a289620fe3a6"}}, "__type__": "1"}, "8ba1e891-7fae-43a0-9502-a289620fe3a6": {"__data__": {"text": "2016]  SDNHub, \u201cApp Development Tutorials,\u201d http://sdnhub.org/ \ntutorials/\n[Segaller 1998]  S. Segaller, Nerds 2.0.1, A Brief History of the Internet , TV Books, \nNew York, 1998.\n[Sekar 2011 ] V. Sekar, S. Ratnasamy, M. Reiter, N. Egi, G. Shi, \u201c The Middle-\nbox Manifesto: Enabling Innovation in Middlebox Deployment,\u201d Proc. 10th ACM \nWorkshop on Hot Topics in Networks (HotNets) , Article 21, 6 pages.\n[Serpanos 2011]  D. Serpanos, T. Wolf, Architecture of Network Systems , Morgan \nKaufmann Publishers, 2011.\n[Shacham 1990]  N. Shacham, P. McKenney, \u201cPacket Recovery in High-Speed \nNetworks Using Coding and Buffer Management,\u201d Proc. 1990 IEEE INFOCOM  \n(San Francisco, CA, Apr. 1990), pp. 124\u2013131.\n[Shaikh 2001]  A. Shaikh, R. Tewari, M. Agrawal, \u201cOn the Effectiveness of DNS-\nbased Server Selection,\u201d Proc. 2001 IEEE INFOCOM .\n[Singh 1999]  S. Singh, The Code Book: The Evolution of Secrecy from Mary, \nQueen of Scotsto Quantum Cryptography , Doubleday Press, 1999.\nREFERENCES      805\n[Singh 2015]  A. Singh, J. Ong,. Agarwal, G. Anderson, A. Armistead, R. Banno, S. \nBoving, G. Desai, B. Felderman, P. Germano, A. Kanagala, J. Provost, J. Simmons, \nE. Tanda, J. Wanderer, U. H\u00f6lzle, S. Stuart, A. Vahdat, \u201cJupiter Rising: A Decade \nof Clos Topologies and Centralized Control in Google\u2019s Datacenter Network,\u201d \nSigcomm, 2015.\n[SIP Software 2016]  H. Schulzrinne Software Package site, http://www.\ncs.columbia.edu/IRT/software\n[Skoudis 2004]  E. Skoudis, L. Zeltser, Malware: Fighting Malicious Code , Pren-\ntice Hall, 2004.\n[Skoudis 2006]  E. Skoudis, T. Liston, Counter Hack Reloaded: A Step-by-Step \nGuide to Computer Attacks and Effective Defenses (2nd Edition) , Prentice Hall, \n2006.\n[Smith 2009]  J. Smith, \u201cFighting Physics: A Tough Battle,\u201d Communications of the \nACM , Vol. 52, No. 7 (July 2009), pp. 60\u201365.\n[Snort 2012]  Sourcefire Inc., Snort homepage, http://http://www.snort.org/\n[Solensky 1996]  F. Solensky, \u201cIPv4 Address Lifetime Expectations,\u201d in IPng: \nInternet Protocol Next Generation  (S. Bradner, A. Mankin, ed.), Addison-Wesley, \nReading, MA, 1996.\n[Spragins 1991]  J. D. Spragins, Telecommunications Protocols and Design , \nAddison-Wesley, Reading, MA, 1991.\n[Srikant 2004]  R. Srikant, The Mathematics of Internet Congestion Control , \nBirkhauser, 2004\n[Steinder 2002]  M. Steinder, A. Sethi, \u201cIncreasing Robustness of Fault Localiza-\ntion Through Analysis of Lost, Spurious, and Positive Symptoms,\u201d Proc. 2002 \nIEEE INFOCOM.\n[Stevens 1990]  W. R. Stevens, Unix Network Programming , Prentice-Hall, Engle-\nwood Cliffs, NJ.\n[Stevens 1994]  W. R. Stevens, TCP/IP Illustrated, Vol. 1: The Protocols , Addison-\nWesley, Reading, MA, 1994.\n[Stevens 1997]  W.R. Stevens, Unix Network Programming, Volume 1: Networking", "doc_id": "8ba1e891-7fae-43a0-9502-a289620fe3a6", "embedding": null, "doc_hash": "51f6e82f7df6ab43b14187e079f385987f3a0856eec98debed63343a21f74efe", "extra_info": null, "node_info": {"start": 2368074, "end": 2370813}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "cb47a884-0d9c-4ed8-a911-6c13c93571b7", "3": "26475304-2b2e-4154-8b48-8265a3b9cc4a"}}, "__type__": "1"}, "26475304-2b2e-4154-8b48-8265a3b9cc4a": {"__data__": {"text": "MA, 1991.\n[Srikant 2004]  R. Srikant, The Mathematics of Internet Congestion Control , \nBirkhauser, 2004\n[Steinder 2002]  M. Steinder, A. Sethi, \u201cIncreasing Robustness of Fault Localiza-\ntion Through Analysis of Lost, Spurious, and Positive Symptoms,\u201d Proc. 2002 \nIEEE INFOCOM.\n[Stevens 1990]  W. R. Stevens, Unix Network Programming , Prentice-Hall, Engle-\nwood Cliffs, NJ.\n[Stevens 1994]  W. R. Stevens, TCP/IP Illustrated, Vol. 1: The Protocols , Addison-\nWesley, Reading, MA, 1994.\n[Stevens 1997]  W.R. Stevens, Unix Network Programming, Volume 1: Networking \nAPIs-Sockets and XTI , 2nd edition, Prentice-Hall, Englewood Cliffs, NJ, 1997.\n[Stewart 1999]  J. Stewart, BGP4: Interdomain Routing in the Internet , Addison-\nWesley, 1999.\n806     REFERENCES\n[Stone 1998]  J. Stone, M. Greenwald, C. Partridge, J. Hughes, \u201cPerformance of \nChecksums and CRC\u2019s Over Real Data,\u201d IEEE/ACM Transactions on Networking , \nVol. 6, No. 5 (Oct. 1998), pp. 529\u2013543.\n[Stone 2000]  J. Stone, C. Partridge, \u201cWhen Reality and the Checksum Disagree,\u201d \nProc. 2000 ACM SIGCOMM  (Stockholm, Sweden, Aug. 2000).\n[Strayer 1992]  W. T. Strayer, B. Dempsey, A. Weaver, XTP: The Xpress Transfer \nProtocol , Addison-Wesley, Reading, MA, 1992.\n[Stubblefield 2002]  A. Stubblefield, J. Ioannidis, A. Rubin, \u201cUsing the Fluhrer, \nMantin, and Shamir Attack to Break WEP,\u201d Proceedings of 2002 Network and \nDistributed Systems Security Symposium  (2002), pp. 17\u201322.\n[Subramanian 2000]  M. Subramanian, Network Management: Principles and \nPractice , Addison-Wesley, Reading, MA, 2000.\n[Subramanian 2002]  L. Subramanian, S. Agarwal, J. Rexford, R. Katz, \u201cCharac-\nterizing the Internet Hierarchy from Multiple Vantage Points,\u201d Proc. 2002 IEEE \nINFOCOM .\n[Sundaresan 2006]  K.Sundaresan, K. Papagiannaki, \u201cThe Need for Cross-layer \nInformation in Access Point Selection,\u201d Proc. 2006 ACM Internet Measurement \nConference  (Rio De Janeiro, Oct. 2006).\n[Suh 2006]  K. Suh, D. R. Figueiredo, J. Kurose and D. Towsley, \u201cCharacterizing \nand Detecting Relayed Traffic: A Case Study Using Skype,\u201d Proc. 2006 IEEE \nINFOCOM  (Barcelona, Spain, Apr. 2006).\n[Sunshine 1978]  C. Sunshine, Y. Dalal, \u201cConnection Management in Transport \nProtocols,\u201d Computer Networks , North-Holland, Amsterdam, 1978.\n[Tariq 2008]  M. Tariq, A. Zeitoun, V. Valancius, N. Feamster, M. Ammar, \u201cAn-\nswering What-If Deployment and Configuration Questions with WISE,\u201d Proc. 2008 \nACM SIGCOMM  (Aug. 2008).\n[TechnOnLine 2012]  TechOnLine, \u201cProtected Wireless Networks,\u201d online  \nwebcast tutorial, http://www.techonline.com/community/tech_topic/internet/21752\n[Teixeira 2006]  R. Teixeira, J. Rexford, \u201cManaging Routing Disruptions in Inter-\nnet Service Provider Networks,\u201d IEEE Communications Magazine  (Mar. 2006).\n[Think 2012]  Technical History of Network Protocols, \u201cCyclades,\u201d", "doc_id": "26475304-2b2e-4154-8b48-8265a3b9cc4a", "embedding": null, "doc_hash": "fcb5abdee7d052696ef61dc6413dcc8aaeb379ed3a9596e246696a74194ca273", "extra_info": null, "node_info": {"start": 2370723, "end": 2373530}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "8ba1e891-7fae-43a0-9502-a289620fe3a6", "3": "edea2894-0041-4cdb-ac6f-fe13bbf3bc6e"}}, "__type__": "1"}, "edea2894-0041-4cdb-ac6f-fe13bbf3bc6e": {"__data__": {"text": "2008]  M. Tariq, A. Zeitoun, V. Valancius, N. Feamster, M. Ammar, \u201cAn-\nswering What-If Deployment and Configuration Questions with WISE,\u201d Proc. 2008 \nACM SIGCOMM  (Aug. 2008).\n[TechnOnLine 2012]  TechOnLine, \u201cProtected Wireless Networks,\u201d online  \nwebcast tutorial, http://www.techonline.com/community/tech_topic/internet/21752\n[Teixeira 2006]  R. Teixeira, J. Rexford, \u201cManaging Routing Disruptions in Inter-\nnet Service Provider Networks,\u201d IEEE Communications Magazine  (Mar. 2006).\n[Think 2012]  Technical History of Network Protocols, \u201cCyclades,\u201d http://www.\ncs.utexas.edu/users/chris/think/Cyclades/index.shtml\n[Tian 2012]  Y. Tian, R. Dey, Y. Liu, K. W. Ross, \u201cChina\u2019s Internet: Topology \nMapping and Geolocating,\u201d IEEE INFOCOM Mini-Conference 2012  (Orlando, FL, \n2012).\nREFERENCES      807\n[TLD list 2016]  TLD list maintained by Wikipedia, https://en.wikipedia.org/wiki/\nList_of_Internet_top-level_domains\n[Tobagi 1990]  F. Tobagi, \u201cFast Packet Switch Architectures for Broadband Inte-\ngrated Networks,\u201d Proc. 1990 IEEE INFOCOM , Vol. 78, No. 1 (Jan. 1990), pp. \n133\u2013167.\n[TOR 2016]  Tor: Anonymity Online, http://www.torproject.org\n[Torres 2011]  R. Torres, A. Finamore, J. R. Kim, M. M. Munafo, S. Rao, \u201cDissect-\ning Video Server Selection Strategies in the YouTube CDN,\u201d Proc. 2011 Int. Conf. \non Distributed Computing Systems .\n[Tourrilhes 2014]  J. Tourrilhes, P. Sharma, S. Banerjee, J. Petit, \u201cSDN and Open-\nflow Evolution: A Standards Perspective,\u201d IEEE Computer Magazine , Nov. 2014,  \npp. 22\u201329.\n[Turner 1988]  J. S. Turner, \u201cDesign of a Broadcast packet switching network,\u201d \nIEEE Transactions on Communications , Vol. 36, No. 6 (June 1988), pp. 734\u2013743.\n[Turner 2012]  B. Turner, \u201c2G, 3G, 4G Wireless Tutorial,\u201d http://blogs.nmscom-\nmunications.com/communications/2008/10/2g-3g-4g-wireless-tutorial.html\n[UPnP Forum 2016]  UPnP Forum homepage, http://www.upnp.org/\n[van der Berg 2008]  R. van der Berg, \u201cHow the \u2019Net Works: An Introduction to \nPeering and Transit,\u201d http://arstechnica.com/guides/other/peering-and-transit.ars\n[van der Merwe 1998]  J. van der Merwe, S. Rooney, I. Leslie, S. Crosby, \u201cThe \nTempest: A Practical Framework for Network Programmability,\u201d IEEE Network , \nVol. 12, No. 3 (May 1998), pp. 20\u201328.\n[Varghese 1997]  G. Varghese, A. Lauck, \u201cHashed and Hierarchical Timing \nWheels: Efficient Data Structures for Implementing a Timer Facility,\u201d IEEE/ACM \nTransactions on Networking , Vol. 5, No. 6 (Dec. 1997), pp. 824\u2013834.\n[Vasudevan 2012]  S. Vasudevan, C. Diot, J. Kurose, D. Towsley, \u201cFacilitating Ac-\ncess Point Selection in IEEE 802.11 Wireless Networks,\u201d Proc. 2005 ACM Internet \nMeasurement Conference , (San Francisco CA,", "doc_id": "edea2894-0041-4cdb-ac6f-fe13bbf3bc6e", "embedding": null, "doc_hash": "c525cc2e36b02f528a7833a183550e8a4a8dc9df821fb57388e437fdab9cf675", "extra_info": null, "node_info": {"start": 2373532, "end": 2376200}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "26475304-2b2e-4154-8b48-8265a3b9cc4a", "3": "05f95331-96c8-4463-bfdd-8a6183cafae4"}}, "__type__": "1"}, "05f95331-96c8-4463-bfdd-8a6183cafae4": {"__data__": {"text": "A Practical Framework for Network Programmability,\u201d IEEE Network , \nVol. 12, No. 3 (May 1998), pp. 20\u201328.\n[Varghese 1997]  G. Varghese, A. Lauck, \u201cHashed and Hierarchical Timing \nWheels: Efficient Data Structures for Implementing a Timer Facility,\u201d IEEE/ACM \nTransactions on Networking , Vol. 5, No. 6 (Dec. 1997), pp. 824\u2013834.\n[Vasudevan 2012]  S. Vasudevan, C. Diot, J. Kurose, D. Towsley, \u201cFacilitating Ac-\ncess Point Selection in IEEE 802.11 Wireless Networks,\u201d Proc. 2005 ACM Internet \nMeasurement Conference , (San Francisco CA, Oct. 2005).\n[Villamizar 1994]  C. Villamizar, C. Song. \u201cHigh Performance TCP in ANSNET,\u201d \nACM SIGCOMM Computer Communications Review , Vol. 24, No. 5 (1994),  \npp. 45\u201360.\n[Viterbi 1995]  A. Viterbi, CDMA: Principles of Spread Spectrum Communication , \nAddison-Wesley, Reading, MA, 1995.\n[Vixie 2009]  P. Vixie, \u201cWhat DNS Is Not,\u201d Communications of the ACM , Vol. 52, \nNo. 12 (Dec. 2009), pp. 43\u201347.\n808     REFERENCES\n[Wakeman 1992]  I. Wakeman, J. Crowcroft, Z. Wang, D. Sirovica, \u201cLayering \nConsidered Harmful,\u201d IEEE Network  (Jan. 1992), pp. 20\u201324.\n[Waldrop 2007]  M. Waldrop, \u201cData Center in a Box,\u201d Scientific American  (July \n2007).\n[Wang 2004]  B. Wang, J. Kurose, P. Shenoy, D. Towsley, \u201cMultimedia Streaming \nvia TCP: An Analytic Performance Study,\u201d Proc. 2004 ACM Multimedia Confer-\nence (New York, NY, Oct. 2004).\n[Wang 2008]  B. Wang, J. Kurose, P. Shenoy, D. Towsley, \u201cMultimedia Streaming  \nvia TCP: An Analytic Performance Study,\u201d  ACM Transactions on Multimedia \nComputing Communications and Applications (TOMCCAP) , Vol. 4, No. 2 (Apr. \n2008), p. 16. 1\u201322.\n[Wang 2010]  G. Wang, D. G. Andersen, M. Kaminsky, K. Papagiannaki, T. S. E. \nNg, M. Kozuch, M. Ryan, \u201cc-Through: Part-time Optics in Data Centers,\u201d Proc. \n2010 ACM SIGCOMM .\n[Wei 2006]  W. Wei, C. Zhang, H. Zang, J. Kurose, D. Towsley, \u201cInference and \nEvaluation of Split-Connection Approaches in Cellular Data Networks,\u201d Proc.  \nActive and Passive Measurement Workshop  (Adelaide, Australia, Mar. 2006).\n[Wei 2007]  D. X. Wei, C. Jin, S. H. Low, S. Hegde, \u201cFAST TCP: Motivation, \nArchitecture, Algorithms, Performance,\u201d IEEE/ACM Transactions on Networking  \n(2007).\n[Weiser 1991]  M. Weiser, \u201cThe Computer for the Twenty-First Century,\u201d  \nScientific American  (Sept. 1991): 94\u201310. http://www.ubiq.com/hypertext/weiser/ \nSciAmDraft3.html\n[White 2011]  A. White, K. Snow, A. Matthews, F. Monrose, \u201cHookt on fon-iks: \nPhonotactic Reconstruction of Encrypted VoIP Conversations,\u201d IEEE Symposium \non Security and Privacy , Oakland, CA, 2011.\n[Wigle.net 2016]  Wireless Geographic Logging Engine, http://www.wigle.net\n[Wiki Satellite 2016] ", "doc_id": "05f95331-96c8-4463-bfdd-8a6183cafae4", "embedding": null, "doc_hash": "3d6bb73afeed471f2bae87b044d967e05c6fa14d2d9f9e74622b2d799ec443ad", "extra_info": null, "node_info": {"start": 2376229, "end": 2378874}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "edea2894-0041-4cdb-ac6f-fe13bbf3bc6e", "3": "6e2a8857-450b-4bc0-8ebe-dab0351ed813"}}, "__type__": "1"}, "6e2a8857-450b-4bc0-8ebe-dab0351ed813": {"__data__": {"text": "\nArchitecture, Algorithms, Performance,\u201d IEEE/ACM Transactions on Networking  \n(2007).\n[Weiser 1991]  M. Weiser, \u201cThe Computer for the Twenty-First Century,\u201d  \nScientific American  (Sept. 1991): 94\u201310. http://www.ubiq.com/hypertext/weiser/ \nSciAmDraft3.html\n[White 2011]  A. White, K. Snow, A. Matthews, F. Monrose, \u201cHookt on fon-iks: \nPhonotactic Reconstruction of Encrypted VoIP Conversations,\u201d IEEE Symposium \non Security and Privacy , Oakland, CA, 2011.\n[Wigle.net 2016]  Wireless Geographic Logging Engine, http://www.wigle.net\n[Wiki Satellite 2016]  Satellite Internet access, https://en.wikipedia.org/wiki/Satel-\nlite_Internet_access\n[Wireshark 2016]  Wireshark homepage, http://www.wireshark.org\n[Wischik 2005]  D. Wischik, N. McKeown, \u201cPart I: Buffer Sizes for Core  \nRouters,\u201d ACM SIGCOMM Computer Communications Review , Vol. 35, No. 3 \n(July 2005).\nREFERENCES      809\n[Woo 1994]  T. Woo, R. Bindignavle, S. Su, S. Lam, \u201cSNP: an interface for secure \nnetwork programming,\u201d Proc. 1994 Summer USENIX  (Boston, MA, June 1994), \npp. 45\u201358.\n[Wright 2015]  J. Wright, J. Wireless Security Secrets & Solutions , 3e, \u201cHacking \nExposed Wireless,\u201d McGraw-Hill Education, 2015.\n[Wu 2005]  J. Wu, Z. M. Mao, J. Rexford, J. Wang, \u201cFinding a Needle in a Hay-\nstack: Pinpointing Significant BGP Routing Changes in an IP Network,\u201d Proc. \nUSENIX NSDI  (2005).\n[Xanadu 2012]  Xanadu Project homepage, http://www.xanadu.com/\n[Xiao 2000]  X. Xiao, A. Hannan, B. Bailey, L. Ni, \u201cTraffic Engineering with \nMPLS in the Internet,\u201d IEEE Network  (Mar./Apr. 2000).\n[Xu 2004]  L. Xu, K Harfoush, I. Rhee, \u201cBinary Increase Congestion Control (BIC) \nfor Fast Long-Distance Networks,\u201d IEEE  INFOCOM 2004 , pp. 2514\u20132524.\n[Yavatkar 1994]  R. Yavatkar, N. Bhagwat, \u201cImproving End-to-End Performance \nof TCP over Mobile Internetworks,\u201d Proc. Mobile 94 Workshop on Mobile Com-\nputing Systems and Applications  (Dec. 1994).\n[YouTube 2009]  YouTube 2009, Google container data center tour, 2009.\n[YouTube 2016]  YouTube Statistics, 2016, https://www.youtube.com/yt/press/  \nstatistics.html\n[Yu 2004]  Yu, Fang, H. Katz, Tirunellai V. Lakshman. \u201cGigabit Rate Packet \nPattern-Matching Using TCAM,\u201d Proc. 2004 Int. Conf. Network Protocols ,  \npp. 174\u2013183.\n[Yu 2011]  M. Yu, J. Rexford, X. Sun, S. Rao, N. Feamster, \u201cA Survey of VLAN \nUsage in Campus Networks,\u201d IEEE Communications Magazine , July 2011.\n[Zegura 1997]  E. Zegura, K. Calvert, M. Donahoo, \u201cA Quantitative Comparison of \nGraph-based Models for Internet Topology,\u201d IEEE/ACM Transactions on Network-\ning, Vol. 5, No. 6, (Dec. 1997). See also http://www.cc.gatech.edu/projects/gtim for \na software package that generates networks with a transit-stub structure.\n[Zhang 1993]  L. Zhang, S. Deering, D. Estrin,", "doc_id": "6e2a8857-450b-4bc0-8ebe-dab0351ed813", "embedding": null, "doc_hash": "6497a4b5501ffda2b87e82bc44e060d580cdf38db7a472328eb7ee81532a2e3f", "extra_info": null, "node_info": {"start": 2378843, "end": 2381583}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "05f95331-96c8-4463-bfdd-8a6183cafae4", "3": "28eaf934-344a-44c7-b7dc-7dad5691c033"}}, "__type__": "1"}, "28eaf934-344a-44c7-b7dc-7dad5691c033": {"__data__": {"text": "Protocols ,  \npp. 174\u2013183.\n[Yu 2011]  M. Yu, J. Rexford, X. Sun, S. Rao, N. Feamster, \u201cA Survey of VLAN \nUsage in Campus Networks,\u201d IEEE Communications Magazine , July 2011.\n[Zegura 1997]  E. Zegura, K. Calvert, M. Donahoo, \u201cA Quantitative Comparison of \nGraph-based Models for Internet Topology,\u201d IEEE/ACM Transactions on Network-\ning, Vol. 5, No. 6, (Dec. 1997). See also http://www.cc.gatech.edu/projects/gtim for \na software package that generates networks with a transit-stub structure.\n[Zhang 1993]  L. Zhang, S. Deering, D. Estrin, S. Shenker, D. Zappala, \u201cRSVP: \nA New Resource Reservation Protocol,\u201d IEEE Network Magazine , Vol. 7, No. 9 \n(Sept. 1993), pp. 8\u201318.\n[Zhang 2007]  L. Zhang, \u201cA Retrospective View of NAT,\u201d  The IETF Journal , Vol. \n3, Issue 2 (Oct. 2007).\n810     REFERENCES\n[Zhang 2015]  G. Zhang, W. Liu, X. Hei, W. Cheng, \u201cUnreeling Xunlei Kankan: \nUnderstanding Hybrid CDN-P2P Video-on-Demand Streaming,\u201d IEEE Transac-\ntions on Multimedia , Vol. 17, No. 2, Feb. 2015.\n[Zhang X 2102]  X. Zhang, Y. Xu, Y. Liu, Z. Guo, Y. Wang, \u201cProfiling Skype \nVideo Calls: Rate Control and Video Quality,\u201d IEEE INFOCOM  (Mar. 2012).\n[Zink 2009]  M. Zink, K. Suh, Y. Gu, J. Kurose, \u201cCharacteristics of YouTube Network \nTraffic at a Campus Network\u2014Measurements, Models, and Implications,\u201d  Computer \nNetworks , Vol. 53, No. 4, pp. 501\u2013514, 2009.\n811Index\nA\nAAC. See Advanced Audio Coding\nABR. See ATM Available Bit Rate\nAbramson, Norman, 90, 488, 506\naccess control lists, 682, 684\naccess networks, 40\u201346, 432\ncable, 42\u201343, 92, 491, 493\u2013495\ndial-up access, 44, 519\nDSL, 41\u201342, 92\nenterprise, 44\u201345\nEthernet, 44\u201345\nFTTH, 43\u201344, 92\nHFC, 42\nLTE, 46, 580, 581, 585\u2013588\nradio access networks, 584\u2013588\nsatellite, 44, 467\n3G, 46\nWiFi, 44\u201345\naccess points (APs), 550, 551\nin infrastructure LANs, 562\nMAC addresses, 561, 563\nmobility between, 588\u2013589\npower management and, 576\nscanning for, 564\nACK (positive acknowledgments), \n238\u2013242\ncorrupted, 240\nDHCP, 372\u2013373, 530\nduplicate, 242, 277\nin 802.11 RTC/CTS system, \n569\u2013570\nTCP generation recommendation, \n278\nACK bit, 264\nTCP, 681\u2013682ack clocking, 331\nACK frames, 569\u2013570\nacknowledged segments, 299\nacknowledgement frames, 567\nacknowledgements\ncumulative, 252, 266\nlink-layer, 565, 566, 567\nnegative, 238\u2013242, 269, 476\npiggybacked, 269\npositive, 238\u2013242, 277, 372\u2013373, \n569\u2013570\nTCP, 265\u2013267, 280\nacknowledgment number, 265\u2013267\npiggybacked, 269\nTelnet and, 267\u2013269\nacknowledgment number field, 264\nACK received events, 273, 274\nactive optical networks (AONs), 43\nactive queue management (AQM), \n352\nactive scanning, 564\nadapters, 471, 472\nARP query and, 500\nCSMA/CD operation and, 490\u2013491\ndatagram transmission and, 499, \n501\u2013502\n802.11, 561,", "doc_id": "28eaf934-344a-44c7-b7dc-7dad5691c033", "embedding": null, "doc_hash": "aa57bba16872253cf74f1c7446f01a90595f37e57246b3ae3c594192ab4b72e9", "extra_info": null, "node_info": {"start": 2381614, "end": 2384305}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "6e2a8857-450b-4bc0-8ebe-dab0351ed813", "3": "d2214610-4564-4fe7-8b83-685f3c75bfbf"}}, "__type__": "1"}, "d2214610-4564-4fe7-8b83-685f3c75bfbf": {"__data__": {"text": "segments, 299\nacknowledgement frames, 567\nacknowledgements\ncumulative, 252, 266\nlink-layer, 565, 566, 567\nnegative, 238\u2013242, 269, 476\npiggybacked, 269\npositive, 238\u2013242, 277, 372\u2013373, \n569\u2013570\nTCP, 265\u2013267, 280\nacknowledgment number, 265\u2013267\npiggybacked, 269\nTelnet and, 267\u2013269\nacknowledgment number field, 264\nACK received events, 273, 274\nactive optical networks (AONs), 43\nactive queue management (AQM), \n352\nactive scanning, 564\nadapters, 471, 472\nARP query and, 500\nCSMA/CD operation and, 490\u2013491\ndatagram transmission and, 499, \n501\u2013502\n802.11, 561, 565\nerror detection in, 476\nEthernet frames and, 504\u2013506\njabbering, 512\nLAN-on-motherboard configuration, \n471\nlayer independence and, 498\nMAC addresses, 496\u2013498\non separate cards, 471\n812     INDEX\nadaptive backoff, 544\nadaptive congestion control,  \n231\nadaptive HTTP streaming, 709\nadaptive playout delay, 720\u2013722\nadditive-increase,  \nmultiplicative-decrease  \n(AIMD), 305\nfairness of, 307\u2013310\naddress aggregation, 367\naddresses. See also  IP addresses; \nMAC addresses\nanycast, 377\ncare-of, 592, 593\u2013595, 601\nforeign, 592\nIP broadcast, 369, 371\nLAN, 496\nMAC broadcast, 498, 500\nmobile node, 589\nobtaining with DHCP,  \n370\u2013373\npermanent, 592\nphysical, 496\nrealm with private, 373\nSIP, 733\u2013734\naddressing, 117\u2013118\nclassful, 366\u2013367\nIPv4, 362\u2013373\nlink-layer, 496\u2013502\nmobility and, 590\u2013592\nmobility management and,  \n590\u2013592\nprocesses, 117\u2013118\nSIP, 733\u2013734\naddress lease time, 372\nAddress Resolution Protocol (ARP), \n496, 498\u2013501, 531\ndata center network design and, \n525\nAddress Supporting Organization of \nICANN, 369ad hoc networks, 562\nmobile, 552\u2013553, 590\nvehicular, 553\nAdleman, Leonard, 633\nadministrative autonomy, 420\nAdvanced Audio Coding (AAC), 706, \n728\nAdvanced Research Projects Agency \n(ARPA), 88, 399, 544\nAES (Advanced Encryption \nStandard), 630, 664\nagent advertisement, 599, 602\nagent discovery, 598, 599\u2013601\nagent solicitation, 600\naging time, 511\nAH protocol. See Authentication \nHeader protocol\nAIMD. See additive-increase, \n multiplicative-decrease\nAkamai, 178, 183\naliasing\nhost, 156, 164\nmail server, 156\nALOHANet, 88, 90, 488\nALOHA protocols, 483, 506\nbackoff in, 544\npure, 486\nslotted, 484\u2013486, 544\nalternating-bit protocol, 245, 246\nAlto computers, 506\nAmazon, 92, 528, 703\ncloud services, 182\nNetflix and, 182\u2013184\nvideo streaming, 175, 707\nanchor foreign agent, 597\nanchor MSC, 607\nAndreessen, Marc, 91, 212\u2013213\nAndreessen Horowitz, 212\nAndroid devices, 46\nanomaly-based systems, 689\nanonymity, 686\nINDEX      813\nanycast address, 377\nAONs. See active optical networks\nApache Web server, 186, 227\nAPI. See Application Programming \nInterface\napplication architecture, 114\napplication delay, 71\napplication gateways, 680, 684\u2013685, \n687\napplication layer, 78\napplication-layer message, 82\napplication-layer protocols, 123\ndefining, 124\u2013125\nDNS, 78\nFTP, 78\nHTTP, 78, 124\u2013125\nSkype, 124\nSMTP, 78, 125\napplication-level transport reliability, \n231\u2013232\nApplication Programming Interface \n(API),", "doc_id": "d2214610-4564-4fe7-8b83-685f3c75bfbf", "embedding": null, "doc_hash": "25fbd06cb67d0d4435b7289652ae97f1e07b997e7849d59903abb09fa1b36301", "extra_info": null, "node_info": {"start": 2384262, "end": 2387233}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "28eaf934-344a-44c7-b7dc-7dad5691c033", "3": "a72a1047-66eb-405a-b0e2-2d1decb7d959"}}, "__type__": "1"}, "a72a1047-66eb-405a-b0e2-2d1decb7d959": {"__data__": {"text": "212\nAndroid devices, 46\nanomaly-based systems, 689\nanonymity, 686\nINDEX      813\nanycast address, 377\nAONs. See active optical networks\nApache Web server, 186, 227\nAPI. See Application Programming \nInterface\napplication architecture, 114\napplication delay, 71\napplication gateways, 680, 684\u2013685, \n687\napplication layer, 78\napplication-layer message, 82\napplication-layer protocols, 123\ndefining, 124\u2013125\nDNS, 78\nFTP, 78\nHTTP, 78, 124\u2013125\nSkype, 124\nSMTP, 78, 125\napplication-level transport reliability, \n231\u2013232\nApplication Programming Interface \n(API), 117\napplication protocols, well-known, \n223\napplications. See also  multimedia \n applications; network applica -\ntions\nbandwidth-sensitive, 120\ndelay-sensitive, 708\ndistributed, 33\nelastic, 120\nloss-tolerant, 119, 708\nnetwork-service, 444\npeer-to-peer, 168\u2013175\nreal-time conversational, 728\u2013736\nSDN control, 438\u2013440\ntransport services available to, \n118\u2013121\nAPs. See access points\nAQM. See active queue management\nA records, 163ARP. See Address Resolution \nProtocol\nARPA. See Advanced Research \nProjects Agency\nARPAnet, 262\nALOHAnet connection to, 488\nCerf on, 399\ndevelopment of, 88\u201391\nLam on, 544\nMetcalfe and, 506\nrouting algorithms, 407, 414\nARPAnet Satellite System, 544\nARP packet, 500\nARP query, 531\nARP reply, 531\nARP table, 500\nARQ (Automatic Repeat reQuest) \nprotocols, 238, 476\nASN. See autonomous system number\nAS numbers. See autonomous system \nnumber\nAS-PATH, 427, 429\nASs. See autonomous systems\nassociate, 563\nassociation\nin 802.11, 562\u2013865\nsecurity, 668\u2013669, 673\nassured forwarding PHB, 750\nAtheros AR5006, 471\nATM, 545\ncongestion control, 296\ndelay and bandwidth guarantees, \n340\nEthernet and, 503\nIP device interconnection with, 520\nMPLS headers for, 520\nQ2931b and, 753\nQoS information in, 753\nSDN and, 443\nATM Available Bit Rate (ABR), 289\ncongestion control, 296\n814     INDEX\nAT&T, 33, 403, 464, 764\naudio\nAAC, 706, 728\njitter removal for, 719\u2013722\nMP3, 706, 728\nproperties of, 705\u2013707\nquantization, 706\nRTP payloads, 731\nSkype quality adaptation for,  \n725\nstreaming, 707\u2013708\nauthentication\n802.11i, 677\u2013678\nend-point, 86\u201387, 623\nMD5, 422\nmessage, code for, 641\u2013645,  \n662\u2013663, 670\nin OSPF, 422\nreceiver, 655\nsender, 655, 656\nsimple, 422\nwireless LANs, 564\u2013565\nAuthentication Header protocol  \n(AH  protocol), 668\nauthentication key, 641\nauthentication protocol,  \n649\u2013653\nauthoritative DNS servers,  \n160, 532\nautonomous system number (ASN), \n420\nautonomous systems (ASs), 420\nin BGP route advertisement,  \n424\u2013426\nhierarchy within, 422\u2013423\niBGP connections within, 425\nrouting between, 419\u2013423,  \n433, 444\navailability zones, 528\naverage throughput, 72\nAzure, 93B\nB4, 403, 441, 444\nbackbone providers, 432\nbackoff\nadaptive, 544\nbinary exponential, 491\nrandom, 567\nin slotted ALOHA, 544\nback pressure, 714\nbandwidth, 56\u201357\napplication sensitivity to, 120\nATM guarantees, 340\nbest-effort service and, 340\nbottleneck, 139\ncongestion control and, 299\nfairness and, 307\u2013310\nguaranteed", "doc_id": "a72a1047-66eb-405a-b0e2-2d1decb7d959", "embedding": null, "doc_hash": "10d23ba2031d6f9e39845f8c92d3ea660237233c021ebd113e706d9321184a4e", "extra_info": null, "node_info": {"start": 2387236, "end": 2390195}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "d2214610-4564-4fe7-8b83-685f3c75bfbf", "3": "d25b4cc7-632e-4584-bf88-2d207a6986c8"}}, "__type__": "1"}, "d25b4cc7-632e-4584-bf88-2d207a6986c8": {"__data__": {"text": "420\nin BGP route advertisement,  \n424\u2013426\nhierarchy within, 422\u2013423\niBGP connections within, 425\nrouting between, 419\u2013423,  \n433, 444\navailability zones, 528\naverage throughput, 72\nAzure, 93B\nB4, 403, 441, 444\nbackbone providers, 432\nbackoff\nadaptive, 544\nbinary exponential, 491\nrandom, 567\nin slotted ALOHA, 544\nback pressure, 714\nbandwidth, 56\u201357\napplication sensitivity to, 120\nATM guarantees, 340\nbest-effort service and, 340\nbottleneck, 139\ncongestion control and, 299\nfairness and, 307\u2013310\nguaranteed minimal, 339\u2013340\nhost-to-host, 526, 527\nHTTP streaming and, 176\u2013177\nlink-layer switching properties and, \n512\nmemory, 347\nP2P applications and, 168, 170\nQoS guarantees, 738, 753\nSkype usage of, 727\nTCP and high, 306\u2013307\nthroughput and, 119\u2013120\ntraffic class isolation and, 743\u2013744\nUDP streaming and, 709, 711\nvideo early termination wasting, \n716\nvideo prefetching and, 712\nvideo properties and, 704\u2013705\nvideo streaming quality adaptation \nto, 708\nWeb caching and, 139\u2013140\nbandwidth flooding, 84, 85, 167\nbandwidth probing, 299, 305\nbandwidth provisioning, 739\nbandwidth-sensitive applications, 120\nBaran, Paul, 88\nINDEX      815\nbase HTML file, 126\nbase station (BS), 550, 561\nhandoff and, 605\u2013607\nbase station controller (BSC), 582\nbase station subsystem (BSS), 582\nbase transceiver station (BTS), 582\nbasic service set (BSS), 561, 572\nmobility across, 574\u2013575\nBBN, 89\nbeacon frames, 563, 564, 576\nbeacon signals, 606\nBellman-Ford equation, 412\u2013413\nBellovin, Steven, 701\u2013702\nBER. See bit error rate\nBerkeley Internet Name Domain \n(BIND), 155\nBerners-Lee, Tim, 91\nbest-effort delivery services, 220\nbest-effort services, 340\ndimensioning, 737, 739\u2013740\nlimitations of, 716\u2013717\nmultiple classes of service for, \n740\u2013747\nBGP. See Border Gateway Protocol\nBGP attributes, 426\u2013427\nBGP connection, 425\nbidirectional data transfer, 236\nbinary exponential backoff, 491\nBIND. See Berkeley Internet Name \nDomain\nbind(), 223\nbit error rate (BER), 554\u2013556\nrate adaptation and, 575\nbit errors\ndata transfer over channel with, \n237\u2013242\ndata transfer over lossy channel \nwith, 242\u2013245\nundetected, 473\nbit-level error detection and \ncorrection, 472BITNET, 90\nBitTorrent, 169, 172\u2013175, 186,  \n728\ntrackers, 172\u2013174\ntrading algorithm, 174\nblades, 523\nblock ciphers, 628\u2013630\nBluetooth, 577\u2013578\nBoggs, David, 503, 506\nBorder Gateway Protocol (BGP), 402, \n407, 414, 423\u2013435, 532\ndetermining best routes, 426\u2013430\nin Google SDN, 441\nhot potato routing, 428\u2013429\ninternal BGP, 425\u2013426\nIP-anycast implementation with, \n430\u2013431\noutside-AS destinations, 428\nrole of, 423\u2013424\nroute attributes, 427\nroute information advertisement, \n424\u2013426\nroute-selection algorithm, 429\u2013430\nrouting policy, 431\u2013434\nrouting tables, 429\u2013430\nborder routers, 422\u2013423, 523\nbotnets, 84\nbottleneck bandwidth, 139\nbottleneck link, 73\nTCP fairness and, 307\u2013308\nbounded delay, 339\nbring home, 178\nbroadband Internet, 92\nbroadcast\nin ALOHA, 90, 486, 487, 488\nARP messages, 499\u2013501, 531\nCSMA and, 488\u2013489\nCSMA/CD and, 490\nCTS and RTS", "doc_id": "d25b4cc7-632e-4584-bf88-2d207a6986c8", "embedding": null, "doc_hash": "abbbdcff4b3505bace31171c85b5fe55bb98513072c0a47e6e0520c7057b402c", "extra_info": null, "node_info": {"start": 2390239, "end": 2393223}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "a72a1047-66eb-405a-b0e2-2d1decb7d959", "3": "00880046-7cbd-432e-b95e-e793116e9d81"}}, "__type__": "1"}, "00880046-7cbd-432e-b95e-e793116e9d81": {"__data__": {"text": "implementation with, \n430\u2013431\noutside-AS destinations, 428\nrole of, 423\u2013424\nroute attributes, 427\nroute information advertisement, \n424\u2013426\nroute-selection algorithm, 429\u2013430\nrouting policy, 431\u2013434\nrouting tables, 429\u2013430\nborder routers, 422\u2013423, 523\nbotnets, 84\nbottleneck bandwidth, 139\nbottleneck link, 73\nTCP fairness and, 307\u2013308\nbounded delay, 339\nbring home, 178\nbroadband Internet, 92\nbroadcast\nin ALOHA, 90, 486, 487, 488\nARP messages, 499\u2013501, 531\nCSMA and, 488\u2013489\nCSMA/CD and, 490\nCTS and RTS frames, 569\nDHCP requests, 529\u2013530\nEthernet links, 508\n816     INDEX\nbroadcast. (continued)\nforwarding to, 386\nlink-layer, 479\nlink-state, 407, 419\nMAC address for, 498, 500\nin OSPF, 421\u2013422\npacket sniffing and, 86\nprobe frames, 564\nin switch poisoning, 513\nwireless LANs, 479\nbroadcast address\nIP, 369, 371\nMAC, 498, 500\nbroadcast channels, 481\nbroadcast link, 479\u2013481\nbroadcast media, 126, 331\nlive streaming as, 709\nbroadcast storms, 514\u2013515\nBrooks, Fred, 701\nbrowsers, 709\nbrute-force attacks, 629\nBS. See base station\nBSC. See base station controller\nBSS. See base station subsystem; \nbasic service set\nBTS. See base transceiver station\nbuffered distributors, 508\nbuffer overflows, congestion causing, \n294\u2013295\nbuffers\nclient application, 713\u2013714\nclient-side, 710\noutput, 52\nreceive, 281, 282\nsend, 263\nsizing for routers, 353\nin streaming, 713\u2013714\nTCP, 713\u2013714\nbuffer starvation, 717\nbus, switching via, 348\nBush, Vannevar, 91C\nCA. See Certification Authority\ncable Internet access, 42\u201343, 92\nbinary exponential backoff in, 491\nDOCSIS, 493\u2013495\ncable modem termination system \n(CMTS), 43, 493\u2013494\ncaching, 331\nDNS, 162\u2013163\npush, 183\u2013184\nWeb, 138\u2013144\nCaesar cipher, 625\ncall admission, 752, 753\ncall routing, to mobile users, 604\u2013605\ncall setup protocol, 753\ncall setup signaling, 753\ncanonical hostname, 156\ncare-of address (COA), 592\nin agent discovery, 601\nindirect routing and, 593\u2013595\ncarrier sense multiple access (CSMA), \n483, 487\u2013489\ncarrier sensing, 487\ncarrier-sensing random access, 565\nCAST, 658\nCBC. See Cipher Block Chaining\nCD. See compact disk\nCDMA. See code division multiple \naccess\nCDNs. See Content Distribution \nNetworks\ncells, 581\ncell towers, 550\ncellular data networks, 551\nCDMA in, 556\ncellular Internet access, 579\ncellular network architecture,  \n579\u2013582\n4G, 585\u2013588\n3G, 582\u2013585\n2G, 581\u2013582\nINDEX      817\ncellular networks\nCDMA use in, 483\n4G, 548, 580, 581, 585\u2013588\nGSM, 579\u2013582, 605\u2013608\nLTE, 46, 580, 581, 585\u2013588\nmobility management in, 602\u2013610\n3G, 46, 548, 551, 582\u2013585, 705\n2G, 581\u2013582\ncellular telephony, 46, 92, 483, 547\ncentralized designs, 157\u2013158\ncentralized routing algorithm, 406\u2013\n407\nin LS algorithm, 408\ncentral office (CO), 41\u201342\nCerf, Vinton, 90, 262, 399\u2013400, 544\nCERT Coordination Center, 624\ncertificates, 648\nCertification Authority (CA), 647\u2013\n648, 658\nchannel partitioning protocols, 481\u2013\n483, 556, 565\nCDMA, 485\nFDM,", "doc_id": "00880046-7cbd-432e-b95e-e793116e9d81", "embedding": null, "doc_hash": "3c38d6ff1ed0f797703b895d43da897cde2c78c4af746d1b14525cd6f3120d9f", "extra_info": null, "node_info": {"start": 2393225, "end": 2396101}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "d25b4cc7-632e-4584-bf88-2d207a6986c8", "3": "96a7d6f1-128c-4a09-b935-a1c99927c717"}}, "__type__": "1"}, "96a7d6f1-128c-4a09-b935-a1c99927c717": {"__data__": {"text": "605\u2013608\nLTE, 46, 580, 581, 585\u2013588\nmobility management in, 602\u2013610\n3G, 46, 548, 551, 582\u2013585, 705\n2G, 581\u2013582\ncellular telephony, 46, 92, 483, 547\ncentralized designs, 157\u2013158\ncentralized routing algorithm, 406\u2013\n407\nin LS algorithm, 408\ncentral office (CO), 41\u201342\nCerf, Vinton, 90, 262, 399\u2013400, 544\nCERT Coordination Center, 624\ncertificates, 648\nCertification Authority (CA), 647\u2013\n648, 658\nchannel partitioning protocols, 481\u2013\n483, 556, 565\nCDMA, 485\nFDM, 485\nTDM, 484\u2013485\nchannel propagation delay, 489\nchannels\nwith bit errors, 238\u2013244\nbroadcast, 481\n802.11, 562\u2013565\nlossy, 242\u2013245\nmultiple access, 479, 480\nperfectly reliable, 236, 237\nsatellite radio, 49\nterrestrial radio, 48\u201349\nchannel utilization, 247\nCheck Point, 680, 688\nchecksum field, 264\nchecksumming, 476\nchecksums\ncorrupted ACK and NAK packet \ndetection, 240error detection with, 476\nhash functions and, 639\u2013640\nInternet, 476, 639\u2013640\nIPv4 headers, 359\u2013360\nUDP, 232\u2013234\nChina Telecom, 403\nChina Unicom, 403\nchipping rate, 556\nchoke packets, 296\nchosen-plaintext attacks, 627\nchunks\nBitTorrent, 172\u2013174\nNetflix streaming platform, 183\nCIDR. See Classless Interdomain \nRouting\nCipher Block Chaining (CBC), 630\u2013\n632, 669\nin SSL, 664\nciphertext, 625\nciphertext-only attacks, 627\ncircuit, 55\ncircuit switching, 55\u201359\npacket switching versus , 58\u201359\nCisco, 32, 92, 680, 688\nCisco 12000 series, switching fabric, \n348\u2013349\nCisco Catalyst 6500 Series, 346\nswitching bus, 348\nCisco Catalyst 7600 Series, 346\nswitching fabric, 349\nCisco Catalyst 8500 Series, switching \nfabric, 348\nCisco CRS, switching strategy, 349\nClark, Jim, 91, 212\nclassful addressing, 366\u2013367\nClassless Interdomain Routing \n(CIDR), 365\u2013366, 530\ncleartext, 625\nClear to Send (CTS), 568\u2013570\nclient application buffers, 713\u2013714\nclient buffering, 710\n818     INDEX\nclient process, 261\nclients, 39, 114\nprocesses, 116\u2013117\nclient-server architecture, 114, 115\nfile distribution, 169\u2013172\nTCP socket programming, 193\nUDP socket programming, 188\nclient-side buffers, 710\ncloud computing, 93\nAmazon, 182\u2013184\ncloud data centers, 524\nhierarchical architecture in,  \n525\u2013526\ncloud services, response time of, 303\ncluster selection strategy, 181\nCMTS. See cable modem termination \nsystem\nCNAME records, 164\nCO. See central office\nCOA. See care-of address\ncoaxial cable, 48\ncode division multiple access \n(CDMA), 483, 485, 548,  \n556\u2013560\ncollide, 481\ncollision avoidance, 565\nRTS/CTS frames for, 568\u2013570\ncollision detection, 487\nCSMA/CD, 487, 489\u2013492, 560, \n567\n802.11 MAC protocol and,  \n565\u2013566\ncollisions\nin broadcast channels, 481\nin CSMA, 488\u2013489\nCSMA/CD and, 567\nFDM avoiding, 483\nlink-layer switching eliminating, \n512\nrandom access protocols and,  \n483in slotted ALOHA, 484\nTDM eliminating, 482\ncommunication layer, SDN, 438\ncommunication links, 32\nCommunications-Electronics Security \nGroup, 633\ncompact disk (CD), 706\ncomputational complexity, of LS \nalgorithm, 410\ncomputer networks, 30\ngraph model of,", "doc_id": "96a7d6f1-128c-4a09-b935-a1c99927c717", "embedding": null, "doc_hash": "3be8d7f7f24da08e6edf2990a315f137c01904f6bf547d1d35b250e854d760f2", "extra_info": null, "node_info": {"start": 2396150, "end": 2399077}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "00880046-7cbd-432e-b95e-e793116e9d81", "3": "3b033c94-6f3b-4dbc-95bd-0b2feb8eaf27"}}, "__type__": "1"}, "3b033c94-6f3b-4dbc-95bd-0b2feb8eaf27": {"__data__": {"text": "detection, 487\nCSMA/CD, 487, 489\u2013492, 560, \n567\n802.11 MAC protocol and,  \n565\u2013566\ncollisions\nin broadcast channels, 481\nin CSMA, 488\u2013489\nCSMA/CD and, 567\nFDM avoiding, 483\nlink-layer switching eliminating, \n512\nrandom access protocols and,  \n483in slotted ALOHA, 484\nTDM eliminating, 482\ncommunication layer, SDN, 438\ncommunication links, 32\nCommunications-Electronics Security \nGroup, 633\ncompact disk (CD), 706\ncomputational complexity, of LS \nalgorithm, 410\ncomputer networks, 30\ngraph model of, 405\u2013406\nhistory of, 87\u201393\nprocess interface to, 117\nthroughput in, 71\u201374\nconditional GET, 142\u2013144\nconfidentiality, 622, 655\ncongestion\nalternative algorithms, 305\nbuffer overflows from, 294\u2013295\ncauses and costs of, 289\u2013295\ndelays from, 291\nlost segments and, 299\nmultihop paths and, 293\u2013295\nretransmission and, 292\u2013293\nrouters and, 290\u2013295\nthroughput and, 290\u2013295\ncongestion avoidance, 301\u2013302\ncongestion control, 220, 281\nABR, 231\nadaptive, 231\nAIMD, 305\napproaches to, 296\nbandwidth and, 299\nend-to-end, 296\nnetwork-assisted, 296, 297\nprinciples of, 289\u2013296\nTCP, 297\u2013311\ncongestion window, 298, 304\nconnection flooding, 85\nconnectionless demultiplexing, \n223\u2013224\nINDEX      819\nconnectionless multiplexing,  \n223\u2013224\nconnectionless transport, 228\u2013234\nconnection management, TCP,  \n283\u2013287, 289\nconnection-oriented demultiplexing, \n224\u2013227\nconnection-oriented multiplexing, \n224\u2013227\nconnection-oriented transport,  \n261\u2013289\nconnection replay attack, 664\nconnection requests, 225\nconnection state, 230\nconnection tables, 683\nContent Distribution Networks \n(CDNs), 142, 177\u2013181\ncase studies, 181\u2013185\ncluster selection strategy,  \n181\ndata centers, 178\nDNS and, 179\u2013180\nGoogle, 184\nIP-anycast and, 430\nISPs and, 178\nIXPs and, 178\nKankan, 184\u2013185\nNetflix, 182\u2013184\noperation of, 178\u2013181\nprivate, 178, 182\u2013184\nthird-party, 178\nvideo streaming and,  \n180\u2013181\nYouTube, 184\ncontent ingestion, 182\ncontent processing, 182\ncontent provider networks,  \n62\ncontrol frames, 568\u2013570\ncontrol packets, 342\nin Skype, 725control plane, 333, 343, 401\n4G, 586\nSDN, 435\u2013444\nconvergence, routing algorithm speed \nof, 419\nconversational voice and video, \n708\u2013709\ncookies, 136\u2013138\nSYN, 288\ncorrespondent, 590\nin indirect routing, 594\u2013595\ncorrespondent agent, 596\ncountdown timer, 244\nCRC. See cyclic redundancy check\ncrossbar switches, 347\u2013349\ncryptographic hash functions,  \n639\u2013641\ncryptography, 702\nattack types against, 627\ncomponents, 625\nprinciples of, 624\u2013638\npublic key encryption, 625,  \n632\u2013638, 658, 664\nsymmetric key, 626\u2013632, 653, 655, \n658, 664\nCSMA. See carrier sense multiple \naccess\nCSMA/CA. See CSMA with collision \navoidance\nCSMA/CD. See CSMA with collision \ndetection\nCSMA with collision avoidance \n(CSMA/CA), 565, 567\nCSMA with collision detection \n(CSMA/CD), 487, 489\u2013492, \n560, 567\nCSNET, 90\nCTS. See Clear to Send\ncumulative acknowledgement, 252, \n266\ncustomer, 60\n820     INDEX\ncwnd, 298, 300\u2013304\nCyclades,", "doc_id": "3b033c94-6f3b-4dbc-95bd-0b2feb8eaf27", "embedding": null, "doc_hash": "1305bcaf8a69bccefad5c37204709a34e225a2d02c596f6b0312a12e4222a36a", "extra_info": null, "node_info": {"start": 2399040, "end": 2401947}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "96a7d6f1-128c-4a09-b935-a1c99927c717", "3": "e4f80229-f4d7-43f1-a4fc-a860d543f2e2"}}, "__type__": "1"}, "e4f80229-f4d7-43f1-a4fc-a860d543f2e2": {"__data__": {"text": " \n632\u2013638, 658, 664\nsymmetric key, 626\u2013632, 653, 655, \n658, 664\nCSMA. See carrier sense multiple \naccess\nCSMA/CA. See CSMA with collision \navoidance\nCSMA/CD. See CSMA with collision \ndetection\nCSMA with collision avoidance \n(CSMA/CA), 565, 567\nCSMA with collision detection \n(CSMA/CD), 487, 489\u2013492, \n560, 567\nCSNET, 90\nCTS. See Clear to Send\ncumulative acknowledgement, 252, \n266\ncustomer, 60\n820     INDEX\ncwnd, 298, 300\u2013304\nCyclades, 89\ncyclic redundancy check (CRC), \n477\u2013479, 554\nin 802.11, 566, 571\nin Ethernet frames, 505\nD\nDARPA. See Defense Advanced \nResearch Projects Agency\nDARTnet, 764\nDASH. See Dynamic Adaptive \nStreaming over HTTP\ndata center network design, 523\ndata center networks, 523\u2013528\nhierarchical architecture,  \n525\u2013526\nload balancing, 524\u2013525\ntrends in, 526\u2013528\ndata centers, 39, 114\nCDNs, 178\nGoogle, 179\nhosts, 523\nmodular, 526\u2013527\nData Center TCP (DCTCP),  \n311, 313\nDATA frames, 568\u2013570\nDatagram Congestion Control \nProtocol (DCCP), 313\u2013314\ndatagrams, 79, 219\nindirect routing of, 599\ninspecting, 376\nIP, 529\nIPsec, 669\u2013672\nIPv4 format, 358\u2013360\nIPv4 fragmentation, 360\u2013363\nIPv6 format, 377\u2013379\nNAT and, 374\u2013375\nnetwork-layer, 82\nreassembly of, 361\u2013362, 379\nsubnet dispatch of, 501\u2013502Data-Over-Cable Service Interface \nSpecifications (DOCSIS), \n493\u2013495\nbinary exponential backoff in, 491\ndata plane, 333, 389\n4G, 586\ngeneralized forwarding and SDN, \n382\u2013389\nIP, 357\u2013382\nrouters, 341\u2013357\nSDN and, 436, 442\u2013443\ndata received events, 273, 274\nDavies, Donald, 88\nDCCP. See Datagram Congestion \nControl Protocol\nDCTCP. See Data Center TCP\nDDoS. See distributed DoS\ndecentralized routing algorithm, \n406\u2013407\nDECnet, 498\ndecryption algorithm, 625\ndeep packet inspection (DPI), 376, \n382, 687\nDeering, Steve, 617\nDefense Advanced Research Projects \nAgency (DARPA), 89, 90, 399\ndelays\nadaptive playout, 720\u2013722\napplication, 71\nbounded, 339\nchannel propagation, 489\nin end systems, 71\nend-to-end, 69\u201371, 717, 718\nfixed playout, 719\u2013720\nnetwork congestion and, 291\nnodal, 64\nnodal processing, 63\nin packet-switched networks, \n63\u201374\nplayout, 719\u2013720, 720\u2013722\nprocessing, 64\nINDEX      821\npropagation, 63, 65\u201367\nqueuing, 52\u201353, 63, 64, 67\u201369, 291\nin shared medium, 71\ntotal nodal, 63\ntransmission, 63, 64\u201367\ntypes of, 63\u201367\ndelay-sensitive applications, 708\ndemilitarized zone (DMZ), 689\ndemultiplexing, 221\u2013228, 530\nconnectionless, 223\u2013224\nconnection-oriented, 224\u2013227\ntransport-layer, 220\ndenial-of-service (DoS) attacks,  \n84\u201385\ndistributed, 85, 86, 167\nSYN floods for, 288\nDES (Data Encryption Standard), 630, \n658\ndestination-based forwarding, 343, \n344\u2013347\ndestination port number, 264\ndestination port number field, 222\nDHCP. See Dynamic Host \nConfiguration Protocol\nDHCP ACK message, 372\u2013373, 530\nDHCP discover message, 371\nDHCP offer message,", "doc_id": "e4f80229-f4d7-43f1-a4fc-a860d543f2e2", "embedding": null, "doc_hash": "63d7eb7b3f7f041f3d0a0b618e050a1bbd47e4d022168e0d4945515584c1a6ec", "extra_info": null, "node_info": {"start": 2402013, "end": 2404782}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "3b033c94-6f3b-4dbc-95bd-0b2feb8eaf27", "3": "e61fc082-0804-498b-9dad-f5768ad2d518"}}, "__type__": "1"}, "e61fc082-0804-498b-9dad-f5768ad2d518": {"__data__": {"text": "of, 63\u201367\ndelay-sensitive applications, 708\ndemilitarized zone (DMZ), 689\ndemultiplexing, 221\u2013228, 530\nconnectionless, 223\u2013224\nconnection-oriented, 224\u2013227\ntransport-layer, 220\ndenial-of-service (DoS) attacks,  \n84\u201385\ndistributed, 85, 86, 167\nSYN floods for, 288\nDES (Data Encryption Standard), 630, \n658\ndestination-based forwarding, 343, \n344\u2013347\ndestination port number, 264\ndestination port number field, 222\nDHCP. See Dynamic Host \nConfiguration Protocol\nDHCP ACK message, 372\u2013373, 530\nDHCP discover message, 371\nDHCP offer message, 371\u2013372\nDHCP request message, 372, 529\ndial-up Internet access, 44, 519\nDIAMETER, 565, 678\nDIC, 305\ndifferentiated service, 737\nDiffserv, 747\u2013751\nDiffie-Hellman Key Exchange, 632\nDiffserv, 747\u2013751\nDIFS. See Distributed Inter-frame \nSpace\nDigital Attack Map, 84\ndigital signatures, 638, 642\u2013648\ndigital subscriber line (DSL),  \n41\u201342, 92digital subscriber line access  \nmultiplexer (DSLAM), 41\u201342\nDijkstra's algorithm, 407, 414\nin OSPF, 420\ndirectional antennas, 570\ndirect routing, 596\u2013597\nDirect Sequence Wideband CDMA \n(DS-WCDMA), 584\ndistance-vector algorithm (DV algo -\nrithm), 412\u2013419\ndecentralization, 414\nlink-cost changes and link failure, \n416\u2013418\nLS compared with, 418\u2013419\nmessage complexity, 418\u2013419\npoisoned reverse, 418\nrobustness, 419\nspeed of convergence, 419\ndistributed applications, 33\ndistributed DoS (DDoS), 85\nDNS servers targeted by, 167\nDistributed Inter-frame Space (DIFS), \n567\ndistribution time, 169\u2013172\nDMZ. See demilitarized zone\nDNS. See domain name system\nDNS caching, 162\u2013163\nDNS query message, 531\nDNS reply message, 532\nDNS servers, 155\nauthoritative, 160, 532\nBIND, 155\nDDoS attacks targeting, 167\ninteractions of, 161\nlocal, 160\nroot, 159, 162\nTLD, 158, 159\nDOCSIS. See Data-Over-Cable \nService Interface Specifications\nDOCSIS 2.0, 43\ndomain names, 434\n822     INDEX\ndomain name system (DNS), 78, \n154\u2013168, 531\nCDNs and, 179\u2013180\ndistributed, hierarchical database, \n158\u2013162\ninserting records, 166, 168\nInternet presence and, 434\u2013435\nintra-domain routing to, 531\u2013532\nintruder interference with, 624\nIP-anycast in, 430\niterative queries, 161\nmessages, 164\u2013166, 531\u2013532\noperation of, 157\u2013163\nquery chain, 161\u2013162\nrecords, 163\u2013164, 166, 168\nrecursive queries, 161\u2013162\nresource records, 163\u2013164, 532\nservices provided by, 155\u2013157\nUDP usage by, 229\nvulnerabilities, 167\nDoS. See denial-of-service attacks\ndotted-decimal notation, 363, 498\u2013499\nDPI. See deep packet inspection\ndropping\nOpenFlow, 386\npackets, strategies for, 352\ndrop-tail, 352\nDSL. See digital subscriber line\nDSLAM. See digital subscriber line \naccess multiplexer\nduplicate ACKs, 242, 277\nduplicate data packets, 244\nduplicate packets, 240\nDV algorithm. See distance-vector \nalgorithm\nDynamic Adaptive Streaming over \nHTTP (DASH), 176\u2013177, 183, \n716\nDynamic Host Configuration Protocol \n(DHCP), 370\u2013372\naddress obtainment with, 370\u2013373messages, 371\u2013372, 529\u2013530\nmobile nodes and, 372\nNAT and, 373\nrequests, 529\u2013530\ndynamic", "doc_id": "e61fc082-0804-498b-9dad-f5768ad2d518", "embedding": null, "doc_hash": "8a220de35db85af0008618ee039277774e91c08048aeaba26269b655fa8ee33a", "extra_info": null, "node_info": {"start": 2404678, "end": 2407633}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "e4f80229-f4d7-43f1-a4fc-a860d543f2e2", "3": "6da5349d-8690-4b43-bd13-66adcbe75336"}}, "__type__": "1"}, "6da5349d-8690-4b43-bd13-66adcbe75336": {"__data__": {"text": "deep packet inspection\ndropping\nOpenFlow, 386\npackets, strategies for, 352\ndrop-tail, 352\nDSL. See digital subscriber line\nDSLAM. See digital subscriber line \naccess multiplexer\nduplicate ACKs, 242, 277\nduplicate data packets, 244\nduplicate packets, 240\nDV algorithm. See distance-vector \nalgorithm\nDynamic Adaptive Streaming over \nHTTP (DASH), 176\u2013177, 183, \n716\nDynamic Host Configuration Protocol \n(DHCP), 370\u2013372\naddress obtainment with, 370\u2013373messages, 371\u2013372, 529\u2013530\nmobile nodes and, 372\nNAT and, 373\nrequests, 529\u2013530\ndynamic routing algorithms, 407\nDYSWIS, 764\nE\nEAP. See Extensible Authentication \nProtocol\nEAPoL, 677\nEarthlink, 551\neavesdropping, 624\ne-Bay, 92\neBGP. See external BGP\nEC2, 93\nECE. See Explicit Congestion \nNotification Echo\necho request, 447\nECN. See Explicit Congestion \nNotification\nedge routers, 342\nEducause, 159\nefficiency\nof CSMA/CD, 492\nof slotted ALOHA, 485\u2013486\nof slotted multiple access  \nprotocols, 485\n802.11. See IEEE 802.11\nEIGRP protocol, 420\nelastic applications, 120\ne-mail, 144\u2013154\naccess protocols, 150\u2013154\nIMAP, 151, 153\u2013154\nmessage formats, 149\u2013150\nsecuring, 654\u2013659\nservers, 144\u2013145, 156\nSMTP, 78, 125, 146\u2013151\nweb-based, 154\nencapsulation, 81\u201383\nin indirect routing, 594\nINDEX      823\nEncapsulation Security Payload \n(ESP), 668, 670\u2013671\nencrypted, 622\nencryption\nattack types against, 627\npasswords, 651\u2013652\npolyalphabetic, 627\u2013628\npublic key, 625, 632\u2013638, 658, 664\nsecurity associations and, 669\nstandards for, 630\nsymmetric key, 626\u2013632\nencryption algorithm, 625\nend-end principle, 233\nend-point authentication, 86\u201387, 623\nend systems, 30, 32, 37, 39\ndelay in, 71\nend-to-end congestion control, 296\nend-to-end connection, 55\nend-to-end delay, 69\u201371, 717, 718\nenhanced packet core (EPC), 586\neNodeB, 586\nenter deep, 178, 179\nentity body, 134\nEPC. See enhanced packet core\nerror checking, UDP checksums and, \n232\u2013234\nerror correction, 471\nbit-level, 472\ntechniques for, 472\u2013479\nerror detection, 238, 471\nbit-level, 472\nchecksumming, 476\nparity bits, 474\u2013476\ntechniques for, 472\u2013479\nESP. See Encapsulation Security \nPayload\nEstimatedRTT, 270\nEstrin, Deborah, 617\u2013619\nEthane project, 443\u2013444\nEthernet, 33, 44\u201345, 471, 488, 502\u2013503\nbinary exponential backoff in, 491broadcast, 479\nCSMA used by, 483\ndevelopment of, 90\n802.1Q-tagged VLAN frames, 518\nframes, 529\nframe structure, 504\u2013506, 518\nGigabit, 508\nMAC protocol, 507\nMTU, 263\npacket sniffing, 86\nrepeater, 507\nrun lengths, 507\u2013508\nspeeds, 507\u2013508\ntechnologies, 506\u2013509\ntopologies, 503\neven parity schemes, 474\nevent-based programming, 253\nEWMA. See exponential weighted \nmoving average\nexpedited forwarding PHB, 750\nExplicit Congestion Notification \n(ECN), 310\u2013311\nExplicit Congestion Notification Echo \n(ECE), 311\nexponential weighted moving average \n(EWMA), 270\nextended FSM, 252\nExtensible Authentication Protocol \n(EAP), 677\nexternal BGP (eBGP),", "doc_id": "6da5349d-8690-4b43-bd13-66adcbe75336", "embedding": null, "doc_hash": "af9e42d1a64ec3f2ba70786eb6724a33eba8be224dbecb811bf47902a09db81a", "extra_info": null, "node_info": {"start": 2407638, "end": 2410494}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "e61fc082-0804-498b-9dad-f5768ad2d518", "3": "927d4969-d577-49f4-b605-b6ba3b3a738f"}}, "__type__": "1"}, "927d4969-d577-49f4-b605-b6ba3b3a738f": {"__data__": {"text": "518\nGigabit, 508\nMAC protocol, 507\nMTU, 263\npacket sniffing, 86\nrepeater, 507\nrun lengths, 507\u2013508\nspeeds, 507\u2013508\ntechnologies, 506\u2013509\ntopologies, 503\neven parity schemes, 474\nevent-based programming, 253\nEWMA. See exponential weighted \nmoving average\nexpedited forwarding PHB, 750\nExplicit Congestion Notification \n(ECN), 310\u2013311\nExplicit Congestion Notification Echo \n(ECE), 311\nexponential weighted moving average \n(EWMA), 270\nextended FSM, 252\nExtensible Authentication Protocol \n(EAP), 677\nexternal BGP (eBGP), 425\nF\nFacebook, 704\nfading, 556\nfailover paths, 522\nfairness\nof AIMD, 307\u2013310\nparallel TCP connections and, 310\nTCP and, 307\u2013310\nUDP and, 309\u2013310\nfast recovery, 302\u2013304\n824     INDEX\nfast retransmit, 277\u2013279\nFCFS. See first-come-first-served\nFDDI. See fiber distributed data inter -\nface\nFDM. See frequency-division  \nmultiplexing\nFDMA, 581\nfeature phones, 618\nFEC. See forward error correction\nFeynman, Richard, 332\nFHSS. See frequency-hopping spread \nspectrum\nfiber distributed data interface \n(FDDI), 493, 503\nfiber optics, 92\nin cable systems, 42\u201343\nphysical media, 48\nfiber to the home (FTTH), 43\u201344, 92\nFIFO. See first-in-first-out\nfile distribution\nclient-server, 169\u2013172\nP2P, 168\u2013175\nfiltering, 509\nFIN bit, 265\nfinite-state machine (FSM)\nfor data transfer over channel with \nbit errors, 238\u2013244\nfor data transfer over lossy channel \nwith bit errors, 244\u2013245\nfor data transfer over perfectly reli -\nable channel, 236, 237\nextended, 252\nfor GBN protocol, 250\u2013252\nTCP congestion control, 301, 302\nfirewalls, 376, 382, 623, 679\u2013687\napplication gateways, 684\u2013685, \n687\nstateful filters, 680, 682\u2013684\ntraditional packet filters, 680\u2013682\nfirst-come-first-served (FCFS), 353\nfirst-in-first-out (FIFO), 353\u2013354fixed playout delay, 719\u2013720\nflag days, 380\nflag field, 264\nflow, 377\nflow-based forwarding, 435\u2013436\nflow control, TCP, 280\u2013282\nflow-control service, 280\nflow table, 384\nmatch-plus-action, 443\nSDN, 438\nwildcards in, 385\nFloyd, Sally, 465\u2013466\nforeign address, 592\nforeign agent, 590\nanchor, 597\ndiscovery, 598, 599\u2013600\nforeign network, 590\u2013592\nforward error correction (FEC), 476, \n717\npacket loss recovery with, 722\u2013723\nin Skype, 725\nforwarding, 334, 337, 340\nto broadcast, 386\ndestination-based, 343, 344\u2013347\nflow-based, 435\u2013436\ngeneralized, 343, 382\u2013389\nlink-layer switches, 509\u2013510\nlongest prefix matching rule, 345, \n367\nMPLS-enhanced, 521\nOpenFlow, 386\npackets, 336\nSDN, 435\u2013436\nforwarding plane, 342\u2013343\nforwarding tables, 53\u201354, 336, 337\nin input processing, 345\u2013346\nIP, 530\nline cards, 345\nin LS algorithm, 409\u2013410\nmatch-plus-action, 384\nprefixes, 345\nINDEX      825\nrouters, 336, 337\nin SDN, 342, 344\n4G, 548, 580\ncore network, 585\u2013587\ndata plane, 586\nnetwork architecture, 585\u2013588\nQoS in, 586\nradio access network, 587\u2013588\ntunneling in, 586\nwireless LANs versus , 580\n4G LTE, 580, 581\nfragment, 361\nfragmentation\nIPv4", "doc_id": "927d4969-d577-49f4-b605-b6ba3b3a738f", "embedding": null, "doc_hash": "37efc25f078097426218e94a748b1afb2a23a780300ee9ce4ba8643fbacd46e1", "extra_info": null, "node_info": {"start": 2410508, "end": 2413363}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "6da5349d-8690-4b43-bd13-66adcbe75336", "3": "339c99a9-4348-48ee-a9c3-8483b58fd861"}}, "__type__": "1"}, "339c99a9-4348-48ee-a9c3-8483b58fd861": {"__data__": {"text": "435\u2013436\nforwarding plane, 342\u2013343\nforwarding tables, 53\u201354, 336, 337\nin input processing, 345\u2013346\nIP, 530\nline cards, 345\nin LS algorithm, 409\u2013410\nmatch-plus-action, 384\nprefixes, 345\nINDEX      825\nrouters, 336, 337\nin SDN, 342, 344\n4G, 548, 580\ncore network, 585\u2013587\ndata plane, 586\nnetwork architecture, 585\u2013588\nQoS in, 586\nradio access network, 587\u2013588\ntunneling in, 586\nwireless LANs versus , 580\n4G LTE, 580, 581\nfragment, 361\nfragmentation\nIPv4 datagram, 360\u2013363\nIPv6 datagram, 379\nframe control fields, 573\nframe relay, 520\nframes, 80\nACK, 569\u2013570\nacknowledgement, 567\nbeacon, 563, 564, 576\ncollisions between, 481\ncontrol, 568\u2013570\nCTS, 568\u2013570\nDATA, 568\u2013570\n802.11, 570\u2013573\n802.11 transmission, 566\nEthernet, 529\nEthernet structure for, 504\u2013506, \n507\nlink-layer, 82, 468\nMPLS, 520\u2013521\nprobe, 564\nRTS, 568\u2013570\ntime, 482\nVLAN, 518\nframing, 470\nfrequency-division multiplexing \n(FDM), 56\u201357, 481, 582\nchannel partitioning, 485\ncollision avoidance, 483in DOCSIS, 493\northogonal, 587\nfrequency-hopping spread spectrum \n(FHSS), 577\nFSM. See finite-state machine\nFTP protocol, 78\nFTTH. See fiber to the home\nfull-duplex service, 261\nfully connected topology, 526\nG\nGateway GPRS Support Nodes \n(GGSNs), 584\nGateway Mobile services Switching \nCenter (GMSC), 603\ngateway router, 424\ngateways, 343\napplication, 680, 684\u2013685, 687\nP-GW, 586\nS-GW, 586\nGBN protocol. See Go-Back-N (GBN) \nprotocol\nGE Information Services, 89\ngeneralized forwarding, 343,  \n382\u2013389\naction, 386\nmatch, 384\u2013386\nmatch-plus-action, 386\u2013389\nGeneralized Packet Radio Service \n(GPRS), 584\ngenerator, 477\ngeographically closest, 181\ngeostationary satellites, 49\nGET requests, 132, 532\nconditional, 142\u2013144\nDASH and, 176\u2013177\nHTTP streaming and, 176\nGGSNs. See Gateway GPRS Support \nNodes\nGigabit Ethernet, 508\nGIST, 764\n826     INDEX\nGlobal System for Mobile \nCommunications (GSM), \n579\u2013580\nhandoffs in, 605\u2013608\nmobile IP commonalities to,  \n608\n2G standards, 581\u2013582\nGMSC. See Gateway Mobile services \nSwitching Center\nGo-Back-N (GBN) protocol,  \n249\u2013254\nevents, 252\nTCP as, 280\nGoogle, 39, 92, 313\nCDNs, 184\ndata centers, 179\nnetwork infrastructure, 179\nprivate network, 62, 93, 403\nSDN use by, 403, 441, 444\nweb-based e-mail, 154\nGoogle Application Engine, 93\nGoogle Chrome browser, 186\nQUIC protocol, 230, 231, 313\nGoogle Chromium, 313\nGoogle Talk, 703, 708, 727\nGPRS. See Generalized Packet Radio \nService\ngraph, 405\ngraph algorithms, 407\nGSM. See Global System for Mobile \nCommunications\nguaranteed delivery, 339\nguaranteed delivery with bounded \ndelay, 339\nguaranteed minimal bandwidth, \n339\u2013340\nguided media, 47\nH\nH.263, 728\nHandley, Mark, 617handoff\nin 802.11 subnets, 574\u2013575\nin GSM, 605\u2013608\nin wireless networks, 552\nhandshaking, 121\nSSL, 661, 664\u2013665\nTCP three-way, 130, 193, 262, \n284\u2013285,", "doc_id": "339c99a9-4348-48ee-a9c3-8483b58fd861", "embedding": null, "doc_hash": "83efb1d8c73c3f2c406ee30ee46de58f3a734611e78ee1fe9b71727278eb997e", "extra_info": null, "node_info": {"start": 2413434, "end": 2416203}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "927d4969-d577-49f4-b605-b6ba3b3a738f", "3": "43781ed3-561a-494e-911a-81755c7fe564"}}, "__type__": "1"}, "43781ed3-561a-494e-911a-81755c7fe564": {"__data__": {"text": "231, 313\nGoogle Chromium, 313\nGoogle Talk, 703, 708, 727\nGPRS. See Generalized Packet Radio \nService\ngraph, 405\ngraph algorithms, 407\nGSM. See Global System for Mobile \nCommunications\nguaranteed delivery, 339\nguaranteed delivery with bounded \ndelay, 339\nguaranteed minimal bandwidth, \n339\u2013340\nguided media, 47\nH\nH.263, 728\nHandley, Mark, 617handoff\nin 802.11 subnets, 574\u2013575\nin GSM, 605\u2013608\nin wireless networks, 552\nhandshaking, 121\nSSL, 661, 664\u2013665\nTCP three-way, 130, 193, 262, \n284\u2013285, 532\nhard guarantees, 738\nhash functions\nchecksums and, 639\u2013640\ncryptographic, 639\u2013641\ndigital signatures using, 644\nMD5, 640, 642\nSHA-1, 641\nHDLC. See high-level data link con -\ntrol\nheader length field, 264\nheader lines, 132, 134\nheaders\nIPv4, 359\u2013360\nMIME, 658\nMPLS, 520\u2013521\nRTP, 730\nWeb browsers and, 135\u2013136\nhead-of-the-line blocking (HOL \nblocking), 350\nHELLO message, 422\nHFC. See hybrid fiber coax\nhidden terminal problem, 556,  \n568\u2013570\nhierarchical architectures\nwithin ASs, 422\u2013423\nin data center networks, 525\u2013526\nDNS distributed database, 158\u2013162\nSkype peers, 726\nhigh bit rate, 704\nhigh-level data link control (HDLC), \n479\nHLR. See home location register\nHMAC, 642\nINDEX      827\nHOL blocking. See head-of-the-line \nblocking\nhome agent, 590\ndiscovery, 598, 599\u2013600\nindirect routing and, 593\u2013594\nregistration with, 600\u2013601, 602\nhome location register (HLR), 603\ncall routing and, 604\u2013605\nhome MSC, 603\nhome network, 590, 603\nhome public land mobile network \n(home PMLN), 603\nHome Subscriber Service (HSS), 587\nhop limit, 379\nhost addresses, obtaining with DHCP, \n370\u2013373\nhost aliasing, 156, 164\nhostname, 154\u2013155\nalias, 156, 164\nin DNS queries, 160\u2013161\nin DNS resource records,  \n163\u2013165\nDNS services and, 155\u2013156\nhosts, 30, 37, 39\ndata center, 523\nwireless, 548\nHotmail, 154\nhot potato routing, 428\u2013429\nHSPA (High Speed Packet Access), \n585\nHSS. See Home Subscriber Service\nHTML, development of, 91\nHTML file, 126\nHTTP. See HyperText Transfer \nProtocol\nHTTP byte-range header, 715\nHTTP GET message, 532\nHTTP protocol, 78, 91\nHTTP request, 530\nHTTP response message, 533\nHTTP streaming, 176\u2013177, 709adaptive, 709\nclient application buffer, 713\u2013714\nDASH, 176\u2013177, 183, 716\nearly termination, 715\u2013716\nprefetching video, 712\u2013713\nrepositioning video, 715\u2013716\nTCP buffer, 713\u2013714\nYouTube use of, 184\nhub, 503\nHughesNet, 44\nHulu, 707\nhybrid fiber coax (HFC), 42\u201343, 467\nhyperlinks, 130\nHyperText Transfer Protocol (HTTP), \n124\u2013125, 126\u2013128\ncookies, 136\u2013138\nICMP and, 447\nmessage format, 131\u2013136\nnon-persistent connections, 128\u2013\n131\npersistent connections, 128, 131\nports, 227\u2013228\nrequest message, 131\u2013133\nresponse message, 133\u2013136\nSMTP comparison with, 149\nI\nIANA, 377\niBGP. See internal BGP\nIBM, 89\nICANN. See Internet Corporation for \nAssigned Names and Numbers\nICMP. See Internet Control Message \nProtocol\nICMP messages, 167\nIDEA, 658\nIDSs. See intrusion detection systems\nIEEE 802.1Q,", "doc_id": "43781ed3-561a-494e-911a-81755c7fe564", "embedding": null, "doc_hash": "0e8f4a70846e70fb6952fc85de8243271abbdf2d10075f4d687ac2c05726144e", "extra_info": null, "node_info": {"start": 2416164, "end": 2419052}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "339c99a9-4348-48ee-a9c3-8483b58fd861", "3": "f52ac61d-f89d-4889-90e3-b48e8897e78d"}}, "__type__": "1"}, "f52ac61d-f89d-4889-90e3-b48e8897e78d": {"__data__": {"text": "130\nHyperText Transfer Protocol (HTTP), \n124\u2013125, 126\u2013128\ncookies, 136\u2013138\nICMP and, 447\nmessage format, 131\u2013136\nnon-persistent connections, 128\u2013\n131\npersistent connections, 128, 131\nports, 227\u2013228\nrequest message, 131\u2013133\nresponse message, 133\u2013136\nSMTP comparison with, 149\nI\nIANA, 377\niBGP. See internal BGP\nIBM, 89\nICANN. See Internet Corporation for \nAssigned Names and Numbers\nICMP. See Internet Control Message \nProtocol\nICMP messages, 167\nIDEA, 658\nIDSs. See intrusion detection systems\nIEEE 802.1Q, 517, 519\nIEEE 802.3 (Ethernet), 507\nIEEE 802.3z (Gigabit Ethernet), 507\nIEEE 802.5, 493\n828     INDEX\nIEEE 802.11, 45, 548\naccess points, 561\u2013562\nadapters, 561, 565\nad hoc networks, 562\narchitecture, 561\u2013565\nauthentication, 564\u2013565\nbasic service set, 561, 572,  \n574\u2013575\nchannels and association,  \n562\u2013565\ncollision detection, 565\u2013566\nCRCs, 566, 571\nframe transmission, 566\nfrequency ranges, 560\nhandoff in subnets, 574\u2013575\nhidden terminals and, 568\u2013570\nMAC addresses in, 497\nMAC protocol, 565\u2013570\nmobility on same IP subnet, \n574\u2013575\nas point-to-point link, 570\npower management, 576\npublic access, 92, 551\nrate adaptation, 575\u2013576\nRTS/CTS control frames, 568\u2013570\nstandards, 560\nIEEE 802.11ac, 560\nIEEE 802.11b, interference from other \ndevices, 553\nIEEE 802.11 frames, 570\naddress fields, 571\u2013573\nMAC addresses in, 571\u2013573\npayload and CRC fields, 571\nsequence number, duration, and \nframe control fields, 573\nIEEE 802.11g, 560\nIEEE 802.11i, 676\u2013678\nIEEE 802.11n, 560\nIEEE 802.15.1, 577\u2013578\nIEEE 802.15.4, 578\u2013579\nIEEE 802.16, 588IEEE 802 LAN/MAN Standards \nCommittee, 33\nIETF. See Internet Engineering  \nTask Force\nIETF Mobile Ad Hoc Network  \nworking group, 590\nIKE. See Internet Key Exchange\nIKE SA, 673\nIMAP. See Internet Mail Access \nProtocol\nindirect routing, 593\u2013596, 599\ninformation propagation, 331\ninfrastructure mode, 550\ninfrastructure wireless LANs, 562\nInitialization Vector (IV), 631, 664, \n676\u2013677\nin-order packet delivery, 339\ninput port, 342\ninput port processing, 344\u2013347\nforwarding tables in, 345\u2013346\ninput queuing, 350\ninstantaneous throughput, 72\nintegrity checks, 669\nIntel, 506\nIntel 710 adapter, 471\nintelligent software agents, 108\ninter-area routing, 422\u2013423\ninter-autonomous system routing pro -\ntocol, 423, 433\ninterconnection networks, 523\nrouting algorithms in, 527\nswitching via, 348\u2013349\ninterface, 363\nAPI, 117\nNIC, 471\nSDN controller, 438\u2013439\nsocket, 34, 117\ninterference, 553\ninterleaving, 722, 724\ninternal BGP (iBGP), 425\u2013426\ninternal router, 424\nINDEX      829\nInternational Organization for \nStandardization (ISO), 80\nInternational Telecommunication \nUnion (ITU), 648\nInternet. See also  access networks\nbest-effort service in, 340\nbroadband, 92\nCerf on, 399\u2013400\ncommercialization of, 91\ncomponents of, 30\u201333\nDNS and presence on, 434\u2013435\nenterprise access, 44\u201345\nhistory of, 87\u201393\nhome access, 41\u201344\nnetwork core, 49, 50\nnetwork edges, 37\u201339\nnetwork layer, 340\nobtaining presence on,  \n434\u2013435\nregistries,", "doc_id": "f52ac61d-f89d-4889-90e3-b48e8897e78d", "embedding": null, "doc_hash": "490f8364c4a19aee8c717e505ff5f95b4802db6c50c64f7997a345c405ebf988", "extra_info": null, "node_info": {"start": 2419036, "end": 2421989}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "43781ed3-561a-494e-911a-81755c7fe564", "3": "af926539-87f4-4a2f-93a3-9a2938695dbb"}}, "__type__": "1"}, "af926539-87f4-4a2f-93a3-9a2938695dbb": {"__data__": {"text": "722, 724\ninternal BGP (iBGP), 425\u2013426\ninternal router, 424\nINDEX      829\nInternational Organization for \nStandardization (ISO), 80\nInternational Telecommunication \nUnion (ITU), 648\nInternet. See also  access networks\nbest-effort service in, 340\nbroadband, 92\nCerf on, 399\u2013400\ncommercialization of, 91\ncomponents of, 30\u201333\nDNS and presence on, 434\u2013435\nenterprise access, 44\u201345\nhistory of, 87\u201393\nhome access, 41\u201344\nnetwork core, 49, 50\nnetwork edges, 37\u201339\nnetwork layer, 340\nobtaining presence on,  \n434\u2013435\nregistries, 369\nrouter self-synchronization, 411\nrouting algorithms used in, 407\nas service infrastructure, 33\u201334\nservices not provided by, 123\ntopology of, 514\ntransport layer, 219\u2013221\ntransport services provided by, \n121\u2013123\nInternet applications, transport  \nprotocols used by, 231\nInternet checksum, 476, 639\u2013640\nInternet Control Message Protocol \n(ICMP), 447\u2013449\nIPv6 and, 449\nmessage types, 448\npacket filtering and, 681\nInternet Corporation for Assigned \nNames and Numbers (ICANN), \n166, 369, 420\nInternet Engineering Task Force \n(IETF), 33, 376, 648, 764Internet Exchange Points (IXPs), \n61\u201362\nCDNs in, 178\nGoogle infrastructure at, 179, 184\nNetflix infrastructure at, 183\nInternet Key Exchange (IKE), 673\nInternet Mail Access Protocol \n(IMAP), 151, 153\u2013154\nInternet of Things (IoT), 39, 618\nInternet Protocol (IP), 33, 79, 399, \n545. See also  IPv4; IPv6\nbest-effort service, 716\u2013717\nICMP and, 447\nservice model, 220\nstack for, 78\ntotal annual traffic using, 32\ntransition to, 90\nInternet Real-Time Lab, 764\nInternet registrars, 434\nInternet Service Providers (ISPs), 32\u201333\naccess, 60\nbackbone, 432\nCDNs and, 178\nAS configurations, 420\nglobal transit, 60\nGoogle infrastructure at, 179, 184\nmulti-home, 61\nmulti-homed access, 432\nNetflix infrastructure at, 183\npeering agreements among,  \n432\u2013433\nPoP, 61\nrouting among, 423\u2013435\nInternet standards, 33\nInternet Systems Consortium, 373\nInternet telephony, 123, 708, 718\nInternet video, 175\u2013176\ninternetworking, 88\u201390\nintra-autonomous system routing, \n419\u2013423, 433\nSDN in, 444\n830     INDEX\nintra-domain routing, 531\u2013532\nintrusion detection systems (IDSs), \n376, 623, 687\u2013690\nintrusion prevention systems (IPSs), \n376, 687\nIntserv, 340\nIoT. See Internet of Things\nIP. See Internet Protocol\nIP addresses, 91, 118, 155\nbroadcast, 369, 371\nclasses of, 366\u2013367\nDHCP, 370\u2013373\nInternet presence and, 434\nIPv4, 362\u2013373\nIPv6, 377\nMAC addresses and, 497\nNAT and, 373\u2013375\nobtaining blocks of, 369\nSIP and, 732\u2013734\nsocket programming, 187\ntemporary, 370\nIP-anycast, 430\u2013431\nIP datagram, 529\nIP forwarding table, 530\nIP fragmentation\nIPv4, 360\u2013363\nIPv6, 379\niPhones, 46\nIPsec, 382, 645, 665, 666\u2013667\nAH and ESP, 668\ndatagram, 669\u2013672\nkey management, 673\npacket forms, 669\u2013670\nsecurity associations, 668\u2013669,  \n673\nIP spoofing, 86\u201387, 651\nIPSs. See intrusion prevention systems\nIP traffic, volume of, 32\nIPv4\naddressing, 362\u2013373\ndatagram format, 358\u2013360datagram fragmentation,  \n360\u2013363\ntransitioning to IPv6 from, ", "doc_id": "af926539-87f4-4a2f-93a3-9a2938695dbb", "embedding": null, "doc_hash": "0fdb5fd44b721f0c70a62ce09e763cf25066b84558f96fcc311e7d2037acdc14", "extra_info": null, "node_info": {"start": 2421985, "end": 2424950}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "f52ac61d-f89d-4889-90e3-b48e8897e78d", "3": "7fba8177-f74a-4a47-b92c-0e34316dd5f2"}}, "__type__": "1"}, "7fba8177-f74a-4a47-b92c-0e34316dd5f2": {"__data__": {"text": "430\u2013431\nIP datagram, 529\nIP forwarding table, 530\nIP fragmentation\nIPv4, 360\u2013363\nIPv6, 379\niPhones, 46\nIPsec, 382, 645, 665, 666\u2013667\nAH and ESP, 668\ndatagram, 669\u2013672\nkey management, 673\npacket forms, 669\u2013670\nsecurity associations, 668\u2013669,  \n673\nIP spoofing, 86\u201387, 651\nIPSs. See intrusion prevention systems\nIP traffic, volume of, 32\nIPv4\naddressing, 362\u2013373\ndatagram format, 358\u2013360datagram fragmentation,  \n360\u2013363\ntransitioning to IPv6 from,  \n380\u2013382\nIPv6, 376\nadoption of, 380\u2013381\ndatagram format, 377\u2013379\nICMP, 449\ntransitioning to, 380\u2013382\ntunneling, 380\u2013381\nIPX, 414, 498\nIS-IS, 420, 441, 532\nISO. See International Organization \nfor Standardization\nISO IDRP, 414\nISPs. See Internet Service Providers\niterative queries, 161\nITU. See International \nTelecommunication Union\nIV. See Initialization Vector\nIXPs. See Internet Exchange Points\nJ\njabbering adapters, 512\nJacobson, Van, 331\u2013332, 617\nJava, client-server programming with, \n187\nJet Propulsion Laboratory, 400\njitter\npacket, 718\u2013719\nremoving, for audio, 719\u2013722\nJuniper MX2020, 342\nJuniper Networks Contrail, 444\nK\nKahn, Robert, 399, 400, 544\nARPAnet development and,  \n88\u201390\nTCP/IP creation and, 262\nKankan, 184\u2013185, 703\nKarels, Mike, 331\nINDEX      831\nkeys, 625\nIPsec management of, 673\nSSL, 662\nKleinrock, Leonard, 88, 107\u2013109,  \n399, 544\nknown-plaintext attacks, 627\nL\nlabel-switched router, 521\nLam, Simon, 544\u2013546\nLampson, Butler, 386\nLAN. See local area network\nLAN address, 496\nLAN-on-motherboard configuration, \n471\nlayer 4 switching, 343\nlayer 5 switching, 343\nlayered architectures, 75\u201381\nencapsulation, 81\u201383\nlayers, 77\nleaky bucket policer, 744\u2013747\nleast-cost path, 406\nBellman-Ford equation for,  \n412\u2013413\nin LS algorithm, 408\u2013410\nLEO satellites. See low-earth orbiting \nsatellites\nLevel 3 Communications, 33\nCDN, 178\nLicklider, J. C. R., 88\nLimelight, 178\nline cards, 471\nforwarding tables in, 345\ninput and output ports, 342\nprocessing on, 348\nline speeds, queuing and,  \n349\u2013350\nlink access, 470\nlink capacity\nbuffer sizing and, 353\nnetwork congestion and, 291link failure\nDV algorithm and, 416\u2013418\nprecomputed failover paths for, \n522\nlink layer, 79\u201380, 468, 469\nbroadcast, 479\nimplementation locations, 471\u2013472\nIP datagram size and, 361\nnetwork as, 519\u2013522\nservices provided by, 470\u2013471\nlink-layer acknowledgement, 565, 566, \n567\nlink-layer addressing, 496\u2013502\nlink-layer frame, 82, 468\nlink-layer switches, 32, 51, 341, \n509\u2013515\ndestination address lookup in, 346\nforwarding and filtering, 509\u2013510\nproperties of, 512\nself-learning, 511\u2013512\nlinks, 468\nwireless, 549\nlink-scheduling discipline, 744\nlink-state algorithms (LS algorithms), \n406, 407\u2013411, 414\ncentralized routing algorithm, 408\ncomputational complexity of, 410\nDV compared with, 418\u2013419\nforwarding tables, 409\u2013410\nmessage complexity, 418\u2013419\noscillations in, 410\u2013411\nOSPF, 420\nrobustness, 419\nspeed of convergence, 419\nsteps of,", "doc_id": "7fba8177-f74a-4a47-b92c-0e34316dd5f2", "embedding": null, "doc_hash": "a0aa948e266fff2e3f3fd5a876f360a32ced543c3b4653221bfd3a9405fe6124", "extra_info": null, "node_info": {"start": 2425012, "end": 2427888}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "af926539-87f4-4a2f-93a3-9a2938695dbb", "3": "81065987-5c95-4b2f-bae2-09a8f0c0b450"}}, "__type__": "1"}, "81065987-5c95-4b2f-bae2-09a8f0c0b450": {"__data__": {"text": "82, 468\nlink-layer switches, 32, 51, 341, \n509\u2013515\ndestination address lookup in, 346\nforwarding and filtering, 509\u2013510\nproperties of, 512\nself-learning, 511\u2013512\nlinks, 468\nwireless, 549\nlink-scheduling discipline, 744\nlink-state algorithms (LS algorithms), \n406, 407\u2013411, 414\ncentralized routing algorithm, 408\ncomputational complexity of, 410\nDV compared with, 418\u2013419\nforwarding tables, 409\u2013410\nmessage complexity, 418\u2013419\noscillations in, 410\u2013411\nOSPF, 420\nrobustness, 419\nspeed of convergence, 419\nsteps of, 408\u2013409\nlink-state broadcast, 407\nerroneous, 419\nlink virtualization, 519\u2013522\nlink weights, in OSPF, 421\nlive streaming, 709\nload balancers, 382, 524\u2013525\n832     INDEX\nload distribution, 156\nload-insensitive algorithms, 407\nload-sensitive algorithm, 407\nlocal area network (LAN), 44\u201345. See \nalso virtual local area networks; \nwireless LANs\nsniffing, 513\nswitched, 495\u2013519\nlocal DNS server, 160\nlocal preference, 429\nlogical communication, 216\nlogically centralized control, 402\u2013403, \n404, 465\nlogically centralized routing controllers, \n338\nlongest prefix matching rule, 345, 367\nLong-Term Evolution (LTE), 46, 580, \n581\nnetwork architecture, 585\u2013588\ntime slots in, 587\u2013588\nlookup algorithms, 346\nloss anticipation schemes, 722\u2013725\nloss recovery schemes\nerror concealment, 724\u2013725\nFEC, 722\u2013723\ninterleaving, 724\nloss-tolerant applications, 119, 708\nlossy channels, 242\u2013245\nLoST, 764\nlost segments, 299\nlow-earth orbiting (LEO) satellites, 49\nLS algorithms. See link-state algo -\nrithms\nLTE. See Long-Term Evolution\nLTE-Advanced, 588\nM\nMAC. See message authentication \ncode\nMAC addresses\nARP and, 499\u2013500in beacon frames, 563\nbroadcast address, 498, 500\n802.11 access points, 561, 563\n802.11 frames, 571\u2013573\nnetwork adapters, 496\u2013498\nwireless LAN authentication by, \n564\nMAC protocol. See medium access \ncontrol protocol\nmailbox, 144\nmail servers, 144\u2013145\naliasing, 156\nmalware, 83\u201384\nself-replicating, 84\nmanaged device, 450\nmanaged objects, 450\nManagement Information Base (MIB), \n450, 452\nmanaging server, 450\nMANETs. See mobile ad hoc net -\nworks\nmanifest file, 177\nMAP message, 493\nMaster Key, 677\nMaster Secret (MS), 664\nmatch-plus-action, 346\nforwarding table, 384\nin generalized forwarding,  \n382\u2013383\nOpenFlow, 386\u2013389\nmatch-plus-action flow tables,  \n443\nmaximum segment size (MSS), 263, \n307\nnegotiating, 264\nmaximum transmission unit (MTU), \n263, 361\nMD4, 641\nMD5 authentication, 422\nMD5 hash algorithm, 640, 642\nMDCs. See modular data centers\nINDEX      833\nmedium access control protocol \n(MAC protocol), 470\n802.11, 565\u2013570\nEthernet, 507\nmedium access protocol, 467\nmemory\naccess times, 346\nbandwidth of, 347\nswitching via, 347\u2013348\nmesh networks, wireless, 552\nmessage authentication code (MAC), \n641\u2013642\ndigital signatures and, 644\u2013645\nIPsec datagrams, 670\nin SSL, 662\u2013663\nmessage integrity, 622\u2013623, 638, 655, \n656\nmessage queue, 145\nmessages, 51, 78, 116\napplication-layer, 82\nARP, 499\u2013501, 531\ncomplexity in LS algorithms, \n418\u2013419\nDHCP, 371\u2013372,", "doc_id": "81065987-5c95-4b2f-bae2-09a8f0c0b450", "embedding": null, "doc_hash": "933ea923fb8f4900c307bbc510066734f80cb7c52617a9152e5a6d83e00bedde", "extra_info": null, "node_info": {"start": 2427825, "end": 2430802}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "7fba8177-f74a-4a47-b92c-0e34316dd5f2", "3": "8162c312-1a45-440d-9b4d-ab6f53d3fe3a"}}, "__type__": "1"}, "8162c312-1a45-440d-9b4d-ab6f53d3fe3a": {"__data__": {"text": "  833\nmedium access control protocol \n(MAC protocol), 470\n802.11, 565\u2013570\nEthernet, 507\nmedium access protocol, 467\nmemory\naccess times, 346\nbandwidth of, 347\nswitching via, 347\u2013348\nmesh networks, wireless, 552\nmessage authentication code (MAC), \n641\u2013642\ndigital signatures and, 644\u2013645\nIPsec datagrams, 670\nin SSL, 662\u2013663\nmessage integrity, 622\u2013623, 638, 655, \n656\nmessage queue, 145\nmessages, 51, 78, 116\napplication-layer, 82\nARP, 499\u2013501, 531\ncomplexity in LS algorithms, \n418\u2013419\nDHCP, 371\u2013372, 529\u2013530\nDNS, 164\u2013166, 531\u2013532\ne-mail formats, 149\u2013150\nHELLO, 422\nHTTP format, 131\u2013136\nICMP ping, 167\nintruder actions on, 624\nOpenFlow, 443\nport-status, 443\nSIP, 734\nsource quench, 447\u2013448\nMetcalfe, Bob, 488, 503, 506\nmetering function, 750\nMIB. See Management Information \nBase\nMicrosoft, 92\nprivate network, 93\nMicrosoft Research, 403middleboxes, 375, 382\nMIME headers, 658\nMIMO. See multiple input  \nmultiple-output\nMinitel, 91\nMME. See Mobility Management \nEntity\nmobile ad hoc networks (MANETs), \n552\u2013553, 590\nmobile IP, 598\u2013602\nagent discovery, 599\u2013600\nGSM commonalities to, 608\nregistration with home agent, \n600\u2013601, 602\nmobile nodes\naddressing, 590\u2013592\nDHCP and, 372\ndirect routing to, 596\u2013597\nin foreign networks, 591\u2013592\nindirect routing to, 593\u2013596\nrouting to, 592\u2013597\nmobile station roaming number \n(MSRN), 604\nmobile switching center (MSC), 582, \n584, 603\nanchor, 607\nhandoffs and, 606\u2013608\nmobile-user location protocol, 596\nmobility, 547\u2013548, 618\naddressing and, 590\u2013592\ncellular network management of, \n602\u2013610\ndegrees of, 588\u2013589\nhandoff and, 552\nhigher-layer protocols and, 608\u2013\n610\nmanagement, 588\u2013597\nnode address and, 589\non same IP subnet, 574\u2013575\nwithin VLANs, 576\nwired infrastructure and, 590\n834     INDEX\nMobility Management Entity (MME), \n587\nmodify-field action, 386\nmodular data centers (MDCs),  \n526\u2013527\nmodulation techniques\ndynamic selection of, 555\u2013556\nPCM, 706, 728\nSNR and BER for, 554\u2013556\nmonoalphabetic cipher, 625\nMosaic Communications, 91\nMOSPF. See multicast OSPF\nMP3. See MPEG 1 layer 3\nMPEG, 728\nMPEG 1 layer 3 (MP3), 706, 728\nMPLS. See Multiprotocol Label \nSwitching\nMPLS-enhanced forwarding, 521\nMS. See Master Secret\nMSC. See mobile switching center\nMSRN. See mobile station roaming \nnumber\nMSS. See maximum segment size\nMTU. See maximum transmission \nunit\nmulticast OSPF (MOSPF), 422\nmulticast routing, 617\nin OSPF, 422\nmulti-home, 61\nmulti-homed access ISP, 432\nmulti-hop, infrastructure-based wire -\nless networks, 552\nmulti-hop, infrastructure-less wireless \nnetworks, 552\u2013553\nmultihop path, 293\u2013295\nmulti-hop wireless networks, point-to-\npoint 802.11 links in, 570\nmultimedia applications, 765\naudio properties, 705\u2013707\nconversational voice and video \nover IP, 708\u2013709network support for, 737\u2013754\nstreaming live audio and video, \n709\nstreaming stored audio and video, \n707\u2013708\nTCP use by, 230\ntypes of, 707\u2013709\nUDP use by, 230\u2013231\nvideo properties, 704\u2013705\nmultipath propagation, 553\nmultiple access", "doc_id": "8162c312-1a45-440d-9b4d-ab6f53d3fe3a", "embedding": null, "doc_hash": "e7db0b32ed8cf18840e678bf800fe2134ccad32b1eb7f42137c95eb501f58b88", "extra_info": null, "node_info": {"start": 2430819, "end": 2433770}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "81065987-5c95-4b2f-bae2-09a8f0c0b450", "3": "0f8ecf36-8108-47ab-b5bb-63d30725710c"}}, "__type__": "1"}, "0f8ecf36-8108-47ab-b5bb-63d30725710c": {"__data__": {"text": "432\nmulti-hop, infrastructure-based wire -\nless networks, 552\nmulti-hop, infrastructure-less wireless \nnetworks, 552\u2013553\nmultihop path, 293\u2013295\nmulti-hop wireless networks, point-to-\npoint 802.11 links in, 570\nmultimedia applications, 765\naudio properties, 705\u2013707\nconversational voice and video \nover IP, 708\u2013709network support for, 737\u2013754\nstreaming live audio and video, \n709\nstreaming stored audio and video, \n707\u2013708\nTCP use by, 230\ntypes of, 707\u2013709\nUDP use by, 230\u2013231\nvideo properties, 704\u2013705\nmultipath propagation, 553\nmultiple access channels, 479, 480\nmultiple access problem, 479\nmultiple access protocols, 480\u2013481, \n565\nmultiple input multiple-output (MIMO), \n560\nmultiple same-cost paths, in OSPF, \n422\nmultiple versions, 705\nmultiplexing, 221\u2013228\nconnectionless, 223\u2013224\nconnection-oriented, 224\u2013227\ntransport-layer, 220\nMultiprotocol Label Switching \n(MPLS), 519, 520\u2013522\nMX records, 156, 164\nN\nNAK (negative acknowledgments), \n238\u2013242, 476\ncorrupted, 240\nNAT. See network address translation; \nnetwork address translator\nNational Physical Laboratory, 88\nNAT translation table, 374\nNAT traversal, 375\nNCP. See network-control protocol\nNCS. See network control server\nnegative acknowledgments, 238\nneighbor, 405\nneighboring peers, 173\u2013174\nINDEX      835\nNelson, Ted, 91\nNetflix, 175, 703, 707\nCDNs, 182\u2013184\nnetnews, 701\nNetscape Communications, 91\u201392, 212, \n659\nnetwork adapters, 471, 472\nARP query and, 500\nCSMA/CD operation and, 490\u2013491\ndatagram transmission and, 499, \n501\u2013502\n802.11, 561, 565\nerror detection in, 476\nEthernet frames and, 504\u2013506\njabbering, 512\nLAN-on-motherboard configuration, \n471\nlayer independence and, 498\nMAC address assignment, 496\u2013498\nMAC addresses, 496\u2013498\non separate cards, 471\nnetwork address translation (NAT), \n373\u2013375, 382\nSkype traversal of, 725\u2013727\nnetwork address translator (NAT), 346\nnetwork applications, 111\narchitectures, 114\u2013116\ncommunication for, 113\nprinciples of, 112\u2013125\nproprietary, 186\nservice requirements, 121\nstandards-based, 186\ntransport services available to, \n118\u2013121\nnetwork-assisted congestion control, \n296, 297\nnetwork control functions, in SDN, \n436\nnetwork-control protocol (NCP), 88, \n90\nnetwork control server (NCS), 441network core, 49\u201350\ncircuit switching, 55\u201359\n4G networks, 585\u2013587\nnetwork of networks, 59\u201362\npacket switching, 50\u201354, 58\u201359\n3G networks, 584\nnetwork dimensioning, 737, 739\u2013740\nnetwork functions virtualization (NFV), \n444\nNetwork Information Base (NIB), 441\nnetwork infrastructure, wireless net -\nworks and, 550\u2013553\nnetwork interface card (NIC), 471\nnetwork layer, 51. See also  control \nplane; data plane\nbest-effort service, 340\nforwarding and routing, 334\u2013339\nsecurity, 340, 665\u2013673\nservices, 339\u2013340\ntransport layer relationship to, \n216\u2013219\nnetwork-layer datagram, 82\nnetwork management, 449\u2013454\ndefining, 449\nframework for, 450\u2013451\nintruder interference with, 624\nlink-layer switching and, 512\nnetwork management agent, 450\u2013451\nnetwork management protocol, 451\nnetwork of networks, 59\u201362, 90\nnetwork operations center (NOC), 450\nnetwork protocols, 36\u201337\nnetworks. See also  access networks; \ncellular networks; Internet; local \narea network; wireless networks\nad hoc, 562\nattacks against, 83\u201387\nCDNs, 142,", "doc_id": "0f8ecf36-8108-47ab-b5bb-63d30725710c", "embedding": null, "doc_hash": "f53598148ef339a59341dca8a7e045d37c35448c97d3aa10e42560ded45960b8", "extra_info": null, "node_info": {"start": 2433730, "end": 2436942}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "8162c312-1a45-440d-9b4d-ab6f53d3fe3a", "3": "c728acca-bafd-4e75-aa12-538e0f4b6b4a"}}, "__type__": "1"}, "c728acca-bafd-4e75-aa12-538e0f4b6b4a": {"__data__": {"text": "and routing, 334\u2013339\nsecurity, 340, 665\u2013673\nservices, 339\u2013340\ntransport layer relationship to, \n216\u2013219\nnetwork-layer datagram, 82\nnetwork management, 449\u2013454\ndefining, 449\nframework for, 450\u2013451\nintruder interference with, 624\nlink-layer switching and, 512\nnetwork management agent, 450\u2013451\nnetwork management protocol, 451\nnetwork of networks, 59\u201362, 90\nnetwork operations center (NOC), 450\nnetwork protocols, 36\u201337\nnetworks. See also  access networks; \ncellular networks; Internet; local \narea network; wireless networks\nad hoc, 562\nattacks against, 83\u201387\nCDNs, 142, 177\u2013185\ncellular, 46, 551, 556, 579\u2013588, \n602\u2013610\ncontent provider, 62\n836     INDEX\nnetworks. (continued)\ndata center, 523\u2013528\nedges, 37\u201339, 592\nforeign, 590\u2013592\nhome, 590, 603\nhome PMLN, 603\nmobile ad hoc, 552\u2013553, 590\nmultimedia application support, \n737\u2013754\nmultimedia support, 737\u2013754\npacket-radio, 89\npacket-satellite, 88\npersonal area, 576\u2013579\nPMLN, 603\nprivate, 62, 93, 373, 403, 666\nprogrammable, 436\nproliferation of, 90\u201391\nproprietary, 88\u201390\nprovider, 432\nradio access, 584\u2013585, 587\u2013588\ntelephone, 519\nthroughput in, 71\u201374\ntopology of switched, 514\nvirtual-circuit, 520\nvisited, 590, 603\nVLANs, 515\u2013519, 525, 576\nVPNs, 522, 576, 665\u2013667\nwireless mesh, 552\nWPANs, 577\u2013578\nnetwork security, 622\u2013624\nnetwork-service applications, 444\nnetwork service model, 339\u2013340\nNeVoT, 764\nNEXT-HOP, 427\u2013428, 429\nNFV. See network functions virtual -\nization\nNIB. See Network Information Base\nNIC. See network interface card\nNIST, 380, 630\nnmap, 226, 289\nNOC. See network operations centernodal delay, 64\nnodal processing delay, 63\nnodes, 468\nnomadic computing, 108\nnon-blocking switches, 348\nnonce, 653, 676\nnon-persistent connections, 128\u2013131\nnon-preemptive priority queuing, 355\nNovell IPX, 414\nNOX controller, 440, 444\nNSFNET, 90, 91\nnslookup program, 166\nNS records, 164\nNTT, 33\nO\nobject, 126\nOC. See Optical Carrier standard\nodd parity schemes, 474\nOFA. See Open Flow Agent\nOFC. See Open Flow Controller\nOFDM. See orthogonal frequency \ndivision multiplexing\noffered load, 292\nOLT. See optical line terminator\none-bit parity, 474\u2013475\nONIX SDN controller, 441\nONOS, 440, 444, 446\u2013447\nONT. See optical network terminator\nOpenDaylight, 440, 444\u2013445\nOpenDaylight Lithium, 444\nOpenFlow, 438, 440\u2013441, 442\u2013443\naction, 386\nflow table, 384\nmatch, 384\u2013386\nmatch-plus-action, 386\u2013389\nOpen Flow Agent (OFA), 441\nOpen Flow Controller (OFC), 441\nOpen Shortest Path First (OSPF), 402, \n407, 420\u2013423, 532\nauthentication in, 422\nINDEX      837\nbroadcast in, 421\u2013422\nDijkstra's algorithm, 420\nlink weights, 421\nmulticast, 422\nsecurity and, 422\nsubnets, 420\nOpen Systems Interconnection (OSI), \n80\noperational security, 623, 679\u2013690\nfirewalls, 679\u2013687\nIDSs, 376, 623, 687\u2013690\nopportunistic scheduling, 588\nOptical Carrier standard (OC), 48\noptical line terminator (OLT), 44\noptical network terminator (ONT), 43\noptimistically choked peers, 174\noptions field, 264\northogonal frequency division", "doc_id": "c728acca-bafd-4e75-aa12-538e0f4b6b4a", "embedding": null, "doc_hash": "fe9dac33ba79e7f7230a87f9e679d9c4e0a1e1092022ba0a5e430c1b70de6848", "extra_info": null, "node_info": {"start": 2436920, "end": 2439862}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "0f8ecf36-8108-47ab-b5bb-63d30725710c", "3": "61ec02b2-3b5d-44e8-940b-66c331737fd6"}}, "__type__": "1"}, "61ec02b2-3b5d-44e8-940b-66c331737fd6": {"__data__": {"text": "First (OSPF), 402, \n407, 420\u2013423, 532\nauthentication in, 422\nINDEX      837\nbroadcast in, 421\u2013422\nDijkstra's algorithm, 420\nlink weights, 421\nmulticast, 422\nsecurity and, 422\nsubnets, 420\nOpen Systems Interconnection (OSI), \n80\noperational security, 623, 679\u2013690\nfirewalls, 679\u2013687\nIDSs, 376, 623, 687\u2013690\nopportunistic scheduling, 588\nOptical Carrier standard (OC), 48\noptical line terminator (OLT), 44\noptical network terminator (ONT), 43\noptimistically choked peers, 174\noptions field, 264\northogonal frequency division \nmultiplexing (OFDM), 587\nOSI. See Open Systems \nInterconnection\nOSI reference model, 78, 80\u201381\nOSPF. See Open Shortest Path First\nout-of-order packets, 253\noutput buffer, 52\noutput port, 342\nforwarding to, 346\noutput port processing, 349\noutput queue, 52\noutput queueing, 351\u2013352\noutside-AS destinations, 428\nOVSDB, 445\nP\nP2P architecture, 114\u2013116, 545\nfile distribution, 168\u2013175\nscalability of, 169\u2013172\nSkype use of, 725\u2013727\nP2P live streaming, 175\nP2P streaming, 185\nP2P video streaming, 709packet classification, 748\nPacket Data Network Gateway (P-GW), \n586\npacket-dropping strategies, 352\npacket filtering, 680\u2013682, 689\npacket header overhead, 230\npacket headers\nMPLS, 520\u2013521\nrouting and, 336, 337\npacket jitter, 718\u2013719\npacket loss, 53, 69, 349\nerror concealment, 724\u2013725\nFEC for, 722\u2013723\ninterleaving for, 724\nrecovery from, 722\u2013725\nVoIP and, 717\u2013718\npacket marking, 742\npacket-marking strategies, 352\nPacket Radio, 544\npacket-radio networks, 89\npackets, 32, 51\nARP, 500\nchoke, 296\ncontrol, 342, 725\ndeep inspection of, 376, 382, 687\nduplicate, 240\nduplicate data, 244\nforwarding, 336\nin-order delivery of, 339\nIPsec forms, 669\u2013670\nout-of-order, 253\nprocessing, 514\nRTP, 729\nPacket Satellite, 544\npacket-satellite networks, 88\npacket scheduler, 353\npacket scheduling\nFIFO, 353\u2013354\npriority queuing, 354\u2013356\nround robin, 356\u2013357\nWFQ, 356\u2013357\n838     INDEX\npacket sniffer, 86, 105\npacket-switched networks, delays in, \n63\u201374\npacket switches, 32, 51, 341\npacket switching, 51\u201354, 55, 107\ncircuit switching versus , 58\u201359\ndevelopment of, 87\u201388\nstore-and-forward, 51\u201352\npaging, 582\npairwise communication, 331\nPairwise Master Key (PMK), 678\nparallel TCP connections, fairness \nand, 310\nparity bit, 474\nparity checks, 474\u2013476\npassive optical networks (PONs), \n43\u201344\npassive scanning, 564\npasswords, 651\u2013652\npath loss, 553\npaths, 32\nfailover, 522\nhigh-bandwidth, 306\u2013307\nleast-cost, 406, 408\u2013410, 412\u2013413\nmultihop, 293\u2013295\nmultiple same-cost, 422\nshortest, 406\nPaxos, 441\npayload field, 82\nin 802.11 frames, 571\nPCM. See pulse code modulation\nPDUs. See protocol data units\npeering agreements, 432\u2013433\npeers, 61, 114\u2013115\nBitTorrent, 172\u2013174\nneighboring, 173\u2013174\noptimistically choked, 174\nP2P streaming, 185\nrelay, 726\u2013727\nSkype, 726\u2013727\nunchoked,", "doc_id": "61ec02b2-3b5d-44e8-940b-66c331737fd6", "embedding": null, "doc_hash": "1659470567558368d8b5ece37f5fe09bb865cbe8634f2a9c386688669706b626", "extra_info": null, "node_info": {"start": 2439909, "end": 2442679}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "c728acca-bafd-4e75-aa12-538e0f4b6b4a", "3": "dec1c46e-99a7-4f01-827a-8815bbb6161b"}}, "__type__": "1"}, "dec1c46e-99a7-4f01-827a-8815bbb6161b": {"__data__": {"text": "651\u2013652\npath loss, 553\npaths, 32\nfailover, 522\nhigh-bandwidth, 306\u2013307\nleast-cost, 406, 408\u2013410, 412\u2013413\nmultihop, 293\u2013295\nmultiple same-cost, 422\nshortest, 406\nPaxos, 441\npayload field, 82\nin 802.11 frames, 571\nPCM. See pulse code modulation\nPDUs. See protocol data units\npeering agreements, 432\u2013433\npeers, 61, 114\u2013115\nBitTorrent, 172\u2013174\nneighboring, 173\u2013174\noptimistically choked, 174\nP2P streaming, 185\nrelay, 726\u2013727\nSkype, 726\u2013727\nunchoked, 174peer-to-peer applications, 168\u2013175\nper-connection throughput, 290\u2013291\nper-hop behavior (PHB), 748, 750\npermanent address, 592\nper-router control, 402, 403\npersistent connections, 128, 131\npersonal area networks, 576\u2013579\nPGP. See Pretty Good Privacy\nP-GW. See Packet Data Network \nGateway\nPHB. See per-hop behavior\nPhotobell, 107\nphysical address, 496\nphysical layer, 80\nphysical media, 46\u201349\ncoaxial cable, 48\nfiber optics, 48\nsatellite radio, 49\nterrestrial radio, 48\u201349\ntwisted-pair copper wire, 47\u201348\npiconet, 577\npiggybacked acknowledgments, 269\nping, 447\nping messages, 167\npipelined reliable data transfer proto -\ncols, 245, 247\u2013249\npipelining, 249\nTCP, 271\nPlain Old Telephone Service (POTS), \n725\nplaintext, 625, 627\nplayback attack, 652\nplayout delay\nadaptive, 720\u2013722\nfixed, 719\u2013720\nplug-and-play, 370, 512\nPMK. See Pairwise Master Key\nPMLN. See public land mobile net -\nwork\nPMS. See Pre-Master Secret\npoints of presence (PoPs), 61\nINDEX      839\npoint-to-point connections, 261\npoint-to-point link, 479\n802.11 as, 570\nPoint-to-Point Protocol (PPP), 468, \n479\nMTU, 263\npoisoned reverse, 418\npolling protocol, 492\npolls, 492\npolyalphabetic encryption, 627\u2013628\npolynomial codes, 477\nPONs. See passive optical networks\nPoPs. See points of presence\nport numbers, 118, 187\nNAT and, 373\u2013375\nsocket, 223\u2013224\nwell-known, 222\nport scanning, 226\nport-status message, 443\npositive acknowledgments, 238\nPost Office Protocol\u2014Version 3 \n(POP3), 151\u2013153\nPOTS. See Plain Old Telephone \nService\nPouzin, Louis, 89\npower management, 576\nPPLive, 175\nPPP. See Point-to-Point Protocol\nppstream, 175\nprefetching video, 712\u2013713\nprefix, 345, 346, 366, 367\nPre-Master Secret (PMS), 664\nPretty Good Privacy (PGP), 654, \n658\u2013659\nPrim's algorithm, 407\npriority queueing, 353, 354\u2013356\nnon-preemptive, 355\nprivacy, 686\nVoIP and, 727\nprivate CDNs, 178\nNetflix, 182\u2013184private key, 633\nprivate networks, 62, 93, 373,  \n403, 666\nprobe frames, 564\nprocesses\naddressing, 117\u2013118\nclient, 116\u2013117\ncommunicating, 116\u2013118\nnetwork interface, 117\nserver, 116\u2013117, 261\ntransport layer protocols connecting, \n216\nprocessing delay, 64\nprogrammable network, 436\npropagation delay, 63, 65\u201367\nproprietary networks, 88\u201390\nprotocol data units (PDUs), 452, 453\nprotocol layering, 77\u201378\nprotocols, 5. See also  specific protocols\ndefining, 35\u201337\nnetwork, 36\u201337\nrouting, 53\u201354\nprotocol stack, 78\nprovider, 60\nprovider networks, 432\nproxy server, 138,", "doc_id": "dec1c46e-99a7-4f01-827a-8815bbb6161b", "embedding": null, "doc_hash": "dadc54c7babfb9ef18178cab6e3e4194901d66efd3e360030c8c7747405ec1f2", "extra_info": null, "node_info": {"start": 2442739, "end": 2445597}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "61ec02b2-3b5d-44e8-940b-66c331737fd6", "3": "0dd26e67-4ee1-4277-bc36-73394f2daedd"}}, "__type__": "1"}, "0dd26e67-4ee1-4277-bc36-73394f2daedd": {"__data__": {"text": " \n403, 666\nprobe frames, 564\nprocesses\naddressing, 117\u2013118\nclient, 116\u2013117\ncommunicating, 116\u2013118\nnetwork interface, 117\nserver, 116\u2013117, 261\ntransport layer protocols connecting, \n216\nprocessing delay, 64\nprogrammable network, 436\npropagation delay, 63, 65\u201367\nproprietary networks, 88\u201390\nprotocol data units (PDUs), 452, 453\nprotocol layering, 77\u201378\nprotocols, 5. See also  specific protocols\ndefining, 35\u201337\nnetwork, 36\u201337\nrouting, 53\u201354\nprotocol stack, 78\nprovider, 60\nprovider networks, 432\nproxy server, 138, 686\nSIP, 735\nPSH bit, 265\npublic key, 633\ncertifying, 658\npublic key certification, 645\u2013648, \n658\u2013659\npublic key encryption, 625, 632\u2013638\nin PGP, 658\nin SSL, 664\npublic land mobile network (PMLN), \n603\npublic WiFi, 92, 551\npull protocol, 149\npulse code modulation (PCM),  \n706, 728\n840     INDEX\npure ALOHA protocol, 486\npush caching, 183\u2013184\npush protocol, 149\nPython, 186\nport numbers, 223\nTCP connections, 194\u2013197\nUDP connections, 189\u2013192, 223\nQ\nQ2931b protocol, 753\nQoS. See quality of service\nQQ, 708\nquality of service (QoS)\ncall admission, 752\nin 4G, 586\nper-connection guarantees, 738, \n751\u2013754\nresource reservation, 753\nRTP and, 729\ntraffic policing and, 745\nquantization, 706\nquery\nARP, 500, 531\nDNS chain, 161\u2013162\nDNS message, 531\nqueueing delays, 52\u201353, 63, 64, 67\u201369\nnetwork congestion and, 291\nqueuing\nFIFO, 353\u2013354\ninput, 350\nline speed and, 349\u2013350\nnon-preemptive priority, 355\noutput, 351\u2013352\npriority, 353, 354\u2013356\nround-robin, 353, 356\u2013357\nin routers, 349\u2013353\ntraffic load and, 350\ntransmission rate and, 349\u2013350\nWFQ, 356\u2013357\nwork-conserving, 355, 356\nQUIC protocol, 230, 231, 313R\nRA. See router agent\nradio access network\n4G, 587\u2013588\n3G, 584\u2013585\nRadio Network Controller (RNC), 584, \n586\nRADIUS, 565, 677\u2013678\nRand Institute, 88\nrandom access protocols, 481,  \n483\u2013492, 506, 565\nrandom backoff, 567\nRandom Early Detection (RED), 352\nrarest first, 174\nrate adaptation, 575\u2013576\nRC4 stream cipher, 675\nRCP. See Routing Control Platform\nrealm with private addresses, 373\nreal-time conversational applications. \nSee also  Voice-over-IP\nprotocols for, 728\u2013736\nRTP, 728\u2013731\nSIP, 731\u2013736, 765\nreal-time measurements, 181\nReal-Time Streaming Protocol (RTSP), \n711\nReal-Time Transport Protocol (RTP), \n711, 728\u2013730\naudio and video payload types, 731\npacket header fields, 730\nreassembly\nIPv4 datagram, 361\u2013362\nIPv6 datagram, 379\nreceive buffer, 281, 282\nreceiver\nin CRC operation, 477\nin parity bit operation, 474\u2013476\nreceiver authentication, 655\nreceiver feedback, 238\nreceive window, 264, 281, 282\nrecursive queries, 161\nINDEX      841\nRED. See Random Early Detection\nreduced-function devices, 578\nregional ISP, 60\u201361\nregistrar, 166, 434\nSIP, 735\nregistration\nwith home agent, 600\u2013602\nin mobile IP, 602\nregistries, 369\nrelay peers, 726\u2013727\nrelays, Skype, 726\u2013727\nreliable data transfer, 119,", "doc_id": "0dd26e67-4ee1-4277-bc36-73394f2daedd", "embedding": null, "doc_hash": "d7722ab71fba75cc87fd309442ef1696cf30fdeddc0b1f94e95c972e38932f89", "extra_info": null, "node_info": {"start": 2445540, "end": 2448357}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "dec1c46e-99a7-4f01-827a-8815bbb6161b", "3": "1d8c0a27-f8e3-41af-9bfa-ab8998d8a9d1"}}, "__type__": "1"}, "1d8c0a27-f8e3-41af-9bfa-ab8998d8a9d1": {"__data__": {"text": "361\u2013362\nIPv6 datagram, 379\nreceive buffer, 281, 282\nreceiver\nin CRC operation, 477\nin parity bit operation, 474\u2013476\nreceiver authentication, 655\nreceiver feedback, 238\nreceive window, 264, 281, 282\nrecursive queries, 161\nINDEX      841\nRED. See Random Early Detection\nreduced-function devices, 578\nregional ISP, 60\u201361\nregistrar, 166, 434\nSIP, 735\nregistration\nwith home agent, 600\u2013602\nin mobile IP, 602\nregistries, 369\nrelay peers, 726\u2013727\nrelays, Skype, 726\u2013727\nreliable data transfer, 119, 220,  \n259\u2013260\nover channel with bit errors, \n237\u2013242\nover lossy channel with bit errors, \n242\u2013245\nover perfectly reliable channel, \n236\u2013237\nprinciples of, 234\u2013260\nservice implementation for, 235, \n236\nservice model for, 234, 235\nTCP, 272\u2013379\nreliable data transfer protocol, 234\nbuilding, 236\u2013245\npipelined, 245, 247\u2013249\nreliable data transfer service, 272\nreliable delivery service, link-layer, \n470\nrepeater, 507\nrequest line, 132\nrequest messages, HTTP, 131\u2013133\nrequests for comments (RFCs), 33\nas protocol standards, 186\nRequest to Send (RTS), 568\u2013570\nresource records (RRs), 163\u2013164, 532\nresource reservation, 753\nresponse messages, HTTP, 133\u2013136\nresponse time, cloud service perfor -\nmance, 303retransmission, 238\ncongestion and, 292\u2013293\nCSMA/CA and, 567\nCSMA/CD and, 567\nduplicate packets from, 240\nfast, 277\u2013279\nin random access protocols, 483\nsequence numbers for handling, \n240\u2013241\nin slotted ALOHA, 484\nTCP timeout interval for,  \n270\u2013271\nTCP timer management for, \n272\u2013273\ntime-based, 244\u2013245\nRexford, Jennifer, 464\u2013466\nRFC 2616, 186\nRFCs. See requests for comments\nRIP, 407, 414, 532\nRivest, Ron, 633, 640\nRNC. See Radio Network Controller\nroaming number, 604\nRoberts, Lawrence, 88, 544\nrobustness, LS and DV algorithms, \n419\nroot DNS servers, 159, 162\nround-robin queuing, 353,  \n356\u2013357\nround-trip time (RTT), 130\nbuffer sizing and, 353\nTCP estimation for, 269\u2013271\nTCP variable tracking, 297\u2013298\nroute, 32\nBGP, 427\nBGP selection algorithm for, \n429\u2013430\nroute aggregation, 367\nroute information, advertising in BGP, \n424\u2013426\nrouter agent (RA), 402\nrouter discovery, 599\n842     INDEX\nrouters, 32, 51, 382\narchitecture of, 341\nborder, 422\u2013423, 523\nbuffer sizing, 353\ncomponents of, 341\u2013344\ncongestion and, 290\u2013295\ndata plane, 341\u2013357\ndestination-based forwarding, 343, \n344\u2013347\nedge, 342\nforwarding plane, 342\u2013343\nforwarding tables, 336, 337\ngateway, 424\ninput port processing, 344\u2013347\ninternal, 424\nlabel-switched, 521\nNAT-enabled, 373\u2013375\noutput port processing, 349\nper-router control, 402, 403\nqueuing in, 349\u2013353\nself-synchronization, 411\nswitches versus , 513\u2013515\nswitching fabric, 347\u2013349\nroute summarization, 367\nrouting, 336, 337\ncalls to mobile users, 604\u2013605\ndirect, to mobile nodes,  \n596\u2013597\nhot potato, 428\u2013429\nindirect, in mobile IP, 599\nindirect, to mobile nodes,  \n593\u2013596\ninter-area, 422\u2013423\nintra-ASs, 419\u2013423, 433, 444\nintra-domain, 531\u2013532\nintruder interference with, 624\namong ISPs, 423\u2013435\nlink", "doc_id": "1d8c0a27-f8e3-41af-9bfa-ab8998d8a9d1", "embedding": null, "doc_hash": "8ae90b72a6c426378f727ed8affcdeee0a1a6a5581dda7b032ede884af4f8364", "extra_info": null, "node_info": {"start": 2448386, "end": 2451309}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "0dd26e67-4ee1-4277-bc36-73394f2daedd", "3": "1bb99108-663a-4e18-bac5-38a3cabc49d6"}}, "__type__": "1"}, "1bb99108-663a-4e18-bac5-38a3cabc49d6": {"__data__": {"text": "port processing, 349\nper-router control, 402, 403\nqueuing in, 349\u2013353\nself-synchronization, 411\nswitches versus , 513\u2013515\nswitching fabric, 347\u2013349\nroute summarization, 367\nrouting, 336, 337\ncalls to mobile users, 604\u2013605\ndirect, to mobile nodes,  \n596\u2013597\nhot potato, 428\u2013429\nindirect, in mobile IP, 599\nindirect, to mobile nodes,  \n593\u2013596\ninter-area, 422\u2013423\nintra-ASs, 419\u2013423, 433, 444\nintra-domain, 531\u2013532\nintruder interference with, 624\namong ISPs, 423\u2013435\nlink weights in, 421\nlogically centralized, 338\nto mobile nodes, 592\u2013597\nmulticast, 422, 617routing algorithms, 336, 337, 404\u2013419\nARPAnet, 407, 414\ncentralized, 406\u2013408\nconvergence speed, 419\ndecentralized, 406\u2013407\ndistance-vector, 412\u2013419\ndynamic, 407\nin interconnection networks, 527\nlink-state, 407\u2013411\nload sensitivity, 407\nstatic, 407\nrouting controllers\nlogically centralized, 338\nSDN and, 339\nRouting Control Platform (RCP), 464\nrouting loop, 417\nrouting policy, BGP, 431\u2013434\nrouting processor, 342\nrouting protocols, 53\u201354\nrouting tables, 414\nBGP, 429\u2013430\nRRs. See resource records\nRSA algorithm, 633\u2013638, 658\nRST bit, 264\nRSVP protocol, 753\nRTP. See Real-Time Transport \nProtocol\nRTP header, 729\nRTP packet, 729\nRTP session, 729\nRTS. See Request to Send\nRTSP. See Real-Time Streaming  \nProtocol\nRTT. See round-trip time\nrwnd, 297\u2013298\nS\nSA. See security association\nSAD. See Security Association \nDatabase\nSAL. See Service Abstraction Layer\nINDEX      843\nSampleRTT, 270\nsatellite Internet access, 44, 467\nsatellite radio channels, 49\nScantlebury, Roger, 88\nscheduling algorithms, 588\nSchulzrinne, Henning, 728, 764\u2013766\nSCTP. See Stream Control \nTransmission Protocol\nSDN. See software-defined network -\ning\nSDN controller, 438\u2013440, 465\nsecure communication, 622\nsecure e-mail, 655\u2013658\nSecure Hash Algorithm (SHA-1), 641, \n642\nSecure Sockets Layer (SSL), 122, \n212, 544, 659\u2013665, 686\nconnection closure, 665\ndata transfer, 662\u2013663\nhandshake, 661, 664\u2013665\nkey derivation, 662\nsecurity, 701\u2013702\ndatagram inspection, 376\nDNS vulnerabilities, 167\ne-mail, 654\u2013659\nfirewalls, 376, 382, 623, 679\u2013687\nIDSs, 376, 623, 687\u2013690\nnetwork layer, 340, 665\u2013673\noperational, 412, 623, 679\u2013690\nOSPF and, 422\nswitch poisoning, 513\nSYN flood attacks, 288\ntransport protocol, 120\u2013121\nwireless LANs, 674\u2013678\nsecurity association (SA), 668\u2013669,  \n673\nSecurity Association Database (SAD),  \n669\nSecurity Parameter Index (SPI), 669\nSecurity Policy Database (SPD), 672\nsegment replay attack, 664segments, 79, 216, 219\nacknowledged, 299\nlost, 299\nmaximum size, 263, 264, 307\nTCP, 263\nTCP structure, 264\u2013269\nTCP SYN, 532, 681\ntransport-layer, 82\nUDP, 529\nUDP structure, 232\nselective acknowledgment, 280\nselective repeat (SR), 249, 254\u2013260\nevents and actions, 256\noperation of, 257\nTCP as, 280\nwindow size, 258, 259\nself-clocking, 298\nself-learning, 511\u2013512, 530\nself-replicating malware, 84\nself-scalability, 115\nself-synchronization, 411\nsend buffer,", "doc_id": "1bb99108-663a-4e18-bac5-38a3cabc49d6", "embedding": null, "doc_hash": "e81f3bfb5fd73c068fb8802c44883895e344d97d3e6e486bebb332a1d5c8eaeb", "extra_info": null, "node_info": {"start": 2451326, "end": 2454223}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "1d8c0a27-f8e3-41af-9bfa-ab8998d8a9d1", "3": "e59b878e-f355-48e6-91f5-0d915e8d511b"}}, "__type__": "1"}, "e59b878e-f355-48e6-91f5-0d915e8d511b": {"__data__": {"text": "672\nsegment replay attack, 664segments, 79, 216, 219\nacknowledged, 299\nlost, 299\nmaximum size, 263, 264, 307\nTCP, 263\nTCP structure, 264\u2013269\nTCP SYN, 532, 681\ntransport-layer, 82\nUDP, 529\nUDP structure, 232\nselective acknowledgment, 280\nselective repeat (SR), 249, 254\u2013260\nevents and actions, 256\noperation of, 257\nTCP as, 280\nwindow size, 258, 259\nself-clocking, 298\nself-learning, 511\u2013512, 530\nself-replicating malware, 84\nself-scalability, 115\nself-synchronization, 411\nsend buffer, 263\nsender authentication, 655, 656\nsenders\nin CRC operation, 477\u2013478\nin parity bit operation, 474\nsending rate, 292\nsequence number, 240\nin 802.11 frames, 573\nin GBN protocol, 249\u2013250\njitter control with, 719\nin pipelined protocols, 249\nretransmission handling with, \n240\u2013241\nRTP, 730\nin SR protocol, 255, 258\nin SSL MAC calculation, 663\nTCP, 265\u2013267\nfor TCP segment, 266\nTelnet and, 267\u2013269\nsequence number field, 264\n844     INDEX\nservers, 39, 114, 116\nauthoritative DNS, 160, 532\nDNS, 155, 159\u2013162, 160, 167\nDNS root, 159, 162\nenter-deep, 179\nlocal DNS, 160\nmail, 144\u2013145, 156\nmanaging, 450\nnetwork control, 441\nprocesses, 116\u2013117, 261\nproxy, 686, 735, 138\nTCP socket programming,  \n196\u2013198\nUDP socket programming,  \n191\u2013192\nuser interaction with via cookies, \n136\u2013138\nweb, 91, 127, 227\u2013228\nService Abstraction Layer (SAL), \n444\u2013445\nservice differentiation, 737, 747\u2013751\nService Level Agreements (SLAs), \n450\nservice model, 77\nIP, 220\nnetwork, 339\u2013340\nreliable data transfer, 234, 235\nservices\nDNS, 155\u2013157\nflow-control, 280\nfull-duplex, 261\nlayering, 77\nlink layer, 470\u2013471\nnetwork layer, 339\u2013340\nTCP, 220\ntransport layer, 118\u2013123\nUDP, 123\nunreliable, 220\nService Set Identifier (SSID), 562\nin beacon frames, 563\nServing Gateway (S-GW), 586Serving GPRS Support Nodes \n(SGSNs), 584\nSession Initiation Protocol (SIP), \n731\u2013736, 765\naddresses, 733\u2013734\ncall to known IP address, 732\u2013733\nmessages, 734\nname translation and user location, \n734\u2013736\nsession keys, 637, 655\nSGSNs. See Serving GPRS Support \nNodes\nS-GW. See Serving Gateway\nSHA-1. See Secure Hash Algorithm\nShamir, Adi, 633\nshared medium, 48\ndelays in, 71\nshipping containers, 526\u2013527\nshortest path, 406\nShort Inter-frame Spacing (SIFS), 566\nSIFS. See Short Inter-frame Spacing\nsignal strength, 553\nfading, 556\nsignal-to-noise ratio (SNR), 554\u2013556\nrate adaptation and, 575\nsignature-based systems, 689, 690\nsilent periods, 57\nsimple authentication, 422\nSimple Mail Transfer Protocol \n(SMTP), 78, 125, 144, 146\u2013148\nHTTP comparison with, 149\nmail access protocols and, 150\u2013151\nSimple Network Management \nProtocol (SNMP), 445, 452\u2013454\nsingle-hop, infrastructure-based wire -\nless networks, 552\nsingle-hop, infrastructure-less wireless \nnetworks, 552\nSIP. See Session Initiation Protocol\nSIP addresses, 733\u2013734\nSIP proxy, 735\nINDEX      845\nSIP registrar, 735\nSkype, 703, 708, 725\u2013728\naudio and video quality, 725\ncontrol", "doc_id": "e59b878e-f355-48e6-91f5-0d915e8d511b", "embedding": null, "doc_hash": "98af94630d34675dd249bb37ed4274053e65044f1ae077fe752edbab80e6ffd0", "extra_info": null, "node_info": {"start": 2454207, "end": 2457071}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "1bb99108-663a-4e18-bac5-38a3cabc49d6", "3": "89cd2518-f708-4678-afe6-cd0ef19b0462"}}, "__type__": "1"}, "89cd2518-f708-4678-afe6-cd0ef19b0462": {"__data__": {"text": "689, 690\nsilent periods, 57\nsimple authentication, 422\nSimple Mail Transfer Protocol \n(SMTP), 78, 125, 144, 146\u2013148\nHTTP comparison with, 149\nmail access protocols and, 150\u2013151\nSimple Network Management \nProtocol (SNMP), 445, 452\u2013454\nsingle-hop, infrastructure-based wire -\nless networks, 552\nsingle-hop, infrastructure-less wireless \nnetworks, 552\nSIP. See Session Initiation Protocol\nSIP addresses, 733\u2013734\nSIP proxy, 735\nINDEX      845\nSIP registrar, 735\nSkype, 703, 708, 725\u2013728\naudio and video quality, 725\ncontrol packets in, 725\nP2P techniques in, 725\u2013727\npeer hierarchy, 726\nrelay peers, 726\u2013727\nTCP use by, 725\nUDP use by, 123, 725\nSlammer worm, 226\nSLAs. See Service Level  \nAgreements\nsliding-window protocol, 250\nslotted ALOHA\nbackoff in, 544\ncollisions in, 484\nefficiency of, 485\u2013486\nretransmission in, 484\nslow start, 300\u2013301\nsmall office, home office (SOHO), \nsubnets, 373\nsmart phones, 618\nsmart spaces, 108\nSMI. See Structure of Management \nInformation\nSMTP. See Simple Mail Transfer \nProtocol\nSNA, 89\nsniffing, 86, 105, 513\nSNMP. See Simple Network \nManagement Protocol\nSnort, 690\nSNR. See signal-to-noise ratio\nsocial networks, 93\nsocket interface, 34, 117\nsocket programming, 185\u2013186\nclient-server architecture, 188\nIP addresses, 187\nport numbers, 187, 223\u2013224\nTCP, 192\u2013198\nUDP, 187\u2013192sockets, 221\nport numbers, 223\u2013224\nsimultaneous, 226\nTCP, 530, 532\nwelcoming, 225\nsoft guarantees, 738\nsoftware agents, 108\nsoftware-defined networking (SDN), \n334, 339, 464, 465, 618\narchitecture of, 436\ncontrol applications, 438\u2013440\ncontrol plane, 343, 435\u2013444\ndata plane, 436, 442\u2013443\nforwarding tables in, 342, 344\ngeneralized forwarding and, \n382\u2013389\nkey characteristics of, 435\u2013436\nlink state change in, 442\u2013443\nlogically centralized control in, \n402\u2013403\npacket forwarding and, 340\nrouting processor responsibilities \nin, 342\nSOHO. See small office, home  \noffice\nsource port number, 264\nsource port number field, 222\nsource quench message, 447\u2013448\nspanning trees, 514\nspatial redundancy, 705\nSPD. See Security Policy Database\nspectrum access rights, 551\nSPI. See Security Parameter Index\nsplit-connection approaches, 610\nSpotify, 704\nSprint, 33\nSR. See selective repeat\nSRI. See Stanford Research Institute\nSSID. See Service Set Identifier\nSSL. See Secure Sockets Layer\nSSL record, 663\n846     INDEX\nSSRC. See synchronization source \nidentifier\nssthresh, 301\u2013304\nStanford Research Institute (SRI), 88, \n107\nStarBand, 44\nstateful filters, 680, 682\u2013684\nstateless protocols, 128\nstate-management layer, SDN, 438\nstatic routing algorithms, 407\nstatus line, 134\nstop-and-wait protocols, 239, 247, 248\nstore-and-forward transmission,  \n51\u201352\nstream ciphers, 628, 675\nStream Control Transmission Protocol \n(SCTP), 313\nstreaming\nadaptive HTTP, 709\nCDNs and, 180\u2013181\nDASH, 176\u2013177, 183, 716\nHTTP, 176\u2013177, 709, 713\u2013716\nlive, 709\nlive video, 709\nNetflix platform, 182\u2013184\nP2P, 185\nP2P live, 175\nP2P video, 709\nprocessing for, 182\nRTSP, 711\nstored audio and video, 707\u2013708\nTCP buffers in, 713\u2013714\nUDP,", "doc_id": "89cd2518-f708-4678-afe6-cd0ef19b0462", "embedding": null, "doc_hash": "9d49d862aafe93968183146011b981b1a8bb9f8e683894718417908808ab5b88", "extra_info": null, "node_info": {"start": 2457050, "end": 2460053}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "e59b878e-f355-48e6-91f5-0d915e8d511b", "3": "41899c62-cda9-4b42-9b60-5247cd4b1991"}}, "__type__": "1"}, "41899c62-cda9-4b42-9b60-5247cd4b1991": {"__data__": {"text": "407\nstatus line, 134\nstop-and-wait protocols, 239, 247, 248\nstore-and-forward transmission,  \n51\u201352\nstream ciphers, 628, 675\nStream Control Transmission Protocol \n(SCTP), 313\nstreaming\nadaptive HTTP, 709\nCDNs and, 180\u2013181\nDASH, 176\u2013177, 183, 716\nHTTP, 176\u2013177, 709, 713\u2013716\nlive, 709\nlive video, 709\nNetflix platform, 182\u2013184\nP2P, 185\nP2P live, 175\nP2P video, 709\nprocessing for, 182\nRTSP, 711\nstored audio and video, 707\u2013708\nTCP buffers in, 713\u2013714\nUDP, 709, 711\nvideo, 175\u2013176, 180\u2013184\nstreetlamp wireless hotspots, 551\nStructure of Management Information \n(SMI), 450\nsubnet mask, 364\nsubnets, 363\u2013367\ndatagram transmission to, 501\u2013502\nmobility on, 574\u2013575obtaining blocks of IP addresses, \n369\nin OSPF, 420\nSOHO, 373\nsuccessful slot, 485\nsuper peers, 726\nSWAN, 403\nswitch, 503\nswitched networks, topology of, 514\nswitches\ncrossbar, 347\u2013349\nforwarding and filtering by,  \n509\u2013510\nlayer 4, 343\nlayer 5, 343\nlink-layer, 32, 51, 341, 346,  \n509\u2013515\nnon-blocking, 348\nplug-and-play, 512\nproperties of, 512\nrouters versus , 513\u2013515\nself-learning, 511\u2013512\ntop of rack, 523\nVLANs and, 516\nswitch filtering, 509\u2013510\nswitch forwarding, 509\u2013510\nswitching, 340\nin destination-based forwarding, \n346\ntechniques for, 347\u2013349\nswitching fabric, 342\nbus, 348\ncrossbar, 347\u2013349\ninterconnection network, 348\u2013349\nmemory, 347\u2013348\nqueuing and speed of, 349\u2013350\nswitch poisoning, 513\nswitch table, 509\npoisoning, 513\nsymmetric key cryptography, 626\u2013632\nblock ciphers, 628\u2013630\nINDEX      847\ncipher-block chaining,  \n630\u2013632\nnonce use with, 653\nin PGP, 658\npolyalphabetic encryption,  \n627\u2013628\nsecure e-mail using, 655\nin SSL handshake, 664\nSYNACK segment, 283, 287\nSYN bit, 265\nsynchronization source identifier \n(SSRC), 730\nSYN cookies, 288\nSYN flood attack, 288\nT\nTag Protocol Identifier (TPID),  \n517\ntaking-turns protocols, 481, 492\u2013493, \n565\nTCAMs. See Ternary Content \nAddressable Memories\nTCP. See Transmission Control \nProtocol\nTCP ACK bits, 681\u2013682\nTCP congestion-control algorithm, \n299\u2013304\nTCP connection, 121\nTCP-Friendly Rate Control (TFRC), \n313\u2013314\nTCP/IP, 33, 262\nTCP Reno, 304, 305\nTCP segments, 263\nTCP services, 121\u2013123\nTCP socket, 530, 532\nTCP splitting, 303\nTCP states, 285\u2013287\nTCP SYN segment, 532, 681\nTCP Tahoe, 304\nTCP Vegas, 305\nTDM. See time-division multiplexingtelco. See telephone company\nTelenet, 89\ntelephone company (telco), 41\ntelephone networks, 519\nTelnet, 148, 267\u2013269, 651,  \n684\u2013685\nTemporal Key (TK), 678\ntemporal redundancy, 705\ntemporary IP addresses, 370\nTernary Content Addressable \nMemories (TCAMs), 346\nterrestrial radio channels, 48\u201349\nTFRC. See TCP-Friendly Rate \nControl\n3rd Generation Partnership Project \n(3GPP), 583, 585\nThird Generation Partnership \nProgram, 381\nthird-party CDNs, 178\n3Com, 506\n3G, 46, 548, 551\ncore network, 584\nnetwork architecture,", "doc_id": "41899c62-cda9-4b42-9b60-5247cd4b1991", "embedding": null, "doc_hash": "87808f78aa53b9a4568d548d1e1757bb33df9e8634089b5c79827462fc3d63cd", "extra_info": null, "node_info": {"start": 2460108, "end": 2462892}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "89cd2518-f708-4678-afe6-cd0ef19b0462", "3": "3f240d93-fb2e-4eb0-a2a9-b0a3e43219a0"}}, "__type__": "1"}, "3f240d93-fb2e-4eb0-a2a9-b0a3e43219a0": {"__data__": {"text": "See telephone company\nTelenet, 89\ntelephone company (telco), 41\ntelephone networks, 519\nTelnet, 148, 267\u2013269, 651,  \n684\u2013685\nTemporal Key (TK), 678\ntemporal redundancy, 705\ntemporary IP addresses, 370\nTernary Content Addressable \nMemories (TCAMs), 346\nterrestrial radio channels, 48\u201349\nTFRC. See TCP-Friendly Rate \nControl\n3rd Generation Partnership Project \n(3GPP), 583, 585\nThird Generation Partnership \nProgram, 381\nthird-party CDNs, 178\n3Com, 506\n3G, 46, 548, 551\ncore network, 584\nnetwork architecture, 582\u2013585\nradio access network, 584\u2013585\nvideo over, 705\n3GPP. See 3rd Generation Partnership \nproject\nthree-way handshake, 130, 193, 262, \n284\u2013285, 532\nthroughput, 71\u201374, 119\u2013120\naverage, 72\ncongestion and, 290\u2013295\ninstantaneous, 72\nper-connection, 290\u2013291\nTCP, 306\nof transport layer, 119\u2013120\ntier-1 ISPs, 60\u201361\ntime-based retransmission, 244\u2013245\ntime-division multiplexing (TDM), \n56\u201358, 481\u2013485, 582, 584\ntime frames, 482\n848     INDEX\ntimeout events\nin GBN protocol, 252\nin SR protocol, 256\nTCP, 270\u2013271, 273, 274\ntimeout intervals\ndoubling, 275\u2013277\nTCP, 270\u2013271, 275\u2013277\ntime slots, 482\nin LTE, 587\u2013588\ntimestamps, 719, 730\ntime-to-live (TTL), 359\nTK. See Temporal Key\nTLD. See top-level domain\nTLS. See Transport Layer Security\ntoken, 493\ntoken-passing protocol, 493\ntoken ring protocol, 493, 503\nTomlinson, Ray, 88\ntop-down approach, 78\ntop-level domain (TLD), DNS servers, \n158, 159\nTop of Rack switch (TOR switch), \n523\nTOR, 686\ntorrents, 172\u2013174\nTOR switch. See Top of Rack  \nswitch\nTOS. See type of service\ntotal nodal delay, 63\nTPID. See Tag Protocol Identifier\nTraceroute, 70\u201371, 448\u2013449\ntrackers, 172\u2013174\ntraditional packet filters,  \n680\u2013682\ntraffic classes, 742\nisolating, 743\u2013744\ntraffic conditioning, 748\ntraffic engineering, 421\nMPLS and, 522\ntraffic intensity, 67\ntraffic isolation, 515\u2013516, 742traffic load\nbuffers and, 353\nqueuing and, 350\ntraffic policing, 743\nleaky bucket, 744\u2013747\ntraffic profiles, 749\u2013750\nTransmission Control Protocol (TCP), \n33, 219. See also  Secure \nSockets Layer\nACK bit, 681\u2013682\nACK generation recommendation, \n278\nacknowledgment number, 265\u2013267\nbuffers in streaming, 713\u2013714\nclosing connection, 284\u2013285\ncongestion avoidance, 301\u2013302\ncongestion-control algorithm, \n299\u2013304\ncongestion control in, 297\u2013311\ncongestion window, 298, 304\nconnection, 261\u2013264\nconnection management, 283\u2013287, \n289\nconnection requests, 225\ncumulative acknowledgement, 266\ndemultiplexing, 224\u2013227\ndevelopment of, 90\nestablishing connection, 283\u2013284\nfairness and, 307\u2013310\nfast recovery, 302\u2013304\nfast retransmit, 277\u2013279\nflow control, 280\u2013282\nfull-duplex service, 261\nhigh-bandwidth paths and, 306\u2013\n307\nInternet checksum in, 476\nmultimedia applications using, 230\nparallel browser connections, \n129\u2013130\nparallel connection fairness, 310\npipelining, 271\nINDEX      849\npoint-to-point connections, 261\nreceive window, 281, 282\nreliable data transfer, 272\u2013379\nretransmission timeout interval,", "doc_id": "3f240d93-fb2e-4eb0-a2a9-b0a3e43219a0", "embedding": null, "doc_hash": "b133c1872f5ef4e6cac21ba6cc8de76a4f15e1a69ddf93ce26eb755b0032467a", "extra_info": null, "node_info": {"start": 2462845, "end": 2465760}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "41899c62-cda9-4b42-9b60-5247cd4b1991", "3": "0910a13c-7672-46b9-a4b9-1ca0e40ce112"}}, "__type__": "1"}, "0910a13c-7672-46b9-a4b9-1ca0e40ce112": {"__data__": {"text": "acknowledgement, 266\ndemultiplexing, 224\u2013227\ndevelopment of, 90\nestablishing connection, 283\u2013284\nfairness and, 307\u2013310\nfast recovery, 302\u2013304\nfast retransmit, 277\u2013279\nflow control, 280\u2013282\nfull-duplex service, 261\nhigh-bandwidth paths and, 306\u2013\n307\nInternet checksum in, 476\nmultimedia applications using, 230\nparallel browser connections, \n129\u2013130\nparallel connection fairness, 310\npipelining, 271\nINDEX      849\npoint-to-point connections, 261\nreceive window, 281, 282\nreliable data transfer, 272\u2013379\nretransmission timeout interval, \n270\u2013271\nRTT estimation, 269\u2013271\nsecuring, 122\nsegment structure, 264\u2013269\nselective acknowledgment, 280\nself-clocking, 298\nsequence number, 265\u2013267\nservices provided by, 220\nsimultaneous connection sockets, \n226\nSkype use of, 725\nslow start, 300\u2013301\nSMTP using, 147\nsocket client, 194\u2013196\nsocket programming, 186,  \n192\u2013198\nsocket server, 196\u2013198\nsteady-state behavior of, 306\nthree-way handshake, 130, 193, \n262, 284\u2013285, 532\nthroughput, 306\ntimeout events, 270\u2013271, 273,  \n274\ntimeout intervals, 270\u2013271,  \n275\u2013277\ntimer management, 272\u2013273\ntransition to, 90\u201391\nvariables, 297\u2013298, 301, 304\nWeb servers and, 227\u2013228\nwireless networks and, 609\ntransmission delay, 63, 64\u201367\ntransmission power, 555\ntransmission rate, 32\nBER and, 555\nqueuing and, 349\u2013350\ntransparent, 509\ntransport layer, 79application services, 118\u2013121\nfragment reassembly and, 362\u2013363\nin Internet, 219\u2013221\nnetwork layer relationship to, \n216\u2013219\nreliable data transfer and, 119\nsecurity, 120\u2013121\nthroughput of, 119\u2013120\ntiming guarantees, 120\ntransport-layer multiplexing and \ndemultiplexing, 220\ntransport-layer protocols, 216\nTransport Layer Security (TLS), 659\ntransport-layer segment, 82\ntransport mode, 669\ntransport services\napplication availability of, 118\u2013121\nInternet, 121\u2013123\nnetwork application requirements, \n121\ntriangle routing problem, 596\ntriple-DES, 658\n3DES, 630, 669\nTTL. See time-to-live\ntunnel, 380\ntunneling, 380\nin 4G networks, 586\ntunnel mode, 669\ntwisted-pair copper wire, 47\u201348\ntwo-dimensional parity, 475\n2G cellular networks, 581\u2013582\nTymnet, 89\ntype numbers, 505\ntype of service (TOS), 359, 741, 742\nU\nubiquitous WiFi, 551, 580\nUCLA, 107, 399\nUDP. See User Datagram Protocol\nUDP segment, 529\nUDP services, 123\n850     INDEX\nUDP socket programming, 186, \n187\u2013192\nclient, 189\u2013191\nport numbers, 223\u2013224\nserver, 191\u2013192\nUDP streaming, 709, 711\nUMTS (Universal Mobile \nTelecommunications Service), \n583, 584\nunchoked peers, 174\nundetected bit errors, 473\nunguided media, 47\nunidirectional data transfer, 236\nunlicensed spectrum, 551\nunreliable services, 220\nunshielded twisted pair (UTP),  \n47\nURG bit, 265\nurgent data pointer field, 265\nURLs, SIP, 733\u2013734\nuser agents, 144\nUser Datagram Protocol (UDP), 219, \n220, 228\u2013234\nadvantages of, 229\u2013230\nchecksum, 232\u2013234\nconnectionless nature of, 229\nDNS using, 229\nfairness and, 309\u2013310\nInternet checksum in, 476\nmultimedia applications using, \n230\u2013231\nmultiplexing and demultiplexing, \n223\u2013224\nreliability with, 231\u2013232\nRTP and, 728\u2013729\nsegment", "doc_id": "0910a13c-7672-46b9-a4b9-1ca0e40ce112", "embedding": null, "doc_hash": "05f1673f426942c481aa176115ea5341e6804b22fe5d868ac621d4b181730acb", "extra_info": null, "node_info": {"start": 2465729, "end": 2468745}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "3f240d93-fb2e-4eb0-a2a9-b0a3e43219a0", "3": "0356d565-621a-4e5f-8568-babfd88426e2"}}, "__type__": "1"}, "0356d565-621a-4e5f-8568-babfd88426e2": {"__data__": {"text": "data transfer, 236\nunlicensed spectrum, 551\nunreliable services, 220\nunshielded twisted pair (UTP),  \n47\nURG bit, 265\nurgent data pointer field, 265\nURLs, SIP, 733\u2013734\nuser agents, 144\nUser Datagram Protocol (UDP), 219, \n220, 228\u2013234\nadvantages of, 229\u2013230\nchecksum, 232\u2013234\nconnectionless nature of, 229\nDNS using, 229\nfairness and, 309\u2013310\nInternet checksum in, 476\nmultimedia applications using, \n230\u2013231\nmultiplexing and demultiplexing, \n223\u2013224\nreliability with, 231\u2013232\nRTP and, 728\u2013729\nsegment structure, 232\nSkype use of, 123, 725\nin VoIP, 717\nuser state, cookies, 136\u2013138\nutilization, 247\nUTP. See unshielded twisted pairV\nVANET. See vehicular ad hoc net -\nwork\nVC networks. See virtual-circuit net -\nworks\nvehicular ad hoc network (VANET), \n553\nVerisign Global Registry Services, \n159\nvideo\nproperties of, 704\u2013705\nRTP payloads, 731\nSkype quality adaptation for, 725\nstreaming, 175\u2013176, 180\u2013184, \n707\u2013709\nvideo compression, 705\nvideo conferencing, 728\nvideo streaming, 175\u2013176\nCDNs and, 180\u2013181\nlive, 709\nNetflix platform, 182\u2013184\nP2P, 709\nprefetching, 712\u2013713\nprocessing for, 182\nrepositioning, 715\u2013716\nstored video, 707\u2013708\nvirtual-circuit networks  \n(VC networks), 520\nvirtual local area networks (VLANs), \n515\u2013519\nin data center networks, 525\nmobility within, 576\nvirtual private networks (VPNs), 522, \n665, 666\u2013667\nmobility within, 576\nviruses, 84\nvisited network, 590, 603\nvisitor location register (VLR), 603\ncall routing and, 605\nVLANs. See virtual local area  \nnetworks\nINDEX      851\nVLAN tags, 517, 518\nVLAN trunking, 517, 518\nVLR. See visitor location register\nVoice-over-IP (VoIP), 71, 548, 708, \n725\u2013728, 764\nbest-effort IP service limitations \nand, 716\u2013717\nend-to-end delay, 718\njitter removal, 719\u2013722\npacket jitter, 718\u2013719\npacket loss, 717\u2013718\nprivacy concerns, 727\nRTP, 728\u2013731\nSIP, 731\u2013736\nVoIP. See Voice-over-IP\nVPNs. See virtual private networks\nvulnerability attacks, 84\nW\nweb-based e-mail, 154\nWeb browsers, 91\u201392, 116\u2013117, 127\nconditional GET and, 143\u2013144\ncookies, 136\u2013138\nemail access via, 154\nGET requests, 132\nheader lines from, 135\u2013136\nparallel connections, 129\u2013130, 310\nSSL support, 659\nweb caches and, 138\u2013141\nWeb caching, 138\u2013144\nweb of trust, 659\nWeb page, 126\nweb page requests, 528\u2013533\nWeb servers, 91, 127\nTCP and, 227\u2013228\nWechat, 703, 727\nweighted fair queuing (WFQ),  \n356\u2013357, 744\u2013747\nwelcoming socket, 225\nwell-known application protocols,  \n223well-known port numbers, 222\nWEP. See Wired Equivalent Privacy\nWFQ. See weighted fair queuing\nwide-area wireless Internet access,  \n46\nWiFi, 32, 33, 471, 548, 560\naddress fields, 571\u2013573\narchitecture, 561\u2013565\nenterprise usage of, 44\u201345\nframes, 570\u2013573\nlink layer implementation, 471\nMAC addresses in, 571\u2013573\nMAC protocol, 565\u2013570\nmobility on same IP subnet, \n574\u2013575\npacket sniffing, 86\npayload and CRC fields, 571\npower management, 576\npublic, 92, 551\nrate adaptation,", "doc_id": "0356d565-621a-4e5f-8568-babfd88426e2", "embedding": null, "doc_hash": "e9f0dd91e8616e8d25fe3a34ffeaaa588b139da6d088ada387f467a7237e3681", "extra_info": null, "node_info": {"start": 2468783, "end": 2471648}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "0910a13c-7672-46b9-a4b9-1ca0e40ce112", "3": "1b0b6747-a405-4d9e-90d9-7a98cd6525f9"}}, "__type__": "1"}, "1b0b6747-a405-4d9e-90d9-7a98cd6525f9": {"__data__": {"text": "socket, 225\nwell-known application protocols,  \n223well-known port numbers, 222\nWEP. See Wired Equivalent Privacy\nWFQ. See weighted fair queuing\nwide-area wireless Internet access,  \n46\nWiFi, 32, 33, 471, 548, 560\naddress fields, 571\u2013573\narchitecture, 561\u2013565\nenterprise usage of, 44\u201345\nframes, 570\u2013573\nlink layer implementation, 471\nMAC addresses in, 571\u2013573\nMAC protocol, 565\u2013570\nmobility on same IP subnet, \n574\u2013575\npacket sniffing, 86\npayload and CRC fields, 571\npower management, 576\npublic, 92, 551\nrate adaptation, 575\u2013576\nsequence number, duration, and \nframe control fields, 573\nubiquitous, 551, 580\nwide-area wireless versus , 46\nWiFi jungle, 563\nwildcards, in flow table entries, 385\nWiMAX (World Interoperability for \nMicrowave Access), 588, 764\nwindow scaling factor, 264\nwindow size, 250\nin SR, 258, 259\nWired Equivalent Privacy (WEP), \n674\u2013676\nwireless communication links, 549, \n553\u2013556\ndifferences from wired links, 553\ndynamic selection of modulation \ntechniques, 555\u2013556\ninterference, 553\nmodulation techniques, 554\u2013556\nmultipath propagation, 553\n852     INDEX\nwireless communication links.  \n(continued)\nsignal strength, 553\ntransmission power, 555\ntransmission rate, 555\nwireless hops, 552\u2013553\nwireless hosts, 548\nwireless Internet devices, 547\u2013548\nwireless LANs, 45, 467\nauthentication, 564\u2013565\nbroadcast, 479\nCDMA in, 556\n4G versus , 580\ninfrastructure, 562\nsecuring, 674\u2013678\nwireless mesh networks, 552\nwireless networks, 618\nad hoc, 562\nelements of, 548\u2013552\nhandoff in, 552\nhigher-layer protocols and,  \n608\u2013610\ninfrastructure and, 550\u2013551, \n552\u2013553\nmobile ad hoc, 552\u2013553, 590\npacket sniffing, 86\ntypes of, 552\u2013553\nvehicular ad hoc, 553\nwireless personal area networks \n(WPANs), 577\u2013578Wireless Philadelphia, 551\nWireshark, 86, 105\u2013106, 515\nwork-conserving queuing, 355, 356\nWorld Wide Web, 111, 126\nworms, 84, 226\nWPANs. See wireless personal area \nnetworks\nX\nX.25 protocol suite, 91, 545\nX.509, 648\nXerox Palo Alto Research Center  \n(Xerox PARC), 506\nXTP, 476\nY\nYahoo, 92\nweb-based e-mail, 154\nYouku, 175, 703\nYouTube, 175, 707\nCDNs, 184\ndata centers, 179\nZ\nzeroconf, 370\nZigbee, 578\u2013579\nZimmerman, Phil, 658\nThis page intentionally left blank\nThis page intentionally left blank\nThis page intentionally left blank\nThis page intentionally left blank\nThis page intentionally left blank\nThis page intentionally left blank\nThis page intentionally left blank\nThis page intentionally left blank\nThis page intentionally left blank\nThis page intentionally left blank\nThis page intentionally left blank\nThis page intentionally left blank\nThis is a special edition of an established \ntitle widely used by colleges and universities \nthroughout the world. Pearson published this \nexclusive edition for the bene\ufb01t of students \noutside the United States and Canada. If you \npurchased this book within the United States \nor Canada, you should be aware that it has \nbeen imported without the approval of the \nPublisher or Author.\nPearson Global Edition\nGLOBAL  \nEDITION\nFor these Global Editions, the editorial team at Pearson has \ncollaborated with educators across the world to address a \nwide range of subjects and requirements, equipping students \nwith the best possible learning tools. This Global Edition \npreserves the cutting-edge approach and pedagogy of the \noriginal, but also features alterations, customization, and \nadaptation", "doc_id": "1b0b6747-a405-4d9e-90d9-7a98cd6525f9", "embedding": null, "doc_hash": "25efc08d65dc2d97381e1992dc1f55295bc5330672359e0a203fc64a81ac5918", "extra_info": null, "node_info": {"start": 2471635, "end": 2474987}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "0356d565-621a-4e5f-8568-babfd88426e2", "3": "aabb4c3d-fc0d-4bd9-b7a8-da002ca95d9c"}}, "__type__": "1"}, "aabb4c3d-fc0d-4bd9-b7a8-da002ca95d9c": {"__data__": {"text": "\nthroughout the world. Pearson published this \nexclusive edition for the bene\ufb01t of students \noutside the United States and Canada. If you \npurchased this book within the United States \nor Canada, you should be aware that it has \nbeen imported without the approval of the \nPublisher or Author.\nPearson Global Edition\nGLOBAL  \nEDITION\nFor these Global Editions, the editorial team at Pearson has \ncollaborated with educators across the world to address a \nwide range of subjects and requirements, equipping students \nwith the best possible learning tools. This Global Edition \npreserves the cutting-edge approach and pedagogy of the \noriginal, but also features alterations, customization, and \nadaptation from the North American version.\nKurose \u2022 Ross\n", "doc_id": "aabb4c3d-fc0d-4bd9-b7a8-da002ca95d9c", "embedding": null, "doc_hash": "d19d6350ed69b7326d794b8f5a807982f193b2fc3a4d49511298fc184612d5a0", "extra_info": null, "node_info": {"start": 2474748, "end": 2475499}, "relationships": {"1": "5fdca76f-20a7-47a4-a83c-cacec63c90c4", "2": "1b0b6747-a405-4d9e-90d9-7a98cd6525f9"}}, "__type__": "1"}}}